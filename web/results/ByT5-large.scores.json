{
    "submission_name": "ByT5-large (Baseline)",
    "param_count": 0,
    "web_nlg_ru_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_challenge_train_sample",
        "N": 501
    },
    "web_nlg_ru_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_challenge_validation_sample",
        "N": 500
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.6756756756756757,
        "vocab_size-1": 25,
        "unique-1": 18,
        "entropy-1": 4.422442136473174,
        "distinct-2": 0.8235294117647058,
        "vocab_size-2": 28,
        "unique-2": 23,
        "entropy-2": 4.712319091186707,
        "cond_entropy-2": 0.3593191219919862,
        "distinct-3": 0.8709677419354839,
        "vocab_size-3": 27,
        "unique-3": 23,
        "entropy-3": 4.696131794257844,
        "cond_entropy-3": 0.020116936948260708,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 9.666666666666666,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.32316116739216,
        "distinct-2-nopunct": 0.8076923076923077,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.286790198827111,
        "cond_entropy-2-nopunct": 0.025339011558268777,
        "distinct-3-nopunct": 0.8695652173913043,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.2626923908396215,
        "cond_entropy-3-nopunct": 0.029856477140419488,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.3333333333333333,
            "3": 0.4642857142857143
        },
        "nist": 1.0283568967780252,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "bleu": 21.95388,
        "meteor": 0.427137817418147,
        "bertscore": {
            "precision": 0.94479,
            "recall": 0.908,
            "f1": 0.92525
        },
        "nubia": {
            "semantic_relation": 3.61165,
            "contradiction": 24.24968,
            "irrelevancy": 14.72526,
            "logical_agreement": 61.02506,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.75076,
            "nubia_score": 0.68733
        },
        "bleurt": 0.04319
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.095795255000932,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.3138381850938442,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.32142857142857145
        },
        "nist": 0.37055378637852016,
        "rouge1": {
            "precision": 0.73684,
            "recall": 0.33815,
            "fmeasure": 0.46313
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.19795,
            "fmeasure": 0.2735
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.26461,
            "fmeasure": 0.3629
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.26461,
            "fmeasure": 0.3629
        },
        "bleu": 14.98803,
        "meteor": 0.21789086282835424,
        "bertscore": {
            "precision": 0.9369,
            "recall": 0.86294,
            "f1": 0.8984
        },
        "nubia": {
            "semantic_relation": 2.27856,
            "contradiction": 16.63099,
            "irrelevancy": 56.11978,
            "logical_agreement": 27.24923,
            "grammar_ref": 4.14314,
            "grammar_hyp": 4.18837,
            "nubia_score": 0.1249
        },
        "bleurt": -0.632
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.08333333333333333,
            "3": 0.11764705882352941
        },
        "nist": 0.018581109550566906,
        "rouge1": {
            "precision": 0.48148,
            "recall": 0.16626,
            "fmeasure": 0.24451
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.08201,
            "fmeasure": 0.12226
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.15725,
            "fmeasure": 0.23001
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.15725,
            "fmeasure": 0.23001
        },
        "bleu": 3.67147,
        "meteor": 0.12773948383110287,
        "bertscore": {
            "precision": 0.86267,
            "recall": 0.75826,
            "f1": 0.80584
        },
        "nubia": {
            "semantic_relation": 2.95901,
            "contradiction": 0.09589,
            "irrelevancy": 33.88114,
            "logical_agreement": 66.02298,
            "grammar_ref": 4.39709,
            "grammar_hyp": 4.77233,
            "nubia_score": 0.24124
        },
        "bleurt": -0.43961
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750188,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.2936119717201712,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.1523912776298655,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.25454711376829514,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.38095238095238093
        },
        "nist": 2.534774334934587,
        "rouge1": {
            "precision": 0.51515,
            "recall": 0.48313,
            "fmeasure": 0.49593
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.26852,
            "fmeasure": 0.25224
        },
        "rougeL": {
            "precision": 0.4697,
            "recall": 0.43995,
            "fmeasure": 0.4519
        },
        "rougeLsum": {
            "precision": 0.4697,
            "recall": 0.43995,
            "fmeasure": 0.4519
        },
        "bleu": 27.59324,
        "meteor": 0.22065286479166152,
        "bertscore": {
            "precision": 0.85512,
            "recall": 0.86622,
            "f1": 0.85791
        },
        "nubia": {
            "semantic_relation": 2.93758,
            "contradiction": 0.38355,
            "irrelevancy": 94.15661,
            "logical_agreement": 5.45984,
            "grammar_ref": 4.75948,
            "grammar_hyp": 4.88368,
            "nubia_score": 0.38403
        },
        "bleurt": -0.68968
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 3.0,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 26,
        "unique-1": 17,
        "entropy-1": 4.593400348604437,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 30,
        "unique-2": 26,
        "entropy-2": 4.852168723603279,
        "cond_entropy-2": 0.23385806045989377,
        "distinct-3": 0.90625,
        "vocab_size-3": 29,
        "unique-3": 26,
        "entropy-3": 4.8125,
        "cond_entropy-3": -0.02496284125033941,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.476064195050471,
        "distinct-2-nopunct": 0.8709677419354839,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.696131794257844,
        "cond_entropy-2-nopunct": 0.2567340459369209,
        "distinct-3-nopunct": 0.896551724137931,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.651084443403434,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.3409090909090909
        },
        "nist": 0.9837986849118412,
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.29825,
            "fmeasure": 0.34759
        },
        "rouge2": {
            "precision": 0.13846,
            "recall": 0.09674,
            "fmeasure": 0.11389
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.25526,
            "fmeasure": 0.29768
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.25526,
            "fmeasure": 0.29768
        },
        "bleu": 9.82564,
        "meteor": 0.1484496228072474,
        "bertscore": {
            "precision": 0.81192,
            "recall": 0.75674,
            "f1": 0.78292
        },
        "nubia": {
            "semantic_relation": 2.62145,
            "contradiction": 26.01248,
            "irrelevancy": 72.03756,
            "logical_agreement": 1.94996,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.06365,
            "nubia_score": 0.21746
        },
        "bleurt": -0.61848
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "nist": 1.0,
        "rouge1": {
            "precision": 0.26667,
            "recall": 0.26667,
            "fmeasure": 0.26667
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.07143,
            "fmeasure": 0.07143
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "bleu": 5.81664,
        "meteor": 0.11611197449693993,
        "bertscore": {
            "precision": 0.78903,
            "recall": 0.79034,
            "f1": 0.78964
        },
        "nubia": {
            "semantic_relation": 2.24515,
            "contradiction": 10.29014,
            "irrelevancy": 89.43458,
            "logical_agreement": 0.27528,
            "grammar_ref": 5.48676,
            "grammar_hyp": 3.98562,
            "nubia_score": 0.24994
        },
        "bleurt": -0.35023
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.46153846153846156
        },
        "nist": 1.6111111111111112,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.46667,
            "fmeasure": 0.46667
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.14286,
            "fmeasure": 0.14286
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "bleu": 3.61197,
        "meteor": 0.17777777777777778,
        "bertscore": {
            "precision": 0.76803,
            "recall": 0.82087,
            "f1": 0.79357
        },
        "nubia": {
            "semantic_relation": 3.02194,
            "contradiction": 6.46497,
            "irrelevancy": 93.10373,
            "logical_agreement": 0.4313,
            "grammar_ref": 5.57252,
            "grammar_hyp": 4.96939,
            "nubia_score": 0.36084
        },
        "bleurt": -0.62634
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nist": 1.513656186816603,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.66154,
            "fmeasure": 0.66029
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.41667,
            "fmeasure": 0.41394
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.66154,
            "fmeasure": 0.66029
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.66154,
            "fmeasure": 0.66029
        },
        "bleu": 37.99178,
        "meteor": 0.39550668585199933,
        "bertscore": {
            "precision": 0.97439,
            "recall": 0.97461,
            "f1": 0.96311
        },
        "nubia": {
            "semantic_relation": 2.66013,
            "contradiction": 98.26216,
            "irrelevancy": 1.18859,
            "logical_agreement": 0.54925,
            "grammar_ref": 6.66832,
            "grammar_hyp": 7.32039,
            "nubia_score": 0.14589
        },
        "bleurt": 0.14999
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.767894147619623,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 20,
        "unique-2": 17,
        "entropy-2": 4.2626923908396215,
        "cond_entropy-2": 0.4868446933548487,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 20,
        "unique-3": 18,
        "entropy-3": 4.277613436819114,
        "cond_entropy-3": -0.018675791965170108,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6521739130434783,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.6709688919510652,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.186704345910023,
        "cond_entropy-2-nopunct": 0.5090351386910487,
        "distinct-3-nopunct": 0.9047619047619048,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.201841232302569,
        "cond_entropy-3-nopunct": -0.019495148239489106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 2.65492402811578,
        "rouge1": {
            "precision": 0.50725,
            "recall": 0.66222,
            "fmeasure": 0.56652
        },
        "rouge2": {
            "precision": 0.24242,
            "recall": 0.32143,
            "fmeasure": 0.27214
        },
        "rougeL": {
            "precision": 0.34783,
            "recall": 0.48889,
            "fmeasure": 0.40473
        },
        "rougeLsum": {
            "precision": 0.34783,
            "recall": 0.48889,
            "fmeasure": 0.40473
        },
        "bleu": 11.32836,
        "meteor": 0.28995137140292404,
        "bertscore": {
            "precision": 0.78819,
            "recall": 0.81469,
            "f1": 0.78363
        },
        "nubia": {
            "semantic_relation": 3.53416,
            "contradiction": 45.10359,
            "irrelevancy": 46.00197,
            "logical_agreement": 8.89443,
            "grammar_ref": 4.19943,
            "grammar_hyp": 2.77771,
            "nubia_score": 0.67072
        },
        "bleurt": -0.29383
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.229871195093384,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.24291000358771486,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.6071428571428571
        },
        "nist": 0.3776253920295472,
        "rouge1": {
            "precision": 0.97368,
            "recall": 0.48571,
            "fmeasure": 0.64693
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.31313,
            "fmeasure": 0.41949
        },
        "rougeL": {
            "precision": 0.71053,
            "recall": 0.35476,
            "fmeasure": 0.47237
        },
        "rougeLsum": {
            "precision": 0.71053,
            "recall": 0.35476,
            "fmeasure": 0.47237
        },
        "bleu": 22.51599,
        "meteor": 0.27669307680864397,
        "bertscore": {
            "precision": 0.95321,
            "recall": 0.86536,
            "f1": 0.90716
        },
        "nubia": {
            "semantic_relation": 3.27419,
            "contradiction": 4.74177,
            "irrelevancy": 1.05689,
            "logical_agreement": 94.20134,
            "grammar_ref": 3.72412,
            "grammar_hyp": 4.73068,
            "nubia_score": 0.30895
        },
        "bleurt": -0.09684
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.7058823529411765,
        "vocab_size-1": 24,
        "unique-1": 16,
        "entropy-1": 4.454822399946606,
        "distinct-2": 0.9375,
        "vocab_size-2": 30,
        "unique-2": 28,
        "entropy-2": 4.875,
        "cond_entropy-2": 0.39721762763487756,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 29,
        "unique-3": 28,
        "entropy-3": 4.840223928941852,
        "cond_entropy-3": -0.02644273772481478,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.71875,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.390319531114783,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.773557262275186,
        "cond_entropy-2-nopunct": 0.4238830957527498,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.735926350629034,
        "cond_entropy-3-nopunct": -0.02810710212234294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7666666666666667
        },
        "nist": 4.0134926600372,
        "rouge1": {
            "precision": 0.88312,
            "recall": 0.74923,
            "fmeasure": 0.8015
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.56316,
            "fmeasure": 0.59974
        },
        "rougeL": {
            "precision": 0.69481,
            "recall": 0.57097,
            "fmeasure": 0.61973
        },
        "rougeLsum": {
            "precision": 0.69481,
            "recall": 0.57097,
            "fmeasure": 0.61973
        },
        "bleu": 52.98059,
        "meteor": 0.4083200848226998,
        "bertscore": {
            "precision": 0.9537,
            "recall": 0.92697,
            "f1": 0.93945
        },
        "nubia": {
            "semantic_relation": 3.69398,
            "contradiction": 40.0872,
            "irrelevancy": 20.90145,
            "logical_agreement": 39.01134,
            "grammar_ref": 4.80653,
            "grammar_hyp": 4.84025,
            "nubia_score": 0.50465
        },
        "bleurt": 0.15178
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.11475004073479994,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75
        },
        "nist": 3.596705286039819,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.71181,
            "fmeasure": 0.75269
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.38039,
            "fmeasure": 0.40267
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.65278,
            "fmeasure": 0.69013
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.65278,
            "fmeasure": 0.69013
        },
        "bleu": 35.55191,
        "meteor": 0.39652135491015644,
        "bertscore": {
            "precision": 0.94946,
            "recall": 0.94004,
            "f1": 0.94472
        },
        "nubia": {
            "semantic_relation": 4.20327,
            "contradiction": 6.82207,
            "irrelevancy": 48.09893,
            "logical_agreement": 45.079,
            "grammar_ref": 4.60656,
            "grammar_hyp": 5.34396,
            "nubia_score": 0.57554
        },
        "bleurt": 0.35647
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.14285714285714285
        },
        "nist": 1.8175097543287453,
        "rouge1": {
            "precision": 0.40909,
            "recall": 0.3,
            "fmeasure": 0.33641
        },
        "rouge2": {
            "precision": 0.15,
            "recall": 0.07895,
            "fmeasure": 0.10345
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.275,
            "fmeasure": 0.30415
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.275,
            "fmeasure": 0.30415
        },
        "bleu": 18.36028,
        "meteor": 0.11804813852776577,
        "bertscore": {
            "precision": 0.82896,
            "recall": 0.80136,
            "f1": 0.81492
        },
        "nubia": {
            "semantic_relation": 1.97358,
            "contradiction": 97.79464,
            "irrelevancy": 1.45405,
            "logical_agreement": 0.75131,
            "grammar_ref": 5.69136,
            "grammar_hyp": 4.19649,
            "nubia_score": 0.16588
        },
        "bleurt": -0.1276
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.6402239289418516,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.11475004073479993,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05263157894736842,
            "2": 0.2727272727272727
        },
        "nist": 0.05719092773719586,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.21515,
            "fmeasure": 0.29521
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.01852,
            "fmeasure": 0.02857
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.16515,
            "fmeasure": 0.23138
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.16515,
            "fmeasure": 0.23138
        },
        "bleu": 3.16121,
        "meteor": 0.09061488673139158,
        "bertscore": {
            "precision": 0.88689,
            "recall": 0.79575,
            "f1": 0.82894
        },
        "nubia": {
            "semantic_relation": 2.27944,
            "contradiction": 96.12551,
            "irrelevancy": 2.47853,
            "logical_agreement": 1.39596,
            "grammar_ref": 4.34131,
            "grammar_hyp": 4.21095,
            "nubia_score": 0.19657
        },
        "bleurt": -0.24717
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.916126946588283,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.42961067210860193,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.821928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.4523152080299073,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nist": 1.4789434453340473,
        "rouge1": {
            "precision": 0.28333,
            "recall": 0.3635,
            "fmeasure": 0.31723
        },
        "rouge2": {
            "precision": 0.05263,
            "recall": 0.07639,
            "fmeasure": 0.06206
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.31222,
            "fmeasure": 0.27682
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.31222,
            "fmeasure": 0.27682
        },
        "bleu": 5.23752,
        "meteor": 0.14516384509432115,
        "bertscore": {
            "precision": 0.65164,
            "recall": 0.66635,
            "f1": 0.65854
        },
        "nubia": {
            "semantic_relation": 1.29963,
            "contradiction": 22.78174,
            "irrelevancy": 75.0121,
            "logical_agreement": 2.20616,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.49215,
            "nubia_score": 0.14288
        },
        "bleurt": -0.73834
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.9
        },
        "nist": 3.512201038453565,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.85348,
            "fmeasure": 0.81363
        },
        "rouge2": {
            "precision": 0.59524,
            "recall": 0.65598,
            "fmeasure": 0.62393
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.85348,
            "fmeasure": 0.81363
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.85348,
            "fmeasure": 0.81363
        },
        "bleu": 56.64313,
        "meteor": 0.4398027655070263,
        "bertscore": {
            "precision": 0.91731,
            "recall": 0.95134,
            "f1": 0.93402
        },
        "nubia": {
            "semantic_relation": 2.13423,
            "contradiction": 82.96958,
            "irrelevancy": 16.60469,
            "logical_agreement": 0.42573,
            "grammar_ref": 4.48671,
            "grammar_hyp": 4.04266,
            "nubia_score": 0.22161
        },
        "bleurt": 0.07397
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.3845171317931,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.2532445236699311,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": 0.023416471633632502,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.315824333525707,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.4838561897747224,
        "cond_entropy-2-nopunct": 0.18341647163363248,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": 0.10777297761309834,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4666666666666667
        },
        "nist": 1.2609029705085284,
        "rouge1": {
            "precision": 0.26923,
            "recall": 0.41176,
            "fmeasure": 0.32558
        },
        "rouge2": {
            "precision": 0.16,
            "recall": 0.25,
            "fmeasure": 0.19512
        },
        "rougeL": {
            "precision": 0.19231,
            "recall": 0.29412,
            "fmeasure": 0.23256
        },
        "rougeLsum": {
            "precision": 0.19231,
            "recall": 0.29412,
            "fmeasure": 0.23256
        },
        "bleu": 14.61178,
        "meteor": 0.20326368596694702,
        "bertscore": {
            "precision": 0.77115,
            "recall": 0.79445,
            "f1": 0.78263
        },
        "nubia": {
            "semantic_relation": 1.92508,
            "contradiction": 16.62051,
            "irrelevancy": 83.16098,
            "logical_agreement": 0.2185,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.05981,
            "nubia_score": 0.23597
        },
        "bleurt": -0.47352
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 124,
        "msttr-100": 0.70259,
        "msttr-100_nopunct": 0.73708,
        "total_length": 2790,
        "mean_pred_length": 22.5,
        "std_pred_length": 4.151369770056859,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.4290322580645161,
        "vocab_size-1": 1197,
        "unique-1": 925,
        "entropy-1": 8.537817115295521,
        "distinct-2": 0.8135783945986497,
        "vocab_size-2": 2169,
        "unique-2": 1928,
        "entropy-2": 10.809319993879965,
        "cond_entropy-2": 2.234043689279055,
        "distinct-3": 0.9461054287962234,
        "vocab_size-3": 2405,
        "unique-3": 2294,
        "entropy-3": 11.194215602191802,
        "cond_entropy-3": 0.4033739198080395,
        "total_length-nopunct": 2478,
        "mean_pred_length-nopunct": 19.983870967741936,
        "std_pred_length-nopunct": 3.8874983061250163,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.47901533494753834,
        "vocab_size-1-nopunct": 1187,
        "unique-1-nopunct": 923,
        "entropy-1-nopunct": 8.770299000005084,
        "distinct-2-nopunct": 0.8347493627867459,
        "vocab_size-2-nopunct": 1965,
        "unique-2-nopunct": 1779,
        "entropy-2-nopunct": 10.683380981431018,
        "cond_entropy-2-nopunct": 2.0044948038678454,
        "distinct-3-nopunct": 0.9556053811659193,
        "vocab_size-3-nopunct": 2131,
        "unique-3-nopunct": 2053,
        "entropy-3-nopunct": 11.024624533615476,
        "cond_entropy-3-nopunct": 0.3648252664560766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.3724604966139955,
            "3": 0.6725708502024291
        },
        "nist": 6.578787607103104,
        "rouge1": {
            "precision": 0.71813,
            "recall": 0.63712,
            "fmeasure": 0.66435
        },
        "rouge2": {
            "precision": 0.43652,
            "recall": 0.39282,
            "fmeasure": 0.40532
        },
        "rougeL": {
            "precision": 0.57679,
            "recall": 0.52289,
            "fmeasure": 0.53831
        },
        "rougeLsum": {
            "precision": 0.57679,
            "recall": 0.52289,
            "fmeasure": 0.53831
        },
        "bleu": 31.8594,
        "meteor": 0.3194438922756507,
        "bertscore": {
            "precision": 0.90745,
            "recall": 0.89423,
            "f1": 0.89886
        },
        "nubia": {
            "semantic_relation": 3.72532,
            "contradiction": 16.38037,
            "irrelevancy": 35.69477,
            "logical_agreement": 47.92486,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.30579,
            "nubia_score": 0.58492
        },
        "bleurt": -0.02785
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.070656113151928,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.2673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9057645846554525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.2222222222222222
        },
        "nist": 2.4457301827671785,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.29032,
            "fmeasure": 0.36735
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.06667,
            "fmeasure": 0.08511
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.22581,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.22581,
            "fmeasure": 0.28571
        },
        "bleu": 8.67235,
        "meteor": 0.15934678489236104,
        "bertscore": {
            "precision": 0.88009,
            "recall": 0.81077,
            "f1": 0.84401
        },
        "nubia": {
            "semantic_relation": 1.45749,
            "contradiction": 70.31196,
            "irrelevancy": 27.24476,
            "logical_agreement": 2.44329,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.45232,
            "nubia_score": 0.11025
        },
        "bleurt": -0.44075
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "msttr-100": 0.70857,
        "msttr-100_nopunct": 0.75375,
        "total_length": 2803,
        "mean_pred_length": 16.8855421686747,
        "std_pred_length": 5.865369728793805,
        "median_pred_length": 17.5,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.4370317516946129,
        "vocab_size-1": 1225,
        "unique-1": 957,
        "entropy-1": 8.490698936556207,
        "distinct-2": 0.850967007963595,
        "vocab_size-2": 2244,
        "unique-2": 2097,
        "entropy-2": 10.866143551050259,
        "cond_entropy-2": 2.1923303580496043,
        "distinct-3": 0.9664103601780656,
        "vocab_size-3": 2388,
        "unique-3": 2336,
        "entropy-3": 11.188463779144353,
        "cond_entropy-3": 0.3448849219825455,
        "total_length-nopunct": 2480,
        "mean_pred_length-nopunct": 14.939759036144578,
        "std_pred_length-nopunct": 5.293436257462249,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.49032258064516127,
        "vocab_size-1-nopunct": 1216,
        "unique-1-nopunct": 956,
        "entropy-1-nopunct": 8.756705328622614,
        "distinct-2-nopunct": 0.8686257562662058,
        "vocab_size-2-nopunct": 2010,
        "unique-2-nopunct": 1892,
        "entropy-2-nopunct": 10.733472376471683,
        "cond_entropy-2-nopunct": 2.1107437037919423,
        "distinct-3-nopunct": 0.9767225325884544,
        "vocab_size-3-nopunct": 2098,
        "unique-3-nopunct": 2059,
        "entropy-3-nopunct": 11.017901084077392,
        "cond_entropy-3-nopunct": 0.3096374963643258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.037456875308033516,
            "2": 0.13978494623655913,
            "3": 0.3309608540925267,
            "4": 0.5064377682403434,
            "5": 0.6774193548387096,
            "6": 0.7386363636363636,
            "7": 0.7323943661971831,
            "8": 0.7813504823151125,
            "9": 0.8712121212121212,
            "10": 0.9257425742574258
        },
        "nist": 11.266025702182178,
        "rouge1": {
            "precision": 0.84824,
            "recall": 0.86444,
            "fmeasure": 0.84276
        },
        "rouge2": {
            "precision": 0.75494,
            "recall": 0.76764,
            "fmeasure": 0.74521
        },
        "rougeL": {
            "precision": 0.83182,
            "recall": 0.85229,
            "fmeasure": 0.82929
        },
        "rougeLsum": {
            "precision": 0.83182,
            "recall": 0.85229,
            "fmeasure": 0.82929
        },
        "bleu": 78.15992,
        "meteor": 0.5042023183757484,
        "bertscore": {
            "precision": 0.95888,
            "recall": 0.96563,
            "f1": 0.95857
        },
        "nubia": {
            "semantic_relation": 4.08293,
            "contradiction": 4.21467,
            "irrelevancy": 34.23858,
            "logical_agreement": 61.54675,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.75307,
            "nubia_score": 0.63155
        },
        "bleurt": 0.20378
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "msttr-100": 0.72545,
        "msttr-100_nopunct": 0.755,
        "total_length": 1138,
        "mean_pred_length": 19.620689655172413,
        "std_pred_length": 5.89221457754417,
        "median_pred_length": 20.5,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.5017574692442882,
        "vocab_size-1": 571,
        "unique-1": 459,
        "entropy-1": 8.00590136677908,
        "distinct-2": 0.8935185185185185,
        "vocab_size-2": 965,
        "unique-2": 914,
        "entropy-2": 9.755117767935637,
        "cond_entropy-2": 1.667031402056213,
        "distinct-3": 0.9637964774951077,
        "vocab_size-3": 985,
        "unique-3": 970,
        "entropy-3": 9.87759882274631,
        "cond_entropy-3": 0.13625161409427217,
        "total_length-nopunct": 1007,
        "mean_pred_length-nopunct": 17.362068965517242,
        "std_pred_length-nopunct": 5.221633632144945,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5580933465739821,
        "vocab_size-1-nopunct": 562,
        "unique-1-nopunct": 458,
        "entropy-1-nopunct": 8.170281669574441,
        "distinct-2-nopunct": 0.9357218124341412,
        "vocab_size-2-nopunct": 888,
        "unique-2-nopunct": 846,
        "entropy-2-nopunct": 9.738423437792182,
        "cond_entropy-2-nopunct": 1.6347017121053296,
        "distinct-3-nopunct": 0.9876543209876543,
        "vocab_size-3-nopunct": 880,
        "unique-3-nopunct": 869,
        "entropy-3-nopunct": 9.774590263497299,
        "cond_entropy-3-nopunct": 0.04090510423993262,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.026595744680851064,
            "2": 0.1744186046511628,
            "3": 0.24503311258278146,
            "4": 0.4636363636363636,
            "5": 0.6296296296296297,
            "6": 0.6826923076923077,
            "7": 0.7280701754385965,
            "8": 0.7959183673469388,
            "9": 0.7843137254901961,
            "10": 0.92018779342723
        },
        "nist": 10.675024564058294,
        "rouge1": {
            "precision": 0.87154,
            "recall": 0.81559,
            "fmeasure": 0.8316
        },
        "rouge2": {
            "precision": 0.77421,
            "recall": 0.71243,
            "fmeasure": 0.73005
        },
        "rougeL": {
            "precision": 0.85344,
            "recall": 0.79763,
            "fmeasure": 0.8132
        },
        "rougeLsum": {
            "precision": 0.85344,
            "recall": 0.79763,
            "fmeasure": 0.8132
        },
        "bleu": 80.71123,
        "meteor": 0.46078497921129397,
        "bertscore": {
            "precision": 0.95231,
            "recall": 0.95127,
            "f1": 0.94835
        },
        "nubia": {
            "semantic_relation": 4.00503,
            "contradiction": 5.45021,
            "irrelevancy": 32.40531,
            "logical_agreement": 62.14447,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.88885,
            "nubia_score": 0.58812
        },
        "bleurt": 0.06256
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 183,
        "msttr-100": 0.179,
        "msttr-100_nopunct": 0.16647,
        "total_length": 2066,
        "mean_pred_length": 11.289617486338798,
        "std_pred_length": 1.840126915948477,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 13,
        "distinct-1": 0.02420135527589545,
        "vocab_size-1": 50,
        "unique-1": 10,
        "entropy-1": 4.001093390459525,
        "distinct-2": 0.03983005841741901,
        "vocab_size-2": 75,
        "unique-2": 22,
        "entropy-2": 4.134549832798778,
        "cond_entropy-2": 0.08445863551622115,
        "distinct-3": 0.041176470588235294,
        "vocab_size-3": 70,
        "unique-3": 22,
        "entropy-3": 4.015424143712819,
        "cond_entropy-3": -0.06750754401896,
        "total_length-nopunct": 1717,
        "mean_pred_length-nopunct": 9.382513661202186,
        "std_pred_length-nopunct": 1.5492357426890826,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.027955736750145604,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.8230221768872443,
        "distinct-2-nopunct": 0.03911342894393742,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 3.8295300854737016,
        "cond_entropy-2-nopunct": 0.05029882673731423,
        "distinct-3-nopunct": 0.04145077720207254,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 3.679530584627029,
        "cond_entropy-3-nopunct": -0.10969622305817875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.21036889332003988
        },
        "nist": 0.8753083642858362,
        "rouge1": {
            "precision": 0.20379,
            "recall": 0.32398,
            "fmeasure": 0.23567
        },
        "rouge2": {
            "precision": 0.09447,
            "recall": 0.14568,
            "fmeasure": 0.1055
        },
        "rougeL": {
            "precision": 0.17368,
            "recall": 0.27795,
            "fmeasure": 0.20093
        },
        "rougeLsum": {
            "precision": 0.17368,
            "recall": 0.27795,
            "fmeasure": 0.20093
        },
        "bleu": 3.76138,
        "meteor": 0.10537227285766933,
        "bertscore": {
            "precision": 0.85416,
            "recall": 0.88075,
            "f1": 0.86709
        },
        "nubia": {
            "semantic_relation": 1.88361,
            "contradiction": 23.09566,
            "irrelevancy": 33.25784,
            "logical_agreement": 43.6465,
            "grammar_ref": 6.72681,
            "grammar_hyp": 6.03995,
            "nubia_score": 0.1727
        },
        "bleurt": -0.44456
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 71,
        "msttr-100": 0.64222,
        "msttr-100_nopunct": 0.6825,
        "total_length": 907,
        "mean_pred_length": 12.774647887323944,
        "std_pred_length": 4.219996606028245,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.4255788313120176,
        "vocab_size-1": 386,
        "unique-1": 304,
        "entropy-1": 7.125402115526138,
        "distinct-2": 0.777511961722488,
        "vocab_size-2": 650,
        "unique-2": 577,
        "entropy-2": 9.002485886333131,
        "cond_entropy-2": 1.600466536603725,
        "distinct-3": 0.8849673202614379,
        "vocab_size-3": 677,
        "unique-3": 634,
        "entropy-3": 9.267437269052092,
        "cond_entropy-3": 0.273875199057622,
        "total_length-nopunct": 819,
        "mean_pred_length-nopunct": 11.535211267605634,
        "std_pred_length-nopunct": 3.924753462843035,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.46642246642246643,
        "vocab_size-1-nopunct": 382,
        "unique-1-nopunct": 304,
        "entropy-1-nopunct": 7.273021170711709,
        "distinct-2-nopunct": 0.7820855614973262,
        "vocab_size-2-nopunct": 585,
        "unique-2-nopunct": 518,
        "entropy-2-nopunct": 8.856515759296963,
        "cond_entropy-2-nopunct": 1.7394860830620023,
        "distinct-3-nopunct": 0.880354505169867,
        "vocab_size-3-nopunct": 596,
        "unique-3-nopunct": 555,
        "entropy-3-nopunct": 9.08052676668056,
        "cond_entropy-3-nopunct": 0.28459725220188686,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26256983240223464,
            "2": 0.6894736842105263,
            "3": 0.8313253012048193
        },
        "nist": 7.054430927772463,
        "rouge1": {
            "precision": 0.74156,
            "recall": 0.80381,
            "fmeasure": 0.75468
        },
        "rouge2": {
            "precision": 0.55551,
            "recall": 0.61526,
            "fmeasure": 0.57003
        },
        "rougeL": {
            "precision": 0.70838,
            "recall": 0.77907,
            "fmeasure": 0.72584
        },
        "rougeLsum": {
            "precision": 0.70838,
            "recall": 0.77907,
            "fmeasure": 0.72584
        },
        "bleu": 55.14464,
        "meteor": 0.44343657876467796,
        "bertscore": {
            "precision": 0.93915,
            "recall": 0.95175,
            "f1": 0.94386
        },
        "nubia": {
            "semantic_relation": 4.17623,
            "contradiction": 4.80764,
            "irrelevancy": 48.59708,
            "logical_agreement": 46.59528,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.03675,
            "nubia_score": 0.73071
        },
        "bleurt": 0.42707
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "msttr-100": 0.73167,
        "msttr-100_nopunct": 0.752,
        "total_length": 618,
        "mean_pred_length": 19.3125,
        "std_pred_length": 4.64648724844909,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.5566343042071198,
        "vocab_size-1": 344,
        "unique-1": 277,
        "entropy-1": 7.595028249026751,
        "distinct-2": 0.9078498293515358,
        "vocab_size-2": 532,
        "unique-2": 503,
        "entropy-2": 8.9615345156844,
        "cond_entropy-2": 1.2702246220464097,
        "distinct-3": 0.9729241877256317,
        "vocab_size-3": 539,
        "unique-3": 533,
        "entropy-3": 9.0383370441886,
        "cond_entropy-3": 0.08199774933246513,
        "total_length-nopunct": 547,
        "mean_pred_length-nopunct": 17.09375,
        "std_pred_length-nopunct": 3.9793166420253616,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6142595978062158,
        "vocab_size-1-nopunct": 336,
        "unique-1-nopunct": 275,
        "entropy-1-nopunct": 7.693244668253864,
        "distinct-2-nopunct": 0.9359223300970874,
        "vocab_size-2-nopunct": 482,
        "unique-2-nopunct": 461,
        "entropy-2-nopunct": 8.858168276468156,
        "cond_entropy-2-nopunct": 1.2155441785515952,
        "distinct-3-nopunct": 0.9937888198757764,
        "vocab_size-3-nopunct": 480,
        "unique-3-nopunct": 477,
        "entropy-3-nopunct": 8.903457018587291,
        "cond_entropy-3-nopunct": 0.055243878887872126,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.043121149897330596,
            "2": 0.14018691588785046,
            "3": 0.30985915492957744,
            "4": 0.546875,
            "5": 0.7090909090909091,
            "6": 0.7205882352941176,
            "7": 0.7727272727272727,
            "8": 0.7936507936507936,
            "9": 0.8095238095238095,
            "10": 0.9516129032258065
        },
        "nist": 10.030354583609679,
        "rouge1": {
            "precision": 0.85769,
            "recall": 0.84417,
            "fmeasure": 0.8424
        },
        "rouge2": {
            "precision": 0.74495,
            "recall": 0.74178,
            "fmeasure": 0.73423
        },
        "rougeL": {
            "precision": 0.83739,
            "recall": 0.83128,
            "fmeasure": 0.82621
        },
        "rougeLsum": {
            "precision": 0.83739,
            "recall": 0.83128,
            "fmeasure": 0.82621
        },
        "bleu": 81.68414,
        "meteor": 0.49533891771219474,
        "bertscore": {
            "precision": 0.95407,
            "recall": 0.96379,
            "f1": 0.95471
        },
        "nubia": {
            "semantic_relation": 4.29702,
            "contradiction": 2.48116,
            "irrelevancy": 35.29278,
            "logical_agreement": 62.22606,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.69486,
            "nubia_score": 0.68555
        },
        "bleurt": 0.1893
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 81,
        "mean_pred_length": 16.2,
        "std_pred_length": 6.615134163416491,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.7654320987654321,
        "vocab_size-1": 62,
        "unique-1": 51,
        "entropy-1": 5.7654138916132505,
        "distinct-2": 0.9868421052631579,
        "vocab_size-2": 75,
        "unique-2": 74,
        "entropy-2": 6.221611723969907,
        "cond_entropy-2": 0.4182674778065576,
        "distinct-3": 1.0,
        "vocab_size-3": 71,
        "unique-3": 71,
        "entropy-3": 6.149747119504677,
        "cond_entropy-3": -0.08409588689664996,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 15.2,
        "std_pred_length-nopunct": 6.615134163416491,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.724579651459151,
        "distinct-2-nopunct": 0.9859154929577465,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.12157810542017,
        "cond_entropy-2-nopunct": 0.40568492311486176,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.044394119358462,
        "cond_entropy-3-nopunct": -0.09020148499471337,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.06944444444444445,
            "2": 0.23809523809523808,
            "3": 0.375,
            "4": 0.4,
            "5": 0.5714285714285714,
            "6": 0.7692307692307693,
            "7": 0.8333333333333334,
            "8": 0.8333333333333334,
            "9": 0.75,
            "10": 0.8095238095238095
        },
        "nist": 7.535373234721606,
        "rouge1": {
            "precision": 0.84515,
            "recall": 0.81993,
            "fmeasure": 0.81791
        },
        "rouge2": {
            "precision": 0.87922,
            "recall": 0.69804,
            "fmeasure": 0.74811
        },
        "rougeL": {
            "precision": 0.84258,
            "recall": 0.82083,
            "fmeasure": 0.81693
        },
        "rougeLsum": {
            "precision": 0.84258,
            "recall": 0.82083,
            "fmeasure": 0.81693
        },
        "bleu": 83.47989,
        "meteor": 0.5160561731326878,
        "bertscore": {
            "precision": 0.96789,
            "recall": 0.95278,
            "f1": 0.95311
        },
        "nubia": {
            "semantic_relation": 3.82294,
            "contradiction": 0.44288,
            "irrelevancy": 42.97813,
            "logical_agreement": 56.57899,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.44646,
            "nubia_score": 0.58473
        },
        "bleurt": 0.06962
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 200,
        "msttr-100": 0.77304,
        "msttr-100_nopunct": 0.848,
        "total_length": 2365,
        "mean_pred_length": 11.825,
        "std_pred_length": 2.5148310082389234,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 19,
        "distinct-1": 0.4071881606765328,
        "vocab_size-1": 963,
        "unique-1": 653,
        "entropy-1": 8.527548855243015,
        "distinct-2": 0.7501154734411085,
        "vocab_size-2": 1624,
        "unique-2": 1325,
        "entropy-2": 10.412268310150985,
        "cond_entropy-2": 1.8800564602970236,
        "distinct-3": 0.9002544529262086,
        "vocab_size-3": 1769,
        "unique-3": 1606,
        "entropy-3": 10.724594731268654,
        "cond_entropy-3": 0.359301068099892,
        "total_length-nopunct": 2012,
        "mean_pred_length-nopunct": 10.06,
        "std_pred_length-nopunct": 2.065526567246231,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.47564612326043737,
        "vocab_size-1-nopunct": 957,
        "unique-1-nopunct": 652,
        "entropy-1-nopunct": 8.947074140652074,
        "distinct-2-nopunct": 0.7886313465783664,
        "vocab_size-2-nopunct": 1429,
        "unique-2-nopunct": 1204,
        "entropy-2-nopunct": 10.28181385072513,
        "cond_entropy-2-nopunct": 1.470093882456269,
        "distinct-3-nopunct": 0.9205955334987593,
        "vocab_size-3-nopunct": 1484,
        "unique-3-nopunct": 1376,
        "entropy-3-nopunct": 10.483349965290644,
        "cond_entropy-3-nopunct": 0.2518239168394132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.187683284457478,
            "2": 0.4425403225806452,
            "3": 0.6697009102730819,
            "4": 0.85,
            "5": 0.6153846153846154,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 5.644291364428092,
        "rouge1": {
            "precision": 0.28239,
            "recall": 0.25694,
            "fmeasure": 0.2631
        },
        "rouge2": {
            "precision": 0.12364,
            "recall": 0.11157,
            "fmeasure": 0.11576
        },
        "rougeL": {
            "precision": 0.27116,
            "recall": 0.24656,
            "fmeasure": 0.25224
        },
        "rougeLsum": {
            "precision": 0.27116,
            "recall": 0.24656,
            "fmeasure": 0.25224
        },
        "bleu": 34.03562,
        "meteor": 0.4999840432506645,
        "bertscore": {
            "precision": 0.95251,
            "recall": 0.93123,
            "f1": 0.94074
        },
        "nubia": {
            "semantic_relation": 3.68934,
            "contradiction": 21.40313,
            "irrelevancy": 24.15268,
            "logical_agreement": 54.44419,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.72289,
            "nubia_score": 0.73222
        },
        "bleurt": 0.10902
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 52,
        "msttr-100": 0.63571,
        "msttr-100_nopunct": 0.67167,
        "total_length": 784,
        "mean_pred_length": 15.076923076923077,
        "std_pred_length": 5.04535640978664,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.4260204081632653,
        "vocab_size-1": 334,
        "unique-1": 258,
        "entropy-1": 7.0615431655749346,
        "distinct-2": 0.7622950819672131,
        "vocab_size-2": 558,
        "unique-2": 490,
        "entropy-2": 8.774928656086233,
        "cond_entropy-2": 1.5169588702724814,
        "distinct-3": 0.875,
        "vocab_size-3": 595,
        "unique-3": 557,
        "entropy-3": 9.0528317300859,
        "cond_entropy-3": 0.27677938129229984,
        "total_length-nopunct": 684,
        "mean_pred_length-nopunct": 13.153846153846153,
        "std_pred_length-nopunct": 4.266977922571897,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.48099415204678364,
        "vocab_size-1-nopunct": 329,
        "unique-1-nopunct": 257,
        "entropy-1-nopunct": 7.198432313601789,
        "distinct-2-nopunct": 0.7863924050632911,
        "vocab_size-2-nopunct": 497,
        "unique-2-nopunct": 443,
        "entropy-2-nopunct": 8.639484820156369,
        "cond_entropy-2-nopunct": 1.5156417470086354,
        "distinct-3-nopunct": 0.8879310344827587,
        "vocab_size-3-nopunct": 515,
        "unique-3-nopunct": 484,
        "entropy-3-nopunct": 8.87500431626472,
        "cond_entropy-3-nopunct": 0.27380145861552696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3026315789473684,
            "2": 0.5297297297297298,
            "3": 0.8097686375321337
        },
        "nist": 6.547615062930007,
        "rouge1": {
            "precision": 0.7114,
            "recall": 0.76352,
            "fmeasure": 0.72233
        },
        "rouge2": {
            "precision": 0.51637,
            "recall": 0.53264,
            "fmeasure": 0.51461
        },
        "rougeL": {
            "precision": 0.66538,
            "recall": 0.71398,
            "fmeasure": 0.6756
        },
        "rougeLsum": {
            "precision": 0.66538,
            "recall": 0.71398,
            "fmeasure": 0.6756
        },
        "bleu": 47.94533,
        "meteor": 0.4186955621156459,
        "bertscore": {
            "precision": 0.92414,
            "recall": 0.93695,
            "f1": 0.92822
        },
        "nubia": {
            "semantic_relation": 4.10288,
            "contradiction": 11.05806,
            "irrelevancy": 35.62116,
            "logical_agreement": 53.32078,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.88129,
            "nubia_score": 0.70368
        },
        "bleurt": 0.33727
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.69133,
        "msttr-100_nopunct": 0.72115,
        "total_length": 3006,
        "mean_pred_length": 23.484375,
        "std_pred_length": 4.391014217623874,
        "median_pred_length": 24.0,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.41051230871590155,
        "vocab_size-1": 1234,
        "unique-1": 962,
        "entropy-1": 8.434925263450829,
        "distinct-2": 0.7644197359277276,
        "vocab_size-2": 2200,
        "unique-2": 1980,
        "entropy-2": 10.657589982793908,
        "cond_entropy-2": 2.1979181848509772,
        "distinct-3": 0.8869090909090909,
        "vocab_size-3": 2439,
        "unique-3": 2317,
        "entropy-3": 11.06492275252009,
        "cond_entropy-3": 0.42370336928323615,
        "total_length-nopunct": 2627,
        "mean_pred_length-nopunct": 20.5234375,
        "std_pred_length-nopunct": 3.7143405449142315,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4647887323943662,
        "vocab_size-1-nopunct": 1221,
        "unique-1-nopunct": 956,
        "entropy-1-nopunct": 8.689371466639725,
        "distinct-2-nopunct": 0.789515806322529,
        "vocab_size-2-nopunct": 1973,
        "unique-2-nopunct": 1798,
        "entropy-2-nopunct": 10.544706050135474,
        "cond_entropy-2-nopunct": 1.9194918190632442,
        "distinct-3-nopunct": 0.9063686208350907,
        "vocab_size-3-nopunct": 2149,
        "unique-3-nopunct": 2059,
        "entropy-3-nopunct": 10.91428121622593,
        "cond_entropy-3-nopunct": 0.39344180109243526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25170068027210885,
            "2": 0.4011627906976744,
            "3": 0.6485260770975056
        },
        "nist": 5.87890751454787,
        "rouge1": {
            "precision": 0.74172,
            "recall": 0.6104,
            "fmeasure": 0.65585
        },
        "rouge2": {
            "precision": 0.4992,
            "recall": 0.40001,
            "fmeasure": 0.43407
        },
        "rougeL": {
            "precision": 0.61801,
            "recall": 0.50851,
            "fmeasure": 0.54558
        },
        "rougeLsum": {
            "precision": 0.61801,
            "recall": 0.50851,
            "fmeasure": 0.54558
        },
        "bleu": 35.47813,
        "meteor": 0.3138744970143757,
        "bertscore": {
            "precision": 0.91296,
            "recall": 0.89041,
            "f1": 0.90022
        },
        "nubia": {
            "semantic_relation": 3.58642,
            "contradiction": 25.33953,
            "irrelevancy": 25.41683,
            "logical_agreement": 49.24364,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.22307,
            "nubia_score": 0.52631
        },
        "bleurt": -0.05822
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 32,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.67333,
        "total_length": 389,
        "mean_pred_length": 12.15625,
        "std_pred_length": 2.18101717955178,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.46786632390745503,
        "vocab_size-1": 182,
        "unique-1": 111,
        "entropy-1": 6.7663228401222195,
        "distinct-2": 0.7394957983193278,
        "vocab_size-2": 264,
        "unique-2": 203,
        "entropy-2": 7.854082059919071,
        "cond_entropy-2": 1.2091812443036558,
        "distinct-3": 0.8430769230769231,
        "vocab_size-3": 274,
        "unique-3": 232,
        "entropy-3": 8.003511638678361,
        "cond_entropy-3": 0.19385228654644066,
        "total_length-nopunct": 339,
        "mean_pred_length-nopunct": 10.59375,
        "std_pred_length-nopunct": 1.982097610487435,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5191740412979351,
        "vocab_size-1-nopunct": 176,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.872335555272713,
        "distinct-2-nopunct": 0.745928338762215,
        "vocab_size-2-nopunct": 229,
        "unique-2-nopunct": 179,
        "entropy-2-nopunct": 7.646427969504695,
        "cond_entropy-2-nopunct": 0.8996882968226066,
        "distinct-3-nopunct": 0.84,
        "vocab_size-3-nopunct": 231,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 7.7587245811314265,
        "cond_entropy-3-nopunct": 0.1766651208183196,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.08103448275862069,
            "2": 0.21029082774049218,
            "3": 0.35782747603833864
        },
        "nist": 0.019071713095165876,
        "rouge1": {
            "precision": 0.38021,
            "recall": 0.23485,
            "fmeasure": 0.28051
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.11111,
            "fmeasure": 0.12708
        },
        "rougeL": {
            "precision": 0.38021,
            "recall": 0.23485,
            "fmeasure": 0.28051
        },
        "rougeLsum": {
            "precision": 0.38021,
            "recall": 0.23485,
            "fmeasure": 0.28051
        },
        "bleu": 5.80278,
        "meteor": 0.2585536926368262,
        "bertscore": {
            "precision": 0.93829,
            "recall": 0.85677,
            "f1": 0.89514
        },
        "nubia": {
            "semantic_relation": 3.14185,
            "contradiction": 21.26099,
            "irrelevancy": 24.40305,
            "logical_agreement": 54.33596,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.68364,
            "nubia_score": 0.59997
        },
        "bleurt": -0.01667
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.718,
        "total_length": 580,
        "mean_pred_length": 16.11111111111111,
        "std_pred_length": 4.834929493785462,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5189655172413793,
        "vocab_size-1": 301,
        "unique-1": 244,
        "entropy-1": 7.303639071014782,
        "distinct-2": 0.8161764705882353,
        "vocab_size-2": 444,
        "unique-2": 405,
        "entropy-2": 8.561708504069264,
        "cond_entropy-2": 1.0796884738325576,
        "distinct-3": 0.905511811023622,
        "vocab_size-3": 460,
        "unique-3": 435,
        "entropy-3": 8.746443249713257,
        "cond_entropy-3": 0.16884332071975997,
        "total_length-nopunct": 512,
        "mean_pred_length-nopunct": 14.222222222222221,
        "std_pred_length-nopunct": 4.243368100872957,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5703125,
        "vocab_size-1-nopunct": 292,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 7.383354016692392,
        "distinct-2-nopunct": 0.8235294117647058,
        "vocab_size-2-nopunct": 392,
        "unique-2-nopunct": 361,
        "entropy-2-nopunct": 8.385362754017702,
        "cond_entropy-2-nopunct": 1.060021957699943,
        "distinct-3-nopunct": 0.9136363636363637,
        "vocab_size-3-nopunct": 402,
        "unique-3-nopunct": 382,
        "entropy-3-nopunct": 8.556827923707717,
        "cond_entropy-3-nopunct": 0.1818867443088785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21782178217821782,
            "2": 0.5079365079365079,
            "3": 0.7624633431085044
        },
        "nist": 6.323691879996889,
        "rouge1": {
            "precision": 0.72874,
            "recall": 0.72951,
            "fmeasure": 0.71675
        },
        "rouge2": {
            "precision": 0.5186,
            "recall": 0.51613,
            "fmeasure": 0.50769
        },
        "rougeL": {
            "precision": 0.64273,
            "recall": 0.64275,
            "fmeasure": 0.63198
        },
        "rougeLsum": {
            "precision": 0.64273,
            "recall": 0.64275,
            "fmeasure": 0.63198
        },
        "bleu": 44.87688,
        "meteor": 0.3758061133486042,
        "bertscore": {
            "precision": 0.91849,
            "recall": 0.91447,
            "f1": 0.91514
        },
        "nubia": {
            "semantic_relation": 3.94111,
            "contradiction": 10.08708,
            "irrelevancy": 44.24157,
            "logical_agreement": 45.67134,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.58028,
            "nubia_score": 0.66171
        },
        "bleurt": 0.14324
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.774,
        "total_length": 570,
        "mean_pred_length": 20.357142857142858,
        "std_pred_length": 5.708479192734046,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.5789473684210527,
        "vocab_size-1": 330,
        "unique-1": 269,
        "entropy-1": 7.594410417795582,
        "distinct-2": 0.9206642066420664,
        "vocab_size-2": 499,
        "unique-2": 472,
        "entropy-2": 8.88824944000743,
        "cond_entropy-2": 1.1904851131236833,
        "distinct-3": 0.9766536964980544,
        "vocab_size-3": 502,
        "unique-3": 496,
        "entropy-3": 8.944886648515165,
        "cond_entropy-3": 0.05941773153830876,
        "total_length-nopunct": 505,
        "mean_pred_length-nopunct": 18.035714285714285,
        "std_pred_length-nopunct": 4.981982844332615,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6396039603960396,
        "vocab_size-1-nopunct": 323,
        "unique-1-nopunct": 269,
        "entropy-1-nopunct": 7.680310477922758,
        "distinct-2-nopunct": 0.9517819706498952,
        "vocab_size-2-nopunct": 454,
        "unique-2-nopunct": 438,
        "entropy-2-nopunct": 8.784083060813748,
        "cond_entropy-2-nopunct": 1.1653977711342116,
        "distinct-3-nopunct": 0.9977728285077951,
        "vocab_size-3-nopunct": 448,
        "unique-3-nopunct": 447,
        "entropy-3-nopunct": 8.806117291756763,
        "cond_entropy-3-nopunct": 0.024674202135391326,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.023121387283236993,
            "2": 0.09868421052631579,
            "3": 0.2631578947368421,
            "4": 0.532258064516129,
            "5": 0.46774193548387094,
            "6": 0.6507936507936508,
            "7": 0.654320987654321,
            "8": 0.7258064516129032,
            "9": 0.8636363636363636,
            "10": 0.9651162790697675
        },
        "nist": 9.701350989276214,
        "rouge1": {
            "precision": 0.89179,
            "recall": 0.80246,
            "fmeasure": 0.83602
        },
        "rouge2": {
            "precision": 0.78785,
            "recall": 0.71121,
            "fmeasure": 0.73694
        },
        "rougeL": {
            "precision": 0.88464,
            "recall": 0.78582,
            "fmeasure": 0.82442
        },
        "rougeLsum": {
            "precision": 0.88464,
            "recall": 0.78582,
            "fmeasure": 0.82442
        },
        "bleu": 79.46875,
        "meteor": 0.47180190763539936,
        "bertscore": {
            "precision": 0.9622,
            "recall": 0.95764,
            "f1": 0.95276
        },
        "nubia": {
            "semantic_relation": 4.07975,
            "contradiction": 3.46327,
            "irrelevancy": 28.51171,
            "logical_agreement": 68.02502,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.87721,
            "nubia_score": 0.6266
        },
        "bleurt": 0.06799
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.79,
        "total_length": 159,
        "mean_pred_length": 22.714285714285715,
        "std_pred_length": 3.410667538946664,
        "median_pred_length": 22.0,
        "min_pred_length": 17,
        "max_pred_length": 29,
        "distinct-1": 0.7672955974842768,
        "vocab_size-1": 122,
        "unique-1": 109,
        "entropy-1": 6.61825734538575,
        "distinct-2": 0.9671052631578947,
        "vocab_size-2": 147,
        "unique-2": 145,
        "entropy-2": 7.158390405059113,
        "cond_entropy-2": 0.5326487127607934,
        "distinct-3": 1.0,
        "vocab_size-3": 145,
        "unique-3": 145,
        "entropy-3": 7.179909090014958,
        "cond_entropy-3": 0.02584116605022333,
        "total_length-nopunct": 145,
        "mean_pred_length-nopunct": 20.714285714285715,
        "std_pred_length-nopunct": 2.249716535431946,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.53897324884566,
        "distinct-2-nopunct": 0.9637681159420289,
        "vocab_size-2-nopunct": 133,
        "unique-2-nopunct": 131,
        "entropy-2-nopunct": 7.0099038736300745,
        "cond_entropy-2-nopunct": 0.5034418631046171,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.03342300153745,
        "cond_entropy-3-nopunct": 0.028788930060325527,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03529411764705882,
            "2": 0.13636363636363635,
            "3": 0.5333333333333333,
            "4": 0.8333333333333334,
            "5": 0.75,
            "6": 0.6666666666666666,
            "7": 0.6,
            "8": 0.76,
            "9": 1.0,
            "10": 0.875
        },
        "nist": 7.6219270909361265,
        "rouge1": {
            "precision": 0.81855,
            "recall": 0.80225,
            "fmeasure": 0.80756
        },
        "rouge2": {
            "precision": 0.70502,
            "recall": 0.70224,
            "fmeasure": 0.69997
        },
        "rougeL": {
            "precision": 0.80052,
            "recall": 0.79711,
            "fmeasure": 0.79654
        },
        "rougeLsum": {
            "precision": 0.80052,
            "recall": 0.79711,
            "fmeasure": 0.79654
        },
        "bleu": 72.41482,
        "meteor": 0.4654200541912473,
        "bertscore": {
            "precision": 0.95094,
            "recall": 0.95909,
            "f1": 0.95003
        },
        "nubia": {
            "semantic_relation": 4.17917,
            "contradiction": 2.51076,
            "irrelevancy": 53.27679,
            "logical_agreement": 44.21245,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.92997,
            "nubia_score": 0.64279
        },
        "bleurt": 0.07101
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "msttr-100": 0.75308,
        "msttr-100_nopunct": 0.77833,
        "total_length": 1389,
        "mean_pred_length": 22.047619047619047,
        "std_pred_length": 4.544064928794208,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.4996400287976962,
        "vocab_size-1": 694,
        "unique-1": 569,
        "entropy-1": 8.238079361339535,
        "distinct-2": 0.9019607843137255,
        "vocab_size-2": 1196,
        "unique-2": 1146,
        "entropy-2": 10.066965430442291,
        "cond_entropy-2": 1.8272316534842876,
        "distinct-3": 0.9667458432304038,
        "vocab_size-3": 1221,
        "unique-3": 1213,
        "entropy-3": 10.177251332357027,
        "cond_entropy-3": 0.12237749072657048,
        "total_length-nopunct": 1249,
        "mean_pred_length-nopunct": 19.825396825396826,
        "std_pred_length-nopunct": 4.19576385969696,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5484387510008006,
        "vocab_size-1-nopunct": 685,
        "unique-1-nopunct": 567,
        "entropy-1-nopunct": 8.389372498842093,
        "distinct-2-nopunct": 0.945193929173693,
        "vocab_size-2-nopunct": 1121,
        "unique-2-nopunct": 1083,
        "entropy-2-nopunct": 10.076556512535978,
        "cond_entropy-2-nopunct": 1.7577588162989872,
        "distinct-3-nopunct": 0.9955476402493322,
        "vocab_size-3-nopunct": 1118,
        "unique-3-nopunct": 1114,
        "entropy-3-nopunct": 10.123565286753383,
        "cond_entropy-3-nopunct": 0.05371037908509987,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.031020408163265307,
            "2": 0.1366120218579235,
            "3": 0.27631578947368424,
            "4": 0.50920245398773,
            "5": 0.5508982035928144,
            "6": 0.6129032258064516,
            "7": 0.7108433734939759,
            "8": 0.8186046511627907,
            "9": 0.7528735632183908,
            "10": 0.9027777777777778
        },
        "nist": 11.046458915484257,
        "rouge1": {
            "precision": 0.85305,
            "recall": 0.79112,
            "fmeasure": 0.81166
        },
        "rouge2": {
            "precision": 0.74912,
            "recall": 0.67609,
            "fmeasure": 0.70064
        },
        "rougeL": {
            "precision": 0.84297,
            "recall": 0.7771,
            "fmeasure": 0.79938
        },
        "rougeLsum": {
            "precision": 0.84297,
            "recall": 0.7771,
            "fmeasure": 0.79938
        },
        "bleu": 80.65476,
        "meteor": 0.45498589964410885,
        "bertscore": {
            "precision": 0.94721,
            "recall": 0.94461,
            "f1": 0.94181
        },
        "nubia": {
            "semantic_relation": 3.95324,
            "contradiction": 3.6177,
            "irrelevancy": 38.08994,
            "logical_agreement": 58.29236,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.82571,
            "nubia_score": 0.57697
        },
        "bleurt": -0.09517
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76208,
        "total_length": 2774,
        "mean_pred_length": 15.942528735632184,
        "std_pred_length": 5.806964351948998,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.43330930064888246,
        "vocab_size-1": 1202,
        "unique-1": 934,
        "entropy-1": 8.504533328217024,
        "distinct-2": 0.8576923076923076,
        "vocab_size-2": 2230,
        "unique-2": 2087,
        "entropy-2": 10.887794584818634,
        "cond_entropy-2": 2.1519266324185056,
        "distinct-3": 0.9657873042044518,
        "vocab_size-3": 2343,
        "unique-3": 2295,
        "entropy-3": 11.158822597085187,
        "cond_entropy-3": 0.2903905814505902,
        "total_length-nopunct": 2468,
        "mean_pred_length-nopunct": 14.183908045977011,
        "std_pred_length-nopunct": 5.315405361067395,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4837925445705024,
        "vocab_size-1-nopunct": 1194,
        "unique-1-nopunct": 933,
        "entropy-1-nopunct": 8.779231664097736,
        "distinct-2-nopunct": 0.8731473408892764,
        "vocab_size-2-nopunct": 2003,
        "unique-2-nopunct": 1887,
        "entropy-2-nopunct": 10.75111225379543,
        "cond_entropy-2-nopunct": 2.1037906221246647,
        "distinct-3-nopunct": 0.9797169811320755,
        "vocab_size-3-nopunct": 2077,
        "unique-3-nopunct": 2044,
        "entropy-3-nopunct": 11.005259245198847,
        "cond_entropy-3-nopunct": 0.2768611183297833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04564533053515215,
            "2": 0.1419141914191419,
            "3": 0.37037037037037035,
            "4": 0.4717741935483871,
            "5": 0.5634674922600619,
            "6": 0.7104477611940299,
            "7": 0.830379746835443
        },
        "nist": 9.369539719111732,
        "rouge1": {
            "precision": 0.83124,
            "recall": 0.77046,
            "fmeasure": 0.78245
        },
        "rouge2": {
            "precision": 0.67982,
            "recall": 0.63082,
            "fmeasure": 0.63788
        },
        "rougeL": {
            "precision": 0.8009,
            "recall": 0.73888,
            "fmeasure": 0.75214
        },
        "rougeLsum": {
            "precision": 0.8009,
            "recall": 0.73888,
            "fmeasure": 0.75214
        },
        "bleu": 63.69429,
        "meteor": 0.43033229199277667,
        "bertscore": {
            "precision": 0.94883,
            "recall": 0.93558,
            "f1": 0.93919
        },
        "nubia": {
            "semantic_relation": 4.11497,
            "contradiction": 5.85281,
            "irrelevancy": 21.23351,
            "logical_agreement": 72.91368,
            "grammar_ref": 4.58509,
            "grammar_hyp": 4.9705,
            "nubia_score": 0.6432
        },
        "bleurt": 0.16878
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 61,
        "msttr-100": 0.67929,
        "msttr-100_nopunct": 0.7375,
        "total_length": 1425,
        "mean_pred_length": 23.360655737704917,
        "std_pred_length": 4.995187148843902,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 34,
        "distinct-1": 0.4807017543859649,
        "vocab_size-1": 685,
        "unique-1": 546,
        "entropy-1": 8.039405787471798,
        "distinct-2": 0.8401759530791789,
        "vocab_size-2": 1146,
        "unique-2": 1046,
        "entropy-2": 9.934316160591651,
        "cond_entropy-2": 1.898679529973551,
        "distinct-3": 0.9501151189562548,
        "vocab_size-3": 1238,
        "unique-3": 1187,
        "entropy-3": 10.23745339080775,
        "cond_entropy-3": 0.3155992546783609,
        "total_length-nopunct": 1232,
        "mean_pred_length-nopunct": 20.19672131147541,
        "std_pred_length-nopunct": 4.337483111437419,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5503246753246753,
        "vocab_size-1-nopunct": 678,
        "unique-1-nopunct": 544,
        "entropy-1-nopunct": 8.325121499996623,
        "distinct-2-nopunct": 0.8889837745516652,
        "vocab_size-2-nopunct": 1041,
        "unique-2-nopunct": 969,
        "entropy-2-nopunct": 9.89413704222763,
        "cond_entropy-2-nopunct": 1.6335499760990382,
        "distinct-3-nopunct": 0.9702702702702702,
        "vocab_size-3-nopunct": 1077,
        "unique-3-nopunct": 1049,
        "entropy-3-nopunct": 10.05304246348384,
        "cond_entropy-3-nopunct": 0.17265559009816006,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1827956989247312,
            "2": 0.43891402714932126,
            "3": 0.6440501043841336
        },
        "nist": 6.0651018037950095,
        "rouge1": {
            "precision": 0.68603,
            "recall": 0.60774,
            "fmeasure": 0.63341
        },
        "rouge2": {
            "precision": 0.40816,
            "recall": 0.35688,
            "fmeasure": 0.3741
        },
        "rougeL": {
            "precision": 0.55895,
            "recall": 0.49498,
            "fmeasure": 0.51471
        },
        "rougeLsum": {
            "precision": 0.55895,
            "recall": 0.49498,
            "fmeasure": 0.51471
        },
        "bleu": 31.96429,
        "meteor": 0.30705594373828143,
        "bertscore": {
            "precision": 0.90126,
            "recall": 0.89127,
            "f1": 0.89486
        },
        "nubia": {
            "semantic_relation": 3.5964,
            "contradiction": 16.0965,
            "irrelevancy": 32.20926,
            "logical_agreement": 51.69424,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.33172,
            "nubia_score": 0.54937
        },
        "bleurt": -0.05158
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 41,
        "msttr-100": 0.606,
        "msttr-100_nopunct": 0.645,
        "total_length": 578,
        "mean_pred_length": 14.097560975609756,
        "std_pred_length": 4.287274863882312,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.43252595155709345,
        "vocab_size-1": 250,
        "unique-1": 201,
        "entropy-1": 6.769634081441011,
        "distinct-2": 0.7579143389199255,
        "vocab_size-2": 407,
        "unique-2": 369,
        "entropy-2": 8.302570059185056,
        "cond_entropy-2": 1.3175074404232177,
        "distinct-3": 0.8528225806451613,
        "vocab_size-3": 423,
        "unique-3": 398,
        "entropy-3": 8.517842723348908,
        "cond_entropy-3": 0.26498969938306605,
        "total_length-nopunct": 497,
        "mean_pred_length-nopunct": 12.121951219512194,
        "std_pred_length-nopunct": 3.794701838932929,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.4909456740442656,
        "vocab_size-1-nopunct": 244,
        "unique-1-nopunct": 200,
        "entropy-1-nopunct": 6.8781327418798766,
        "distinct-2-nopunct": 0.7807017543859649,
        "vocab_size-2-nopunct": 356,
        "unique-2-nopunct": 325,
        "entropy-2-nopunct": 8.137737415199254,
        "cond_entropy-2-nopunct": 1.4180053619599073,
        "distinct-3-nopunct": 0.8650602409638555,
        "vocab_size-3-nopunct": 359,
        "unique-3-nopunct": 339,
        "entropy-3-nopunct": 8.294544737787186,
        "cond_entropy-3-nopunct": 0.22066577212429547,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.49586776859504134,
            "3": 0.7878787878787878
        },
        "nist": 6.349117110199066,
        "rouge1": {
            "precision": 0.72763,
            "recall": 0.74048,
            "fmeasure": 0.72431
        },
        "rouge2": {
            "precision": 0.50866,
            "recall": 0.52883,
            "fmeasure": 0.51071
        },
        "rougeL": {
            "precision": 0.6178,
            "recall": 0.63975,
            "fmeasure": 0.61949
        },
        "rougeLsum": {
            "precision": 0.6178,
            "recall": 0.63975,
            "fmeasure": 0.61949
        },
        "bleu": 44.72463,
        "meteor": 0.40333393986434274,
        "bertscore": {
            "precision": 0.92545,
            "recall": 0.93321,
            "f1": 0.92745
        },
        "nubia": {
            "semantic_relation": 3.98331,
            "contradiction": 9.69109,
            "irrelevancy": 37.72868,
            "logical_agreement": 52.58023,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.3604,
            "nubia_score": 0.70331
        },
        "bleurt": 0.33071
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.67889,
        "msttr-100_nopunct": 0.73,
        "total_length": 915,
        "mean_pred_length": 22.875,
        "std_pred_length": 4.556245713303881,
        "median_pred_length": 23.0,
        "min_pred_length": 14,
        "max_pred_length": 33,
        "distinct-1": 0.4885245901639344,
        "vocab_size-1": 447,
        "unique-1": 348,
        "entropy-1": 7.644569484995198,
        "distinct-2": 0.8194285714285714,
        "vocab_size-2": 717,
        "unique-2": 643,
        "entropy-2": 9.260151840300663,
        "cond_entropy-2": 1.6055405024546472,
        "distinct-3": 0.9365269461077844,
        "vocab_size-3": 782,
        "unique-3": 743,
        "entropy-3": 9.560698794536494,
        "cond_entropy-3": 0.3194267232835249,
        "total_length-nopunct": 795,
        "mean_pred_length-nopunct": 19.875,
        "std_pred_length-nopunct": 3.494191608941902,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5522012578616352,
        "vocab_size-1-nopunct": 439,
        "unique-1-nopunct": 345,
        "entropy-1-nopunct": 7.828177564212681,
        "distinct-2-nopunct": 0.8410596026490066,
        "vocab_size-2-nopunct": 635,
        "unique-2-nopunct": 574,
        "entropy-2-nopunct": 9.120880464414897,
        "cond_entropy-2-nopunct": 1.3569618008791324,
        "distinct-3-nopunct": 0.9426573426573427,
        "vocab_size-3-nopunct": 674,
        "unique-3-nopunct": 641,
        "entropy-3-nopunct": 9.354499361723686,
        "cond_entropy-3-nopunct": 0.2545883131004683,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22602739726027396,
            "2": 0.39644970414201186,
            "3": 0.6630434782608695
        },
        "nist": 5.659091176794653,
        "rouge1": {
            "precision": 0.73673,
            "recall": 0.62693,
            "fmeasure": 0.6673
        },
        "rouge2": {
            "precision": 0.47856,
            "recall": 0.40379,
            "fmeasure": 0.43135
        },
        "rougeL": {
            "precision": 0.56605,
            "recall": 0.49387,
            "fmeasure": 0.51656
        },
        "rougeLsum": {
            "precision": 0.56605,
            "recall": 0.49387,
            "fmeasure": 0.51656
        },
        "bleu": 34.36581,
        "meteor": 0.32696507599864316,
        "bertscore": {
            "precision": 0.91105,
            "recall": 0.89317,
            "f1": 0.90126
        },
        "nubia": {
            "semantic_relation": 3.62336,
            "contradiction": 19.23142,
            "irrelevancy": 27.82631,
            "logical_agreement": 52.94227,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.26381,
            "nubia_score": 0.54877
        },
        "bleurt": -0.02084
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "msttr-100": 0.736,
        "msttr-100_nopunct": 0.76222,
        "total_length": 1057,
        "mean_pred_length": 18.224137931034484,
        "std_pred_length": 6.12243782708263,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.5089877010406811,
        "vocab_size-1": 538,
        "unique-1": 430,
        "entropy-1": 7.9580084179828114,
        "distinct-2": 0.9009009009009009,
        "vocab_size-2": 900,
        "unique-2": 853,
        "entropy-2": 9.69202600356037,
        "cond_entropy-2": 1.6227695603166348,
        "distinct-3": 0.9638682252922423,
        "vocab_size-3": 907,
        "unique-3": 890,
        "entropy-3": 9.774694503625199,
        "cond_entropy-3": 0.09592284016101289,
        "total_length-nopunct": 944,
        "mean_pred_length-nopunct": 16.275862068965516,
        "std_pred_length-nopunct": 5.782831615931456,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5614406779661016,
        "vocab_size-1-nopunct": 530,
        "unique-1-nopunct": 428,
        "entropy-1-nopunct": 8.124430136846494,
        "distinct-2-nopunct": 0.9322799097065463,
        "vocab_size-2-nopunct": 826,
        "unique-2-nopunct": 786,
        "entropy-2-nopunct": 9.633247083816604,
        "cond_entropy-2-nopunct": 1.601055867391612,
        "distinct-3-nopunct": 0.9806763285024155,
        "vocab_size-3-nopunct": 812,
        "unique-3-nopunct": 798,
        "entropy-3-nopunct": 9.65301621474043,
        "cond_entropy-3-nopunct": 0.030830866038399074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04220398593200469,
            "2": 0.18309859154929578,
            "3": 0.2987012987012987,
            "4": 0.38461538461538464,
            "5": 0.5195530726256983,
            "6": 0.6308243727598566,
            "7": 0.7629107981220657
        },
        "nist": 7.479369704431875,
        "rouge1": {
            "precision": 0.80687,
            "recall": 0.68791,
            "fmeasure": 0.72894
        },
        "rouge2": {
            "precision": 0.65524,
            "recall": 0.56004,
            "fmeasure": 0.5913
        },
        "rougeL": {
            "precision": 0.78828,
            "recall": 0.67649,
            "fmeasure": 0.71493
        },
        "rougeLsum": {
            "precision": 0.78828,
            "recall": 0.67649,
            "fmeasure": 0.71493
        },
        "bleu": 57.59947,
        "meteor": 0.38423532526399384,
        "bertscore": {
            "precision": 0.93792,
            "recall": 0.9191,
            "f1": 0.92586
        },
        "nubia": {
            "semantic_relation": 3.98946,
            "contradiction": 5.18759,
            "irrelevancy": 22.13003,
            "logical_agreement": 72.68239,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.93404,
            "nubia_score": 0.61198
        },
        "bleurt": -0.0272
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.76,
        "total_length": 424,
        "mean_pred_length": 19.272727272727273,
        "std_pred_length": 5.445446957044341,
        "median_pred_length": 19.5,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5754716981132075,
        "vocab_size-1": 244,
        "unique-1": 197,
        "entropy-1": 7.229920500201635,
        "distinct-2": 0.9203980099502488,
        "vocab_size-2": 370,
        "unique-2": 352,
        "entropy-2": 8.458553984747903,
        "cond_entropy-2": 1.126637948615268,
        "distinct-3": 0.9763157894736842,
        "vocab_size-3": 371,
        "unique-3": 366,
        "entropy-3": 8.511960871488848,
        "cond_entropy-3": 0.053177995810879036,
        "total_length-nopunct": 378,
        "mean_pred_length-nopunct": 17.181818181818183,
        "std_pred_length-nopunct": 4.811315862690633,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6296296296296297,
        "vocab_size-1-nopunct": 238,
        "unique-1-nopunct": 197,
        "entropy-1-nopunct": 7.2919141339073565,
        "distinct-2-nopunct": 0.9410112359550562,
        "vocab_size-2-nopunct": 335,
        "unique-2-nopunct": 322,
        "entropy-2-nopunct": 8.337014110783128,
        "cond_entropy-2-nopunct": 1.0904366832376966,
        "distinct-3-nopunct": 0.9940119760479041,
        "vocab_size-3-nopunct": 332,
        "unique-3-nopunct": 330,
        "entropy-3-nopunct": 8.371728244569807,
        "cond_entropy-3-nopunct": 0.03689945399378227,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04666666666666667,
            "2": 0.2542372881355932,
            "3": 0.28125,
            "4": 0.30612244897959184,
            "5": 0.5135135135135135,
            "6": 0.6161616161616161,
            "7": 0.8095238095238095
        },
        "nist": 6.739878674872126,
        "rouge1": {
            "precision": 0.79122,
            "recall": 0.69693,
            "fmeasure": 0.72896
        },
        "rouge2": {
            "precision": 0.60999,
            "recall": 0.56246,
            "fmeasure": 0.57634
        },
        "rougeL": {
            "precision": 0.75866,
            "recall": 0.68184,
            "fmeasure": 0.70684
        },
        "rougeLsum": {
            "precision": 0.75866,
            "recall": 0.68184,
            "fmeasure": 0.70684
        },
        "bleu": 58.60564,
        "meteor": 0.3709488389699112,
        "bertscore": {
            "precision": 0.93965,
            "recall": 0.92233,
            "f1": 0.92879
        },
        "nubia": {
            "semantic_relation": 4.065,
            "contradiction": 3.11473,
            "irrelevancy": 19.54944,
            "logical_agreement": 77.33583,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.81112,
            "nubia_score": 0.65239
        },
        "bleurt": 0.09028
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.6775,
        "msttr-100_nopunct": 0.77333,
        "total_length": 480,
        "mean_pred_length": 24.0,
        "std_pred_length": 5.412947441089743,
        "median_pred_length": 24.5,
        "min_pred_length": 12,
        "max_pred_length": 35,
        "distinct-1": 0.5458333333333333,
        "vocab_size-1": 262,
        "unique-1": 214,
        "entropy-1": 7.0465543262877155,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 400,
        "unique-2": 366,
        "entropy-2": 8.496452569924791,
        "cond_entropy-2": 1.4411029524904047,
        "distinct-3": 0.9568181818181818,
        "vocab_size-3": 421,
        "unique-3": 403,
        "entropy-3": 8.693280423747058,
        "cond_entropy-3": 0.20814773932315866,
        "total_length-nopunct": 386,
        "mean_pred_length-nopunct": 19.3,
        "std_pred_length-nopunct": 4.484417464955732,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6632124352331606,
        "vocab_size-1-nopunct": 256,
        "unique-1-nopunct": 213,
        "entropy-1-nopunct": 7.427971351129748,
        "distinct-2-nopunct": 0.912568306010929,
        "vocab_size-2-nopunct": 334,
        "unique-2-nopunct": 310,
        "entropy-2-nopunct": 8.322996764478034,
        "cond_entropy-2-nopunct": 0.9174404661966442,
        "distinct-3-nopunct": 0.9653179190751445,
        "vocab_size-3-nopunct": 334,
        "unique-3-nopunct": 323,
        "entropy-3-nopunct": 8.36308231000039,
        "cond_entropy-3-nopunct": 0.05122445152267428,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19540229885057472,
            "2": 0.4175824175824176,
            "3": 0.6325301204819277
        },
        "nist": 4.7463154678992,
        "rouge1": {
            "precision": 0.73983,
            "recall": 0.59257,
            "fmeasure": 0.64035
        },
        "rouge2": {
            "precision": 0.47263,
            "recall": 0.39147,
            "fmeasure": 0.41042
        },
        "rougeL": {
            "precision": 0.58883,
            "recall": 0.49747,
            "fmeasure": 0.5177
        },
        "rougeLsum": {
            "precision": 0.58883,
            "recall": 0.49747,
            "fmeasure": 0.5177
        },
        "bleu": 35.34826,
        "meteor": 0.3094769144289559,
        "bertscore": {
            "precision": 0.9158,
            "recall": 0.90389,
            "f1": 0.90403
        },
        "nubia": {
            "semantic_relation": 3.57375,
            "contradiction": 22.71714,
            "irrelevancy": 25.12363,
            "logical_agreement": 52.15923,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.24048,
            "nubia_score": 0.53542
        },
        "bleurt": -0.04858
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 5.90668171555645,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.8867924528301887,
        "vocab_size-1": 47,
        "unique-1": 42,
        "entropy-1": 5.487262199805395,
        "distinct-2": 1.0,
        "vocab_size-2": 50,
        "unique-2": 50,
        "entropy-2": 5.643856189774728,
        "cond_entropy-2": 0.10763498522594848,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.08926733809708727,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 4.714045207910316,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9347826086956522,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.393127173448314,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.018981868412526783,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.1043366598147359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.06666666666666667,
            "3": 0.25,
            "4": 0.2857142857142857,
            "5": 0.5,
            "6": 0.42857142857142855,
            "7": 0.75
        },
        "nist": 4.309166415659701,
        "rouge1": {
            "precision": 0.73348,
            "recall": 0.62843,
            "fmeasure": 0.67626
        },
        "rouge2": {
            "precision": 0.5124,
            "recall": 0.41426,
            "fmeasure": 0.4571
        },
        "rougeL": {
            "precision": 0.63564,
            "recall": 0.53701,
            "fmeasure": 0.58149
        },
        "rougeLsum": {
            "precision": 0.63564,
            "recall": 0.53701,
            "fmeasure": 0.58149
        },
        "bleu": 39.52596,
        "meteor": 0.3309145427302758,
        "bertscore": {
            "precision": 0.91799,
            "recall": 0.90347,
            "f1": 0.90669
        },
        "nubia": {
            "semantic_relation": 4.10093,
            "contradiction": 1.27556,
            "irrelevancy": 16.38159,
            "logical_agreement": 82.34285,
            "grammar_ref": 4.54431,
            "grammar_hyp": 4.73604,
            "nubia_score": 0.69716
        },
        "bleurt": -0.00781
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "msttr-100": 0.738,
        "msttr-100_nopunct": 0.766,
        "total_length": 591,
        "mean_pred_length": 19.7,
        "std_pred_length": 6.219056734478844,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.5397631133671743,
        "vocab_size-1": 319,
        "unique-1": 251,
        "entropy-1": 7.511069951208626,
        "distinct-2": 0.9037433155080213,
        "vocab_size-2": 507,
        "unique-2": 476,
        "entropy-2": 8.87739192049804,
        "cond_entropy-2": 1.2673351827449124,
        "distinct-3": 0.9698681732580038,
        "vocab_size-3": 515,
        "unique-3": 511,
        "entropy-3": 8.95463961389273,
        "cond_entropy-3": 0.08974101016176954,
        "total_length-nopunct": 522,
        "mean_pred_length-nopunct": 17.4,
        "std_pred_length-nopunct": 5.511200716117435,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5977011494252874,
        "vocab_size-1-nopunct": 312,
        "unique-1-nopunct": 251,
        "entropy-1-nopunct": 7.6003526589369645,
        "distinct-2-nopunct": 0.9451219512195121,
        "vocab_size-2-nopunct": 465,
        "unique-2-nopunct": 442,
        "entropy-2-nopunct": 8.824628326477358,
        "cond_entropy-2-nopunct": 1.2983290876749862,
        "distinct-3-nopunct": 0.9956709956709957,
        "vocab_size-3-nopunct": 460,
        "unique-3-nopunct": 458,
        "entropy-3-nopunct": 8.843091032758096,
        "cond_entropy-3-nopunct": 0.026117652959934623,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05429864253393665,
            "2": 0.16049382716049382,
            "3": 0.3559322033898305,
            "4": 0.391304347826087,
            "5": 0.43478260869565216,
            "6": 0.564935064935065,
            "7": 0.7853881278538812
        },
        "nist": 6.422917835231694,
        "rouge1": {
            "precision": 0.75361,
            "recall": 0.66235,
            "fmeasure": 0.68838
        },
        "rouge2": {
            "precision": 0.5846,
            "recall": 0.48321,
            "fmeasure": 0.51251
        },
        "rougeL": {
            "precision": 0.73523,
            "recall": 0.62478,
            "fmeasure": 0.65614
        },
        "rougeLsum": {
            "precision": 0.73523,
            "recall": 0.62478,
            "fmeasure": 0.65614
        },
        "bleu": 52.39851,
        "meteor": 0.369919773457808,
        "bertscore": {
            "precision": 0.92573,
            "recall": 0.91509,
            "f1": 0.91445
        },
        "nubia": {
            "semantic_relation": 3.83877,
            "contradiction": 4.50663,
            "irrelevancy": 23.4435,
            "logical_agreement": 72.04987,
            "grammar_ref": 4.65355,
            "grammar_hyp": 5.16396,
            "nubia_score": 0.5549
        },
        "bleurt": -0.14787
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "total_length": 194,
        "mean_pred_length": 21.555555555555557,
        "std_pred_length": 6.130272988503876,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.6855670103092784,
        "vocab_size-1": 133,
        "unique-1": 110,
        "entropy-1": 6.636676469189971,
        "distinct-2": 0.9243243243243243,
        "vocab_size-2": 171,
        "unique-2": 165,
        "entropy-2": 7.32642931478174,
        "cond_entropy-2": 0.624953642498275,
        "distinct-3": 0.9772727272727273,
        "vocab_size-3": 172,
        "unique-3": 170,
        "entropy-3": 7.405398806112722,
        "cond_entropy-3": 0.08944999878329554,
        "total_length-nopunct": 165,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 4.594682917363407,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7636363636363637,
        "vocab_size-1-nopunct": 126,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.650723009142942,
        "distinct-2-nopunct": 0.9551282051282052,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 147,
        "entropy-2-nopunct": 7.14661065184686,
        "cond_entropy-2-nopunct": 0.5063558345235637,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 147,
        "unique-3-nopunct": 147,
        "entropy-3-nopunct": 7.199672344836354,
        "cond_entropy-3-nopunct": 0.06155913586801526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05925925925925926,
            "2": 0.13636363636363635,
            "3": 0.0,
            "4": 0.75,
            "5": 0.5,
            "6": 0.64,
            "7": 0.8253968253968254
        },
        "nist": 6.694772969225632,
        "rouge1": {
            "precision": 0.81849,
            "recall": 0.74111,
            "fmeasure": 0.75977
        },
        "rouge2": {
            "precision": 0.67194,
            "recall": 0.57198,
            "fmeasure": 0.59786
        },
        "rougeL": {
            "precision": 0.75018,
            "recall": 0.65622,
            "fmeasure": 0.6871
        },
        "rougeLsum": {
            "precision": 0.75018,
            "recall": 0.65622,
            "fmeasure": 0.6871
        },
        "bleu": 53.06476,
        "meteor": 0.39815279713225993,
        "bertscore": {
            "precision": 0.92479,
            "recall": 0.91505,
            "f1": 0.91707
        },
        "nubia": {
            "semantic_relation": 4.16653,
            "contradiction": 7.97654,
            "irrelevancy": 20.25984,
            "logical_agreement": 71.76362,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.22586,
            "nubia_score": 0.59627
        },
        "bleurt": -0.03165
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.724,
        "total_length": 657,
        "mean_pred_length": 25.26923076923077,
        "std_pred_length": 5.509137111742303,
        "median_pred_length": 27.0,
        "min_pred_length": 11,
        "max_pred_length": 33,
        "distinct-1": 0.4885844748858447,
        "vocab_size-1": 321,
        "unique-1": 253,
        "entropy-1": 7.21342159095901,
        "distinct-2": 0.8225039619651348,
        "vocab_size-2": 519,
        "unique-2": 463,
        "entropy-2": 8.811856381699936,
        "cond_entropy-2": 1.5872849243421963,
        "distinct-3": 0.9371900826446281,
        "vocab_size-3": 567,
        "unique-3": 542,
        "entropy-3": 9.092281462026452,
        "cond_entropy-3": 0.2837157489803403,
        "total_length-nopunct": 548,
        "mean_pred_length-nopunct": 21.076923076923077,
        "std_pred_length-nopunct": 4.09430257912962,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5748175182481752,
        "vocab_size-1-nopunct": 315,
        "unique-1-nopunct": 251,
        "entropy-1-nopunct": 7.491550579793712,
        "distinct-2-nopunct": 0.8869731800766284,
        "vocab_size-2-nopunct": 463,
        "unique-2-nopunct": 430,
        "entropy-2-nopunct": 8.747995778296927,
        "cond_entropy-2-nopunct": 1.2786668614174717,
        "distinct-3-nopunct": 0.9637096774193549,
        "vocab_size-3-nopunct": 478,
        "unique-3-nopunct": 467,
        "entropy-3-nopunct": 8.865538712703222,
        "cond_entropy-3-nopunct": 0.11574402447419782,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.175,
            "2": 0.35294117647058826,
            "3": 0.6387665198237885
        },
        "nist": 4.559802839414434,
        "rouge1": {
            "precision": 0.7514,
            "recall": 0.58106,
            "fmeasure": 0.64132
        },
        "rouge2": {
            "precision": 0.48685,
            "recall": 0.36726,
            "fmeasure": 0.40964
        },
        "rougeL": {
            "precision": 0.59853,
            "recall": 0.46194,
            "fmeasure": 0.50981
        },
        "rougeLsum": {
            "precision": 0.59853,
            "recall": 0.46194,
            "fmeasure": 0.50981
        },
        "bleu": 30.74744,
        "meteor": 0.29930621693286424,
        "bertscore": {
            "precision": 0.90275,
            "recall": 0.88263,
            "f1": 0.8914
        },
        "nubia": {
            "semantic_relation": 3.32997,
            "contradiction": 21.85397,
            "irrelevancy": 26.05748,
            "logical_agreement": 52.08855,
            "grammar_ref": 4.04917,
            "grammar_hyp": 4.17877,
            "nubia_score": 0.46467
        },
        "bleurt": -0.09228
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "msttr-100": 0.73615,
        "msttr-100_nopunct": 0.77417,
        "total_length": 1379,
        "mean_pred_length": 21.88888888888889,
        "std_pred_length": 4.6738418007171045,
        "median_pred_length": 23.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.47643219724437996,
        "vocab_size-1": 657,
        "unique-1": 525,
        "entropy-1": 8.147547156141535,
        "distinct-2": 0.8882978723404256,
        "vocab_size-2": 1169,
        "unique-2": 1110,
        "entropy-2": 9.992453211205206,
        "cond_entropy-2": 1.8128159594990048,
        "distinct-3": 0.9553072625698324,
        "vocab_size-3": 1197,
        "unique-3": 1183,
        "entropy-3": 10.115993618902573,
        "cond_entropy-3": 0.13972389168726956,
        "total_length-nopunct": 1233,
        "mean_pred_length-nopunct": 19.571428571428573,
        "std_pred_length-nopunct": 4.403152859263555,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5255474452554745,
        "vocab_size-1-nopunct": 648,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 8.297918635466491,
        "distinct-2-nopunct": 0.935042735042735,
        "vocab_size-2-nopunct": 1094,
        "unique-2-nopunct": 1044,
        "entropy-2-nopunct": 10.03831420086522,
        "cond_entropy-2-nopunct": 1.8118893753434022,
        "distinct-3-nopunct": 0.991869918699187,
        "vocab_size-3-nopunct": 1098,
        "unique-3-nopunct": 1091,
        "entropy-3-nopunct": 10.094815500454164,
        "cond_entropy-3-nopunct": 0.05841249214219565,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.048216007714561235,
            "2": 0.16149068322981366,
            "3": 0.30851063829787234,
            "4": 0.44029850746268656,
            "5": 0.48627450980392156,
            "6": 0.5969773299748111,
            "7": 0.769811320754717
        },
        "nist": 7.457735745092322,
        "rouge1": {
            "precision": 0.7759,
            "recall": 0.67016,
            "fmeasure": 0.70274
        },
        "rouge2": {
            "precision": 0.6335,
            "recall": 0.54808,
            "fmeasure": 0.57238
        },
        "rougeL": {
            "precision": 0.74687,
            "recall": 0.65364,
            "fmeasure": 0.67995
        },
        "rougeLsum": {
            "precision": 0.74687,
            "recall": 0.65364,
            "fmeasure": 0.67995
        },
        "bleu": 57.56928,
        "meteor": 0.37216197888582964,
        "bertscore": {
            "precision": 0.92218,
            "recall": 0.91567,
            "f1": 0.91485
        },
        "nubia": {
            "semantic_relation": 3.85389,
            "contradiction": 6.65404,
            "irrelevancy": 25.6737,
            "logical_agreement": 67.67226,
            "grammar_ref": 4.43738,
            "grammar_hyp": 4.89627,
            "nubia_score": 0.56658
        },
        "bleurt": -0.16894
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.755,
        "total_length": 241,
        "mean_pred_length": 24.1,
        "std_pred_length": 5.664803615307418,
        "median_pred_length": 25.5,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.6265560165975104,
        "vocab_size-1": 151,
        "unique-1": 126,
        "entropy-1": 6.701335278646786,
        "distinct-2": 0.8961038961038961,
        "vocab_size-2": 207,
        "unique-2": 192,
        "entropy-2": 7.60660103066672,
        "cond_entropy-2": 0.9187529406599446,
        "distinct-3": 0.9592760180995475,
        "vocab_size-3": 212,
        "unique-3": 205,
        "entropy-3": 7.699623034484955,
        "cond_entropy-3": 0.10411467398787924,
        "total_length-nopunct": 210,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 4.878524367060187,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6952380952380952,
        "vocab_size-1-nopunct": 146,
        "unique-1-nopunct": 125,
        "entropy-1-nopunct": 6.763474046427592,
        "distinct-2-nopunct": 0.945,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 181,
        "entropy-2-nopunct": 7.520081752263923,
        "cond_entropy-2-nopunct": 0.7891462793982297,
        "distinct-3-nopunct": 0.9842105263157894,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.538276660962538,
        "cond_entropy-3-nopunct": 0.024709352778136216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2191780821917808,
            "2": 0.288135593220339,
            "3": 0.6301369863013698
        },
        "nist": 4.303986720288664,
        "rouge1": {
            "precision": 0.6528,
            "recall": 0.54629,
            "fmeasure": 0.57646
        },
        "rouge2": {
            "precision": 0.41947,
            "recall": 0.35388,
            "fmeasure": 0.37254
        },
        "rougeL": {
            "precision": 0.51061,
            "recall": 0.43127,
            "fmeasure": 0.45572
        },
        "rougeLsum": {
            "precision": 0.51061,
            "recall": 0.43127,
            "fmeasure": 0.45572
        },
        "bleu": 32.04289,
        "meteor": 0.27542003673512055,
        "bertscore": {
            "precision": 0.88813,
            "recall": 0.87224,
            "f1": 0.87749
        },
        "nubia": {
            "semantic_relation": 3.06799,
            "contradiction": 25.44613,
            "irrelevancy": 48.61329,
            "logical_agreement": 25.94058,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.58462,
            "nubia_score": 0.37463
        },
        "bleurt": -0.28785
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.78,
        "total_length": 315,
        "mean_pred_length": 22.5,
        "std_pred_length": 5.728998915293017,
        "median_pred_length": 22.5,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.6095238095238096,
        "vocab_size-1": 192,
        "unique-1": 159,
        "entropy-1": 6.8653181410095865,
        "distinct-2": 0.8970099667774086,
        "vocab_size-2": 270,
        "unique-2": 254,
        "entropy-2": 7.977826592175978,
        "cond_entropy-2": 1.0898657387247068,
        "distinct-3": 0.9721254355400697,
        "vocab_size-3": 279,
        "unique-3": 273,
        "entropy-3": 8.10389725767103,
        "cond_entropy-3": 0.1350640563806686,
        "total_length-nopunct": 265,
        "mean_pred_length-nopunct": 18.928571428571427,
        "std_pred_length-nopunct": 4.7277944981065465,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7018867924528301,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 159,
        "entropy-1-nopunct": 7.0090897099680145,
        "distinct-2-nopunct": 0.9203187250996016,
        "vocab_size-2-nopunct": 231,
        "unique-2-nopunct": 221,
        "entropy-2-nopunct": 7.772841151636316,
        "cond_entropy-2-nopunct": 0.7951067565472163,
        "distinct-3-nopunct": 0.9873417721518988,
        "vocab_size-3-nopunct": 234,
        "unique-3-nopunct": 232,
        "entropy-3-nopunct": 7.860241613868078,
        "cond_entropy-3-nopunct": 0.09491874760049873,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.43478260869565216,
            "3": 0.5254237288135594
        },
        "nist": 4.012819152177764,
        "rouge1": {
            "precision": 0.65894,
            "recall": 0.52278,
            "fmeasure": 0.57009
        },
        "rouge2": {
            "precision": 0.35376,
            "recall": 0.29555,
            "fmeasure": 0.31069
        },
        "rougeL": {
            "precision": 0.52553,
            "recall": 0.42333,
            "fmeasure": 0.45891
        },
        "rougeLsum": {
            "precision": 0.52553,
            "recall": 0.42333,
            "fmeasure": 0.45891
        },
        "bleu": 24.39991,
        "meteor": 0.26187860364466986,
        "bertscore": {
            "precision": 0.87844,
            "recall": 0.86157,
            "f1": 0.86896
        },
        "nubia": {
            "semantic_relation": 3.21684,
            "contradiction": 19.56728,
            "irrelevancy": 38.12783,
            "logical_agreement": 42.30489,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.22071,
            "nubia_score": 0.43842
        },
        "bleurt": -0.18484
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 267,
        "msttr-100": 0.47964,
        "msttr-100_nopunct": 0.508,
        "total_length": 2892,
        "mean_pred_length": 10.831460674157304,
        "std_pred_length": 3.224099171772987,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.12240663900414937,
        "vocab_size-1": 354,
        "unique-1": 158,
        "entropy-1": 6.274658885275744,
        "distinct-2": 0.3142857142857143,
        "vocab_size-2": 825,
        "unique-2": 510,
        "entropy-2": 8.303570485541675,
        "cond_entropy-2": 1.771949424718545,
        "distinct-3": 0.44232400339270567,
        "vocab_size-3": 1043,
        "unique-3": 742,
        "entropy-3": 9.03347651078296,
        "cond_entropy-3": 0.9463163381743278,
        "total_length-nopunct": 2540,
        "mean_pred_length-nopunct": 9.513108614232209,
        "std_pred_length-nopunct": 2.951990453895192,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.13818897637795274,
        "vocab_size-1-nopunct": 351,
        "unique-1-nopunct": 158,
        "entropy-1-nopunct": 6.427261502703761,
        "distinct-2-nopunct": 0.2938847338319402,
        "vocab_size-2-nopunct": 668,
        "unique-2-nopunct": 413,
        "entropy-2-nopunct": 7.929257919999262,
        "cond_entropy-2-nopunct": 1.8587070323609278,
        "distinct-3-nopunct": 0.4222333000997009,
        "vocab_size-3-nopunct": 847,
        "unique-3-nopunct": 597,
        "entropy-3-nopunct": 8.70543922208303,
        "cond_entropy-3-nopunct": 1.0505737889199593,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.5756972111553785
        },
        "nist": 3.584461968479888,
        "rouge1": {
            "precision": 0.49477,
            "recall": 0.61992,
            "fmeasure": 0.5322
        },
        "rouge2": {
            "precision": 0.26404,
            "recall": 0.33977,
            "fmeasure": 0.28554
        },
        "rougeL": {
            "precision": 0.44346,
            "recall": 0.55296,
            "fmeasure": 0.4761
        },
        "rougeLsum": {
            "precision": 0.44346,
            "recall": 0.55296,
            "fmeasure": 0.4761
        },
        "bleu": 16.57998,
        "meteor": 0.28482258993398646,
        "bertscore": {
            "precision": 0.89189,
            "recall": 0.91168,
            "f1": 0.90135
        },
        "nubia": {
            "semantic_relation": 3.59939,
            "contradiction": 16.15022,
            "irrelevancy": 37.62067,
            "logical_agreement": 46.22911,
            "grammar_ref": 7.44295,
            "grammar_hyp": 6.88578,
            "nubia_score": 0.56162
        },
        "bleurt": -0.10128
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 414,
        "msttr-100": 0.52519,
        "msttr-100_nopunct": 0.53319,
        "total_length": 7700,
        "mean_pred_length": 18.59903381642512,
        "std_pred_length": 4.785606341102092,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.14896103896103896,
        "vocab_size-1": 1147,
        "unique-1": 448,
        "entropy-1": 7.9710775277653205,
        "distinct-2": 0.4080428218501235,
        "vocab_size-2": 2973,
        "unique-2": 1758,
        "entropy-2": 10.73490990764474,
        "cond_entropy-2": 2.6235148549942733,
        "distinct-3": 0.6037543655413271,
        "vocab_size-3": 4149,
        "unique-3": 2984,
        "entropy-3": 11.592954035895634,
        "cond_entropy-3": 0.9282017281910717,
        "total_length-nopunct": 6928,
        "mean_pred_length-nopunct": 16.734299516908212,
        "std_pred_length-nopunct": 4.476123707687434,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.16440531177829099,
        "vocab_size-1-nopunct": 1139,
        "unique-1-nopunct": 447,
        "entropy-1-nopunct": 8.157267708817448,
        "distinct-2-nopunct": 0.40712311943506296,
        "vocab_size-2-nopunct": 2652,
        "unique-2-nopunct": 1591,
        "entropy-2-nopunct": 10.556911524214796,
        "cond_entropy-2-nopunct": 2.567160912015095,
        "distinct-3-nopunct": 0.6011475409836066,
        "vocab_size-3-nopunct": 3667,
        "unique-3-nopunct": 2665,
        "entropy-3-nopunct": 11.397895049946774,
        "cond_entropy-3-nopunct": 0.9103306244943901,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21540210287013356,
            "2": 0.5700652938222,
            "3": 0.849171974522293,
            "4": 0.7272727272727273,
            "5": 0.375
        },
        "nist": 8.67918385010164,
        "rouge1": {
            "precision": 0.76744,
            "recall": 0.74322,
            "fmeasure": 0.74698
        },
        "rouge2": {
            "precision": 0.51952,
            "recall": 0.50202,
            "fmeasure": 0.50403
        },
        "rougeL": {
            "precision": 0.63819,
            "recall": 0.61933,
            "fmeasure": 0.62072
        },
        "rougeLsum": {
            "precision": 0.63819,
            "recall": 0.61933,
            "fmeasure": 0.62072
        },
        "bleu": 47.45166,
        "meteor": 0.3869379074555234,
        "bertscore": {
            "precision": 0.92676,
            "recall": 0.92236,
            "f1": 0.92318
        },
        "nubia": {
            "semantic_relation": 4.44407,
            "contradiction": 8.45155,
            "irrelevancy": 8.5576,
            "logical_agreement": 82.99085,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.72493,
            "nubia_score": 0.77612
        },
        "bleurt": 0.19553
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 149,
        "msttr-100": 0.12,
        "msttr-100_nopunct": 0.1,
        "total_length": 1788,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.006711409395973154,
        "vocab_size-1": 12,
        "unique-1": 0,
        "entropy-1": 3.584962500721156,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 11,
        "unique-2": 0,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 10,
        "unique-3": 0,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 1490,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.006711409395973154,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.17962466487935658
        },
        "nist": 0.5773276759049379,
        "rouge1": {
            "precision": 0.14855,
            "recall": 0.30745,
            "fmeasure": 0.19614
        },
        "rouge2": {
            "precision": 0.05225,
            "recall": 0.12245,
            "fmeasure": 0.07129
        },
        "rougeL": {
            "precision": 0.12215,
            "recall": 0.25885,
            "fmeasure": 0.16224
        },
        "rougeLsum": {
            "precision": 0.12215,
            "recall": 0.25885,
            "fmeasure": 0.16224
        },
        "bleu": 0.52546,
        "meteor": 0.0885976561821442,
        "bertscore": {
            "precision": 0.8442,
            "recall": 0.87897,
            "f1": 0.86118
        },
        "nubia": {
            "semantic_relation": 1.72668,
            "contradiction": 22.65286,
            "irrelevancy": 34.73899,
            "logical_agreement": 42.60815,
            "grammar_ref": 6.81129,
            "grammar_hyp": 5.93004,
            "nubia_score": 0.14929
        },
        "bleurt": -0.48881
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.8,
        "total_length": 292,
        "mean_pred_length": 20.857142857142858,
        "std_pred_length": 5.629731570068008,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.5993150684931506,
        "vocab_size-1": 175,
        "unique-1": 133,
        "entropy-1": 6.9126120369757205,
        "distinct-2": 0.9100719424460432,
        "vocab_size-2": 253,
        "unique-2": 235,
        "entropy-2": 7.915238948683576,
        "cond_entropy-2": 0.9677204829522991,
        "distinct-3": 0.9848484848484849,
        "vocab_size-3": 260,
        "unique-3": 256,
        "entropy-3": 8.014091089055432,
        "cond_entropy-3": 0.10965452573756261,
        "total_length-nopunct": 254,
        "mean_pred_length-nopunct": 18.142857142857142,
        "std_pred_length-nopunct": 4.61143211187685,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6614173228346457,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.954733751817024,
        "distinct-2-nopunct": 0.9458333333333333,
        "vocab_size-2-nopunct": 227,
        "unique-2-nopunct": 216,
        "entropy-2-nopunct": 7.79226653309053,
        "cond_entropy-2-nopunct": 0.8679718983064784,
        "distinct-3-nopunct": 0.9911504424778761,
        "vocab_size-3-nopunct": 224,
        "unique-3-nopunct": 222,
        "entropy-3-nopunct": 7.802479847370966,
        "cond_entropy-3-nopunct": 0.008464362401036069,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2619047619047619,
            "2": 0.23529411764705882,
            "3": 0.46387832699619774
        },
        "nist": 2.2492497129769897,
        "rouge1": {
            "precision": 0.6497,
            "recall": 0.47085,
            "fmeasure": 0.52876
        },
        "rouge2": {
            "precision": 0.2897,
            "recall": 0.21423,
            "fmeasure": 0.23706
        },
        "rougeL": {
            "precision": 0.49035,
            "recall": 0.36156,
            "fmeasure": 0.40197
        },
        "rougeLsum": {
            "precision": 0.49035,
            "recall": 0.36156,
            "fmeasure": 0.40197
        },
        "bleu": 16.04828,
        "meteor": 0.20871085162420433,
        "bertscore": {
            "precision": 0.88359,
            "recall": 0.84488,
            "f1": 0.86282
        },
        "nubia": {
            "semantic_relation": 3.19686,
            "contradiction": 35.96766,
            "irrelevancy": 22.23054,
            "logical_agreement": 41.80179,
            "grammar_ref": 3.91022,
            "grammar_hyp": 4.11485,
            "nubia_score": 0.42345
        },
        "bleurt": -0.20979
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 144,
        "msttr-100": 0.6981,
        "msttr-100_nopunct": 0.72944,
        "total_length": 2121,
        "mean_pred_length": 14.729166666666666,
        "std_pred_length": 5.404754529835539,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.363979255068364,
        "vocab_size-1": 772,
        "unique-1": 575,
        "entropy-1": 7.917638553015323,
        "distinct-2": 0.6798179059180577,
        "vocab_size-2": 1344,
        "unique-2": 1156,
        "entropy-2": 9.836316611243301,
        "cond_entropy-2": 1.6472618644357546,
        "distinct-3": 0.8221494817239499,
        "vocab_size-3": 1507,
        "unique-3": 1378,
        "entropy-3": 10.319032160531195,
        "cond_entropy-3": 0.4765560974564944,
        "total_length-nopunct": 1855,
        "mean_pred_length-nopunct": 12.881944444444445,
        "std_pred_length-nopunct": 4.716249286270491,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.41132075471698115,
        "vocab_size-1-nopunct": 763,
        "unique-1-nopunct": 573,
        "entropy-1-nopunct": 8.139537726501166,
        "distinct-2-nopunct": 0.700759789596727,
        "vocab_size-2-nopunct": 1199,
        "unique-2-nopunct": 1050,
        "entropy-2-nopunct": 9.67005162137906,
        "cond_entropy-2-nopunct": 1.6174918361856312,
        "distinct-3-nopunct": 0.8353541799617102,
        "vocab_size-3-nopunct": 1309,
        "unique-3-nopunct": 1205,
        "entropy-3-nopunct": 10.132162817170329,
        "cond_entropy-3-nopunct": 0.5094367801215377,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26653696498054474,
            "2": 0.5143487858719646,
            "3": 0.7424124513618677
        },
        "nist": 7.402194596792016,
        "rouge1": {
            "precision": 0.73701,
            "recall": 0.71583,
            "fmeasure": 0.70955
        },
        "rouge2": {
            "precision": 0.51175,
            "recall": 0.5022,
            "fmeasure": 0.49349
        },
        "rougeL": {
            "precision": 0.63985,
            "recall": 0.62648,
            "fmeasure": 0.61711
        },
        "rougeLsum": {
            "precision": 0.63985,
            "recall": 0.62648,
            "fmeasure": 0.61711
        },
        "bleu": 45.23129,
        "meteor": 0.39738361108910386,
        "bertscore": {
            "precision": 0.92092,
            "recall": 0.91915,
            "f1": 0.91816
        },
        "nubia": {
            "semantic_relation": 4.08304,
            "contradiction": 6.66671,
            "irrelevancy": 35.26986,
            "logical_agreement": 58.06344,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.62997,
            "nubia_score": 0.71291
        },
        "bleurt": 0.24992
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.66,
        "total_length": 167,
        "mean_pred_length": 23.857142857142858,
        "std_pred_length": 2.2314999074019015,
        "median_pred_length": 23.0,
        "min_pred_length": 21,
        "max_pred_length": 28,
        "distinct-1": 0.6047904191616766,
        "vocab_size-1": 101,
        "unique-1": 82,
        "entropy-1": 6.133985374359882,
        "distinct-2": 0.91875,
        "vocab_size-2": 147,
        "unique-2": 137,
        "entropy-2": 7.142210047998845,
        "cond_entropy-2": 1.0358878257133934,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 150,
        "unique-3": 147,
        "entropy-3": 7.218172156418122,
        "cond_entropy-3": 0.08418450272139033,
        "total_length-nopunct": 149,
        "mean_pred_length-nopunct": 21.285714285714285,
        "std_pred_length-nopunct": 3.103651568914347,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6510067114093959,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.189637712299363,
        "distinct-2-nopunct": 0.9154929577464789,
        "vocab_size-2-nopunct": 130,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.961332418785227,
        "cond_entropy-2-nopunct": 0.7990523653749638,
        "distinct-3-nopunct": 0.9777777777777777,
        "vocab_size-3-nopunct": 132,
        "unique-3-nopunct": 129,
        "entropy-3-nopunct": 7.0323711526064105,
        "cond_entropy-3-nopunct": 0.08080838496958177,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.38333333333333336,
            "3": 0.6630434782608695
        },
        "nist": 3.4743890296588695,
        "rouge1": {
            "precision": 0.65935,
            "recall": 0.54043,
            "fmeasure": 0.58967
        },
        "rouge2": {
            "precision": 0.40153,
            "recall": 0.34539,
            "fmeasure": 0.3684
        },
        "rougeL": {
            "precision": 0.54665,
            "recall": 0.46214,
            "fmeasure": 0.49676
        },
        "rougeLsum": {
            "precision": 0.54665,
            "recall": 0.46214,
            "fmeasure": 0.49676
        },
        "bleu": 30.53533,
        "meteor": 0.2709625893952037,
        "bertscore": {
            "precision": 0.87277,
            "recall": 0.86089,
            "f1": 0.8652
        },
        "nubia": {
            "semantic_relation": 3.01567,
            "contradiction": 30.81561,
            "irrelevancy": 42.94955,
            "logical_agreement": 26.23484,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.81121,
            "nubia_score": 0.43016
        },
        "bleurt": -0.28695
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.73,
        "total_length": 154,
        "mean_pred_length": 25.666666666666668,
        "std_pred_length": 4.642796092394706,
        "median_pred_length": 25.0,
        "min_pred_length": 20,
        "max_pred_length": 33,
        "distinct-1": 0.6688311688311688,
        "vocab_size-1": 103,
        "unique-1": 79,
        "entropy-1": 6.317351479600336,
        "distinct-2": 0.9527027027027027,
        "vocab_size-2": 141,
        "unique-2": 134,
        "entropy-2": 7.114858771034353,
        "cond_entropy-2": 0.8157276317486746,
        "distinct-3": 0.9929577464788732,
        "vocab_size-3": 141,
        "unique-3": 140,
        "entropy-3": 7.135662612462435,
        "cond_entropy-3": 0.02480079612925354,
        "total_length-nopunct": 138,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 3.696845502136472,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.717391304347826,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.333207656345623,
        "distinct-2-nopunct": 0.9621212121212122,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 6.968636543600869,
        "cond_entropy-2-nopunct": 0.6630948024264272,
        "distinct-3-nopunct": 0.9920634920634921,
        "vocab_size-3-nopunct": 125,
        "unique-3-nopunct": 124,
        "entropy-3-nopunct": 6.961406907626909,
        "cond_entropy-3-nopunct": -0.003622132366473239,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.2222222222222222,
            "3": 0.5663716814159292
        },
        "nist": 3.6396237582115,
        "rouge1": {
            "precision": 0.65311,
            "recall": 0.49179,
            "fmeasure": 0.55593
        },
        "rouge2": {
            "precision": 0.4752,
            "recall": 0.35748,
            "fmeasure": 0.40395
        },
        "rougeL": {
            "precision": 0.55756,
            "recall": 0.42948,
            "fmeasure": 0.48057
        },
        "rougeLsum": {
            "precision": 0.55756,
            "recall": 0.42948,
            "fmeasure": 0.48057
        },
        "bleu": 35.43497,
        "meteor": 0.2764115501537,
        "bertscore": {
            "precision": 0.89487,
            "recall": 0.86279,
            "f1": 0.87792
        },
        "nubia": {
            "semantic_relation": 3.01822,
            "contradiction": 5.65823,
            "irrelevancy": 46.78441,
            "logical_agreement": 47.55735,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.62666,
            "nubia_score": 0.43169
        },
        "bleurt": -0.20955
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 254,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.89412,
        "total_length": 2102,
        "mean_pred_length": 8.275590551181102,
        "std_pred_length": 2.2278734090697014,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 15,
        "distinct-1": 0.4514747859181732,
        "vocab_size-1": 949,
        "unique-1": 684,
        "entropy-1": 8.479767261629052,
        "distinct-2": 0.7949134199134199,
        "vocab_size-2": 1469,
        "unique-2": 1241,
        "entropy-2": 10.32538858463087,
        "cond_entropy-2": 1.2338956528186424,
        "distinct-3": 0.9058971141781681,
        "vocab_size-3": 1444,
        "unique-3": 1325,
        "entropy-3": 10.428918185377183,
        "cond_entropy-3": 0.11114540698231383,
        "total_length-nopunct": 1700,
        "mean_pred_length-nopunct": 6.692913385826771,
        "std_pred_length-nopunct": 2.048666979787781,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5552941176470588,
        "vocab_size-1-nopunct": 944,
        "unique-1-nopunct": 684,
        "entropy-1-nopunct": 9.1840158124677,
        "distinct-2-nopunct": 0.8125864453665284,
        "vocab_size-2-nopunct": 1175,
        "unique-2-nopunct": 1013,
        "entropy-2-nopunct": 10.011901046328749,
        "cond_entropy-2-nopunct": 0.9723210667266073,
        "distinct-3-nopunct": 0.912751677852349,
        "vocab_size-3-nopunct": 1088,
        "unique-3-nopunct": 1007,
        "entropy-3-nopunct": 10.022367193764357,
        "cond_entropy-3-nopunct": 0.07385305837268669,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.37771739130434784,
            "2": 0.6754507628294036,
            "3": 0.7474402730375427,
            "4": 0.7142857142857143,
            "5": 0.6363636363636364,
            "6": 0.9,
            "7": 1.0
        },
        "nist": 8.21737935192436,
        "rouge1": {
            "precision": 0.30243,
            "recall": 0.30272,
            "fmeasure": 0.29992
        },
        "rouge2": {
            "precision": 0.17851,
            "recall": 0.1752,
            "fmeasure": 0.17616
        },
        "rougeL": {
            "precision": 0.30243,
            "recall": 0.30272,
            "fmeasure": 0.29992
        },
        "rougeLsum": {
            "precision": 0.30243,
            "recall": 0.30272,
            "fmeasure": 0.29992
        },
        "bleu": 57.45407,
        "meteor": 0.7227191630137031,
        "bertscore": {
            "precision": 0.96799,
            "recall": 0.96391,
            "f1": 0.96551
        },
        "nubia": {
            "semantic_relation": 4.14825,
            "contradiction": 20.61925,
            "irrelevancy": 21.23232,
            "logical_agreement": 58.14844,
            "grammar_ref": 2.90382,
            "grammar_hyp": 2.9212,
            "nubia_score": 0.83126
        },
        "bleurt": 0.38222
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.67714,
        "msttr-100_nopunct": 0.72167,
        "total_length": 787,
        "mean_pred_length": 16.74468085106383,
        "std_pred_length": 6.224413447906909,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.4307496823379924,
        "vocab_size-1": 339,
        "unique-1": 245,
        "entropy-1": 7.302976833502755,
        "distinct-2": 0.7391891891891892,
        "vocab_size-2": 547,
        "unique-2": 453,
        "entropy-2": 8.80330777110186,
        "cond_entropy-2": 1.3341640042395644,
        "distinct-3": 0.8268398268398268,
        "vocab_size-3": 573,
        "unique-3": 504,
        "entropy-3": 8.983781533055092,
        "cond_entropy-3": 0.2027891672928345,
        "total_length-nopunct": 675,
        "mean_pred_length-nopunct": 14.361702127659575,
        "std_pred_length-nopunct": 5.532978621132597,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4918518518518519,
        "vocab_size-1-nopunct": 332,
        "unique-1-nopunct": 245,
        "entropy-1-nopunct": 7.44350356640711,
        "distinct-2-nopunct": 0.7579617834394905,
        "vocab_size-2-nopunct": 476,
        "unique-2-nopunct": 403,
        "entropy-2-nopunct": 8.604508563889276,
        "cond_entropy-2-nopunct": 1.238209035350214,
        "distinct-3-nopunct": 0.8382099827882961,
        "vocab_size-3-nopunct": 487,
        "unique-3-nopunct": 434,
        "entropy-3-nopunct": 8.754906020720068,
        "cond_entropy-3-nopunct": 0.18557004322527054,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18620689655172415,
            "2": 0.31654676258992803,
            "3": 0.7419354838709677
        },
        "nist": 5.942659821341551,
        "rouge1": {
            "precision": 0.67093,
            "recall": 0.7145,
            "fmeasure": 0.67584
        },
        "rouge2": {
            "precision": 0.44247,
            "recall": 0.46443,
            "fmeasure": 0.44498
        },
        "rougeL": {
            "precision": 0.59067,
            "recall": 0.62331,
            "fmeasure": 0.59297
        },
        "rougeLsum": {
            "precision": 0.59067,
            "recall": 0.62331,
            "fmeasure": 0.59297
        },
        "bleu": 41.14872,
        "meteor": 0.37115770492313166,
        "bertscore": {
            "precision": 0.90366,
            "recall": 0.91215,
            "f1": 0.90614
        },
        "nubia": {
            "semantic_relation": 3.85354,
            "contradiction": 10.95083,
            "irrelevancy": 36.79751,
            "logical_agreement": 52.25165,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.26191,
            "nubia_score": 0.64055
        },
        "bleurt": 0.19875
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 107,
        "mean_pred_length": 21.4,
        "std_pred_length": 3.3823069050575527,
        "median_pred_length": 21.0,
        "min_pred_length": 18,
        "max_pred_length": 27,
        "distinct-1": 0.7102803738317757,
        "vocab_size-1": 76,
        "unique-1": 62,
        "entropy-1": 5.978394645356798,
        "distinct-2": 0.9607843137254902,
        "vocab_size-2": 98,
        "unique-2": 94,
        "entropy-2": 6.59399396942248,
        "cond_entropy-2": 0.5712415956572107,
        "distinct-3": 0.9896907216494846,
        "vocab_size-3": 96,
        "unique-3": 95,
        "entropy-3": 6.57929428548611,
        "cond_entropy-3": -0.0209661080317907,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.8944271909999159,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7888888888888889,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.951528757628658,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.409390936137707,
        "cond_entropy-2-nopunct": 0.4778812572561534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.08746284125033944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.38095238095238093,
            "3": 0.5066666666666667
        },
        "nist": 2.0402084142246135,
        "rouge1": {
            "precision": 0.6178,
            "recall": 0.49653,
            "fmeasure": 0.52305
        },
        "rouge2": {
            "precision": 0.33423,
            "recall": 0.28865,
            "fmeasure": 0.28857
        },
        "rougeL": {
            "precision": 0.50842,
            "recall": 0.43113,
            "fmeasure": 0.44316
        },
        "rougeLsum": {
            "precision": 0.50842,
            "recall": 0.43113,
            "fmeasure": 0.44316
        },
        "bleu": 13.62216,
        "meteor": 0.211642186247431,
        "bertscore": {
            "precision": 0.863,
            "recall": 0.86599,
            "f1": 0.86337
        },
        "nubia": {
            "semantic_relation": 2.99167,
            "contradiction": 35.34001,
            "irrelevancy": 36.56291,
            "logical_agreement": 28.09708,
            "grammar_ref": 3.87874,
            "grammar_hyp": 4.05224,
            "nubia_score": 0.35384
        },
        "bleurt": -0.22224
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 96,
        "mean_pred_length": 19.2,
        "std_pred_length": 5.6000000000000005,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6875,
        "vocab_size-1": 66,
        "unique-1": 50,
        "entropy-1": 5.787782031835944,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 84,
        "unique-2": 77,
        "entropy-2": 6.353948486352544,
        "cond_entropy-2": 0.5467270571788292,
        "distinct-3": 0.9534883720930233,
        "vocab_size-3": 82,
        "unique-3": 78,
        "entropy-3": 6.333241498888145,
        "cond_entropy-3": -0.011762443636133085,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 4.758150901348127,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7469879518072289,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.7212483168109,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.208479141939178,
        "cond_entropy-2-nopunct": 0.49599996707646793,
        "distinct-3-nopunct": 0.9863013698630136,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.162427298606055,
        "cond_entropy-3-nopunct": -0.04078313943428604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.36363636363636365,
            "3": 0.6857142857142857
        },
        "nist": 3.7542021336190223,
        "rouge1": {
            "precision": 0.54021,
            "recall": 0.50459,
            "fmeasure": 0.51694
        },
        "rouge2": {
            "precision": 0.25993,
            "recall": 0.23702,
            "fmeasure": 0.24514
        },
        "rougeL": {
            "precision": 0.45193,
            "recall": 0.4256,
            "fmeasure": 0.43414
        },
        "rougeLsum": {
            "precision": 0.45193,
            "recall": 0.4256,
            "fmeasure": 0.43414
        },
        "bleu": 21.25195,
        "meteor": 0.25803397516059956,
        "bertscore": {
            "precision": 0.86279,
            "recall": 0.87033,
            "f1": 0.86453
        },
        "nubia": {
            "semantic_relation": 3.12817,
            "contradiction": 58.23575,
            "irrelevancy": 36.2165,
            "logical_agreement": 5.54775,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.36064,
            "nubia_score": 0.43742
        },
        "bleurt": -0.22834
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.61,
        "msttr-100_nopunct": 0.67,
        "total_length": 121,
        "mean_pred_length": 24.2,
        "std_pred_length": 3.4292856398964493,
        "median_pred_length": 23.0,
        "min_pred_length": 21,
        "max_pred_length": 30,
        "distinct-1": 0.6115702479338843,
        "vocab_size-1": 74,
        "unique-1": 61,
        "entropy-1": 5.615750371590367,
        "distinct-2": 0.8879310344827587,
        "vocab_size-2": 103,
        "unique-2": 93,
        "entropy-2": 6.614320111450917,
        "cond_entropy-2": 1.0210583065227459,
        "distinct-3": 0.9819819819819819,
        "vocab_size-3": 109,
        "unique-3": 107,
        "entropy-3": 6.758379830314084,
        "cond_entropy-3": 0.15503543434406877,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 21.2,
        "std_pred_length-nopunct": 4.166533331199932,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6886792452830188,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.793266701604095,
        "distinct-2-nopunct": 0.9108910891089109,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.457571259915243,
        "cond_entropy-2-nopunct": 0.7105745460814056,
        "distinct-3-nopunct": 0.9791666666666666,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.543295834054494,
        "cond_entropy-3-nopunct": 0.09617458574530346,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.15625,
            "3": 0.48148148148148145
        },
        "nist": 2.2854580810568224,
        "rouge1": {
            "precision": 0.49381,
            "recall": 0.43015,
            "fmeasure": 0.44401
        },
        "rouge2": {
            "precision": 0.20237,
            "recall": 0.20182,
            "fmeasure": 0.196
        },
        "rougeL": {
            "precision": 0.34623,
            "recall": 0.30186,
            "fmeasure": 0.31058
        },
        "rougeLsum": {
            "precision": 0.34623,
            "recall": 0.30186,
            "fmeasure": 0.31058
        },
        "bleu": 14.69769,
        "meteor": 0.2045886414856922,
        "bertscore": {
            "precision": 0.82572,
            "recall": 0.79315,
            "f1": 0.80562
        },
        "nubia": {
            "semantic_relation": 3.00119,
            "contradiction": 10.23409,
            "irrelevancy": 38.71136,
            "logical_agreement": 51.05455,
            "grammar_ref": 4.13756,
            "grammar_hyp": 3.62505,
            "nubia_score": 0.45052
        },
        "bleurt": -0.36824
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.664,
        "msttr-100_nopunct": 0.7134,
        "total_length": 5589,
        "mean_pred_length": 11.178,
        "std_pred_length": 3.053901766593025,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.29397029880121667,
        "vocab_size-1": 1643,
        "unique-1": 979,
        "entropy-1": 8.892655502510973,
        "distinct-2": 0.6191786205541364,
        "vocab_size-2": 3151,
        "unique-2": 2367,
        "entropy-2": 11.160582974846228,
        "cond_entropy-2": 2.2968803853545547,
        "distinct-3": 0.7973414687295707,
        "vocab_size-3": 3659,
        "unique-3": 3083,
        "entropy-3": 11.672574805759357,
        "cond_entropy-3": 0.5909144394785805,
        "total_length-nopunct": 4756,
        "mean_pred_length-nopunct": 9.512,
        "std_pred_length-nopunct": 2.693298349607782,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3437762825904121,
        "vocab_size-1-nopunct": 1635,
        "unique-1-nopunct": 977,
        "entropy-1-nopunct": 9.382875426813104,
        "distinct-2-nopunct": 0.6614191729323309,
        "vocab_size-2-nopunct": 2815,
        "unique-2-nopunct": 2203,
        "entropy-2-nopunct": 11.056472990142076,
        "cond_entropy-2-nopunct": 1.8548763852172017,
        "distinct-3-nopunct": 0.81975505857295,
        "vocab_size-3-nopunct": 3079,
        "unique-3-nopunct": 2662,
        "entropy-3-nopunct": 11.435762453360752,
        "cond_entropy-3-nopunct": 0.4694532053105117,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.1716101694915254,
            "2": 0.34424242424242424,
            "3": 0.5025359256128487,
            "4": 0.5777777777777777,
            "5": 0.6,
            "6": 1.0
        },
        "nist": 1.5731512282118305,
        "rouge1": {
            "precision": 0.29323,
            "recall": 0.23738,
            "fmeasure": 0.25237
        },
        "rouge2": {
            "precision": 0.13695,
            "recall": 0.10775,
            "fmeasure": 0.11533
        },
        "rougeL": {
            "precision": 0.28808,
            "recall": 0.23362,
            "fmeasure": 0.24807
        },
        "rougeLsum": {
            "precision": 0.28808,
            "recall": 0.23362,
            "fmeasure": 0.24807
        },
        "bleu": 21.88039,
        "meteor": 0.3960675890612548,
        "bertscore": {
            "precision": 0.95061,
            "recall": 0.91326,
            "f1": 0.93058
        },
        "nubia": {
            "semantic_relation": 3.59833,
            "contradiction": 22.47054,
            "irrelevancy": 22.56021,
            "logical_agreement": 54.96926,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.74654,
            "nubia_score": 0.69842
        },
        "bleurt": 0.10714
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73266,
        "msttr-100_nopunct": 0.76982,
        "total_length": 6472,
        "mean_pred_length": 18.027855153203344,
        "std_pred_length": 6.155306936102102,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.35939431396786153,
        "vocab_size-1": 2326,
        "unique-1": 1694,
        "entropy-1": 9.041400391999355,
        "distinct-2": 0.8194012759692458,
        "vocab_size-2": 5009,
        "unique-2": 4631,
        "entropy-2": 11.908622435405071,
        "cond_entropy-2": 2.6994473115553896,
        "distinct-3": 0.9494264859228363,
        "vocab_size-3": 5463,
        "unique-3": 5351,
        "entropy-3": 12.300521906911825,
        "cond_entropy-3": 0.41462919015205124,
        "total_length-nopunct": 5756,
        "mean_pred_length-nopunct": 16.03342618384401,
        "std_pred_length-nopunct": 5.604315608736071,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.40218902015288394,
        "vocab_size-1-nopunct": 2315,
        "unique-1-nopunct": 1693,
        "entropy-1-nopunct": 9.3388958536926,
        "distinct-2-nopunct": 0.8530665184361682,
        "vocab_size-2-nopunct": 4604,
        "unique-2-nopunct": 4283,
        "entropy-2-nopunct": 11.908064888858732,
        "cond_entropy-2-nopunct": 2.7008409707095486,
        "distinct-3-nopunct": 0.9753870583564906,
        "vocab_size-3-nopunct": 4914,
        "unique-3-nopunct": 4827,
        "entropy-3-nopunct": 12.241499115043315,
        "cond_entropy-3-nopunct": 0.3566665332014031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04711375212224109,
            "2": 0.16219667943805874,
            "3": 0.3347921225382932,
            "4": 0.4358161648177496,
            "5": 0.5160955347871236,
            "6": 0.6473429951690821,
            "7": 0.8010691103474609
        },
        "nist": 9.429216404028697,
        "rouge1": {
            "precision": 0.80752,
            "recall": 0.72406,
            "fmeasure": 0.74722
        },
        "rouge2": {
            "precision": 0.65389,
            "recall": 0.58506,
            "fmeasure": 0.6021
        },
        "rougeL": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "rougeLsum": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "bleu": 59.46369,
        "sari": 42.21422,
        "meteor": 0.39878954357926183,
        "bertscore": {
            "precision": 0.93904,
            "recall": 0.92612,
            "f1": 0.92923
        },
        "nubia": {
            "semantic_relation": 4.02391,
            "contradiction": 5.62065,
            "irrelevancy": 22.17407,
            "logical_agreement": 72.20528,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.96242,
            "nubia_score": 0.61717
        },
        "bleurt": 0.04008
    },
    "wiki_auto_asset_turk_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_train_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 86,
        "mean_pred_length": 21.5,
        "std_pred_length": 6.946221994724902,
        "median_pred_length": 24.5,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.7325581395348837,
        "vocab_size-1": 63,
        "unique-1": 52,
        "entropy-1": 5.753307743295968,
        "distinct-2": 0.9634146341463414,
        "vocab_size-2": 79,
        "unique-2": 77,
        "entropy-2": 6.275175327762435,
        "cond_entropy-2": 0.5546947557545684,
        "distinct-3": 0.9871794871794872,
        "vocab_size-3": 77,
        "unique-3": 76,
        "entropy-3": 6.259761193221231,
        "cond_entropy-3": -0.01118968957425218,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 6.946221994724902,
        "median_pred_length-nopunct": 23.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7439024390243902,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.7097542548770654,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.198801097039648,
        "cond_entropy-2-nopunct": 0.5222672395851936,
        "distinct-3-nopunct": 0.9864864864864865,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.182426338601928,
        "cond_entropy-3-nopunct": -0.011693616717576166,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.4523809523809524
        },
        "nist": 1.131254411369941,
        "rouge1": {
            "precision": 0.59878,
            "recall": 0.47899,
            "fmeasure": 0.52316
        },
        "rouge2": {
            "precision": 0.33119,
            "recall": 0.2899,
            "fmeasure": 0.30417
        },
        "rougeL": {
            "precision": 0.48368,
            "recall": 0.40279,
            "fmeasure": 0.43168
        },
        "rougeLsum": {
            "precision": 0.48368,
            "recall": 0.40279,
            "fmeasure": 0.43168
        },
        "bleu": 11.58553,
        "meteor": 0.18717159628646135,
        "bertscore": {
            "precision": 0.85467,
            "recall": 0.81688,
            "f1": 0.83433
        },
        "nubia": {
            "semantic_relation": 2.88241,
            "contradiction": 26.00692,
            "irrelevancy": 45.27675,
            "logical_agreement": 28.71633,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.74535,
            "nubia_score": 0.33271
        },
        "bleurt": -0.2662
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 59,
        "msttr-100": 0.70889,
        "msttr-100_nopunct": 0.76125,
        "total_length": 935,
        "mean_pred_length": 15.847457627118644,
        "std_pred_length": 4.21383339032583,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.47593582887700536,
        "vocab_size-1": 445,
        "unique-1": 360,
        "entropy-1": 7.641495068969171,
        "distinct-2": 0.7945205479452054,
        "vocab_size-2": 696,
        "unique-2": 620,
        "entropy-2": 9.182231930958993,
        "cond_entropy-2": 1.3069303287081546,
        "distinct-3": 0.8886168910648715,
        "vocab_size-3": 726,
        "unique-3": 674,
        "entropy-3": 9.396408956716082,
        "cond_entropy-3": 0.22520672234545505,
        "total_length-nopunct": 823,
        "mean_pred_length-nopunct": 13.94915254237288,
        "std_pred_length-nopunct": 3.8638863759022946,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5297691373025516,
        "vocab_size-1-nopunct": 436,
        "unique-1-nopunct": 357,
        "entropy-1-nopunct": 7.808798617198955,
        "distinct-2-nopunct": 0.7971204188481675,
        "vocab_size-2-nopunct": 609,
        "unique-2-nopunct": 546,
        "entropy-2-nopunct": 8.980970431824684,
        "cond_entropy-2-nopunct": 1.25858447443238,
        "distinct-3-nopunct": 0.8921985815602836,
        "vocab_size-3-nopunct": 629,
        "unique-3-nopunct": 584,
        "entropy-3-nopunct": 9.194217545974212,
        "cond_entropy-3-nopunct": 0.2438940402145132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3081761006289308,
            "2": 0.5112781954887218,
            "3": 0.810641627543036
        },
        "nist": 7.544365658106644,
        "rouge1": {
            "precision": 0.78843,
            "recall": 0.76359,
            "fmeasure": 0.76934
        },
        "rouge2": {
            "precision": 0.58122,
            "recall": 0.55802,
            "fmeasure": 0.56396
        },
        "rougeL": {
            "precision": 0.69899,
            "recall": 0.68351,
            "fmeasure": 0.68489
        },
        "rougeLsum": {
            "precision": 0.69899,
            "recall": 0.68351,
            "fmeasure": 0.68489
        },
        "bleu": 53.10781,
        "meteor": 0.42353375619641337,
        "bertscore": {
            "precision": 0.94135,
            "recall": 0.93288,
            "f1": 0.93601
        },
        "nubia": {
            "semantic_relation": 4.27131,
            "contradiction": 4.63189,
            "irrelevancy": 27.11004,
            "logical_agreement": 68.25807,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.43262,
            "nubia_score": 0.78047
        },
        "bleurt": 0.34511
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622848,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.2727272727272727,
            "3": 0.6666666666666666
        },
        "nist": 1.6804511722130415,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.51429,
            "fmeasure": 0.5202
        },
        "rouge2": {
            "precision": 0.2619,
            "recall": 0.25776,
            "fmeasure": 0.25814
        },
        "rougeL": {
            "precision": 0.35556,
            "recall": 0.35238,
            "fmeasure": 0.35205
        },
        "rougeLsum": {
            "precision": 0.35556,
            "recall": 0.35238,
            "fmeasure": 0.35205
        },
        "bleu": 14.9808,
        "meteor": 0.2616147355069234,
        "bertscore": {
            "precision": 0.90054,
            "recall": 0.89719,
            "f1": 0.87313
        },
        "nubia": {
            "semantic_relation": 4.05738,
            "contradiction": 0.07047,
            "irrelevancy": 99.75774,
            "logical_agreement": 0.1718,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.05928,
            "nubia_score": 0.72237
        },
        "bleurt": 0.14794
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 500,
        "msttr-100": 0.51,
        "msttr-100_nopunct": 0.51144,
        "total_length": 11180,
        "mean_pred_length": 22.36,
        "std_pred_length": 4.003298639871875,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.02817531305903399,
        "vocab_size-1": 315,
        "unique-1": 95,
        "entropy-1": 6.118610331155203,
        "distinct-2": 0.10449438202247191,
        "vocab_size-2": 1116,
        "unique-2": 494,
        "entropy-2": 8.192458619843297,
        "cond_entropy-2": 2.1198574272231108,
        "distinct-3": 0.20166994106090375,
        "vocab_size-3": 2053,
        "unique-3": 1059,
        "entropy-3": 9.490862799189397,
        "cond_entropy-3": 1.3847009243198136,
        "total_length-nopunct": 10488,
        "mean_pred_length-nopunct": 20.976,
        "std_pred_length-nopunct": 3.938962299895748,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.029748283752860413,
        "vocab_size-1-nopunct": 312,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.1285428283405725,
        "distinct-2-nopunct": 0.10853023628354025,
        "vocab_size-2-nopunct": 1084,
        "unique-2-nopunct": 492,
        "entropy-2-nopunct": 8.177696099130879,
        "cond_entropy-2-nopunct": 2.1645584306687384,
        "distinct-3-nopunct": 0.20994940978077573,
        "vocab_size-3-nopunct": 1992,
        "unique-3-nopunct": 1033,
        "entropy-3-nopunct": 9.517510996379675,
        "cond_entropy-3-nopunct": 1.4112485387892535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6411234074211848
        },
        "nist": 4.74184561043458,
        "rouge1": {
            "precision": 0.73988,
            "recall": 0.65913,
            "fmeasure": 0.68721
        },
        "rouge2": {
            "precision": 0.43351,
            "recall": 0.38589,
            "fmeasure": 0.40226
        },
        "rougeL": {
            "precision": 0.51813,
            "recall": 0.46318,
            "fmeasure": 0.48215
        },
        "rougeLsum": {
            "precision": 0.51813,
            "recall": 0.46318,
            "fmeasure": 0.48215
        },
        "bleu": 26.37949,
        "meteor": 0.3284652487694952,
        "bertscore": {
            "precision": 0.91018,
            "recall": 0.89077,
            "f1": 0.90004
        },
        "nubia": {
            "semantic_relation": 4.0775,
            "contradiction": 2.90277,
            "irrelevancy": 22.50317,
            "logical_agreement": 74.59406,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.79104,
            "nubia_score": 0.68668
        },
        "bleurt": 0.01666
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.68,
        "vocab_size-1": 34,
        "unique-1": 27,
        "entropy-1": 4.748758439731456,
        "distinct-2": 0.8958333333333334,
        "vocab_size-2": 43,
        "unique-2": 38,
        "entropy-2": 5.376629167387826,
        "cond_entropy-2": 0.6651664672415043,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 44,
        "unique-3": 42,
        "entropy-3": 5.43660543431788,
        "cond_entropy-3": 0.06903423794455235,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.898153434632012,
        "distinct-2-nopunct": 0.925,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.171928094887363,
        "cond_entropy-2-nopunct": 0.2984828596626887,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": 0.08389415539832848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.19047619047619047,
            "3": 0.631578947368421
        },
        "nist": 2.471584827493907,
        "rouge1": {
            "precision": 0.42271,
            "recall": 0.38328,
            "fmeasure": 0.40142
        },
        "rouge2": {
            "precision": 0.21034,
            "recall": 0.18091,
            "fmeasure": 0.19413
        },
        "rougeL": {
            "precision": 0.37923,
            "recall": 0.32845,
            "fmeasure": 0.35137
        },
        "rougeLsum": {
            "precision": 0.37923,
            "recall": 0.32845,
            "fmeasure": 0.35137
        },
        "bleu": 20.99579,
        "meteor": 0.21497798463951615,
        "bertscore": {
            "precision": 0.85221,
            "recall": 0.85792,
            "f1": 0.85223
        },
        "nubia": {
            "semantic_relation": 2.77286,
            "contradiction": 53.99913,
            "irrelevancy": 39.22405,
            "logical_agreement": 6.77682,
            "grammar_ref": 4.17,
            "grammar_hyp": 4.11428,
            "nubia_score": 0.31493
        },
        "bleurt": -0.53474
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "total_length": 107,
        "mean_pred_length": 26.75,
        "std_pred_length": 4.380353866983808,
        "median_pred_length": 26.5,
        "min_pred_length": 21,
        "max_pred_length": 33,
        "distinct-1": 0.6542056074766355,
        "vocab_size-1": 70,
        "unique-1": 58,
        "entropy-1": 5.681653057277238,
        "distinct-2": 0.9029126213592233,
        "vocab_size-2": 93,
        "unique-2": 87,
        "entropy-2": 6.449951711876432,
        "cond_entropy-2": 0.7649422780532976,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 96,
        "unique-3": 93,
        "entropy-3": 6.568750559473558,
        "cond_entropy-3": 0.10490255634803643,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 20.5,
        "std_pred_length-nopunct": 1.6583123951777,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7804878048780488,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.782414694145766,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.234120167580204,
        "cond_entropy-2-nopunct": 0.4683791816637825,
        "distinct-3-nopunct": 0.9864864864864865,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.182426338601928,
        "cond_entropy-3-nopunct": -0.048921826206271835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4772727272727273,
            "3": 0.5263157894736842
        },
        "nist": 3.7204216125101452,
        "rouge1": {
            "precision": 0.708,
            "recall": 0.54707,
            "fmeasure": 0.59774
        },
        "rouge2": {
            "precision": 0.46562,
            "recall": 0.36676,
            "fmeasure": 0.39525
        },
        "rougeL": {
            "precision": 0.63136,
            "recall": 0.46692,
            "fmeasure": 0.51676
        },
        "rougeLsum": {
            "precision": 0.63136,
            "recall": 0.46692,
            "fmeasure": 0.51676
        },
        "bleu": 42.27373,
        "meteor": 0.30805265601641985,
        "bertscore": {
            "precision": 0.88244,
            "recall": 0.88989,
            "f1": 0.88369
        },
        "nubia": {
            "semantic_relation": 3.00616,
            "contradiction": 7.34572,
            "irrelevancy": 27.4454,
            "logical_agreement": 65.20888,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.41677,
            "nubia_score": 0.39548
        },
        "bleurt": -0.27469
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 159,
        "msttr-100": 0.77211,
        "msttr-100_nopunct": 0.83187,
        "total_length": 1908,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.363240499902064,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.41352201257861637,
        "vocab_size-1": 789,
        "unique-1": 535,
        "entropy-1": 8.325798498505398,
        "distinct-2": 0.747284162378502,
        "vocab_size-2": 1307,
        "unique-2": 1084,
        "entropy-2": 10.084264935856629,
        "cond_entropy-2": 1.8992390993442854,
        "distinct-3": 0.8886792452830189,
        "vocab_size-3": 1413,
        "unique-3": 1284,
        "entropy-3": 10.384193548266664,
        "cond_entropy-3": 0.3485571185241007,
        "total_length-nopunct": 1632,
        "mean_pred_length-nopunct": 10.264150943396226,
        "std_pred_length-nopunct": 1.7678214934098984,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.4791666666666667,
        "vocab_size-1-nopunct": 782,
        "unique-1-nopunct": 535,
        "entropy-1-nopunct": 8.719842340366661,
        "distinct-2-nopunct": 0.7861507128309573,
        "vocab_size-2-nopunct": 1158,
        "unique-2-nopunct": 988,
        "entropy-2-nopunct": 9.964824169658343,
        "cond_entropy-2-nopunct": 1.3661917771720757,
        "distinct-3-nopunct": 0.9041095890410958,
        "vocab_size-3-nopunct": 1188,
        "unique-3-nopunct": 1094,
        "entropy-3-nopunct": 10.145576669909305,
        "cond_entropy-3-nopunct": 0.23409207340152305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.10721247563352826,
            "2": 0.2508038585209003,
            "3": 0.3699825479930192
        },
        "nist": 0.14729609116819448,
        "rouge1": {
            "precision": 0.22799,
            "recall": 0.1515,
            "fmeasure": 0.17099
        },
        "rouge2": {
            "precision": 0.07731,
            "recall": 0.04625,
            "fmeasure": 0.05316
        },
        "rougeL": {
            "precision": 0.22243,
            "recall": 0.14709,
            "fmeasure": 0.16617
        },
        "rougeLsum": {
            "precision": 0.22243,
            "recall": 0.14709,
            "fmeasure": 0.16617
        },
        "bleu": 9.73533,
        "meteor": 0.2837746486255458,
        "bertscore": {
            "precision": 0.93825,
            "recall": 0.87304,
            "f1": 0.90371
        },
        "nubia": {
            "semantic_relation": 3.24991,
            "contradiction": 22.25898,
            "irrelevancy": 21.73158,
            "logical_agreement": 56.00944,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.66105,
            "nubia_score": 0.57588
        },
        "bleurt": -0.0549
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 29,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.70667,
        "total_length": 361,
        "mean_pred_length": 12.448275862068966,
        "std_pred_length": 2.190673127485323,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.4182825484764543,
        "vocab_size-1": 151,
        "unique-1": 81,
        "entropy-1": 6.497114702342828,
        "distinct-2": 0.6445783132530121,
        "vocab_size-2": 214,
        "unique-2": 143,
        "entropy-2": 7.508469825993305,
        "cond_entropy-2": 1.1360382583444877,
        "distinct-3": 0.7656765676567657,
        "vocab_size-3": 232,
        "unique-3": 183,
        "entropy-3": 7.7116272837172986,
        "cond_entropy-3": 0.2671034347968903,
        "total_length-nopunct": 315,
        "mean_pred_length-nopunct": 10.862068965517242,
        "std_pred_length-nopunct": 2.046428982752799,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.46984126984126984,
        "vocab_size-1-nopunct": 148,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.669518368834487,
        "distinct-2-nopunct": 0.6713286713286714,
        "vocab_size-2-nopunct": 192,
        "unique-2-nopunct": 135,
        "entropy-2-nopunct": 7.363274113014546,
        "cond_entropy-2-nopunct": 0.8126867205385291,
        "distinct-3-nopunct": 0.77431906614786,
        "vocab_size-3-nopunct": 199,
        "unique-3-nopunct": 158,
        "entropy-3-nopunct": 7.498606017972893,
        "cond_entropy-3-nopunct": 0.20671879984937314,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.06818181818181818,
            "2": 0.18823529411764706,
            "3": 0.34017595307917886
        },
        "nist": 0.007491548206658293,
        "rouge1": {
            "precision": 0.48276,
            "recall": 0.28994,
            "fmeasure": 0.33916
        },
        "rouge2": {
            "precision": 0.31034,
            "recall": 0.19758,
            "fmeasure": 0.21925
        },
        "rougeL": {
            "precision": 0.48276,
            "recall": 0.28994,
            "fmeasure": 0.33916
        },
        "rougeLsum": {
            "precision": 0.48276,
            "recall": 0.28994,
            "fmeasure": 0.33916
        },
        "bleu": 4.88265,
        "meteor": 0.24806495397507417,
        "bertscore": {
            "precision": 0.93703,
            "recall": 0.84986,
            "f1": 0.89097
        },
        "nubia": {
            "semantic_relation": 3.02831,
            "contradiction": 25.07612,
            "irrelevancy": 23.26332,
            "logical_agreement": 51.66056,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.69229,
            "nubia_score": 0.65417
        },
        "bleurt": -0.0097
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5714285714285714,
            "3": 0.3333333333333333
        },
        "nist": 2.2735571753428823,
        "rouge1": {
            "precision": 0.38889,
            "recall": 0.4375,
            "fmeasure": 0.41176
        },
        "rouge2": {
            "precision": 0.17647,
            "recall": 0.2,
            "fmeasure": 0.1875
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.375,
            "fmeasure": 0.35294
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.375,
            "fmeasure": 0.35294
        },
        "bleu": 10.41303,
        "meteor": 0.1793403579288511,
        "bertscore": {
            "precision": 0.80945,
            "recall": 0.83972,
            "f1": 0.82431
        },
        "nubia": {
            "semantic_relation": 2.56735,
            "contradiction": 60.36854,
            "irrelevancy": 35.4818,
            "logical_agreement": 4.14966,
            "grammar_ref": 3.92881,
            "grammar_hyp": 3.09714,
            "nubia_score": 0.38229
        },
        "bleurt": -0.2119
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 7.5,
        "median_pred_length": 22.5,
        "min_pred_length": 15,
        "max_pred_length": 30,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 33,
        "unique-1": 30,
        "entropy-1": 4.557325367329447,
        "distinct-2": 0.9767441860465116,
        "vocab_size-2": 42,
        "unique-2": 41,
        "entropy-2": 5.379753126795121,
        "cond_entropy-2": 0.8426383515121961,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.04432250618157529,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.923181998146335,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.006576384576808918,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.0,
            "3": 0.7222222222222222
        },
        "nist": 1.8073747253710215,
        "rouge1": {
            "precision": 0.49901,
            "recall": 0.68443,
            "fmeasure": 0.55732
        },
        "rouge2": {
            "precision": 0.32163,
            "recall": 0.43803,
            "fmeasure": 0.35734
        },
        "rougeL": {
            "precision": 0.49901,
            "recall": 0.68443,
            "fmeasure": 0.55732
        },
        "rougeLsum": {
            "precision": 0.49901,
            "recall": 0.68443,
            "fmeasure": 0.55732
        },
        "bleu": 19.05604,
        "meteor": 0.34693159112068095,
        "bertscore": {
            "precision": 0.81762,
            "recall": 0.93976,
            "f1": 0.86453
        },
        "nubia": {
            "semantic_relation": 3.80838,
            "contradiction": 15.54498,
            "irrelevancy": 49.86222,
            "logical_agreement": 34.5928,
            "grammar_ref": 5.41182,
            "grammar_hyp": 4.45466,
            "nubia_score": 0.59553
        },
        "bleurt": 0.05581
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72925,
        "msttr-100_nopunct": 0.762,
        "total_length": 6758,
        "mean_pred_length": 18.824512534818943,
        "std_pred_length": 5.890822920340777,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3709677419354839,
        "vocab_size-1": 2507,
        "unique-1": 1859,
        "entropy-1": 9.13529021808793,
        "distinct-2": 0.8223159868729489,
        "vocab_size-2": 5262,
        "unique-2": 4859,
        "entropy-2": 11.99041361863729,
        "cond_entropy-2": 2.7286039137986697,
        "distinct-3": 0.9548013245033112,
        "vocab_size-3": 5767,
        "unique-3": 5644,
        "entropy-3": 12.398848657134623,
        "cond_entropy-3": 0.4322075231108565,
        "total_length-nopunct": 6009,
        "mean_pred_length-nopunct": 16.738161559888578,
        "std_pred_length-nopunct": 5.312356748618713,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.41521051755699784,
        "vocab_size-1-nopunct": 2495,
        "unique-1-nopunct": 1857,
        "entropy-1-nopunct": 9.42737677718133,
        "distinct-2-nopunct": 0.8543362831858408,
        "vocab_size-2-nopunct": 4827,
        "unique-2-nopunct": 4488,
        "entropy-2-nopunct": 11.97557207338415,
        "cond_entropy-2-nopunct": 2.6784103275196585,
        "distinct-3-nopunct": 0.9775089775089775,
        "vocab_size-3-nopunct": 5172,
        "unique-3-nopunct": 5076,
        "entropy-3-nopunct": 12.320505242471597,
        "cond_entropy-3-nopunct": 0.36939251540770074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03362734288864388,
            "2": 0.1421832884097035,
            "3": 0.2963855421686747,
            "4": 0.5107033639143731,
            "5": 0.6191198786039454,
            "6": 0.6873239436619718,
            "7": 0.7199453551912568,
            "8": 0.7901085645355851,
            "9": 0.8306878306878307,
            "10": 0.9232558139534883
        },
        "nist": 12.655379487862204,
        "rouge1": {
            "precision": 0.85647,
            "recall": 0.83521,
            "fmeasure": 0.83391
        },
        "rouge2": {
            "precision": 0.75947,
            "recall": 0.7337,
            "fmeasure": 0.73247
        },
        "rougeL": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "rougeLsum": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "bleu": 79.81079,
        "meteor": 0.4813906927942626,
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.95853,
            "f1": 0.95294
        },
        "nubia": {
            "semantic_relation": 4.06468,
            "contradiction": 4.01064,
            "irrelevancy": 34.75851,
            "logical_agreement": 61.23085,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.80536,
            "nubia_score": 0.61895
        },
        "bleurt": 0.11216
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 24.5,
        "std_pred_length": 9.5,
        "median_pred_length": 24.5,
        "min_pred_length": 15,
        "max_pred_length": 34,
        "distinct-1": 0.7346938775510204,
        "vocab_size-1": 36,
        "unique-1": 34,
        "entropy-1": 4.592144204608388,
        "distinct-2": 1.0,
        "vocab_size-2": 47,
        "unique-2": 47,
        "entropy-2": 5.55458885167764,
        "cond_entropy-2": 1.005958078537625,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.06273575534796279,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9714285714285714,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.072140159802107,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": -0.02428283698045265,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.2,
            "3": 0.4090909090909091
        },
        "nist": 1.5278462381680873,
        "rouge1": {
            "precision": 0.34871,
            "recall": 0.37302,
            "fmeasure": 0.35563
        },
        "rouge2": {
            "precision": 0.11667,
            "recall": 0.14271,
            "fmeasure": 0.12548
        },
        "rougeL": {
            "precision": 0.27282,
            "recall": 0.32381,
            "fmeasure": 0.2898
        },
        "rougeLsum": {
            "precision": 0.27282,
            "recall": 0.32381,
            "fmeasure": 0.2898
        },
        "bleu": 5.00663,
        "meteor": 0.16194103632187296,
        "bertscore": {
            "precision": 0.75226,
            "recall": 0.8088,
            "f1": 0.77101
        },
        "nubia": {
            "semantic_relation": 2.82429,
            "contradiction": 4.86662,
            "irrelevancy": 94.80074,
            "logical_agreement": 0.33264,
            "grammar_ref": 5.71002,
            "grammar_hyp": 4.18076,
            "nubia_score": 0.36799
        },
        "bleurt": -0.23145
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.66667,
        "msttr-100_nopunct": 0.698,
        "total_length": 629,
        "mean_pred_length": 15.725,
        "std_pred_length": 4.939572349910466,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.4594594594594595,
        "vocab_size-1": 289,
        "unique-1": 239,
        "entropy-1": 6.95671833883197,
        "distinct-2": 0.767402376910017,
        "vocab_size-2": 452,
        "unique-2": 406,
        "entropy-2": 8.482931994509707,
        "cond_entropy-2": 1.3691518809238576,
        "distinct-3": 0.8579234972677595,
        "vocab_size-3": 471,
        "unique-3": 439,
        "entropy-3": 8.696148313441277,
        "cond_entropy-3": 0.2619734649658706,
        "total_length-nopunct": 547,
        "mean_pred_length-nopunct": 13.675,
        "std_pred_length-nopunct": 4.496595934704385,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5173674588665448,
        "vocab_size-1-nopunct": 283,
        "unique-1-nopunct": 238,
        "entropy-1-nopunct": 7.087613625214094,
        "distinct-2-nopunct": 0.7712031558185405,
        "vocab_size-2-nopunct": 391,
        "unique-2-nopunct": 352,
        "entropy-2-nopunct": 8.279541715177759,
        "cond_entropy-2-nopunct": 1.332948907935805,
        "distinct-3-nopunct": 0.867237687366167,
        "vocab_size-3-nopunct": 405,
        "unique-3-nopunct": 379,
        "entropy-3-nopunct": 8.490237626145253,
        "cond_entropy-3-nopunct": 0.26779879399172085,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26495726495726496,
            "2": 0.4461538461538462,
            "3": 0.7730496453900709
        },
        "nist": 6.7248346434199675,
        "rouge1": {
            "precision": 0.7605,
            "recall": 0.74486,
            "fmeasure": 0.74323
        },
        "rouge2": {
            "precision": 0.576,
            "recall": 0.55251,
            "fmeasure": 0.55527
        },
        "rougeL": {
            "precision": 0.68114,
            "recall": 0.67064,
            "fmeasure": 0.66645
        },
        "rougeLsum": {
            "precision": 0.68114,
            "recall": 0.67064,
            "fmeasure": 0.66645
        },
        "bleu": 51.28189,
        "meteor": 0.4020511795305516,
        "bertscore": {
            "precision": 0.92817,
            "recall": 0.93343,
            "f1": 0.92912
        },
        "nubia": {
            "semantic_relation": 4.21748,
            "contradiction": 4.01855,
            "irrelevancy": 34.49273,
            "logical_agreement": 61.48872,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.34854,
            "nubia_score": 0.75152
        },
        "bleurt": 0.31979
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.69067,
        "msttr-100_nopunct": 0.72692,
        "total_length": 1514,
        "mean_pred_length": 14.41904761904762,
        "std_pred_length": 6.117548454484894,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.404227212681638,
        "vocab_size-1": 612,
        "unique-1": 469,
        "entropy-1": 7.766941044637476,
        "distinct-2": 0.7629524485450674,
        "vocab_size-2": 1075,
        "unique-2": 953,
        "entropy-2": 9.731959018151672,
        "cond_entropy-2": 1.7184517645118351,
        "distinct-3": 0.8788343558282209,
        "vocab_size-3": 1146,
        "unique-3": 1071,
        "entropy-3": 10.022239755802477,
        "cond_entropy-3": 0.3105229206268306,
        "total_length-nopunct": 1307,
        "mean_pred_length-nopunct": 12.447619047619048,
        "std_pred_length-nopunct": 5.313022549997322,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4613618974751339,
        "vocab_size-1-nopunct": 603,
        "unique-1-nopunct": 466,
        "entropy-1-nopunct": 7.989325255129176,
        "distinct-2-nopunct": 0.781198003327787,
        "vocab_size-2-nopunct": 939,
        "unique-2-nopunct": 842,
        "entropy-2-nopunct": 9.553407477820778,
        "cond_entropy-2-nopunct": 1.69992704412956,
        "distinct-3-nopunct": 0.8896991795806746,
        "vocab_size-3-nopunct": 976,
        "unique-3-nopunct": 917,
        "entropy-3-nopunct": 9.803800787508369,
        "cond_entropy-3-nopunct": 0.295731369209507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2138728323699422,
            "2": 0.3993808049535604,
            "3": 0.6526881720430108
        },
        "nist": 6.277751366733083,
        "rouge1": {
            "precision": 0.6201,
            "recall": 0.58049,
            "fmeasure": 0.58364
        },
        "rouge2": {
            "precision": 0.39089,
            "recall": 0.37001,
            "fmeasure": 0.36901
        },
        "rougeL": {
            "precision": 0.52987,
            "recall": 0.49759,
            "fmeasure": 0.49858
        },
        "rougeLsum": {
            "precision": 0.52987,
            "recall": 0.49759,
            "fmeasure": 0.49858
        },
        "bleu": 35.88691,
        "meteor": 0.32375382999215424,
        "bertscore": {
            "precision": 0.88768,
            "recall": 0.88195,
            "f1": 0.88355
        },
        "nubia": {
            "semantic_relation": 3.43399,
            "contradiction": 21.90913,
            "irrelevancy": 30.08804,
            "logical_agreement": 48.00284,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.82701,
            "nubia_score": 0.58038
        },
        "bleurt": 0.06296
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72925,
        "msttr-100_nopunct": 0.762,
        "total_length": 6758,
        "mean_pred_length": 18.824512534818943,
        "std_pred_length": 5.890822920340777,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3709677419354839,
        "vocab_size-1": 2507,
        "unique-1": 1859,
        "entropy-1": 9.13529021808793,
        "distinct-2": 0.8223159868729489,
        "vocab_size-2": 5262,
        "unique-2": 4859,
        "entropy-2": 11.99041361863729,
        "cond_entropy-2": 2.7286039137986697,
        "distinct-3": 0.9548013245033112,
        "vocab_size-3": 5767,
        "unique-3": 5644,
        "entropy-3": 12.398848657134623,
        "cond_entropy-3": 0.4322075231108565,
        "total_length-nopunct": 6009,
        "mean_pred_length-nopunct": 16.738161559888578,
        "std_pred_length-nopunct": 5.312356748618713,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.41521051755699784,
        "vocab_size-1-nopunct": 2495,
        "unique-1-nopunct": 1857,
        "entropy-1-nopunct": 9.42737677718133,
        "distinct-2-nopunct": 0.8543362831858408,
        "vocab_size-2-nopunct": 4827,
        "unique-2-nopunct": 4488,
        "entropy-2-nopunct": 11.97557207338415,
        "cond_entropy-2-nopunct": 2.6784103275196585,
        "distinct-3-nopunct": 0.9775089775089775,
        "vocab_size-3-nopunct": 5172,
        "unique-3-nopunct": 5076,
        "entropy-3-nopunct": 12.320505242471597,
        "cond_entropy-3-nopunct": 0.36939251540770074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03362734288864388,
            "2": 0.1421832884097035,
            "3": 0.2963855421686747,
            "4": 0.5107033639143731,
            "5": 0.6191198786039454,
            "6": 0.6873239436619718,
            "7": 0.7199453551912568,
            "8": 0.7901085645355851,
            "9": 0.8306878306878307,
            "10": 0.9232558139534883
        },
        "nist": 12.655379487862204,
        "rouge1": {
            "precision": 0.85647,
            "recall": 0.83521,
            "fmeasure": 0.83391
        },
        "rouge2": {
            "precision": 0.75947,
            "recall": 0.7337,
            "fmeasure": 0.73247
        },
        "rougeL": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "rougeLsum": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "bleu": 79.81079,
        "meteor": 0.4813906927942626,
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.95853,
            "f1": 0.95294
        },
        "nubia": {
            "semantic_relation": 4.06468,
            "contradiction": 4.01064,
            "irrelevancy": 34.75851,
            "logical_agreement": 61.23085,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.80536,
            "nubia_score": 0.61895
        },
        "bleurt": 0.11216
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 382,
        "msttr-100": 0.51265,
        "msttr-100_nopunct": 0.51133,
        "total_length": 8321,
        "mean_pred_length": 21.782722513089006,
        "std_pred_length": 3.696951471083373,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.13580098545847855,
        "vocab_size-1": 1130,
        "unique-1": 414,
        "entropy-1": 7.980726305938743,
        "distinct-2": 0.3878322206827056,
        "vocab_size-2": 3079,
        "unique-2": 1817,
        "entropy-2": 10.743825903787569,
        "cond_entropy-2": 2.7275359497873297,
        "distinct-3": 0.5874024083631071,
        "vocab_size-3": 4439,
        "unique-3": 3204,
        "entropy-3": 11.661817274850675,
        "cond_entropy-3": 0.9800491986487099,
        "total_length-nopunct": 7565,
        "mean_pred_length-nopunct": 19.80366492146597,
        "std_pred_length-nopunct": 3.6561197599696733,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.14818241903502974,
        "vocab_size-1-nopunct": 1121,
        "unique-1-nopunct": 412,
        "entropy-1-nopunct": 8.142382809609797,
        "distinct-2-nopunct": 0.397883892524015,
        "vocab_size-2-nopunct": 2858,
        "unique-2-nopunct": 1748,
        "entropy-2-nopunct": 10.64498764835947,
        "cond_entropy-2-nopunct": 2.636612580111033,
        "distinct-3-nopunct": 0.5937362152624615,
        "vocab_size-3-nopunct": 4038,
        "unique-3-nopunct": 2957,
        "entropy-3-nopunct": 11.52382122267547,
        "cond_entropy-3-nopunct": 0.9365339333850913,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19398159661775677,
            "2": 0.5073784722222222,
            "3": 0.7851132686084142,
            "4": 0.5,
            "5": 0.42857142857142855
        },
        "nist": 7.597564519837038,
        "rouge1": {
            "precision": 0.75885,
            "recall": 0.68319,
            "fmeasure": 0.70965
        },
        "rouge2": {
            "precision": 0.48529,
            "recall": 0.42977,
            "fmeasure": 0.44893
        },
        "rougeL": {
            "precision": 0.60228,
            "recall": 0.53736,
            "fmeasure": 0.56045
        },
        "rougeLsum": {
            "precision": 0.60228,
            "recall": 0.53736,
            "fmeasure": 0.56045
        },
        "bleu": 40.96327,
        "meteor": 0.34103359400051997,
        "bertscore": {
            "precision": 0.91364,
            "recall": 0.89772,
            "f1": 0.90414
        },
        "nubia": {
            "semantic_relation": 4.14968,
            "contradiction": 8.28873,
            "irrelevancy": 10.22903,
            "logical_agreement": 81.48225,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.61006,
            "nubia_score": 0.6815
        },
        "bleurt": 0.02823
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 253,
        "msttr-100": 0.773,
        "msttr-100_nopunct": 0.88813,
        "total_length": 2093,
        "mean_pred_length": 8.272727272727273,
        "std_pred_length": 2.2318055029706754,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 15,
        "distinct-1": 0.45007166746297184,
        "vocab_size-1": 942,
        "unique-1": 677,
        "entropy-1": 8.470644392190541,
        "distinct-2": 0.7940217391304348,
        "vocab_size-2": 1461,
        "unique-2": 1233,
        "entropy-2": 10.316841070433714,
        "cond_entropy-2": 1.2358568873515312,
        "distinct-3": 0.9054820415879017,
        "vocab_size-3": 1437,
        "unique-3": 1318,
        "entropy-3": 10.42164453545051,
        "cond_entropy-3": 0.11248603035091505,
        "total_length-nopunct": 1693,
        "mean_pred_length-nopunct": 6.691699604743083,
        "std_pred_length-nopunct": 2.0526205839222564,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5534554046072061,
        "vocab_size-1-nopunct": 937,
        "unique-1-nopunct": 677,
        "entropy-1-nopunct": 9.171665447767165,
        "distinct-2-nopunct": 0.8118055555555556,
        "vocab_size-2-nopunct": 1169,
        "unique-2-nopunct": 1007,
        "entropy-2-nopunct": 10.003877510746475,
        "cond_entropy-2-nopunct": 0.9772992169879386,
        "distinct-3-nopunct": 0.9123841617523167,
        "vocab_size-3-nopunct": 1083,
        "unique-3-nopunct": 1002,
        "entropy-3-nopunct": 10.015473906732018,
        "cond_entropy-3-nopunct": 0.07527248711600569,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.378839590443686,
            "2": 0.6764295676429568,
            "3": 0.7474402730375427,
            "4": 0.7142857142857143,
            "5": 0.6363636363636364,
            "6": 0.9,
            "7": 1.0
        },
        "nist": 8.222100482851737,
        "rouge1": {
            "precision": 0.30362,
            "recall": 0.30392,
            "fmeasure": 0.30111
        },
        "rouge2": {
            "precision": 0.17922,
            "recall": 0.17589,
            "fmeasure": 0.17685
        },
        "rougeL": {
            "precision": 0.30362,
            "recall": 0.30392,
            "fmeasure": 0.30111
        },
        "rougeLsum": {
            "precision": 0.30362,
            "recall": 0.30392,
            "fmeasure": 0.30111
        },
        "bleu": 57.55937,
        "meteor": 0.7229425327964532,
        "bertscore": {
            "precision": 0.96809,
            "recall": 0.96394,
            "f1": 0.96558
        },
        "nubia": {
            "semantic_relation": 4.14953,
            "contradiction": 20.5602,
            "irrelevancy": 21.21096,
            "logical_agreement": 58.22884,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.92161,
            "nubia_score": 0.83169
        },
        "bleurt": 0.38281
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5
        },
        "nist": 2.2511488103250943,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "bleu": 31.55985,
        "meteor": 0.665058921087943,
        "bertscore": {
            "precision": 0.94193,
            "recall": 0.95635,
            "f1": 0.94909
        },
        "nubia": {
            "semantic_relation": 3.82438,
            "contradiction": 35.55774,
            "irrelevancy": 26.63605,
            "logical_agreement": 37.80622,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.81722,
            "nubia_score": 0.72206
        },
        "bleurt": 0.23243
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 77,
        "msttr-100": 0.71583,
        "msttr-100_nopunct": 0.766,
        "total_length": 1212,
        "mean_pred_length": 15.74025974025974,
        "std_pred_length": 5.051430548061177,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.48432343234323433,
        "vocab_size-1": 587,
        "unique-1": 460,
        "entropy-1": 7.9446949850356,
        "distinct-2": 0.8704845814977974,
        "vocab_size-2": 988,
        "unique-2": 907,
        "entropy-2": 9.805198889857438,
        "cond_entropy-2": 1.6295948367840338,
        "distinct-3": 0.9489603024574669,
        "vocab_size-3": 1004,
        "unique-3": 968,
        "entropy-3": 9.928576484890325,
        "cond_entropy-3": 0.12803034295776694,
        "total_length-nopunct": 1062,
        "mean_pred_length-nopunct": 13.792207792207792,
        "std_pred_length-nopunct": 4.827781244943705,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5433145009416196,
        "vocab_size-1-nopunct": 577,
        "unique-1-nopunct": 457,
        "entropy-1-nopunct": 8.15258300958169,
        "distinct-2-nopunct": 0.8791878172588833,
        "vocab_size-2-nopunct": 866,
        "unique-2-nopunct": 801,
        "entropy-2-nopunct": 9.617999350109242,
        "cond_entropy-2-nopunct": 1.5732725094453923,
        "distinct-3-nopunct": 0.9559471365638766,
        "vocab_size-3-nopunct": 868,
        "unique-3-nopunct": 840,
        "entropy-3-nopunct": 9.726985020337285,
        "cond_entropy-3-nopunct": 0.1272122744801175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2178988326848249,
            "2": 0.437984496124031,
            "3": 0.7802340702210663
        },
        "nist": 7.33209384424891,
        "rouge1": {
            "precision": 0.78159,
            "recall": 0.72406,
            "fmeasure": 0.74173
        },
        "rouge2": {
            "precision": 0.55099,
            "recall": 0.51187,
            "fmeasure": 0.52372
        },
        "rougeL": {
            "precision": 0.6841,
            "recall": 0.63578,
            "fmeasure": 0.6503
        },
        "rougeLsum": {
            "precision": 0.6841,
            "recall": 0.63578,
            "fmeasure": 0.6503
        },
        "bleu": 48.78982,
        "meteor": 0.4045811114086093,
        "bertscore": {
            "precision": 0.93243,
            "recall": 0.92469,
            "f1": 0.92727
        },
        "nubia": {
            "semantic_relation": 4.19488,
            "contradiction": 9.0414,
            "irrelevancy": 25.27994,
            "logical_agreement": 65.67867,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.69792,
            "nubia_score": 0.72713
        },
        "bleurt": 0.25366
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 494,
        "msttr-100": 0.77483,
        "msttr-100_nopunct": 0.84137,
        "total_length": 6071,
        "mean_pred_length": 12.289473684210526,
        "std_pred_length": 2.6062853268153634,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.2717838906275737,
        "vocab_size-1": 1650,
        "unique-1": 948,
        "entropy-1": 8.851765695115905,
        "distinct-2": 0.5926125156894387,
        "vocab_size-2": 3305,
        "unique-2": 2402,
        "entropy-2": 11.201933940584674,
        "cond_entropy-2": 2.488256956462517,
        "distinct-3": 0.786740114105843,
        "vocab_size-3": 3999,
        "unique-3": 3356,
        "entropy-3": 11.780810862714642,
        "cond_entropy-3": 0.6646546081339922,
        "total_length-nopunct": 5184,
        "mean_pred_length-nopunct": 10.493927125506072,
        "std_pred_length-nopunct": 2.1414937564371623,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3167438271604938,
        "vocab_size-1-nopunct": 1642,
        "unique-1-nopunct": 947,
        "entropy-1-nopunct": 9.316229789114189,
        "distinct-2-nopunct": 0.6464818763326226,
        "vocab_size-2-nopunct": 3032,
        "unique-2-nopunct": 2341,
        "entropy-2-nopunct": 11.14617112985399,
        "cond_entropy-2-nopunct": 2.016650039746624,
        "distinct-3-nopunct": 0.8217349857006673,
        "vocab_size-3-nopunct": 3448,
        "unique-3-nopunct": 3001,
        "entropy-3-nopunct": 11.58795152264354,
        "cond_entropy-3-nopunct": 0.5346086251196428,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.14259977827050999,
            "2": 0.3284543325526932,
            "3": 0.5164388622090875,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 1.5611225480992619,
        "rouge1": {
            "precision": 0.25092,
            "recall": 0.19209,
            "fmeasure": 0.20837
        },
        "rouge2": {
            "precision": 0.10392,
            "recall": 0.07509,
            "fmeasure": 0.0843
        },
        "rougeL": {
            "precision": 0.24191,
            "recall": 0.18499,
            "fmeasure": 0.20042
        },
        "rougeLsum": {
            "precision": 0.24191,
            "recall": 0.18499,
            "fmeasure": 0.20042
        },
        "bleu": 19.66405,
        "meteor": 0.3673536170407919,
        "bertscore": {
            "precision": 0.94382,
            "recall": 0.90295,
            "f1": 0.92202
        },
        "nubia": {
            "semantic_relation": 3.46165,
            "contradiction": 22.38845,
            "irrelevancy": 23.23,
            "logical_agreement": 54.38155,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.68616,
            "nubia_score": 0.66373
        },
        "bleurt": 0.0073
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "total_length": 111,
        "mean_pred_length": 15.857142857142858,
        "std_pred_length": 6.9370345955308474,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.6756756756756757,
        "vocab_size-1": 75,
        "unique-1": 60,
        "entropy-1": 5.858467078855243,
        "distinct-2": 0.9519230769230769,
        "vocab_size-2": 99,
        "unique-2": 95,
        "entropy-2": 6.597027338312605,
        "cond_entropy-2": 0.6395940284969627,
        "distinct-3": 0.9896907216494846,
        "vocab_size-3": 96,
        "unique-3": 95,
        "entropy-3": 6.579294285486111,
        "cond_entropy-3": -0.010270303766712187,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 14.142857142857142,
        "std_pred_length-nopunct": 6.663945022680343,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.846690524570888,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.428400135381337,
        "cond_entropy-2-nopunct": 0.6303907267730617,
        "distinct-3-nopunct": 0.9882352941176471,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.385861524373001,
        "cond_entropy-3-nopunct": -0.04646646107032911,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.5172413793103449,
            "3": 0.711864406779661
        },
        "nist": 4.305751170422976,
        "rouge1": {
            "precision": 0.73643,
            "recall": 0.74479,
            "fmeasure": 0.73308
        },
        "rouge2": {
            "precision": 0.53866,
            "recall": 0.54355,
            "fmeasure": 0.53695
        },
        "rougeL": {
            "precision": 0.68762,
            "recall": 0.69802,
            "fmeasure": 0.68696
        },
        "rougeLsum": {
            "precision": 0.68762,
            "recall": 0.69802,
            "fmeasure": 0.68696
        },
        "bleu": 39.08621,
        "meteor": 0.32069214887720604,
        "bertscore": {
            "precision": 0.91355,
            "recall": 0.9169,
            "f1": 0.91402
        },
        "nubia": {
            "semantic_relation": 4.13497,
            "contradiction": 21.99685,
            "irrelevancy": 29.44651,
            "logical_agreement": 48.55664,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.1875,
            "nubia_score": 0.73425
        },
        "bleurt": 0.2381
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72925,
        "msttr-100_nopunct": 0.762,
        "total_length": 6758,
        "mean_pred_length": 18.824512534818943,
        "std_pred_length": 5.890822920340777,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3709677419354839,
        "vocab_size-1": 2507,
        "unique-1": 1859,
        "entropy-1": 9.13529021808793,
        "distinct-2": 0.8223159868729489,
        "vocab_size-2": 5262,
        "unique-2": 4859,
        "entropy-2": 11.99041361863729,
        "cond_entropy-2": 2.7286039137986697,
        "distinct-3": 0.9548013245033112,
        "vocab_size-3": 5767,
        "unique-3": 5644,
        "entropy-3": 12.398848657134623,
        "cond_entropy-3": 0.4322075231108565,
        "total_length-nopunct": 6009,
        "mean_pred_length-nopunct": 16.738161559888578,
        "std_pred_length-nopunct": 5.312356748618713,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.41521051755699784,
        "vocab_size-1-nopunct": 2495,
        "unique-1-nopunct": 1857,
        "entropy-1-nopunct": 9.42737677718133,
        "distinct-2-nopunct": 0.8543362831858408,
        "vocab_size-2-nopunct": 4827,
        "unique-2-nopunct": 4488,
        "entropy-2-nopunct": 11.97557207338415,
        "cond_entropy-2-nopunct": 2.6784103275196585,
        "distinct-3-nopunct": 0.9775089775089775,
        "vocab_size-3-nopunct": 5172,
        "unique-3-nopunct": 5076,
        "entropy-3-nopunct": 12.320505242471597,
        "cond_entropy-3-nopunct": 0.36939251540770074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03362734288864388,
            "2": 0.1421832884097035,
            "3": 0.2963855421686747,
            "4": 0.5107033639143731,
            "5": 0.6191198786039454,
            "6": 0.6873239436619718,
            "7": 0.7199453551912568,
            "8": 0.7901085645355851,
            "9": 0.8306878306878307,
            "10": 0.9232558139534883
        },
        "nist": 12.655379487862204,
        "rouge1": {
            "precision": 0.85647,
            "recall": 0.83521,
            "fmeasure": 0.83391
        },
        "rouge2": {
            "precision": 0.75947,
            "recall": 0.7337,
            "fmeasure": 0.73247
        },
        "rougeL": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "rougeLsum": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "bleu": 79.81079,
        "meteor": 0.4813906927942626,
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.95853,
            "f1": 0.95294
        },
        "nubia": {
            "semantic_relation": 4.06468,
            "contradiction": 4.01064,
            "irrelevancy": 34.75851,
            "logical_agreement": 61.23085,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.80536,
            "nubia_score": 0.61895
        },
        "bleurt": 0.11216
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 297,
        "msttr-100": 0.62083,
        "msttr-100_nopunct": 0.65065,
        "total_length": 3650,
        "mean_pred_length": 12.289562289562289,
        "std_pred_length": 3.8791064450175345,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.10849315068493151,
        "vocab_size-1": 396,
        "unique-1": 157,
        "entropy-1": 6.879131580376927,
        "distinct-2": 0.3068893528183716,
        "vocab_size-2": 1029,
        "unique-2": 568,
        "entropy-2": 8.895487361915636,
        "cond_entropy-2": 1.7335210931053198,
        "distinct-3": 0.4656413612565445,
        "vocab_size-3": 1423,
        "unique-3": 975,
        "entropy-3": 9.502409422044664,
        "cond_entropy-3": 0.6030300634797491,
        "total_length-nopunct": 3185,
        "mean_pred_length-nopunct": 10.723905723905723,
        "std_pred_length-nopunct": 3.513974156841567,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.12307692307692308,
        "vocab_size-1-nopunct": 392,
        "unique-1-nopunct": 156,
        "entropy-1-nopunct": 7.097056560627092,
        "distinct-2-nopunct": 0.3192520775623269,
        "vocab_size-2-nopunct": 922,
        "unique-2-nopunct": 516,
        "entropy-2-nopunct": 8.75571096698441,
        "cond_entropy-2-nopunct": 1.7491759252576506,
        "distinct-3-nopunct": 0.4851408722500965,
        "vocab_size-3-nopunct": 1257,
        "unique-3-nopunct": 884,
        "entropy-3-nopunct": 9.313980472265055,
        "cond_entropy-3-nopunct": 0.6336279206837048,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.46354733405875953
        },
        "nist": 3.39320643071496,
        "rouge1": {
            "precision": 0.48346,
            "recall": 0.51731,
            "fmeasure": 0.48452
        },
        "rouge2": {
            "precision": 0.25858,
            "recall": 0.28063,
            "fmeasure": 0.26104
        },
        "rougeL": {
            "precision": 0.42092,
            "recall": 0.45056,
            "fmeasure": 0.42263
        },
        "rougeLsum": {
            "precision": 0.42092,
            "recall": 0.45056,
            "fmeasure": 0.42263
        },
        "bleu": 14.99094,
        "meteor": 0.23230287338959812,
        "bertscore": {
            "precision": 0.89229,
            "recall": 0.89549,
            "f1": 0.89364
        },
        "nubia": {
            "semantic_relation": 3.44841,
            "contradiction": 16.41044,
            "irrelevancy": 38.86858,
            "logical_agreement": 44.72098,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.55826,
            "nubia_score": 0.51456
        },
        "bleurt": -0.17836
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 251,
        "msttr-100": 0.51034,
        "msttr-100_nopunct": 0.51208,
        "total_length": 5851,
        "mean_pred_length": 23.310756972111555,
        "std_pred_length": 3.148237321387017,
        "median_pred_length": 24.0,
        "min_pred_length": 14,
        "max_pred_length": 31,
        "distinct-1": 0.1560417022731157,
        "vocab_size-1": 913,
        "unique-1": 324,
        "entropy-1": 7.880908301670575,
        "distinct-2": 0.4014285714285714,
        "vocab_size-2": 2248,
        "unique-2": 1300,
        "entropy-2": 10.3791971169604,
        "cond_entropy-2": 2.5315148830765537,
        "distinct-3": 0.5819779398018321,
        "vocab_size-3": 3113,
        "unique-3": 2197,
        "entropy-3": 11.169804444848245,
        "cond_entropy-3": 0.850716580367305,
        "total_length-nopunct": 5384,
        "mean_pred_length-nopunct": 21.45019920318725,
        "std_pred_length-nopunct": 3.294403977941965,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.16827637444279347,
        "vocab_size-1-nopunct": 906,
        "unique-1-nopunct": 322,
        "entropy-1-nopunct": 7.993612491897662,
        "distinct-2-nopunct": 0.4145723748295344,
        "vocab_size-2-nopunct": 2128,
        "unique-2-nopunct": 1264,
        "entropy-2-nopunct": 10.335530700795703,
        "cond_entropy-2-nopunct": 2.4471087506169216,
        "distinct-3-nopunct": 0.5927898402294142,
        "vocab_size-3-nopunct": 2894,
        "unique-3-nopunct": 2073,
        "entropy-3-nopunct": 11.08208994935954,
        "cond_entropy-3-nopunct": 0.8090899381714047,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.16542328900421668,
            "2": 0.4767772511848341,
            "3": 0.6912429378531073
        },
        "nist": 4.731786920678531,
        "rouge1": {
            "precision": 0.76424,
            "recall": 0.58156,
            "fmeasure": 0.64455
        },
        "rouge2": {
            "precision": 0.48692,
            "recall": 0.3594,
            "fmeasure": 0.40221
        },
        "rougeL": {
            "precision": 0.59793,
            "recall": 0.44928,
            "fmeasure": 0.50014
        },
        "rougeLsum": {
            "precision": 0.59793,
            "recall": 0.44928,
            "fmeasure": 0.50014
        },
        "bleu": 32.95494,
        "meteor": 0.2862499427918558,
        "bertscore": {
            "precision": 0.90569,
            "recall": 0.86596,
            "f1": 0.88363
        },
        "nubia": {
            "semantic_relation": 3.6686,
            "contradiction": 9.08138,
            "irrelevancy": 13.59729,
            "logical_agreement": 77.32133,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.59768,
            "nubia_score": 0.52109
        },
        "bleurt": -0.18381
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 162,
        "msttr-100": 0.70783,
        "msttr-100_nopunct": 0.761,
        "total_length": 2387,
        "mean_pred_length": 14.734567901234568,
        "std_pred_length": 5.031742709025758,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.3489736070381232,
        "vocab_size-1": 833,
        "unique-1": 615,
        "entropy-1": 7.994696814776126,
        "distinct-2": 0.7069662921348314,
        "vocab_size-2": 1573,
        "unique-2": 1329,
        "entropy-2": 10.193686965408874,
        "cond_entropy-2": 1.9238842631121877,
        "distinct-3": 0.8739699466795928,
        "vocab_size-3": 1803,
        "unique-3": 1671,
        "entropy-3": 10.660300339951739,
        "cond_entropy-3": 0.47280148154653084,
        "total_length-nopunct": 2077,
        "mean_pred_length-nopunct": 12.820987654320987,
        "std_pred_length-nopunct": 4.4775218027023325,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.39768897448242657,
        "vocab_size-1-nopunct": 826,
        "unique-1-nopunct": 614,
        "entropy-1-nopunct": 8.309602462462198,
        "distinct-2-nopunct": 0.7310704960835509,
        "vocab_size-2-nopunct": 1400,
        "unique-2-nopunct": 1207,
        "entropy-2-nopunct": 10.035432690315556,
        "cond_entropy-2-nopunct": 1.837982384230885,
        "distinct-3-nopunct": 0.8853394181403309,
        "vocab_size-3-nopunct": 1552,
        "unique-3-nopunct": 1454,
        "entropy-3-nopunct": 10.454705615755595,
        "cond_entropy-3-nopunct": 0.4606405537682393,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18654434250764526,
            "2": 0.3755656108597285,
            "3": 0.7622377622377622
        },
        "nist": 7.541105097432928,
        "rouge1": {
            "precision": 0.7232,
            "recall": 0.71543,
            "fmeasure": 0.70904
        },
        "rouge2": {
            "precision": 0.48084,
            "recall": 0.47271,
            "fmeasure": 0.46901
        },
        "rougeL": {
            "precision": 0.60835,
            "recall": 0.60052,
            "fmeasure": 0.59487
        },
        "rougeLsum": {
            "precision": 0.60835,
            "recall": 0.60052,
            "fmeasure": 0.59487
        },
        "bleu": 41.84611,
        "meteor": 0.3868937087866591,
        "bertscore": {
            "precision": 0.92763,
            "recall": 0.92643,
            "f1": 0.92475
        },
        "nubia": {
            "semantic_relation": 4.0653,
            "contradiction": 24.20652,
            "irrelevancy": 25.78899,
            "logical_agreement": 50.00448,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.49213,
            "nubia_score": 0.69993
        },
        "bleurt": 0.28687
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 86,
        "msttr-100": 0.62538,
        "msttr-100_nopunct": 0.66455,
        "total_length": 1320,
        "mean_pred_length": 15.348837209302326,
        "std_pred_length": 4.128087123484749,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.23106060606060605,
        "vocab_size-1": 305,
        "unique-1": 153,
        "entropy-1": 6.902748375426117,
        "distinct-2": 0.5372771474878444,
        "vocab_size-2": 663,
        "unique-2": 464,
        "entropy-2": 8.80427313078794,
        "cond_entropy-2": 1.7314307919345855,
        "distinct-3": 0.7020905923344948,
        "vocab_size-3": 806,
        "unique-3": 639,
        "entropy-3": 9.320914109321564,
        "cond_entropy-3": 0.47142830942614394,
        "total_length-nopunct": 1176,
        "mean_pred_length-nopunct": 13.674418604651162,
        "std_pred_length-nopunct": 3.7678007293908276,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.2568027210884354,
        "vocab_size-1-nopunct": 302,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 7.064675709778863,
        "distinct-2-nopunct": 0.5651376146788991,
        "vocab_size-2-nopunct": 616,
        "unique-2-nopunct": 439,
        "entropy-2-nopunct": 8.752984330970731,
        "cond_entropy-2-nopunct": 1.7314815643346857,
        "distinct-3-nopunct": 0.7330677290836654,
        "vocab_size-3-nopunct": 736,
        "unique-3-nopunct": 595,
        "entropy-3-nopunct": 9.240480276550837,
        "cond_entropy-3-nopunct": 0.470820481078335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.47756653992395437
        },
        "nist": 3.9867471467780438,
        "rouge1": {
            "precision": 0.60235,
            "recall": 0.51827,
            "fmeasure": 0.54923
        },
        "rouge2": {
            "precision": 0.32258,
            "recall": 0.27918,
            "fmeasure": 0.29497
        },
        "rougeL": {
            "precision": 0.50131,
            "recall": 0.42891,
            "fmeasure": 0.45578
        },
        "rougeLsum": {
            "precision": 0.50131,
            "recall": 0.42891,
            "fmeasure": 0.45578
        },
        "bleu": 17.49292,
        "meteor": 0.2366207272572176,
        "bertscore": {
            "precision": 0.919,
            "recall": 0.90792,
            "f1": 0.91331
        },
        "nubia": {
            "semantic_relation": 3.27251,
            "contradiction": 18.26276,
            "irrelevancy": 22.36817,
            "logical_agreement": 59.36907,
            "grammar_ref": 6.22337,
            "grammar_hyp": 6.30265,
            "nubia_score": 0.50339
        },
        "bleurt": -0.07459
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72925,
        "msttr-100_nopunct": 0.762,
        "total_length": 6758,
        "mean_pred_length": 18.824512534818943,
        "std_pred_length": 5.890822920340777,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3709677419354839,
        "vocab_size-1": 2507,
        "unique-1": 1859,
        "entropy-1": 9.13529021808793,
        "distinct-2": 0.8223159868729489,
        "vocab_size-2": 5262,
        "unique-2": 4859,
        "entropy-2": 11.99041361863729,
        "cond_entropy-2": 2.7286039137986697,
        "distinct-3": 0.9548013245033112,
        "vocab_size-3": 5767,
        "unique-3": 5644,
        "entropy-3": 12.398848657134623,
        "cond_entropy-3": 0.4322075231108565,
        "total_length-nopunct": 6009,
        "mean_pred_length-nopunct": 16.738161559888578,
        "std_pred_length-nopunct": 5.312356748618713,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.41521051755699784,
        "vocab_size-1-nopunct": 2495,
        "unique-1-nopunct": 1857,
        "entropy-1-nopunct": 9.42737677718133,
        "distinct-2-nopunct": 0.8543362831858408,
        "vocab_size-2-nopunct": 4827,
        "unique-2-nopunct": 4488,
        "entropy-2-nopunct": 11.97557207338415,
        "cond_entropy-2-nopunct": 2.6784103275196585,
        "distinct-3-nopunct": 0.9775089775089775,
        "vocab_size-3-nopunct": 5172,
        "unique-3-nopunct": 5076,
        "entropy-3-nopunct": 12.320505242471597,
        "cond_entropy-3-nopunct": 0.36939251540770074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03362734288864388,
            "2": 0.1421832884097035,
            "3": 0.2963855421686747,
            "4": 0.5107033639143731,
            "5": 0.6191198786039454,
            "6": 0.6873239436619718,
            "7": 0.7199453551912568,
            "8": 0.7901085645355851,
            "9": 0.8306878306878307,
            "10": 0.9232558139534883
        },
        "nist": 12.655379487862204,
        "rouge1": {
            "precision": 0.85647,
            "recall": 0.83521,
            "fmeasure": 0.83391
        },
        "rouge2": {
            "precision": 0.75947,
            "recall": 0.7337,
            "fmeasure": 0.73247
        },
        "rougeL": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "rougeLsum": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "bleu": 79.81079,
        "meteor": 0.4813906927942626,
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.95853,
            "f1": 0.95294
        },
        "nubia": {
            "semantic_relation": 4.06468,
            "contradiction": 4.01064,
            "irrelevancy": 34.75851,
            "logical_agreement": 61.23085,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.80536,
            "nubia_score": 0.61895
        },
        "bleurt": 0.11216
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 986,
        "msttr-100": 0.67486,
        "msttr-100_nopunct": 0.71656,
        "total_length": 10978,
        "mean_pred_length": 11.133874239350913,
        "std_pred_length": 2.93822962116637,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.219074512661687,
        "vocab_size-1": 2405,
        "unique-1": 1271,
        "entropy-1": 9.118866981819318,
        "distinct-2": 0.5171136909527622,
        "vocab_size-2": 5167,
        "unique-2": 3603,
        "entropy-2": 11.669464756075401,
        "cond_entropy-2": 2.595135068407403,
        "distinct-3": 0.7138574283810792,
        "vocab_size-3": 6429,
        "unique-3": 5209,
        "entropy-3": 12.350678461825323,
        "cond_entropy-3": 0.791620905623652,
        "total_length-nopunct": 9313,
        "mean_pred_length-nopunct": 9.44523326572008,
        "std_pred_length-nopunct": 2.5926136687216386,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.2573821539783099,
        "vocab_size-1-nopunct": 2397,
        "unique-1-nopunct": 1270,
        "entropy-1-nopunct": 9.658185605479153,
        "distinct-2-nopunct": 0.5646691485529002,
        "vocab_size-2-nopunct": 4702,
        "unique-2-nopunct": 3454,
        "entropy-2-nopunct": 11.603410580586736,
        "cond_entropy-2-nopunct": 2.1691955589363117,
        "distinct-3-nopunct": 0.7462198610543522,
        "vocab_size-3-nopunct": 5478,
        "unique-3-nopunct": 4585,
        "entropy-3-nopunct": 12.1397243582338,
        "cond_entropy-3-nopunct": 0.6638081672841405,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16371066612178178,
            "2": 0.3494313756036766,
            "3": 0.4774166314900802,
            "4": 0.6363636363636364,
            "5": 0.6216216216216216,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "nist": 1.6689346465193315,
        "rouge1": {
            "precision": 0.30685,
            "recall": 0.25081,
            "fmeasure": 0.26542
        },
        "rouge2": {
            "precision": 0.14317,
            "recall": 0.11462,
            "fmeasure": 0.12235
        },
        "rougeL": {
            "precision": 0.30014,
            "recall": 0.24516,
            "fmeasure": 0.25934
        },
        "rougeLsum": {
            "precision": 0.30014,
            "recall": 0.24516,
            "fmeasure": 0.25934
        },
        "bleu": 21.62652,
        "meteor": 0.3951403165839423,
        "bertscore": {
            "precision": 0.94998,
            "recall": 0.91384,
            "f1": 0.93067
        },
        "nubia": {
            "semantic_relation": 3.59372,
            "contradiction": 22.004,
            "irrelevancy": 22.7795,
            "logical_agreement": 55.2165,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.74266,
            "nubia_score": 0.6963
        },
        "bleurt": 0.10059
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 9,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.68,
        "total_length": 148,
        "mean_pred_length": 16.444444444444443,
        "std_pred_length": 3.6851386559504444,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.5337837837837838,
        "vocab_size-1": 79,
        "unique-1": 52,
        "entropy-1": 5.876536815395664,
        "distinct-2": 0.7769784172661871,
        "vocab_size-2": 108,
        "unique-2": 87,
        "entropy-2": 6.615062655332817,
        "cond_entropy-2": 0.6521679187292233,
        "distinct-3": 0.8384615384615385,
        "vocab_size-3": 109,
        "unique-3": 93,
        "entropy-3": 6.670256755252938,
        "cond_entropy-3": 0.05930875958564257,
        "total_length-nopunct": 131,
        "mean_pred_length-nopunct": 14.555555555555555,
        "std_pred_length-nopunct": 3.337034981706935,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.5877862595419847,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.928519761678326,
        "distinct-2-nopunct": 0.7786885245901639,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.428407726783028,
        "cond_entropy-2-nopunct": 0.5294312368739315,
        "distinct-3-nopunct": 0.8495575221238938,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.492572325170481,
        "cond_entropy-3-nopunct": 0.0480682841762465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4074074074074074
        },
        "nist": 2.593720070812498,
        "rouge1": {
            "precision": 0.52718,
            "recall": 0.46235,
            "fmeasure": 0.47965
        },
        "rouge2": {
            "precision": 0.2403,
            "recall": 0.2164,
            "fmeasure": 0.2218
        },
        "rougeL": {
            "precision": 0.40661,
            "recall": 0.34547,
            "fmeasure": 0.36429
        },
        "rougeLsum": {
            "precision": 0.40661,
            "recall": 0.34547,
            "fmeasure": 0.36429
        },
        "bleu": 9.11687,
        "meteor": 0.18800363911541035,
        "bertscore": {
            "precision": 0.90317,
            "recall": 0.89407,
            "f1": 0.89836
        },
        "nubia": {
            "semantic_relation": 3.1773,
            "contradiction": 23.30961,
            "irrelevancy": 23.21563,
            "logical_agreement": 53.47475,
            "grammar_ref": 6.01604,
            "grammar_hyp": 6.24923,
            "nubia_score": 0.46223
        },
        "bleurt": -0.15912
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73266,
        "msttr-100_nopunct": 0.76982,
        "total_length": 6472,
        "mean_pred_length": 18.027855153203344,
        "std_pred_length": 6.155306936102102,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.35939431396786153,
        "vocab_size-1": 2326,
        "unique-1": 1694,
        "entropy-1": 9.041400391999355,
        "distinct-2": 0.8194012759692458,
        "vocab_size-2": 5009,
        "unique-2": 4631,
        "entropy-2": 11.908622435405071,
        "cond_entropy-2": 2.6994473115553896,
        "distinct-3": 0.9494264859228363,
        "vocab_size-3": 5463,
        "unique-3": 5351,
        "entropy-3": 12.300521906911825,
        "cond_entropy-3": 0.41462919015205124,
        "total_length-nopunct": 5756,
        "mean_pred_length-nopunct": 16.03342618384401,
        "std_pred_length-nopunct": 5.604315608736071,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.40218902015288394,
        "vocab_size-1-nopunct": 2315,
        "unique-1-nopunct": 1693,
        "entropy-1-nopunct": 9.3388958536926,
        "distinct-2-nopunct": 0.8530665184361682,
        "vocab_size-2-nopunct": 4604,
        "unique-2-nopunct": 4283,
        "entropy-2-nopunct": 11.908064888858732,
        "cond_entropy-2-nopunct": 2.7008409707095486,
        "distinct-3-nopunct": 0.9753870583564906,
        "vocab_size-3-nopunct": 4914,
        "unique-3-nopunct": 4827,
        "entropy-3-nopunct": 12.241499115043315,
        "cond_entropy-3-nopunct": 0.3566665332014031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04711375212224109,
            "2": 0.16219667943805874,
            "3": 0.3347921225382932,
            "4": 0.4358161648177496,
            "5": 0.5160955347871236,
            "6": 0.6473429951690821,
            "7": 0.8010691103474609
        },
        "nist": 9.429216404028697,
        "rouge1": {
            "precision": 0.80752,
            "recall": 0.72406,
            "fmeasure": 0.74722
        },
        "rouge2": {
            "precision": 0.65389,
            "recall": 0.58506,
            "fmeasure": 0.6021
        },
        "rougeL": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "rougeLsum": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "bleu": 59.46369,
        "meteor": 0.39878954357926183,
        "bertscore": {
            "precision": 0.93904,
            "recall": 0.92612,
            "f1": 0.92923
        },
        "nubia": {
            "semantic_relation": 4.02391,
            "contradiction": 5.62065,
            "irrelevancy": 22.17407,
            "logical_agreement": 72.20528,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.96242,
            "nubia_score": 0.61717
        },
        "bleurt": 0.04008
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 609,
        "msttr-100": 0.59164,
        "msttr-100_nopunct": 0.62547,
        "total_length": 7351,
        "mean_pred_length": 12.070607553366173,
        "std_pred_length": 3.9140947518062204,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.08774316419534757,
        "vocab_size-1": 645,
        "unique-1": 226,
        "entropy-1": 6.9975485674490425,
        "distinct-2": 0.27350934440818747,
        "vocab_size-2": 1844,
        "unique-2": 1012,
        "entropy-2": 9.422635087747945,
        "cond_entropy-2": 2.1428266972932857,
        "distinct-3": 0.43746942768628727,
        "vocab_size-3": 2683,
        "unique-3": 1878,
        "entropy-3": 10.292418843025752,
        "cond_entropy-3": 0.957014078268773,
        "total_length-nopunct": 6455,
        "mean_pred_length-nopunct": 10.599343185550081,
        "std_pred_length-nopunct": 3.5779473565390205,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.09930286599535244,
        "vocab_size-1-nopunct": 641,
        "unique-1-nopunct": 225,
        "entropy-1-nopunct": 7.224120025724397,
        "distinct-2-nopunct": 0.2786520697913103,
        "vocab_size-2-nopunct": 1629,
        "unique-2-nopunct": 937,
        "entropy-2-nopunct": 9.20692095107576,
        "cond_entropy-2-nopunct": 2.2097080505236577,
        "distinct-3-nopunct": 0.44701164789001335,
        "vocab_size-3-nopunct": 2341,
        "unique-3-nopunct": 1675,
        "entropy-3-nopunct": 10.084406639377118,
        "cond_entropy-3-nopunct": 1.0346546426766892,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.514823362329132
        },
        "nist": 3.9475167263634803,
        "rouge1": {
            "precision": 0.50536,
            "recall": 0.5649,
            "fmeasure": 0.51553
        },
        "rouge2": {
            "precision": 0.26807,
            "recall": 0.30557,
            "fmeasure": 0.27514
        },
        "rougeL": {
            "precision": 0.44137,
            "recall": 0.49335,
            "fmeasure": 0.45065
        },
        "rougeLsum": {
            "precision": 0.44137,
            "recall": 0.49335,
            "fmeasure": 0.45065
        },
        "bleu": 16.59075,
        "meteor": 0.25412536889032666,
        "bertscore": {
            "precision": 0.89491,
            "recall": 0.90351,
            "f1": 0.89889
        },
        "nubia": {
            "semantic_relation": 3.50955,
            "contradiction": 15.85618,
            "irrelevancy": 36.89947,
            "logical_agreement": 47.24434,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.68204,
            "nubia_score": 0.53913
        },
        "bleurt": -0.13427
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.61833,
        "msttr-100_nopunct": 0.646,
        "total_length": 638,
        "mean_pred_length": 17.72222222222222,
        "std_pred_length": 6.021309893993679,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.4090909090909091,
        "vocab_size-1": 261,
        "unique-1": 212,
        "entropy-1": 6.822793097952401,
        "distinct-2": 0.7159468438538206,
        "vocab_size-2": 431,
        "unique-2": 380,
        "entropy-2": 8.367058012472242,
        "cond_entropy-2": 1.4361010261201113,
        "distinct-3": 0.8392226148409894,
        "vocab_size-3": 475,
        "unique-3": 436,
        "entropy-3": 8.710416845616596,
        "cond_entropy-3": 0.347028098931582,
        "total_length-nopunct": 546,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 5.382585087318381,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.46703296703296704,
        "vocab_size-1-nopunct": 255,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 6.8985761236882945,
        "distinct-2-nopunct": 0.7450980392156863,
        "vocab_size-2-nopunct": 380,
        "unique-2-nopunct": 338,
        "entropy-2-nopunct": 8.238308692718473,
        "cond_entropy-2-nopunct": 1.4147341173021877,
        "distinct-3-nopunct": 0.8354430379746836,
        "vocab_size-3-nopunct": 396,
        "unique-3-nopunct": 363,
        "entropy-3-nopunct": 8.442507028819367,
        "cond_entropy-3-nopunct": 0.2595097512676308,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5377358490566038,
            "3": 0.7741935483870968
        },
        "nist": 6.446315221658988,
        "rouge1": {
            "precision": 0.74336,
            "recall": 0.75956,
            "fmeasure": 0.74073
        },
        "rouge2": {
            "precision": 0.54424,
            "recall": 0.56393,
            "fmeasure": 0.54575
        },
        "rougeL": {
            "precision": 0.6623,
            "recall": 0.68923,
            "fmeasure": 0.66557
        },
        "rougeLsum": {
            "precision": 0.6623,
            "recall": 0.68923,
            "fmeasure": 0.66557
        },
        "bleu": 47.44595,
        "meteor": 0.4148451838201382,
        "bertscore": {
            "precision": 0.93212,
            "recall": 0.93658,
            "f1": 0.93285
        },
        "nubia": {
            "semantic_relation": 3.93181,
            "contradiction": 8.02526,
            "irrelevancy": 40.83739,
            "logical_agreement": 51.13735,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.74413,
            "nubia_score": 0.70259
        },
        "bleurt": 0.34344
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 354,
        "msttr-100": 0.75929,
        "msttr-100_nopunct": 0.81757,
        "total_length": 4265,
        "mean_pred_length": 12.048022598870057,
        "std_pred_length": 2.273765646274602,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 18,
        "distinct-1": 0.2846424384525205,
        "vocab_size-1": 1214,
        "unique-1": 744,
        "entropy-1": 8.48101863469062,
        "distinct-2": 0.564050115060087,
        "vocab_size-2": 2206,
        "unique-2": 1638,
        "entropy-2": 10.491553785419129,
        "cond_entropy-2": 2.183570260708405,
        "distinct-3": 0.7239246556086589,
        "vocab_size-3": 2575,
        "unique-3": 2131,
        "entropy-3": 11.027071799804453,
        "cond_entropy-3": 0.6378999307132369,
        "total_length-nopunct": 3701,
        "mean_pred_length-nopunct": 10.454802259887005,
        "std_pred_length-nopunct": 1.9235213971824232,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.3263982707376385,
        "vocab_size-1-nopunct": 1208,
        "unique-1-nopunct": 744,
        "entropy-1-nopunct": 8.864085576438335,
        "distinct-2-nopunct": 0.6035255452644159,
        "vocab_size-2-nopunct": 2020,
        "unique-2-nopunct": 1560,
        "entropy-2-nopunct": 10.430777634403054,
        "cond_entropy-2-nopunct": 1.7555245172191039,
        "distinct-3-nopunct": 0.7407283661877715,
        "vocab_size-3-nopunct": 2217,
        "unique-3-nopunct": 1878,
        "entropy-3-nopunct": 10.813223103183313,
        "cond_entropy-3-nopunct": 0.4977406403173097,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.12755964681570542,
            "2": 0.2987220447284345,
            "3": 0.4145824501907588,
            "4": 0.5135135135135135,
            "5": 0.5454545454545454,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 0.4593735248042651,
        "rouge1": {
            "precision": 0.30916,
            "recall": 0.23216,
            "fmeasure": 0.25308
        },
        "rouge2": {
            "precision": 0.1299,
            "recall": 0.093,
            "fmeasure": 0.10098
        },
        "rougeL": {
            "precision": 0.30306,
            "recall": 0.22633,
            "fmeasure": 0.24724
        },
        "rougeLsum": {
            "precision": 0.30306,
            "recall": 0.22633,
            "fmeasure": 0.24724
        },
        "bleu": 14.20576,
        "meteor": 0.32723357931972713,
        "bertscore": {
            "precision": 0.94422,
            "recall": 0.88873,
            "f1": 0.91484
        },
        "nubia": {
            "semantic_relation": 3.3576,
            "contradiction": 22.82421,
            "irrelevancy": 23.11632,
            "logical_agreement": 54.05946,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.65911,
            "nubia_score": 0.63676
        },
        "bleurt": -0.00203
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 116,
        "msttr-100": 0.63857,
        "msttr-100_nopunct": 0.6775,
        "total_length": 1460,
        "mean_pred_length": 12.586206896551724,
        "std_pred_length": 2.491603020620707,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.36232876712328765,
        "vocab_size-1": 529,
        "unique-1": 323,
        "entropy-1": 7.895735299061641,
        "distinct-2": 0.6592261904761905,
        "vocab_size-2": 886,
        "unique-2": 647,
        "entropy-2": 9.481037036156573,
        "cond_entropy-2": 1.7015150853259815,
        "distinct-3": 0.8070032573289903,
        "vocab_size-3": 991,
        "unique-3": 816,
        "entropy-3": 9.820289519249014,
        "cond_entropy-3": 0.404727149672916,
        "total_length-nopunct": 1272,
        "mean_pred_length-nopunct": 10.96551724137931,
        "std_pred_length-nopunct": 2.2242047570821515,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.4119496855345912,
        "vocab_size-1-nopunct": 524,
        "unique-1-nopunct": 323,
        "entropy-1-nopunct": 8.159885018527559,
        "distinct-2-nopunct": 0.6972318339100346,
        "vocab_size-2-nopunct": 806,
        "unique-2-nopunct": 619,
        "entropy-2-nopunct": 9.374737199228157,
        "cond_entropy-2-nopunct": 1.3365762571765696,
        "distinct-3-nopunct": 0.8259615384615384,
        "vocab_size-3-nopunct": 859,
        "unique-3-nopunct": 727,
        "entropy-3-nopunct": 9.61924018998846,
        "cond_entropy-3-nopunct": 0.308859978521183,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.14695945945945946,
            "2": 0.35495283018867924,
            "3": 0.5362318840579711
        },
        "nist": 1.1869556828138483,
        "rouge1": {
            "precision": 0.06609,
            "recall": 0.05747,
            "fmeasure": 0.06034
        },
        "rouge2": {
            "precision": 0.01293,
            "recall": 0.01293,
            "fmeasure": 0.01293
        },
        "rougeL": {
            "precision": 0.06609,
            "recall": 0.05747,
            "fmeasure": 0.06034
        },
        "rougeLsum": {
            "precision": 0.06609,
            "recall": 0.05747,
            "fmeasure": 0.06034
        },
        "bleu": 18.63551,
        "meteor": 0.3586903504687789,
        "bertscore": {
            "precision": 0.94561,
            "recall": 0.90047,
            "f1": 0.92178
        },
        "nubia": {
            "semantic_relation": 3.52493,
            "contradiction": 23.11214,
            "irrelevancy": 22.33812,
            "logical_agreement": 54.54975,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.63795,
            "nubia_score": 0.6714
        },
        "bleurt": 0.00679
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 122,
        "msttr-100": 0.72632,
        "msttr-100_nopunct": 0.76941,
        "total_length": 1928,
        "mean_pred_length": 15.80327868852459,
        "std_pred_length": 4.8765738850917595,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.46213692946058094,
        "vocab_size-1": 891,
        "unique-1": 708,
        "entropy-1": 8.31782138826971,
        "distinct-2": 0.844407530454042,
        "vocab_size-2": 1525,
        "unique-2": 1378,
        "entropy-2": 10.398884572152463,
        "cond_entropy-2": 1.8357372492382196,
        "distinct-3": 0.9483372921615202,
        "vocab_size-3": 1597,
        "unique-3": 1528,
        "entropy-3": 10.60402792070007,
        "cond_entropy-3": 0.21068301889706864,
        "total_length-nopunct": 1711,
        "mean_pred_length-nopunct": 14.024590163934427,
        "std_pred_length-nopunct": 4.74680758079402,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5154880187025132,
        "vocab_size-1-nopunct": 882,
        "unique-1-nopunct": 706,
        "entropy-1-nopunct": 8.574881008384878,
        "distinct-2-nopunct": 0.8558842039018251,
        "vocab_size-2-nopunct": 1360,
        "unique-2-nopunct": 1240,
        "entropy-2-nopunct": 10.2377609412815,
        "cond_entropy-2-nopunct": 1.7661984301350948,
        "distinct-3-nopunct": 0.9556918882072256,
        "vocab_size-3-nopunct": 1402,
        "unique-3-nopunct": 1347,
        "entropy-3-nopunct": 10.423305982543816,
        "cond_entropy-3-nopunct": 0.20991069811569424,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20898876404494382,
            "2": 0.3916913946587537,
            "3": 0.7424130273871207
        },
        "nist": 7.3269110702060445,
        "rouge1": {
            "precision": 0.75233,
            "recall": 0.71123,
            "fmeasure": 0.72069
        },
        "rouge2": {
            "precision": 0.50759,
            "recall": 0.48063,
            "fmeasure": 0.48664
        },
        "rougeL": {
            "precision": 0.63714,
            "recall": 0.60762,
            "fmeasure": 0.6129
        },
        "rougeLsum": {
            "precision": 0.63714,
            "recall": 0.60762,
            "fmeasure": 0.6129
        },
        "bleu": 42.07609,
        "meteor": 0.37312490472863824,
        "bertscore": {
            "precision": 0.9254,
            "recall": 0.91559,
            "f1": 0.91838
        },
        "nubia": {
            "semantic_relation": 4.12669,
            "contradiction": 10.86121,
            "irrelevancy": 26.21729,
            "logical_agreement": 62.9215,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.63466,
            "nubia_score": 0.7078
        },
        "bleurt": 0.22648
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.522680508593631,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.828125,
        "vocab_size-1": 53,
        "unique-1": 48,
        "entropy-1": 5.55680425036562,
        "distinct-2": 1.0,
        "vocab_size-2": 60,
        "unique-2": 60,
        "entropy-2": 5.906890595608517,
        "cond_entropy-2": 0.30038460351579843,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.09953567355091447,
        "total_length-nopunct": 57,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 4.322904116447646,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8596491228070176,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.453773514613214,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.727920454563195,
        "cond_entropy-2-nopunct": 0.30275950595386875,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.11321061044799063,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5454545454545454,
            "3": 0.5333333333333333
        },
        "nist": 3.532972075174294,
        "rouge1": {
            "precision": 0.63271,
            "recall": 0.71201,
            "fmeasure": 0.65559
        },
        "rouge2": {
            "precision": 0.48761,
            "recall": 0.54083,
            "fmeasure": 0.50346
        },
        "rougeL": {
            "precision": 0.61078,
            "recall": 0.65215,
            "fmeasure": 0.61932
        },
        "rougeLsum": {
            "precision": 0.61078,
            "recall": 0.65215,
            "fmeasure": 0.61932
        },
        "bleu": 29.02347,
        "meteor": 0.27277857203064276,
        "bertscore": {
            "precision": 0.88657,
            "recall": 0.89582,
            "f1": 0.89063
        },
        "nubia": {
            "semantic_relation": 3.58285,
            "contradiction": 0.14241,
            "irrelevancy": 74.90097,
            "logical_agreement": 24.95663,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.2375,
            "nubia_score": 0.578
        },
        "bleurt": 0.12897
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 158,
        "msttr-100": 0.53658,
        "msttr-100_nopunct": 0.54086,
        "total_length": 3852,
        "mean_pred_length": 24.379746835443036,
        "std_pred_length": 2.668635442652504,
        "median_pred_length": 25.0,
        "min_pred_length": 16,
        "max_pred_length": 30,
        "distinct-1": 0.19080996884735202,
        "vocab_size-1": 735,
        "unique-1": 269,
        "entropy-1": 7.77222668407336,
        "distinct-2": 0.4607471575527883,
        "vocab_size-2": 1702,
        "unique-2": 1017,
        "entropy-2": 10.13345492081226,
        "cond_entropy-2": 2.42137151832153,
        "distinct-3": 0.625,
        "vocab_size-3": 2210,
        "unique-3": 1570,
        "entropy-3": 10.7596368405441,
        "cond_entropy-3": 0.677646415315582,
        "total_length-nopunct": 3539,
        "mean_pred_length-nopunct": 22.39873417721519,
        "std_pred_length-nopunct": 2.7922584512276383,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.20570782706979374,
        "vocab_size-1-nopunct": 728,
        "unique-1-nopunct": 269,
        "entropy-1-nopunct": 7.875816213364838,
        "distinct-2-nopunct": 0.47737355811889975,
        "vocab_size-2-nopunct": 1614,
        "unique-2-nopunct": 977,
        "entropy-2-nopunct": 10.107849915147106,
        "cond_entropy-2-nopunct": 2.322686417219958,
        "distinct-3-nopunct": 0.6400868755817561,
        "vocab_size-3-nopunct": 2063,
        "unique-3-nopunct": 1484,
        "entropy-3-nopunct": 10.679454839448956,
        "cond_entropy-3-nopunct": 0.6268749701339486,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1554357592093441,
            "2": 0.3747855917667238,
            "3": 0.6326820603907638
        },
        "nist": 3.031349449405397,
        "rouge1": {
            "precision": 0.77028,
            "recall": 0.52516,
            "fmeasure": 0.61154
        },
        "rouge2": {
            "precision": 0.46936,
            "recall": 0.3058,
            "fmeasure": 0.36116
        },
        "rougeL": {
            "precision": 0.58441,
            "recall": 0.39094,
            "fmeasure": 0.45749
        },
        "rougeLsum": {
            "precision": 0.58441,
            "recall": 0.39094,
            "fmeasure": 0.45749
        },
        "bleu": 28.33653,
        "meteor": 0.2561253175447696,
        "bertscore": {
            "precision": 0.90066,
            "recall": 0.84956,
            "f1": 0.87262
        },
        "nubia": {
            "semantic_relation": 3.47328,
            "contradiction": 11.10304,
            "irrelevancy": 14.49504,
            "logical_agreement": 74.40192,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.57873,
            "nubia_score": 0.47067
        },
        "bleurt": -0.3108
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73266,
        "msttr-100_nopunct": 0.76982,
        "total_length": 6472,
        "mean_pred_length": 18.027855153203344,
        "std_pred_length": 6.155306936102102,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.35939431396786153,
        "vocab_size-1": 2326,
        "unique-1": 1694,
        "entropy-1": 9.041400391999355,
        "distinct-2": 0.8194012759692458,
        "vocab_size-2": 5009,
        "unique-2": 4631,
        "entropy-2": 11.908622435405071,
        "cond_entropy-2": 2.6994473115553896,
        "distinct-3": 0.9494264859228363,
        "vocab_size-3": 5463,
        "unique-3": 5351,
        "entropy-3": 12.300521906911825,
        "cond_entropy-3": 0.41462919015205124,
        "total_length-nopunct": 5756,
        "mean_pred_length-nopunct": 16.03342618384401,
        "std_pred_length-nopunct": 5.604315608736071,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.40218902015288394,
        "vocab_size-1-nopunct": 2315,
        "unique-1-nopunct": 1693,
        "entropy-1-nopunct": 9.3388958536926,
        "distinct-2-nopunct": 0.8530665184361682,
        "vocab_size-2-nopunct": 4604,
        "unique-2-nopunct": 4283,
        "entropy-2-nopunct": 11.908064888858732,
        "cond_entropy-2-nopunct": 2.7008409707095486,
        "distinct-3-nopunct": 0.9753870583564906,
        "vocab_size-3-nopunct": 4914,
        "unique-3-nopunct": 4827,
        "entropy-3-nopunct": 12.241499115043315,
        "cond_entropy-3-nopunct": 0.3566665332014031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04711375212224109,
            "2": 0.16219667943805874,
            "3": 0.3347921225382932,
            "4": 0.4358161648177496,
            "5": 0.5160955347871236,
            "6": 0.6473429951690821,
            "7": 0.8010691103474609
        },
        "nist": 9.429216404028697,
        "rouge1": {
            "precision": 0.80752,
            "recall": 0.72406,
            "fmeasure": 0.74722
        },
        "rouge2": {
            "precision": 0.65389,
            "recall": 0.58506,
            "fmeasure": 0.6021
        },
        "rougeL": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "rougeLsum": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "bleu": 59.46369,
        "meteor": 0.39878954357926183,
        "bertscore": {
            "precision": 0.93904,
            "recall": 0.92612,
            "f1": 0.92923
        },
        "nubia": {
            "semantic_relation": 4.02391,
            "contradiction": 5.62065,
            "irrelevancy": 22.17407,
            "logical_agreement": 72.20528,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.96242,
            "nubia_score": 0.61717
        },
        "bleurt": 0.04008
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 22,
        "msttr-100": 0.26,
        "msttr-100_nopunct": 0.24,
        "total_length": 188,
        "mean_pred_length": 8.545454545454545,
        "std_pred_length": 2.250803346025445,
        "median_pred_length": 9.0,
        "min_pred_length": 6,
        "max_pred_length": 13,
        "distinct-1": 0.13829787234042554,
        "vocab_size-1": 26,
        "unique-1": 0,
        "entropy-1": 4.225597861741161,
        "distinct-2": 0.18674698795180722,
        "vocab_size-2": 31,
        "unique-2": 0,
        "entropy-2": 4.612809890911531,
        "cond_entropy-2": 0.23739459645097868,
        "distinct-3": 0.2013888888888889,
        "vocab_size-3": 29,
        "unique-3": 0,
        "entropy-3": 4.567397743686569,
        "cond_entropy-3": -0.035100776569164945,
        "total_length-nopunct": 153,
        "mean_pred_length-nopunct": 6.954545454545454,
        "std_pred_length-nopunct": 1.636994827760828,
        "median_pred_length-nopunct": 7.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.1568627450980392,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.122504874312244,
        "distinct-2-nopunct": 0.19083969465648856,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.291498242818967,
        "cond_entropy-2-nopunct": 0.17650107888246366,
        "distinct-3-nopunct": 0.2018348623853211,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.172309209284247,
        "cond_entropy-3-nopunct": -0.1894786716387603,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.32571428571428573
        },
        "nist": 2.1072947665298463,
        "rouge1": {
            "precision": 0.49257,
            "recall": 0.43847,
            "fmeasure": 0.45329
        },
        "rouge2": {
            "precision": 0.3097,
            "recall": 0.26637,
            "fmeasure": 0.28066
        },
        "rougeL": {
            "precision": 0.42089,
            "recall": 0.38469,
            "fmeasure": 0.39392
        },
        "rougeLsum": {
            "precision": 0.42089,
            "recall": 0.38469,
            "fmeasure": 0.39392
        },
        "bleu": 18.12863,
        "meteor": 0.17022557680249478,
        "bertscore": {
            "precision": 0.9077,
            "recall": 0.89553,
            "f1": 0.90139
        },
        "nubia": {
            "semantic_relation": 2.67085,
            "contradiction": 22.15008,
            "irrelevancy": 26.4178,
            "logical_agreement": 51.43212,
            "grammar_ref": 6.09546,
            "grammar_hyp": 6.088,
            "nubia_score": 0.31994
        },
        "bleurt": -0.22043
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 16,
        "msttr-100": 0.495,
        "msttr-100_nopunct": 0.515,
        "total_length": 268,
        "mean_pred_length": 16.75,
        "std_pred_length": 4.2793106921559225,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.3283582089552239,
        "vocab_size-1": 88,
        "unique-1": 44,
        "entropy-1": 5.710880534561984,
        "distinct-2": 0.5158730158730159,
        "vocab_size-2": 130,
        "unique-2": 78,
        "entropy-2": 6.589324303444004,
        "cond_entropy-2": 0.8370851266538271,
        "distinct-3": 0.6186440677966102,
        "vocab_size-3": 146,
        "unique-3": 97,
        "entropy-3": 6.886220988115048,
        "cond_entropy-3": 0.3655716419629934,
        "total_length-nopunct": 233,
        "mean_pred_length-nopunct": 14.5625,
        "std_pred_length-nopunct": 3.999511688944039,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.3648068669527897,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.757527185144068,
        "distinct-2-nopunct": 0.5299539170506913,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.433827381005094,
        "cond_entropy-2-nopunct": 0.7866764901006652,
        "distinct-3-nopunct": 0.6368159203980099,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.726318387999359,
        "cond_entropy-3-nopunct": 0.3625091991414614,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.3967611336032389
        },
        "nist": 2.842547464904639,
        "rouge1": {
            "precision": 0.50472,
            "recall": 0.47626,
            "fmeasure": 0.47905
        },
        "rouge2": {
            "precision": 0.26333,
            "recall": 0.26262,
            "fmeasure": 0.25535
        },
        "rougeL": {
            "precision": 0.41574,
            "recall": 0.39868,
            "fmeasure": 0.39657
        },
        "rougeLsum": {
            "precision": 0.41574,
            "recall": 0.39868,
            "fmeasure": 0.39657
        },
        "bleu": 14.82394,
        "meteor": 0.20485685565438078,
        "bertscore": {
            "precision": 0.89909,
            "recall": 0.89678,
            "f1": 0.8977
        },
        "nubia": {
            "semantic_relation": 3.13581,
            "contradiction": 27.39036,
            "irrelevancy": 28.33397,
            "logical_agreement": 44.27567,
            "grammar_ref": 5.92126,
            "grammar_hyp": 6.25156,
            "nubia_score": 0.42997
        },
        "bleurt": -0.12171
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73266,
        "msttr-100_nopunct": 0.76982,
        "total_length": 6472,
        "mean_pred_length": 18.027855153203344,
        "std_pred_length": 6.155306936102102,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.35939431396786153,
        "vocab_size-1": 2326,
        "unique-1": 1694,
        "entropy-1": 9.041400391999355,
        "distinct-2": 0.8194012759692458,
        "vocab_size-2": 5009,
        "unique-2": 4631,
        "entropy-2": 11.908622435405071,
        "cond_entropy-2": 2.6994473115553896,
        "distinct-3": 0.9494264859228363,
        "vocab_size-3": 5463,
        "unique-3": 5351,
        "entropy-3": 12.300521906911825,
        "cond_entropy-3": 0.41462919015205124,
        "total_length-nopunct": 5756,
        "mean_pred_length-nopunct": 16.03342618384401,
        "std_pred_length-nopunct": 5.604315608736071,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.40218902015288394,
        "vocab_size-1-nopunct": 2315,
        "unique-1-nopunct": 1693,
        "entropy-1-nopunct": 9.3388958536926,
        "distinct-2-nopunct": 0.8530665184361682,
        "vocab_size-2-nopunct": 4604,
        "unique-2-nopunct": 4283,
        "entropy-2-nopunct": 11.908064888858732,
        "cond_entropy-2-nopunct": 2.7008409707095486,
        "distinct-3-nopunct": 0.9753870583564906,
        "vocab_size-3-nopunct": 4914,
        "unique-3-nopunct": 4827,
        "entropy-3-nopunct": 12.241499115043315,
        "cond_entropy-3-nopunct": 0.3566665332014031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04711375212224109,
            "2": 0.16219667943805874,
            "3": 0.3347921225382932,
            "4": 0.4358161648177496,
            "5": 0.5160955347871236,
            "6": 0.6473429951690821,
            "7": 0.8010691103474609
        },
        "nist": 9.429216404028697,
        "rouge1": {
            "precision": 0.80752,
            "recall": 0.72406,
            "fmeasure": 0.74722
        },
        "rouge2": {
            "precision": 0.65389,
            "recall": 0.58506,
            "fmeasure": 0.6021
        },
        "rougeL": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "rougeLsum": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "bleu": 59.46369,
        "meteor": 0.39878954357926183,
        "bertscore": {
            "precision": 0.93904,
            "recall": 0.92612,
            "f1": 0.92923
        },
        "nubia": {
            "semantic_relation": 4.02391,
            "contradiction": 5.62065,
            "irrelevancy": 22.17407,
            "logical_agreement": 72.20528,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.96242,
            "nubia_score": 0.61717
        },
        "bleurt": 0.04008
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 49,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.77,
        "total_length": 825,
        "mean_pred_length": 16.836734693877553,
        "std_pred_length": 5.265780709508617,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5454545454545454,
        "vocab_size-1": 450,
        "unique-1": 377,
        "entropy-1": 7.726754671062948,
        "distinct-2": 0.9175257731958762,
        "vocab_size-2": 712,
        "unique-2": 676,
        "entropy-2": 9.385005424699298,
        "cond_entropy-2": 1.4617984317843598,
        "distinct-3": 0.9793672627235214,
        "vocab_size-3": 712,
        "unique-3": 700,
        "entropy-3": 9.461431000265378,
        "cond_entropy-3": 0.07886790837875678,
        "total_length-nopunct": 710,
        "mean_pred_length-nopunct": 14.489795918367347,
        "std_pred_length-nopunct": 4.4406400025019,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6211267605633802,
        "vocab_size-1-nopunct": 441,
        "unique-1-nopunct": 374,
        "entropy-1-nopunct": 7.928868923225965,
        "distinct-2-nopunct": 0.9304084720121029,
        "vocab_size-2-nopunct": 615,
        "unique-2-nopunct": 592,
        "entropy-2-nopunct": 9.177866115867106,
        "cond_entropy-2-nopunct": 1.333222148410582,
        "distinct-3-nopunct": 0.9901960784313726,
        "vocab_size-3-nopunct": 606,
        "unique-3-nopunct": 601,
        "entropy-3-nopunct": 9.236546523244746,
        "cond_entropy-3-nopunct": 0.06617467115884466,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21649484536082475,
            "2": 0.37572254335260113,
            "3": 0.7703984819734345
        },
        "nist": 6.918575196979654,
        "rouge1": {
            "precision": 0.77052,
            "recall": 0.70756,
            "fmeasure": 0.72366
        },
        "rouge2": {
            "precision": 0.52804,
            "recall": 0.491,
            "fmeasure": 0.49764
        },
        "rougeL": {
            "precision": 0.66365,
            "recall": 0.61664,
            "fmeasure": 0.62612
        },
        "rougeLsum": {
            "precision": 0.66365,
            "recall": 0.61664,
            "fmeasure": 0.62612
        },
        "bleu": 44.42909,
        "meteor": 0.3775603387749599,
        "bertscore": {
            "precision": 0.93719,
            "recall": 0.92277,
            "f1": 0.92764
        },
        "nubia": {
            "semantic_relation": 4.17898,
            "contradiction": 5.85168,
            "irrelevancy": 33.44599,
            "logical_agreement": 60.70233,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.90941,
            "nubia_score": 0.70056
        },
        "bleurt": 0.24145
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 34,
        "msttr-100": 0.57667,
        "msttr-100_nopunct": 0.6,
        "total_length": 391,
        "mean_pred_length": 11.5,
        "std_pred_length": 3.292147520102592,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.289002557544757,
        "vocab_size-1": 113,
        "unique-1": 45,
        "entropy-1": 6.079473619338975,
        "distinct-2": 0.5462184873949579,
        "vocab_size-2": 195,
        "unique-2": 116,
        "entropy-2": 7.276904557158124,
        "cond_entropy-2": 0.9540107794113348,
        "distinct-3": 0.6780185758513931,
        "vocab_size-3": 219,
        "unique-3": 147,
        "entropy-3": 7.5972986271586285,
        "cond_entropy-3": 0.24723137346995955,
        "total_length-nopunct": 344,
        "mean_pred_length-nopunct": 10.117647058823529,
        "std_pred_length-nopunct": 2.8570316340190334,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.3226744186046512,
        "vocab_size-1-nopunct": 111,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 6.191505866192511,
        "distinct-2-nopunct": 0.567741935483871,
        "vocab_size-2-nopunct": 176,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 7.170004075145304,
        "cond_entropy-2-nopunct": 0.946718570085888,
        "distinct-3-nopunct": 0.6992753623188406,
        "vocab_size-3-nopunct": 193,
        "unique-3-nopunct": 134,
        "entropy-3-nopunct": 7.424126438699952,
        "cond_entropy-3-nopunct": 0.24148958717544383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.35522388059701493
        },
        "nist": 2.4905725682217987,
        "rouge1": {
            "precision": 0.48232,
            "recall": 0.47777,
            "fmeasure": 0.46859
        },
        "rouge2": {
            "precision": 0.28622,
            "recall": 0.28605,
            "fmeasure": 0.27899
        },
        "rougeL": {
            "precision": 0.43357,
            "recall": 0.43009,
            "fmeasure": 0.42125
        },
        "rougeLsum": {
            "precision": 0.43357,
            "recall": 0.43009,
            "fmeasure": 0.42125
        },
        "bleu": 13.61269,
        "meteor": 0.19862423149252442,
        "bertscore": {
            "precision": 0.90947,
            "recall": 0.90941,
            "f1": 0.90925
        },
        "nubia": {
            "semantic_relation": 3.16935,
            "contradiction": 25.63913,
            "irrelevancy": 23.41675,
            "logical_agreement": 50.94412,
            "grammar_ref": 6.46033,
            "grammar_hyp": 6.32906,
            "nubia_score": 0.44176
        },
        "bleurt": -0.12196
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73266,
        "msttr-100_nopunct": 0.76982,
        "total_length": 6472,
        "mean_pred_length": 18.027855153203344,
        "std_pred_length": 6.155306936102102,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.35939431396786153,
        "vocab_size-1": 2326,
        "unique-1": 1694,
        "entropy-1": 9.041400391999355,
        "distinct-2": 0.8194012759692458,
        "vocab_size-2": 5009,
        "unique-2": 4631,
        "entropy-2": 11.908622435405071,
        "cond_entropy-2": 2.6994473115553896,
        "distinct-3": 0.9494264859228363,
        "vocab_size-3": 5463,
        "unique-3": 5351,
        "entropy-3": 12.300521906911825,
        "cond_entropy-3": 0.41462919015205124,
        "total_length-nopunct": 5756,
        "mean_pred_length-nopunct": 16.03342618384401,
        "std_pred_length-nopunct": 5.604315608736071,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.40218902015288394,
        "vocab_size-1-nopunct": 2315,
        "unique-1-nopunct": 1693,
        "entropy-1-nopunct": 9.3388958536926,
        "distinct-2-nopunct": 0.8530665184361682,
        "vocab_size-2-nopunct": 4604,
        "unique-2-nopunct": 4283,
        "entropy-2-nopunct": 11.908064888858732,
        "cond_entropy-2-nopunct": 2.7008409707095486,
        "distinct-3-nopunct": 0.9753870583564906,
        "vocab_size-3-nopunct": 4914,
        "unique-3-nopunct": 4827,
        "entropy-3-nopunct": 12.241499115043315,
        "cond_entropy-3-nopunct": 0.3566665332014031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04711375212224109,
            "2": 0.16219667943805874,
            "3": 0.3347921225382932,
            "4": 0.4358161648177496,
            "5": 0.5160955347871236,
            "6": 0.6473429951690821,
            "7": 0.8010691103474609
        },
        "nist": 9.429216404028697,
        "rouge1": {
            "precision": 0.80752,
            "recall": 0.72406,
            "fmeasure": 0.74722
        },
        "rouge2": {
            "precision": 0.65389,
            "recall": 0.58506,
            "fmeasure": 0.6021
        },
        "rougeL": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "rougeLsum": {
            "precision": 0.77865,
            "recall": 0.69705,
            "fmeasure": 0.7196
        },
        "bleu": 59.46369,
        "meteor": 0.39878954357926183,
        "bertscore": {
            "precision": 0.93904,
            "recall": 0.92612,
            "f1": 0.92923
        },
        "nubia": {
            "semantic_relation": 4.02391,
            "contradiction": 5.62065,
            "irrelevancy": 22.17407,
            "logical_agreement": 72.20528,
            "grammar_ref": 4.55265,
            "grammar_hyp": 4.96242,
            "nubia_score": 0.61717
        },
        "bleurt": 0.04008
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 642,
        "msttr-100": 0.67176,
        "msttr-100_nopunct": 0.72,
        "total_length": 6866,
        "mean_pred_length": 10.694704049844237,
        "std_pred_length": 3.1425533782011423,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.26915234488785317,
        "vocab_size-1": 1848,
        "unique-1": 1022,
        "entropy-1": 9.029756791186262,
        "distinct-2": 0.5981683804627249,
        "vocab_size-2": 3723,
        "unique-2": 2741,
        "entropy-2": 11.394643457244266,
        "cond_entropy-2": 2.2954371667451996,
        "distinct-3": 0.7810820494446435,
        "vocab_size-3": 4360,
        "unique-3": 3681,
        "entropy-3": 11.88500967599056,
        "cond_entropy-3": 0.5701107809275382,
        "total_length-nopunct": 5812,
        "mean_pred_length-nopunct": 9.052959501557632,
        "std_pred_length-nopunct": 2.831234161983041,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3165863730213352,
        "vocab_size-1-nopunct": 1840,
        "unique-1-nopunct": 1020,
        "entropy-1-nopunct": 9.5537518323887,
        "distinct-2-nopunct": 0.6350096711798839,
        "vocab_size-2-nopunct": 3283,
        "unique-2-nopunct": 2512,
        "entropy-2-nopunct": 11.250072452675639,
        "cond_entropy-2-nopunct": 1.8946673022350224,
        "distinct-3-nopunct": 0.8041077738515902,
        "vocab_size-3-nopunct": 3641,
        "unique-3-nopunct": 3138,
        "entropy-3-nopunct": 11.641488437581259,
        "cond_entropy-3-nopunct": 0.4915564628614683,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.18824219322679958,
            "2": 0.37247956403269755,
            "3": 0.4989503149055283,
            "4": 0.631578947368421,
            "5": 0.5757575757575758,
            "6": 0.9090909090909091,
            "7": 1.0
        },
        "nist": 2.4408445503152,
        "rouge1": {
            "precision": 0.34327,
            "recall": 0.27274,
            "fmeasure": 0.29121
        },
        "rouge2": {
            "precision": 0.18374,
            "recall": 0.14828,
            "fmeasure": 0.1586
        },
        "rougeL": {
            "precision": 0.33336,
            "recall": 0.26445,
            "fmeasure": 0.28226
        },
        "rougeLsum": {
            "precision": 0.33336,
            "recall": 0.26445,
            "fmeasure": 0.28226
        },
        "bleu": 25.3405,
        "meteor": 0.4312031527455309,
        "bertscore": {
            "precision": 0.95357,
            "recall": 0.92391,
            "f1": 0.93765
        },
        "nubia": {
            "semantic_relation": 3.66514,
            "contradiction": 21.50082,
            "irrelevancy": 22.8978,
            "logical_agreement": 55.60137,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.79388,
            "nubia_score": 0.7179
        },
        "bleurt": 0.15401
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 12,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 90,
        "mean_pred_length": 7.5,
        "std_pred_length": 2.8136571693556887,
        "median_pred_length": 7.0,
        "min_pred_length": 5,
        "max_pred_length": 13,
        "distinct-1": 0.4,
        "vocab_size-1": 36,
        "unique-1": 13,
        "entropy-1": 4.8264356357822065,
        "distinct-2": 0.6153846153846154,
        "vocab_size-2": 48,
        "unique-2": 28,
        "entropy-2": 5.419391000636162,
        "cond_entropy-2": 0.29764074328877244,
        "distinct-3": 0.6515151515151515,
        "vocab_size-3": 43,
        "unique-3": 28,
        "entropy-3": 5.255922906975004,
        "cond_entropy-3": -0.18040203889773448,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 6.166666666666667,
        "std_pred_length-nopunct": 2.4094720491334933,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.4594594594594595,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.8733990218368115,
        "distinct-2-nopunct": 0.6290322580645161,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 5.114855987527072,
        "cond_entropy-2-nopunct": 0.2580863854458905,
        "distinct-3-nopunct": 0.66,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.873269689515109,
        "cond_entropy-3-nopunct": -0.27034012061215046,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.24390243902439024
        },
        "nist": 1.697331131621417,
        "rouge1": {
            "precision": 0.36033,
            "recall": 0.31933,
            "fmeasure": 0.32753
        },
        "rouge2": {
            "precision": 0.22407,
            "recall": 0.21295,
            "fmeasure": 0.2092
        },
        "rougeL": {
            "precision": 0.36033,
            "recall": 0.31933,
            "fmeasure": 0.32753
        },
        "rougeLsum": {
            "precision": 0.36033,
            "recall": 0.31933,
            "fmeasure": 0.32753
        },
        "bleu": 12.65123,
        "meteor": 0.13621185897409022,
        "bertscore": {
            "precision": 0.87968,
            "recall": 0.87581,
            "f1": 0.87761
        },
        "nubia": {
            "semantic_relation": 2.38887,
            "contradiction": 30.32729,
            "irrelevancy": 27.40698,
            "logical_agreement": 42.26573,
            "grammar_ref": 6.83527,
            "grammar_hyp": 7.31655,
            "nubia_score": 0.1934
        },
        "bleurt": -0.30602
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.74,
        "total_length": 306,
        "mean_pred_length": 14.571428571428571,
        "std_pred_length": 5.695206242943258,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5620915032679739,
        "vocab_size-1": 172,
        "unique-1": 132,
        "entropy-1": 6.780871787929578,
        "distinct-2": 0.8982456140350877,
        "vocab_size-2": 256,
        "unique-2": 241,
        "entropy-2": 7.896051070589473,
        "cond_entropy-2": 0.9003307608061053,
        "distinct-3": 0.9772727272727273,
        "vocab_size-3": 258,
        "unique-3": 254,
        "entropy-3": 7.993220729190559,
        "cond_entropy-3": 0.06620173183320842,
        "total_length-nopunct": 257,
        "mean_pred_length-nopunct": 12.238095238095237,
        "std_pred_length-nopunct": 4.555527902133866,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6498054474708171,
        "vocab_size-1-nopunct": 167,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.915611660155271,
        "distinct-2-nopunct": 0.9194915254237288,
        "vocab_size-2-nopunct": 217,
        "unique-2-nopunct": 208,
        "entropy-2-nopunct": 7.673388481627692,
        "cond_entropy-2-nopunct": 0.8013388138257425,
        "distinct-3-nopunct": 0.9906976744186047,
        "vocab_size-3-nopunct": 213,
        "unique-3-nopunct": 212,
        "entropy-3-nopunct": 7.726077093765419,
        "cond_entropy-3-nopunct": 0.04170934897611733,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2753623188405797,
            "2": 0.41509433962264153,
            "3": 0.7978723404255319
        },
        "nist": 6.113748335312709,
        "rouge1": {
            "precision": 0.76812,
            "recall": 0.73939,
            "fmeasure": 0.7437
        },
        "rouge2": {
            "precision": 0.54077,
            "recall": 0.51858,
            "fmeasure": 0.5223
        },
        "rougeL": {
            "precision": 0.65594,
            "recall": 0.64663,
            "fmeasure": 0.64214
        },
        "rougeLsum": {
            "precision": 0.65594,
            "recall": 0.64663,
            "fmeasure": 0.64214
        },
        "bleu": 45.74644,
        "meteor": 0.39584069890965345,
        "bertscore": {
            "precision": 0.92903,
            "recall": 0.92277,
            "f1": 0.92444
        },
        "nubia": {
            "semantic_relation": 4.02828,
            "contradiction": 6.56179,
            "irrelevancy": 39.56829,
            "logical_agreement": 53.86992,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.84099,
            "nubia_score": 0.68733
        },
        "bleurt": 0.24939
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 460,
        "msttr-100": 0.63891,
        "msttr-100_nopunct": 0.68255,
        "total_length": 5572,
        "mean_pred_length": 12.11304347826087,
        "std_pred_length": 2.364649867974039,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.2605886575735822,
        "vocab_size-1": 1452,
        "unique-1": 817,
        "entropy-1": 8.648325758591417,
        "distinct-2": 0.5471439749608764,
        "vocab_size-2": 2797,
        "unique-2": 1984,
        "entropy-2": 10.855371446020806,
        "cond_entropy-2": 2.3739581719025407,
        "distinct-3": 0.7239896818572656,
        "vocab_size-3": 3368,
        "unique-3": 2704,
        "entropy-3": 11.47189997611075,
        "cond_entropy-3": 0.7177579101299179,
        "total_length-nopunct": 4773,
        "mean_pred_length-nopunct": 10.376086956521739,
        "std_pred_length-nopunct": 1.9923423818088113,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.30274460507018647,
        "vocab_size-1-nopunct": 1445,
        "unique-1-nopunct": 816,
        "entropy-1-nopunct": 9.096361059628718,
        "distinct-2-nopunct": 0.6016693716670531,
        "vocab_size-2-nopunct": 2595,
        "unique-2-nopunct": 1943,
        "entropy-2-nopunct": 10.851589991194375,
        "cond_entropy-2-nopunct": 1.9404556040106993,
        "distinct-3-nopunct": 0.758629639242149,
        "vocab_size-3-nopunct": 2923,
        "unique-3-nopunct": 2429,
        "entropy-3-nopunct": 11.293531612874913,
        "cond_entropy-3-nopunct": 0.551560036003065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13630041724617525,
            "2": 0.327217125382263,
            "3": 0.4674130347860856,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 0.88893996632074,
        "rouge1": {
            "precision": 0.19529,
            "recall": 0.17146,
            "fmeasure": 0.17772
        },
        "rouge2": {
            "precision": 0.05371,
            "recall": 0.042,
            "fmeasure": 0.04415
        },
        "rougeL": {
            "precision": 0.19475,
            "recall": 0.17091,
            "fmeasure": 0.17717
        },
        "rougeLsum": {
            "precision": 0.19475,
            "recall": 0.17091,
            "fmeasure": 0.17717
        },
        "bleu": 17.0476,
        "meteor": 0.34751984305676736,
        "bertscore": {
            "precision": 0.94386,
            "recall": 0.89641,
            "f1": 0.9187
        },
        "nubia": {
            "semantic_relation": 3.4767,
            "contradiction": 22.98571,
            "irrelevancy": 22.50308,
            "logical_agreement": 54.51121,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.64478,
            "nubia_score": 0.65987
        },
        "bleurt": 0.00238
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 80,
        "msttr-100": 0.536,
        "msttr-100_nopunct": 0.53556,
        "total_length": 2038,
        "mean_pred_length": 25.475,
        "std_pred_length": 2.280213805764714,
        "median_pred_length": 26.0,
        "min_pred_length": 19,
        "max_pred_length": 31,
        "distinct-1": 0.25417075564278707,
        "vocab_size-1": 518,
        "unique-1": 264,
        "entropy-1": 7.4801377979682675,
        "distinct-2": 0.5270684371807968,
        "vocab_size-2": 1032,
        "unique-2": 669,
        "entropy-2": 9.519375550949306,
        "cond_entropy-2": 2.111726842358999,
        "distinct-3": 0.6794462193823216,
        "vocab_size-3": 1276,
        "unique-3": 958,
        "entropy-3": 10.028784101644323,
        "cond_entropy-3": 0.5487067935988412,
        "total_length-nopunct": 1881,
        "mean_pred_length-nopunct": 23.5125,
        "std_pred_length-nopunct": 2.3075622960171627,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.27219564061669327,
        "vocab_size-1-nopunct": 512,
        "unique-1-nopunct": 262,
        "entropy-1-nopunct": 7.558035425629135,
        "distinct-2-nopunct": 0.5430316490838423,
        "vocab_size-2-nopunct": 978,
        "unique-2-nopunct": 640,
        "entropy-2-nopunct": 9.487842810640544,
        "cond_entropy-2-nopunct": 2.0207367671265644,
        "distinct-3-nopunct": 0.6891342242882045,
        "vocab_size-3-nopunct": 1186,
        "unique-3-nopunct": 900,
        "entropy-3-nopunct": 9.937903136754471,
        "cond_entropy-3-nopunct": 0.4923892265807564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.13505311077389984,
            "2": 0.353887399463807,
            "3": 0.6039136302294197
        },
        "nist": 2.098931344175621,
        "rouge1": {
            "precision": 0.75816,
            "recall": 0.46455,
            "fmeasure": 0.56965
        },
        "rouge2": {
            "precision": 0.44405,
            "recall": 0.25697,
            "fmeasure": 0.32141
        },
        "rougeL": {
            "precision": 0.56666,
            "recall": 0.34497,
            "fmeasure": 0.42393
        },
        "rougeLsum": {
            "precision": 0.56666,
            "recall": 0.34497,
            "fmeasure": 0.42393
        },
        "bleu": 24.52323,
        "meteor": 0.23388086207369982,
        "bertscore": {
            "precision": 0.8926,
            "recall": 0.8258,
            "f1": 0.85615
        },
        "nubia": {
            "semantic_relation": 3.20141,
            "contradiction": 16.26426,
            "irrelevancy": 21.42231,
            "logical_agreement": 62.31343,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.61779,
            "nubia_score": 0.35487
        },
        "bleurt": -0.4297
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 213,
        "msttr-100": 0.6651,
        "msttr-100_nopunct": 0.68128,
        "total_length": 5178,
        "mean_pred_length": 24.309859154929576,
        "std_pred_length": 2.6814869532839705,
        "median_pred_length": 25.0,
        "min_pred_length": 16,
        "max_pred_length": 30,
        "distinct-1": 0.1797991502510622,
        "vocab_size-1": 931,
        "unique-1": 356,
        "entropy-1": 7.96207842203244,
        "distinct-2": 0.46183282980866064,
        "vocab_size-2": 2293,
        "unique-2": 1424,
        "entropy-2": 10.512432808001893,
        "cond_entropy-2": 2.6194849249843983,
        "distinct-3": 0.6500420875420876,
        "vocab_size-3": 3089,
        "unique-3": 2277,
        "entropy-3": 11.26574136052705,
        "cond_entropy-3": 0.8053206694622344,
        "total_length-nopunct": 4761,
        "mean_pred_length-nopunct": 22.35211267605634,
        "std_pred_length-nopunct": 2.7292465290647687,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.19407687460617518,
        "vocab_size-1-nopunct": 924,
        "unique-1-nopunct": 355,
        "entropy-1-nopunct": 8.085391328590736,
        "distinct-2-nopunct": 0.47845206684256814,
        "vocab_size-2-nopunct": 2176,
        "unique-2-nopunct": 1372,
        "entropy-2-nopunct": 10.493002696888574,
        "cond_entropy-2-nopunct": 2.5055915165917164,
        "distinct-3-nopunct": 0.6645905420991927,
        "vocab_size-3-nopunct": 2881,
        "unique-3-nopunct": 2157,
        "entropy-3-nopunct": 11.179727916958793,
        "cond_entropy-3-nopunct": 0.7438257456365136,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1584055459272097,
            "2": 0.38885486834047767,
            "3": 0.6684923609109253
        },
        "nist": 4.138070589094824,
        "rouge1": {
            "precision": 0.75791,
            "recall": 0.53934,
            "fmeasure": 0.62122
        },
        "rouge2": {
            "precision": 0.46043,
            "recall": 0.31324,
            "fmeasure": 0.36627
        },
        "rougeL": {
            "precision": 0.57506,
            "recall": 0.40503,
            "fmeasure": 0.46782
        },
        "rougeLsum": {
            "precision": 0.57506,
            "recall": 0.40503,
            "fmeasure": 0.46782
        },
        "bleu": 30.82209,
        "meteor": 0.26954454947685624,
        "bertscore": {
            "precision": 0.90107,
            "recall": 0.85626,
            "f1": 0.87646
        },
        "nubia": {
            "semantic_relation": 3.53459,
            "contradiction": 11.43005,
            "irrelevancy": 13.24302,
            "logical_agreement": 75.32693,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.57329,
            "nubia_score": 0.47342
        },
        "bleurt": -0.27822
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 14.857142857142858,
        "std_pred_length": 5.591538797365979,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.6826923076923077,
        "vocab_size-1": 71,
        "unique-1": 56,
        "entropy-1": 5.8539099102823675,
        "distinct-2": 0.9484536082474226,
        "vocab_size-2": 92,
        "unique-2": 87,
        "entropy-2": 6.496820058681983,
        "cond_entropy-2": 0.5441053406747038,
        "distinct-3": 0.9777777777777777,
        "vocab_size-3": 88,
        "unique-3": 86,
        "entropy-3": 6.447408651885218,
        "cond_entropy-3": -0.041393079190786546,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 5.3566666455007645,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.8385668472673045,
        "distinct-2-nopunct": 0.9529411764705882,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.315273289078884,
        "cond_entropy-2-nopunct": 0.5331178037119113,
        "distinct-3-nopunct": 0.9871794871794872,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.25976119322123,
        "cond_entropy-3-nopunct": -0.047065640352376335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.4782608695652174,
            "3": 0.49122807017543857
        },
        "nist": 3.2803054987248736,
        "rouge1": {
            "precision": 0.57596,
            "recall": 0.53896,
            "fmeasure": 0.53282
        },
        "rouge2": {
            "precision": 0.29253,
            "recall": 0.30167,
            "fmeasure": 0.28336
        },
        "rougeL": {
            "precision": 0.43704,
            "recall": 0.4408,
            "fmeasure": 0.41839
        },
        "rougeLsum": {
            "precision": 0.43704,
            "recall": 0.4408,
            "fmeasure": 0.41839
        },
        "bleu": 12.86879,
        "meteor": 0.23701512272407965,
        "bertscore": {
            "precision": 0.88128,
            "recall": 0.86693,
            "f1": 0.86854
        },
        "nubia": {
            "semantic_relation": 3.60387,
            "contradiction": 1.24234,
            "irrelevancy": 60.59115,
            "logical_agreement": 38.1665,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.58589,
            "nubia_score": 0.5924
        },
        "bleurt": -0.12499
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 1075,
        "msttr-100": 0.77595,
        "msttr-100_nopunct": 0.84903,
        "total_length": 12150,
        "mean_pred_length": 11.30232558139535,
        "std_pred_length": 2.9080072592031385,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.20987654320987653,
        "vocab_size-1": 2550,
        "unique-1": 1331,
        "entropy-1": 9.151796167814233,
        "distinct-2": 0.5031151241534989,
        "vocab_size-2": 5572,
        "unique-2": 3835,
        "entropy-2": 11.74843434530688,
        "cond_entropy-2": 2.666757969765606,
        "distinct-3": 0.7021,
        "vocab_size-3": 7021,
        "unique-3": 5616,
        "entropy-3": 12.471273700086455,
        "cond_entropy-3": 0.8379301455405841,
        "total_length-nopunct": 10345,
        "mean_pred_length-nopunct": 9.623255813953488,
        "std_pred_length-nopunct": 2.575812105788515,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.2457225712904785,
        "vocab_size-1-nopunct": 2542,
        "unique-1-nopunct": 1330,
        "entropy-1-nopunct": 9.683823323436306,
        "distinct-2-nopunct": 0.5525350593311759,
        "vocab_size-2-nopunct": 5122,
        "unique-2-nopunct": 3724,
        "entropy-2-nopunct": 11.705222285954685,
        "cond_entropy-2-nopunct": 2.2461825212475612,
        "distinct-3-nopunct": 0.7348383160463697,
        "vocab_size-3-nopunct": 6022,
        "unique-3-nopunct": 4976,
        "entropy-3-nopunct": 12.27165502017225,
        "cond_entropy-3-nopunct": 0.696839452032133,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16022900210160157,
            "2": 0.34919524142757175,
            "3": 0.4830022918258212,
            "4": 0.6363636363636364,
            "5": 0.6216216216216216,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "nist": 1.5954590269409432,
        "rouge1": {
            "precision": 0.27997,
            "recall": 0.22988,
            "fmeasure": 0.24294
        },
        "rouge2": {
            "precision": 0.12729,
            "recall": 0.10233,
            "fmeasure": 0.10901
        },
        "rougeL": {
            "precision": 0.27428,
            "recall": 0.22497,
            "fmeasure": 0.23771
        },
        "rougeLsum": {
            "precision": 0.27428,
            "recall": 0.22497,
            "fmeasure": 0.23771
        },
        "bleu": 21.08629,
        "meteor": 0.3890351353435059,
        "bertscore": {
            "precision": 0.94947,
            "recall": 0.91198,
            "f1": 0.92949
        },
        "nubia": {
            "semantic_relation": 3.58283,
            "contradiction": 21.93375,
            "irrelevancy": 22.79978,
            "logical_agreement": 55.26647,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.725,
            "nubia_score": 0.69305
        },
        "bleurt": 0.0902
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 41,
        "msttr-100": 0.548,
        "msttr-100_nopunct": 0.57222,
        "total_length": 1068,
        "mean_pred_length": 26.048780487804876,
        "std_pred_length": 2.1747017683081715,
        "median_pred_length": 26.0,
        "min_pred_length": 22,
        "max_pred_length": 31,
        "distinct-1": 0.32771535580524347,
        "vocab_size-1": 350,
        "unique-1": 204,
        "entropy-1": 7.210663874583008,
        "distinct-2": 0.6222005842259006,
        "vocab_size-2": 639,
        "unique-2": 460,
        "entropy-2": 8.977361463137358,
        "cond_entropy-2": 1.8065106435592853,
        "distinct-3": 0.7535496957403651,
        "vocab_size-3": 743,
        "unique-3": 601,
        "entropy-3": 9.340691760882327,
        "cond_entropy-3": 0.39655683844204515,
        "total_length-nopunct": 982,
        "mean_pred_length-nopunct": 23.951219512195124,
        "std_pred_length-nopunct": 1.8734501824069778,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.3513238289205703,
        "vocab_size-1-nopunct": 345,
        "unique-1-nopunct": 204,
        "entropy-1-nopunct": 7.273351269595888,
        "distinct-2-nopunct": 0.6429330499468651,
        "vocab_size-2-nopunct": 605,
        "unique-2-nopunct": 445,
        "entropy-2-nopunct": 8.928755784903798,
        "cond_entropy-2-nopunct": 1.7110815735819982,
        "distinct-3-nopunct": 0.77,
        "vocab_size-3-nopunct": 693,
        "unique-3-nopunct": 574,
        "entropy-3-nopunct": 9.251940795710892,
        "cond_entropy-3-nopunct": 0.35605306662692293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.13293051359516617,
            "2": 0.3112244897959184,
            "3": 0.5760626398210291
        },
        "nist": 1.5961994965200743,
        "rouge1": {
            "precision": 0.77698,
            "recall": 0.45132,
            "fmeasure": 0.56614
        },
        "rouge2": {
            "precision": 0.45921,
            "recall": 0.25928,
            "fmeasure": 0.32844
        },
        "rougeL": {
            "precision": 0.59667,
            "recall": 0.34513,
            "fmeasure": 0.43355
        },
        "rougeLsum": {
            "precision": 0.59667,
            "recall": 0.34513,
            "fmeasure": 0.43355
        },
        "bleu": 23.20577,
        "meteor": 0.22926450508798618,
        "bertscore": {
            "precision": 0.89725,
            "recall": 0.82407,
            "f1": 0.85803
        },
        "nubia": {
            "semantic_relation": 3.17583,
            "contradiction": 10.28031,
            "irrelevancy": 13.79964,
            "logical_agreement": 75.92005,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.50644,
            "nubia_score": 0.34152
        },
        "bleurt": -0.45181
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 7.5,
        "std_pred_length": 1.5,
        "median_pred_length": 7.0,
        "min_pred_length": 6,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 27,
        "unique-1": 26,
        "entropy-1": 4.640223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": -0.20645087746742646,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.24100809950379512,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 6.25,
        "std_pred_length-nopunct": 1.6393596310755,
        "median_pred_length-nopunct": 5.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.643856189774723,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.25153876699596434,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.3048545815284209,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.5333333333333333,
            "2": 0.07692307692307693,
            "3": 1.0
        },
        "nist": 3.1949211813603555,
        "rouge1": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.125,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "bleu": 45.43853,
        "meteor": 0.648621926599067,
        "bertscore": {
            "precision": 0.95994,
            "recall": 0.95889,
            "f1": 0.95572
        },
        "nubia": {
            "semantic_relation": 4.26036,
            "contradiction": 28.65352,
            "irrelevancy": 15.96335,
            "logical_agreement": 55.38313,
            "grammar_ref": 3.0388,
            "grammar_hyp": 3.00091,
            "nubia_score": 0.86038
        },
        "bleurt": 0.35593
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 158,
        "msttr-100": 0.7196,
        "msttr-100_nopunct": 0.77,
        "total_length": 2553,
        "mean_pred_length": 16.158227848101266,
        "std_pred_length": 5.04476436440683,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.4144144144144144,
        "vocab_size-1": 1058,
        "unique-1": 828,
        "entropy-1": 8.369011945315158,
        "distinct-2": 0.7799582463465553,
        "vocab_size-2": 1868,
        "unique-2": 1650,
        "entropy-2": 10.551150552399553,
        "cond_entropy-2": 1.9144820186306863,
        "distinct-3": 0.9012069736253912,
        "vocab_size-3": 2016,
        "unique-3": 1905,
        "entropy-3": 10.862097962369493,
        "cond_entropy-3": 0.32691879833063486,
        "total_length-nopunct": 2229,
        "mean_pred_length-nopunct": 14.10759493670886,
        "std_pred_length-nopunct": 4.474379163550499,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4697173620457604,
        "vocab_size-1-nopunct": 1047,
        "unique-1-nopunct": 825,
        "entropy-1-nopunct": 8.653881655287975,
        "distinct-2-nopunct": 0.7991308546595848,
        "vocab_size-2-nopunct": 1655,
        "unique-2-nopunct": 1483,
        "entropy-2-nopunct": 10.391892466331962,
        "cond_entropy-2-nopunct": 1.8606630254203103,
        "distinct-3-nopunct": 0.9069524307370622,
        "vocab_size-3-nopunct": 1735,
        "unique-3-nopunct": 1642,
        "entropy-3-nopunct": 10.658638833177871,
        "cond_entropy-3-nopunct": 0.30121324364568025,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26325088339222613,
            "2": 0.4762845849802372,
            "3": 0.741390106449593
        },
        "nist": 7.749910586973603,
        "rouge1": {
            "precision": 0.73921,
            "recall": 0.71678,
            "fmeasure": 0.71617
        },
        "rouge2": {
            "precision": 0.49314,
            "recall": 0.47488,
            "fmeasure": 0.47535
        },
        "rougeL": {
            "precision": 0.61914,
            "recall": 0.60749,
            "fmeasure": 0.60309
        },
        "rougeLsum": {
            "precision": 0.61914,
            "recall": 0.60749,
            "fmeasure": 0.60309
        },
        "bleu": 43.28766,
        "meteor": 0.38595019859721674,
        "bertscore": {
            "precision": 0.92656,
            "recall": 0.92047,
            "f1": 0.92194
        },
        "nubia": {
            "semantic_relation": 4.09718,
            "contradiction": 9.98629,
            "irrelevancy": 31.82959,
            "logical_agreement": 58.18412,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.5636,
            "nubia_score": 0.71751
        },
        "bleurt": 0.22864
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.71,
        "total_length": 217,
        "mean_pred_length": 11.421052631578947,
        "std_pred_length": 3.77409158778896,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 18,
        "distinct-1": 0.5299539170506913,
        "vocab_size-1": 115,
        "unique-1": 76,
        "entropy-1": 6.389110837227914,
        "distinct-2": 0.797979797979798,
        "vocab_size-2": 158,
        "unique-2": 127,
        "entropy-2": 7.188527263942507,
        "cond_entropy-2": 0.7003664693632127,
        "distinct-3": 0.8659217877094972,
        "vocab_size-3": 155,
        "unique-3": 135,
        "entropy-3": 7.19879035822149,
        "cond_entropy-3": 0.04588185275163247,
        "total_length-nopunct": 181,
        "mean_pred_length-nopunct": 9.526315789473685,
        "std_pred_length-nopunct": 3.484830601525652,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6077348066298343,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.454466727169474,
        "distinct-2-nopunct": 0.8271604938271605,
        "vocab_size-2-nopunct": 134,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.9631861139422995,
        "cond_entropy-2-nopunct": 0.5928760864510058,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 130,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 6.9727742213786525,
        "cond_entropy-3-nopunct": 0.05264135142166956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2147239263803681,
            "2": 0.4791666666666667,
            "3": 0.5652173913043478
        },
        "nist": 3.5304433418197174,
        "rouge1": {
            "precision": 0.28947,
            "recall": 0.21554,
            "fmeasure": 0.23322
        },
        "rouge2": {
            "precision": 0.2193,
            "recall": 0.19211,
            "fmeasure": 0.20175
        },
        "rougeL": {
            "precision": 0.28947,
            "recall": 0.21554,
            "fmeasure": 0.23322
        },
        "rougeLsum": {
            "precision": 0.28947,
            "recall": 0.21554,
            "fmeasure": 0.23322
        },
        "bleu": 33.89683,
        "meteor": 0.5105416340178381,
        "bertscore": {
            "precision": 0.95091,
            "recall": 0.92982,
            "f1": 0.93932
        },
        "nubia": {
            "semantic_relation": 3.68467,
            "contradiction": 30.83512,
            "irrelevancy": 20.65045,
            "logical_agreement": 48.51443,
            "grammar_ref": 2.97301,
            "grammar_hyp": 2.94286,
            "nubia_score": 0.71972
        },
        "bleurt": 0.10472
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "msttr-100": 0.72081,
        "msttr-100_nopunct": 0.75778,
        "total_length": 6220,
        "mean_pred_length": 17.32590529247911,
        "std_pred_length": 6.346729265524138,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3614147909967846,
        "vocab_size-1": 2248,
        "unique-1": 1678,
        "entropy-1": 8.922262223949891,
        "distinct-2": 0.8072001364954786,
        "vocab_size-2": 4731,
        "unique-2": 4365,
        "entropy-2": 11.786488743529691,
        "cond_entropy-2": 2.662557832351336,
        "distinct-3": 0.9445656125045439,
        "vocab_size-3": 5197,
        "unique-3": 5090,
        "entropy-3": 12.199456922492747,
        "cond_entropy-3": 0.44125795795947637,
        "total_length-nopunct": 5489,
        "mean_pred_length-nopunct": 15.289693593314762,
        "std_pred_length-nopunct": 5.612330204464295,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.40754235744215705,
        "vocab_size-1-nopunct": 2237,
        "unique-1-nopunct": 1676,
        "entropy-1-nopunct": 9.243357503638965,
        "distinct-2-nopunct": 0.8450292397660819,
        "vocab_size-2-nopunct": 4335,
        "unique-2-nopunct": 4024,
        "entropy-2-nopunct": 11.815310078129672,
        "cond_entropy-2-nopunct": 2.7056082993098443,
        "distinct-3-nopunct": 0.9775728358834626,
        "vocab_size-3-nopunct": 4664,
        "unique-3-nopunct": 4581,
        "entropy-3-nopunct": 12.170552195890444,
        "cond_entropy-3-nopunct": 0.3818445589453309,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "local_recall": {
            "1": 0.050628019323671496,
            "2": 0.12980769230769232,
            "3": 0.19577960140679954,
            "4": 0.28611898016997167,
            "5": 0.3426294820717131,
            "6": 0.3977832512315271,
            "7": 0.4634703196347032,
            "8": 0.6091269841269841,
            "9": 0.7402877697841727
        },
        "nist": 8.003000277946018,
        "rouge1": {
            "precision": 0.64714,
            "recall": 0.61101,
            "fmeasure": 0.61259
        },
        "rouge2": {
            "precision": 0.42271,
            "recall": 0.39961,
            "fmeasure": 0.39649
        },
        "rougeL": {
            "precision": 0.59708,
            "recall": 0.56446,
            "fmeasure": 0.56408
        },
        "rougeLsum": {
            "precision": 0.59708,
            "recall": 0.56446,
            "fmeasure": 0.56408
        },
        "bleu": 37.36384,
        "sari": 42.02344,
        "meteor": 0.3129068502487501,
        "bertscore": {
            "precision": 0.89266,
            "recall": 0.89468,
            "f1": 0.8887
        },
        "nubia": {
            "semantic_relation": 3.32991,
            "contradiction": 13.66457,
            "irrelevancy": 38.1915,
            "logical_agreement": 48.14393,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.15769,
            "nubia_score": 0.4301
        },
        "bleurt": -0.26781
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 10.25,
        "std_pred_length": 2.165063509461097,
        "median_pred_length": 10.5,
        "min_pred_length": 7,
        "max_pred_length": 13,
        "distinct-1": 0.7560975609756098,
        "vocab_size-1": 31,
        "unique-1": 22,
        "entropy-1": 4.851335236272632,
        "distinct-2": 0.8918918918918919,
        "vocab_size-2": 33,
        "unique-2": 29,
        "entropy-2": 4.993237149412737,
        "cond_entropy-2": 0.14257399620447325,
        "distinct-3": 0.9393939393939394,
        "vocab_size-3": 31,
        "unique-3": 29,
        "entropy-3": 4.923181998146335,
        "cond_entropy-3": -0.04384712505837499,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 2.0615528128088303,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.73452166477975,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.640223928941852,
        "cond_entropy-2-nopunct": -0.04723891230848745,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.546593564294937,
        "cond_entropy-3-nopunct": -0.05260472362127267,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.15384615384615385,
            "3": 0.34615384615384615
        },
        "nist": 1.1604780382545803,
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.52273,
            "fmeasure": 0.57698
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.08935,
            "fmeasure": 0.11203
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.44848,
            "fmeasure": 0.48651
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.44848,
            "fmeasure": 0.48651
        },
        "bleu": 7.53292,
        "meteor": 0.2797444526131828,
        "bertscore": {
            "precision": 0.94647,
            "recall": 0.90515,
            "f1": 0.92495
        },
        "nubia": {
            "semantic_relation": 3.42716,
            "contradiction": 24.42268,
            "irrelevancy": 21.45899,
            "logical_agreement": 54.11833,
            "grammar_ref": 2.93748,
            "grammar_hyp": 3.24481,
            "nubia_score": 0.57291
        },
        "bleurt": -0.10254
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.72778,
        "msttr-100_nopunct": 0.77467,
        "total_length": 1808,
        "mean_pred_length": 15.859649122807017,
        "std_pred_length": 5.1296817605583,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.4717920353982301,
        "vocab_size-1": 853,
        "unique-1": 671,
        "entropy-1": 8.279551921699467,
        "distinct-2": 0.8654073199527745,
        "vocab_size-2": 1466,
        "unique-2": 1339,
        "entropy-2": 10.35195188995022,
        "cond_entropy-2": 1.822600779230971,
        "distinct-3": 0.9607594936708861,
        "vocab_size-3": 1518,
        "unique-3": 1463,
        "entropy-3": 10.543573123120858,
        "cond_entropy-3": 0.19440711431155538,
        "total_length-nopunct": 1589,
        "mean_pred_length-nopunct": 13.93859649122807,
        "std_pred_length-nopunct": 4.861746649744665,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5317809943360604,
        "vocab_size-1-nopunct": 845,
        "unique-1-nopunct": 670,
        "entropy-1-nopunct": 8.552120870433678,
        "distinct-2-nopunct": 0.8779661016949153,
        "vocab_size-2-nopunct": 1295,
        "unique-2-nopunct": 1202,
        "entropy-2-nopunct": 10.171874586008949,
        "cond_entropy-2-nopunct": 1.725597874005158,
        "distinct-3-nopunct": 0.9691403379867745,
        "vocab_size-3-nopunct": 1319,
        "unique-3-nopunct": 1279,
        "entropy-3-nopunct": 10.34762271446911,
        "cond_entropy-3-nopunct": 0.19663513099982735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17661691542288557,
            "2": 0.4416243654822335,
            "3": 0.7576821773485514
        },
        "nist": 7.288161655327283,
        "rouge1": {
            "precision": 0.74397,
            "recall": 0.69434,
            "fmeasure": 0.70466
        },
        "rouge2": {
            "precision": 0.49527,
            "recall": 0.46272,
            "fmeasure": 0.46887
        },
        "rougeL": {
            "precision": 0.63877,
            "recall": 0.59513,
            "fmeasure": 0.60476
        },
        "rougeLsum": {
            "precision": 0.63877,
            "recall": 0.59513,
            "fmeasure": 0.60476
        },
        "bleu": 39.85688,
        "meteor": 0.37497715450867164,
        "bertscore": {
            "precision": 0.92157,
            "recall": 0.9185,
            "f1": 0.91859
        },
        "nubia": {
            "semantic_relation": 4.1084,
            "contradiction": 6.99894,
            "irrelevancy": 37.48448,
            "logical_agreement": 55.51658,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.65744,
            "nubia_score": 0.69546
        },
        "bleurt": 0.17069
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.76,
        "total_length": 301,
        "mean_pred_length": 16.72222222222222,
        "std_pred_length": 5.140315117400181,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.5980066445182725,
        "vocab_size-1": 180,
        "unique-1": 149,
        "entropy-1": 6.854945838817068,
        "distinct-2": 0.8975265017667845,
        "vocab_size-2": 254,
        "unique-2": 235,
        "entropy-2": 7.906551960198454,
        "cond_entropy-2": 0.9025465068335674,
        "distinct-3": 0.969811320754717,
        "vocab_size-3": 257,
        "unique-3": 250,
        "entropy-3": 7.986622558876313,
        "cond_entropy-3": 0.09624385561147461,
        "total_length-nopunct": 268,
        "mean_pred_length-nopunct": 14.88888888888889,
        "std_pred_length-nopunct": 4.794544224531426,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6492537313432836,
        "vocab_size-1-nopunct": 174,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 6.889487172672963,
        "distinct-2-nopunct": 0.884,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 202,
        "entropy-2-nopunct": 7.696247972721082,
        "cond_entropy-2-nopunct": 0.8691362953257049,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 224,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 7.785761652445813,
        "cond_entropy-3-nopunct": 0.10359424487225018,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2621359223300971,
            "2": 0.3409090909090909,
            "3": 0.7040816326530612
        },
        "nist": 5.671670714061985,
        "rouge1": {
            "precision": 0.71438,
            "recall": 0.65489,
            "fmeasure": 0.66922
        },
        "rouge2": {
            "precision": 0.44481,
            "recall": 0.4179,
            "fmeasure": 0.42278
        },
        "rougeL": {
            "precision": 0.59395,
            "recall": 0.55235,
            "fmeasure": 0.56151
        },
        "rougeLsum": {
            "precision": 0.59395,
            "recall": 0.55235,
            "fmeasure": 0.56151
        },
        "bleu": 36.38239,
        "meteor": 0.35318088430185296,
        "bertscore": {
            "precision": 0.91217,
            "recall": 0.90237,
            "f1": 0.90497
        },
        "nubia": {
            "semantic_relation": 3.86156,
            "contradiction": 9.50334,
            "irrelevancy": 54.96101,
            "logical_agreement": 35.53565,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.61025,
            "nubia_score": 0.63278
        },
        "bleurt": 0.05951
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 500,
        "msttr-100": 0.5945,
        "msttr-100_nopunct": 0.61981,
        "total_length": 6037,
        "mean_pred_length": 12.074,
        "std_pred_length": 3.620569568451903,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.09358953122411794,
        "vocab_size-1": 565,
        "unique-1": 231,
        "entropy-1": 6.948095770060592,
        "distinct-2": 0.2750586960447896,
        "vocab_size-2": 1523,
        "unique-2": 926,
        "entropy-2": 8.959013307895496,
        "cond_entropy-2": 1.7980428602916576,
        "distinct-3": 0.4129442128250943,
        "vocab_size-3": 2080,
        "unique-3": 1523,
        "entropy-3": 9.584593631502667,
        "cond_entropy-3": 0.6837471708177268,
        "total_length-nopunct": 5248,
        "mean_pred_length-nopunct": 10.496,
        "std_pred_length-nopunct": 3.333164262378918,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.10689786585365854,
        "vocab_size-1-nopunct": 561,
        "unique-1-nopunct": 231,
        "entropy-1-nopunct": 7.117683147147332,
        "distinct-2-nopunct": 0.2832771693344566,
        "vocab_size-2-nopunct": 1345,
        "unique-2-nopunct": 841,
        "entropy-2-nopunct": 8.773771286534904,
        "cond_entropy-2-nopunct": 1.8064045852162856,
        "distinct-3-nopunct": 0.4289077212806026,
        "vocab_size-3-nopunct": 1822,
        "unique-3-nopunct": 1374,
        "entropy-3-nopunct": 9.404118760910132,
        "cond_entropy-3-nopunct": 0.7325872681253414,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.47099930118798045
        },
        "nist": 3.472556126183151,
        "rouge1": {
            "precision": 0.44165,
            "recall": 0.51408,
            "fmeasure": 0.45714
        },
        "rouge2": {
            "precision": 0.23529,
            "recall": 0.27787,
            "fmeasure": 0.24442
        },
        "rougeL": {
            "precision": 0.38442,
            "recall": 0.44736,
            "fmeasure": 0.39804
        },
        "rougeLsum": {
            "precision": 0.38442,
            "recall": 0.44736,
            "fmeasure": 0.39804
        },
        "bleu": 14.57413,
        "meteor": 0.23268038824010334,
        "bertscore": {
            "precision": 0.88729,
            "recall": 0.8996,
            "f1": 0.89315
        },
        "nubia": {
            "semantic_relation": 3.14593,
            "contradiction": 18.53941,
            "irrelevancy": 35.32668,
            "logical_agreement": 46.1339,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.51692,
            "nubia_score": 0.4564
        },
        "bleurt": -0.19619
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 103,
        "msttr-100": 0.70353,
        "msttr-100_nopunct": 0.752,
        "total_length": 1749,
        "mean_pred_length": 16.980582524271846,
        "std_pred_length": 5.380620714407954,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.4339622641509434,
        "vocab_size-1": 759,
        "unique-1": 584,
        "entropy-1": 8.055187755332883,
        "distinct-2": 0.7976913730255164,
        "vocab_size-2": 1313,
        "unique-2": 1169,
        "entropy-2": 10.06951602095393,
        "cond_entropy-2": 1.7856270243856887,
        "distinct-3": 0.9021386908619572,
        "vocab_size-3": 1392,
        "unique-3": 1321,
        "entropy-3": 10.3107042308972,
        "cond_entropy-3": 0.22955220554433345,
        "total_length-nopunct": 1537,
        "mean_pred_length-nopunct": 14.922330097087379,
        "std_pred_length-nopunct": 5.189027483173797,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4886141834743006,
        "vocab_size-1-nopunct": 751,
        "unique-1-nopunct": 581,
        "entropy-1-nopunct": 8.287419293591993,
        "distinct-2-nopunct": 0.8124128312412832,
        "vocab_size-2-nopunct": 1165,
        "unique-2-nopunct": 1061,
        "entropy-2-nopunct": 9.892325205713668,
        "cond_entropy-2-nopunct": 1.7150224216595578,
        "distinct-3-nopunct": 0.9015777610818934,
        "vocab_size-3-nopunct": 1200,
        "unique-3-nopunct": 1146,
        "entropy-3-nopunct": 10.084870765015882,
        "cond_entropy-3-nopunct": 0.23098668501452216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2073170731707317,
            "2": 0.5185185185185185,
            "3": 0.8051601423487544
        },
        "nist": 7.988844207690998,
        "rouge1": {
            "precision": 0.76515,
            "recall": 0.75215,
            "fmeasure": 0.74846
        },
        "rouge2": {
            "precision": 0.55373,
            "recall": 0.54795,
            "fmeasure": 0.5434
        },
        "rougeL": {
            "precision": 0.67194,
            "recall": 0.66773,
            "fmeasure": 0.66074
        },
        "rougeLsum": {
            "precision": 0.67194,
            "recall": 0.66773,
            "fmeasure": 0.66074
        },
        "bleu": 53.17203,
        "meteor": 0.416300244629705,
        "bertscore": {
            "precision": 0.93503,
            "recall": 0.93037,
            "f1": 0.93141
        },
        "nubia": {
            "semantic_relation": 4.19762,
            "contradiction": 13.92623,
            "irrelevancy": 26.59214,
            "logical_agreement": 59.48163,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.4777,
            "nubia_score": 0.74043
        },
        "bleurt": 0.27981
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.562,
        "msttr-100_nopunct": 0.585,
        "total_length": 566,
        "mean_pred_length": 16.17142857142857,
        "std_pred_length": 4.866713260423679,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.3498233215547703,
        "vocab_size-1": 198,
        "unique-1": 156,
        "entropy-1": 6.340829463592105,
        "distinct-2": 0.6610169491525424,
        "vocab_size-2": 351,
        "unique-2": 299,
        "entropy-2": 7.978746225179876,
        "cond_entropy-2": 1.4904607146051163,
        "distinct-3": 0.7923387096774194,
        "vocab_size-3": 393,
        "unique-3": 357,
        "entropy-3": 8.322062562119463,
        "cond_entropy-3": 0.3611164909612707,
        "total_length-nopunct": 476,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 4.237249781908745,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4054621848739496,
        "vocab_size-1-nopunct": 193,
        "unique-1-nopunct": 156,
        "entropy-1-nopunct": 6.4034609212130675,
        "distinct-2-nopunct": 0.7006802721088435,
        "vocab_size-2-nopunct": 309,
        "unique-2-nopunct": 268,
        "entropy-2-nopunct": 7.834507623140819,
        "cond_entropy-2-nopunct": 1.5263642885613162,
        "distinct-3-nopunct": 0.8004926108374384,
        "vocab_size-3-nopunct": 325,
        "unique-3-nopunct": 297,
        "entropy-3-nopunct": 8.05671577619289,
        "cond_entropy-3-nopunct": 0.29138186680374434,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5192307692307693,
            "3": 0.7838616714697406
        },
        "nist": 6.567318507874562,
        "rouge1": {
            "precision": 0.77468,
            "recall": 0.76415,
            "fmeasure": 0.75842
        },
        "rouge2": {
            "precision": 0.54851,
            "recall": 0.53748,
            "fmeasure": 0.53727
        },
        "rougeL": {
            "precision": 0.67242,
            "recall": 0.66299,
            "fmeasure": 0.65889
        },
        "rougeLsum": {
            "precision": 0.67242,
            "recall": 0.66299,
            "fmeasure": 0.65889
        },
        "bleu": 50.85357,
        "meteor": 0.4249383518955427,
        "bertscore": {
            "precision": 0.93904,
            "recall": 0.93823,
            "f1": 0.93726
        },
        "nubia": {
            "semantic_relation": 4.21196,
            "contradiction": 4.08967,
            "irrelevancy": 17.17431,
            "logical_agreement": 78.73602,
            "grammar_ref": 4.23324,
            "grammar_hyp": 3.9652,
            "nubia_score": 0.78634
        },
        "bleurt": 0.43031
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 55,
        "msttr-100": 0.7425,
        "msttr-100_nopunct": 0.78714,
        "total_length": 863,
        "mean_pred_length": 15.690909090909091,
        "std_pred_length": 4.8425114718885185,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5283893395133256,
        "vocab_size-1": 456,
        "unique-1": 374,
        "entropy-1": 7.773704037788921,
        "distinct-2": 0.8861386138613861,
        "vocab_size-2": 716,
        "unique-2": 665,
        "entropy-2": 9.36508140853425,
        "cond_entropy-2": 1.3572998599562063,
        "distinct-3": 0.9641434262948207,
        "vocab_size-3": 726,
        "unique-3": 705,
        "entropy-3": 9.478777867403693,
        "cond_entropy-3": 0.1000387990094238,
        "total_length-nopunct": 749,
        "mean_pred_length-nopunct": 13.618181818181819,
        "std_pred_length-nopunct": 4.367195518203287,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5994659546061415,
        "vocab_size-1-nopunct": 449,
        "unique-1-nopunct": 373,
        "entropy-1-nopunct": 7.984872796158086,
        "distinct-2-nopunct": 0.899135446685879,
        "vocab_size-2-nopunct": 624,
        "unique-2-nopunct": 587,
        "entropy-2-nopunct": 9.175199701271444,
        "cond_entropy-2-nopunct": 1.2843648210707554,
        "distinct-3-nopunct": 0.9702660406885759,
        "vocab_size-3-nopunct": 620,
        "unique-3-nopunct": 606,
        "entropy-3-nopunct": 9.254297414357346,
        "cond_entropy-3-nopunct": 0.0970907777522577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29901960784313725,
            "2": 0.41530054644808745,
            "3": 0.7397769516728625
        },
        "nist": 6.971411460206739,
        "rouge1": {
            "precision": 0.74387,
            "recall": 0.69899,
            "fmeasure": 0.70893
        },
        "rouge2": {
            "precision": 0.50189,
            "recall": 0.46889,
            "fmeasure": 0.47668
        },
        "rougeL": {
            "precision": 0.64388,
            "recall": 0.61432,
            "fmeasure": 0.6186
        },
        "rougeLsum": {
            "precision": 0.64388,
            "recall": 0.61432,
            "fmeasure": 0.6186
        },
        "bleu": 43.94997,
        "meteor": 0.3771292661370555,
        "bertscore": {
            "precision": 0.92508,
            "recall": 0.91862,
            "f1": 0.92086
        },
        "nubia": {
            "semantic_relation": 4.15559,
            "contradiction": 4.54833,
            "irrelevancy": 35.89377,
            "logical_agreement": 59.5579,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.81698,
            "nubia_score": 0.71393
        },
        "bleurt": 0.20894
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 349,
        "msttr-100": 0.66667,
        "msttr-100_nopunct": 0.69275,
        "total_length": 5778,
        "mean_pred_length": 16.555873925501434,
        "std_pred_length": 3.8822793567906118,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.16960886119764623,
        "vocab_size-1": 980,
        "unique-1": 410,
        "entropy-1": 7.8443200094013585,
        "distinct-2": 0.44207036286608953,
        "vocab_size-2": 2400,
        "unique-2": 1477,
        "entropy-2": 10.511021366493686,
        "cond_entropy-2": 2.4409881040442456,
        "distinct-3": 0.6208661417322835,
        "vocab_size-3": 3154,
        "unique-3": 2313,
        "entropy-3": 11.229687016156998,
        "cond_entropy-3": 0.7939490990374876,
        "total_length-nopunct": 5168,
        "mean_pred_length-nopunct": 14.808022922636104,
        "std_pred_length-nopunct": 3.607592096260179,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.18808049535603716,
        "vocab_size-1-nopunct": 972,
        "unique-1-nopunct": 409,
        "entropy-1-nopunct": 8.049414198552428,
        "distinct-2-nopunct": 0.4324548661548039,
        "vocab_size-2-nopunct": 2084,
        "unique-2-nopunct": 1288,
        "entropy-2-nopunct": 10.283624116225,
        "cond_entropy-2-nopunct": 2.423556138233192,
        "distinct-3-nopunct": 0.6118568232662193,
        "vocab_size-3-nopunct": 2735,
        "unique-3-nopunct": 2004,
        "entropy-3-nopunct": 11.007331377676847,
        "cond_entropy-3-nopunct": 0.797272345928108,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23894862604540024,
            "2": 0.5660377358490566,
            "3": 0.8868762816131237,
            "4": 1.0
        },
        "nist": 8.967946797807025,
        "rouge1": {
            "precision": 0.77676,
            "recall": 0.78159,
            "fmeasure": 0.77243
        },
        "rouge2": {
            "precision": 0.54487,
            "recall": 0.54662,
            "fmeasure": 0.53977
        },
        "rougeL": {
            "precision": 0.66011,
            "recall": 0.66101,
            "fmeasure": 0.65357
        },
        "rougeLsum": {
            "precision": 0.66011,
            "recall": 0.66101,
            "fmeasure": 0.65357
        },
        "bleu": 52.66316,
        "meteor": 0.4243590204692044,
        "bertscore": {
            "precision": 0.93358,
            "recall": 0.93449,
            "f1": 0.93266
        },
        "nubia": {
            "semantic_relation": 4.63031,
            "contradiction": 5.81823,
            "irrelevancy": 6.41042,
            "logical_agreement": 87.77135,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.80798,
            "nubia_score": 0.83522
        },
        "bleurt": 0.29148
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 339,
        "msttr-100": 0.68267,
        "msttr-100_nopunct": 0.7528,
        "total_length": 3046,
        "mean_pred_length": 8.985250737463128,
        "std_pred_length": 2.5813754615347824,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 19,
        "distinct-1": 0.39001969796454367,
        "vocab_size-1": 1188,
        "unique-1": 800,
        "entropy-1": 8.672432879005447,
        "distinct-2": 0.7403029183598079,
        "vocab_size-2": 2004,
        "unique-2": 1633,
        "entropy-2": 10.697292109142136,
        "cond_entropy-2": 1.607358878402557,
        "distinct-3": 0.8800675675675675,
        "vocab_size-3": 2084,
        "unique-3": 1871,
        "entropy-3": 10.93852579363357,
        "cond_entropy-3": 0.27116867476033946,
        "total_length-nopunct": 2503,
        "mean_pred_length-nopunct": 7.383480825958702,
        "std_pred_length-nopunct": 2.3799478766666415,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.47263284059129046,
        "vocab_size-1-nopunct": 1183,
        "unique-1-nopunct": 800,
        "entropy-1-nopunct": 9.299527277715464,
        "distinct-2-nopunct": 0.7634011090573013,
        "vocab_size-2-nopunct": 1652,
        "unique-2-nopunct": 1373,
        "entropy-2-nopunct": 10.440985523837153,
        "cond_entropy-2-nopunct": 1.309111105840835,
        "distinct-3-nopunct": 0.890958904109589,
        "vocab_size-3-nopunct": 1626,
        "unique-3-nopunct": 1478,
        "entropy-3-nopunct": 10.58457196099535,
        "cond_entropy-3-nopunct": 0.22030330152107094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.3094209161624892,
            "2": 0.6029011786038078,
            "3": 0.7157360406091371,
            "4": 0.7222222222222222,
            "5": 0.7333333333333333,
            "6": 0.9166666666666666,
            "7": 1.0
        },
        "nist": 7.880193681383141,
        "rouge1": {
            "precision": 0.262,
            "recall": 0.26222,
            "fmeasure": 0.26012
        },
        "rouge2": {
            "precision": 0.13375,
            "recall": 0.13127,
            "fmeasure": 0.13199
        },
        "rougeL": {
            "precision": 0.262,
            "recall": 0.26222,
            "fmeasure": 0.26012
        },
        "rougeLsum": {
            "precision": 0.262,
            "recall": 0.26222,
            "fmeasure": 0.26012
        },
        "bleu": 50.53525,
        "meteor": 0.6610166042391017,
        "bertscore": {
            "precision": 0.96513,
            "recall": 0.95675,
            "f1": 0.9603
        },
        "nubia": {
            "semantic_relation": 4.0669,
            "contradiction": 20.74483,
            "irrelevancy": 21.65641,
            "logical_agreement": 57.59876,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.85385,
            "nubia_score": 0.81777
        },
        "bleurt": 0.32508
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 316,
        "msttr-100": 0.67605,
        "msttr-100_nopunct": 0.7197,
        "total_length": 3888,
        "mean_pred_length": 12.30379746835443,
        "std_pred_length": 2.3819172704003733,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.3351337448559671,
        "vocab_size-1": 1303,
        "unique-1": 816,
        "entropy-1": 8.719394704951826,
        "distinct-2": 0.6595744680851063,
        "vocab_size-2": 2356,
        "unique-2": 1792,
        "entropy-2": 10.806755694385936,
        "cond_entropy-2": 2.200869463225016,
        "distinct-3": 0.8304668304668305,
        "vocab_size-3": 2704,
        "unique-3": 2318,
        "entropy-3": 11.28016431598485,
        "cond_entropy-3": 0.5400741660411008,
        "total_length-nopunct": 3337,
        "mean_pred_length-nopunct": 10.560126582278482,
        "std_pred_length-nopunct": 1.9469690782269407,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.38867246029367697,
        "vocab_size-1-nopunct": 1297,
        "unique-1-nopunct": 815,
        "entropy-1-nopunct": 9.15551447203786,
        "distinct-2-nopunct": 0.7073816617014234,
        "vocab_size-2-nopunct": 2137,
        "unique-2-nopunct": 1694,
        "entropy-2-nopunct": 10.750096649072558,
        "cond_entropy-2-nopunct": 1.747715415687065,
        "distinct-3-nopunct": 0.8573012939001848,
        "vocab_size-3-nopunct": 2319,
        "unique-3-nopunct": 2046,
        "entropy-3-nopunct": 11.07536942015659,
        "cond_entropy-3-nopunct": 0.3985167804076738,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.15955951265229615,
            "2": 0.3897732754462132,
            "3": 0.569718309859155,
            "4": 0.8421052631578947,
            "5": 0.5454545454545454,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 2.422814530492762,
        "rouge1": {
            "precision": 0.26364,
            "recall": 0.23625,
            "fmeasure": 0.24217
        },
        "rouge2": {
            "precision": 0.10476,
            "recall": 0.09356,
            "fmeasure": 0.09652
        },
        "rougeL": {
            "precision": 0.25574,
            "recall": 0.22889,
            "fmeasure": 0.2345
        },
        "rougeLsum": {
            "precision": 0.25574,
            "recall": 0.22889,
            "fmeasure": 0.2345
        },
        "bleu": 23.55571,
        "meteor": 0.3985657738338519,
        "bertscore": {
            "precision": 0.94596,
            "recall": 0.90964,
            "f1": 0.92656
        },
        "nubia": {
            "semantic_relation": 3.52203,
            "contradiction": 22.97854,
            "irrelevancy": 23.57023,
            "logical_agreement": 53.45123,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.68299,
            "nubia_score": 0.6754
        },
        "bleurt": 0.01359
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 169,
        "mean_pred_length": 15.363636363636363,
        "std_pred_length": 4.578064840732426,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.6390532544378699,
        "vocab_size-1": 108,
        "unique-1": 89,
        "entropy-1": 6.1984555148966916,
        "distinct-2": 0.9367088607594937,
        "vocab_size-2": 148,
        "unique-2": 140,
        "entropy-2": 7.1645402418480035,
        "cond_entropy-2": 0.8395491711688038,
        "distinct-3": 0.9931972789115646,
        "vocab_size-3": 146,
        "unique-3": 145,
        "entropy-3": 7.1860669026594834,
        "cond_entropy-3": 0.03194601842796882,
        "total_length-nopunct": 147,
        "mean_pred_length-nopunct": 13.363636363636363,
        "std_pred_length-nopunct": 4.183793999637764,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7006802721088435,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.189600326054408,
        "distinct-2-nopunct": 0.9338235294117647,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 6.940404017720915,
        "cond_entropy-2-nopunct": 0.8325006931856431,
        "distinct-3-nopunct": 0.992,
        "vocab_size-3-nopunct": 124,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.949784284662096,
        "cond_entropy-3-nopunct": 0.022321443411747514,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5806451612903226,
            "3": 0.8369565217391305
        },
        "nist": 6.0765100843692155,
        "rouge1": {
            "precision": 0.76712,
            "recall": 0.75994,
            "fmeasure": 0.75413
        },
        "rouge2": {
            "precision": 0.59569,
            "recall": 0.56868,
            "fmeasure": 0.57264
        },
        "rougeL": {
            "precision": 0.66743,
            "recall": 0.66734,
            "fmeasure": 0.65778
        },
        "rougeLsum": {
            "precision": 0.66743,
            "recall": 0.66734,
            "fmeasure": 0.65778
        },
        "bleu": 54.60065,
        "meteor": 0.42458544559903727,
        "bertscore": {
            "precision": 0.938,
            "recall": 0.93517,
            "f1": 0.93312
        },
        "nubia": {
            "semantic_relation": 4.1018,
            "contradiction": 1.6838,
            "irrelevancy": 45.54245,
            "logical_agreement": 52.77374,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.27116,
            "nubia_score": 0.75064
        },
        "bleurt": 0.20368
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.70833,
        "msttr-100_nopunct": 0.75727,
        "total_length": 1299,
        "mean_pred_length": 16.443037974683545,
        "std_pred_length": 5.319528948982631,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.41416474210931487,
        "vocab_size-1": 538,
        "unique-1": 417,
        "entropy-1": 7.712743690278598,
        "distinct-2": 0.740983606557377,
        "vocab_size-2": 904,
        "unique-2": 803,
        "entropy-2": 9.423997126193136,
        "cond_entropy-2": 1.5282132913471786,
        "distinct-3": 0.8475021910604733,
        "vocab_size-3": 967,
        "unique-3": 909,
        "entropy-3": 9.673975321396417,
        "cond_entropy-3": 0.2813351979400015,
        "total_length-nopunct": 1144,
        "mean_pred_length-nopunct": 14.481012658227849,
        "std_pred_length-nopunct": 4.877903574110581,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.46503496503496505,
        "vocab_size-1-nopunct": 532,
        "unique-1-nopunct": 417,
        "entropy-1-nopunct": 7.903522391246381,
        "distinct-2-nopunct": 0.7539906103286385,
        "vocab_size-2-nopunct": 803,
        "unique-2-nopunct": 722,
        "entropy-2-nopunct": 9.26310882226138,
        "cond_entropy-2-nopunct": 1.478520582881494,
        "distinct-3-nopunct": 0.8519269776876268,
        "vocab_size-3-nopunct": 840,
        "unique-3-nopunct": 791,
        "entropy-3-nopunct": 9.480121512876497,
        "cond_entropy-3-nopunct": 0.26606629552422795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1417004048582996,
            "2": 0.4782608695652174,
            "3": 0.7622298065984073
        },
        "nist": 6.939912986344877,
        "rouge1": {
            "precision": 0.76756,
            "recall": 0.71331,
            "fmeasure": 0.72993
        },
        "rouge2": {
            "precision": 0.55064,
            "recall": 0.51541,
            "fmeasure": 0.52639
        },
        "rougeL": {
            "precision": 0.66116,
            "recall": 0.62042,
            "fmeasure": 0.63229
        },
        "rougeLsum": {
            "precision": 0.66116,
            "recall": 0.62042,
            "fmeasure": 0.63229
        },
        "bleu": 47.85744,
        "meteor": 0.37260101210569624,
        "bertscore": {
            "precision": 0.92968,
            "recall": 0.92251,
            "f1": 0.92342
        },
        "nubia": {
            "semantic_relation": 4.09502,
            "contradiction": 10.669,
            "irrelevancy": 26.48123,
            "logical_agreement": 62.84977,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.37594,
            "nubia_score": 0.72185
        },
        "bleurt": 0.26933
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 217,
        "msttr-100": 0.68346,
        "msttr-100_nopunct": 0.72783,
        "total_length": 2686,
        "mean_pred_length": 12.377880184331797,
        "std_pred_length": 2.4560785357277646,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.3857036485480268,
        "vocab_size-1": 1036,
        "unique-1": 680,
        "entropy-1": 8.599448246573937,
        "distinct-2": 0.7189145402997165,
        "vocab_size-2": 1775,
        "unique-2": 1420,
        "entropy-2": 10.518351667009311,
        "cond_entropy-2": 2.049968397479228,
        "distinct-3": 0.8672291296625222,
        "vocab_size-3": 1953,
        "unique-3": 1737,
        "entropy-3": 10.838335118948923,
        "cond_entropy-3": 0.37240058046864366,
        "total_length-nopunct": 2303,
        "mean_pred_length-nopunct": 10.612903225806452,
        "std_pred_length-nopunct": 2.0063078763694824,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.44680851063829785,
        "vocab_size-1-nopunct": 1029,
        "unique-1-nopunct": 680,
        "entropy-1-nopunct": 9.024150385243347,
        "distinct-2-nopunct": 0.7689357622243528,
        "vocab_size-2-nopunct": 1604,
        "unique-2-nopunct": 1338,
        "entropy-2-nopunct": 10.431722873463116,
        "cond_entropy-2-nopunct": 1.5280220070466528,
        "distinct-3-nopunct": 0.8908507223113965,
        "vocab_size-3-nopunct": 1665,
        "unique-3-nopunct": 1519,
        "entropy-3-nopunct": 10.620998842511787,
        "cond_entropy-3-nopunct": 0.23977999445244533,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.12883435582822086,
            "2": 0.31382636655948554,
            "3": 0.46661775495231106,
            "4": 0.3181818181818182
        },
        "nist": 1.139727702208005,
        "rouge1": {
            "precision": 0.27875,
            "recall": 0.21202,
            "fmeasure": 0.23313
        },
        "rouge2": {
            "precision": 0.12366,
            "recall": 0.08497,
            "fmeasure": 0.09758
        },
        "rougeL": {
            "precision": 0.27667,
            "recall": 0.21041,
            "fmeasure": 0.23133
        },
        "rougeLsum": {
            "precision": 0.27667,
            "recall": 0.21041,
            "fmeasure": 0.23133
        },
        "bleu": 18.00304,
        "meteor": 0.3508943747010877,
        "bertscore": {
            "precision": 0.94187,
            "recall": 0.89407,
            "f1": 0.91668
        },
        "nubia": {
            "semantic_relation": 3.38487,
            "contradiction": 22.34324,
            "irrelevancy": 22.82128,
            "logical_agreement": 54.83548,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.65317,
            "nubia_score": 0.63409
        },
        "bleurt": -0.02427
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.764,
        "total_length": 676,
        "mean_pred_length": 15.720930232558139,
        "std_pred_length": 5.414560822643813,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5281065088757396,
        "vocab_size-1": 357,
        "unique-1": 286,
        "entropy-1": 7.441594513425278,
        "distinct-2": 0.8799368088467614,
        "vocab_size-2": 557,
        "unique-2": 502,
        "entropy-2": 9.023867075711,
        "cond_entropy-2": 1.3550797620099517,
        "distinct-3": 0.9423728813559322,
        "vocab_size-3": 556,
        "unique-3": 526,
        "entropy-3": 9.082537245944208,
        "cond_entropy-3": 0.05083878190717961,
        "total_length-nopunct": 587,
        "mean_pred_length-nopunct": 13.651162790697674,
        "std_pred_length-nopunct": 4.694795341554367,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5945485519591142,
        "vocab_size-1-nopunct": 349,
        "unique-1-nopunct": 284,
        "entropy-1-nopunct": 7.61680584715561,
        "distinct-2-nopunct": 0.8970588235294118,
        "vocab_size-2-nopunct": 488,
        "unique-2-nopunct": 449,
        "entropy-2-nopunct": 8.839081562796736,
        "cond_entropy-2-nopunct": 1.301067864301092,
        "distinct-3-nopunct": 0.9620758483033932,
        "vocab_size-3-nopunct": 482,
        "unique-3-nopunct": 465,
        "entropy-3-nopunct": 8.888826473833848,
        "cond_entropy-3-nopunct": 0.04044460159732225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16379310344827586,
            "2": 0.45112781954887216,
            "3": 0.8066037735849056
        },
        "nist": 6.806963886289169,
        "rouge1": {
            "precision": 0.78422,
            "recall": 0.76377,
            "fmeasure": 0.76384
        },
        "rouge2": {
            "precision": 0.60213,
            "recall": 0.57385,
            "fmeasure": 0.58197
        },
        "rougeL": {
            "precision": 0.71245,
            "recall": 0.69412,
            "fmeasure": 0.69332
        },
        "rougeLsum": {
            "precision": 0.71245,
            "recall": 0.69412,
            "fmeasure": 0.69332
        },
        "bleu": 53.02309,
        "meteor": 0.40929677072636955,
        "bertscore": {
            "precision": 0.93031,
            "recall": 0.92759,
            "f1": 0.92675
        },
        "nubia": {
            "semantic_relation": 4.14988,
            "contradiction": 9.09407,
            "irrelevancy": 31.57971,
            "logical_agreement": 59.32622,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.48852,
            "nubia_score": 0.71969
        },
        "bleurt": 0.27115
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 143,
        "msttr-100": 0.67588,
        "msttr-100_nopunct": 0.716,
        "total_length": 1778,
        "mean_pred_length": 12.433566433566433,
        "std_pred_length": 2.546242097486638,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.40044994375703036,
        "vocab_size-1": 712,
        "unique-1": 466,
        "entropy-1": 8.25000519268996,
        "distinct-2": 0.7327217125382263,
        "vocab_size-2": 1198,
        "unique-2": 960,
        "entropy-2": 9.986309500373096,
        "cond_entropy-2": 1.875157100647722,
        "distinct-3": 0.8632707774798928,
        "vocab_size-3": 1288,
        "unique-3": 1141,
        "entropy-3": 10.235560982095325,
        "cond_entropy-3": 0.29530791586820104,
        "total_length-nopunct": 1523,
        "mean_pred_length-nopunct": 10.65034965034965,
        "std_pred_length-nopunct": 2.1197002732400643,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.46355876559422193,
        "vocab_size-1-nopunct": 706,
        "unique-1-nopunct": 466,
        "entropy-1-nopunct": 8.614335154373991,
        "distinct-2-nopunct": 0.7652173913043478,
        "vocab_size-2-nopunct": 1056,
        "unique-2-nopunct": 871,
        "entropy-2-nopunct": 9.840052901617694,
        "cond_entropy-2-nopunct": 1.362906362364529,
        "distinct-3-nopunct": 0.8730800323362975,
        "vocab_size-3-nopunct": 1080,
        "unique-3-nopunct": 970,
        "entropy-3-nopunct": 9.983868575992322,
        "cond_entropy-3-nopunct": 0.19609721233302646,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.11972103835722588,
            "2": 0.25221540558963873,
            "3": 0.3724007561436673
        },
        "nist": 0.16275859832000547,
        "rouge1": {
            "precision": 0.27168,
            "recall": 0.16663,
            "fmeasure": 0.19607
        },
        "rouge2": {
            "precision": 0.11519,
            "recall": 0.07225,
            "fmeasure": 0.08325
        },
        "rougeL": {
            "precision": 0.25221,
            "recall": 0.15129,
            "fmeasure": 0.1792
        },
        "rougeLsum": {
            "precision": 0.25221,
            "recall": 0.15129,
            "fmeasure": 0.1792
        },
        "bleu": 9.59746,
        "meteor": 0.2766306044329397,
        "bertscore": {
            "precision": 0.93754,
            "recall": 0.87319,
            "f1": 0.90359
        },
        "nubia": {
            "semantic_relation": 3.23092,
            "contradiction": 22.84485,
            "irrelevancy": 22.4126,
            "logical_agreement": 54.74255,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.69715,
            "nubia_score": 0.5842
        },
        "bleurt": -0.04661
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 56,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.752,
        "total_length": 668,
        "mean_pred_length": 11.928571428571429,
        "std_pred_length": 2.6783333227503823,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.5194610778443114,
        "vocab_size-1": 347,
        "unique-1": 243,
        "entropy-1": 7.672543423823362,
        "distinct-2": 0.8218954248366013,
        "vocab_size-2": 503,
        "unique-2": 433,
        "entropy-2": 8.829724959540716,
        "cond_entropy-2": 1.2733755931139437,
        "distinct-3": 0.9244604316546763,
        "vocab_size-3": 514,
        "unique-3": 483,
        "entropy-3": 8.949400312819684,
        "cond_entropy-3": 0.14836082352461283,
        "total_length-nopunct": 590,
        "mean_pred_length-nopunct": 10.535714285714286,
        "std_pred_length-nopunct": 2.146128455367659,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.5779661016949152,
        "vocab_size-1-nopunct": 341,
        "unique-1-nopunct": 243,
        "entropy-1-nopunct": 7.863128630887797,
        "distinct-2-nopunct": 0.8352059925093633,
        "vocab_size-2-nopunct": 446,
        "unique-2-nopunct": 388,
        "entropy-2-nopunct": 8.672184654566728,
        "cond_entropy-2-nopunct": 0.9135482571122092,
        "distinct-3-nopunct": 0.9246861924686193,
        "vocab_size-3-nopunct": 442,
        "unique-3-nopunct": 416,
        "entropy-3-nopunct": 8.730344266130757,
        "cond_entropy-3-nopunct": 0.09321532603838628,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.08999081726354453,
            "2": 0.2082670906200318,
            "3": 0.36684303350970016
        },
        "nist": 0.04621098162679808,
        "rouge1": {
            "precision": 0.42113,
            "recall": 0.23433,
            "fmeasure": 0.28276
        },
        "rouge2": {
            "precision": 0.21875,
            "recall": 0.14248,
            "fmeasure": 0.16284
        },
        "rougeL": {
            "precision": 0.40536,
            "recall": 0.22179,
            "fmeasure": 0.26909
        },
        "rougeLsum": {
            "precision": 0.40536,
            "recall": 0.22179,
            "fmeasure": 0.26909
        },
        "bleu": 7.22678,
        "meteor": 0.2663713458868998,
        "bertscore": {
            "precision": 0.94035,
            "recall": 0.86483,
            "f1": 0.90014
        },
        "nubia": {
            "semantic_relation": 3.08493,
            "contradiction": 21.83374,
            "irrelevancy": 23.7683,
            "logical_agreement": 54.39796,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.68424,
            "nubia_score": 0.60566
        },
        "bleurt": -0.04556
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.72277,
        "msttr-100_nopunct": 0.7731,
        "total_length": 4778,
        "mean_pred_length": 15.926666666666666,
        "std_pred_length": 5.205889826810484,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.37714524905818336,
        "vocab_size-1": 1802,
        "unique-1": 1378,
        "entropy-1": 8.790454073543836,
        "distinct-2": 0.7699866011612327,
        "vocab_size-2": 3448,
        "unique-2": 3048,
        "entropy-2": 11.385894039939798,
        "cond_entropy-2": 2.3221088823837235,
        "distinct-3": 0.9181426519865965,
        "vocab_size-3": 3836,
        "unique-3": 3641,
        "entropy-3": 11.822404345714203,
        "cond_entropy-3": 0.43340721762650625,
        "total_length-nopunct": 4208,
        "mean_pred_length-nopunct": 14.026666666666667,
        "std_pred_length-nopunct": 4.808945368327192,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.42609315589353614,
        "vocab_size-1-nopunct": 1793,
        "unique-1-nopunct": 1376,
        "entropy-1-nopunct": 9.149909471982197,
        "distinct-2-nopunct": 0.7998976458546572,
        "vocab_size-2-nopunct": 3126,
        "unique-2-nopunct": 2827,
        "entropy-2-nopunct": 11.261398818388146,
        "cond_entropy-2-nopunct": 2.2127094154300746,
        "distinct-3-nopunct": 0.9368070953436807,
        "vocab_size-3-nopunct": 3380,
        "unique-3-nopunct": 3235,
        "entropy-3-nopunct": 11.665313197420646,
        "cond_entropy-3-nopunct": 0.43483054590026854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18436406067677946,
            "2": 0.4186939820742638,
            "3": 0.8067073170731708
        },
        "nist": 8.701620468490827,
        "rouge1": {
            "precision": 0.79467,
            "recall": 0.77147,
            "fmeasure": 0.77283
        },
        "rouge2": {
            "precision": 0.57122,
            "recall": 0.5569,
            "fmeasure": 0.55606
        },
        "rougeL": {
            "precision": 0.69094,
            "recall": 0.67364,
            "fmeasure": 0.6729
        },
        "rougeLsum": {
            "precision": 0.69094,
            "recall": 0.67364,
            "fmeasure": 0.6729
        },
        "bleu": 47.68705,
        "meteor": 0.41110854707589106,
        "bertscore": {
            "precision": 0.94061,
            "recall": 0.93815,
            "f1": 0.93803
        },
        "nubia": {
            "semantic_relation": 4.38013,
            "contradiction": 5.68631,
            "irrelevancy": 25.16082,
            "logical_agreement": 69.15287,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.81259,
            "nubia_score": 0.77994
        },
        "bleurt": 0.36473
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.71923,
        "msttr-100_nopunct": 0.77,
        "total_length": 1333,
        "mean_pred_length": 16.6625,
        "std_pred_length": 5.506686276700353,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.47561890472618157,
        "vocab_size-1": 634,
        "unique-1": 505,
        "entropy-1": 7.989395248274955,
        "distinct-2": 0.8411811652035116,
        "vocab_size-2": 1054,
        "unique-2": 942,
        "entropy-2": 9.868313628782648,
        "cond_entropy-2": 1.6990264134561268,
        "distinct-3": 0.9420289855072463,
        "vocab_size-3": 1105,
        "unique-3": 1059,
        "entropy-3": 10.06265087177596,
        "cond_entropy-3": 0.21145035308820465,
        "total_length-nopunct": 1171,
        "mean_pred_length-nopunct": 14.6375,
        "std_pred_length-nopunct": 4.87914887557246,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5345858240819812,
        "vocab_size-1-nopunct": 626,
        "unique-1-nopunct": 502,
        "entropy-1-nopunct": 8.2092903427165,
        "distinct-2-nopunct": 0.846012832263978,
        "vocab_size-2-nopunct": 923,
        "unique-2-nopunct": 836,
        "entropy-2-nopunct": 9.66721874161528,
        "cond_entropy-2-nopunct": 1.5604803473261757,
        "distinct-3-nopunct": 0.9436201780415431,
        "vocab_size-3-nopunct": 954,
        "unique-3-nopunct": 917,
        "entropy-3-nopunct": 9.85011935609738,
        "cond_entropy-3-nopunct": 0.21152309873213038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23728813559322035,
            "2": 0.47368421052631576,
            "3": 0.7011642949547219
        },
        "nist": 6.9267458549187495,
        "rouge1": {
            "precision": 0.72017,
            "recall": 0.66704,
            "fmeasure": 0.67441
        },
        "rouge2": {
            "precision": 0.47756,
            "recall": 0.44966,
            "fmeasure": 0.44991
        },
        "rougeL": {
            "precision": 0.61109,
            "recall": 0.58381,
            "fmeasure": 0.58023
        },
        "rougeLsum": {
            "precision": 0.61109,
            "recall": 0.58381,
            "fmeasure": 0.58023
        },
        "bleu": 42.38206,
        "meteor": 0.34383651250009123,
        "bertscore": {
            "precision": 0.91094,
            "recall": 0.90231,
            "f1": 0.9043
        },
        "nubia": {
            "semantic_relation": 3.91263,
            "contradiction": 12.42341,
            "irrelevancy": 35.62285,
            "logical_agreement": 51.95375,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.44554,
            "nubia_score": 0.63919
        },
        "bleurt": 0.09714
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.535,
        "msttr-100_nopunct": 0.57,
        "total_length": 223,
        "mean_pred_length": 11.736842105263158,
        "std_pred_length": 1.9958405500903726,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 15,
        "distinct-1": 0.45739910313901344,
        "vocab_size-1": 102,
        "unique-1": 61,
        "entropy-1": 6.01661228591,
        "distinct-2": 0.6519607843137255,
        "vocab_size-2": 133,
        "unique-2": 90,
        "entropy-2": 6.840324332354566,
        "cond_entropy-2": 0.9454015026658624,
        "distinct-3": 0.7297297297297297,
        "vocab_size-3": 135,
        "unique-3": 103,
        "entropy-3": 6.901493217202896,
        "cond_entropy-3": 0.11011500204054701,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 10.473684210526315,
        "std_pred_length-nopunct": 1.7879250264697923,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.48743718592964824,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 6.02652778826706,
        "distinct-2-nopunct": 0.6555555555555556,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.668304035454514,
        "cond_entropy-2-nopunct": 0.7613041594997166,
        "distinct-3-nopunct": 0.7391304347826086,
        "vocab_size-3-nopunct": 119,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.723622235190278,
        "cond_entropy-3-nopunct": 0.11055139634734402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.07457627118644068,
            "2": 0.20300751879699247,
            "3": 0.3712871287128713
        },
        "nist": 0.01085696774302245,
        "rouge1": {
            "precision": 0.48246,
            "recall": 0.24635,
            "fmeasure": 0.31817
        },
        "rouge2": {
            "precision": 0.29825,
            "recall": 0.11853,
            "fmeasure": 0.1557
        },
        "rougeL": {
            "precision": 0.48246,
            "recall": 0.24635,
            "fmeasure": 0.31817
        },
        "rougeLsum": {
            "precision": 0.48246,
            "recall": 0.24635,
            "fmeasure": 0.31817
        },
        "bleu": 5.54783,
        "meteor": 0.2744509587351919,
        "bertscore": {
            "precision": 0.9449,
            "recall": 0.8556,
            "f1": 0.89743
        },
        "nubia": {
            "semantic_relation": 3.02387,
            "contradiction": 21.37702,
            "irrelevancy": 23.73784,
            "logical_agreement": 54.88514,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.68781,
            "nubia_score": 0.57865
        },
        "bleurt": 0.00757
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 12,
        "msttr-100": 0.54,
        "msttr-100_nopunct": 0.59,
        "total_length": 149,
        "mean_pred_length": 12.416666666666666,
        "std_pred_length": 2.4986107250941583,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.4899328859060403,
        "vocab_size-1": 73,
        "unique-1": 37,
        "entropy-1": 5.747878434738902,
        "distinct-2": 0.6861313868613139,
        "vocab_size-2": 94,
        "unique-2": 64,
        "entropy-2": 6.388845838463647,
        "cond_entropy-2": 0.6935232709391655,
        "distinct-3": 0.784,
        "vocab_size-3": 98,
        "unique-3": 80,
        "entropy-3": 6.479432384506326,
        "cond_entropy-3": 0.11262932549705482,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 10.833333333333334,
        "std_pred_length-nopunct": 2.4094720491334933,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5384615384615384,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.807604321767231,
        "distinct-2-nopunct": 0.711864406779661,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 6.224602875702985,
        "cond_entropy-2-nopunct": 0.4688785088072018,
        "distinct-3-nopunct": 0.7830188679245284,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.244107128948624,
        "cond_entropy-3-nopunct": 0.04914193797906366,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.16091954022988506,
            "3": 0.31645569620253167
        },
        "nist": 0.005633534069171427,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.23194,
            "fmeasure": 0.29107
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.12083,
            "fmeasure": 0.14444
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.23194,
            "fmeasure": 0.29107
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.23194,
            "fmeasure": 0.29107
        },
        "bleu": 4.45666,
        "meteor": 0.24439909660646184,
        "bertscore": {
            "precision": 0.9333,
            "recall": 0.84601,
            "f1": 0.88715
        },
        "nubia": {
            "semantic_relation": 2.82606,
            "contradiction": 28.2574,
            "irrelevancy": 26.90225,
            "logical_agreement": 44.84035,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.68119,
            "nubia_score": 0.64441
        },
        "bleurt": -0.01526
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 136,
        "msttr-100": 0.65048,
        "msttr-100_nopunct": 0.68944,
        "total_length": 2166,
        "mean_pred_length": 15.926470588235293,
        "std_pred_length": 4.305660352682776,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.3716528162511542,
        "vocab_size-1": 805,
        "unique-1": 629,
        "entropy-1": 7.676099885183509,
        "distinct-2": 0.6886699507389162,
        "vocab_size-2": 1398,
        "unique-2": 1261,
        "entropy-2": 9.642501461639219,
        "cond_entropy-2": 1.7517791773980704,
        "distinct-3": 0.795142555438226,
        "vocab_size-3": 1506,
        "unique-3": 1431,
        "entropy-3": 10.007711610080825,
        "cond_entropy-3": 0.4418275029018333,
        "total_length-nopunct": 1895,
        "mean_pred_length-nopunct": 13.933823529411764,
        "std_pred_length-nopunct": 3.9186623728496364,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.42110817941952505,
        "vocab_size-1-nopunct": 798,
        "unique-1-nopunct": 629,
        "entropy-1-nopunct": 7.910451579154342,
        "distinct-2-nopunct": 0.6918703808982376,
        "vocab_size-2-nopunct": 1217,
        "unique-2-nopunct": 1108,
        "entropy-2-nopunct": 9.43359951107411,
        "cond_entropy-2-nopunct": 1.6940696338736139,
        "distinct-3-nopunct": 0.8028342575477511,
        "vocab_size-3-nopunct": 1303,
        "unique-3-nopunct": 1245,
        "entropy-3-nopunct": 9.819532040513351,
        "cond_entropy-3-nopunct": 0.48447666639074627,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2545454545454545,
            "2": 0.4448051948051948,
            "3": 0.7885554780181437
        },
        "nist": 7.649349537667005,
        "rouge1": {
            "precision": 0.74984,
            "recall": 0.74197,
            "fmeasure": 0.73632
        },
        "rouge2": {
            "precision": 0.5264,
            "recall": 0.52108,
            "fmeasure": 0.51728
        },
        "rougeL": {
            "precision": 0.65405,
            "recall": 0.64871,
            "fmeasure": 0.64322
        },
        "rougeLsum": {
            "precision": 0.65405,
            "recall": 0.64871,
            "fmeasure": 0.64322
        },
        "bleu": 49.60758,
        "meteor": 0.39801997413097434,
        "bertscore": {
            "precision": 0.92886,
            "recall": 0.92827,
            "f1": 0.92672
        },
        "nubia": {
            "semantic_relation": 4.26425,
            "contradiction": 7.42381,
            "irrelevancy": 26.43991,
            "logical_agreement": 66.13628,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.42854,
            "nubia_score": 0.76445
        },
        "bleurt": 0.35737
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 131,
        "msttr-100": 0.71762,
        "msttr-100_nopunct": 0.77889,
        "total_length": 2117,
        "mean_pred_length": 16.16030534351145,
        "std_pred_length": 6.098199952023298,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 35,
        "distinct-1": 0.456778460085026,
        "vocab_size-1": 967,
        "unique-1": 788,
        "entropy-1": 8.301812305055762,
        "distinct-2": 0.8318227593152064,
        "vocab_size-2": 1652,
        "unique-2": 1496,
        "entropy-2": 10.473008000111127,
        "cond_entropy-2": 1.9216186261082202,
        "distinct-3": 0.9471698113207547,
        "vocab_size-3": 1757,
        "unique-3": 1690,
        "entropy-3": 10.734989244814013,
        "cond_entropy-3": 0.2675106513797683,
        "total_length-nopunct": 1838,
        "mean_pred_length-nopunct": 14.030534351145038,
        "std_pred_length-nopunct": 5.384369421354175,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5206746463547334,
        "vocab_size-1-nopunct": 957,
        "unique-1-nopunct": 785,
        "entropy-1-nopunct": 8.60838641785204,
        "distinct-2-nopunct": 0.8541300527240774,
        "vocab_size-2-nopunct": 1458,
        "unique-2-nopunct": 1342,
        "entropy-2-nopunct": 10.306230703489303,
        "cond_entropy-2-nopunct": 1.7970561051363665,
        "distinct-3-nopunct": 0.9593908629441624,
        "vocab_size-3-nopunct": 1512,
        "unique-3-nopunct": 1461,
        "entropy-3-nopunct": 10.534295624961631,
        "cond_entropy-3-nopunct": 0.25231393110471023,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22546419098143236,
            "2": 0.44711538461538464,
            "3": 0.729312762973352
        },
        "nist": 7.50568880212228,
        "rouge1": {
            "precision": 0.77497,
            "recall": 0.71562,
            "fmeasure": 0.73265
        },
        "rouge2": {
            "precision": 0.53639,
            "recall": 0.49162,
            "fmeasure": 0.50451
        },
        "rougeL": {
            "precision": 0.66813,
            "recall": 0.61598,
            "fmeasure": 0.63075
        },
        "rougeLsum": {
            "precision": 0.66813,
            "recall": 0.61598,
            "fmeasure": 0.63075
        },
        "bleu": 42.9395,
        "meteor": 0.3801133429369713,
        "bertscore": {
            "precision": 0.93201,
            "recall": 0.92291,
            "f1": 0.9265
        },
        "nubia": {
            "semantic_relation": 4.19198,
            "contradiction": 13.22041,
            "irrelevancy": 24.22561,
            "logical_agreement": 62.55398,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.62265,
            "nubia_score": 0.71601
        },
        "bleurt": 0.26344
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.72,
        "total_length": 131,
        "mean_pred_length": 13.1,
        "std_pred_length": 3.726929030716845,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 20,
        "distinct-1": 0.6259541984732825,
        "vocab_size-1": 82,
        "unique-1": 63,
        "entropy-1": 5.98754719321154,
        "distinct-2": 0.859504132231405,
        "vocab_size-2": 104,
        "unique-2": 95,
        "entropy-2": 6.587961584238998,
        "cond_entropy-2": 0.4123108962703103,
        "distinct-3": 0.8918918918918919,
        "vocab_size-3": 99,
        "unique-3": 93,
        "entropy-3": 6.537394920287229,
        "cond_entropy-3": -0.038773722236858515,
        "total_length-nopunct": 119,
        "mean_pred_length-nopunct": 11.9,
        "std_pred_length-nopunct": 3.3896902513356584,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6722689075630253,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.039435831023734,
        "distinct-2-nopunct": 0.8532110091743119,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.419201755810791,
        "cond_entropy-2-nopunct": 0.43989270756543386,
        "distinct-3-nopunct": 0.8787878787878788,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.3411816199484985,
        "cond_entropy-3-nopunct": -0.042769371320276986,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.36363636363636365,
            "3": 0.9433962264150944
        },
        "nist": 6.461935781093685,
        "rouge1": {
            "precision": 0.91389,
            "recall": 0.92887,
            "fmeasure": 0.91792
        },
        "rouge2": {
            "precision": 0.81836,
            "recall": 0.84642,
            "fmeasure": 0.82872
        },
        "rougeL": {
            "precision": 0.85093,
            "recall": 0.86625,
            "fmeasure": 0.85582
        },
        "rougeLsum": {
            "precision": 0.85093,
            "recall": 0.86625,
            "fmeasure": 0.85582
        },
        "bleu": 76.7177,
        "meteor": 0.5343072752653824,
        "bertscore": {
            "precision": 0.97612,
            "recall": 0.97702,
            "f1": 0.97632
        },
        "nubia": {
            "semantic_relation": 4.7993,
            "contradiction": 0.35236,
            "irrelevancy": 20.25567,
            "logical_agreement": 79.39196,
            "grammar_ref": 5.03704,
            "grammar_hyp": 5.02142,
            "nubia_score": 0.91207
        },
        "bleurt": 0.74637
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 80,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 2.1343747458109497,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.725,
        "vocab_size-1": 58,
        "unique-1": 48,
        "entropy-1": 5.561768795973191,
        "distinct-2": 0.9594594594594594,
        "vocab_size-2": 71,
        "unique-2": 68,
        "entropy-2": 6.128372284547875,
        "cond_entropy-2": 0.40061465426574644,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 66,
        "unique-3": 64,
        "entropy-3": 6.028639311838581,
        "cond_entropy-3": -0.0925787596727279,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.7320508075688772,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.564826173079622,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.806890595608517,
        "cond_entropy-2-nopunct": 0.27335455049011903,
        "distinct-3-nopunct": 0.9629629629629629,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.680813428089393,
        "cond_entropy-3-nopunct": -0.13348457492653137,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.8,
            "3": 0.9090909090909091
        },
        "nist": 4.504098850534567,
        "rouge1": {
            "precision": 0.69907,
            "recall": 0.81667,
            "fmeasure": 0.74753
        },
        "rouge2": {
            "precision": 0.46815,
            "recall": 0.53797,
            "fmeasure": 0.49672
        },
        "rougeL": {
            "precision": 0.66852,
            "recall": 0.78869,
            "fmeasure": 0.71812
        },
        "rougeLsum": {
            "precision": 0.66852,
            "recall": 0.78869,
            "fmeasure": 0.71812
        },
        "bleu": 49.88098,
        "meteor": 0.45692081740181045,
        "bertscore": {
            "precision": 0.8896,
            "recall": 0.91962,
            "f1": 0.90308
        },
        "nubia": {
            "semantic_relation": 3.95746,
            "contradiction": 2.37889,
            "irrelevancy": 55.88118,
            "logical_agreement": 41.73994,
            "grammar_ref": 5.1808,
            "grammar_hyp": 4.54894,
            "nubia_score": 0.66476
        },
        "bleurt": 0.00902
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.6725,
        "msttr-100_nopunct": 0.74333,
        "total_length": 423,
        "mean_pred_length": 16.26923076923077,
        "std_pred_length": 4.653846153846154,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5460992907801419,
        "vocab_size-1": 231,
        "unique-1": 185,
        "entropy-1": 6.965326771915836,
        "distinct-2": 0.8942065491183879,
        "vocab_size-2": 355,
        "unique-2": 323,
        "entropy-2": 8.391498212304366,
        "cond_entropy-2": 1.2335453231079765,
        "distinct-3": 0.9649595687331537,
        "vocab_size-3": 358,
        "unique-3": 345,
        "entropy-3": 8.465194514087042,
        "cond_entropy-3": 0.07444811204099124,
        "total_length-nopunct": 359,
        "mean_pred_length-nopunct": 13.807692307692308,
        "std_pred_length-nopunct": 3.605756410233618,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6239554317548747,
        "vocab_size-1-nopunct": 224,
        "unique-1-nopunct": 183,
        "entropy-1-nopunct": 7.123192097228883,
        "distinct-2-nopunct": 0.9009009009009009,
        "vocab_size-2-nopunct": 300,
        "unique-2-nopunct": 277,
        "entropy-2-nopunct": 8.145521601362796,
        "cond_entropy-2-nopunct": 1.0853056943654995,
        "distinct-3-nopunct": 0.9641693811074918,
        "vocab_size-3-nopunct": 296,
        "unique-3-nopunct": 285,
        "entropy-3-nopunct": 8.190433607585122,
        "cond_entropy-3-nopunct": 0.05494547823679105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27586206896551724,
            "2": 0.5376344086021505,
            "3": 0.7725321888412017
        },
        "nist": 6.263259921114887,
        "rouge1": {
            "precision": 0.71555,
            "recall": 0.73816,
            "fmeasure": 0.71195
        },
        "rouge2": {
            "precision": 0.48295,
            "recall": 0.4825,
            "fmeasure": 0.4706
        },
        "rougeL": {
            "precision": 0.63738,
            "recall": 0.65494,
            "fmeasure": 0.63322
        },
        "rougeLsum": {
            "precision": 0.63738,
            "recall": 0.65494,
            "fmeasure": 0.63322
        },
        "bleu": 44.9697,
        "meteor": 0.3713929615878131,
        "bertscore": {
            "precision": 0.91383,
            "recall": 0.9194,
            "f1": 0.91466
        },
        "nubia": {
            "semantic_relation": 3.8496,
            "contradiction": 7.3764,
            "irrelevancy": 49.74603,
            "logical_agreement": 42.87756,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.42288,
            "nubia_score": 0.66046
        },
        "bleurt": 0.07379
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 73,
        "msttr-100": 0.70818,
        "msttr-100_nopunct": 0.76778,
        "total_length": 1158,
        "mean_pred_length": 15.863013698630137,
        "std_pred_length": 6.016677890283706,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.47150259067357514,
        "vocab_size-1": 546,
        "unique-1": 424,
        "entropy-1": 7.834902172026832,
        "distinct-2": 0.8276497695852535,
        "vocab_size-2": 898,
        "unique-2": 789,
        "entropy-2": 9.63298761383322,
        "cond_entropy-2": 1.5826303452099892,
        "distinct-3": 0.9140316205533597,
        "vocab_size-3": 925,
        "unique-3": 853,
        "entropy-3": 9.797085506030879,
        "cond_entropy-3": 0.15779476233483022,
        "total_length-nopunct": 992,
        "mean_pred_length-nopunct": 13.58904109589041,
        "std_pred_length-nopunct": 5.280710870676503,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5423387096774194,
        "vocab_size-1-nopunct": 538,
        "unique-1-nopunct": 423,
        "entropy-1-nopunct": 8.082912241739768,
        "distinct-2-nopunct": 0.8422198041349293,
        "vocab_size-2-nopunct": 774,
        "unique-2-nopunct": 694,
        "entropy-2-nopunct": 9.41844872089159,
        "cond_entropy-2-nopunct": 1.4276789432516126,
        "distinct-3-nopunct": 0.925531914893617,
        "vocab_size-3-nopunct": 783,
        "unique-3-nopunct": 732,
        "entropy-3-nopunct": 9.562121325950484,
        "cond_entropy-3-nopunct": 0.1558529745823383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24651162790697675,
            "2": 0.4939759036144578,
            "3": 0.7406060606060606
        },
        "nist": 7.444795752133913,
        "rouge1": {
            "precision": 0.80323,
            "recall": 0.73682,
            "fmeasure": 0.75743
        },
        "rouge2": {
            "precision": 0.59448,
            "recall": 0.54982,
            "fmeasure": 0.56257
        },
        "rougeL": {
            "precision": 0.72765,
            "recall": 0.67615,
            "fmeasure": 0.69023
        },
        "rougeLsum": {
            "precision": 0.72765,
            "recall": 0.67615,
            "fmeasure": 0.69023
        },
        "bleu": 51.1255,
        "meteor": 0.4029512503312533,
        "bertscore": {
            "precision": 0.94033,
            "recall": 0.92613,
            "f1": 0.93159
        },
        "nubia": {
            "semantic_relation": 4.18635,
            "contradiction": 8.36001,
            "irrelevancy": 30.29635,
            "logical_agreement": 61.34364,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.66843,
            "nubia_score": 0.72284
        },
        "bleurt": 0.27434
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 1099,
        "msttr-100": 0.67516,
        "msttr-100_nopunct": 0.72229,
        "total_length": 12401,
        "mean_pred_length": 11.283894449499545,
        "std_pred_length": 2.9288538118655687,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.20909604064188372,
        "vocab_size-1": 2593,
        "unique-1": 1355,
        "entropy-1": 9.166414105785966,
        "distinct-2": 0.5022119978764821,
        "vocab_size-2": 5676,
        "unique-2": 3914,
        "entropy-2": 11.77119336810398,
        "cond_entropy-2": 2.667653921167319,
        "distinct-3": 0.701264334019406,
        "vocab_size-3": 7155,
        "unique-3": 5730,
        "entropy-3": 12.495432784075453,
        "cond_entropy-3": 0.8392544973158274,
        "total_length-nopunct": 10556,
        "mean_pred_length-nopunct": 9.605095541401274,
        "std_pred_length-nopunct": 2.60058988635711,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.2448844259189087,
        "vocab_size-1-nopunct": 2585,
        "unique-1-nopunct": 1354,
        "entropy-1-nopunct": 9.69992417876476,
        "distinct-2-nopunct": 0.5511261499418421,
        "vocab_size-2-nopunct": 5212,
        "unique-2-nopunct": 3793,
        "entropy-2-nopunct": 11.724865649281055,
        "cond_entropy-2-nopunct": 2.248937367559119,
        "distinct-3-nopunct": 0.734146925101699,
        "vocab_size-3-nopunct": 6136,
        "unique-3-nopunct": 5073,
        "entropy-3-nopunct": 12.296448572325378,
        "cond_entropy-3-nopunct": 0.7027592016897967,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16165736367539715,
            "2": 0.35010337698139216,
            "3": 0.48433689739260927,
            "4": 0.6363636363636364,
            "5": 0.6216216216216216,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "nist": 1.6429281613362205,
        "rouge1": {
            "precision": 0.28227,
            "recall": 0.23109,
            "fmeasure": 0.2445
        },
        "rouge2": {
            "precision": 0.12981,
            "recall": 0.1042,
            "fmeasure": 0.11113
        },
        "rougeL": {
            "precision": 0.27625,
            "recall": 0.22602,
            "fmeasure": 0.23905
        },
        "rougeLsum": {
            "precision": 0.27625,
            "recall": 0.22602,
            "fmeasure": 0.23905
        },
        "bleu": 21.27021,
        "meteor": 0.39075556845136156,
        "bertscore": {
            "precision": 0.94953,
            "recall": 0.91245,
            "f1": 0.92975
        },
        "nubia": {
            "semantic_relation": 3.58641,
            "contradiction": 22.11484,
            "irrelevancy": 22.7549,
            "logical_agreement": 55.13027,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.73159,
            "nubia_score": 0.6937
        },
        "bleurt": 0.09085
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846629,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.6470588235294118
        },
        "nist": 2.570632064843987,
        "rouge1": {
            "precision": 0.60317,
            "recall": 0.64386,
            "fmeasure": 0.62276
        },
        "rouge2": {
            "precision": 0.18333,
            "recall": 0.19591,
            "fmeasure": 0.18938
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.42105,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.42105,
            "fmeasure": 0.4
        },
        "bleu": 7.43667,
        "meteor": 0.3061356681972043,
        "bertscore": {
            "precision": 0.87325,
            "recall": 0.88139,
            "f1": 0.877
        },
        "nubia": {
            "semantic_relation": 3.92289,
            "contradiction": 3.95167,
            "irrelevancy": 45.3661,
            "logical_agreement": 50.68223,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.74161,
            "nubia_score": 0.59918
        },
        "bleurt": 0.02638
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nist": 1.9877836651684964,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.42857,
            "fmeasure": 0.42967
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "bleu": 41.72261,
        "meteor": 0.3832699063476993,
        "bertscore": {
            "precision": 0.95353,
            "recall": 0.96991,
            "f1": 0.96165
        },
        "nubia": {
            "semantic_relation": 4.14875,
            "contradiction": 0.05561,
            "irrelevancy": 34.18796,
            "logical_agreement": 65.75644,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.32832,
            "nubia_score": 0.69679
        },
        "bleurt": 0.43554
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 111,
        "msttr-100": 0.64056,
        "msttr-100_nopunct": 0.68067,
        "total_length": 1834,
        "mean_pred_length": 16.52252252252252,
        "std_pred_length": 5.1619656268107414,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.3876772082878953,
        "vocab_size-1": 711,
        "unique-1": 586,
        "entropy-1": 7.625847110673767,
        "distinct-2": 0.7045850261172374,
        "vocab_size-2": 1214,
        "unique-2": 1106,
        "entropy-2": 9.53524393692075,
        "cond_entropy-2": 1.714305795625488,
        "distinct-3": 0.8033498759305211,
        "vocab_size-3": 1295,
        "unique-3": 1231,
        "entropy-3": 9.847468159463226,
        "cond_entropy-3": 0.37036429419115774,
        "total_length-nopunct": 1573,
        "mean_pred_length-nopunct": 14.17117117117117,
        "std_pred_length-nopunct": 4.378230079422288,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.445645263827082,
        "vocab_size-1-nopunct": 701,
        "unique-1-nopunct": 583,
        "entropy-1-nopunct": 7.836281335080939,
        "distinct-2-nopunct": 0.7161422708618331,
        "vocab_size-2-nopunct": 1047,
        "unique-2-nopunct": 967,
        "entropy-2-nopunct": 9.311098931175104,
        "cond_entropy-2-nopunct": 1.6304727514887085,
        "distinct-3-nopunct": 0.8119911176905995,
        "vocab_size-3-nopunct": 1097,
        "unique-3-nopunct": 1050,
        "entropy-3-nopunct": 9.61547268477479,
        "cond_entropy-3-nopunct": 0.38800218201240405,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20303030303030303,
            "2": 0.4185185185185185,
            "3": 0.7629688747007183
        },
        "nist": 7.3347309373390175,
        "rouge1": {
            "precision": 0.77179,
            "recall": 0.73401,
            "fmeasure": 0.74053
        },
        "rouge2": {
            "precision": 0.57341,
            "recall": 0.53716,
            "fmeasure": 0.54655
        },
        "rougeL": {
            "precision": 0.68647,
            "recall": 0.64757,
            "fmeasure": 0.65539
        },
        "rougeLsum": {
            "precision": 0.68647,
            "recall": 0.64757,
            "fmeasure": 0.65539
        },
        "bleu": 49.93446,
        "meteor": 0.39275196148142677,
        "bertscore": {
            "precision": 0.93375,
            "recall": 0.92727,
            "f1": 0.92856
        },
        "nubia": {
            "semantic_relation": 4.19169,
            "contradiction": 9.87167,
            "irrelevancy": 21.46675,
            "logical_agreement": 68.66158,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.43964,
            "nubia_score": 0.73732
        },
        "bleurt": 0.36313
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.71286,
        "msttr-100_nopunct": 0.75833,
        "total_length": 747,
        "mean_pred_length": 16.977272727272727,
        "std_pred_length": 5.781980772442309,
        "median_pred_length": 17.5,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.5060240963855421,
        "vocab_size-1": 378,
        "unique-1": 294,
        "entropy-1": 7.573198463150975,
        "distinct-2": 0.8634423897581792,
        "vocab_size-2": 607,
        "unique-2": 544,
        "entropy-2": 9.124802850954696,
        "cond_entropy-2": 1.4088453588025478,
        "distinct-3": 0.9514415781487102,
        "vocab_size-3": 627,
        "unique-3": 598,
        "entropy-3": 9.26283740538403,
        "cond_entropy-3": 0.13633280288929056,
        "total_length-nopunct": 655,
        "mean_pred_length-nopunct": 14.886363636363637,
        "std_pred_length-nopunct": 5.175185148602324,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5679389312977099,
        "vocab_size-1-nopunct": 372,
        "unique-1-nopunct": 294,
        "entropy-1-nopunct": 7.7221489902377884,
        "distinct-2-nopunct": 0.8788870703764321,
        "vocab_size-2-nopunct": 537,
        "unique-2-nopunct": 492,
        "entropy-2-nopunct": 8.950130732236916,
        "cond_entropy-2-nopunct": 1.2986547250865954,
        "distinct-3-nopunct": 0.9664902998236331,
        "vocab_size-3-nopunct": 548,
        "unique-3-nopunct": 530,
        "entropy-3-nopunct": 9.078854153333557,
        "cond_entropy-3-nopunct": 0.1319518908548099,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27722772277227725,
            "2": 0.496,
            "3": 0.8207343412526998
        },
        "nist": 7.029105592174926,
        "rouge1": {
            "precision": 0.76894,
            "recall": 0.78687,
            "fmeasure": 0.76772
        },
        "rouge2": {
            "precision": 0.5302,
            "recall": 0.5475,
            "fmeasure": 0.53206
        },
        "rougeL": {
            "precision": 0.68188,
            "recall": 0.69331,
            "fmeasure": 0.67809
        },
        "rougeLsum": {
            "precision": 0.68188,
            "recall": 0.69331,
            "fmeasure": 0.67809
        },
        "bleu": 48.30999,
        "meteor": 0.4130100754790831,
        "bertscore": {
            "precision": 0.93068,
            "recall": 0.92987,
            "f1": 0.92879
        },
        "nubia": {
            "semantic_relation": 4.35206,
            "contradiction": 2.61277,
            "irrelevancy": 31.62217,
            "logical_agreement": 65.76506,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.54539,
            "nubia_score": 0.79388
        },
        "bleurt": 0.32447
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.68647,
        "msttr-100_nopunct": 0.73333,
        "total_length": 5149,
        "mean_pred_length": 17.163333333333334,
        "std_pred_length": 5.0921497315857565,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.36006991648863856,
        "vocab_size-1": 1854,
        "unique-1": 1480,
        "entropy-1": 8.457883876757904,
        "distinct-2": 0.7187048876056918,
        "vocab_size-2": 3485,
        "unique-2": 3115,
        "entropy-2": 11.174721319483353,
        "cond_entropy-2": 2.5024724722934444,
        "distinct-3": 0.8786546493734887,
        "vocab_size-3": 3997,
        "unique-3": 3779,
        "entropy-3": 11.789021777635892,
        "cond_entropy-3": 0.6331269311000449,
        "total_length-nopunct": 4515,
        "mean_pred_length-nopunct": 15.05,
        "std_pred_length-nopunct": 4.691925688527757,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.40841638981173867,
        "vocab_size-1-nopunct": 1844,
        "unique-1-nopunct": 1478,
        "entropy-1-nopunct": 8.77276890011236,
        "distinct-2-nopunct": 0.7359430604982207,
        "vocab_size-2-nopunct": 3102,
        "unique-2-nopunct": 2811,
        "entropy-2-nopunct": 11.0026123929293,
        "cond_entropy-2-nopunct": 2.38614998461402,
        "distinct-3-nopunct": 0.8942528735632184,
        "vocab_size-3-nopunct": 3501,
        "unique-3-nopunct": 3326,
        "entropy-3-nopunct": 11.623838862912441,
        "cond_entropy-3-nopunct": 0.6918234907617798,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20658342792281498,
            "2": 0.3686440677966102,
            "3": 0.787919826652221
        },
        "nist": 8.635974969171347,
        "rouge1": {
            "precision": 0.80989,
            "recall": 0.76435,
            "fmeasure": 0.77757
        },
        "rouge2": {
            "precision": 0.57154,
            "recall": 0.53959,
            "fmeasure": 0.5488
        },
        "rougeL": {
            "precision": 0.69642,
            "recall": 0.65948,
            "fmeasure": 0.66958
        },
        "rougeLsum": {
            "precision": 0.69642,
            "recall": 0.65948,
            "fmeasure": 0.66958
        },
        "bleu": 46.7722,
        "meteor": 0.40466289505519587,
        "bertscore": {
            "precision": 0.9417,
            "recall": 0.93509,
            "f1": 0.93703
        },
        "nubia": {
            "semantic_relation": 4.38923,
            "contradiction": 6.22619,
            "irrelevancy": 24.27202,
            "logical_agreement": 69.50179,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.91681,
            "nubia_score": 0.76821
        },
        "bleurt": 0.33889
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 33,
        "msttr-100": 0.706,
        "msttr-100_nopunct": 0.7525,
        "total_length": 517,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 4.469876729821302,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5686653771760155,
        "vocab_size-1": 294,
        "unique-1": 255,
        "entropy-1": 7.179849671475306,
        "distinct-2": 0.9276859504132231,
        "vocab_size-2": 449,
        "unique-2": 428,
        "entropy-2": 8.725343840003061,
        "cond_entropy-2": 1.366405157150586,
        "distinct-3": 0.9866962305986696,
        "vocab_size-3": 445,
        "unique-3": 440,
        "entropy-3": 8.788702276243859,
        "cond_entropy-3": 0.05091085333618216,
        "total_length-nopunct": 444,
        "mean_pred_length-nopunct": 13.454545454545455,
        "std_pred_length-nopunct": 4.045880127427115,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6486486486486487,
        "vocab_size-1-nopunct": 288,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.339224310585931,
        "distinct-2-nopunct": 0.9391727493917275,
        "vocab_size-2-nopunct": 386,
        "unique-2-nopunct": 373,
        "entropy-2-nopunct": 8.508631108549194,
        "cond_entropy-2-nopunct": 1.2643491856523796,
        "distinct-3-nopunct": 0.9947089947089947,
        "vocab_size-3-nopunct": 376,
        "unique-3-nopunct": 375,
        "entropy-3-nopunct": 8.549663356755056,
        "cond_entropy-3-nopunct": 0.050963451061303906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15,
            "2": 0.22388059701492538,
            "3": 0.7707317073170732
        },
        "nist": 6.771213346058688,
        "rouge1": {
            "precision": 0.85473,
            "recall": 0.75917,
            "fmeasure": 0.79675
        },
        "rouge2": {
            "precision": 0.62253,
            "recall": 0.55183,
            "fmeasure": 0.57844
        },
        "rougeL": {
            "precision": 0.73742,
            "recall": 0.65954,
            "fmeasure": 0.68951
        },
        "rougeLsum": {
            "precision": 0.73742,
            "recall": 0.65954,
            "fmeasure": 0.68951
        },
        "bleu": 47.81273,
        "meteor": 0.40149915484698506,
        "bertscore": {
            "precision": 0.94396,
            "recall": 0.92718,
            "f1": 0.93482
        },
        "nubia": {
            "semantic_relation": 4.44145,
            "contradiction": 4.36401,
            "irrelevancy": 20.14155,
            "logical_agreement": 75.49444,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.25218,
            "nubia_score": 0.76817
        },
        "bleurt": 0.27301
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 64,
        "msttr-100": 0.718,
        "msttr-100_nopunct": 0.78667,
        "total_length": 1074,
        "mean_pred_length": 16.78125,
        "std_pred_length": 5.682948041069881,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 35,
        "distinct-1": 0.5083798882681564,
        "vocab_size-1": 546,
        "unique-1": 438,
        "entropy-1": 7.9039933322174125,
        "distinct-2": 0.906930693069307,
        "vocab_size-2": 916,
        "unique-2": 853,
        "entropy-2": 9.753729536682602,
        "cond_entropy-2": 1.6447921537294017,
        "distinct-3": 0.9788583509513742,
        "vocab_size-3": 926,
        "unique-3": 908,
        "entropy-3": 9.841817118577858,
        "cond_entropy-3": 0.09600538593469427,
        "total_length-nopunct": 923,
        "mean_pred_length-nopunct": 14.421875,
        "std_pred_length-nopunct": 4.872770924676739,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5839653304442037,
        "vocab_size-1-nopunct": 539,
        "unique-1-nopunct": 437,
        "entropy-1-nopunct": 8.178808834847738,
        "distinct-2-nopunct": 0.9220023282887078,
        "vocab_size-2-nopunct": 792,
        "unique-2-nopunct": 751,
        "entropy-2-nopunct": 9.548133088473099,
        "cond_entropy-2-nopunct": 1.4582643275316831,
        "distinct-3-nopunct": 0.9849056603773585,
        "vocab_size-3-nopunct": 783,
        "unique-3-nopunct": 772,
        "entropy-3-nopunct": 9.603672826898693,
        "cond_entropy-3-nopunct": 0.06951638797255885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1623931623931624,
            "2": 0.4185022026431718,
            "3": 0.7566433566433567
        },
        "nist": 6.944278849135911,
        "rouge1": {
            "precision": 0.76236,
            "recall": 0.71205,
            "fmeasure": 0.72759
        },
        "rouge2": {
            "precision": 0.48872,
            "recall": 0.46859,
            "fmeasure": 0.47247
        },
        "rougeL": {
            "precision": 0.62276,
            "recall": 0.59415,
            "fmeasure": 0.60068
        },
        "rougeLsum": {
            "precision": 0.62276,
            "recall": 0.59415,
            "fmeasure": 0.60068
        },
        "bleu": 42.111,
        "meteor": 0.3757337446643372,
        "bertscore": {
            "precision": 0.92489,
            "recall": 0.91596,
            "f1": 0.91874
        },
        "nubia": {
            "semantic_relation": 4.15649,
            "contradiction": 10.4823,
            "irrelevancy": 27.75083,
            "logical_agreement": 61.76688,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.67404,
            "nubia_score": 0.71401
        },
        "bleurt": 0.21124
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78,
        "total_length": 157,
        "mean_pred_length": 13.083333333333334,
        "std_pred_length": 5.634097581295123,
        "median_pred_length": 12.5,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6560509554140127,
        "vocab_size-1": 103,
        "unique-1": 82,
        "entropy-1": 6.293922682899241,
        "distinct-2": 0.9379310344827586,
        "vocab_size-2": 136,
        "unique-2": 128,
        "entropy-2": 7.050565038275897,
        "cond_entropy-2": 0.6034637060182533,
        "distinct-3": 0.9849624060150376,
        "vocab_size-3": 131,
        "unique-3": 129,
        "entropy-3": 7.025207247531273,
        "cond_entropy-3": -0.02120644773056093,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 5.005552472560402,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.355136299747805,
        "distinct-2-nopunct": 0.9296875,
        "vocab_size-2-nopunct": 119,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.853477441389348,
        "cond_entropy-2-nopunct": 0.5552923963787856,
        "distinct-3-nopunct": 0.9827586206896551,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.823498236506866,
        "cond_entropy-3-nopunct": -0.03206307812963934,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.5714285714285714,
            "3": 0.75
        },
        "nist": 5.213712566725947,
        "rouge1": {
            "precision": 0.73804,
            "recall": 0.73359,
            "fmeasure": 0.72581
        },
        "rouge2": {
            "precision": 0.53165,
            "recall": 0.51212,
            "fmeasure": 0.51068
        },
        "rougeL": {
            "precision": 0.64527,
            "recall": 0.6381,
            "fmeasure": 0.63278
        },
        "rougeLsum": {
            "precision": 0.64527,
            "recall": 0.6381,
            "fmeasure": 0.63278
        },
        "bleu": 41.6652,
        "meteor": 0.38047646633318444,
        "bertscore": {
            "precision": 0.9185,
            "recall": 0.92083,
            "f1": 0.91814
        },
        "nubia": {
            "semantic_relation": 4.25614,
            "contradiction": 10.27956,
            "irrelevancy": 23.42865,
            "logical_agreement": 66.29179,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.39866,
            "nubia_score": 0.76704
        },
        "bleurt": 0.19139
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 110,
        "msttr-100": 0.72056,
        "msttr-100_nopunct": 0.75563,
        "total_length": 1823,
        "mean_pred_length": 16.572727272727274,
        "std_pred_length": 5.59457381740085,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.46516730663741085,
        "vocab_size-1": 848,
        "unique-1": 677,
        "entropy-1": 8.238142361309759,
        "distinct-2": 0.833041447752481,
        "vocab_size-2": 1427,
        "unique-2": 1293,
        "entropy-2": 10.267117347837493,
        "cond_entropy-2": 1.8044239883041848,
        "distinct-3": 0.9394884591391142,
        "vocab_size-3": 1506,
        "unique-3": 1441,
        "entropy-3": 10.50801959597205,
        "cond_entropy-3": 0.24636784682631588,
        "total_length-nopunct": 1621,
        "mean_pred_length-nopunct": 14.736363636363636,
        "std_pred_length-nopunct": 5.2182847630010185,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5175817396668723,
        "vocab_size-1-nopunct": 839,
        "unique-1-nopunct": 675,
        "entropy-1-nopunct": 8.447686298124454,
        "distinct-2-nopunct": 0.8358702845797485,
        "vocab_size-2-nopunct": 1263,
        "unique-2-nopunct": 1152,
        "entropy-2-nopunct": 10.081983107537246,
        "cond_entropy-2-nopunct": 1.7525832782739794,
        "distinct-3-nopunct": 0.939329050678087,
        "vocab_size-3-nopunct": 1316,
        "unique-3-nopunct": 1260,
        "entropy-3-nopunct": 10.312474261467122,
        "cond_entropy-3-nopunct": 0.2633024634496673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25396825396825395,
            "2": 0.5490716180371353,
            "3": 0.7971698113207547
        },
        "nist": 7.698833067928561,
        "rouge1": {
            "precision": 0.74194,
            "recall": 0.74067,
            "fmeasure": 0.72754
        },
        "rouge2": {
            "precision": 0.53746,
            "recall": 0.53185,
            "fmeasure": 0.52305
        },
        "rougeL": {
            "precision": 0.65332,
            "recall": 0.64796,
            "fmeasure": 0.63825
        },
        "rougeLsum": {
            "precision": 0.65332,
            "recall": 0.64796,
            "fmeasure": 0.63825
        },
        "bleu": 48.36635,
        "meteor": 0.4006195073883007,
        "bertscore": {
            "precision": 0.93157,
            "recall": 0.93183,
            "f1": 0.93028
        },
        "nubia": {
            "semantic_relation": 4.22822,
            "contradiction": 8.4667,
            "irrelevancy": 28.07407,
            "logical_agreement": 63.45923,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.64455,
            "nubia_score": 0.74202
        },
        "bleurt": 0.282
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.625
        },
        "nist": 2.2225326567719255,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.85714,
            "fmeasure": 0.77419
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.53846,
            "fmeasure": 0.48276
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.5873,
            "fmeasure": 0.43672
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.5873,
            "fmeasure": 0.43672
        },
        "bleu": 20.45516,
        "meteor": 0.3514145157584194,
        "bertscore": {
            "precision": 0.88692,
            "recall": 0.91283,
            "f1": 0.89969
        },
        "nubia": {
            "semantic_relation": 3.78913,
            "contradiction": 0.20059,
            "irrelevancy": 99.70148,
            "logical_agreement": 0.09793,
            "grammar_ref": 4.76643,
            "grammar_hyp": 3.52723,
            "nubia_score": 0.76537
        },
        "bleurt": 0.24329
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 30,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.755,
        "total_length": 497,
        "mean_pred_length": 16.566666666666666,
        "std_pred_length": 4.876360209099497,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5613682092555332,
        "vocab_size-1": 279,
        "unique-1": 224,
        "entropy-1": 7.282551851222288,
        "distinct-2": 0.8993576017130621,
        "vocab_size-2": 420,
        "unique-2": 384,
        "entropy-2": 8.64323336394295,
        "cond_entropy-2": 1.1635437791822028,
        "distinct-3": 0.965675057208238,
        "vocab_size-3": 422,
        "unique-3": 408,
        "entropy-3": 8.701112152561944,
        "cond_entropy-3": 0.07325947803104359,
        "total_length-nopunct": 442,
        "mean_pred_length-nopunct": 14.733333333333333,
        "std_pred_length-nopunct": 4.202644669993196,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6153846153846154,
        "vocab_size-1-nopunct": 272,
        "unique-1-nopunct": 222,
        "entropy-1-nopunct": 7.408812381949127,
        "distinct-2-nopunct": 0.8980582524271845,
        "vocab_size-2-nopunct": 370,
        "unique-2-nopunct": 339,
        "entropy-2-nopunct": 8.456818026010641,
        "cond_entropy-2-nopunct": 1.1237405477552789,
        "distinct-3-nopunct": 0.9685863874345549,
        "vocab_size-3-nopunct": 370,
        "unique-3-nopunct": 359,
        "entropy-3-nopunct": 8.512625457611263,
        "cond_entropy-3-nopunct": 0.0712275233156909,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2653061224489796,
            "2": 0.2803738317757009,
            "3": 0.8149253731343283
        },
        "nist": 6.632242229424194,
        "rouge1": {
            "precision": 0.75184,
            "recall": 0.73328,
            "fmeasure": 0.73283
        },
        "rouge2": {
            "precision": 0.51991,
            "recall": 0.51294,
            "fmeasure": 0.50862
        },
        "rougeL": {
            "precision": 0.65712,
            "recall": 0.63684,
            "fmeasure": 0.6383
        },
        "rougeLsum": {
            "precision": 0.65712,
            "recall": 0.63684,
            "fmeasure": 0.6383
        },
        "bleu": 47.78591,
        "meteor": 0.40437416603997484,
        "bertscore": {
            "precision": 0.93259,
            "recall": 0.92444,
            "f1": 0.92575
        },
        "nubia": {
            "semantic_relation": 4.03008,
            "contradiction": 14.77318,
            "irrelevancy": 27.8995,
            "logical_agreement": 57.32732,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.74579,
            "nubia_score": 0.67611
        },
        "bleurt": 0.21759
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.6915,
        "msttr-100_nopunct": 0.74294,
        "total_length": 2038,
        "mean_pred_length": 15.921875,
        "std_pred_length": 5.4780946947250735,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.380765456329735,
        "vocab_size-1": 776,
        "unique-1": 601,
        "entropy-1": 7.876131528225212,
        "distinct-2": 0.7445026178010471,
        "vocab_size-2": 1422,
        "unique-2": 1237,
        "entropy-2": 10.091714567817535,
        "cond_entropy-2": 1.9882101615457983,
        "distinct-3": 0.9113355780022446,
        "vocab_size-3": 1624,
        "unique-3": 1537,
        "entropy-3": 10.564654945331661,
        "cond_entropy-3": 0.4046051151776122,
        "total_length-nopunct": 1772,
        "mean_pred_length-nopunct": 13.84375,
        "std_pred_length-nopunct": 5.014724412916427,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.4322799097065463,
        "vocab_size-1-nopunct": 766,
        "unique-1-nopunct": 597,
        "entropy-1-nopunct": 8.158741578346092,
        "distinct-2-nopunct": 0.7816301703163017,
        "vocab_size-2-nopunct": 1285,
        "unique-2-nopunct": 1146,
        "entropy-2-nopunct": 9.995334291407616,
        "cond_entropy-2-nopunct": 1.843685615983805,
        "distinct-3-nopunct": 0.9360158311345647,
        "vocab_size-3-nopunct": 1419,
        "unique-3-nopunct": 1363,
        "entropy-3-nopunct": 10.406646380545864,
        "cond_entropy-3-nopunct": 0.3839430602198306,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16363636363636364,
            "2": 0.3289036544850498,
            "3": 0.7779282329045363
        },
        "nist": 7.638232675422316,
        "rouge1": {
            "precision": 0.79981,
            "recall": 0.76853,
            "fmeasure": 0.77536
        },
        "rouge2": {
            "precision": 0.56546,
            "recall": 0.55624,
            "fmeasure": 0.55385
        },
        "rougeL": {
            "precision": 0.70123,
            "recall": 0.68052,
            "fmeasure": 0.68231
        },
        "rougeLsum": {
            "precision": 0.70123,
            "recall": 0.68052,
            "fmeasure": 0.68231
        },
        "bleu": 47.48681,
        "meteor": 0.40590664680533384,
        "bertscore": {
            "precision": 0.93798,
            "recall": 0.9371,
            "f1": 0.93562
        },
        "nubia": {
            "semantic_relation": 4.36947,
            "contradiction": 6.58889,
            "irrelevancy": 30.35769,
            "logical_agreement": 63.05342,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.23348,
            "nubia_score": 0.80095
        },
        "bleurt": 0.33209
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.685638950147956,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.87729,
            "fmeasure": 0.8545
        },
        "rouge2": {
            "precision": 0.5641,
            "recall": 0.59829,
            "fmeasure": 0.58051
        },
        "rougeL": {
            "precision": 0.54762,
            "recall": 0.57692,
            "fmeasure": 0.56173
        },
        "rougeLsum": {
            "precision": 0.54762,
            "recall": 0.57692,
            "fmeasure": 0.56173
        },
        "bleu": 38.60974,
        "meteor": 0.4810476258322474,
        "bertscore": {
            "precision": 0.9486,
            "recall": 0.96263,
            "f1": 0.95556
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23138,
            "irrelevancy": 0.44913,
            "logical_agreement": 99.31949,
            "grammar_ref": 5.12321,
            "grammar_hyp": 4.16617,
            "nubia_score": 1.0
        },
        "bleurt": 0.58643
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 1654,
        "msttr-100": 0.51663,
        "msttr-100_nopunct": 0.52452,
        "total_length": 30931,
        "mean_pred_length": 18.700725513905684,
        "std_pred_length": 6.4059968092831685,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.06226762794607352,
        "vocab_size-1": 1926,
        "unique-1": 618,
        "entropy-1": 8.164979950743835,
        "distinct-2": 0.22174403115073266,
        "vocab_size-2": 6492,
        "unique-2": 3135,
        "entropy-2": 11.297972028244383,
        "cond_entropy-2": 3.064158949782066,
        "distinct-3": 0.39445389711472323,
        "vocab_size-3": 10896,
        "unique-3": 6721,
        "entropy-3": 12.512246254504305,
        "cond_entropy-3": 1.319378682621638,
        "total_length-nopunct": 27972,
        "mean_pred_length-nopunct": 16.911729141475213,
        "std_pred_length-nopunct": 6.09513019753826,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.06853281853281853,
        "vocab_size-1-nopunct": 1917,
        "unique-1-nopunct": 617,
        "entropy-1-nopunct": 8.360600606526408,
        "distinct-2-nopunct": 0.2314765559692986,
        "vocab_size-2-nopunct": 6092,
        "unique-2-nopunct": 3089,
        "entropy-2-nopunct": 11.189213096885032,
        "cond_entropy-2-nopunct": 3.01576335615651,
        "distinct-3-nopunct": 0.40463833927992215,
        "vocab_size-3-nopunct": 9980,
        "unique-3-nopunct": 6312,
        "entropy-3-nopunct": 12.373949760879112,
        "cond_entropy-3-nopunct": 1.2897505268328993,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18847146183374236,
            "2": 0.5069502948609941,
            "3": 0.7475869809203143,
            "4": 0.8909090909090909,
            "5": 0.41379310344827586
        },
        "nist": 6.966270295224029,
        "rouge1": {
            "precision": 0.78354,
            "recall": 0.68522,
            "fmeasure": 0.71789
        },
        "rouge2": {
            "precision": 0.52543,
            "recall": 0.45696,
            "fmeasure": 0.47885
        },
        "rougeL": {
            "precision": 0.64671,
            "recall": 0.56571,
            "fmeasure": 0.59217
        },
        "rougeLsum": {
            "precision": 0.64671,
            "recall": 0.56571,
            "fmeasure": 0.59217
        },
        "bleu": 39.93053,
        "meteor": 0.3307866474392489,
        "bertscore": {
            "precision": 0.92368,
            "recall": 0.90383,
            "f1": 0.91214
        },
        "nubia": {
            "semantic_relation": 4.16457,
            "contradiction": 8.39171,
            "irrelevancy": 9.8421,
            "logical_agreement": 81.76619,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.80791,
            "nubia_score": 0.68469
        },
        "bleurt": 0.08185
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 54,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78625,
        "total_length": 910,
        "mean_pred_length": 16.85185185185185,
        "std_pred_length": 5.512300747746597,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5164835164835165,
        "vocab_size-1": 470,
        "unique-1": 374,
        "entropy-1": 7.815390097791918,
        "distinct-2": 0.8808411214953271,
        "vocab_size-2": 754,
        "unique-2": 700,
        "entropy-2": 9.416308356277565,
        "cond_entropy-2": 1.4213396660557183,
        "distinct-3": 0.9713216957605985,
        "vocab_size-3": 779,
        "unique-3": 758,
        "entropy-3": 9.588219305501939,
        "cond_entropy-3": 0.18382936072893183,
        "total_length-nopunct": 803,
        "mean_pred_length-nopunct": 14.87037037037037,
        "std_pred_length-nopunct": 5.073702338370014,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5740971357409713,
        "vocab_size-1-nopunct": 461,
        "unique-1-nopunct": 372,
        "entropy-1-nopunct": 7.987815797192158,
        "distinct-2-nopunct": 0.8891855807743658,
        "vocab_size-2-nopunct": 666,
        "unique-2-nopunct": 626,
        "entropy-2-nopunct": 9.234781358516054,
        "cond_entropy-2-nopunct": 1.328355768179504,
        "distinct-3-nopunct": 0.9784172661870504,
        "vocab_size-3-nopunct": 680,
        "unique-3-nopunct": 666,
        "entropy-3-nopunct": 9.396617530917135,
        "cond_entropy-3-nopunct": 0.18335874750446168,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26256983240223464,
            "2": 0.4228571428571429,
            "3": 0.7209677419354839
        },
        "nist": 6.8136587827567165,
        "rouge1": {
            "precision": 0.74814,
            "recall": 0.71047,
            "fmeasure": 0.71554
        },
        "rouge2": {
            "precision": 0.51262,
            "recall": 0.49304,
            "fmeasure": 0.49225
        },
        "rougeL": {
            "precision": 0.63302,
            "recall": 0.60926,
            "fmeasure": 0.60874
        },
        "rougeLsum": {
            "precision": 0.63302,
            "recall": 0.60926,
            "fmeasure": 0.60874
        },
        "bleu": 42.87262,
        "meteor": 0.37914022697798533,
        "bertscore": {
            "precision": 0.92617,
            "recall": 0.92324,
            "f1": 0.92343
        },
        "nubia": {
            "semantic_relation": 4.15887,
            "contradiction": 12.07691,
            "irrelevancy": 30.96486,
            "logical_agreement": 56.95824,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.61364,
            "nubia_score": 0.71064
        },
        "bleurt": 0.21891
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 76,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 5.962847939999438,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 56,
        "unique-1": 49,
        "entropy-1": 5.53774108645626,
        "distinct-2": 0.8142857142857143,
        "vocab_size-2": 57,
        "unique-2": 52,
        "entropy-2": 5.650571945454585,
        "cond_entropy-2": 0.007851974533857373,
        "distinct-3": 0.859375,
        "vocab_size-3": 55,
        "unique-3": 51,
        "entropy-3": 5.652114648336087,
        "cond_entropy-3": -0.07857813416627059,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 5.962847939999438,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7714285714285715,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.524075474422109,
        "distinct-2-nopunct": 0.84375,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.601409765557392,
        "cond_entropy-2-nopunct": 0.00907249824680454,
        "distinct-3-nopunct": 0.896551724137931,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.612038538119116,
        "cond_entropy-3-nopunct": -0.08606878939248766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7567567567567568
        },
        "nist": 4.35504951151974,
        "rouge1": {
            "precision": 0.90222,
            "recall": 0.87265,
            "fmeasure": 0.88614
        },
        "rouge2": {
            "precision": 0.78869,
            "recall": 0.77222,
            "fmeasure": 0.77969
        },
        "rougeL": {
            "precision": 0.81556,
            "recall": 0.79839,
            "fmeasure": 0.80626
        },
        "rougeLsum": {
            "precision": 0.81556,
            "recall": 0.79839,
            "fmeasure": 0.80626
        },
        "bleu": 52.41642,
        "meteor": 0.4187711024830107,
        "bertscore": {
            "precision": 0.97135,
            "recall": 0.95885,
            "f1": 0.96491
        },
        "nubia": {
            "semantic_relation": 4.61615,
            "contradiction": 15.69778,
            "irrelevancy": 4.30489,
            "logical_agreement": 79.99733,
            "grammar_ref": 5.92578,
            "grammar_hyp": 6.19195,
            "nubia_score": 0.84107
        },
        "bleurt": 0.69967
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 125,
        "msttr-100": 0.49138,
        "msttr-100_nopunct": 0.4737,
        "total_length": 2930,
        "mean_pred_length": 23.44,
        "std_pred_length": 4.014772720839873,
        "median_pred_length": 25.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.14709897610921502,
        "vocab_size-1": 431,
        "unique-1": 158,
        "entropy-1": 7.075635488685568,
        "distinct-2": 0.3778966131907308,
        "vocab_size-2": 1060,
        "unique-2": 592,
        "entropy-2": 9.3196651966866,
        "cond_entropy-2": 2.256747384014331,
        "distinct-3": 0.5611940298507463,
        "vocab_size-3": 1504,
        "unique-3": 1036,
        "entropy-3": 10.09400030091787,
        "cond_entropy-3": 0.8300602348467152,
        "total_length-nopunct": 2717,
        "mean_pred_length-nopunct": 21.736,
        "std_pred_length-nopunct": 4.010274803551497,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.15642252484357747,
        "vocab_size-1-nopunct": 425,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 7.1202487684280245,
        "distinct-2-nopunct": 0.3819444444444444,
        "vocab_size-2-nopunct": 990,
        "unique-2-nopunct": 563,
        "entropy-2-nopunct": 9.213409134470247,
        "cond_entropy-2-nopunct": 2.1934104084696338,
        "distinct-3-nopunct": 0.558573165788407,
        "vocab_size-3-nopunct": 1378,
        "unique-3-nopunct": 959,
        "entropy-3-nopunct": 9.954999248197156,
        "cond_entropy-3-nopunct": 0.7894519364803726,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.16189856957087126,
            "2": 0.4419475655430712,
            "3": 0.7470238095238095
        },
        "nist": 5.68117680495639,
        "rouge1": {
            "precision": 0.72939,
            "recall": 0.63342,
            "fmeasure": 0.66528
        },
        "rouge2": {
            "precision": 0.43731,
            "recall": 0.38341,
            "fmeasure": 0.39912
        },
        "rougeL": {
            "precision": 0.55464,
            "recall": 0.4858,
            "fmeasure": 0.50745
        },
        "rougeLsum": {
            "precision": 0.55464,
            "recall": 0.4858,
            "fmeasure": 0.50745
        },
        "bleu": 33.95701,
        "meteor": 0.3006480552610662,
        "bertscore": {
            "precision": 0.8984,
            "recall": 0.87623,
            "f1": 0.88533
        },
        "nubia": {
            "semantic_relation": 3.8201,
            "contradiction": 12.83072,
            "irrelevancy": 16.52607,
            "logical_agreement": 70.6432,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.62214,
            "nubia_score": 0.57098
        },
        "bleurt": -0.17757
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.52143,
        "msttr-100_nopunct": 0.54167,
        "total_length": 770,
        "mean_pred_length": 16.041666666666668,
        "std_pred_length": 3.46986030778698,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.3194805194805195,
        "vocab_size-1": 246,
        "unique-1": 198,
        "entropy-1": 6.290118921119913,
        "distinct-2": 0.5623268698060941,
        "vocab_size-2": 406,
        "unique-2": 359,
        "entropy-2": 7.784272102691383,
        "cond_entropy-2": 1.3548753275457737,
        "distinct-3": 0.6706231454005934,
        "vocab_size-3": 452,
        "unique-3": 417,
        "entropy-3": 8.184936315679684,
        "cond_entropy-3": 0.4683595473332401,
        "total_length-nopunct": 665,
        "mean_pred_length-nopunct": 13.854166666666666,
        "std_pred_length-nopunct": 2.943846571900256,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.3609022556390977,
        "vocab_size-1-nopunct": 240,
        "unique-1-nopunct": 198,
        "entropy-1-nopunct": 6.361045682087985,
        "distinct-2-nopunct": 0.5705024311183144,
        "vocab_size-2-nopunct": 352,
        "unique-2-nopunct": 312,
        "entropy-2-nopunct": 7.610733388907584,
        "cond_entropy-2-nopunct": 1.3596439632543813,
        "distinct-3-nopunct": 0.6766256590509666,
        "vocab_size-3-nopunct": 385,
        "unique-3-nopunct": 355,
        "entropy-3-nopunct": 7.972774293491584,
        "cond_entropy-3-nopunct": 0.4861232911069053,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.32432432432432434,
            "2": 0.625,
            "3": 0.834319526627219
        },
        "nist": 7.0231164882349955,
        "rouge1": {
            "precision": 0.78234,
            "recall": 0.80848,
            "fmeasure": 0.78689
        },
        "rouge2": {
            "precision": 0.61009,
            "recall": 0.62577,
            "fmeasure": 0.61134
        },
        "rougeL": {
            "precision": 0.69098,
            "recall": 0.71326,
            "fmeasure": 0.69415
        },
        "rougeLsum": {
            "precision": 0.69098,
            "recall": 0.71326,
            "fmeasure": 0.69415
        },
        "bleu": 60.505,
        "meteor": 0.45076298681301286,
        "bertscore": {
            "precision": 0.94425,
            "recall": 0.94847,
            "f1": 0.94516
        },
        "nubia": {
            "semantic_relation": 4.4429,
            "contradiction": 10.7455,
            "irrelevancy": 15.73493,
            "logical_agreement": 73.51957,
            "grammar_ref": 4.06325,
            "grammar_hyp": 3.90694,
            "nubia_score": 0.84937
        },
        "bleurt": 0.56228
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68683,
        "msttr-100_nopunct": 0.70857,
        "total_length": 6368,
        "mean_pred_length": 12.736,
        "std_pred_length": 6.690762587328891,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 30,
        "distinct-1": 0.15687814070351758,
        "vocab_size-1": 999,
        "unique-1": 564,
        "entropy-1": 7.80809476603071,
        "distinct-2": 0.48057259713701433,
        "vocab_size-2": 2820,
        "unique-2": 1958,
        "entropy-2": 10.670147607397935,
        "cond_entropy-2": 2.627217075872239,
        "distinct-3": 0.7002608047690015,
        "vocab_size-3": 3759,
        "unique-3": 3058,
        "entropy-3": 11.487642256610627,
        "cond_entropy-3": 0.8389289530488535,
        "total_length-nopunct": 5611,
        "mean_pred_length-nopunct": 11.222,
        "std_pred_length-nopunct": 6.213591232129774,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.1757262520049902,
        "vocab_size-1-nopunct": 986,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 7.981942219869354,
        "distinct-2-nopunct": 0.498923889649775,
        "vocab_size-2-nopunct": 2550,
        "unique-2-nopunct": 1816,
        "entropy-2-nopunct": 10.51544816867354,
        "cond_entropy-2-nopunct": 2.6605192292179978,
        "distinct-3-nopunct": 0.7165473866840165,
        "vocab_size-3-nopunct": 3304,
        "unique-3-nopunct": 2748,
        "entropy-3-nopunct": 11.295168767298026,
        "cond_entropy-3-nopunct": 0.8240700210341535,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5686201780415431
        },
        "nist": 5.909992674342335,
        "rouge1": {
            "precision": 0.55576,
            "recall": 0.55451,
            "fmeasure": 0.54292
        },
        "rouge2": {
            "precision": 0.34304,
            "recall": 0.34227,
            "fmeasure": 0.3347
        },
        "rougeL": {
            "precision": 0.4946,
            "recall": 0.49371,
            "fmeasure": 0.48337
        },
        "rougeLsum": {
            "precision": 0.4946,
            "recall": 0.49371,
            "fmeasure": 0.48337
        },
        "bleu": 31.43829,
        "meteor": 0.3167103582138943,
        "bertscore": {
            "precision": 0.8691,
            "recall": 0.8671,
            "f1": 0.86758
        },
        "nubia": {
            "semantic_relation": 3.64371,
            "contradiction": 5.13684,
            "irrelevancy": 24.48326,
            "logical_agreement": 70.37989,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.49215,
            "nubia_score": 0.65872
        },
        "bleurt": -0.05888
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 369,
        "msttr-100": 0.64861,
        "msttr-100_nopunct": 0.69065,
        "total_length": 3604,
        "mean_pred_length": 9.766937669376693,
        "std_pred_length": 2.7408169610539614,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.22169811320754718,
        "vocab_size-1": 799,
        "unique-1": 449,
        "entropy-1": 7.536476462916842,
        "distinct-2": 0.5360123647604328,
        "vocab_size-2": 1734,
        "unique-2": 1240,
        "entropy-2": 10.182814386756466,
        "cond_entropy-2": 2.161279766933685,
        "distinct-3": 0.7302861130495464,
        "vocab_size-3": 2093,
        "unique-3": 1735,
        "entropy-3": 10.755406304130844,
        "cond_entropy-3": 0.6663266663975735,
        "total_length-nopunct": 3143,
        "mean_pred_length-nopunct": 8.517615176151761,
        "std_pred_length-nopunct": 2.478162347700066,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.25198854597518294,
        "vocab_size-1-nopunct": 792,
        "unique-1-nopunct": 448,
        "entropy-1-nopunct": 7.848448291724593,
        "distinct-2-nopunct": 0.5169430425378515,
        "vocab_size-2-nopunct": 1434,
        "unique-2-nopunct": 1011,
        "entropy-2-nopunct": 9.877820934054867,
        "cond_entropy-2-nopunct": 2.341764772421418,
        "distinct-3-nopunct": 0.716008316008316,
        "vocab_size-3-nopunct": 1722,
        "unique-3-nopunct": 1409,
        "entropy-3-nopunct": 10.458342281412738,
        "cond_entropy-3-nopunct": 0.7199677048224843,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2288135593220339,
            "2": 0.6916802610114192,
            "3": 0.8837981407702523,
            "4": 1.0
        },
        "nist": 9.309802922948741,
        "rouge1": {
            "precision": 0.83483,
            "recall": 0.79738,
            "fmeasure": 0.80842
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.58741,
            "fmeasure": 0.59529
        },
        "rougeL": {
            "precision": 0.75283,
            "recall": 0.71806,
            "fmeasure": 0.72828
        },
        "rougeLsum": {
            "precision": 0.75283,
            "recall": 0.71806,
            "fmeasure": 0.72828
        },
        "bleu": 62.45059,
        "meteor": 0.4714024659201262,
        "bertscore": {
            "precision": 0.95236,
            "recall": 0.94928,
            "f1": 0.94986
        },
        "nubia": {
            "semantic_relation": 4.60494,
            "contradiction": 6.88175,
            "irrelevancy": 6.78133,
            "logical_agreement": 86.33692,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.32467,
            "nubia_score": 0.82919
        },
        "bleurt": 0.41312
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.67571,
        "msttr-100_nopunct": 0.70833,
        "total_length": 754,
        "mean_pred_length": 16.04255319148936,
        "std_pred_length": 5.094667411559336,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5,
        "vocab_size-1": 377,
        "unique-1": 309,
        "entropy-1": 7.328636459128207,
        "distinct-2": 0.85997171145686,
        "vocab_size-2": 608,
        "unique-2": 558,
        "entropy-2": 9.064405884051116,
        "cond_entropy-2": 1.5442345857780706,
        "distinct-3": 0.956060606060606,
        "vocab_size-3": 631,
        "unique-3": 609,
        "entropy-3": 9.266913668072327,
        "cond_entropy-3": 0.22084059761734776,
        "total_length-nopunct": 668,
        "mean_pred_length-nopunct": 14.212765957446809,
        "std_pred_length-nopunct": 5.044213749384476,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5553892215568862,
        "vocab_size-1-nopunct": 371,
        "unique-1-nopunct": 308,
        "entropy-1-nopunct": 7.452948273765176,
        "distinct-2-nopunct": 0.8663446054750402,
        "vocab_size-2-nopunct": 538,
        "unique-2-nopunct": 498,
        "entropy-2-nopunct": 8.883512324243922,
        "cond_entropy-2-nopunct": 1.5573684512505894,
        "distinct-3-nopunct": 0.9668989547038328,
        "vocab_size-3-nopunct": 555,
        "unique-3-nopunct": 538,
        "entropy-3-nopunct": 9.095220515525765,
        "cond_entropy-3-nopunct": 0.23533544789668884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1592920353982301,
            "2": 0.4411764705882353,
            "3": 0.74375
        },
        "nist": 6.232337065635807,
        "rouge1": {
            "precision": 0.74275,
            "recall": 0.69857,
            "fmeasure": 0.71124
        },
        "rouge2": {
            "precision": 0.48477,
            "recall": 0.46012,
            "fmeasure": 0.46713
        },
        "rougeL": {
            "precision": 0.63331,
            "recall": 0.60191,
            "fmeasure": 0.60967
        },
        "rougeLsum": {
            "precision": 0.63331,
            "recall": 0.60191,
            "fmeasure": 0.60967
        },
        "bleu": 38.28841,
        "meteor": 0.3580287970061566,
        "bertscore": {
            "precision": 0.92601,
            "recall": 0.91654,
            "f1": 0.9202
        },
        "nubia": {
            "semantic_relation": 4.1196,
            "contradiction": 9.54416,
            "irrelevancy": 31.30773,
            "logical_agreement": 59.1481,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.82021,
            "nubia_score": 0.67656
        },
        "bleurt": 0.23623
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 350,
        "msttr-100": 0.67108,
        "msttr-100_nopunct": 0.69864,
        "total_length": 7409,
        "mean_pred_length": 21.16857142857143,
        "std_pred_length": 3.843010087237899,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.1434741530570927,
        "vocab_size-1": 1063,
        "unique-1": 395,
        "entropy-1": 7.943823540670849,
        "distinct-2": 0.402039949001275,
        "vocab_size-2": 2838,
        "unique-2": 1671,
        "entropy-2": 10.680984665030731,
        "cond_entropy-2": 2.648232865349017,
        "distinct-3": 0.6033686093307498,
        "vocab_size-3": 4048,
        "unique-3": 2940,
        "entropy-3": 11.564336792190495,
        "cond_entropy-3": 0.9447525095916112,
        "total_length-nopunct": 6699,
        "mean_pred_length-nopunct": 19.14,
        "std_pred_length-nopunct": 3.7683418103988386,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.1573369159576056,
        "vocab_size-1-nopunct": 1054,
        "unique-1-nopunct": 393,
        "entropy-1-nopunct": 8.110625944364655,
        "distinct-2-nopunct": 0.4077807528744684,
        "vocab_size-2-nopunct": 2589,
        "unique-2-nopunct": 1569,
        "entropy-2-nopunct": 10.54361138237619,
        "cond_entropy-2-nopunct": 2.574907709175165,
        "distinct-3-nopunct": 0.6084347391231872,
        "vocab_size-3-nopunct": 3650,
        "unique-3-nopunct": 2687,
        "entropy-3-nopunct": 11.411524959191599,
        "cond_entropy-3-nopunct": 0.9197143724713558,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2108380219129405,
            "2": 0.5570433851098018,
            "3": 0.8481308411214953,
            "4": 0.4,
            "5": 0.41379310344827586
        },
        "nist": 8.4324802515999,
        "rouge1": {
            "precision": 0.76126,
            "recall": 0.72888,
            "fmeasure": 0.7376
        },
        "rouge2": {
            "precision": 0.49334,
            "recall": 0.46727,
            "fmeasure": 0.47478
        },
        "rougeL": {
            "precision": 0.60877,
            "recall": 0.5763,
            "fmeasure": 0.58592
        },
        "rougeLsum": {
            "precision": 0.60877,
            "recall": 0.5763,
            "fmeasure": 0.58592
        },
        "bleu": 45.18533,
        "meteor": 0.37612290973778173,
        "bertscore": {
            "precision": 0.91651,
            "recall": 0.90995,
            "f1": 0.91176
        },
        "nubia": {
            "semantic_relation": 4.34008,
            "contradiction": 8.66739,
            "irrelevancy": 9.67149,
            "logical_agreement": 81.66112,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.6553,
            "nubia_score": 0.7465
        },
        "bleurt": 0.11613
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.6915,
        "msttr-100_nopunct": 0.74647,
        "total_length": 2002,
        "mean_pred_length": 15.640625,
        "std_pred_length": 5.064790184141392,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.42207792207792205,
        "vocab_size-1": 845,
        "unique-1": 672,
        "entropy-1": 8.113997484747662,
        "distinct-2": 0.8153681963713981,
        "vocab_size-2": 1528,
        "unique-2": 1373,
        "entropy-2": 10.32085377599031,
        "cond_entropy-2": 1.967014433889792,
        "distinct-3": 0.9427262313860252,
        "vocab_size-3": 1646,
        "unique-3": 1586,
        "entropy-3": 10.627760514721604,
        "cond_entropy-3": 0.27171037571535356,
        "total_length-nopunct": 1765,
        "mean_pred_length-nopunct": 13.7890625,
        "std_pred_length-nopunct": 4.775674598535137,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4753541076487252,
        "vocab_size-1-nopunct": 839,
        "unique-1-nopunct": 671,
        "entropy-1-nopunct": 8.414988318646884,
        "distinct-2-nopunct": 0.8387293830177154,
        "vocab_size-2-nopunct": 1373,
        "unique-2-nopunct": 1257,
        "entropy-2-nopunct": 10.190189918489263,
        "cond_entropy-2-nopunct": 1.8460502531517693,
        "distinct-3-nopunct": 0.9648774022531478,
        "vocab_size-3-nopunct": 1456,
        "unique-3-nopunct": 1423,
        "entropy-3-nopunct": 10.475719813550555,
        "cond_entropy-3-nopunct": 0.28676014327422417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2182890855457227,
            "2": 0.27755102040816326,
            "3": 0.8157894736842105
        },
        "nist": 8.02952946391694,
        "rouge1": {
            "precision": 0.81711,
            "recall": 0.78871,
            "fmeasure": 0.79403
        },
        "rouge2": {
            "precision": 0.57264,
            "recall": 0.56032,
            "fmeasure": 0.55966
        },
        "rougeL": {
            "precision": 0.70654,
            "recall": 0.68775,
            "fmeasure": 0.68875
        },
        "rougeLsum": {
            "precision": 0.70654,
            "recall": 0.68775,
            "fmeasure": 0.68875
        },
        "bleu": 48.35379,
        "meteor": 0.4189800158038515,
        "bertscore": {
            "precision": 0.94013,
            "recall": 0.93836,
            "f1": 0.93775
        },
        "nubia": {
            "semantic_relation": 4.47486,
            "contradiction": 7.79827,
            "irrelevancy": 18.21032,
            "logical_agreement": 73.99141,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.56123,
            "nubia_score": 0.816
        },
        "bleurt": 0.40404
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 66,
        "msttr-100": 0.739,
        "msttr-100_nopunct": 0.78778,
        "total_length": 1061,
        "mean_pred_length": 16.075757575757574,
        "std_pred_length": 5.326635773966831,
        "median_pred_length": 16.5,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5155513666352498,
        "vocab_size-1": 547,
        "unique-1": 452,
        "entropy-1": 7.920429769131008,
        "distinct-2": 0.8653266331658291,
        "vocab_size-2": 861,
        "unique-2": 786,
        "entropy-2": 9.595772092186085,
        "cond_entropy-2": 1.4612728723754949,
        "distinct-3": 0.9558665231431647,
        "vocab_size-3": 888,
        "unique-3": 858,
        "entropy-3": 9.750209142885112,
        "cond_entropy-3": 0.12848416946005292,
        "total_length-nopunct": 928,
        "mean_pred_length-nopunct": 14.06060606060606,
        "std_pred_length-nopunct": 4.839480274746477,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5797413793103449,
        "vocab_size-1-nopunct": 538,
        "unique-1-nopunct": 447,
        "entropy-1-nopunct": 8.159158161386724,
        "distinct-2-nopunct": 0.8851508120649652,
        "vocab_size-2-nopunct": 763,
        "unique-2-nopunct": 702,
        "entropy-2-nopunct": 9.455252646885716,
        "cond_entropy-2-nopunct": 1.3582871945537234,
        "distinct-3-nopunct": 0.9673366834170855,
        "vocab_size-3-nopunct": 770,
        "unique-3-nopunct": 746,
        "entropy-3-nopunct": 9.569401285111152,
        "cond_entropy-3-nopunct": 0.08380994011716886,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23383084577114427,
            "2": 0.39285714285714285,
            "3": 0.7198275862068966
        },
        "nist": 6.452297969161747,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.69728,
            "fmeasure": 0.69693
        },
        "rouge2": {
            "precision": 0.49104,
            "recall": 0.4792,
            "fmeasure": 0.47585
        },
        "rougeL": {
            "precision": 0.63882,
            "recall": 0.62051,
            "fmeasure": 0.61631
        },
        "rougeLsum": {
            "precision": 0.63882,
            "recall": 0.62051,
            "fmeasure": 0.61631
        },
        "bleu": 37.21928,
        "meteor": 0.36624317505647497,
        "bertscore": {
            "precision": 0.91504,
            "recall": 0.91565,
            "f1": 0.91371
        },
        "nubia": {
            "semantic_relation": 4.11577,
            "contradiction": 9.25782,
            "irrelevancy": 36.81551,
            "logical_agreement": 53.92667,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.28681,
            "nubia_score": 0.71914
        },
        "bleurt": 0.21015
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 114,
        "msttr-100": 0.66444,
        "msttr-100_nopunct": 0.6848,
        "total_length": 2755,
        "mean_pred_length": 24.166666666666668,
        "std_pred_length": 2.806373281328064,
        "median_pred_length": 24.0,
        "min_pred_length": 18,
        "max_pred_length": 31,
        "distinct-1": 0.2206896551724138,
        "vocab_size-1": 608,
        "unique-1": 274,
        "entropy-1": 7.628629866033653,
        "distinct-2": 0.47519878833775087,
        "vocab_size-2": 1255,
        "unique-2": 761,
        "entropy-2": 9.743713866376355,
        "cond_entropy-2": 2.1851280185076676,
        "distinct-3": 0.6264345073209339,
        "vocab_size-3": 1583,
        "unique-3": 1123,
        "entropy-3": 10.2971122816406,
        "cond_entropy-3": 0.5965185470491127,
        "total_length-nopunct": 2531,
        "mean_pred_length-nopunct": 22.20175438596491,
        "std_pred_length-nopunct": 2.8196672211307776,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.2374555511655472,
        "vocab_size-1-nopunct": 601,
        "unique-1-nopunct": 271,
        "entropy-1-nopunct": 7.7302543088490046,
        "distinct-2-nopunct": 0.49151841125362017,
        "vocab_size-2-nopunct": 1188,
        "unique-2-nopunct": 732,
        "entropy-2-nopunct": 9.707971652511787,
        "cond_entropy-2-nopunct": 2.0649586618271405,
        "distinct-3-nopunct": 0.6404689535388624,
        "vocab_size-3-nopunct": 1475,
        "unique-3-nopunct": 1069,
        "entropy-3-nopunct": 10.207476561799686,
        "cond_entropy-3-nopunct": 0.5474915299356358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.13703284258210646,
            "2": 0.3897849462365591,
            "3": 0.5839598997493735
        },
        "nist": 1.5866193315404886,
        "rouge1": {
            "precision": 0.7827,
            "recall": 0.45571,
            "fmeasure": 0.56752
        },
        "rouge2": {
            "precision": 0.47529,
            "recall": 0.25928,
            "fmeasure": 0.33018
        },
        "rougeL": {
            "precision": 0.59771,
            "recall": 0.34395,
            "fmeasure": 0.42975
        },
        "rougeLsum": {
            "precision": 0.59771,
            "recall": 0.34395,
            "fmeasure": 0.42975
        },
        "bleu": 22.91689,
        "meteor": 0.22929240743269172,
        "bertscore": {
            "precision": 0.90119,
            "recall": 0.82998,
            "f1": 0.86218
        },
        "nubia": {
            "semantic_relation": 3.2287,
            "contradiction": 11.94081,
            "irrelevancy": 18.50116,
            "logical_agreement": 69.55803,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.61518,
            "nubia_score": 0.35719
        },
        "bleurt": -0.3953
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846626,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.12336199461765371,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.6,
            "3": 0.5714285714285714
        },
        "nist": 3.9567061359617997,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.59524,
            "fmeasure": 0.64103
        },
        "rouge2": {
            "precision": 0.4058,
            "recall": 0.34568,
            "fmeasure": 0.37333
        },
        "rougeL": {
            "precision": 0.43056,
            "recall": 0.40476,
            "fmeasure": 0.41538
        },
        "rougeLsum": {
            "precision": 0.43056,
            "recall": 0.40476,
            "fmeasure": 0.41538
        },
        "bleu": 35.00788,
        "meteor": 0.3245801827975201,
        "bertscore": {
            "precision": 0.87376,
            "recall": 0.83651,
            "f1": 0.85473
        },
        "nubia": {
            "semantic_relation": 3.68535,
            "contradiction": 1.52651,
            "irrelevancy": 45.61631,
            "logical_agreement": 52.85718,
            "grammar_ref": 3.5675,
            "grammar_hyp": 4.32215,
            "nubia_score": 0.5264
        },
        "bleurt": -0.49006
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 305,
        "msttr-100": 0.65833,
        "msttr-100_nopunct": 0.67561,
        "total_length": 7214,
        "mean_pred_length": 23.652459016393443,
        "std_pred_length": 3.170127295234763,
        "median_pred_length": 24.0,
        "min_pred_length": 14,
        "max_pred_length": 31,
        "distinct-1": 0.1535902411976712,
        "vocab_size-1": 1108,
        "unique-1": 441,
        "entropy-1": 7.956272072977504,
        "distinct-2": 0.4138080764220582,
        "vocab_size-2": 2859,
        "unique-2": 1739,
        "entropy-2": 10.673520213324291,
        "cond_entropy-2": 2.740867606686761,
        "distinct-3": 0.6184130829800121,
        "vocab_size-3": 4084,
        "unique-3": 3010,
        "entropy-3": 11.594937806774647,
        "cond_entropy-3": 0.977837240570902,
        "total_length-nopunct": 6628,
        "mean_pred_length-nopunct": 21.731147540983606,
        "std_pred_length-nopunct": 3.2942842195559363,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.16611345805672903,
        "vocab_size-1-nopunct": 1101,
        "unique-1-nopunct": 440,
        "entropy-1-nopunct": 8.080916777276821,
        "distinct-2-nopunct": 0.4290684801518267,
        "vocab_size-2-nopunct": 2713,
        "unique-2-nopunct": 1697,
        "entropy-2-nopunct": 10.63905968292282,
        "cond_entropy-2-nopunct": 2.6664883267946693,
        "distinct-3-nopunct": 0.6301096709870389,
        "vocab_size-3-nopunct": 3792,
        "unique-3-nopunct": 2847,
        "entropy-3-nopunct": 11.498904450211327,
        "cond_entropy-3-nopunct": 0.9208850332485041,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.17123670956911025,
            "2": 0.520776874435411,
            "3": 0.7436922308268799
        },
        "nist": 6.84596300209988,
        "rouge1": {
            "precision": 0.74882,
            "recall": 0.62919,
            "fmeasure": 0.67573
        },
        "rouge2": {
            "precision": 0.4703,
            "recall": 0.38696,
            "fmeasure": 0.41864
        },
        "rougeL": {
            "precision": 0.58381,
            "recall": 0.48886,
            "fmeasure": 0.52544
        },
        "rougeLsum": {
            "precision": 0.58381,
            "recall": 0.48886,
            "fmeasure": 0.52544
        },
        "bleu": 38.34792,
        "meteor": 0.3185160496496681,
        "bertscore": {
            "precision": 0.90498,
            "recall": 0.87778,
            "f1": 0.88983
        },
        "nubia": {
            "semantic_relation": 3.81372,
            "contradiction": 10.7209,
            "irrelevancy": 14.11972,
            "logical_agreement": 75.15938,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.56125,
            "nubia_score": 0.58034
        },
        "bleurt": -0.11828
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 79,
        "msttr-100": 0.68263,
        "msttr-100_nopunct": 0.70412,
        "total_length": 1923,
        "mean_pred_length": 24.341772151898734,
        "std_pred_length": 3.0058427321408097,
        "median_pred_length": 25.0,
        "min_pred_length": 18,
        "max_pred_length": 31,
        "distinct-1": 0.24440977639105566,
        "vocab_size-1": 470,
        "unique-1": 240,
        "entropy-1": 7.42547029122258,
        "distinct-2": 0.47559652928416485,
        "vocab_size-2": 877,
        "unique-2": 559,
        "entropy-2": 9.270955728511105,
        "cond_entropy-2": 1.9161555965122428,
        "distinct-3": 0.5949008498583569,
        "vocab_size-3": 1050,
        "unique-3": 753,
        "entropy-3": 9.6719064199308,
        "cond_entropy-3": 0.44818709249227945,
        "total_length-nopunct": 1759,
        "mean_pred_length-nopunct": 22.265822784810126,
        "std_pred_length-nopunct": 2.8891278556102593,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.2637862421830586,
        "vocab_size-1-nopunct": 464,
        "unique-1-nopunct": 240,
        "entropy-1-nopunct": 7.503510744437996,
        "distinct-2-nopunct": 0.493452380952381,
        "vocab_size-2-nopunct": 829,
        "unique-2-nopunct": 546,
        "entropy-2-nopunct": 9.210892955290596,
        "cond_entropy-2-nopunct": 1.7910057971933973,
        "distinct-3-nopunct": 0.6127420362273579,
        "vocab_size-3-nopunct": 981,
        "unique-3-nopunct": 723,
        "entropy-3-nopunct": 9.58822276028825,
        "cond_entropy-3-nopunct": 0.42402838400150117,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1323529411764706,
            "2": 0.2866578599735799,
            "3": 0.5277301315037164
        },
        "nist": 0.648206352683395,
        "rouge1": {
            "precision": 0.79135,
            "recall": 0.40107,
            "fmeasure": 0.52395
        },
        "rouge2": {
            "precision": 0.48261,
            "recall": 0.23249,
            "fmeasure": 0.30827
        },
        "rougeL": {
            "precision": 0.62089,
            "recall": 0.30959,
            "fmeasure": 0.40616
        },
        "rougeLsum": {
            "precision": 0.62089,
            "recall": 0.30959,
            "fmeasure": 0.40616
        },
        "bleu": 18.12838,
        "meteor": 0.2041072989344778,
        "bertscore": {
            "precision": 0.90343,
            "recall": 0.82075,
            "f1": 0.85892
        },
        "nubia": {
            "semantic_relation": 3.13121,
            "contradiction": 10.30987,
            "irrelevancy": 12.45082,
            "logical_agreement": 77.23932,
            "grammar_ref": 3.96506,
            "grammar_hyp": 4.63904,
            "nubia_score": 0.3361
        },
        "bleurt": -0.52199
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 297,
        "msttr-100": 0.64407,
        "msttr-100_nopunct": 0.68667,
        "total_length": 2796,
        "mean_pred_length": 9.414141414141413,
        "std_pred_length": 2.379811699296771,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 20,
        "distinct-1": 0.244277539341917,
        "vocab_size-1": 683,
        "unique-1": 384,
        "entropy-1": 7.436491219291481,
        "distinct-2": 0.5678271308523409,
        "vocab_size-2": 1419,
        "unique-2": 1020,
        "entropy-2": 9.961048997823982,
        "cond_entropy-2": 2.0252006263392914,
        "distinct-3": 0.762488646684832,
        "vocab_size-3": 1679,
        "unique-3": 1407,
        "entropy-3": 10.481684311397608,
        "cond_entropy-3": 0.6002016800412946,
        "total_length-nopunct": 2450,
        "mean_pred_length-nopunct": 8.24915824915825,
        "std_pred_length-nopunct": 2.2046494255176534,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.27591836734693875,
        "vocab_size-1-nopunct": 676,
        "unique-1-nopunct": 383,
        "entropy-1-nopunct": 7.748664106323624,
        "distinct-2-nopunct": 0.5466790524849048,
        "vocab_size-2-nopunct": 1177,
        "unique-2-nopunct": 833,
        "entropy-2-nopunct": 9.656678592088209,
        "cond_entropy-2-nopunct": 2.203657085229256,
        "distinct-3-nopunct": 0.7462284482758621,
        "vocab_size-3-nopunct": 1385,
        "unique-3-nopunct": 1146,
        "entropy-3-nopunct": 10.18556242769209,
        "cond_entropy-3-nopunct": 0.658691463845546,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2243502051983584,
            "2": 0.6880829015544041,
            "3": 0.8895497026338148,
            "4": 1.0
        },
        "nist": 9.339981219805999,
        "rouge1": {
            "precision": 0.84043,
            "recall": 0.80548,
            "fmeasure": 0.81599
        },
        "rouge2": {
            "precision": 0.63426,
            "recall": 0.60569,
            "fmeasure": 0.61412
        },
        "rougeL": {
            "precision": 0.76568,
            "recall": 0.73059,
            "fmeasure": 0.7414
        },
        "rougeLsum": {
            "precision": 0.76568,
            "recall": 0.73059,
            "fmeasure": 0.7414
        },
        "bleu": 65.85215,
        "meteor": 0.48357851185180056,
        "bertscore": {
            "precision": 0.95754,
            "recall": 0.95459,
            "f1": 0.95523
        },
        "nubia": {
            "semantic_relation": 4.62433,
            "contradiction": 6.8858,
            "irrelevancy": 6.11531,
            "logical_agreement": 86.99889,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.25909,
            "nubia_score": 0.84455
        },
        "bleurt": 0.44882
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 1510,
        "msttr-100": 0.50628,
        "msttr-100_nopunct": 0.50911,
        "total_length": 27492,
        "mean_pred_length": 18.20662251655629,
        "std_pred_length": 6.393784946618002,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.06572821184344536,
        "vocab_size-1": 1807,
        "unique-1": 597,
        "entropy-1": 8.117368889827654,
        "distinct-2": 0.22430913709491188,
        "vocab_size-2": 5828,
        "unique-2": 2817,
        "entropy-2": 11.177028215609191,
        "cond_entropy-2": 2.9765102018786895,
        "distinct-3": 0.39163125204315136,
        "vocab_size-3": 9584,
        "unique-3": 5890,
        "entropy-3": 12.334310393070904,
        "cond_entropy-3": 1.2662997975227743,
        "total_length-nopunct": 24872,
        "mean_pred_length-nopunct": 16.471523178807946,
        "std_pred_length-nopunct": 6.103211373584795,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07229012544226439,
        "vocab_size-1-nopunct": 1798,
        "unique-1-nopunct": 596,
        "entropy-1-nopunct": 8.314181460212431,
        "distinct-2-nopunct": 0.23170105299203836,
        "vocab_size-2-nopunct": 5413,
        "unique-2-nopunct": 2733,
        "entropy-2-nopunct": 11.05106872576767,
        "cond_entropy-2-nopunct": 2.930655019687076,
        "distinct-3-nopunct": 0.39886509244005125,
        "vocab_size-3-nopunct": 8716,
        "unique-3-nopunct": 5474,
        "entropy-3-nopunct": 12.182012348336983,
        "cond_entropy-3-nopunct": 1.2411090465241086,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1930686023341873,
            "2": 0.517103090351498,
            "3": 0.7537052350359392,
            "4": 0.9411764705882353,
            "5": 0.42857142857142855
        },
        "nist": 7.103076247179354,
        "rouge1": {
            "precision": 0.78938,
            "recall": 0.69503,
            "fmeasure": 0.72561
        },
        "rouge2": {
            "precision": 0.53724,
            "recall": 0.47103,
            "fmeasure": 0.49156
        },
        "rougeL": {
            "precision": 0.65595,
            "recall": 0.57811,
            "fmeasure": 0.60287
        },
        "rougeLsum": {
            "precision": 0.65595,
            "recall": 0.57811,
            "fmeasure": 0.60287
        },
        "bleu": 41.16915,
        "meteor": 0.33667711440754455,
        "bertscore": {
            "precision": 0.92704,
            "recall": 0.90801,
            "f1": 0.91591
        },
        "nubia": {
            "semantic_relation": 4.2058,
            "contradiction": 8.30083,
            "irrelevancy": 9.41087,
            "logical_agreement": 82.2883,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.80889,
            "nubia_score": 0.69887
        },
        "bleurt": 0.11411
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 72,
        "msttr-100": 0.61625,
        "msttr-100_nopunct": 0.65,
        "total_length": 808,
        "mean_pred_length": 11.222222222222221,
        "std_pred_length": 3.5364067695198997,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.33663366336633666,
        "vocab_size-1": 272,
        "unique-1": 179,
        "entropy-1": 6.72741570982064,
        "distinct-2": 0.6535326086956522,
        "vocab_size-2": 481,
        "unique-2": 377,
        "entropy-2": 8.55511378195183,
        "cond_entropy-2": 1.5088800387230654,
        "distinct-3": 0.7801204819277109,
        "vocab_size-3": 518,
        "unique-3": 446,
        "entropy-3": 8.817221562501675,
        "cond_entropy-3": 0.3343568483712258,
        "total_length-nopunct": 693,
        "mean_pred_length-nopunct": 9.625,
        "std_pred_length-nopunct": 3.1465920718559413,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.3852813852813853,
        "vocab_size-1-nopunct": 267,
        "unique-1-nopunct": 178,
        "entropy-1-nopunct": 6.900491382435688,
        "distinct-2-nopunct": 0.644122383252818,
        "vocab_size-2-nopunct": 400,
        "unique-2-nopunct": 309,
        "entropy-2-nopunct": 8.292041549524708,
        "cond_entropy-2-nopunct": 1.6123091371832459,
        "distinct-3-nopunct": 0.7759562841530054,
        "vocab_size-3-nopunct": 426,
        "unique-3-nopunct": 364,
        "entropy-3-nopunct": 8.53679686816739,
        "cond_entropy-3-nopunct": 0.3290294205076927,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.24413145539906103,
            "2": 0.7049808429118773,
            "3": 0.8632218844984803
        },
        "nist": 7.297001661192927,
        "rouge1": {
            "precision": 0.81173,
            "recall": 0.76398,
            "fmeasure": 0.7772
        },
        "rouge2": {
            "precision": 0.53748,
            "recall": 0.512,
            "fmeasure": 0.51762
        },
        "rougeL": {
            "precision": 0.69985,
            "recall": 0.66636,
            "fmeasure": 0.67418
        },
        "rougeLsum": {
            "precision": 0.69985,
            "recall": 0.66636,
            "fmeasure": 0.67418
        },
        "bleu": 50.80983,
        "meteor": 0.43137978715995723,
        "bertscore": {
            "precision": 0.93103,
            "recall": 0.92735,
            "f1": 0.92774
        },
        "nubia": {
            "semantic_relation": 4.52498,
            "contradiction": 6.86503,
            "irrelevancy": 9.52865,
            "logical_agreement": 83.60632,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.59518,
            "nubia_score": 0.76585
        },
        "bleurt": 0.26586
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 45,
        "msttr-100": 0.67286,
        "msttr-100_nopunct": 0.71167,
        "total_length": 710,
        "mean_pred_length": 15.777777777777779,
        "std_pred_length": 4.934634463053025,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.46619718309859154,
        "vocab_size-1": 331,
        "unique-1": 260,
        "entropy-1": 7.255418754208306,
        "distinct-2": 0.793984962406015,
        "vocab_size-2": 528,
        "unique-2": 463,
        "entropy-2": 8.780398860935163,
        "cond_entropy-2": 1.3548363727611157,
        "distinct-3": 0.9387096774193548,
        "vocab_size-3": 582,
        "unique-3": 552,
        "entropy-3": 9.140843271434056,
        "cond_entropy-3": 0.36182590263659264,
        "total_length-nopunct": 647,
        "mean_pred_length-nopunct": 14.377777777777778,
        "std_pred_length-nopunct": 4.958892747776526,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5054095826893354,
        "vocab_size-1-nopunct": 327,
        "unique-1-nopunct": 258,
        "entropy-1-nopunct": 7.377148490776716,
        "distinct-2-nopunct": 0.7940199335548173,
        "vocab_size-2-nopunct": 478,
        "unique-2-nopunct": 419,
        "entropy-2-nopunct": 8.628761084260823,
        "cond_entropy-2-nopunct": 1.31634046514494,
        "distinct-3-nopunct": 0.9353680430879713,
        "vocab_size-3-nopunct": 521,
        "unique-3-nopunct": 492,
        "entropy-3-nopunct": 8.979487888114196,
        "cond_entropy-3-nopunct": 0.38851623232919813,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.53125,
            "3": 0.805668016194332
        },
        "nist": 7.261270096678024,
        "rouge1": {
            "precision": 0.82425,
            "recall": 0.76192,
            "fmeasure": 0.78011
        },
        "rouge2": {
            "precision": 0.60597,
            "recall": 0.56367,
            "fmeasure": 0.57448
        },
        "rougeL": {
            "precision": 0.69443,
            "recall": 0.64283,
            "fmeasure": 0.65621
        },
        "rougeLsum": {
            "precision": 0.69443,
            "recall": 0.64283,
            "fmeasure": 0.65621
        },
        "bleu": 47.88641,
        "meteor": 0.4182851908909499,
        "bertscore": {
            "precision": 0.94877,
            "recall": 0.93886,
            "f1": 0.94309
        },
        "nubia": {
            "semantic_relation": 4.46702,
            "contradiction": 4.07651,
            "irrelevancy": 25.08674,
            "logical_agreement": 70.83675,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.97714,
            "nubia_score": 0.79194
        },
        "bleurt": 0.39729
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 123,
        "msttr-100": 0.64684,
        "msttr-100_nopunct": 0.68,
        "total_length": 1913,
        "mean_pred_length": 15.552845528455284,
        "std_pred_length": 4.981597438691648,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.37637219027705177,
        "vocab_size-1": 720,
        "unique-1": 590,
        "entropy-1": 7.546682346517163,
        "distinct-2": 0.6916201117318436,
        "vocab_size-2": 1238,
        "unique-2": 1132,
        "entropy-2": 9.499380540244312,
        "cond_entropy-2": 1.7467596019886042,
        "distinct-3": 0.7960407918416317,
        "vocab_size-3": 1327,
        "unique-3": 1272,
        "entropy-3": 9.844481349356727,
        "cond_entropy-3": 0.40931577729584134,
        "total_length-nopunct": 1674,
        "mean_pred_length-nopunct": 13.609756097560975,
        "std_pred_length-nopunct": 4.5543406372051916,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4265232974910394,
        "vocab_size-1-nopunct": 714,
        "unique-1-nopunct": 590,
        "entropy-1-nopunct": 7.7555764953684445,
        "distinct-2-nopunct": 0.6989039329464861,
        "vocab_size-2-nopunct": 1084,
        "unique-2-nopunct": 999,
        "entropy-2-nopunct": 9.319262680242367,
        "cond_entropy-2-nopunct": 1.7333026177949185,
        "distinct-3-nopunct": 0.803921568627451,
        "vocab_size-3-nopunct": 1148,
        "unique-3-nopunct": 1105,
        "entropy-3-nopunct": 9.659000020240953,
        "cond_entropy-3-nopunct": 0.44012413876717593,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2791519434628975,
            "2": 0.45484949832775917,
            "3": 0.7675134719014627
        },
        "nist": 7.63846679823786,
        "rouge1": {
            "precision": 0.77623,
            "recall": 0.75743,
            "fmeasure": 0.75673
        },
        "rouge2": {
            "precision": 0.57324,
            "recall": 0.55813,
            "fmeasure": 0.55799
        },
        "rougeL": {
            "precision": 0.69201,
            "recall": 0.67317,
            "fmeasure": 0.67325
        },
        "rougeLsum": {
            "precision": 0.69201,
            "recall": 0.67317,
            "fmeasure": 0.67325
        },
        "bleu": 51.60083,
        "meteor": 0.40719867514289054,
        "bertscore": {
            "precision": 0.93408,
            "recall": 0.93075,
            "f1": 0.93096
        },
        "nubia": {
            "semantic_relation": 4.27948,
            "contradiction": 8.52159,
            "irrelevancy": 19.75037,
            "logical_agreement": 71.72805,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.57383,
            "nubia_score": 0.77417
        },
        "bleurt": 0.39867
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 269,
        "msttr-100": 0.55635,
        "msttr-100_nopunct": 0.55828,
        "total_length": 6369,
        "mean_pred_length": 23.676579925650557,
        "std_pred_length": 3.8265665225393093,
        "median_pred_length": 24.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.13000471031559113,
        "vocab_size-1": 828,
        "unique-1": 329,
        "entropy-1": 7.631335544685604,
        "distinct-2": 0.37934426229508195,
        "vocab_size-2": 2314,
        "unique-2": 1374,
        "entropy-2": 10.308675423356659,
        "cond_entropy-2": 2.6997978236465405,
        "distinct-3": 0.5860058309037901,
        "vocab_size-3": 3417,
        "unique-3": 2485,
        "entropy-3": 11.261578903434124,
        "cond_entropy-3": 1.0093821441918236,
        "total_length-nopunct": 5817,
        "mean_pred_length-nopunct": 21.62453531598513,
        "std_pred_length-nopunct": 3.78466779069544,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.14148186350352415,
        "vocab_size-1-nopunct": 823,
        "unique-1-nopunct": 329,
        "entropy-1-nopunct": 7.72418568581076,
        "distinct-2-nopunct": 0.3938356164383562,
        "vocab_size-2-nopunct": 2185,
        "unique-2-nopunct": 1342,
        "entropy-2-nopunct": 10.239105795203638,
        "cond_entropy-2-nopunct": 2.6295709397618485,
        "distinct-3-nopunct": 0.6006819473385111,
        "vocab_size-3-nopunct": 3171,
        "unique-3-nopunct": 2368,
        "entropy-3-nopunct": 11.154671578895245,
        "cond_entropy-3-nopunct": 0.969833843604444,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.15724015398282498,
            "2": 0.43100604727872455,
            "3": 0.7218840963217783,
            "4": 0.25,
            "5": 0.375
        },
        "nist": 5.555032134337601,
        "rouge1": {
            "precision": 0.72561,
            "recall": 0.6061,
            "fmeasure": 0.65012
        },
        "rouge2": {
            "precision": 0.41822,
            "recall": 0.34378,
            "fmeasure": 0.37045
        },
        "rougeL": {
            "precision": 0.55205,
            "recall": 0.45893,
            "fmeasure": 0.49278
        },
        "rougeLsum": {
            "precision": 0.55205,
            "recall": 0.45893,
            "fmeasure": 0.49278
        },
        "bleu": 31.7368,
        "meteor": 0.2927077031823233,
        "bertscore": {
            "precision": 0.8931,
            "recall": 0.86756,
            "f1": 0.87852
        },
        "nubia": {
            "semantic_relation": 3.77307,
            "contradiction": 10.96458,
            "irrelevancy": 15.36867,
            "logical_agreement": 73.66674,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.71609,
            "nubia_score": 0.55224
        },
        "bleurt": -0.21981
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.72833,
        "msttr-100_nopunct": 0.77438,
        "total_length": 1885,
        "mean_pred_length": 16.535087719298247,
        "std_pred_length": 5.220035330527414,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.4625994694960212,
        "vocab_size-1": 872,
        "unique-1": 687,
        "entropy-1": 8.298835449809248,
        "distinct-2": 0.8594014680971203,
        "vocab_size-2": 1522,
        "unique-2": 1394,
        "entropy-2": 10.38962215179524,
        "cond_entropy-2": 1.8628027049711493,
        "distinct-3": 0.9631864815932408,
        "vocab_size-3": 1596,
        "unique-3": 1545,
        "entropy-3": 10.615067556512052,
        "cond_entropy-3": 0.23158483037850439,
        "total_length-nopunct": 1657,
        "mean_pred_length-nopunct": 14.535087719298245,
        "std_pred_length-nopunct": 4.8398561392303465,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5208207604103802,
        "vocab_size-1-nopunct": 863,
        "unique-1-nopunct": 685,
        "entropy-1-nopunct": 8.562683699876537,
        "distinct-2-nopunct": 0.8736228127025275,
        "vocab_size-2-nopunct": 1348,
        "unique-2-nopunct": 1255,
        "entropy-2-nopunct": 10.21246053879441,
        "cond_entropy-2-nopunct": 1.7479192916055049,
        "distinct-3-nopunct": 0.9699090272918125,
        "vocab_size-3-nopunct": 1386,
        "unique-3-nopunct": 1350,
        "entropy-3-nopunct": 10.41562615947351,
        "cond_entropy-3-nopunct": 0.22669821940945514,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.256,
            "2": 0.5024630541871922,
            "3": 0.7679362267493357
        },
        "nist": 7.529454581972232,
        "rouge1": {
            "precision": 0.73195,
            "recall": 0.72585,
            "fmeasure": 0.71679
        },
        "rouge2": {
            "precision": 0.49122,
            "recall": 0.48515,
            "fmeasure": 0.47972
        },
        "rougeL": {
            "precision": 0.61201,
            "recall": 0.60985,
            "fmeasure": 0.60027
        },
        "rougeLsum": {
            "precision": 0.61201,
            "recall": 0.60985,
            "fmeasure": 0.60027
        },
        "bleu": 41.17569,
        "meteor": 0.38228193451445985,
        "bertscore": {
            "precision": 0.92282,
            "recall": 0.91943,
            "f1": 0.91929
        },
        "nubia": {
            "semantic_relation": 4.15108,
            "contradiction": 5.87637,
            "irrelevancy": 35.85933,
            "logical_agreement": 58.2643,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.64477,
            "nubia_score": 0.72197
        },
        "bleurt": 0.24058
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.72417,
        "msttr-100_nopunct": 0.78,
        "total_length": 1208,
        "mean_pred_length": 15.291139240506329,
        "std_pred_length": 5.72834811440895,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.5041390728476821,
        "vocab_size-1": 609,
        "unique-1": 490,
        "entropy-1": 7.986446991912337,
        "distinct-2": 0.887511071744907,
        "vocab_size-2": 1002,
        "unique-2": 934,
        "entropy-2": 9.83761683446247,
        "cond_entropy-2": 1.6265660902740775,
        "distinct-3": 0.9695238095238096,
        "vocab_size-3": 1018,
        "unique-3": 986,
        "entropy-3": 9.975221231601203,
        "cond_entropy-3": 0.11897967996180506,
        "total_length-nopunct": 1043,
        "mean_pred_length-nopunct": 13.20253164556962,
        "std_pred_length-nopunct": 4.987020486984805,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5781399808245445,
        "vocab_size-1-nopunct": 603,
        "unique-1-nopunct": 489,
        "entropy-1-nopunct": 8.278162200654807,
        "distinct-2-nopunct": 0.8993775933609959,
        "vocab_size-2-nopunct": 867,
        "unique-2-nopunct": 815,
        "entropy-2-nopunct": 9.637673718920679,
        "cond_entropy-2-nopunct": 1.460082693687079,
        "distinct-3-nopunct": 0.9785310734463277,
        "vocab_size-3-nopunct": 866,
        "unique-3-nopunct": 847,
        "entropy-3-nopunct": 9.746595791863161,
        "cond_entropy-3-nopunct": 0.1247267579877383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2604501607717042,
            "2": 0.4178082191780822,
            "3": 0.7378129117259552
        },
        "nist": 6.927228058499574,
        "rouge1": {
            "precision": 0.75659,
            "recall": 0.67432,
            "fmeasure": 0.69799
        },
        "rouge2": {
            "precision": 0.51132,
            "recall": 0.45263,
            "fmeasure": 0.46776
        },
        "rougeL": {
            "precision": 0.64857,
            "recall": 0.58511,
            "fmeasure": 0.60137
        },
        "rougeLsum": {
            "precision": 0.64857,
            "recall": 0.58511,
            "fmeasure": 0.60137
        },
        "bleu": 42.24372,
        "meteor": 0.37139140548886085,
        "bertscore": {
            "precision": 0.9278,
            "recall": 0.91345,
            "f1": 0.91907
        },
        "nubia": {
            "semantic_relation": 4.06852,
            "contradiction": 10.83683,
            "irrelevancy": 29.63412,
            "logical_agreement": 59.52905,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.96777,
            "nubia_score": 0.67031
        },
        "bleurt": 0.15909
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.636809247747852,
        "median_pred_length": 18.5,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.71875,
        "vocab_size-1": 46,
        "unique-1": 37,
        "entropy-1": 5.287349367586925,
        "distinct-2": 0.95,
        "vocab_size-2": 57,
        "unique-2": 54,
        "entropy-2": 5.806890595608517,
        "cond_entropy-2": 0.4337179368491318,
        "distinct-3": 0.9821428571428571,
        "vocab_size-3": 55,
        "unique-3": 54,
        "entropy-3": 5.771640636343323,
        "cond_entropy-3": -0.02810710212234301,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.636809247747852,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.280063254367904,
        "distinct-2-nopunct": 0.9464285714285714,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.700212064914751,
        "cond_entropy-2-nopunct": 0.44706504920688567,
        "distinct-3-nopunct": 0.9807692307692307,
        "vocab_size-3-nopunct": 51,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.661978179679557,
        "cond_entropy-3-nopunct": -0.049222896224204504,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42105263157894735,
            "2": 0.8,
            "3": 0.5
        },
        "nist": 4.199890982056493,
        "rouge1": {
            "precision": 0.69194,
            "recall": 0.80271,
            "fmeasure": 0.71914
        },
        "rouge2": {
            "precision": 0.43943,
            "recall": 0.5681,
            "fmeasure": 0.47661
        },
        "rougeL": {
            "precision": 0.59125,
            "recall": 0.77662,
            "fmeasure": 0.64992
        },
        "rougeLsum": {
            "precision": 0.59125,
            "recall": 0.77662,
            "fmeasure": 0.64992
        },
        "bleu": 42.03683,
        "meteor": 0.40888083008990883,
        "bertscore": {
            "precision": 0.89242,
            "recall": 0.91244,
            "f1": 0.89898
        },
        "nubia": {
            "semantic_relation": 4.11183,
            "contradiction": 5.88586,
            "irrelevancy": 42.81085,
            "logical_agreement": 51.30329,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.7843,
            "nubia_score": 0.69116
        },
        "bleurt": 0.10331
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 9.5,
        "std_pred_length": 2.8722813232690143,
        "median_pred_length": 10.5,
        "min_pred_length": 5,
        "max_pred_length": 12,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.774243302917271,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.13365297486557742,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.18057224564182076,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 2.449489742783178,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.09306920777188984,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19230769230769232,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "nist": 4.101012045066882,
        "rouge1": {
            "precision": 0.92222,
            "recall": 0.79226,
            "fmeasure": 0.84206
        },
        "rouge2": {
            "precision": 0.68889,
            "recall": 0.60861,
            "fmeasure": 0.63917
        },
        "rougeL": {
            "precision": 0.79444,
            "recall": 0.70337,
            "fmeasure": 0.73879
        },
        "rougeLsum": {
            "precision": 0.79444,
            "recall": 0.70337,
            "fmeasure": 0.73879
        },
        "bleu": 63.43482,
        "meteor": 0.4520617029436261,
        "bertscore": {
            "precision": 0.97256,
            "recall": 0.96154,
            "f1": 0.96688
        },
        "nubia": {
            "semantic_relation": 4.53303,
            "contradiction": 0.53187,
            "irrelevancy": 4.08536,
            "logical_agreement": 95.38277,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.36685,
            "nubia_score": 0.78125
        },
        "bleurt": 0.51669
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 7.5,
        "median_pred_length": 19.5,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 27,
        "unique-1": 19,
        "entropy-1": 4.580023372597455,
        "distinct-2": 0.8918918918918919,
        "vocab_size-2": 33,
        "unique-2": 29,
        "entropy-2": 4.993237149412738,
        "cond_entropy-2": 0.4513423630998616,
        "distinct-3": 0.9428571428571428,
        "vocab_size-3": 33,
        "unique-3": 31,
        "entropy-3": 5.01499730265925,
        "cond_entropy-3": 0.034115365601730924,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 8.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.5239860659612985,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.947702779220088,
        "cond_entropy-2-nopunct": 0.463935682563364,
        "distinct-3-nopunct": 0.9411764705882353,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.969815782426809,
        "cond_entropy-3-nopunct": 0.03518489863155644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "nist": 2.955883471935471,
        "rouge1": {
            "precision": 0.67695,
            "recall": 0.76623,
            "fmeasure": 0.71521
        },
        "rouge2": {
            "precision": 0.5537,
            "recall": 0.625,
            "fmeasure": 0.58404
        },
        "rougeL": {
            "precision": 0.67695,
            "recall": 0.76623,
            "fmeasure": 0.71521
        },
        "rougeLsum": {
            "precision": 0.67695,
            "recall": 0.76623,
            "fmeasure": 0.71521
        },
        "bleu": 41.13859,
        "meteor": 0.3753036600255502,
        "bertscore": {
            "precision": 0.91592,
            "recall": 0.94021,
            "f1": 0.92777
        },
        "nubia": {
            "semantic_relation": 4.02704,
            "contradiction": 17.91358,
            "irrelevancy": 15.68843,
            "logical_agreement": 66.39799,
            "grammar_ref": 5.14789,
            "grammar_hyp": 4.55275,
            "nubia_score": 0.76902
        },
        "bleurt": 0.34284
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 83,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.76667,
        "total_length": 1405,
        "mean_pred_length": 16.927710843373493,
        "std_pred_length": 5.540177746115834,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.4875444839857651,
        "vocab_size-1": 685,
        "unique-1": 557,
        "entropy-1": 8.091272339914962,
        "distinct-2": 0.8562783661119516,
        "vocab_size-2": 1132,
        "unique-2": 1029,
        "entropy-2": 9.973676074606038,
        "cond_entropy-2": 1.676130745216245,
        "distinct-3": 0.9556093623890234,
        "vocab_size-3": 1184,
        "unique-3": 1143,
        "entropy-3": 10.176066747352333,
        "cond_entropy-3": 0.2134287555609674,
        "total_length-nopunct": 1228,
        "mean_pred_length-nopunct": 14.795180722891565,
        "std_pred_length-nopunct": 4.9253684007393685,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5513029315960912,
        "vocab_size-1-nopunct": 677,
        "unique-1-nopunct": 556,
        "entropy-1-nopunct": 8.31891402643656,
        "distinct-2-nopunct": 0.8646288209606987,
        "vocab_size-2-nopunct": 990,
        "unique-2-nopunct": 909,
        "entropy-2-nopunct": 9.778750393030972,
        "cond_entropy-2-nopunct": 1.5614884268045401,
        "distinct-3-nopunct": 0.9623352165725048,
        "vocab_size-3-nopunct": 1022,
        "unique-3-nopunct": 992,
        "entropy-3-nopunct": 9.968283893549383,
        "cond_entropy-3-nopunct": 0.21227615698314295,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1935483870967742,
            "2": 0.5203252032520326,
            "3": 0.7756410256410257
        },
        "nist": 7.603854676862644,
        "rouge1": {
            "precision": 0.775,
            "recall": 0.73586,
            "fmeasure": 0.74444
        },
        "rouge2": {
            "precision": 0.53825,
            "recall": 0.5141,
            "fmeasure": 0.51909
        },
        "rougeL": {
            "precision": 0.66605,
            "recall": 0.63739,
            "fmeasure": 0.64251
        },
        "rougeLsum": {
            "precision": 0.66605,
            "recall": 0.63739,
            "fmeasure": 0.64251
        },
        "bleu": 48.91899,
        "meteor": 0.3951828496193902,
        "bertscore": {
            "precision": 0.93538,
            "recall": 0.92783,
            "f1": 0.93047
        },
        "nubia": {
            "semantic_relation": 4.29674,
            "contradiction": 5.70392,
            "irrelevancy": 25.54778,
            "logical_agreement": 68.7483,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.69315,
            "nubia_score": 0.7428
        },
        "bleurt": 0.3046
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.495,
        "msttr-100_nopunct": 0.4925,
        "total_length": 469,
        "mean_pred_length": 16.17241379310345,
        "std_pred_length": 4.194158215794928,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.31769722814498935,
        "vocab_size-1": 149,
        "unique-1": 111,
        "entropy-1": 5.834042567643877,
        "distinct-2": 0.5295454545454545,
        "vocab_size-2": 233,
        "unique-2": 195,
        "entropy-2": 6.944953997163498,
        "cond_entropy-2": 1.0473801569216776,
        "distinct-3": 0.6131386861313869,
        "vocab_size-3": 252,
        "unique-3": 221,
        "entropy-3": 7.231920118421698,
        "cond_entropy-3": 0.41654219370222023,
        "total_length-nopunct": 405,
        "mean_pred_length-nopunct": 13.96551724137931,
        "std_pred_length-nopunct": 3.6053863786504086,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.3506172839506173,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 5.775550969180838,
        "distinct-2-nopunct": 0.5159574468085106,
        "vocab_size-2-nopunct": 194,
        "unique-2-nopunct": 161,
        "entropy-2-nopunct": 6.660692276675776,
        "cond_entropy-2-nopunct": 1.0989143357775444,
        "distinct-3-nopunct": 0.6109510086455331,
        "vocab_size-3-nopunct": 212,
        "unique-3-nopunct": 186,
        "entropy-3-nopunct": 6.987139648770072,
        "cond_entropy-3-nopunct": 0.4818450685641411,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.275,
            "2": 0.5263157894736842,
            "3": 0.8461538461538461
        },
        "nist": 6.986382059990635,
        "rouge1": {
            "precision": 0.85743,
            "recall": 0.84572,
            "fmeasure": 0.84339
        },
        "rouge2": {
            "precision": 0.73673,
            "recall": 0.71933,
            "fmeasure": 0.7202
        },
        "rougeL": {
            "precision": 0.8007,
            "recall": 0.78742,
            "fmeasure": 0.78641
        },
        "rougeLsum": {
            "precision": 0.8007,
            "recall": 0.78742,
            "fmeasure": 0.78641
        },
        "bleu": 66.92749,
        "meteor": 0.44116708925729575,
        "bertscore": {
            "precision": 0.95604,
            "recall": 0.95522,
            "f1": 0.95331
        },
        "nubia": {
            "semantic_relation": 4.36095,
            "contradiction": 8.97392,
            "irrelevancy": 15.97438,
            "logical_agreement": 75.0517,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.33102,
            "nubia_score": 0.79646
        },
        "bleurt": 0.48833
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 39,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.794,
        "total_length": 657,
        "mean_pred_length": 16.846153846153847,
        "std_pred_length": 5.798047688832198,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5616438356164384,
        "vocab_size-1": 369,
        "unique-1": 312,
        "entropy-1": 7.503900924706741,
        "distinct-2": 0.9223300970873787,
        "vocab_size-2": 570,
        "unique-2": 538,
        "entropy-2": 9.075210256844217,
        "cond_entropy-2": 1.397384644604017,
        "distinct-3": 0.9758203799654577,
        "vocab_size-3": 565,
        "unique-3": 551,
        "entropy-3": 9.12906029792014,
        "cond_entropy-3": 0.05497932962742519,
        "total_length-nopunct": 548,
        "mean_pred_length-nopunct": 14.051282051282051,
        "std_pred_length-nopunct": 4.361537707833939,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6624087591240876,
        "vocab_size-1-nopunct": 363,
        "unique-1-nopunct": 311,
        "entropy-1-nopunct": 7.8195014855663905,
        "distinct-2-nopunct": 0.9410609037328095,
        "vocab_size-2-nopunct": 479,
        "unique-2-nopunct": 457,
        "entropy-2-nopunct": 8.847545004199246,
        "cond_entropy-2-nopunct": 1.1020961086071595,
        "distinct-3-nopunct": 0.9808510638297873,
        "vocab_size-3-nopunct": 461,
        "unique-3-nopunct": 452,
        "entropy-3-nopunct": 8.838219074224586,
        "cond_entropy-3-nopunct": 0.0004934249896113285,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15037593984962405,
            "2": 0.6190476190476191,
            "3": 0.71712158808933
        },
        "nist": 6.619899141959476,
        "rouge1": {
            "precision": 0.79901,
            "recall": 0.68738,
            "fmeasure": 0.72968
        },
        "rouge2": {
            "precision": 0.55848,
            "recall": 0.4841,
            "fmeasure": 0.51138
        },
        "rougeL": {
            "precision": 0.68148,
            "recall": 0.59003,
            "fmeasure": 0.62492
        },
        "rougeLsum": {
            "precision": 0.68148,
            "recall": 0.59003,
            "fmeasure": 0.62492
        },
        "bleu": 48.66651,
        "meteor": 0.38911050683256404,
        "bertscore": {
            "precision": 0.93779,
            "recall": 0.92287,
            "f1": 0.92912
        },
        "nubia": {
            "semantic_relation": 4.21273,
            "contradiction": 9.10938,
            "irrelevancy": 21.98756,
            "logical_agreement": 68.90306,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.3519,
            "nubia_score": 0.73113
        },
        "bleurt": 0.32414
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.71125,
        "msttr-100_nopunct": 0.75619,
        "total_length": 2429,
        "mean_pred_length": 16.19333333333333,
        "std_pred_length": 4.462729608160857,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.43021819678880197,
        "vocab_size-1": 1045,
        "unique-1": 838,
        "entropy-1": 8.299549340875375,
        "distinct-2": 0.7832382623957876,
        "vocab_size-2": 1785,
        "unique-2": 1615,
        "entropy-2": 10.44556688041492,
        "cond_entropy-2": 1.907406051761183,
        "distinct-3": 0.9102865194927195,
        "vocab_size-3": 1938,
        "unique-3": 1854,
        "entropy-3": 10.81146855283353,
        "cond_entropy-3": 0.38454339943556926,
        "total_length-nopunct": 2121,
        "mean_pred_length-nopunct": 14.14,
        "std_pred_length-nopunct": 4.177766548448265,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4893917963224894,
        "vocab_size-1-nopunct": 1038,
        "unique-1-nopunct": 836,
        "entropy-1-nopunct": 8.612132142527834,
        "distinct-2-nopunct": 0.8011161846778285,
        "vocab_size-2-nopunct": 1579,
        "unique-2-nopunct": 1454,
        "entropy-2-nopunct": 10.267463568854916,
        "cond_entropy-2-nopunct": 1.7844456056262565,
        "distinct-3-nopunct": 0.9308072487644151,
        "vocab_size-3-nopunct": 1695,
        "unique-3-nopunct": 1638,
        "entropy-3-nopunct": 10.641067796618897,
        "cond_entropy-3-nopunct": 0.4196406837359189,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19290465631929046,
            "2": 0.4486486486486487,
            "3": 0.8006872852233677
        },
        "nist": 8.400057714527955,
        "rouge1": {
            "precision": 0.82867,
            "recall": 0.7817,
            "fmeasure": 0.79586
        },
        "rouge2": {
            "precision": 0.60873,
            "recall": 0.58581,
            "fmeasure": 0.58986
        },
        "rougeL": {
            "precision": 0.712,
            "recall": 0.67926,
            "fmeasure": 0.68765
        },
        "rougeLsum": {
            "precision": 0.712,
            "recall": 0.67926,
            "fmeasure": 0.68765
        },
        "bleu": 50.22791,
        "meteor": 0.4165589629926983,
        "bertscore": {
            "precision": 0.95111,
            "recall": 0.94415,
            "f1": 0.94651
        },
        "nubia": {
            "semantic_relation": 4.4862,
            "contradiction": 5.01631,
            "irrelevancy": 22.87184,
            "logical_agreement": 72.11185,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.17375,
            "nubia_score": 0.79109
        },
        "bleurt": 0.38244
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.748,
        "total_length": 640,
        "mean_pred_length": 17.77777777777778,
        "std_pred_length": 5.9072042226754835,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.55,
        "vocab_size-1": 352,
        "unique-1": 293,
        "entropy-1": 7.436632967779643,
        "distinct-2": 0.9155629139072847,
        "vocab_size-2": 553,
        "unique-2": 525,
        "entropy-2": 8.998952437200721,
        "cond_entropy-2": 1.4081317617653297,
        "distinct-3": 0.9894366197183099,
        "vocab_size-3": 562,
        "unique-3": 556,
        "entropy-3": 9.128620358941253,
        "cond_entropy-3": 0.13471263190658864,
        "total_length-nopunct": 549,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.815340071064556,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6284153005464481,
        "vocab_size-1-nopunct": 345,
        "unique-1-nopunct": 291,
        "entropy-1-nopunct": 7.639794616236356,
        "distinct-2-nopunct": 0.9239766081871345,
        "vocab_size-2-nopunct": 474,
        "unique-2-nopunct": 457,
        "entropy-2-nopunct": 8.769141910381027,
        "cond_entropy-2-nopunct": 1.2198371830691832,
        "distinct-3-nopunct": 0.9958071278825996,
        "vocab_size-3-nopunct": 475,
        "unique-3-nopunct": 473,
        "entropy-3-nopunct": 8.88945971177075,
        "cond_entropy-3-nopunct": 0.1337606353270256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20512820512820512,
            "2": 0.49264705882352944,
            "3": 0.7386934673366834
        },
        "nist": 6.345420690246888,
        "rouge1": {
            "precision": 0.77067,
            "recall": 0.68461,
            "fmeasure": 0.71377
        },
        "rouge2": {
            "precision": 0.48004,
            "recall": 0.42338,
            "fmeasure": 0.44285
        },
        "rougeL": {
            "precision": 0.62851,
            "recall": 0.55986,
            "fmeasure": 0.58211
        },
        "rougeLsum": {
            "precision": 0.62851,
            "recall": 0.55986,
            "fmeasure": 0.58211
        },
        "bleu": 38.18827,
        "meteor": 0.35047423465813976,
        "bertscore": {
            "precision": 0.92234,
            "recall": 0.91097,
            "f1": 0.91539
        },
        "nubia": {
            "semantic_relation": 4.00345,
            "contradiction": 14.44369,
            "irrelevancy": 28.61729,
            "logical_agreement": 56.93902,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.94082,
            "nubia_score": 0.65755
        },
        "bleurt": 0.16043
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.79,
        "total_length": 216,
        "mean_pred_length": 18.0,
        "std_pred_length": 8.366600265340756,
        "median_pred_length": 17.5,
        "min_pred_length": 6,
        "max_pred_length": 35,
        "distinct-1": 0.6481481481481481,
        "vocab_size-1": 140,
        "unique-1": 111,
        "entropy-1": 6.649524831549814,
        "distinct-2": 0.946078431372549,
        "vocab_size-2": 193,
        "unique-2": 182,
        "entropy-2": 7.5645822047165945,
        "cond_entropy-2": 0.8353271135313982,
        "distinct-3": 0.9791666666666666,
        "vocab_size-3": 188,
        "unique-3": 184,
        "entropy-3": 7.543295834054511,
        "cond_entropy-3": -0.019754507917005924,
        "total_length-nopunct": 176,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 6.195876765147036,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7670454545454546,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.889655056492459,
        "distinct-2-nopunct": 0.9573170731707317,
        "vocab_size-2-nopunct": 157,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.272186150959568,
        "cond_entropy-2-nopunct": 0.4120269404776995,
        "distinct-3-nopunct": 0.9868421052631579,
        "vocab_size-3-nopunct": 150,
        "unique-3-nopunct": 148,
        "entropy-3-nopunct": 7.2216117239698825,
        "cond_entropy-3-nopunct": -0.04383501749028739,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.325,
            "3": 0.6461538461538462
        },
        "nist": 4.711640753835899,
        "rouge1": {
            "precision": 0.72499,
            "recall": 0.65041,
            "fmeasure": 0.66227
        },
        "rouge2": {
            "precision": 0.44445,
            "recall": 0.38397,
            "fmeasure": 0.39906
        },
        "rougeL": {
            "precision": 0.57204,
            "recall": 0.50142,
            "fmeasure": 0.52013
        },
        "rougeLsum": {
            "precision": 0.57204,
            "recall": 0.50142,
            "fmeasure": 0.52013
        },
        "bleu": 27.9168,
        "meteor": 0.2881215110600515,
        "bertscore": {
            "precision": 0.90375,
            "recall": 0.90823,
            "f1": 0.90503
        },
        "nubia": {
            "semantic_relation": 3.92469,
            "contradiction": 6.03811,
            "irrelevancy": 32.98784,
            "logical_agreement": 60.97405,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.43375,
            "nubia_score": 0.66648
        },
        "bleurt": 0.09322
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "msttr-100": 0.72311,
        "msttr-100_nopunct": 0.76642,
        "total_length": 6109,
        "mean_pred_length": 17.016713091922007,
        "std_pred_length": 6.450130037221804,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.378621705680144,
        "vocab_size-1": 2313,
        "unique-1": 1775,
        "entropy-1": 9.001083205232852,
        "distinct-2": 0.8144347826086956,
        "vocab_size-2": 4683,
        "unique-2": 4316,
        "entropy-2": 11.790379263461883,
        "cond_entropy-2": 2.5723798815519743,
        "distinct-3": 0.9404563160823595,
        "vocab_size-3": 5070,
        "unique-3": 4941,
        "entropy-3": 12.15737182736771,
        "cond_entropy-3": 0.3941928318453003,
        "total_length-nopunct": 5365,
        "mean_pred_length-nopunct": 14.944289693593316,
        "std_pred_length-nopunct": 5.695838727791856,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.42926374650512583,
        "vocab_size-1-nopunct": 2303,
        "unique-1-nopunct": 1774,
        "entropy-1-nopunct": 9.350261037530778,
        "distinct-2-nopunct": 0.8523771474230923,
        "vocab_size-2-nopunct": 4267,
        "unique-2-nopunct": 3956,
        "entropy-2-nopunct": 11.813268637914756,
        "cond_entropy-2-nopunct": 2.6136769298278106,
        "distinct-3-nopunct": 0.974176888315042,
        "vocab_size-3-nopunct": 4527,
        "unique-3-nopunct": 4430,
        "entropy-3-nopunct": 12.125261224012235,
        "cond_entropy-3-nopunct": 0.336732748706786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "local_recall": {
            "1": 0.04676328502415459,
            "2": 0.13598901098901098,
            "3": 0.2227432590855803,
            "4": 0.34419263456090654,
            "5": 0.43824701195219123,
            "6": 0.4667487684729064,
            "7": 0.569634703196347,
            "8": 0.6746031746031746,
            "9": 0.7928057553956834
        },
        "nist": 9.40380484620896,
        "rouge1": {
            "precision": 0.71865,
            "recall": 0.67535,
            "fmeasure": 0.68022
        },
        "rouge2": {
            "precision": 0.52022,
            "recall": 0.48501,
            "fmeasure": 0.48623
        },
        "rougeL": {
            "precision": 0.67542,
            "recall": 0.64216,
            "fmeasure": 0.64146
        },
        "rougeLsum": {
            "precision": 0.67542,
            "recall": 0.64216,
            "fmeasure": 0.64146
        },
        "bleu": 50.29694,
        "sari": 45.05215,
        "meteor": 0.349823743786827,
        "bertscore": {
            "precision": 0.90308,
            "recall": 0.91535,
            "f1": 0.90405
        },
        "nubia": {
            "semantic_relation": 3.69129,
            "contradiction": 7.24059,
            "irrelevancy": 32.00906,
            "logical_agreement": 60.75035,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.54655,
            "nubia_score": 0.47248
        },
        "bleurt": -0.32514
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.023638630780208267,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.625
        },
        "nist": 2.615381617849737,
        "rouge1": {
            "precision": 0.51111,
            "recall": 0.49405,
            "fmeasure": 0.47826
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.24048,
            "fmeasure": 0.18581
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.38889,
            "fmeasure": 0.3752
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.38889,
            "fmeasure": 0.3752
        },
        "bleu": 13.58319,
        "meteor": 0.27650924757351697,
        "bertscore": {
            "precision": 0.80701,
            "recall": 0.93376,
            "f1": 0.84567
        },
        "nubia": {
            "semantic_relation": 3.32962,
            "contradiction": 0.19519,
            "irrelevancy": 99.28926,
            "logical_agreement": 0.51555,
            "grammar_ref": 5.89248,
            "grammar_hyp": 6.42653,
            "nubia_score": 0.36514
        },
        "bleurt": -0.43081
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 1295,
        "msttr-100": 0.66544,
        "msttr-100_nopunct": 0.68632,
        "total_length": 28362,
        "mean_pred_length": 21.9011583011583,
        "std_pred_length": 4.36441810285004,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.06286580636062337,
        "vocab_size-1": 1783,
        "unique-1": 611,
        "entropy-1": 8.11497569562074,
        "distinct-2": 0.21886429970074261,
        "vocab_size-2": 5924,
        "unique-2": 2885,
        "entropy-2": 11.167899705368214,
        "cond_entropy-2": 3.0518601251189748,
        "distinct-3": 0.38794040043458017,
        "vocab_size-3": 9998,
        "unique-3": 6145,
        "entropy-3": 12.388274406150488,
        "cond_entropy-3": 1.3162468631817248,
        "total_length-nopunct": 25855,
        "mean_pred_length-nopunct": 19.965250965250966,
        "std_pred_length-nopunct": 4.27973913012914,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06861342100174048,
        "vocab_size-1-nopunct": 1774,
        "unique-1-nopunct": 610,
        "entropy-1-nopunct": 8.276629073081674,
        "distinct-2-nopunct": 0.23147394136807817,
        "vocab_size-2-nopunct": 5685,
        "unique-2-nopunct": 2928,
        "entropy-2-nopunct": 11.103848859144868,
        "cond_entropy-2-nopunct": 2.9845458977492094,
        "distinct-3-nopunct": 0.4008596604341285,
        "vocab_size-3-nopunct": 9326,
        "unique-3-nopunct": 5906,
        "entropy-3-nopunct": 12.281990175978864,
        "cond_entropy-3-nopunct": 1.2725144218867483,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1777626657599456,
            "2": 0.47109758951556285,
            "3": 0.7285328321390814,
            "4": 0.6470588235294118,
            "5": 0.41379310344827586
        },
        "nist": 6.198565091583256,
        "rouge1": {
            "precision": 0.76302,
            "recall": 0.64099,
            "fmeasure": 0.68235
        },
        "rouge2": {
            "precision": 0.48903,
            "recall": 0.40607,
            "fmeasure": 0.43308
        },
        "rougeL": {
            "precision": 0.60506,
            "recall": 0.50681,
            "fmeasure": 0.53957
        },
        "rougeLsum": {
            "precision": 0.60506,
            "recall": 0.50681,
            "fmeasure": 0.53957
        },
        "bleu": 36.37541,
        "meteor": 0.309300404888255,
        "bertscore": {
            "precision": 0.91177,
            "recall": 0.88521,
            "f1": 0.8966
        },
        "nubia": {
            "semantic_relation": 3.96464,
            "contradiction": 9.58321,
            "irrelevancy": 11.88838,
            "logical_agreement": 78.52842,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.65223,
            "nubia_score": 0.61819
        },
        "bleurt": -0.05973
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 50,
        "msttr-100": 0.6925,
        "msttr-100_nopunct": 0.73714,
        "total_length": 852,
        "mean_pred_length": 17.04,
        "std_pred_length": 6.2352546058681515,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5223004694835681,
        "vocab_size-1": 445,
        "unique-1": 361,
        "entropy-1": 7.646945700762416,
        "distinct-2": 0.8840399002493765,
        "vocab_size-2": 709,
        "unique-2": 651,
        "entropy-2": 9.345696246319848,
        "cond_entropy-2": 1.5199328925054454,
        "distinct-3": 0.9654255319148937,
        "vocab_size-3": 726,
        "unique-3": 702,
        "entropy-3": 9.48343223598046,
        "cond_entropy-3": 0.1484914537652941,
        "total_length-nopunct": 757,
        "mean_pred_length-nopunct": 15.14,
        "std_pred_length-nopunct": 5.681584286094856,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5812417437252312,
        "vocab_size-1-nopunct": 440,
        "unique-1-nopunct": 360,
        "entropy-1-nopunct": 7.829486875452125,
        "distinct-2-nopunct": 0.8967468175388967,
        "vocab_size-2-nopunct": 634,
        "unique-2-nopunct": 591,
        "entropy-2-nopunct": 9.18655879382456,
        "cond_entropy-2-nopunct": 1.4416664278819356,
        "distinct-3-nopunct": 0.974124809741248,
        "vocab_size-3-nopunct": 640,
        "unique-3-nopunct": 623,
        "entropy-3-nopunct": 9.307999179804956,
        "cond_entropy-3-nopunct": 0.1381076318693729,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24666666666666667,
            "2": 0.5534591194968553,
            "3": 0.7408759124087592
        },
        "nist": 6.93887642241667,
        "rouge1": {
            "precision": 0.75578,
            "recall": 0.72393,
            "fmeasure": 0.7323
        },
        "rouge2": {
            "precision": 0.52941,
            "recall": 0.5171,
            "fmeasure": 0.51741
        },
        "rougeL": {
            "precision": 0.64691,
            "recall": 0.63068,
            "fmeasure": 0.63194
        },
        "rougeLsum": {
            "precision": 0.64691,
            "recall": 0.63068,
            "fmeasure": 0.63194
        },
        "bleu": 44.55591,
        "meteor": 0.367171265545027,
        "bertscore": {
            "precision": 0.92644,
            "recall": 0.9165,
            "f1": 0.91986
        },
        "nubia": {
            "semantic_relation": 4.20363,
            "contradiction": 5.86215,
            "irrelevancy": 35.51915,
            "logical_agreement": 58.61869,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.58284,
            "nubia_score": 0.74072
        },
        "bleurt": 0.22926
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "total_length": 178,
        "mean_pred_length": 16.181818181818183,
        "std_pred_length": 4.569029772046932,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6685393258426966,
        "vocab_size-1": 119,
        "unique-1": 96,
        "entropy-1": 6.524283535701675,
        "distinct-2": 0.9341317365269461,
        "vocab_size-2": 156,
        "unique-2": 146,
        "entropy-2": 7.247447481083828,
        "cond_entropy-2": 0.6010962552027816,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 152,
        "unique-3": 148,
        "entropy-3": 7.2341201675802145,
        "cond_entropy-3": -0.016539974238961117,
        "total_length-nopunct": 158,
        "mean_pred_length-nopunct": 14.363636363636363,
        "std_pred_length-nopunct": 4.33322737738654,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7278481012658228,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.562152445077533,
        "distinct-2-nopunct": 0.9387755102040817,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 130,
        "entropy-2-nopunct": 7.072088076114153,
        "cond_entropy-2-nopunct": 0.536030755112887,
        "distinct-3-nopunct": 0.9779411764705882,
        "vocab_size-3-nopunct": 133,
        "unique-3-nopunct": 130,
        "entropy-3-nopunct": 7.043345194191504,
        "cond_entropy-3-nopunct": -0.03312944842305818,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27906976744186046,
            "2": 0.42105263157894735,
            "3": 0.7132352941176471
        },
        "nist": 5.818405971355593,
        "rouge1": {
            "precision": 0.78555,
            "recall": 0.70132,
            "fmeasure": 0.73569
        },
        "rouge2": {
            "precision": 0.57157,
            "recall": 0.50713,
            "fmeasure": 0.53127
        },
        "rougeL": {
            "precision": 0.67083,
            "recall": 0.58593,
            "fmeasure": 0.61915
        },
        "rougeLsum": {
            "precision": 0.67083,
            "recall": 0.58593,
            "fmeasure": 0.61915
        },
        "bleu": 44.85426,
        "meteor": 0.4030989864238857,
        "bertscore": {
            "precision": 0.9141,
            "recall": 0.91724,
            "f1": 0.91492
        },
        "nubia": {
            "semantic_relation": 4.03975,
            "contradiction": 9.48794,
            "irrelevancy": 23.57207,
            "logical_agreement": 66.93998,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.73122,
            "nubia_score": 0.6834
        },
        "bleurt": 0.18464
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.765,
        "msttr-100_nopunct": 0.81,
        "total_length": 232,
        "mean_pred_length": 16.571428571428573,
        "std_pred_length": 5.924697529522206,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.6810344827586207,
        "vocab_size-1": 158,
        "unique-1": 134,
        "entropy-1": 6.862103848522102,
        "distinct-2": 0.9724770642201835,
        "vocab_size-2": 212,
        "unique-2": 206,
        "entropy-2": 7.713138453217279,
        "cond_entropy-2": 0.7404315416101629,
        "distinct-3": 0.9852941176470589,
        "vocab_size-3": 201,
        "unique-3": 198,
        "entropy-3": 7.643013577265614,
        "cond_entropy-3": -0.06634721809954836,
        "total_length-nopunct": 202,
        "mean_pred_length-nopunct": 14.428571428571429,
        "std_pred_length-nopunct": 5.205962045225314,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7475247524752475,
        "vocab_size-1-nopunct": 151,
        "unique-1-nopunct": 130,
        "entropy-1-nopunct": 6.950864780417014,
        "distinct-2-nopunct": 0.9787234042553191,
        "vocab_size-2-nopunct": 184,
        "unique-2-nopunct": 180,
        "entropy-2-nopunct": 7.512035660188296,
        "cond_entropy-2-nopunct": 0.6000958336646741,
        "distinct-3-nopunct": 0.9885057471264368,
        "vocab_size-3-nopunct": 172,
        "unique-3-nopunct": 170,
        "entropy-3-nopunct": 7.419954990101581,
        "cond_entropy-3-nopunct": -0.08865685008178296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1694915254237288,
            "2": 0.2608695652173913,
            "3": 0.6848484848484848
        },
        "nist": 4.794301037990349,
        "rouge1": {
            "precision": 0.7013,
            "recall": 0.62627,
            "fmeasure": 0.64853
        },
        "rouge2": {
            "precision": 0.41283,
            "recall": 0.36195,
            "fmeasure": 0.37434
        },
        "rougeL": {
            "precision": 0.58369,
            "recall": 0.53681,
            "fmeasure": 0.54594
        },
        "rougeLsum": {
            "precision": 0.58369,
            "recall": 0.53681,
            "fmeasure": 0.54594
        },
        "bleu": 29.59515,
        "meteor": 0.31873487360630487,
        "bertscore": {
            "precision": 0.90344,
            "recall": 0.90073,
            "f1": 0.8987
        },
        "nubia": {
            "semantic_relation": 3.877,
            "contradiction": 12.23123,
            "irrelevancy": 23.09021,
            "logical_agreement": 64.67856,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.55058,
            "nubia_score": 0.63892
        },
        "bleurt": 0.05913
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 62,
        "msttr-100": 0.731,
        "msttr-100_nopunct": 0.7825,
        "total_length": 1029,
        "mean_pred_length": 16.596774193548388,
        "std_pred_length": 5.481522267433225,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.4655004859086492,
        "vocab_size-1": 479,
        "unique-1": 364,
        "entropy-1": 7.793646684867956,
        "distinct-2": 0.827300930713547,
        "vocab_size-2": 800,
        "unique-2": 712,
        "entropy-2": 9.463510412741678,
        "cond_entropy-2": 1.469629874989279,
        "distinct-3": 0.918232044198895,
        "vocab_size-3": 831,
        "unique-3": 787,
        "entropy-3": 9.624874448339737,
        "cond_entropy-3": 0.1540835088425339,
        "total_length-nopunct": 876,
        "mean_pred_length-nopunct": 14.129032258064516,
        "std_pred_length-nopunct": 4.587795418870706,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5365296803652968,
        "vocab_size-1-nopunct": 470,
        "unique-1-nopunct": 360,
        "entropy-1-nopunct": 8.065731068966912,
        "distinct-2-nopunct": 0.8452088452088452,
        "vocab_size-2-nopunct": 688,
        "unique-2-nopunct": 626,
        "entropy-2-nopunct": 9.251380476535015,
        "cond_entropy-2-nopunct": 1.2514512843830827,
        "distinct-3-nopunct": 0.9308510638297872,
        "vocab_size-3-nopunct": 700,
        "unique-3-nopunct": 670,
        "entropy-3-nopunct": 9.389325645594134,
        "cond_entropy-3-nopunct": 0.13825606669857268,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23837209302325582,
            "2": 0.423728813559322,
            "3": 0.793002915451895
        },
        "nist": 7.5188601088153115,
        "rouge1": {
            "precision": 0.78927,
            "recall": 0.75967,
            "fmeasure": 0.76625
        },
        "rouge2": {
            "precision": 0.57928,
            "recall": 0.56328,
            "fmeasure": 0.56504
        },
        "rougeL": {
            "precision": 0.6968,
            "recall": 0.67918,
            "fmeasure": 0.68011
        },
        "rougeLsum": {
            "precision": 0.6968,
            "recall": 0.67918,
            "fmeasure": 0.68011
        },
        "bleu": 54.47846,
        "meteor": 0.40689766258028587,
        "bertscore": {
            "precision": 0.9354,
            "recall": 0.93214,
            "f1": 0.93137
        },
        "nubia": {
            "semantic_relation": 4.31977,
            "contradiction": 4.79858,
            "irrelevancy": 26.66307,
            "logical_agreement": 68.53835,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.45077,
            "nubia_score": 0.77728
        },
        "bleurt": 0.32851
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 112,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.738,
        "total_length": 1783,
        "mean_pred_length": 15.919642857142858,
        "std_pred_length": 4.980566506893752,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.4346606842400449,
        "vocab_size-1": 775,
        "unique-1": 643,
        "entropy-1": 7.941809974742968,
        "distinct-2": 0.7899461400359067,
        "vocab_size-2": 1320,
        "unique-2": 1210,
        "entropy-2": 10.003635211896384,
        "cond_entropy-2": 1.8205001256670013,
        "distinct-3": 0.8826170622193714,
        "vocab_size-3": 1376,
        "unique-3": 1317,
        "entropy-3": 10.233924755195185,
        "cond_entropy-3": 0.25440820578225676,
        "total_length-nopunct": 1550,
        "mean_pred_length-nopunct": 13.839285714285714,
        "std_pred_length-nopunct": 4.201516672219542,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.49290322580645163,
        "vocab_size-1-nopunct": 764,
        "unique-1-nopunct": 639,
        "entropy-1-nopunct": 8.182351654816259,
        "distinct-2-nopunct": 0.8004172461752433,
        "vocab_size-2-nopunct": 1151,
        "unique-2-nopunct": 1068,
        "entropy-2-nopunct": 9.803668579164219,
        "cond_entropy-2-nopunct": 1.749877404551664,
        "distinct-3-nopunct": 0.889894419306184,
        "vocab_size-3-nopunct": 1180,
        "unique-3-nopunct": 1133,
        "entropy-3-nopunct": 10.022618815863499,
        "cond_entropy-3-nopunct": 0.27162903813445505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2314540059347181,
            "2": 0.46474358974358976,
            "3": 0.7611548556430446
        },
        "nist": 7.208713604854858,
        "rouge1": {
            "precision": 0.74754,
            "recall": 0.72652,
            "fmeasure": 0.72596
        },
        "rouge2": {
            "precision": 0.50501,
            "recall": 0.48647,
            "fmeasure": 0.48892
        },
        "rougeL": {
            "precision": 0.62535,
            "recall": 0.60823,
            "fmeasure": 0.6073
        },
        "rougeLsum": {
            "precision": 0.62535,
            "recall": 0.60823,
            "fmeasure": 0.6073
        },
        "bleu": 41.5409,
        "meteor": 0.3736699470561324,
        "bertscore": {
            "precision": 0.92299,
            "recall": 0.91917,
            "f1": 0.92004
        },
        "nubia": {
            "semantic_relation": 4.17012,
            "contradiction": 9.03896,
            "irrelevancy": 25.48216,
            "logical_agreement": 65.47888,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.61979,
            "nubia_score": 0.73815
        },
        "bleurt": 0.27356
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 115,
        "msttr-100": 0.66389,
        "msttr-100_nopunct": 0.70625,
        "total_length": 1895,
        "mean_pred_length": 16.47826086956522,
        "std_pred_length": 4.143822696574109,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.27440633245382584,
        "vocab_size-1": 520,
        "unique-1": 254,
        "entropy-1": 7.472895145558956,
        "distinct-2": 0.5893258426966292,
        "vocab_size-2": 1049,
        "unique-2": 734,
        "entropy-2": 9.581279100594745,
        "cond_entropy-2": 1.9085793069684946,
        "distinct-3": 0.7417417417417418,
        "vocab_size-3": 1235,
        "unique-3": 982,
        "entropy-3": 10.046964204095133,
        "cond_entropy-3": 0.520360391126398,
        "total_length-nopunct": 1691,
        "mean_pred_length-nopunct": 14.704347826086957,
        "std_pred_length-nopunct": 3.8964284940765688,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.30396215257244236,
        "vocab_size-1-nopunct": 514,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.64621903697343,
        "distinct-2-nopunct": 0.574238578680203,
        "vocab_size-2-nopunct": 905,
        "unique-2-nopunct": 627,
        "entropy-2-nopunct": 9.340050965547693,
        "cond_entropy-2-nopunct": 1.8320721967866254,
        "distinct-3-nopunct": 0.728952772073922,
        "vocab_size-3-nopunct": 1065,
        "unique-3-nopunct": 839,
        "entropy-3-nopunct": 9.820181684645823,
        "cond_entropy-3-nopunct": 0.5320850254350515,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23684210526315788,
            "2": 0.56,
            "3": 0.8698347107438017
        },
        "nist": 8.38018283855712,
        "rouge1": {
            "precision": 0.79124,
            "recall": 0.76708,
            "fmeasure": 0.77042
        },
        "rouge2": {
            "precision": 0.55097,
            "recall": 0.53144,
            "fmeasure": 0.53399
        },
        "rougeL": {
            "precision": 0.67514,
            "recall": 0.65317,
            "fmeasure": 0.6557
        },
        "rougeLsum": {
            "precision": 0.67514,
            "recall": 0.65317,
            "fmeasure": 0.6557
        },
        "bleu": 53.09257,
        "meteor": 0.4172893189193222,
        "bertscore": {
            "precision": 0.9383,
            "recall": 0.93778,
            "f1": 0.93689
        },
        "nubia": {
            "semantic_relation": 4.62861,
            "contradiction": 4.64435,
            "irrelevancy": 3.88553,
            "logical_agreement": 91.47012,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.70096,
            "nubia_score": 0.84635
        },
        "bleurt": 0.33114
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.70609,
        "msttr-100_nopunct": 0.75524,
        "total_length": 2378,
        "mean_pred_length": 15.853333333333333,
        "std_pred_length": 5.368285470137453,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.4095878889823381,
        "vocab_size-1": 974,
        "unique-1": 758,
        "entropy-1": 8.17115985294947,
        "distinct-2": 0.7908438061041293,
        "vocab_size-2": 1762,
        "unique-2": 1566,
        "entropy-2": 10.444869074890011,
        "cond_entropy-2": 2.058091774988762,
        "distinct-3": 0.9307025986525506,
        "vocab_size-3": 1934,
        "unique-3": 1842,
        "entropy-3": 10.854460912467244,
        "cond_entropy-3": 0.4236150648895697,
        "total_length-nopunct": 2108,
        "mean_pred_length-nopunct": 14.053333333333333,
        "std_pred_length-nopunct": 5.003714176045186,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.45920303605313095,
        "vocab_size-1-nopunct": 968,
        "unique-1-nopunct": 757,
        "entropy-1-nopunct": 8.429154139108848,
        "distinct-2-nopunct": 0.8069458631256384,
        "vocab_size-2-nopunct": 1580,
        "unique-2-nopunct": 1432,
        "entropy-2-nopunct": 10.281544001809507,
        "cond_entropy-2-nopunct": 1.9702387059536375,
        "distinct-3-nopunct": 0.9435840707964602,
        "vocab_size-3-nopunct": 1706,
        "unique-3-nopunct": 1643,
        "entropy-3-nopunct": 10.682710713808598,
        "cond_entropy-3-nopunct": 0.4329718197536622,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18318965517241378,
            "2": 0.44324324324324327,
            "3": 0.7998794454490658
        },
        "nist": 8.058274886035981,
        "rouge1": {
            "precision": 0.78647,
            "recall": 0.75719,
            "fmeasure": 0.76343
        },
        "rouge2": {
            "precision": 0.53417,
            "recall": 0.51938,
            "fmeasure": 0.52073
        },
        "rougeL": {
            "precision": 0.66301,
            "recall": 0.64571,
            "fmeasure": 0.64726
        },
        "rougeLsum": {
            "precision": 0.66301,
            "recall": 0.64571,
            "fmeasure": 0.64726
        },
        "bleu": 46.15621,
        "meteor": 0.4031137986649052,
        "bertscore": {
            "precision": 0.93522,
            "recall": 0.93447,
            "f1": 0.93314
        },
        "nubia": {
            "semantic_relation": 4.35831,
            "contradiction": 6.71764,
            "irrelevancy": 26.65387,
            "logical_agreement": 66.62848,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.75496,
            "nubia_score": 0.77314
        },
        "bleurt": 0.32683
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 518,
        "msttr-100": 0.67065,
        "msttr-100_nopunct": 0.69443,
        "total_length": 10778,
        "mean_pred_length": 20.806949806949806,
        "std_pred_length": 4.847619122790364,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.08842085730191131,
        "vocab_size-1": 953,
        "unique-1": 325,
        "entropy-1": 7.731171982977804,
        "distinct-2": 0.24892787524366472,
        "vocab_size-2": 2554,
        "unique-2": 1247,
        "entropy-2": 10.175435995514773,
        "cond_entropy-2": 2.4520109348651493,
        "distinct-3": 0.3859577088893451,
        "vocab_size-3": 3760,
        "unique-3": 2229,
        "entropy-3": 11.021340162513898,
        "cond_entropy-3": 0.9363633792173119,
        "total_length-nopunct": 9761,
        "mean_pred_length-nopunct": 18.843629343629345,
        "std_pred_length-nopunct": 4.660756640818147,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.09691629955947137,
        "vocab_size-1-nopunct": 946,
        "unique-1-nopunct": 325,
        "entropy-1-nopunct": 7.8888087707638865,
        "distinct-2-nopunct": 0.2583576760791951,
        "vocab_size-2-nopunct": 2388,
        "unique-2-nopunct": 1218,
        "entropy-2-nopunct": 10.065423059622232,
        "cond_entropy-2-nopunct": 2.3202880850604,
        "distinct-3-nopunct": 0.3932378223495702,
        "vocab_size-3-nopunct": 3431,
        "unique-3-nopunct": 2066,
        "entropy-3-nopunct": 10.875367666830025,
        "cond_entropy-3-nopunct": 0.9000028783775686,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19376859793453527,
            "2": 0.47515886770652804,
            "3": 0.6923406687625036,
            "4": 1.0
        },
        "nist": 4.52455337141057,
        "rouge1": {
            "precision": 0.80861,
            "recall": 0.63943,
            "fmeasure": 0.6948
        },
        "rouge2": {
            "precision": 0.56629,
            "recall": 0.44377,
            "fmeasure": 0.48252
        },
        "rougeL": {
            "precision": 0.66674,
            "recall": 0.52844,
            "fmeasure": 0.57298
        },
        "rougeLsum": {
            "precision": 0.66674,
            "recall": 0.52844,
            "fmeasure": 0.57298
        },
        "bleu": 37.86141,
        "meteor": 0.3095153708012986,
        "bertscore": {
            "precision": 0.93244,
            "recall": 0.89635,
            "f1": 0.91237
        },
        "nubia": {
            "semantic_relation": 4.03951,
            "contradiction": 6.61537,
            "irrelevancy": 8.94293,
            "logical_agreement": 84.4417,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.53671,
            "nubia_score": 0.64291
        },
        "bleurt": 0.023
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.71286,
        "msttr-100_nopunct": 0.78167,
        "total_length": 754,
        "mean_pred_length": 15.708333333333334,
        "std_pred_length": 5.259746244407192,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5318302387267905,
        "vocab_size-1": 401,
        "unique-1": 324,
        "entropy-1": 7.563520842602097,
        "distinct-2": 0.8951841359773371,
        "vocab_size-2": 632,
        "unique-2": 578,
        "entropy-2": 9.214475952143975,
        "cond_entropy-2": 1.434517299016897,
        "distinct-3": 0.9665653495440729,
        "vocab_size-3": 636,
        "unique-3": 615,
        "entropy-3": 9.29392722737942,
        "cond_entropy-3": 0.0843136410590481,
        "total_length-nopunct": 651,
        "mean_pred_length-nopunct": 13.5625,
        "std_pred_length-nopunct": 4.716576486181476,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6082949308755761,
        "vocab_size-1-nopunct": 396,
        "unique-1-nopunct": 323,
        "entropy-1-nopunct": 7.834546986869987,
        "distinct-2-nopunct": 0.9071310116086235,
        "vocab_size-2-nopunct": 547,
        "unique-2-nopunct": 509,
        "entropy-2-nopunct": 9.00663042687271,
        "cond_entropy-2-nopunct": 1.2650596071964304,
        "distinct-3-nopunct": 0.9765765765765766,
        "vocab_size-3-nopunct": 542,
        "unique-3-nopunct": 529,
        "entropy-3-nopunct": 9.069497114390604,
        "cond_entropy-3-nopunct": 0.0772998780067539,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1476510067114094,
            "2": 0.38125,
            "3": 0.7663366336633664
        },
        "nist": 6.881526458930982,
        "rouge1": {
            "precision": 0.77539,
            "recall": 0.72403,
            "fmeasure": 0.7395
        },
        "rouge2": {
            "precision": 0.52444,
            "recall": 0.49416,
            "fmeasure": 0.50234
        },
        "rougeL": {
            "precision": 0.64416,
            "recall": 0.59673,
            "fmeasure": 0.61183
        },
        "rougeLsum": {
            "precision": 0.64416,
            "recall": 0.59673,
            "fmeasure": 0.61183
        },
        "bleu": 43.28565,
        "meteor": 0.38318280001939375,
        "bertscore": {
            "precision": 0.93773,
            "recall": 0.92862,
            "f1": 0.93169
        },
        "nubia": {
            "semantic_relation": 4.19869,
            "contradiction": 10.34706,
            "irrelevancy": 19.91581,
            "logical_agreement": 69.73713,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.85457,
            "nubia_score": 0.72179
        },
        "bleurt": 0.2779
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.7084,
        "msttr-100_nopunct": 0.76667,
        "total_length": 2532,
        "mean_pred_length": 16.88,
        "std_pred_length": 5.100222217380991,
        "median_pred_length": 16.5,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.41429699842022116,
        "vocab_size-1": 1049,
        "unique-1": 817,
        "entropy-1": 8.251169693578877,
        "distinct-2": 0.7989084802686818,
        "vocab_size-2": 1903,
        "unique-2": 1709,
        "entropy-2": 10.6040156377145,
        "cond_entropy-2": 2.134521656613421,
        "distinct-3": 0.9381720430107527,
        "vocab_size-3": 2094,
        "unique-3": 2007,
        "entropy-3": 10.97666890928636,
        "cond_entropy-3": 0.3538496041575408,
        "total_length-nopunct": 2177,
        "mean_pred_length-nopunct": 14.513333333333334,
        "std_pred_length-nopunct": 4.4806795119589715,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.47680293982544786,
        "vocab_size-1-nopunct": 1038,
        "unique-1-nopunct": 815,
        "entropy-1-nopunct": 8.582870799674485,
        "distinct-2-nopunct": 0.8322644301924026,
        "vocab_size-2-nopunct": 1687,
        "unique-2-nopunct": 1556,
        "entropy-2-nopunct": 10.455488913660325,
        "cond_entropy-2-nopunct": 1.970181162679403,
        "distinct-3-nopunct": 0.9579115610015982,
        "vocab_size-3-nopunct": 1798,
        "unique-3-nopunct": 1746,
        "entropy-3-nopunct": 10.77447912584015,
        "cond_entropy-3-nopunct": 0.34351314951092454,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1575178997613365,
            "2": 0.3286219081272085,
            "3": 0.8023630504833512
        },
        "nist": 8.368203063076745,
        "rouge1": {
            "precision": 0.82313,
            "recall": 0.78275,
            "fmeasure": 0.79595
        },
        "rouge2": {
            "precision": 0.59298,
            "recall": 0.56369,
            "fmeasure": 0.57263
        },
        "rougeL": {
            "precision": 0.72255,
            "recall": 0.68452,
            "fmeasure": 0.69704
        },
        "rougeLsum": {
            "precision": 0.72255,
            "recall": 0.68452,
            "fmeasure": 0.69704
        },
        "bleu": 51.21252,
        "meteor": 0.4212978969762691,
        "bertscore": {
            "precision": 0.94266,
            "recall": 0.94119,
            "f1": 0.94111
        },
        "nubia": {
            "semantic_relation": 4.43846,
            "contradiction": 5.84336,
            "irrelevancy": 21.96779,
            "logical_agreement": 72.18886,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.63234,
            "nubia_score": 0.79655
        },
        "bleurt": 0.39485
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.71375,
        "msttr-100_nopunct": 0.76143,
        "total_length": 803,
        "mean_pred_length": 16.729166666666668,
        "std_pred_length": 5.739989776897594,
        "median_pred_length": 16.5,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5193026151930261,
        "vocab_size-1": 417,
        "unique-1": 329,
        "entropy-1": 7.662148613032785,
        "distinct-2": 0.9019867549668874,
        "vocab_size-2": 681,
        "unique-2": 633,
        "entropy-2": 9.318858840995578,
        "cond_entropy-2": 1.4726728486822522,
        "distinct-3": 0.9745403111739745,
        "vocab_size-3": 689,
        "unique-3": 671,
        "entropy-3": 9.414647027157194,
        "cond_entropy-3": 0.08620717300441644,
        "total_length-nopunct": 703,
        "mean_pred_length-nopunct": 14.645833333333334,
        "std_pred_length-nopunct": 5.328733367842264,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5846372688477952,
        "vocab_size-1-nopunct": 411,
        "unique-1-nopunct": 328,
        "entropy-1-nopunct": 7.862920436215286,
        "distinct-2-nopunct": 0.9053435114503817,
        "vocab_size-2-nopunct": 593,
        "unique-2-nopunct": 553,
        "entropy-2-nopunct": 9.120315467566712,
        "cond_entropy-2-nopunct": 1.339293511456633,
        "distinct-3-nopunct": 0.9752883031301482,
        "vocab_size-3-nopunct": 592,
        "unique-3-nopunct": 577,
        "entropy-3-nopunct": 9.196129312515973,
        "cond_entropy-3-nopunct": 0.09110496551797587,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19883040935672514,
            "2": 0.5128205128205128,
            "3": 0.6853281853281853
        },
        "nist": 6.195432574240908,
        "rouge1": {
            "precision": 0.73483,
            "recall": 0.66929,
            "fmeasure": 0.68979
        },
        "rouge2": {
            "precision": 0.47997,
            "recall": 0.44611,
            "fmeasure": 0.45512
        },
        "rougeL": {
            "precision": 0.61246,
            "recall": 0.56942,
            "fmeasure": 0.58203
        },
        "rougeLsum": {
            "precision": 0.61246,
            "recall": 0.56942,
            "fmeasure": 0.58203
        },
        "bleu": 33.60574,
        "meteor": 0.34171738042003186,
        "bertscore": {
            "precision": 0.91571,
            "recall": 0.90209,
            "f1": 0.90697
        },
        "nubia": {
            "semantic_relation": 3.99962,
            "contradiction": 13.96339,
            "irrelevancy": 34.21228,
            "logical_agreement": 51.82433,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.57212,
            "nubia_score": 0.67794
        },
        "bleurt": 0.11332
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.72462,
        "msttr-100_nopunct": 0.76455,
        "total_length": 1305,
        "mean_pred_length": 16.3125,
        "std_pred_length": 6.009562692076687,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.49885057471264366,
        "vocab_size-1": 651,
        "unique-1": 525,
        "entropy-1": 8.082770617257491,
        "distinct-2": 0.8824489795918368,
        "vocab_size-2": 1081,
        "unique-2": 998,
        "entropy-2": 9.940489456297417,
        "cond_entropy-2": 1.6603220185429086,
        "distinct-3": 0.9668122270742358,
        "vocab_size-3": 1107,
        "unique-3": 1075,
        "entropy-3": 10.089625941516164,
        "cond_entropy-3": 0.15949558015934226,
        "total_length-nopunct": 1137,
        "mean_pred_length-nopunct": 14.2125,
        "std_pred_length-nopunct": 5.41454926563606,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.565523306948109,
        "vocab_size-1-nopunct": 643,
        "unique-1-nopunct": 522,
        "entropy-1-nopunct": 8.355573842208246,
        "distinct-2-nopunct": 0.8978240302743614,
        "vocab_size-2-nopunct": 949,
        "unique-2-nopunct": 890,
        "entropy-2-nopunct": 9.75728780556645,
        "cond_entropy-2-nopunct": 1.4964344616785767,
        "distinct-3-nopunct": 0.9744114636642784,
        "vocab_size-3-nopunct": 952,
        "unique-3-nopunct": 931,
        "entropy-3-nopunct": 9.876570403988376,
        "cond_entropy-3-nopunct": 0.14085654772105047,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2330508474576271,
            "2": 0.36619718309859156,
            "3": 0.7125416204217536
        },
        "nist": 6.91111936562481,
        "rouge1": {
            "precision": 0.72914,
            "recall": 0.68331,
            "fmeasure": 0.69055
        },
        "rouge2": {
            "precision": 0.47945,
            "recall": 0.44523,
            "fmeasure": 0.45065
        },
        "rougeL": {
            "precision": 0.62912,
            "recall": 0.59223,
            "fmeasure": 0.59588
        },
        "rougeLsum": {
            "precision": 0.62912,
            "recall": 0.59223,
            "fmeasure": 0.59588
        },
        "bleu": 39.98335,
        "meteor": 0.35989015353498854,
        "bertscore": {
            "precision": 0.92048,
            "recall": 0.91405,
            "f1": 0.91577
        },
        "nubia": {
            "semantic_relation": 4.13357,
            "contradiction": 9.62799,
            "irrelevancy": 32.17615,
            "logical_agreement": 58.19586,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.75748,
            "nubia_score": 0.69619
        },
        "bleurt": 0.2193
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "nist": 2.143626447431683,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.45,
            "fmeasure": 0.5625
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.31579,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.45,
            "fmeasure": 0.5625
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.45,
            "fmeasure": 0.5625
        },
        "bleu": 43.66835,
        "meteor": 0.22227134161217832,
        "bertscore": {
            "precision": 0.91429,
            "recall": 0.86057,
            "f1": 0.88175
        },
        "nubia": {
            "semantic_relation": 3.6753,
            "contradiction": 0.17676,
            "irrelevancy": 34.63278,
            "logical_agreement": 65.19046,
            "grammar_ref": 4.8547,
            "grammar_hyp": 3.41807,
            "nubia_score": 0.75855
        },
        "bleurt": -0.25694
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.702,
        "msttr-100_nopunct": 0.7625,
        "total_length": 559,
        "mean_pred_length": 15.527777777777779,
        "std_pred_length": 4.974859635714533,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5724508050089445,
        "vocab_size-1": 320,
        "unique-1": 266,
        "entropy-1": 7.303804690362704,
        "distinct-2": 0.9349904397705545,
        "vocab_size-2": 489,
        "unique-2": 470,
        "entropy-2": 8.859569730022578,
        "cond_entropy-2": 1.3753145466756533,
        "distinct-3": 0.9835728952772074,
        "vocab_size-3": 479,
        "unique-3": 472,
        "entropy-3": 8.893373675630261,
        "cond_entropy-3": 0.04234502697133627,
        "total_length-nopunct": 495,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 4.97423919364113,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6323232323232323,
        "vocab_size-1-nopunct": 313,
        "unique-1-nopunct": 266,
        "entropy-1-nopunct": 7.434328184064863,
        "distinct-2-nopunct": 0.9389978213507625,
        "vocab_size-2-nopunct": 431,
        "unique-2-nopunct": 417,
        "entropy-2-nopunct": 8.675184644169464,
        "cond_entropy-2-nopunct": 1.3385809647021487,
        "distinct-3-nopunct": 0.9929078014184397,
        "vocab_size-3-nopunct": 420,
        "unique-3-nopunct": 417,
        "entropy-3-nopunct": 8.710329455956801,
        "cond_entropy-3-nopunct": 0.047007613614417285,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23648648648648649,
            "2": 0.3146067415730337,
            "3": 0.7215496368038741
        },
        "nist": 5.728171843197239,
        "rouge1": {
            "precision": 0.79397,
            "recall": 0.67876,
            "fmeasure": 0.72474
        },
        "rouge2": {
            "precision": 0.55072,
            "recall": 0.47038,
            "fmeasure": 0.5009
        },
        "rougeL": {
            "precision": 0.70213,
            "recall": 0.60581,
            "fmeasure": 0.6433
        },
        "rougeLsum": {
            "precision": 0.70213,
            "recall": 0.60581,
            "fmeasure": 0.6433
        },
        "bleu": 41.47132,
        "meteor": 0.343376013903374,
        "bertscore": {
            "precision": 0.93846,
            "recall": 0.91118,
            "f1": 0.92283
        },
        "nubia": {
            "semantic_relation": 4.13384,
            "contradiction": 2.97807,
            "irrelevancy": 28.08609,
            "logical_agreement": 68.93583,
            "grammar_ref": 4.82696,
            "grammar_hyp": 5.10063,
            "nubia_score": 0.67584
        },
        "bleurt": 0.22149
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.7025,
        "msttr-100_nopunct": 0.74333,
        "total_length": 407,
        "mean_pred_length": 16.958333333333332,
        "std_pred_length": 4.467280741370775,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.5847665847665847,
        "vocab_size-1": 238,
        "unique-1": 200,
        "entropy-1": 7.016084346932223,
        "distinct-2": 0.9138381201044387,
        "vocab_size-2": 350,
        "unique-2": 333,
        "entropy-2": 8.357634908542567,
        "cond_entropy-2": 1.2302493345604475,
        "distinct-3": 0.9805013927576601,
        "vocab_size-3": 352,
        "unique-3": 347,
        "entropy-3": 8.443271788697718,
        "cond_entropy-3": 0.1005827747544737,
        "total_length-nopunct": 352,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 3.793268892247014,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.65625,
        "vocab_size-1-nopunct": 231,
        "unique-1-nopunct": 198,
        "entropy-1-nopunct": 7.167265747674364,
        "distinct-2-nopunct": 0.9115853658536586,
        "vocab_size-2-nopunct": 299,
        "unique-2-nopunct": 284,
        "entropy-2-nopunct": 8.126985989662488,
        "cond_entropy-2-nopunct": 1.0402904200441605,
        "distinct-3-nopunct": 0.9901315789473685,
        "vocab_size-3-nopunct": 301,
        "unique-3-nopunct": 298,
        "entropy-3-nopunct": 8.228190671338321,
        "cond_entropy-3-nopunct": 0.1194072618039238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.3870967741935484,
            "3": 0.8148148148148148
        },
        "nist": 6.231500584501499,
        "rouge1": {
            "precision": 0.7434,
            "recall": 0.70758,
            "fmeasure": 0.71498
        },
        "rouge2": {
            "precision": 0.48605,
            "recall": 0.45592,
            "fmeasure": 0.4634
        },
        "rougeL": {
            "precision": 0.61508,
            "recall": 0.59067,
            "fmeasure": 0.59501
        },
        "rougeLsum": {
            "precision": 0.61508,
            "recall": 0.59067,
            "fmeasure": 0.59501
        },
        "bleu": 42.25771,
        "meteor": 0.3841583840586865,
        "bertscore": {
            "precision": 0.92378,
            "recall": 0.91626,
            "f1": 0.9183
        },
        "nubia": {
            "semantic_relation": 4.10739,
            "contradiction": 5.12412,
            "irrelevancy": 34.73751,
            "logical_agreement": 60.13838,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.46608,
            "nubia_score": 0.72307
        },
        "bleurt": 0.20947
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 16.5,
        "std_pred_length": 5.795112883571237,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 72,
        "unique-1": 59,
        "entropy-1": 5.945027266929572,
        "distinct-2": 0.956989247311828,
        "vocab_size-2": 89,
        "unique-2": 85,
        "entropy-2": 6.453137305731693,
        "cond_entropy-2": 0.41667278766732074,
        "distinct-3": 1.0,
        "vocab_size-3": 87,
        "unique-3": 87,
        "entropy-3": 6.442943495848723,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.597618541248888,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.920918896493509,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.344698375159712,
        "cond_entropy-2-nopunct": 0.41491852863732204,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.285402218862257,
        "cond_entropy-3-nopunct": -0.05563315263446062,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.4230769230769231,
            "3": 0.7068965517241379
        },
        "nist": 4.493030555680726,
        "rouge1": {
            "precision": 0.63919,
            "recall": 0.58405,
            "fmeasure": 0.59769
        },
        "rouge2": {
            "precision": 0.36706,
            "recall": 0.33857,
            "fmeasure": 0.34541
        },
        "rougeL": {
            "precision": 0.47762,
            "recall": 0.42574,
            "fmeasure": 0.43832
        },
        "rougeLsum": {
            "precision": 0.47762,
            "recall": 0.42574,
            "fmeasure": 0.43832
        },
        "bleu": 26.68691,
        "meteor": 0.30123106440148073,
        "bertscore": {
            "precision": 0.90209,
            "recall": 0.88785,
            "f1": 0.8945
        },
        "nubia": {
            "semantic_relation": 3.5768,
            "contradiction": 18.29462,
            "irrelevancy": 50.70871,
            "logical_agreement": 30.99667,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.19117,
            "nubia_score": 0.57182
        },
        "bleurt": 0.07994
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 1322,
        "msttr-100": 0.52084,
        "msttr-100_nopunct": 0.5276,
        "total_length": 23988,
        "mean_pred_length": 18.145234493192135,
        "std_pred_length": 6.798711443350487,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.06711689177922295,
        "vocab_size-1": 1610,
        "unique-1": 568,
        "entropy-1": 8.0121587643971,
        "distinct-2": 0.23122738904085413,
        "vocab_size-2": 5241,
        "unique-2": 2612,
        "entropy-2": 11.06713320114611,
        "cond_entropy-2": 2.957132388799744,
        "distinct-3": 0.4043759370314843,
        "vocab_size-3": 8631,
        "unique-3": 5406,
        "entropy-3": 12.226657648203464,
        "cond_entropy-3": 1.2613553391903176,
        "total_length-nopunct": 21743,
        "mean_pred_length-nopunct": 16.447049924357035,
        "std_pred_length-nopunct": 6.494894625682379,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07363289334498459,
        "vocab_size-1-nopunct": 1601,
        "unique-1-nopunct": 567,
        "entropy-1-nopunct": 8.190878380359027,
        "distinct-2-nopunct": 0.23808824249547034,
        "vocab_size-2-nopunct": 4862,
        "unique-2-nopunct": 2518,
        "entropy-2-nopunct": 10.941994762866647,
        "cond_entropy-2-nopunct": 2.939973117593302,
        "distinct-3-nopunct": 0.4128488402534164,
        "vocab_size-3-nopunct": 7885,
        "unique-3-nopunct": 5047,
        "entropy-3-nopunct": 12.083832445846955,
        "cond_entropy-3-nopunct": 1.2441793542609754,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1943621434013375,
            "2": 0.5259311314125088,
            "3": 0.7748463498725828,
            "4": 0.9411764705882353,
            "5": 0.42857142857142855
        },
        "nist": 7.73697617953663,
        "rouge1": {
            "precision": 0.78145,
            "recall": 0.70928,
            "fmeasure": 0.73333
        },
        "rouge2": {
            "precision": 0.52507,
            "recall": 0.47582,
            "fmeasure": 0.49157
        },
        "rougeL": {
            "precision": 0.64675,
            "recall": 0.58765,
            "fmeasure": 0.607
        },
        "rougeLsum": {
            "precision": 0.64675,
            "recall": 0.58765,
            "fmeasure": 0.607
        },
        "bleu": 42.50199,
        "meteor": 0.3476869722863409,
        "bertscore": {
            "precision": 0.92389,
            "recall": 0.9093,
            "f1": 0.9151
        },
        "nubia": {
            "semantic_relation": 4.22959,
            "contradiction": 8.22259,
            "irrelevancy": 10.41943,
            "logical_agreement": 81.35798,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.83299,
            "nubia_score": 0.70814
        },
        "bleurt": 0.12966
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 457,
        "msttr-100": 0.49163,
        "msttr-100_nopunct": 0.49292,
        "total_length": 9873,
        "mean_pred_length": 21.603938730853393,
        "std_pred_length": 4.005279041160429,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.12194874911374455,
        "vocab_size-1": 1204,
        "unique-1": 520,
        "entropy-1": 7.902963448008125,
        "distinct-2": 0.34303313508920985,
        "vocab_size-2": 3230,
        "unique-2": 1905,
        "entropy-2": 10.614612180237629,
        "cond_entropy-2": 2.728363637913409,
        "distinct-3": 0.522379729880567,
        "vocab_size-3": 4680,
        "unique-3": 3281,
        "entropy-3": 11.553436908714465,
        "cond_entropy-3": 1.014947744272876,
        "total_length-nopunct": 8946,
        "mean_pred_length-nopunct": 19.575492341356675,
        "std_pred_length-nopunct": 3.9337082004360298,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.1336910350994858,
        "vocab_size-1-nopunct": 1196,
        "unique-1-nopunct": 518,
        "entropy-1-nopunct": 8.060310906724247,
        "distinct-2-nopunct": 0.35492990929438095,
        "vocab_size-2-nopunct": 3013,
        "unique-2-nopunct": 1831,
        "entropy-2-nopunct": 10.525959272981622,
        "cond_entropy-2-nopunct": 2.6039266217832324,
        "distinct-3-nopunct": 0.5297559760956175,
        "vocab_size-3-nopunct": 4255,
        "unique-3-nopunct": 3029,
        "entropy-3-nopunct": 11.414755726889048,
        "cond_entropy-3-nopunct": 0.9646013037470785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.16880341880341881,
            "2": 0.4481458202388435,
            "3": 0.688372848327379,
            "4": 0.25,
            "5": 0.375
        },
        "nist": 4.374928829768615,
        "rouge1": {
            "precision": 0.77477,
            "recall": 0.60146,
            "fmeasure": 0.65883
        },
        "rouge2": {
            "precision": 0.50237,
            "recall": 0.38227,
            "fmeasure": 0.42025
        },
        "rougeL": {
            "precision": 0.6214,
            "recall": 0.48037,
            "fmeasure": 0.5261
        },
        "rougeLsum": {
            "precision": 0.6214,
            "recall": 0.48037,
            "fmeasure": 0.5261
        },
        "bleu": 32.79206,
        "meteor": 0.2884227221361262,
        "bertscore": {
            "precision": 0.91618,
            "recall": 0.88047,
            "f1": 0.89624
        },
        "nubia": {
            "semantic_relation": 3.88228,
            "contradiction": 10.09511,
            "irrelevancy": 10.00023,
            "logical_agreement": 79.90466,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.68455,
            "nubia_score": 0.58576
        },
        "bleurt": -0.12742
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.7025,
        "msttr-100_nopunct": 0.74333,
        "total_length": 415,
        "mean_pred_length": 16.6,
        "std_pred_length": 4.516635916254486,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.563855421686747,
        "vocab_size-1": 234,
        "unique-1": 190,
        "entropy-1": 7.127270207030902,
        "distinct-2": 0.8948717948717949,
        "vocab_size-2": 349,
        "unique-2": 320,
        "entropy-2": 8.370075634229186,
        "cond_entropy-2": 1.0612755117182044,
        "distinct-3": 0.9726027397260274,
        "vocab_size-3": 355,
        "unique-3": 346,
        "entropy-3": 8.454889948282007,
        "cond_entropy-3": 0.09558518251315899,
        "total_length-nopunct": 358,
        "mean_pred_length-nopunct": 14.32,
        "std_pred_length-nopunct": 3.9060977970347848,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6368715083798883,
        "vocab_size-1-nopunct": 228,
        "unique-1-nopunct": 190,
        "entropy-1-nopunct": 7.263483740554215,
        "distinct-2-nopunct": 0.9009009009009009,
        "vocab_size-2-nopunct": 300,
        "unique-2-nopunct": 278,
        "entropy-2-nopunct": 8.151827503675438,
        "cond_entropy-2-nopunct": 0.9630117653073094,
        "distinct-3-nopunct": 0.9805194805194806,
        "vocab_size-3-nopunct": 302,
        "unique-3-nopunct": 296,
        "entropy-3-nopunct": 8.22782550173382,
        "cond_entropy-3-nopunct": 0.0912212824249943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.3333333333333333,
            "3": 0.7561837455830389
        },
        "nist": 6.386675348826871,
        "rouge1": {
            "precision": 0.75429,
            "recall": 0.72437,
            "fmeasure": 0.72687
        },
        "rouge2": {
            "precision": 0.53577,
            "recall": 0.50587,
            "fmeasure": 0.5124
        },
        "rougeL": {
            "precision": 0.63965,
            "recall": 0.62715,
            "fmeasure": 0.62316
        },
        "rougeLsum": {
            "precision": 0.63965,
            "recall": 0.62715,
            "fmeasure": 0.62316
        },
        "bleu": 44.85972,
        "meteor": 0.39121622777476495,
        "bertscore": {
            "precision": 0.9282,
            "recall": 0.92079,
            "f1": 0.92387
        },
        "nubia": {
            "semantic_relation": 3.90789,
            "contradiction": 19.67196,
            "irrelevancy": 21.50432,
            "logical_agreement": 58.82372,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.67625,
            "nubia_score": 0.64377
        },
        "bleurt": 0.18337
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.7825,
        "total_length": 476,
        "mean_pred_length": 16.413793103448278,
        "std_pred_length": 5.65391070870609,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5903361344537815,
        "vocab_size-1": 281,
        "unique-1": 239,
        "entropy-1": 7.285802380273831,
        "distinct-2": 0.9172259507829977,
        "vocab_size-2": 410,
        "unique-2": 388,
        "entropy-2": 8.59052040942639,
        "cond_entropy-2": 1.1174238089055324,
        "distinct-3": 0.9880382775119617,
        "vocab_size-3": 413,
        "unique-3": 408,
        "entropy-3": 8.683435687104748,
        "cond_entropy-3": 0.09816577466637891,
        "total_length-nopunct": 405,
        "mean_pred_length-nopunct": 13.96551724137931,
        "std_pred_length-nopunct": 4.319025741200324,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6790123456790124,
        "vocab_size-1-nopunct": 275,
        "unique-1-nopunct": 237,
        "entropy-1-nopunct": 7.493967474912489,
        "distinct-2-nopunct": 0.9361702127659575,
        "vocab_size-2-nopunct": 352,
        "unique-2-nopunct": 338,
        "entropy-2-nopunct": 8.382437107121202,
        "cond_entropy-2-nopunct": 0.9525962826362749,
        "distinct-3-nopunct": 0.9942363112391931,
        "vocab_size-3-nopunct": 345,
        "unique-3-nopunct": 343,
        "entropy-3-nopunct": 8.427264475056655,
        "cond_entropy-3-nopunct": 0.05007945897485506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18446601941747573,
            "2": 0.37209302325581395,
            "3": 0.8013245033112583
        },
        "nist": 6.52093296160162,
        "rouge1": {
            "precision": 0.76413,
            "recall": 0.74747,
            "fmeasure": 0.74148
        },
        "rouge2": {
            "precision": 0.53229,
            "recall": 0.51791,
            "fmeasure": 0.51546
        },
        "rougeL": {
            "precision": 0.66547,
            "recall": 0.64789,
            "fmeasure": 0.64446
        },
        "rougeLsum": {
            "precision": 0.66547,
            "recall": 0.64789,
            "fmeasure": 0.64446
        },
        "bleu": 45.2603,
        "meteor": 0.38584996528910825,
        "bertscore": {
            "precision": 0.93112,
            "recall": 0.93239,
            "f1": 0.93018
        },
        "nubia": {
            "semantic_relation": 4.19802,
            "contradiction": 8.64153,
            "irrelevancy": 33.19585,
            "logical_agreement": 58.16262,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.51965,
            "nubia_score": 0.72372
        },
        "bleurt": 0.2897
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.70062,
        "msttr-100_nopunct": 0.75929,
        "total_length": 1630,
        "mean_pred_length": 15.523809523809524,
        "std_pred_length": 5.3755978415609755,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 34,
        "distinct-1": 0.4607361963190184,
        "vocab_size-1": 751,
        "unique-1": 606,
        "entropy-1": 7.946179121766164,
        "distinct-2": 0.8340983606557377,
        "vocab_size-2": 1272,
        "unique-2": 1166,
        "entropy-2": 10.071026362045355,
        "cond_entropy-2": 1.8879215720760594,
        "distinct-3": 0.9429577464788732,
        "vocab_size-3": 1339,
        "unique-3": 1293,
        "entropy-3": 10.329412349273277,
        "cond_entropy-3": 0.28241392022388584,
        "total_length-nopunct": 1416,
        "mean_pred_length-nopunct": 13.485714285714286,
        "std_pred_length-nopunct": 4.791091506444983,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5247175141242938,
        "vocab_size-1-nopunct": 743,
        "unique-1-nopunct": 604,
        "entropy-1-nopunct": 8.267297862409759,
        "distinct-2-nopunct": 0.8497330282227308,
        "vocab_size-2-nopunct": 1114,
        "unique-2-nopunct": 1036,
        "entropy-2-nopunct": 9.879459927401815,
        "cond_entropy-2-nopunct": 1.7451211849924821,
        "distinct-3-nopunct": 0.9643449419568823,
        "vocab_size-3-nopunct": 1163,
        "unique-3-nopunct": 1133,
        "entropy-3-nopunct": 10.151217622657368,
        "cond_entropy-3-nopunct": 0.30485407957971083,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.189873417721519,
            "2": 0.3177966101694915,
            "3": 0.7805294619982921
        },
        "nist": 7.577705617554393,
        "rouge1": {
            "precision": 0.80203,
            "recall": 0.75303,
            "fmeasure": 0.76724
        },
        "rouge2": {
            "precision": 0.55421,
            "recall": 0.51745,
            "fmeasure": 0.52679
        },
        "rougeL": {
            "precision": 0.68554,
            "recall": 0.6427,
            "fmeasure": 0.65472
        },
        "rougeLsum": {
            "precision": 0.68554,
            "recall": 0.6427,
            "fmeasure": 0.65472
        },
        "bleu": 44.29848,
        "meteor": 0.3962272223528531,
        "bertscore": {
            "precision": 0.93635,
            "recall": 0.93155,
            "f1": 0.93326
        },
        "nubia": {
            "semantic_relation": 4.42659,
            "contradiction": 5.51331,
            "irrelevancy": 24.28728,
            "logical_agreement": 70.1994,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.13453,
            "nubia_score": 0.77833
        },
        "bleurt": 0.34253
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.026442737724814782,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6923076923076923
        },
        "nist": 2.3529411764705883,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.76923,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.58333,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.76923,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.76923,
            "fmeasure": 0.66667
        },
        "bleu": 34.82353,
        "meteor": 0.3812660427694212,
        "bertscore": {
            "precision": 0.889,
            "recall": 0.90096,
            "f1": 0.89494
        },
        "nubia": {
            "semantic_relation": 3.67479,
            "contradiction": 0.1674,
            "irrelevancy": 99.71684,
            "logical_agreement": 0.11576,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.9497,
            "nubia_score": 0.65993
        },
        "bleurt": 0.07622
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 11.666666666666666,
        "std_pred_length": 5.436502143433364,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.8,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.686146588249908,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.206807217497642,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.14201900487242786,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 4.988876515698588,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.607264455478377,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.23726173674799544,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.16349873228287956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.625
        },
        "nist": 1.6218408142351728,
        "rouge1": {
            "precision": 0.76543,
            "recall": 0.62037,
            "fmeasure": 0.67696
        },
        "rouge2": {
            "precision": 0.5902,
            "recall": 0.49559,
            "fmeasure": 0.53199
        },
        "rougeL": {
            "precision": 0.7284,
            "recall": 0.59656,
            "fmeasure": 0.64798
        },
        "rougeLsum": {
            "precision": 0.7284,
            "recall": 0.59656,
            "fmeasure": 0.64798
        },
        "bleu": 26.32557,
        "meteor": 0.31324457760756036,
        "bertscore": {
            "precision": 0.93938,
            "recall": 0.90252,
            "f1": 0.9205
        },
        "nubia": {
            "semantic_relation": 3.75134,
            "contradiction": 11.79071,
            "irrelevancy": 1.07364,
            "logical_agreement": 87.13565,
            "grammar_ref": 5.04645,
            "grammar_hyp": 5.22101,
            "nubia_score": 0.56068
        },
        "bleurt": 0.11233
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 12.4,
        "std_pred_length": 2.5768197453450252,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.5806451612903226,
        "vocab_size-1": 36,
        "unique-1": 21,
        "entropy-1": 4.936141222019722,
        "distinct-2": 0.7543859649122807,
        "vocab_size-2": 43,
        "unique-2": 31,
        "entropy-2": 5.315174663211639,
        "cond_entropy-2": 0.3279856419258803,
        "distinct-3": 0.8076923076923077,
        "vocab_size-3": 42,
        "unique-3": 32,
        "entropy-3": 5.315824333525705,
        "cond_entropy-3": 0.011968454059560651,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 11.6,
        "std_pred_length-nopunct": 2.5768197453450252,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.603448275862069,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.907646245493714,
        "distinct-2-nopunct": 0.7547169811320755,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.208868095990992,
        "cond_entropy-2-nopunct": 0.35314022310424636,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.2099625007211525,
        "cond_entropy-3-nopunct": 0.013495692081434776,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.4107142857142857
        },
        "nist": 1.965482345528078,
        "rouge1": {
            "precision": 0.41806,
            "recall": 0.4279,
            "fmeasure": 0.38115
        },
        "rouge2": {
            "precision": 0.21303,
            "recall": 0.19318,
            "fmeasure": 0.17638
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.34879,
            "fmeasure": 0.28915
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.34879,
            "fmeasure": 0.28915
        },
        "bleu": 6.30382,
        "meteor": 0.18418205842266655,
        "bertscore": {
            "precision": 0.79433,
            "recall": 0.80872,
            "f1": 0.80055
        },
        "nubia": {
            "semantic_relation": 2.63054,
            "contradiction": 0.31072,
            "irrelevancy": 98.63164,
            "logical_agreement": 1.05765,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.92583,
            "nubia_score": 0.23239
        },
        "bleurt": -1.03496
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 91,
        "msttr-100": 0.67786,
        "msttr-100_nopunct": 0.73167,
        "total_length": 1402,
        "mean_pred_length": 15.406593406593407,
        "std_pred_length": 4.985645376848698,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.39158345221112695,
        "vocab_size-1": 549,
        "unique-1": 427,
        "entropy-1": 7.570390864761462,
        "distinct-2": 0.7215865751334859,
        "vocab_size-2": 946,
        "unique-2": 832,
        "entropy-2": 9.441471188515068,
        "cond_entropy-2": 1.6454434241879543,
        "distinct-3": 0.840983606557377,
        "vocab_size-3": 1026,
        "unique-3": 962,
        "entropy-3": 9.750073291254001,
        "cond_entropy-3": 0.32596803350805764,
        "total_length-nopunct": 1222,
        "mean_pred_length-nopunct": 13.428571428571429,
        "std_pred_length-nopunct": 4.617555742609584,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.44435351882160395,
        "vocab_size-1-nopunct": 543,
        "unique-1-nopunct": 426,
        "entropy-1-nopunct": 7.792352788554112,
        "distinct-2-nopunct": 0.7347480106100795,
        "vocab_size-2-nopunct": 831,
        "unique-2-nopunct": 737,
        "entropy-2-nopunct": 9.266232879644829,
        "cond_entropy-2-nopunct": 1.5874925775833264,
        "distinct-3-nopunct": 0.8519230769230769,
        "vocab_size-3-nopunct": 886,
        "unique-3-nopunct": 832,
        "entropy-3-nopunct": 9.561067863278003,
        "cond_entropy-3-nopunct": 0.3374145326716075,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23423423423423423,
            "2": 0.46616541353383456,
            "3": 0.7457983193277311
        },
        "nist": 7.288328954176523,
        "rouge1": {
            "precision": 0.7798,
            "recall": 0.72358,
            "fmeasure": 0.73805
        },
        "rouge2": {
            "precision": 0.57226,
            "recall": 0.52373,
            "fmeasure": 0.53715
        },
        "rougeL": {
            "precision": 0.69157,
            "recall": 0.63881,
            "fmeasure": 0.65293
        },
        "rougeLsum": {
            "precision": 0.69157,
            "recall": 0.63881,
            "fmeasure": 0.65293
        },
        "bleu": 47.84748,
        "meteor": 0.38881246645326717,
        "bertscore": {
            "precision": 0.93281,
            "recall": 0.91812,
            "f1": 0.92405
        },
        "nubia": {
            "semantic_relation": 4.14033,
            "contradiction": 6.6006,
            "irrelevancy": 23.83761,
            "logical_agreement": 69.56179,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.35459,
            "nubia_score": 0.74018
        },
        "bleurt": 0.28149
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.77273,
        "total_length": 1268,
        "mean_pred_length": 16.050632911392405,
        "std_pred_length": 4.778376224854905,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.4629337539432177,
        "vocab_size-1": 587,
        "unique-1": 465,
        "entropy-1": 7.854874025566214,
        "distinct-2": 0.8418839360807401,
        "vocab_size-2": 1001,
        "unique-2": 907,
        "entropy-2": 9.781445655963237,
        "cond_entropy-2": 1.7252293252445046,
        "distinct-3": 0.9504504504504504,
        "vocab_size-3": 1055,
        "unique-3": 1014,
        "entropy-3": 10.00595718194646,
        "cond_entropy-3": 0.2373880126127209,
        "total_length-nopunct": 1107,
        "mean_pred_length-nopunct": 14.012658227848101,
        "std_pred_length-nopunct": 4.512973341031684,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5239385727190605,
        "vocab_size-1-nopunct": 580,
        "unique-1-nopunct": 464,
        "entropy-1-nopunct": 8.12283911701667,
        "distinct-2-nopunct": 0.8550583657587548,
        "vocab_size-2-nopunct": 879,
        "unique-2-nopunct": 812,
        "entropy-2-nopunct": 9.590147601967706,
        "cond_entropy-2-nopunct": 1.56407721061519,
        "distinct-3-nopunct": 0.9610115911485775,
        "vocab_size-3-nopunct": 912,
        "unique-3-nopunct": 882,
        "entropy-3-nopunct": 9.80620269903291,
        "cond_entropy-3-nopunct": 0.2286112490517907,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1856060606060606,
            "2": 0.4174757281553398,
            "3": 0.790722761596548
        },
        "nist": 7.578306217894298,
        "rouge1": {
            "precision": 0.82836,
            "recall": 0.77331,
            "fmeasure": 0.79266
        },
        "rouge2": {
            "precision": 0.5996,
            "recall": 0.56438,
            "fmeasure": 0.57595
        },
        "rougeL": {
            "precision": 0.69377,
            "recall": 0.64314,
            "fmeasure": 0.66098
        },
        "rougeLsum": {
            "precision": 0.69377,
            "recall": 0.64314,
            "fmeasure": 0.66098
        },
        "bleu": 45.93357,
        "meteor": 0.40832377867432207,
        "bertscore": {
            "precision": 0.94535,
            "recall": 0.9374,
            "f1": 0.94025
        },
        "nubia": {
            "semantic_relation": 4.41935,
            "contradiction": 10.52702,
            "irrelevancy": 22.90139,
            "logical_agreement": 66.57159,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.83188,
            "nubia_score": 0.78219
        },
        "bleurt": 0.40581
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.708,
        "msttr-100_nopunct": 0.742,
        "total_length": 578,
        "mean_pred_length": 16.055555555555557,
        "std_pred_length": 3.985699746485653,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5588235294117647,
        "vocab_size-1": 323,
        "unique-1": 261,
        "entropy-1": 7.422789186070857,
        "distinct-2": 0.9261992619926199,
        "vocab_size-2": 502,
        "unique-2": 475,
        "entropy-2": 8.904770876247985,
        "cond_entropy-2": 1.2762957395650292,
        "distinct-3": 0.9881422924901185,
        "vocab_size-3": 500,
        "unique-3": 494,
        "entropy-3": 8.959278159674534,
        "cond_entropy-3": 0.06712707382940634,
        "total_length-nopunct": 508,
        "mean_pred_length-nopunct": 14.11111111111111,
        "std_pred_length-nopunct": 3.7695989897083053,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6220472440944882,
        "vocab_size-1-nopunct": 316,
        "unique-1-nopunct": 259,
        "entropy-1-nopunct": 7.5722509781018115,
        "distinct-2-nopunct": 0.9216101694915254,
        "vocab_size-2-nopunct": 435,
        "unique-2-nopunct": 411,
        "entropy-2-nopunct": 8.691670664854618,
        "cond_entropy-2-nopunct": 1.2033165005014577,
        "distinct-3-nopunct": 0.9885321100917431,
        "vocab_size-3-nopunct": 431,
        "unique-3-nopunct": 426,
        "entropy-3-nopunct": 8.745248544960356,
        "cond_entropy-3-nopunct": 0.06475908616604258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1419753086419753,
            "2": 0.5423728813559322,
            "3": 0.796923076923077
        },
        "nist": 6.532506702812819,
        "rouge1": {
            "precision": 0.71953,
            "recall": 0.76075,
            "fmeasure": 0.7281
        },
        "rouge2": {
            "precision": 0.49749,
            "recall": 0.52965,
            "fmeasure": 0.50308
        },
        "rougeL": {
            "precision": 0.617,
            "recall": 0.657,
            "fmeasure": 0.62737
        },
        "rougeLsum": {
            "precision": 0.617,
            "recall": 0.657,
            "fmeasure": 0.62737
        },
        "bleu": 45.33378,
        "meteor": 0.4167804144716683,
        "bertscore": {
            "precision": 0.92439,
            "recall": 0.93203,
            "f1": 0.92653
        },
        "nubia": {
            "semantic_relation": 4.21414,
            "contradiction": 6.07107,
            "irrelevancy": 44.29904,
            "logical_agreement": 49.62989,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.31654,
            "nubia_score": 0.7508
        },
        "bleurt": 0.2782
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 1177,
        "msttr-100": 0.64412,
        "msttr-100_nopunct": 0.66801,
        "total_length": 22168,
        "mean_pred_length": 18.834324553950722,
        "std_pred_length": 6.6036403343359,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.05783110790328401,
        "vocab_size-1": 1282,
        "unique-1": 425,
        "entropy-1": 7.762328029880129,
        "distinct-2": 0.21542565861559715,
        "vocab_size-2": 4522,
        "unique-2": 2217,
        "entropy-2": 10.792348784074367,
        "cond_entropy-2": 2.963467315084935,
        "distinct-3": 0.39456949631573635,
        "vocab_size-3": 7818,
        "unique-3": 4907,
        "entropy-3": 12.024564120346094,
        "cond_entropy-3": 1.3350024784639296,
        "total_length-nopunct": 20122,
        "mean_pred_length-nopunct": 17.096006796941378,
        "std_pred_length-nopunct": 6.332083833036554,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06331378590597356,
        "vocab_size-1-nopunct": 1274,
        "unique-1-nopunct": 423,
        "entropy-1-nopunct": 7.903436081774782,
        "distinct-2-nopunct": 0.22544206914753234,
        "vocab_size-2-nopunct": 4271,
        "unique-2-nopunct": 2214,
        "entropy-2-nopunct": 10.675389018534238,
        "cond_entropy-2-nopunct": 2.954801740953983,
        "distinct-3-nopunct": 0.40601080594326877,
        "vocab_size-3-nopunct": 7214,
        "unique-3-nopunct": 4670,
        "entropy-3-nopunct": 11.888310190253167,
        "cond_entropy-3-nopunct": 1.3110294316596747,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1814131693843001,
            "2": 0.508779966407085,
            "3": 0.7751219915639732,
            "4": 0.4,
            "5": 0.41379310344827586
        },
        "nist": 7.257091037398365,
        "rouge1": {
            "precision": 0.7637,
            "recall": 0.69294,
            "fmeasure": 0.71683
        },
        "rouge2": {
            "precision": 0.49266,
            "recall": 0.44639,
            "fmeasure": 0.46129
        },
        "rougeL": {
            "precision": 0.62197,
            "recall": 0.56432,
            "fmeasure": 0.5834
        },
        "rougeLsum": {
            "precision": 0.62197,
            "recall": 0.56432,
            "fmeasure": 0.5834
        },
        "bleu": 39.06005,
        "meteor": 0.3353292091125613,
        "bertscore": {
            "precision": 0.91512,
            "recall": 0.90114,
            "f1": 0.9066
        },
        "nubia": {
            "semantic_relation": 4.15457,
            "contradiction": 9.70399,
            "irrelevancy": 11.36265,
            "logical_agreement": 78.93336,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.8771,
            "nubia_score": 0.68132
        },
        "bleurt": 0.05796
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.0,
        "median_pred_length": 19.0,
        "min_pred_length": 15,
        "max_pred_length": 23,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.80700942128139,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.27629991861437864,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8484848484848485,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.7413638163281515,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.1356086426413251,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.027249798017923668,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.8333333333333334
        },
        "nist": 3.4304632721584185,
        "rouge1": {
            "precision": 0.69487,
            "recall": 0.74929,
            "fmeasure": 0.71779
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.46368,
            "fmeasure": 0.43817
        },
        "rougeL": {
            "precision": 0.60641,
            "recall": 0.67664,
            "fmeasure": 0.63467
        },
        "rougeLsum": {
            "precision": 0.60641,
            "recall": 0.67664,
            "fmeasure": 0.63467
        },
        "bleu": 34.88863,
        "meteor": 0.34394600920413115,
        "bertscore": {
            "precision": 0.86972,
            "recall": 0.91589,
            "f1": 0.88903
        },
        "nubia": {
            "semantic_relation": 4.17835,
            "contradiction": 0.24908,
            "irrelevancy": 50.08292,
            "logical_agreement": 49.668,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.07465,
            "nubia_score": 0.70938
        },
        "bleurt": 0.29661
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.716,
        "msttr-100_nopunct": 0.748,
        "total_length": 581,
        "mean_pred_length": 16.6,
        "std_pred_length": 5.155856586723213,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5387263339070568,
        "vocab_size-1": 313,
        "unique-1": 245,
        "entropy-1": 7.378650768342075,
        "distinct-2": 0.8901098901098901,
        "vocab_size-2": 486,
        "unique-2": 452,
        "entropy-2": 8.816092946733118,
        "cond_entropy-2": 1.2655209796312643,
        "distinct-3": 0.9667318982387475,
        "vocab_size-3": 494,
        "unique-3": 484,
        "entropy-3": 8.919343008313712,
        "cond_entropy-3": 0.11828576959730815,
        "total_length-nopunct": 503,
        "mean_pred_length-nopunct": 14.371428571428572,
        "std_pred_length-nopunct": 5.1218619063535,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6083499005964215,
        "vocab_size-1-nopunct": 306,
        "unique-1-nopunct": 244,
        "entropy-1-nopunct": 7.521480517701942,
        "distinct-2-nopunct": 0.9081196581196581,
        "vocab_size-2-nopunct": 425,
        "unique-2-nopunct": 404,
        "entropy-2-nopunct": 8.627738918255119,
        "cond_entropy-2-nopunct": 1.194437310858517,
        "distinct-3-nopunct": 0.9792147806004619,
        "vocab_size-3-nopunct": 424,
        "unique-3-nopunct": 419,
        "entropy-3-nopunct": 8.7096792193257,
        "cond_entropy-3-nopunct": 0.09924261757514655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19148936170212766,
            "2": 0.5132743362831859,
            "3": 0.7279596977329975
        },
        "nist": 6.561947641832449,
        "rouge1": {
            "precision": 0.78588,
            "recall": 0.72916,
            "fmeasure": 0.74752
        },
        "rouge2": {
            "precision": 0.55181,
            "recall": 0.52739,
            "fmeasure": 0.53153
        },
        "rougeL": {
            "precision": 0.7038,
            "recall": 0.66491,
            "fmeasure": 0.67457
        },
        "rougeLsum": {
            "precision": 0.7038,
            "recall": 0.66491,
            "fmeasure": 0.67457
        },
        "bleu": 45.64205,
        "meteor": 0.39882213821281404,
        "bertscore": {
            "precision": 0.93785,
            "recall": 0.92872,
            "f1": 0.93141
        },
        "nubia": {
            "semantic_relation": 4.11688,
            "contradiction": 8.85148,
            "irrelevancy": 30.31422,
            "logical_agreement": 60.83431,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.40329,
            "nubia_score": 0.73654
        },
        "bleurt": 0.26063
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 56,
        "msttr-100": 0.58333,
        "msttr-100_nopunct": 0.648,
        "total_length": 627,
        "mean_pred_length": 11.196428571428571,
        "std_pred_length": 4.922323938871117,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.3014354066985646,
        "vocab_size-1": 189,
        "unique-1": 109,
        "entropy-1": 6.301475449999489,
        "distinct-2": 0.5779334500875657,
        "vocab_size-2": 330,
        "unique-2": 228,
        "entropy-2": 7.9592909197539905,
        "cond_entropy-2": 1.3766253655685685,
        "distinct-3": 0.7281553398058253,
        "vocab_size-3": 375,
        "unique-3": 295,
        "entropy-3": 8.32665965408687,
        "cond_entropy-3": 0.4114980719978836,
        "total_length-nopunct": 553,
        "mean_pred_length-nopunct": 9.875,
        "std_pred_length-nopunct": 4.575019515961498,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.33273056057866185,
        "vocab_size-1-nopunct": 184,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.405388151336061,
        "distinct-2-nopunct": 0.5694164989939637,
        "vocab_size-2-nopunct": 283,
        "unique-2-nopunct": 196,
        "entropy-2-nopunct": 7.715997695518469,
        "cond_entropy-2-nopunct": 1.4655380607818207,
        "distinct-3-nopunct": 0.7233560090702947,
        "vocab_size-3-nopunct": 319,
        "unique-3-nopunct": 249,
        "entropy-3-nopunct": 8.082591209486603,
        "cond_entropy-3-nopunct": 0.42621221107320506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2254335260115607,
            "2": 0.640625,
            "3": 0.8876811594202898
        },
        "nist": 7.178799338297829,
        "rouge1": {
            "precision": 0.81281,
            "recall": 0.77824,
            "fmeasure": 0.78734
        },
        "rouge2": {
            "precision": 0.58245,
            "recall": 0.56986,
            "fmeasure": 0.57033
        },
        "rougeL": {
            "precision": 0.71503,
            "recall": 0.6928,
            "fmeasure": 0.69652
        },
        "rougeLsum": {
            "precision": 0.71503,
            "recall": 0.6928,
            "fmeasure": 0.69652
        },
        "bleu": 55.78949,
        "meteor": 0.45297610736923966,
        "bertscore": {
            "precision": 0.9522,
            "recall": 0.94943,
            "f1": 0.94981
        },
        "nubia": {
            "semantic_relation": 4.66437,
            "contradiction": 2.93687,
            "irrelevancy": 4.42796,
            "logical_agreement": 92.63516,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.36974,
            "nubia_score": 0.85126
        },
        "bleurt": 0.38926
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.675,
        "total_length": 293,
        "mean_pred_length": 17.235294117647058,
        "std_pred_length": 5.116632759525325,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5460750853242321,
        "vocab_size-1": 160,
        "unique-1": 122,
        "entropy-1": 6.535909710026338,
        "distinct-2": 0.8623188405797102,
        "vocab_size-2": 238,
        "unique-2": 216,
        "entropy-2": 7.745051955649507,
        "cond_entropy-2": 1.1067056787554115,
        "distinct-3": 0.9498069498069498,
        "vocab_size-3": 246,
        "unique-3": 235,
        "entropy-3": 7.908700179578415,
        "cond_entropy-3": 0.17978348462074317,
        "total_length-nopunct": 263,
        "mean_pred_length-nopunct": 15.470588235294118,
        "std_pred_length-nopunct": 4.6918909653198275,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5893536121673004,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 6.5534228045235245,
        "distinct-2-nopunct": 0.8699186991869918,
        "vocab_size-2-nopunct": 214,
        "unique-2-nopunct": 195,
        "entropy-2-nopunct": 7.59469530692733,
        "cond_entropy-2-nopunct": 1.1188477468738176,
        "distinct-3-nopunct": 0.9563318777292577,
        "vocab_size-3-nopunct": 219,
        "unique-3-nopunct": 211,
        "entropy-3-nopunct": 7.743133919101314,
        "cond_entropy-3-nopunct": 0.17425925135743014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13157894736842105,
            "2": 0.359375,
            "3": 0.7543859649122807
        },
        "nist": 5.2618441674589285,
        "rouge1": {
            "precision": 0.69746,
            "recall": 0.67266,
            "fmeasure": 0.66766
        },
        "rouge2": {
            "precision": 0.48353,
            "recall": 0.43993,
            "fmeasure": 0.45168
        },
        "rougeL": {
            "precision": 0.62276,
            "recall": 0.59812,
            "fmeasure": 0.59414
        },
        "rougeLsum": {
            "precision": 0.62276,
            "recall": 0.59812,
            "fmeasure": 0.59414
        },
        "bleu": 44.36803,
        "meteor": 0.356765914637455,
        "bertscore": {
            "precision": 0.90891,
            "recall": 0.90514,
            "f1": 0.90632
        },
        "nubia": {
            "semantic_relation": 4.08127,
            "contradiction": 9.29087,
            "irrelevancy": 21.33384,
            "logical_agreement": 69.37529,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.25062,
            "nubia_score": 0.66192
        },
        "bleurt": 0.13253
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.63,
        "msttr-100_nopunct": NaN,
        "total_length": 112,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.80640040940045,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6160714285714286,
        "vocab_size-1": 69,
        "unique-1": 52,
        "entropy-1": 5.731948922290861,
        "distinct-2": 0.8952380952380953,
        "vocab_size-2": 94,
        "unique-2": 84,
        "entropy-2": 6.497532303359796,
        "cond_entropy-2": 0.6895649714883659,
        "distinct-3": 0.9693877551020408,
        "vocab_size-3": 95,
        "unique-3": 92,
        "entropy-3": 6.5534853543192995,
        "cond_entropy-3": 0.07143256626708033,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 5.742786069211937,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6701030927835051,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.720694156463999,
        "distinct-2-nopunct": 0.9111111111111111,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.305687679638959,
        "cond_entropy-2-nopunct": 0.6533771987312235,
        "distinct-3-nopunct": 0.963855421686747,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.302750274720426,
        "cond_entropy-3-nopunct": 0.012763292874641384,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.23076923076923078,
            "3": 0.6533333333333333
        },
        "nist": 4.189202093241677,
        "rouge1": {
            "precision": 0.70784,
            "recall": 0.67687,
            "fmeasure": 0.68291
        },
        "rouge2": {
            "precision": 0.42705,
            "recall": 0.39697,
            "fmeasure": 0.40625
        },
        "rougeL": {
            "precision": 0.5952,
            "recall": 0.568,
            "fmeasure": 0.57448
        },
        "rougeLsum": {
            "precision": 0.5952,
            "recall": 0.568,
            "fmeasure": 0.57448
        },
        "bleu": 30.56229,
        "meteor": 0.31643767360022845,
        "bertscore": {
            "precision": 0.91415,
            "recall": 0.89987,
            "f1": 0.90355
        },
        "nubia": {
            "semantic_relation": 3.97795,
            "contradiction": 2.55793,
            "irrelevancy": 46.08371,
            "logical_agreement": 51.35836,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.48987,
            "nubia_score": 0.65771
        },
        "bleurt": 0.23182
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 51,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.76857,
        "total_length": 830,
        "mean_pred_length": 16.274509803921568,
        "std_pred_length": 5.269514363055945,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.5349397590361445,
        "vocab_size-1": 444,
        "unique-1": 367,
        "entropy-1": 7.617202879756637,
        "distinct-2": 0.8921694480102695,
        "vocab_size-2": 695,
        "unique-2": 645,
        "entropy-2": 9.31731445161621,
        "cond_entropy-2": 1.4905485032362187,
        "distinct-3": 0.9766483516483516,
        "vocab_size-3": 711,
        "unique-3": 694,
        "entropy-3": 9.461091343495408,
        "cond_entropy-3": 0.14976118911238623,
        "total_length-nopunct": 717,
        "mean_pred_length-nopunct": 14.058823529411764,
        "std_pred_length-nopunct": 4.412156845317453,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6122733612273361,
        "vocab_size-1-nopunct": 439,
        "unique-1-nopunct": 366,
        "entropy-1-nopunct": 7.880088823534621,
        "distinct-2-nopunct": 0.9054054054054054,
        "vocab_size-2-nopunct": 603,
        "unique-2-nopunct": 569,
        "entropy-2-nopunct": 9.107557318307135,
        "cond_entropy-2-nopunct": 1.3160089636011159,
        "distinct-3-nopunct": 0.9869918699186991,
        "vocab_size-3-nopunct": 607,
        "unique-3-nopunct": 599,
        "entropy-3-nopunct": 9.238426340064025,
        "cond_entropy-3-nopunct": 0.14853223067891608,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22916666666666666,
            "2": 0.45652173913043476,
            "3": 0.7576853526220615
        },
        "nist": 7.144011427007363,
        "rouge1": {
            "precision": 0.78666,
            "recall": 0.74387,
            "fmeasure": 0.74913
        },
        "rouge2": {
            "precision": 0.55111,
            "recall": 0.52055,
            "fmeasure": 0.52431
        },
        "rougeL": {
            "precision": 0.6744,
            "recall": 0.64852,
            "fmeasure": 0.64666
        },
        "rougeLsum": {
            "precision": 0.6744,
            "recall": 0.64852,
            "fmeasure": 0.64666
        },
        "bleu": 48.56358,
        "meteor": 0.3898108032021843,
        "bertscore": {
            "precision": 0.93555,
            "recall": 0.9293,
            "f1": 0.93065
        },
        "nubia": {
            "semantic_relation": 4.18677,
            "contradiction": 5.66651,
            "irrelevancy": 30.0223,
            "logical_agreement": 64.31119,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.81439,
            "nubia_score": 0.70677
        },
        "bleurt": 0.29248
    },
    "web_nlg_en_validation": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_validation",
        "N": 1667,
        "msttr-100": 0.57275,
        "msttr-100_nopunct": 0.59446,
        "total_length": 30949,
        "mean_pred_length": 18.565686862627473,
        "std_pred_length": 6.513405367642085,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.11554492875375617,
        "vocab_size-1": 3576,
        "unique-1": 1428,
        "entropy-1": 8.774698409944317,
        "distinct-2": 0.3745645789222048,
        "vocab_size-2": 10968,
        "unique-2": 6669,
        "entropy-2": 12.24504213610963,
        "cond_entropy-2": 3.360238292472077,
        "distinct-3": 0.5989860583016476,
        "vocab_size-3": 16541,
        "unique-3": 12207,
        "entropy-3": 13.457279453099451,
        "cond_entropy-3": 1.286515539105666,
        "total_length-nopunct": 27648,
        "mean_pred_length-nopunct": 16.585482903419315,
        "std_pred_length-nopunct": 6.044851790170262,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.12897858796296297,
        "vocab_size-1-nopunct": 3566,
        "unique-1-nopunct": 1427,
        "entropy-1-nopunct": 9.094378873680377,
        "distinct-2-nopunct": 0.3895539047765675,
        "vocab_size-2-nopunct": 10121,
        "unique-2-nopunct": 6323,
        "entropy-2-nopunct": 12.15369763675946,
        "cond_entropy-2-nopunct": 3.228766007009687,
        "distinct-3-nopunct": 0.6084149049930081,
        "vocab_size-3-nopunct": 14793,
        "unique-3-nopunct": 11086,
        "entropy-3-nopunct": 13.297250568608272,
        "cond_entropy-3-nopunct": 1.2204841047415407,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_validation.json",
        "local_recall": {
            "1": 0.28405514760977074,
            "2": 0.6348659003831417,
            "3": 0.8142493638676844,
            "4": 0.8652482269503546,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0
        },
        "nist": 9.827414824230631,
        "rouge1": {
            "precision": 0.82075,
            "recall": 0.74946,
            "fmeasure": 0.77411
        },
        "rouge2": {
            "precision": 0.6027,
            "recall": 0.5524,
            "fmeasure": 0.56906
        },
        "rougeL": {
            "precision": 0.69462,
            "recall": 0.63888,
            "fmeasure": 0.65723
        },
        "rougeLsum": {
            "precision": 0.69462,
            "recall": 0.63888,
            "fmeasure": 0.65723
        },
        "bleu": 52.69532,
        "meteor": 0.3927784825919962,
        "bertscore": {
            "precision": 0.94468,
            "recall": 0.93094,
            "f1": 0.93668
        },
        "nubia": {
            "semantic_relation": 4.40313,
            "contradiction": 4.31032,
            "irrelevancy": 5.87191,
            "logical_agreement": 89.81777,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.70045,
            "nubia_score": 0.77195
        },
        "bleurt": 0.2581
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 28,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.57,
        "total_length": 288,
        "mean_pred_length": 10.285714285714286,
        "std_pred_length": 3.711537444790452,
        "median_pred_length": 9.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.3958333333333333,
        "vocab_size-1": 114,
        "unique-1": 78,
        "entropy-1": 5.742457343371018,
        "distinct-2": 0.7461538461538462,
        "vocab_size-2": 194,
        "unique-2": 155,
        "entropy-2": 7.413222442086359,
        "cond_entropy-2": 1.4329593738324113,
        "distinct-3": 0.8620689655172413,
        "vocab_size-3": 200,
        "unique-3": 177,
        "entropy-3": 7.548608419649895,
        "cond_entropy-3": 0.1711669382713775,
        "total_length-nopunct": 253,
        "mean_pred_length-nopunct": 9.035714285714286,
        "std_pred_length-nopunct": 3.0877886546054607,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.43478260869565216,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 5.797637419625201,
        "distinct-2-nopunct": 0.7288888888888889,
        "vocab_size-2-nopunct": 164,
        "unique-2-nopunct": 129,
        "entropy-2-nopunct": 7.157679373693537,
        "cond_entropy-2-nopunct": 1.532475975931264,
        "distinct-3-nopunct": 0.8426395939086294,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 144,
        "entropy-3-nopunct": 7.267866857472501,
        "cond_entropy-3-nopunct": 0.1683801756320082,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1564625850340136,
            "2": 0.723404255319149,
            "3": 0.8518518518518519,
            "4": 1.0
        },
        "nist": 7.017355630232159,
        "rouge1": {
            "precision": 0.85342,
            "recall": 0.79083,
            "fmeasure": 0.81602
        },
        "rouge2": {
            "precision": 0.63952,
            "recall": 0.59093,
            "fmeasure": 0.61017
        },
        "rougeL": {
            "precision": 0.7684,
            "recall": 0.70235,
            "fmeasure": 0.72934
        },
        "rougeLsum": {
            "precision": 0.7684,
            "recall": 0.70235,
            "fmeasure": 0.72934
        },
        "bleu": 63.25176,
        "meteor": 0.43157177020402043,
        "bertscore": {
            "precision": 0.95186,
            "recall": 0.94115,
            "f1": 0.94552
        },
        "nubia": {
            "semantic_relation": 4.36145,
            "contradiction": 16.81786,
            "irrelevancy": 3.22666,
            "logical_agreement": 79.95548,
            "grammar_ref": 4.67502,
            "grammar_hyp": 4.96353,
            "nubia_score": 0.75883
        },
        "bleurt": 0.40151
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 81,
        "msttr-100": 0.71692,
        "msttr-100_nopunct": 0.77917,
        "total_length": 1397,
        "mean_pred_length": 17.246913580246915,
        "std_pred_length": 5.241173330602654,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.4638511095204009,
        "vocab_size-1": 648,
        "unique-1": 512,
        "entropy-1": 8.024685169367556,
        "distinct-2": 0.8389057750759878,
        "vocab_size-2": 1104,
        "unique-2": 993,
        "entropy-2": 9.927016543683258,
        "cond_entropy-2": 1.7339289671774776,
        "distinct-3": 0.934412955465587,
        "vocab_size-3": 1154,
        "unique-3": 1097,
        "entropy-3": 10.123260528869695,
        "cond_entropy-3": 0.2057333217287786,
        "total_length-nopunct": 1205,
        "mean_pred_length-nopunct": 14.876543209876543,
        "std_pred_length-nopunct": 4.511665855462124,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5311203319502075,
        "vocab_size-1-nopunct": 640,
        "unique-1-nopunct": 510,
        "entropy-1-nopunct": 8.288067875319514,
        "distinct-2-nopunct": 0.8567615658362989,
        "vocab_size-2-nopunct": 963,
        "unique-2-nopunct": 882,
        "entropy-2-nopunct": 9.736085533508186,
        "cond_entropy-2-nopunct": 1.5534440099443398,
        "distinct-3-nopunct": 0.9434324065196549,
        "vocab_size-3-nopunct": 984,
        "unique-3-nopunct": 944,
        "entropy-3-nopunct": 9.899166695121105,
        "cond_entropy-3-nopunct": 0.18730513450257466,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23208191126279865,
            "2": 0.5,
            "3": 0.8056206088992974
        },
        "nist": 7.7607229532467965,
        "rouge1": {
            "precision": 0.77203,
            "recall": 0.7574,
            "fmeasure": 0.75398
        },
        "rouge2": {
            "precision": 0.57591,
            "recall": 0.55919,
            "fmeasure": 0.55929
        },
        "rougeL": {
            "precision": 0.674,
            "recall": 0.65484,
            "fmeasure": 0.65446
        },
        "rougeLsum": {
            "precision": 0.674,
            "recall": 0.65484,
            "fmeasure": 0.65446
        },
        "bleu": 53.41843,
        "meteor": 0.4127404788139409,
        "bertscore": {
            "precision": 0.93248,
            "recall": 0.93291,
            "f1": 0.93079
        },
        "nubia": {
            "semantic_relation": 4.19535,
            "contradiction": 6.35576,
            "irrelevancy": 31.45197,
            "logical_agreement": 62.19227,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.57902,
            "nubia_score": 0.73249
        },
        "bleurt": 0.24562
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 120,
        "msttr-100": 0.35158,
        "msttr-100_nopunct": 0.34389,
        "total_length": 1945,
        "mean_pred_length": 16.208333333333332,
        "std_pred_length": 4.799124630828232,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.08637532133676093,
        "vocab_size-1": 168,
        "unique-1": 22,
        "entropy-1": 6.053335517581478,
        "distinct-2": 0.1884931506849315,
        "vocab_size-2": 344,
        "unique-2": 79,
        "entropy-2": 7.508506225956815,
        "cond_entropy-2": 1.3465696261681974,
        "distinct-3": 0.25395894428152493,
        "vocab_size-3": 433,
        "unique-3": 123,
        "entropy-3": 8.113757761855767,
        "cond_entropy-3": 0.6827163469983014,
        "total_length-nopunct": 1806,
        "mean_pred_length-nopunct": 15.05,
        "std_pred_length-nopunct": 4.629344806053372,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.09191583610188261,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 6.107720621586126,
        "distinct-2-nopunct": 0.18683274021352314,
        "vocab_size-2-nopunct": 315,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 7.35607763232636,
        "cond_entropy-2-nopunct": 1.3772609325272054,
        "distinct-3-nopunct": 0.2554278416347382,
        "vocab_size-3-nopunct": 400,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 7.9971350994615005,
        "cond_entropy-3-nopunct": 0.7024312827959276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6122584943371085
        },
        "nist": 3.5382058965558194,
        "rouge1": {
            "precision": 0.56241,
            "recall": 0.64579,
            "fmeasure": 0.57197
        },
        "rouge2": {
            "precision": 0.32608,
            "recall": 0.37911,
            "fmeasure": 0.33108
        },
        "rougeL": {
            "precision": 0.451,
            "recall": 0.51279,
            "fmeasure": 0.45569
        },
        "rougeLsum": {
            "precision": 0.451,
            "recall": 0.51279,
            "fmeasure": 0.45569
        },
        "bleu": 19.98912,
        "meteor": 0.29693869880595386,
        "bertscore": {
            "precision": 0.87351,
            "recall": 0.88342,
            "f1": 0.87748
        },
        "nubia": {
            "semantic_relation": 3.61636,
            "contradiction": 10.60858,
            "irrelevancy": 66.10578,
            "logical_agreement": 23.28563,
            "grammar_ref": 5.42765,
            "grammar_hyp": 4.87793,
            "nubia_score": 0.57856
        },
        "bleurt": -0.20363
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 78,
        "msttr-100": 0.73538,
        "msttr-100_nopunct": 0.78,
        "total_length": 1322,
        "mean_pred_length": 16.94871794871795,
        "std_pred_length": 6.042366313294554,
        "median_pred_length": 16.5,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.4742813918305598,
        "vocab_size-1": 627,
        "unique-1": 474,
        "entropy-1": 8.077885480069963,
        "distinct-2": 0.8408360128617364,
        "vocab_size-2": 1046,
        "unique-2": 922,
        "entropy-2": 9.865199218990925,
        "cond_entropy-2": 1.5714245399244104,
        "distinct-3": 0.9399656946826758,
        "vocab_size-3": 1096,
        "unique-3": 1030,
        "entropy-3": 10.064273363934335,
        "cond_entropy-3": 0.19736591941377254,
        "total_length-nopunct": 1151,
        "mean_pred_length-nopunct": 14.756410256410257,
        "std_pred_length-nopunct": 5.216310459131881,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5369244135534318,
        "vocab_size-1-nopunct": 618,
        "unique-1-nopunct": 472,
        "entropy-1-nopunct": 8.311405608387126,
        "distinct-2-nopunct": 0.8499534016775396,
        "vocab_size-2-nopunct": 912,
        "unique-2-nopunct": 814,
        "entropy-2-nopunct": 9.665952347568838,
        "cond_entropy-2-nopunct": 1.4304158186581462,
        "distinct-3-nopunct": 0.9437185929648241,
        "vocab_size-3-nopunct": 939,
        "unique-3-nopunct": 887,
        "entropy-3-nopunct": 9.842462489295965,
        "cond_entropy-3-nopunct": 0.19491777693192128,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21888412017167383,
            "2": 0.5191489361702127,
            "3": 0.7834549878345499
        },
        "nist": 7.522811543714192,
        "rouge1": {
            "precision": 0.76298,
            "recall": 0.74291,
            "fmeasure": 0.74344
        },
        "rouge2": {
            "precision": 0.53591,
            "recall": 0.51907,
            "fmeasure": 0.52027
        },
        "rougeL": {
            "precision": 0.66629,
            "recall": 0.64836,
            "fmeasure": 0.64813
        },
        "rougeLsum": {
            "precision": 0.66629,
            "recall": 0.64836,
            "fmeasure": 0.64813
        },
        "bleu": 49.08642,
        "meteor": 0.4100294730163544,
        "bertscore": {
            "precision": 0.92993,
            "recall": 0.93004,
            "f1": 0.92828
        },
        "nubia": {
            "semantic_relation": 4.26647,
            "contradiction": 7.90609,
            "irrelevancy": 33.13529,
            "logical_agreement": 58.95862,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.55453,
            "nubia_score": 0.75413
        },
        "bleurt": 0.33261
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 249,
        "mean_pred_length": 13.833333333333334,
        "std_pred_length": 5.057996968497839,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6104417670682731,
        "vocab_size-1": 152,
        "unique-1": 123,
        "entropy-1": 6.60508522978979,
        "distinct-2": 0.9134199134199135,
        "vocab_size-2": 211,
        "unique-2": 200,
        "entropy-2": 7.630271727741873,
        "cond_entropy-2": 0.834998500316278,
        "distinct-3": 0.9765258215962441,
        "vocab_size-3": 208,
        "unique-3": 204,
        "entropy-3": 7.684217190638256,
        "cond_entropy-3": 0.05948178554456525,
        "total_length-nopunct": 225,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 5.42883249163411,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6622222222222223,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.686124416048605,
        "distinct-2-nopunct": 0.9130434782608695,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 179,
        "entropy-2-nopunct": 7.469301585728449,
        "cond_entropy-2-nopunct": 0.8362008115066248,
        "distinct-3-nopunct": 0.9841269841269841,
        "vocab_size-3-nopunct": 186,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.53049639247505,
        "cond_entropy-3-nopunct": 0.05711005420592258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.42857142857142855,
            "3": 0.7941176470588235
        },
        "nist": 5.819774970912162,
        "rouge1": {
            "precision": 0.7878,
            "recall": 0.69703,
            "fmeasure": 0.73033
        },
        "rouge2": {
            "precision": 0.52208,
            "recall": 0.45353,
            "fmeasure": 0.47727
        },
        "rougeL": {
            "precision": 0.66734,
            "recall": 0.58732,
            "fmeasure": 0.61593
        },
        "rougeLsum": {
            "precision": 0.66734,
            "recall": 0.58732,
            "fmeasure": 0.61593
        },
        "bleu": 42.43807,
        "meteor": 0.3695930309893633,
        "bertscore": {
            "precision": 0.93411,
            "recall": 0.91746,
            "f1": 0.92447
        },
        "nubia": {
            "semantic_relation": 4.31098,
            "contradiction": 2.00499,
            "irrelevancy": 25.12853,
            "logical_agreement": 72.86649,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.89829,
            "nubia_score": 0.781
        },
        "bleurt": 0.35048
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.68333,
        "msttr-100_nopunct": 0.765,
        "total_length": 325,
        "mean_pred_length": 14.772727272727273,
        "std_pred_length": 4.889058453524918,
        "median_pred_length": 13.5,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5969230769230769,
        "vocab_size-1": 194,
        "unique-1": 165,
        "entropy-1": 6.78422967431437,
        "distinct-2": 0.9273927392739274,
        "vocab_size-2": 281,
        "unique-2": 268,
        "entropy-2": 8.053043156824641,
        "cond_entropy-2": 1.0776675790807952,
        "distinct-3": 0.9893238434163701,
        "vocab_size-3": 278,
        "unique-3": 275,
        "entropy-3": 8.11307400705367,
        "cond_entropy-3": 0.0749165377246188,
        "total_length-nopunct": 283,
        "mean_pred_length-nopunct": 12.863636363636363,
        "std_pred_length-nopunct": 4.309560772235006,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6607773851590106,
        "vocab_size-1-nopunct": 187,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 6.881478415505718,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 243,
        "unique-2-nopunct": 234,
        "entropy-2-nopunct": 7.837830745709941,
        "cond_entropy-2-nopunct": 1.051333005304527,
        "distinct-3-nopunct": 0.99581589958159,
        "vocab_size-3-nopunct": 238,
        "unique-3-nopunct": 237,
        "entropy-3-nopunct": 7.892498607143979,
        "cond_entropy-3-nopunct": 0.07216432804030695,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.43636363636363634,
            "3": 0.8043478260869565
        },
        "nist": 5.784319472679471,
        "rouge1": {
            "precision": 0.71992,
            "recall": 0.7467,
            "fmeasure": 0.72398
        },
        "rouge2": {
            "precision": 0.4801,
            "recall": 0.49565,
            "fmeasure": 0.48164
        },
        "rougeL": {
            "precision": 0.62966,
            "recall": 0.65281,
            "fmeasure": 0.63445
        },
        "rougeLsum": {
            "precision": 0.62966,
            "recall": 0.65281,
            "fmeasure": 0.63445
        },
        "bleu": 43.67514,
        "meteor": 0.3919201125354036,
        "bertscore": {
            "precision": 0.91532,
            "recall": 0.926,
            "f1": 0.9192
        },
        "nubia": {
            "semantic_relation": 4.26581,
            "contradiction": 10.37439,
            "irrelevancy": 25.78596,
            "logical_agreement": 63.83965,
            "grammar_ref": 5.03776,
            "grammar_hyp": 4.94158,
            "nubia_score": 0.75735
        },
        "bleurt": 0.22692
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 90,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.2289646009589745,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 70,
        "unique-1": 61,
        "entropy-1": 5.9238595910100695,
        "distinct-2": 0.9882352941176471,
        "vocab_size-2": 84,
        "unique-2": 83,
        "entropy-2": 6.385861524373001,
        "cond_entropy-2": 0.3777662572052478,
        "distinct-3": 1.0,
        "vocab_size-3": 80,
        "unique-3": 80,
        "entropy-3": 6.321928094887356,
        "cond_entropy-3": -0.06246284125033929,
        "total_length-nopunct": 72,
        "mean_pred_length-nopunct": 14.4,
        "std_pred_length-nopunct": 4.223742416388575,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9027777777777778,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.954511459715554,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.066089190457767,
        "cond_entropy-2-nopunct": 0.12765336818451903,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 62,
        "unique-3-nopunct": 62,
        "entropy-3-nopunct": 5.954196310386873,
        "cond_entropy-3-nopunct": -0.11189288007089701,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.7,
            "3": 0.8695652173913043
        },
        "nist": 5.648874298302745,
        "rouge1": {
            "precision": 0.75869,
            "recall": 0.84929,
            "fmeasure": 0.78609
        },
        "rouge2": {
            "precision": 0.53211,
            "recall": 0.57986,
            "fmeasure": 0.54448
        },
        "rougeL": {
            "precision": 0.68535,
            "recall": 0.77793,
            "fmeasure": 0.71393
        },
        "rougeLsum": {
            "precision": 0.68535,
            "recall": 0.77793,
            "fmeasure": 0.71393
        },
        "bleu": 57.6542,
        "meteor": 0.4248299571114594,
        "bertscore": {
            "precision": 0.92186,
            "recall": 0.95559,
            "f1": 0.93725
        },
        "nubia": {
            "semantic_relation": 4.14982,
            "contradiction": 10.36351,
            "irrelevancy": 29.58707,
            "logical_agreement": 60.04941,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.29722,
            "nubia_score": 0.76179
        },
        "bleurt": 0.32718
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 9.0,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.6421498816369064,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 32,
        "unique-2": 29,
        "entropy-2": 4.926733681937769,
        "cond_entropy-2": 0.318238113179016,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 32,
        "unique-3": 30,
        "entropy-3": 4.969815782426808,
        "cond_entropy-3": 0.057387472224599625,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.494680368408909,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.22981123847439044,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.75,
            "3": 0.8148148148148148
        },
        "nist": 4.187224754665869,
        "rouge1": {
            "precision": 0.97368,
            "recall": 0.78791,
            "fmeasure": 0.86801
        },
        "rouge2": {
            "precision": 0.83565,
            "recall": 0.66914,
            "fmeasure": 0.74062
        },
        "rougeL": {
            "precision": 0.92982,
            "recall": 0.7948,
            "fmeasure": 0.85439
        },
        "rougeLsum": {
            "precision": 0.92982,
            "recall": 0.7948,
            "fmeasure": 0.85439
        },
        "bleu": 77.47216,
        "meteor": 0.42607312093183014,
        "bertscore": {
            "precision": 0.97859,
            "recall": 0.91618,
            "f1": 0.94627
        },
        "nubia": {
            "semantic_relation": 4.14859,
            "contradiction": 2.90877,
            "irrelevancy": 15.91839,
            "logical_agreement": 81.17283,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.709,
            "nubia_score": 0.69951
        },
        "bleurt": 0.26654
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 76,
        "msttr-100": 0.72917,
        "msttr-100_nopunct": 0.789,
        "total_length": 1212,
        "mean_pred_length": 15.947368421052632,
        "std_pred_length": 5.42871201367542,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.5181518151815182,
        "vocab_size-1": 628,
        "unique-1": 521,
        "entropy-1": 8.042971573843415,
        "distinct-2": 0.8811619718309859,
        "vocab_size-2": 1001,
        "unique-2": 930,
        "entropy-2": 9.825496190055675,
        "cond_entropy-2": 1.554141931892277,
        "distinct-3": 0.9754716981132076,
        "vocab_size-3": 1034,
        "unique-3": 1014,
        "entropy-3": 9.99416972868769,
        "cond_entropy-3": 0.16290767366600206,
        "total_length-nopunct": 1033,
        "mean_pred_length-nopunct": 13.592105263157896,
        "std_pred_length-nopunct": 4.600279258053533,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6001936108422071,
        "vocab_size-1-nopunct": 620,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 8.355690455783092,
        "distinct-2-nopunct": 0.9038662486938349,
        "vocab_size-2-nopunct": 865,
        "unique-2-nopunct": 817,
        "entropy-2-nopunct": 9.63548550227651,
        "cond_entropy-2-nopunct": 1.3749031673061758,
        "distinct-3-nopunct": 0.9886492622020431,
        "vocab_size-3-nopunct": 871,
        "unique-3-nopunct": 863,
        "entropy-3-nopunct": 9.758583027303853,
        "cond_entropy-3-nopunct": 0.13864650122162503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18729096989966554,
            "2": 0.491869918699187,
            "3": 0.7354570637119113
        },
        "nist": 6.979413376138295,
        "rouge1": {
            "precision": 0.72528,
            "recall": 0.69362,
            "fmeasure": 0.69283
        },
        "rouge2": {
            "precision": 0.48135,
            "recall": 0.45372,
            "fmeasure": 0.45465
        },
        "rougeL": {
            "precision": 0.62944,
            "recall": 0.6117,
            "fmeasure": 0.60426
        },
        "rougeLsum": {
            "precision": 0.62944,
            "recall": 0.6117,
            "fmeasure": 0.60426
        },
        "bleu": 42.11829,
        "meteor": 0.37641428368786584,
        "bertscore": {
            "precision": 0.9216,
            "recall": 0.91929,
            "f1": 0.91826
        },
        "nubia": {
            "semantic_relation": 4.0743,
            "contradiction": 7.50869,
            "irrelevancy": 33.20614,
            "logical_agreement": 59.28517,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.63347,
            "nubia_score": 0.69078
        },
        "bleurt": 0.20442
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 453,
        "msttr-100": 0.5398,
        "msttr-100_nopunct": 0.55841,
        "total_length": 5031,
        "mean_pred_length": 11.105960264900663,
        "std_pred_length": 4.121476060435559,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.17869210892466705,
        "vocab_size-1": 899,
        "unique-1": 450,
        "entropy-1": 7.601056171496936,
        "distinct-2": 0.4676714722586282,
        "vocab_size-2": 2141,
        "unique-2": 1430,
        "entropy-2": 10.34511044272682,
        "cond_entropy-2": 2.343312203816889,
        "distinct-3": 0.6615757575757576,
        "vocab_size-3": 2729,
        "unique-3": 2138,
        "entropy-3": 11.031910278182835,
        "cond_entropy-3": 0.7843212086975615,
        "total_length-nopunct": 4410,
        "mean_pred_length-nopunct": 9.735099337748345,
        "std_pred_length-nopunct": 3.7751984643033203,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.20204081632653062,
        "vocab_size-1-nopunct": 891,
        "unique-1-nopunct": 448,
        "entropy-1-nopunct": 7.873104265547916,
        "distinct-2-nopunct": 0.45211018448319434,
        "vocab_size-2-nopunct": 1789,
        "unique-2-nopunct": 1189,
        "entropy-2-nopunct": 10.046845862899444,
        "cond_entropy-2-nopunct": 2.4575394249394114,
        "distinct-3-nopunct": 0.6481164383561644,
        "vocab_size-3-nopunct": 2271,
        "unique-3-nopunct": 1761,
        "entropy-3-nopunct": 10.748029323652501,
        "cond_entropy-3-nopunct": 0.8259492976985835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2246153846153846,
            "2": 0.6517632241813602,
            "3": 0.8904481665912177,
            "4": 1.0
        },
        "nist": 9.307608888314412,
        "rouge1": {
            "precision": 0.82454,
            "recall": 0.79305,
            "fmeasure": 0.80138
        },
        "rouge2": {
            "precision": 0.60163,
            "recall": 0.57839,
            "fmeasure": 0.584
        },
        "rougeL": {
            "precision": 0.73396,
            "recall": 0.70297,
            "fmeasure": 0.7115
        },
        "rougeLsum": {
            "precision": 0.73396,
            "recall": 0.70297,
            "fmeasure": 0.7115
        },
        "bleu": 59.45727,
        "meteor": 0.4572404647649217,
        "bertscore": {
            "precision": 0.94825,
            "recall": 0.94535,
            "f1": 0.94576
        },
        "nubia": {
            "semantic_relation": 4.60215,
            "contradiction": 6.75971,
            "irrelevancy": 6.42726,
            "logical_agreement": 86.81303,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.25659,
            "nubia_score": 0.82706
        },
        "bleurt": 0.37437
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.64,
        "msttr-100_nopunct": NaN,
        "total_length": 119,
        "mean_pred_length": 19.833333333333332,
        "std_pred_length": 7.776388764858804,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.6554621848739496,
        "vocab_size-1": 78,
        "unique-1": 62,
        "entropy-1": 5.9247174742640425,
        "distinct-2": 0.9292035398230089,
        "vocab_size-2": 105,
        "unique-2": 99,
        "entropy-2": 6.665225201314967,
        "cond_entropy-2": 0.7098253319598783,
        "distinct-3": 0.9813084112149533,
        "vocab_size-3": 105,
        "unique-3": 103,
        "entropy-3": 6.704083808831045,
        "cond_entropy-3": 0.04754760346565028,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 5.497474167490214,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7346938775510204,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.873168676124836,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.428400135381336,
        "cond_entropy-2-nopunct": 0.5927232745602145,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 86,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.426264754702099,
        "cond_entropy-3-nopunct": -0.00712409086464218,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.4166666666666667,
            "3": 0.8395061728395061
        },
        "nist": 5.3871165604188525,
        "rouge1": {
            "precision": 0.83174,
            "recall": 0.78677,
            "fmeasure": 0.79556
        },
        "rouge2": {
            "precision": 0.65181,
            "recall": 0.61608,
            "fmeasure": 0.62106
        },
        "rougeL": {
            "precision": 0.77234,
            "recall": 0.73303,
            "fmeasure": 0.73835
        },
        "rougeLsum": {
            "precision": 0.77234,
            "recall": 0.73303,
            "fmeasure": 0.73835
        },
        "bleu": 47.60503,
        "meteor": 0.41673829643817467,
        "bertscore": {
            "precision": 0.95176,
            "recall": 0.94417,
            "f1": 0.94728
        },
        "nubia": {
            "semantic_relation": 4.49119,
            "contradiction": 2.76267,
            "irrelevancy": 24.01718,
            "logical_agreement": 73.22015,
            "grammar_ref": 5.04309,
            "grammar_hyp": 4.889,
            "nubia_score": 0.79659
        },
        "bleurt": 0.38711
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.71,
        "total_length": 126,
        "mean_pred_length": 11.454545454545455,
        "std_pred_length": 2.3105936412979697,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.6825396825396826,
        "vocab_size-1": 86,
        "unique-1": 67,
        "entropy-1": 6.098051322244281,
        "distinct-2": 0.8956521739130435,
        "vocab_size-2": 103,
        "unique-2": 92,
        "entropy-2": 6.630230159621229,
        "cond_entropy-2": 0.28537680962739004,
        "distinct-3": 0.9423076923076923,
        "vocab_size-3": 98,
        "unique-3": 92,
        "entropy-3": 6.585055102756484,
        "cond_entropy-3": -0.041637952974788284,
        "total_length-nopunct": 112,
        "mean_pred_length-nopunct": 10.181818181818182,
        "std_pred_length-nopunct": 2.16661368869327,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7321428571428571,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 6.157988351046878,
        "distinct-2-nopunct": 0.8910891089108911,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.432915566888775,
        "cond_entropy-2-nopunct": 0.30025463941018987,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.35851976299633,
        "cond_entropy-3-nopunct": -0.05797074750919256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.1724137931034483,
            "3": 0.6666666666666666
        },
        "nist": 4.615050363048315,
        "rouge1": {
            "precision": 0.71203,
            "recall": 0.63896,
            "fmeasure": 0.66317
        },
        "rouge2": {
            "precision": 0.45539,
            "recall": 0.40623,
            "fmeasure": 0.42168
        },
        "rougeL": {
            "precision": 0.6441,
            "recall": 0.59413,
            "fmeasure": 0.60831
        },
        "rougeLsum": {
            "precision": 0.6441,
            "recall": 0.59413,
            "fmeasure": 0.60831
        },
        "bleu": 33.86006,
        "meteor": 0.35193108563385755,
        "bertscore": {
            "precision": 0.91898,
            "recall": 0.89783,
            "f1": 0.90737
        },
        "nubia": {
            "semantic_relation": 4.19606,
            "contradiction": 1.78061,
            "irrelevancy": 60.10739,
            "logical_agreement": 38.112,
            "grammar_ref": 5.00152,
            "grammar_hyp": 5.246,
            "nubia_score": 0.67235
        },
        "bleurt": 0.27619
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.73,
        "total_length": 265,
        "mean_pred_length": 15.588235294117647,
        "std_pred_length": 5.499292184715409,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.5924528301886792,
        "vocab_size-1": 157,
        "unique-1": 127,
        "entropy-1": 6.642106074907536,
        "distinct-2": 0.9274193548387096,
        "vocab_size-2": 230,
        "unique-2": 217,
        "entropy-2": 7.778182260167529,
        "cond_entropy-2": 0.9745101452084513,
        "distinct-3": 0.9826839826839827,
        "vocab_size-3": 227,
        "unique-3": 223,
        "entropy-3": 7.817117006783992,
        "cond_entropy-3": 0.03457214425170694,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 13.764705882352942,
        "std_pred_length-nopunct": 5.000346008789037,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6495726495726496,
        "vocab_size-1-nopunct": 152,
        "unique-1-nopunct": 124,
        "entropy-1-nopunct": 6.733474951441343,
        "distinct-2-nopunct": 0.9354838709677419,
        "vocab_size-2-nopunct": 203,
        "unique-2-nopunct": 194,
        "entropy-2-nopunct": 7.597258677355077,
        "cond_entropy-2-nopunct": 0.9032871293987415,
        "distinct-3-nopunct": 0.99,
        "vocab_size-3-nopunct": 198,
        "unique-3-nopunct": 196,
        "entropy-3-nopunct": 7.623856189774741,
        "cond_entropy-3-nopunct": 0.030562379602261422,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18055555555555555,
            "2": 0.4262295081967213,
            "3": 0.7142857142857143
        },
        "nist": 5.499721030688923,
        "rouge1": {
            "precision": 0.67029,
            "recall": 0.6858,
            "fmeasure": 0.67294
        },
        "rouge2": {
            "precision": 0.43558,
            "recall": 0.4387,
            "fmeasure": 0.43298
        },
        "rougeL": {
            "precision": 0.59226,
            "recall": 0.60153,
            "fmeasure": 0.59214
        },
        "rougeLsum": {
            "precision": 0.59226,
            "recall": 0.60153,
            "fmeasure": 0.59214
        },
        "bleu": 40.35237,
        "meteor": 0.36922099952084264,
        "bertscore": {
            "precision": 0.90927,
            "recall": 0.90981,
            "f1": 0.90833
        },
        "nubia": {
            "semantic_relation": 4.00929,
            "contradiction": 9.73942,
            "irrelevancy": 39.98948,
            "logical_agreement": 50.2711,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.47011,
            "nubia_score": 0.71084
        },
        "bleurt": 0.11172
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.768,
        "msttr-100_nopunct": 0.805,
        "total_length": 532,
        "mean_pred_length": 17.161290322580644,
        "std_pred_length": 5.640274382444633,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5639097744360902,
        "vocab_size-1": 300,
        "unique-1": 228,
        "entropy-1": 7.484882493867001,
        "distinct-2": 0.9021956087824351,
        "vocab_size-2": 452,
        "unique-2": 414,
        "entropy-2": 8.747766524805794,
        "cond_entropy-2": 1.1144614473763372,
        "distinct-3": 0.9531914893617022,
        "vocab_size-3": 448,
        "unique-3": 427,
        "entropy-3": 8.781293781666792,
        "cond_entropy-3": 0.04171429583977789,
        "total_length-nopunct": 471,
        "mean_pred_length-nopunct": 15.193548387096774,
        "std_pred_length-nopunct": 5.176992244467012,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6284501061571125,
        "vocab_size-1-nopunct": 296,
        "unique-1-nopunct": 228,
        "entropy-1-nopunct": 7.652526432686431,
        "distinct-2-nopunct": 0.9045454545454545,
        "vocab_size-2-nopunct": 398,
        "unique-2-nopunct": 367,
        "entropy-2-nopunct": 8.561652817017746,
        "cond_entropy-2-nopunct": 0.9711351884735107,
        "distinct-3-nopunct": 0.9535452322738386,
        "vocab_size-3-nopunct": 390,
        "unique-3-nopunct": 372,
        "entropy-3-nopunct": 8.581201806775132,
        "cond_entropy-3-nopunct": 0.031311615164995296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23423423423423423,
            "2": 0.40963855421686746,
            "3": 0.7173333333333334
        },
        "nist": 6.383406219353151,
        "rouge1": {
            "precision": 0.75981,
            "recall": 0.7011,
            "fmeasure": 0.7167
        },
        "rouge2": {
            "precision": 0.53381,
            "recall": 0.48403,
            "fmeasure": 0.50021
        },
        "rougeL": {
            "precision": 0.67677,
            "recall": 0.62276,
            "fmeasure": 0.63879
        },
        "rougeLsum": {
            "precision": 0.67677,
            "recall": 0.62276,
            "fmeasure": 0.63879
        },
        "bleu": 44.48781,
        "meteor": 0.3762807077444566,
        "bertscore": {
            "precision": 0.9292,
            "recall": 0.9191,
            "f1": 0.92259
        },
        "nubia": {
            "semantic_relation": 4.27254,
            "contradiction": 8.97464,
            "irrelevancy": 26.52542,
            "logical_agreement": 64.49994,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.81025,
            "nubia_score": 0.753
        },
        "bleurt": 0.28887
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.10341647163363245,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.11768784439846627,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 2.396298558607621,
        "rouge1": {
            "precision": 0.53623,
            "recall": 0.80357,
            "fmeasure": 0.64264
        },
        "rouge2": {
            "precision": 0.30303,
            "recall": 0.42876,
            "fmeasure": 0.35482
        },
        "rougeL": {
            "precision": 0.46377,
            "recall": 0.64352,
            "fmeasure": 0.53867
        },
        "rougeLsum": {
            "precision": 0.46377,
            "recall": 0.64352,
            "fmeasure": 0.53867
        },
        "bleu": 16.91896,
        "meteor": 0.35207112083476777,
        "bertscore": {
            "precision": 0.83145,
            "recall": 0.92303,
            "f1": 0.87485
        },
        "nubia": {
            "semantic_relation": 3.28392,
            "contradiction": 0.25139,
            "irrelevancy": 99.64478,
            "logical_agreement": 0.10383,
            "grammar_ref": 3.66146,
            "grammar_hyp": 2.92133,
            "nubia_score": 0.65407
        },
        "bleurt": -0.0088
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.82,
        "total_length": 544,
        "mean_pred_length": 17.548387096774192,
        "std_pred_length": 5.3330298214019525,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.6084558823529411,
        "vocab_size-1": 331,
        "unique-1": 279,
        "entropy-1": 7.627594656472948,
        "distinct-2": 0.9142300194931774,
        "vocab_size-2": 469,
        "unique-2": 442,
        "entropy-2": 8.799815082882995,
        "cond_entropy-2": 1.0322056497852334,
        "distinct-3": 0.975103734439834,
        "vocab_size-3": 470,
        "unique-3": 461,
        "entropy-3": 8.857381270872722,
        "cond_entropy-3": 0.062323445073641605,
        "total_length-nopunct": 469,
        "mean_pred_length-nopunct": 15.129032258064516,
        "std_pred_length-nopunct": 4.688640600043766,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6865671641791045,
        "vocab_size-1-nopunct": 322,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 7.814254860909098,
        "distinct-2-nopunct": 0.9292237442922374,
        "vocab_size-2-nopunct": 407,
        "unique-2-nopunct": 388,
        "entropy-2-nopunct": 8.607243502557225,
        "cond_entropy-2-nopunct": 0.8552030350250243,
        "distinct-3-nopunct": 0.9877149877149877,
        "vocab_size-3-nopunct": 402,
        "unique-3-nopunct": 397,
        "entropy-3-nopunct": 8.644314959696214,
        "cond_entropy-3-nopunct": 0.04491875509567308,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23008849557522124,
            "2": 0.46938775510204084,
            "3": 0.8071625344352618
        },
        "nist": 7.255986215715752,
        "rouge1": {
            "precision": 0.79899,
            "recall": 0.78129,
            "fmeasure": 0.77702
        },
        "rouge2": {
            "precision": 0.62914,
            "recall": 0.61753,
            "fmeasure": 0.61235
        },
        "rougeL": {
            "precision": 0.70501,
            "recall": 0.69812,
            "fmeasure": 0.69022
        },
        "rougeLsum": {
            "precision": 0.70501,
            "recall": 0.69812,
            "fmeasure": 0.69022
        },
        "bleu": 57.41339,
        "meteor": 0.44929930276637803,
        "bertscore": {
            "precision": 0.94429,
            "recall": 0.93857,
            "f1": 0.94043
        },
        "nubia": {
            "semantic_relation": 4.19541,
            "contradiction": 15.29618,
            "irrelevancy": 20.28132,
            "logical_agreement": 64.4225,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.80185,
            "nubia_score": 0.70718
        },
        "bleurt": 0.36262
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.805,
        "total_length": 301,
        "mean_pred_length": 17.705882352941178,
        "std_pred_length": 6.25689930615282,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.6146179401993356,
        "vocab_size-1": 185,
        "unique-1": 152,
        "entropy-1": 6.922013525133032,
        "distinct-2": 0.897887323943662,
        "vocab_size-2": 255,
        "unique-2": 235,
        "entropy-2": 7.915137293860019,
        "cond_entropy-2": 0.8652855491618946,
        "distinct-3": 0.9550561797752809,
        "vocab_size-3": 255,
        "unique-3": 245,
        "entropy-3": 7.965153703206894,
        "cond_entropy-3": 0.06495411360146269,
        "total_length-nopunct": 253,
        "mean_pred_length-nopunct": 14.882352941176471,
        "std_pred_length-nopunct": 4.309802137415106,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7114624505928854,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 7.096866726055973,
        "distinct-2-nopunct": 0.9279661016949152,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 206,
        "entropy-2-nopunct": 7.723703324767209,
        "cond_entropy-2-nopunct": 0.6906677700114562,
        "distinct-3-nopunct": 0.9726027397260274,
        "vocab_size-3-nopunct": 213,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.719992539053238,
        "cond_entropy-3-nopunct": 0.008627001126669854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1702127659574468,
            "2": 0.34210526315789475,
            "3": 0.8110599078341014
        },
        "nist": 6.8723912534685665,
        "rouge1": {
            "precision": 0.80131,
            "recall": 0.76865,
            "fmeasure": 0.77326
        },
        "rouge2": {
            "precision": 0.59914,
            "recall": 0.59319,
            "fmeasure": 0.5879
        },
        "rougeL": {
            "precision": 0.6662,
            "recall": 0.65475,
            "fmeasure": 0.65166
        },
        "rougeLsum": {
            "precision": 0.6662,
            "recall": 0.65475,
            "fmeasure": 0.65166
        },
        "bleu": 61.10418,
        "meteor": 0.4500568229129765,
        "bertscore": {
            "precision": 0.94443,
            "recall": 0.94162,
            "f1": 0.94135
        },
        "nubia": {
            "semantic_relation": 4.34702,
            "contradiction": 8.0327,
            "irrelevancy": 25.48231,
            "logical_agreement": 66.48499,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.46447,
            "nubia_score": 0.78336
        },
        "bleurt": 0.4118
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 0.7047785513541205,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.625,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.21429,
            "fmeasure": 0.28283
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.4213,
            "fmeasure": 0.5348
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.4213,
            "fmeasure": 0.5348
        },
        "bleu": 12.38076,
        "meteor": 0.23499115295166703,
        "bertscore": {
            "precision": 0.899,
            "recall": 0.88936,
            "f1": 0.89416
        },
        "nubia": {
            "semantic_relation": 4.72339,
            "contradiction": 0.52718,
            "irrelevancy": 0.66594,
            "logical_agreement": 98.80688,
            "grammar_ref": 4.0172,
            "grammar_hyp": 4.735,
            "nubia_score": 0.93648
        },
        "bleurt": 0.08634
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 57,
        "msttr-100": 0.70778,
        "msttr-100_nopunct": 0.74,
        "total_length": 940,
        "mean_pred_length": 16.49122807017544,
        "std_pred_length": 5.361077421882899,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5010638297872341,
        "vocab_size-1": 471,
        "unique-1": 375,
        "entropy-1": 7.713182474100722,
        "distinct-2": 0.855039637599094,
        "vocab_size-2": 755,
        "unique-2": 695,
        "entropy-2": 9.382092177750232,
        "cond_entropy-2": 1.4947186306810734,
        "distinct-3": 0.9443099273607748,
        "vocab_size-3": 780,
        "unique-3": 755,
        "entropy-3": 9.553490843692844,
        "cond_entropy-3": 0.180512878581708,
        "total_length-nopunct": 840,
        "mean_pred_length-nopunct": 14.736842105263158,
        "std_pred_length-nopunct": 5.048975285264288,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5523809523809524,
        "vocab_size-1-nopunct": 464,
        "unique-1-nopunct": 372,
        "entropy-1-nopunct": 7.8569899301980675,
        "distinct-2-nopunct": 0.8607918263090677,
        "vocab_size-2-nopunct": 674,
        "unique-2-nopunct": 622,
        "entropy-2-nopunct": 9.220014760707372,
        "cond_entropy-2-nopunct": 1.4650507418275283,
        "distinct-3-nopunct": 0.9504132231404959,
        "vocab_size-3-nopunct": 690,
        "unique-3-nopunct": 670,
        "entropy-3-nopunct": 9.3826136167836,
        "cond_entropy-3-nopunct": 0.17829122933420216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24423963133640553,
            "2": 0.5121951219512195,
            "3": 0.7893738140417458
        },
        "nist": 7.168946906771733,
        "rouge1": {
            "precision": 0.7508,
            "recall": 0.75801,
            "fmeasure": 0.74378
        },
        "rouge2": {
            "precision": 0.54643,
            "recall": 0.5551,
            "fmeasure": 0.54276
        },
        "rougeL": {
            "precision": 0.65294,
            "recall": 0.66125,
            "fmeasure": 0.64791
        },
        "rougeLsum": {
            "precision": 0.65294,
            "recall": 0.66125,
            "fmeasure": 0.64791
        },
        "bleu": 48.7229,
        "meteor": 0.404717075965117,
        "bertscore": {
            "precision": 0.92465,
            "recall": 0.92711,
            "f1": 0.92418
        },
        "nubia": {
            "semantic_relation": 4.14928,
            "contradiction": 8.44924,
            "irrelevancy": 40.28177,
            "logical_agreement": 51.26899,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.58227,
            "nubia_score": 0.73368
        },
        "bleurt": 0.21844
    },
    "web_nlg_en_test": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 1779,
        "msttr-100": 0.66494,
        "msttr-100_nopunct": 0.6898,
        "total_length": 33861,
        "mean_pred_length": 19.033726812816187,
        "std_pred_length": 6.383824784726317,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.05770650600986386,
        "vocab_size-1": 1954,
        "unique-1": 619,
        "entropy-1": 8.143780704333079,
        "distinct-2": 0.209650271180101,
        "vocab_size-2": 6726,
        "unique-2": 3201,
        "entropy-2": 11.294080683791067,
        "cond_entropy-2": 3.0903846264551236,
        "distinct-3": 0.3798963798963799,
        "vocab_size-3": 11512,
        "unique-3": 7035,
        "entropy-3": 12.547823146461608,
        "cond_entropy-3": 1.3597778965360818,
        "total_length-nopunct": 30689,
        "mean_pred_length-nopunct": 17.25070264193367,
        "std_pred_length-nopunct": 6.098414662434479,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06337775750268826,
        "vocab_size-1-nopunct": 1945,
        "unique-1-nopunct": 618,
        "entropy-1-nopunct": 8.330549433158682,
        "distinct-2-nopunct": 0.21961259079903148,
        "vocab_size-2-nopunct": 6349,
        "unique-2-nopunct": 3183,
        "entropy-2-nopunct": 11.190789781731333,
        "cond_entropy-2-nopunct": 3.044735532162126,
        "distinct-3-nopunct": 0.3905495558586119,
        "vocab_size-3-nopunct": 10596,
        "unique-3-nopunct": 6652,
        "entropy-3-nopunct": 12.414818749254595,
        "cond_entropy-3-nopunct": 1.3295377939228812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18612657065809857,
            "2": 0.5018937554627562,
            "3": 0.7475384615384615,
            "4": 0.8909090909090909,
            "5": 0.41379310344827586
        },
        "nist": 6.94165259293331,
        "rouge1": {
            "precision": 0.77974,
            "recall": 0.68158,
            "fmeasure": 0.71419
        },
        "rouge2": {
            "precision": 0.51924,
            "recall": 0.45179,
            "fmeasure": 0.47325
        },
        "rougeL": {
            "precision": 0.64024,
            "recall": 0.56009,
            "fmeasure": 0.58622
        },
        "rougeLsum": {
            "precision": 0.64024,
            "recall": 0.56009,
            "fmeasure": 0.58622
        },
        "bleu": 39.43611,
        "meteor": 0.32818955132279365,
        "bertscore": {
            "precision": 0.92191,
            "recall": 0.90189,
            "f1": 0.91025
        },
        "nubia": {
            "semantic_relation": 4.14037,
            "contradiction": 8.70361,
            "irrelevancy": 10.31174,
            "logical_agreement": 80.98465,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.79485,
            "nubia_score": 0.6767
        },
        "bleurt": 0.06362
    },
    "web_nlg_en_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_challenge_train_sample",
        "N": 502
    },
    "web_nlg_en_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_challenge_validation_sample",
        "N": 499
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0,
            "3": 0.875
        },
        "nist": 3.1022169742211996,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "rouge2": {
            "precision": 0.57576,
            "recall": 0.7037,
            "fmeasure": 0.63333
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.86667,
            "fmeasure": 0.78788
        },
        "bleu": 54.91005,
        "meteor": 0.4780944755307461,
        "bertscore": {
            "precision": 0.9496,
            "recall": 0.97451,
            "f1": 0.96189
        },
        "nubia": {
            "semantic_relation": 3.92688,
            "contradiction": 0.30821,
            "irrelevancy": 98.27195,
            "logical_agreement": 1.41984,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.61832,
            "nubia_score": 0.6446
        },
        "bleurt": 0.65042
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 32,
        "msttr-100": 0.696,
        "msttr-100_nopunct": 0.74,
        "total_length": 588,
        "mean_pred_length": 18.375,
        "std_pred_length": 4.948168853222372,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5085034013605442,
        "vocab_size-1": 299,
        "unique-1": 225,
        "entropy-1": 7.31165775851755,
        "distinct-2": 0.8183453237410072,
        "vocab_size-2": 455,
        "unique-2": 392,
        "entropy-2": 8.659757483133736,
        "cond_entropy-2": 1.224061063112244,
        "distinct-3": 0.898854961832061,
        "vocab_size-3": 471,
        "unique-3": 424,
        "entropy-3": 8.821553631291955,
        "cond_entropy-3": 0.165028733781916,
        "total_length-nopunct": 521,
        "mean_pred_length-nopunct": 16.28125,
        "std_pred_length-nopunct": 4.317365914246787,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.564299424184261,
        "vocab_size-1-nopunct": 294,
        "unique-1-nopunct": 225,
        "entropy-1-nopunct": 7.440850726985611,
        "distinct-2-nopunct": 0.8241308793456033,
        "vocab_size-2-nopunct": 403,
        "unique-2-nopunct": 353,
        "entropy-2-nopunct": 8.477032013210163,
        "cond_entropy-2-nopunct": 1.0962168541723343,
        "distinct-3-nopunct": 0.9080962800875274,
        "vocab_size-3-nopunct": 415,
        "unique-3-nopunct": 377,
        "entropy-3-nopunct": 8.645635584798466,
        "cond_entropy-3-nopunct": 0.16994509573650943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22448979591836735,
            "2": 0.3253012048192771,
            "3": 0.7678571428571429
        },
        "nist": 6.329525942576621,
        "rouge1": {
            "precision": 0.73868,
            "recall": 0.71399,
            "fmeasure": 0.71268
        },
        "rouge2": {
            "precision": 0.53943,
            "recall": 0.52723,
            "fmeasure": 0.52024
        },
        "rougeL": {
            "precision": 0.6252,
            "recall": 0.61667,
            "fmeasure": 0.6089
        },
        "rougeLsum": {
            "precision": 0.6252,
            "recall": 0.61667,
            "fmeasure": 0.6089
        },
        "bleu": 44.09264,
        "meteor": 0.3695362970693153,
        "bertscore": {
            "precision": 0.92103,
            "recall": 0.91759,
            "f1": 0.91791
        },
        "nubia": {
            "semantic_relation": 4.13432,
            "contradiction": 9.82101,
            "irrelevancy": 34.54749,
            "logical_agreement": 55.63151,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.26876,
            "nubia_score": 0.71701
        },
        "bleurt": 0.19812
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 7.5,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.9393939393939394,
        "vocab_size-1": 31,
        "unique-1": 29,
        "entropy-1": 4.923181998146335,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": -0.025681679939320107,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9655172413793104,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.789015477886192,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": -0.06605645592706638,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5454545454545454,
            "3": 0.34615384615384615
        },
        "nist": 1.5373970392951608,
        "rouge1": {
            "precision": 0.61667,
            "recall": 0.44228,
            "fmeasure": 0.5141
        },
        "rouge2": {
            "precision": 0.31955,
            "recall": 0.225,
            "fmeasure": 0.26362
        },
        "rougeL": {
            "precision": 0.5125,
            "recall": 0.36767,
            "fmeasure": 0.42733
        },
        "rougeLsum": {
            "precision": 0.5125,
            "recall": 0.36767,
            "fmeasure": 0.42733
        },
        "bleu": 9.65139,
        "meteor": 0.2312509071269487,
        "bertscore": {
            "precision": 0.87136,
            "recall": 0.83184,
            "f1": 0.84951
        },
        "nubia": {
            "semantic_relation": 3.9464,
            "contradiction": 47.83947,
            "irrelevancy": 3.0432,
            "logical_agreement": 49.11733,
            "grammar_ref": 4.83168,
            "grammar_hyp": 5.74552,
            "nubia_score": 0.46991
        },
        "bleurt": -0.045
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79,
        "total_length": 284,
        "mean_pred_length": 14.2,
        "std_pred_length": 3.2341923257592455,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6373239436619719,
        "vocab_size-1": 181,
        "unique-1": 151,
        "entropy-1": 6.854427252408977,
        "distinct-2": 0.9507575757575758,
        "vocab_size-2": 251,
        "unique-2": 242,
        "entropy-2": 7.929376967931946,
        "cond_entropy-2": 0.8456612134175483,
        "distinct-3": 0.9836065573770492,
        "vocab_size-3": 240,
        "unique-3": 236,
        "entropy-3": 7.897950452316944,
        "cond_entropy-3": -0.02199888025212359,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 12.45,
        "std_pred_length-nopunct": 3.278337993557101,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7068273092369478,
        "vocab_size-1-nopunct": 176,
        "unique-1-nopunct": 149,
        "entropy-1-nopunct": 6.982258510757234,
        "distinct-2-nopunct": 0.9563318777292577,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 213,
        "entropy-2-nopunct": 7.732808469421839,
        "cond_entropy-2-nopunct": 0.8272087727528864,
        "distinct-3-nopunct": 0.9952153110047847,
        "vocab_size-3-nopunct": 208,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.69778975409047,
        "cond_entropy-3-nopunct": -0.029622034118452344,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.4426229508196721,
            "3": 0.6910994764397905
        },
        "nist": 5.53439090520497,
        "rouge1": {
            "precision": 0.7321,
            "recall": 0.70877,
            "fmeasure": 0.70604
        },
        "rouge2": {
            "precision": 0.47768,
            "recall": 0.44776,
            "fmeasure": 0.45498
        },
        "rougeL": {
            "precision": 0.6209,
            "recall": 0.6114,
            "fmeasure": 0.60411
        },
        "rougeLsum": {
            "precision": 0.6209,
            "recall": 0.6114,
            "fmeasure": 0.60411
        },
        "bleu": 37.09643,
        "meteor": 0.3676868688214657,
        "bertscore": {
            "precision": 0.92284,
            "recall": 0.92334,
            "f1": 0.92183
        },
        "nubia": {
            "semantic_relation": 4.2203,
            "contradiction": 8.96124,
            "irrelevancy": 27.22997,
            "logical_agreement": 63.8088,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.73394,
            "nubia_score": 0.71137
        },
        "bleurt": 0.26479
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69477,
        "msttr-100_nopunct": 0.71544,
        "total_length": 6500,
        "mean_pred_length": 13.0,
        "std_pred_length": 6.867605113866114,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 29,
        "distinct-1": 0.15446153846153846,
        "vocab_size-1": 1004,
        "unique-1": 546,
        "entropy-1": 7.85982691057738,
        "distinct-2": 0.4771666666666667,
        "vocab_size-2": 2863,
        "unique-2": 1958,
        "entropy-2": 10.716956173995497,
        "cond_entropy-2": 2.6570511941223343,
        "distinct-3": 0.6956363636363636,
        "vocab_size-3": 3826,
        "unique-3": 3103,
        "entropy-3": 11.533053294496273,
        "cond_entropy-3": 0.8509716424675214,
        "total_length-nopunct": 5760,
        "mean_pred_length-nopunct": 11.52,
        "std_pred_length-nopunct": 6.378840019940929,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.171875,
        "vocab_size-1-nopunct": 990,
        "unique-1-nopunct": 542,
        "entropy-1-nopunct": 8.015267677211721,
        "distinct-2-nopunct": 0.4923954372623574,
        "vocab_size-2-nopunct": 2590,
        "unique-2-nopunct": 1813,
        "entropy-2-nopunct": 10.567060292473956,
        "cond_entropy-2-nopunct": 2.6920475060586577,
        "distinct-3-nopunct": 0.709724847721067,
        "vocab_size-3-nopunct": 3379,
        "unique-3-nopunct": 2788,
        "entropy-3-nopunct": 11.353588801794293,
        "cond_entropy-3-nopunct": 0.8339602614293414,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5569112776712567
        },
        "nist": 6.00312162869268,
        "rouge1": {
            "precision": 0.5682,
            "recall": 0.54592,
            "fmeasure": 0.54584
        },
        "rouge2": {
            "precision": 0.3577,
            "recall": 0.34007,
            "fmeasure": 0.34098
        },
        "rougeL": {
            "precision": 0.50932,
            "recall": 0.48758,
            "fmeasure": 0.48858
        },
        "rougeLsum": {
            "precision": 0.50932,
            "recall": 0.48758,
            "fmeasure": 0.48858
        },
        "bleu": 30.6932,
        "meteor": 0.3076248493841993,
        "bertscore": {
            "precision": 0.86996,
            "recall": 0.86253,
            "f1": 0.86573
        },
        "nubia": {
            "semantic_relation": 3.6232,
            "contradiction": 5.99878,
            "irrelevancy": 22.34349,
            "logical_agreement": 71.65773,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.64671,
            "nubia_score": 0.64019
        },
        "bleurt": -0.09829
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.736,
        "msttr-100_nopunct": 0.772,
        "total_length": 587,
        "mean_pred_length": 18.93548387096774,
        "std_pred_length": 6.132596586675268,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5502555366269165,
        "vocab_size-1": 323,
        "unique-1": 254,
        "entropy-1": 7.529753515446418,
        "distinct-2": 0.8741007194244604,
        "vocab_size-2": 486,
        "unique-2": 440,
        "entropy-2": 8.816462537642998,
        "cond_entropy-2": 1.178169918761918,
        "distinct-3": 0.9485714285714286,
        "vocab_size-3": 498,
        "unique-3": 475,
        "entropy-3": 8.927564945870305,
        "cond_entropy-3": 0.11800135505646932,
        "total_length-nopunct": 510,
        "mean_pred_length-nopunct": 16.451612903225808,
        "std_pred_length-nopunct": 5.488043953067545,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6215686274509804,
        "vocab_size-1-nopunct": 317,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.702146098839115,
        "distinct-2-nopunct": 0.8810020876826722,
        "vocab_size-2-nopunct": 422,
        "unique-2-nopunct": 386,
        "entropy-2-nopunct": 8.611787058683491,
        "cond_entropy-2-nopunct": 0.97708050050496,
        "distinct-3-nopunct": 0.9598214285714286,
        "vocab_size-3-nopunct": 430,
        "unique-3-nopunct": 415,
        "entropy-3-nopunct": 8.721942728962738,
        "cond_entropy-3-nopunct": 0.1236711577762111,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3644859813084112,
            "2": 0.4050632911392405,
            "3": 0.7389277389277389
        },
        "nist": 6.928513500566998,
        "rouge1": {
            "precision": 0.79907,
            "recall": 0.73184,
            "fmeasure": 0.75589
        },
        "rouge2": {
            "precision": 0.55608,
            "recall": 0.52305,
            "fmeasure": 0.53322
        },
        "rougeL": {
            "precision": 0.69905,
            "recall": 0.63821,
            "fmeasure": 0.65818
        },
        "rougeLsum": {
            "precision": 0.69905,
            "recall": 0.63821,
            "fmeasure": 0.65818
        },
        "bleu": 47.80464,
        "meteor": 0.39781609083247743,
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.92587,
            "f1": 0.93124
        },
        "nubia": {
            "semantic_relation": 4.16576,
            "contradiction": 7.41576,
            "irrelevancy": 23.83841,
            "logical_agreement": 68.74583,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.67931,
            "nubia_score": 0.71017
        },
        "bleurt": 0.2191
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "total_length": 463,
        "mean_pred_length": 15.96551724137931,
        "std_pred_length": 5.756452203731103,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5701943844492441,
        "vocab_size-1": 264,
        "unique-1": 207,
        "entropy-1": 7.285415042934328,
        "distinct-2": 0.923963133640553,
        "vocab_size-2": 401,
        "unique-2": 376,
        "entropy-2": 8.585499684157408,
        "cond_entropy-2": 1.1266222043727483,
        "distinct-3": 0.9753086419753086,
        "vocab_size-3": 395,
        "unique-3": 385,
        "entropy-3": 8.612395381722562,
        "cond_entropy-3": 0.03456358620791929,
        "total_length-nopunct": 405,
        "mean_pred_length-nopunct": 13.96551724137931,
        "std_pred_length-nopunct": 5.242286672822039,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6370370370370371,
        "vocab_size-1-nopunct": 258,
        "unique-1-nopunct": 206,
        "entropy-1-nopunct": 7.4409065021756495,
        "distinct-2-nopunct": 0.9202127659574468,
        "vocab_size-2-nopunct": 346,
        "unique-2-nopunct": 324,
        "entropy-2-nopunct": 8.367337862431402,
        "cond_entropy-2-nopunct": 0.9958991103978583,
        "distinct-3-nopunct": 0.9769452449567724,
        "vocab_size-3-nopunct": 339,
        "unique-3-nopunct": 331,
        "entropy-3-nopunct": 8.39268234249181,
        "cond_entropy-3-nopunct": 0.029466320660182115,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26153846153846155,
            "2": 0.40816326530612246,
            "3": 0.8208955223880597
        },
        "nist": 7.378962233962985,
        "rouge1": {
            "precision": 0.80792,
            "recall": 0.79628,
            "fmeasure": 0.7929
        },
        "rouge2": {
            "precision": 0.60498,
            "recall": 0.60932,
            "fmeasure": 0.59937
        },
        "rougeL": {
            "precision": 0.69632,
            "recall": 0.6945,
            "fmeasure": 0.68766
        },
        "rougeLsum": {
            "precision": 0.69632,
            "recall": 0.6945,
            "fmeasure": 0.68766
        },
        "bleu": 58.84774,
        "meteor": 0.45524725447237424,
        "bertscore": {
            "precision": 0.9489,
            "recall": 0.95158,
            "f1": 0.94808
        },
        "nubia": {
            "semantic_relation": 4.48464,
            "contradiction": 5.34627,
            "irrelevancy": 23.72284,
            "logical_agreement": 70.9309,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.55679,
            "nubia_score": 0.83051
        },
        "bleurt": 0.44678
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.68714,
        "msttr-100_nopunct": 0.73,
        "total_length": 706,
        "mean_pred_length": 16.41860465116279,
        "std_pred_length": 4.5506583124046385,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.5113314447592068,
        "vocab_size-1": 361,
        "unique-1": 287,
        "entropy-1": 7.3541080164910735,
        "distinct-2": 0.8853695324283559,
        "vocab_size-2": 587,
        "unique-2": 544,
        "entropy-2": 9.066369256389853,
        "cond_entropy-2": 1.5237426975614552,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 600,
        "unique-3": 583,
        "entropy-3": 9.207164909303032,
        "cond_entropy-3": 0.15560100704244417,
        "total_length-nopunct": 619,
        "mean_pred_length-nopunct": 14.395348837209303,
        "std_pred_length-nopunct": 4.4832480692468515,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5751211631663974,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 286,
        "entropy-1-nopunct": 7.542372229066608,
        "distinct-2-nopunct": 0.890625,
        "vocab_size-2-nopunct": 513,
        "unique-2-nopunct": 481,
        "entropy-2-nopunct": 8.86489558674805,
        "cond_entropy-2-nopunct": 1.4361539217723176,
        "distinct-3-nopunct": 0.9737335834896811,
        "vocab_size-3-nopunct": 519,
        "unique-3-nopunct": 507,
        "entropy-3-nopunct": 9.001706544522737,
        "cond_entropy-3-nopunct": 0.15766698935425322,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2868217054263566,
            "2": 0.5775862068965517,
            "3": 0.7838427947598253
        },
        "nist": 7.27229251494242,
        "rouge1": {
            "precision": 0.79438,
            "recall": 0.76529,
            "fmeasure": 0.76678
        },
        "rouge2": {
            "precision": 0.56995,
            "recall": 0.56109,
            "fmeasure": 0.55573
        },
        "rougeL": {
            "precision": 0.68108,
            "recall": 0.66104,
            "fmeasure": 0.66128
        },
        "rougeLsum": {
            "precision": 0.68108,
            "recall": 0.66104,
            "fmeasure": 0.66128
        },
        "bleu": 49.4711,
        "meteor": 0.41243259073849975,
        "bertscore": {
            "precision": 0.93965,
            "recall": 0.93385,
            "f1": 0.93552
        },
        "nubia": {
            "semantic_relation": 4.40001,
            "contradiction": 1.20958,
            "irrelevancy": 26.40736,
            "logical_agreement": 72.38305,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.57547,
            "nubia_score": 0.79162
        },
        "bleurt": 0.36074
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.665,
        "total_length": 329,
        "mean_pred_length": 18.27777777777778,
        "std_pred_length": 7.224999466017324,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5319148936170213,
        "vocab_size-1": 175,
        "unique-1": 134,
        "entropy-1": 6.6887282343199175,
        "distinct-2": 0.8553054662379421,
        "vocab_size-2": 266,
        "unique-2": 240,
        "entropy-2": 7.922571122489919,
        "cond_entropy-2": 1.142249707383337,
        "distinct-3": 0.9351535836177475,
        "vocab_size-3": 274,
        "unique-3": 258,
        "entropy-3": 8.05733479808615,
        "cond_entropy-3": 0.15676911470040755,
        "total_length-nopunct": 286,
        "mean_pred_length-nopunct": 15.88888888888889,
        "std_pred_length-nopunct": 6.226189211609734,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.583916083916084,
        "vocab_size-1-nopunct": 167,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.688225060296505,
        "distinct-2-nopunct": 0.8432835820895522,
        "vocab_size-2-nopunct": 226,
        "unique-2-nopunct": 202,
        "entropy-2-nopunct": 7.675622015405151,
        "cond_entropy-2-nopunct": 1.0787761826336104,
        "distinct-3-nopunct": 0.928,
        "vocab_size-3-nopunct": 232,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 7.812725634636137,
        "cond_entropy-3-nopunct": 0.15721725583473034,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.2647058823529412,
            "3": 0.7467248908296943
        },
        "nist": 6.142323391506138,
        "rouge1": {
            "precision": 0.75873,
            "recall": 0.72861,
            "fmeasure": 0.73122
        },
        "rouge2": {
            "precision": 0.56763,
            "recall": 0.53089,
            "fmeasure": 0.53883
        },
        "rougeL": {
            "precision": 0.73295,
            "recall": 0.69551,
            "fmeasure": 0.70247
        },
        "rougeLsum": {
            "precision": 0.73295,
            "recall": 0.69551,
            "fmeasure": 0.70247
        },
        "bleu": 51.08376,
        "meteor": 0.408938230868441,
        "bertscore": {
            "precision": 0.94063,
            "recall": 0.93126,
            "f1": 0.93529
        },
        "nubia": {
            "semantic_relation": 4.3162,
            "contradiction": 9.20756,
            "irrelevancy": 23.3043,
            "logical_agreement": 67.48813,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.38505,
            "nubia_score": 0.77112
        },
        "bleurt": 0.28387
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.69625,
        "msttr-100_nopunct": 0.75286,
        "total_length": 834,
        "mean_pred_length": 17.74468085106383,
        "std_pred_length": 5.628453871468642,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.5095923261390888,
        "vocab_size-1": 425,
        "unique-1": 331,
        "entropy-1": 7.60774282288184,
        "distinct-2": 0.8831003811944091,
        "vocab_size-2": 695,
        "unique-2": 627,
        "entropy-2": 9.340432388032974,
        "cond_entropy-2": 1.5578101142416587,
        "distinct-3": 0.9472972972972973,
        "vocab_size-3": 701,
        "unique-3": 663,
        "entropy-3": 9.42495593686489,
        "cond_entropy-3": 0.09046290296571921,
        "total_length-nopunct": 730,
        "mean_pred_length-nopunct": 15.53191489361702,
        "std_pred_length-nopunct": 5.378645973048905,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.5739726027397261,
        "vocab_size-1-nopunct": 419,
        "unique-1-nopunct": 330,
        "entropy-1-nopunct": 7.822322001755099,
        "distinct-2-nopunct": 0.8843338213762811,
        "vocab_size-2-nopunct": 604,
        "unique-2-nopunct": 547,
        "entropy-2-nopunct": 9.133629120723356,
        "cond_entropy-2-nopunct": 1.3877464113133307,
        "distinct-3-nopunct": 0.9512578616352201,
        "vocab_size-3-nopunct": 605,
        "unique-3-nopunct": 574,
        "entropy-3-nopunct": 9.21539867855465,
        "cond_entropy-3-nopunct": 0.0963281968812153,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2421875,
            "2": 0.40310077519379844,
            "3": 0.7945454545454546
        },
        "nist": 7.103440382033642,
        "rouge1": {
            "precision": 0.78053,
            "recall": 0.76114,
            "fmeasure": 0.75714
        },
        "rouge2": {
            "precision": 0.56051,
            "recall": 0.55146,
            "fmeasure": 0.54615
        },
        "rougeL": {
            "precision": 0.68507,
            "recall": 0.67879,
            "fmeasure": 0.67004
        },
        "rougeLsum": {
            "precision": 0.68507,
            "recall": 0.67879,
            "fmeasure": 0.67004
        },
        "bleu": 51.60501,
        "meteor": 0.4221972173298912,
        "bertscore": {
            "precision": 0.93194,
            "recall": 0.92916,
            "f1": 0.92939
        },
        "nubia": {
            "semantic_relation": 4.23221,
            "contradiction": 5.84309,
            "irrelevancy": 28.78532,
            "logical_agreement": 65.37159,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.3154,
            "nubia_score": 0.74367
        },
        "bleurt": 0.29148
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76,
        "total_length": 113,
        "mean_pred_length": 14.125,
        "std_pred_length": 2.368411915187052,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.6902654867256637,
        "vocab_size-1": 78,
        "unique-1": 63,
        "entropy-1": 5.978642821443511,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 100,
        "unique-2": 95,
        "entropy-2": 6.6190074224280195,
        "cond_entropy-2": 0.4759102117252286,
        "distinct-3": 0.979381443298969,
        "vocab_size-3": 95,
        "unique-3": 93,
        "entropy-3": 6.55867572878508,
        "cond_entropy-3": -0.052477005375901976,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.5495097567963922,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.049016755221095,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.4366054343178964,
        "cond_entropy-2-nopunct": 0.4284442821014624,
        "distinct-3-nopunct": 0.9761904761904762,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.344698375159712,
        "cond_entropy-3-nopunct": -0.09553024756396668,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.3,
            "3": 0.7857142857142857
        },
        "nist": 4.888748725747588,
        "rouge1": {
            "precision": 0.75827,
            "recall": 0.78318,
            "fmeasure": 0.75444
        },
        "rouge2": {
            "precision": 0.51517,
            "recall": 0.55794,
            "fmeasure": 0.52236
        },
        "rougeL": {
            "precision": 0.61932,
            "recall": 0.64682,
            "fmeasure": 0.61938
        },
        "rougeLsum": {
            "precision": 0.61932,
            "recall": 0.64682,
            "fmeasure": 0.61938
        },
        "bleu": 45.12126,
        "meteor": 0.42669118964245434,
        "bertscore": {
            "precision": 0.92681,
            "recall": 0.93445,
            "f1": 0.93015
        },
        "nubia": {
            "semantic_relation": 4.15296,
            "contradiction": 29.45133,
            "irrelevancy": 16.80614,
            "logical_agreement": 53.74253,
            "grammar_ref": 5.14697,
            "grammar_hyp": 4.99318,
            "nubia_score": 0.68966
        },
        "bleurt": 0.35299
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.73,
        "total_length": 140,
        "mean_pred_length": 15.555555555555555,
        "std_pred_length": 5.27280467453541,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.6714285714285714,
        "vocab_size-1": 94,
        "unique-1": 80,
        "entropy-1": 6.121905742109269,
        "distinct-2": 0.9541984732824428,
        "vocab_size-2": 125,
        "unique-2": 121,
        "entropy-2": 6.926552772529818,
        "cond_entropy-2": 0.6802729499776754,
        "distinct-3": 0.9918032786885246,
        "vocab_size-3": 121,
        "unique-3": 120,
        "entropy-3": 6.91434389493995,
        "cond_entropy-3": -0.0043250082368593125,
        "total_length-nopunct": 125,
        "mean_pred_length-nopunct": 13.88888888888889,
        "std_pred_length-nopunct": 5.526591162420395,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.129756336949949,
        "distinct-2-nopunct": 0.9482758620689655,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.737291339955144,
        "cond_entropy-2-nopunct": 0.6587357704939065,
        "distinct-3-nopunct": 0.9906542056074766,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 105,
        "entropy-3-nopunct": 6.722775397616091,
        "cond_entropy-3-nopunct": -0.004364476016144696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.4772727272727273,
            "3": 0.835820895522388
        },
        "nist": 5.142402191134008,
        "rouge1": {
            "precision": 0.72267,
            "recall": 0.71044,
            "fmeasure": 0.7115
        },
        "rouge2": {
            "precision": 0.47422,
            "recall": 0.47358,
            "fmeasure": 0.46854
        },
        "rougeL": {
            "precision": 0.60558,
            "recall": 0.61686,
            "fmeasure": 0.60327
        },
        "rougeLsum": {
            "precision": 0.60558,
            "recall": 0.61686,
            "fmeasure": 0.60327
        },
        "bleu": 34.41307,
        "meteor": 0.35347742177371666,
        "bertscore": {
            "precision": 0.91613,
            "recall": 0.92683,
            "f1": 0.91997
        },
        "nubia": {
            "semantic_relation": 4.25329,
            "contradiction": 13.68584,
            "irrelevancy": 30.41512,
            "logical_agreement": 55.89903,
            "grammar_ref": 5.14381,
            "grammar_hyp": 5.02437,
            "nubia_score": 0.72437
        },
        "bleurt": 0.29399
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 28,
        "msttr-100": 0.7375,
        "msttr-100_nopunct": 0.7775,
        "total_length": 462,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.444097208657794,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5952380952380952,
        "vocab_size-1": 275,
        "unique-1": 227,
        "entropy-1": 7.313465650410061,
        "distinct-2": 0.9308755760368663,
        "vocab_size-2": 404,
        "unique-2": 387,
        "entropy-2": 8.572487297409838,
        "cond_entropy-2": 1.0907625000040018,
        "distinct-3": 0.9950738916256158,
        "vocab_size-3": 404,
        "unique-3": 402,
        "entropy-3": 8.65548370043636,
        "cond_entropy-3": 0.09603529509786632,
        "total_length-nopunct": 413,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 3.897114317029974,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6561743341404358,
        "vocab_size-1-nopunct": 271,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.469291046473528,
        "distinct-2-nopunct": 0.9298701298701298,
        "vocab_size-2-nopunct": 358,
        "unique-2-nopunct": 344,
        "entropy-2-nopunct": 8.391172433491375,
        "cond_entropy-2-nopunct": 0.9935562737652445,
        "distinct-3-nopunct": 0.9971988795518207,
        "vocab_size-3-nopunct": 356,
        "unique-3-nopunct": 355,
        "entropy-3-nopunct": 8.474178023132808,
        "cond_entropy-3-nopunct": 0.09569797523958187,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.4533333333333333,
            "3": 0.7076023391812866
        },
        "nist": 5.878805331768907,
        "rouge1": {
            "precision": 0.75169,
            "recall": 0.67355,
            "fmeasure": 0.70218
        },
        "rouge2": {
            "precision": 0.53291,
            "recall": 0.48551,
            "fmeasure": 0.50387
        },
        "rougeL": {
            "precision": 0.6772,
            "recall": 0.60988,
            "fmeasure": 0.63504
        },
        "rougeLsum": {
            "precision": 0.6772,
            "recall": 0.60988,
            "fmeasure": 0.63504
        },
        "bleu": 43.60249,
        "meteor": 0.3633601865471504,
        "bertscore": {
            "precision": 0.9205,
            "recall": 0.91171,
            "f1": 0.91381
        },
        "nubia": {
            "semantic_relation": 4.08414,
            "contradiction": 11.28038,
            "irrelevancy": 30.27921,
            "logical_agreement": 58.44041,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.63234,
            "nubia_score": 0.70253
        },
        "bleurt": 0.18987
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.71,
        "total_length": 240,
        "mean_pred_length": 17.142857142857142,
        "std_pred_length": 5.383269623261936,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.5958333333333333,
        "vocab_size-1": 143,
        "unique-1": 114,
        "entropy-1": 6.468119360411281,
        "distinct-2": 0.9070796460176991,
        "vocab_size-2": 205,
        "unique-2": 193,
        "entropy-2": 7.576102593128796,
        "cond_entropy-2": 1.006758663178167,
        "distinct-3": 0.9716981132075472,
        "vocab_size-3": 206,
        "unique-3": 200,
        "entropy-3": 7.671316680978306,
        "cond_entropy-3": 0.11133233865145525,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 15.785714285714286,
        "std_pred_length-nopunct": 5.492573836275555,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6380090497737556,
        "vocab_size-1-nopunct": 141,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.5090154010914825,
        "distinct-2-nopunct": 0.8985507246376812,
        "vocab_size-2-nopunct": 186,
        "unique-2-nopunct": 174,
        "entropy-2-nopunct": 7.427007443205919,
        "cond_entropy-2-nopunct": 0.9948249900187928,
        "distinct-3-nopunct": 0.9689119170984456,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 181,
        "entropy-3-nopunct": 7.53028087146495,
        "cond_entropy-3-nopunct": 0.12260354846683862,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.46153846153846156,
            "3": 0.8333333333333334
        },
        "nist": 5.411596300182109,
        "rouge1": {
            "precision": 0.69264,
            "recall": 0.75777,
            "fmeasure": 0.70963
        },
        "rouge2": {
            "precision": 0.49833,
            "recall": 0.53581,
            "fmeasure": 0.50752
        },
        "rougeL": {
            "precision": 0.6095,
            "recall": 0.66527,
            "fmeasure": 0.62259
        },
        "rougeLsum": {
            "precision": 0.6095,
            "recall": 0.66527,
            "fmeasure": 0.62259
        },
        "bleu": 45.07695,
        "meteor": 0.4095391299458175,
        "bertscore": {
            "precision": 0.91325,
            "recall": 0.93231,
            "f1": 0.92036
        },
        "nubia": {
            "semantic_relation": 4.21512,
            "contradiction": 11.09155,
            "irrelevancy": 41.74649,
            "logical_agreement": 47.16196,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.51664,
            "nubia_score": 0.74794
        },
        "bleurt": 0.23949
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 169,
        "msttr-100": 0.71074,
        "msttr-100_nopunct": 0.75042,
        "total_length": 2796,
        "mean_pred_length": 16.54437869822485,
        "std_pred_length": 5.2341149705778065,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.39663805436337624,
        "vocab_size-1": 1109,
        "unique-1": 844,
        "entropy-1": 8.358689365085926,
        "distinct-2": 0.771602588503997,
        "vocab_size-2": 2027,
        "unique-2": 1809,
        "entropy-2": 10.613600432339725,
        "cond_entropy-2": 2.0272123978441514,
        "distinct-3": 0.8893409275834011,
        "vocab_size-3": 2186,
        "unique-3": 2069,
        "entropy-3": 10.935702815522692,
        "cond_entropy-3": 0.34620353735420417,
        "total_length-nopunct": 2441,
        "mean_pred_length-nopunct": 14.44378698224852,
        "std_pred_length-nopunct": 4.890345504142801,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4502253174928308,
        "vocab_size-1-nopunct": 1099,
        "unique-1-nopunct": 843,
        "entropy-1-nopunct": 8.632789535416505,
        "distinct-2-nopunct": 0.7860915492957746,
        "vocab_size-2-nopunct": 1786,
        "unique-2-nopunct": 1615,
        "entropy-2-nopunct": 10.432380776403988,
        "cond_entropy-2-nopunct": 1.9325016802881099,
        "distinct-3-nopunct": 0.896338563956253,
        "vocab_size-3-nopunct": 1885,
        "unique-3-nopunct": 1792,
        "entropy-3-nopunct": 10.729526524108936,
        "cond_entropy-3-nopunct": 0.34573933405909996,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2196652719665272,
            "2": 0.451685393258427,
            "3": 0.7617521367521367
        },
        "nist": 7.9299508861998556,
        "rouge1": {
            "precision": 0.76274,
            "recall": 0.73832,
            "fmeasure": 0.73969
        },
        "rouge2": {
            "precision": 0.53975,
            "recall": 0.51834,
            "fmeasure": 0.52169
        },
        "rougeL": {
            "precision": 0.66335,
            "recall": 0.64268,
            "fmeasure": 0.64394
        },
        "rougeLsum": {
            "precision": 0.66335,
            "recall": 0.64268,
            "fmeasure": 0.64394
        },
        "bleu": 46.63991,
        "meteor": 0.3938019523344246,
        "bertscore": {
            "precision": 0.92882,
            "recall": 0.92517,
            "f1": 0.92567
        },
        "nubia": {
            "semantic_relation": 4.17143,
            "contradiction": 8.26037,
            "irrelevancy": 30.81944,
            "logical_agreement": 60.92019,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.60042,
            "nubia_score": 0.73179
        },
        "bleurt": 0.27756
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79,
        "total_length": 158,
        "mean_pred_length": 14.363636363636363,
        "std_pred_length": 4.866821387026972,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.7025316455696202,
        "vocab_size-1": 111,
        "unique-1": 94,
        "entropy-1": 6.430955888411708,
        "distinct-2": 0.9727891156462585,
        "vocab_size-2": 143,
        "unique-2": 140,
        "entropy-2": 7.140115286998507,
        "cond_entropy-2": 0.5484913204136648,
        "distinct-3": 1.0,
        "vocab_size-3": 136,
        "unique-3": 136,
        "entropy-3": 7.0874628412503275,
        "cond_entropy-3": -0.04783533077599931,
        "total_length-nopunct": 141,
        "mean_pred_length-nopunct": 12.818181818181818,
        "std_pred_length-nopunct": 4.686890456236451,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7730496453900709,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.53646225708206,
        "distinct-2-nopunct": 0.9769230769230769,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 6.97040713993489,
        "cond_entropy-2-nopunct": 0.47728319091807486,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 119,
        "unique-3-nopunct": 119,
        "entropy-3-nopunct": 6.894817763307943,
        "cond_entropy-3-nopunct": -0.0707862891981287,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19444444444444445,
            "2": 0.22727272727272727,
            "3": 0.7142857142857143
        },
        "nist": 5.09354240771492,
        "rouge1": {
            "precision": 0.78874,
            "recall": 0.69518,
            "fmeasure": 0.7312
        },
        "rouge2": {
            "precision": 0.54056,
            "recall": 0.49154,
            "fmeasure": 0.51083
        },
        "rougeL": {
            "precision": 0.64528,
            "recall": 0.57488,
            "fmeasure": 0.60237
        },
        "rougeLsum": {
            "precision": 0.64528,
            "recall": 0.57488,
            "fmeasure": 0.60237
        },
        "bleu": 42.44066,
        "meteor": 0.3933594009165004,
        "bertscore": {
            "precision": 0.92694,
            "recall": 0.91427,
            "f1": 0.91923
        },
        "nubia": {
            "semantic_relation": 4.14466,
            "contradiction": 21.20212,
            "irrelevancy": 14.30414,
            "logical_agreement": 64.49374,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.66275,
            "nubia_score": 0.67759
        },
        "bleurt": 0.22016
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.74667,
        "total_length": 439,
        "mean_pred_length": 16.884615384615383,
        "std_pred_length": 4.585318737993475,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5876993166287016,
        "vocab_size-1": 258,
        "unique-1": 215,
        "entropy-1": 7.194431720137352,
        "distinct-2": 0.9079903147699758,
        "vocab_size-2": 375,
        "unique-2": 355,
        "entropy-2": 8.446249084009283,
        "cond_entropy-2": 1.0971753678792346,
        "distinct-3": 0.979328165374677,
        "vocab_size-3": 379,
        "unique-3": 372,
        "entropy-3": 8.552895473193061,
        "cond_entropy-3": 0.11785432477208337,
        "total_length-nopunct": 395,
        "mean_pred_length-nopunct": 15.192307692307692,
        "std_pred_length-nopunct": 4.402964305392017,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.640506329113924,
        "vocab_size-1-nopunct": 253,
        "unique-1-nopunct": 214,
        "entropy-1-nopunct": 7.278471223500605,
        "distinct-2-nopunct": 0.9051490514905149,
        "vocab_size-2-nopunct": 334,
        "unique-2-nopunct": 317,
        "entropy-2-nopunct": 8.270923373267955,
        "cond_entropy-2-nopunct": 1.0668240077835176,
        "distinct-3-nopunct": 0.9825072886297376,
        "vocab_size-3-nopunct": 337,
        "unique-3-nopunct": 332,
        "entropy-3-nopunct": 8.384878505233534,
        "cond_entropy-3-nopunct": 0.12757144232301457,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21176470588235294,
            "2": 0.5447761194029851,
            "3": 0.7322834645669292
        },
        "nist": 6.25759412877272,
        "rouge1": {
            "precision": 0.74827,
            "recall": 0.71697,
            "fmeasure": 0.72312
        },
        "rouge2": {
            "precision": 0.49769,
            "recall": 0.47557,
            "fmeasure": 0.47979
        },
        "rougeL": {
            "precision": 0.58257,
            "recall": 0.56779,
            "fmeasure": 0.56818
        },
        "rougeLsum": {
            "precision": 0.58257,
            "recall": 0.56779,
            "fmeasure": 0.56818
        },
        "bleu": 43.94466,
        "meteor": 0.3726879724115895,
        "bertscore": {
            "precision": 0.92236,
            "recall": 0.91925,
            "f1": 0.91912
        },
        "nubia": {
            "semantic_relation": 4.20137,
            "contradiction": 13.39486,
            "irrelevancy": 38.06536,
            "logical_agreement": 48.53978,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.65374,
            "nubia_score": 0.7132
        },
        "bleurt": 0.14099
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.375
        },
        "nist": 1.5770677086338152,
        "rouge1": {
            "precision": 0.31818,
            "recall": 0.325,
            "fmeasure": 0.32091
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.22727,
            "recall": 0.23333,
            "fmeasure": 0.22981
        },
        "rougeLsum": {
            "precision": 0.22727,
            "recall": 0.23333,
            "fmeasure": 0.22981
        },
        "bleu": 5.064,
        "meteor": 0.20994035785288273,
        "bertscore": {
            "precision": 0.78172,
            "recall": 0.768,
            "f1": 0.77348
        },
        "nubia": {
            "semantic_relation": 2.69835,
            "contradiction": 1.10697,
            "irrelevancy": 10.03319,
            "logical_agreement": 88.85984,
            "grammar_ref": 5.93899,
            "grammar_hyp": 6.45946,
            "nubia_score": 0.26012
        },
        "bleurt": -0.74347
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.78333,
        "total_length": 389,
        "mean_pred_length": 16.91304347826087,
        "std_pred_length": 4.0207401814597885,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5784061696658098,
        "vocab_size-1": 225,
        "unique-1": 183,
        "entropy-1": 7.04889755227317,
        "distinct-2": 0.9016393442622951,
        "vocab_size-2": 330,
        "unique-2": 306,
        "entropy-2": 8.27660209237053,
        "cond_entropy-2": 1.061579316761838,
        "distinct-3": 0.9650145772594753,
        "vocab_size-3": 331,
        "unique-3": 320,
        "entropy-3": 8.349893082493006,
        "cond_entropy-3": 0.08349287979012035,
        "total_length-nopunct": 348,
        "mean_pred_length-nopunct": 15.130434782608695,
        "std_pred_length-nopunct": 3.882002484443429,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.632183908045977,
        "vocab_size-1-nopunct": 220,
        "unique-1-nopunct": 182,
        "entropy-1-nopunct": 7.149990979892135,
        "distinct-2-nopunct": 0.9015384615384615,
        "vocab_size-2-nopunct": 293,
        "unique-2-nopunct": 273,
        "entropy-2-nopunct": 8.099650446363997,
        "cond_entropy-2-nopunct": 0.9945893082593177,
        "distinct-3-nopunct": 0.9701986754966887,
        "vocab_size-3-nopunct": 293,
        "unique-3-nopunct": 285,
        "entropy-3-nopunct": 8.176302462827884,
        "cond_entropy-3-nopunct": 0.08341321883125642,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3116883116883117,
            "2": 0.4927536231884058,
            "3": 0.8377192982456141
        },
        "nist": 6.500522720197095,
        "rouge1": {
            "precision": 0.75415,
            "recall": 0.77011,
            "fmeasure": 0.75696
        },
        "rouge2": {
            "precision": 0.55319,
            "recall": 0.56109,
            "fmeasure": 0.55263
        },
        "rougeL": {
            "precision": 0.65447,
            "recall": 0.66656,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.65447,
            "recall": 0.66656,
            "fmeasure": 0.65497
        },
        "bleu": 50.80685,
        "meteor": 0.42778910023890654,
        "bertscore": {
            "precision": 0.93278,
            "recall": 0.9399,
            "f1": 0.93503
        },
        "nubia": {
            "semantic_relation": 4.28135,
            "contradiction": 11.93942,
            "irrelevancy": 29.72661,
            "logical_agreement": 58.33397,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.68005,
            "nubia_score": 0.74822
        },
        "bleurt": 0.26569
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 340,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.789698078707183,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5794117647058824,
        "vocab_size-1": 197,
        "unique-1": 157,
        "entropy-1": 6.9459937412293185,
        "distinct-2": 0.875,
        "vocab_size-2": 280,
        "unique-2": 251,
        "entropy-2": 8.045978837000467,
        "cond_entropy-2": 0.9311487165274678,
        "distinct-3": 0.9433333333333334,
        "vocab_size-3": 283,
        "unique-3": 270,
        "entropy-3": 8.105420190467088,
        "cond_entropy-3": 0.05532167898512147,
        "total_length-nopunct": 295,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 5.838450136808569,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6508474576271186,
        "vocab_size-1-nopunct": 192,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 7.094812116263317,
        "distinct-2-nopunct": 0.8909090909090909,
        "vocab_size-2-nopunct": 245,
        "unique-2-nopunct": 223,
        "entropy-2-nopunct": 7.863145626530907,
        "cond_entropy-2-nopunct": 0.7996433941184463,
        "distinct-3-nopunct": 0.9529411764705882,
        "vocab_size-3-nopunct": 243,
        "unique-3-nopunct": 234,
        "entropy-3-nopunct": 7.891354760362829,
        "cond_entropy-3-nopunct": 0.0431222461363157,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13725490196078433,
            "2": 0.5,
            "3": 0.8711111111111111
        },
        "nist": 6.748216370733017,
        "rouge1": {
            "precision": 0.82577,
            "recall": 0.81779,
            "fmeasure": 0.81638
        },
        "rouge2": {
            "precision": 0.66322,
            "recall": 0.66786,
            "fmeasure": 0.66169
        },
        "rougeL": {
            "precision": 0.73798,
            "recall": 0.72847,
            "fmeasure": 0.7289
        },
        "rougeLsum": {
            "precision": 0.73798,
            "recall": 0.72847,
            "fmeasure": 0.7289
        },
        "bleu": 59.80485,
        "meteor": 0.4593964994490647,
        "bertscore": {
            "precision": 0.95095,
            "recall": 0.94844,
            "f1": 0.9486
        },
        "nubia": {
            "semantic_relation": 4.42069,
            "contradiction": 1.45894,
            "irrelevancy": 29.37513,
            "logical_agreement": 69.16593,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.50203,
            "nubia_score": 0.81446
        },
        "bleurt": 0.48261
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.735,
        "total_length": 292,
        "mean_pred_length": 17.176470588235293,
        "std_pred_length": 6.080202145610612,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5753424657534246,
        "vocab_size-1": 168,
        "unique-1": 132,
        "entropy-1": 6.6444630221109975,
        "distinct-2": 0.9163636363636364,
        "vocab_size-2": 252,
        "unique-2": 235,
        "entropy-2": 7.914653979390474,
        "cond_entropy-2": 1.1718934198841036,
        "distinct-3": 0.9806201550387597,
        "vocab_size-3": 253,
        "unique-3": 248,
        "entropy-3": 7.9724675655007395,
        "cond_entropy-3": 0.07024294693730739,
        "total_length-nopunct": 245,
        "mean_pred_length-nopunct": 14.411764705882353,
        "std_pred_length-nopunct": 4.802680912223576,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6693877551020408,
        "vocab_size-1-nopunct": 164,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.8318159231267925,
        "distinct-2-nopunct": 0.9254385964912281,
        "vocab_size-2-nopunct": 211,
        "unique-2-nopunct": 199,
        "entropy-2-nopunct": 7.661313630485986,
        "cond_entropy-2-nopunct": 0.8987168927534269,
        "distinct-3-nopunct": 0.990521327014218,
        "vocab_size-3-nopunct": 209,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.7021418427356485,
        "cond_entropy-3-nopunct": 0.04043389245127605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.3333333333333333,
            "3": 0.7464114832535885
        },
        "nist": 5.9074622669200645,
        "rouge1": {
            "precision": 0.77299,
            "recall": 0.73548,
            "fmeasure": 0.74919
        },
        "rouge2": {
            "precision": 0.56571,
            "recall": 0.52027,
            "fmeasure": 0.5377
        },
        "rougeL": {
            "precision": 0.69065,
            "recall": 0.64762,
            "fmeasure": 0.66427
        },
        "rougeLsum": {
            "precision": 0.69065,
            "recall": 0.64762,
            "fmeasure": 0.66427
        },
        "bleu": 48.71179,
        "meteor": 0.39998338134209327,
        "bertscore": {
            "precision": 0.92521,
            "recall": 0.92222,
            "f1": 0.92293
        },
        "nubia": {
            "semantic_relation": 4.19425,
            "contradiction": 6.34274,
            "irrelevancy": 28.84759,
            "logical_agreement": 64.80967,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.46886,
            "nubia_score": 0.7353
        },
        "bleurt": 0.28934
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548847,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "nist": 2.488212329881815,
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.77647,
            "fmeasure": 0.69704
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.55873,
            "fmeasure": 0.4801
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.65359,
            "fmeasure": 0.58687
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.65359,
            "fmeasure": 0.58687
        },
        "bleu": 21.95152,
        "meteor": 0.360703899295125,
        "bertscore": {
            "precision": 0.88557,
            "recall": 0.93765,
            "f1": 0.90887
        },
        "nubia": {
            "semantic_relation": 4.32213,
            "contradiction": 41.17889,
            "irrelevancy": 55.07604,
            "logical_agreement": 3.74508,
            "grammar_ref": 5.18542,
            "grammar_hyp": 4.59356,
            "nubia_score": 0.73978
        },
        "bleurt": 0.15371
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.242640687119285,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 33,
        "unique-1": 27,
        "entropy-1": 4.81708580796078,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 41,
        "unique-2": 40,
        "entropy-2": 5.344698375159715,
        "cond_entropy-2": 0.46259862345948544,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.05563315263446058,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8108108108108109,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.73351713659012,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838573,
        "cond_entropy-2-nopunct": 0.33711654839894306,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.06875040183120604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.8484848484848485
        },
        "nist": 4.748799966915072,
        "rouge1": {
            "precision": 0.89298,
            "recall": 0.81308,
            "fmeasure": 0.84921
        },
        "rouge2": {
            "precision": 0.65432,
            "recall": 0.59795,
            "fmeasure": 0.62321
        },
        "rougeL": {
            "precision": 0.71053,
            "recall": 0.65471,
            "fmeasure": 0.67989
        },
        "rougeLsum": {
            "precision": 0.71053,
            "recall": 0.65471,
            "fmeasure": 0.67989
        },
        "bleu": 47.29638,
        "meteor": 0.4650075819439694,
        "bertscore": {
            "precision": 0.96911,
            "recall": 0.97002,
            "f1": 0.96955
        },
        "nubia": {
            "semantic_relation": 4.75865,
            "contradiction": 1.34386,
            "irrelevancy": 22.62489,
            "logical_agreement": 76.03125,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.42446,
            "nubia_score": 0.85592
        },
        "bleurt": 0.53193
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.68,
        "total_length": 173,
        "mean_pred_length": 14.416666666666666,
        "std_pred_length": 4.733890812241261,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.5838150289017341,
        "vocab_size-1": 101,
        "unique-1": 75,
        "entropy-1": 6.100951077860031,
        "distinct-2": 0.9006211180124224,
        "vocab_size-2": 145,
        "unique-2": 133,
        "entropy-2": 7.10505024471957,
        "cond_entropy-2": 0.8363015009506507,
        "distinct-3": 0.9664429530201343,
        "vocab_size-3": 144,
        "unique-3": 139,
        "entropy-3": 7.1520544265024375,
        "cond_entropy-3": 0.06519478313009675,
        "total_length-nopunct": 154,
        "mean_pred_length-nopunct": 12.833333333333334,
        "std_pred_length-nopunct": 4.740487551109297,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6298701298701299,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.123299810641161,
        "distinct-2-nopunct": 0.8873239436619719,
        "vocab_size-2-nopunct": 126,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.893658894317362,
        "cond_entropy-2-nopunct": 0.8388227510046912,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 125,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.945444736105379,
        "cond_entropy-3-nopunct": 0.06773244718992821,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3103448275862069,
            "2": 0.47619047619047616,
            "3": 0.7570093457943925
        },
        "nist": 5.48426873658022,
        "rouge1": {
            "precision": 0.78781,
            "recall": 0.74546,
            "fmeasure": 0.75474
        },
        "rouge2": {
            "precision": 0.50676,
            "recall": 0.47109,
            "fmeasure": 0.47671
        },
        "rougeL": {
            "precision": 0.65857,
            "recall": 0.6204,
            "fmeasure": 0.62981
        },
        "rougeLsum": {
            "precision": 0.65857,
            "recall": 0.6204,
            "fmeasure": 0.62981
        },
        "bleu": 40.794,
        "meteor": 0.4011654554192358,
        "bertscore": {
            "precision": 0.9191,
            "recall": 0.91256,
            "f1": 0.91192
        },
        "nubia": {
            "semantic_relation": 4.26685,
            "contradiction": 5.42163,
            "irrelevancy": 29.2293,
            "logical_agreement": 65.34907,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.07496,
            "nubia_score": 0.71949
        },
        "bleurt": 0.19355
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.8,
        "total_length": 140,
        "mean_pred_length": 17.5,
        "std_pred_length": 6.910137480542627,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.6785714285714286,
        "vocab_size-1": 95,
        "unique-1": 83,
        "entropy-1": 6.102930444215443,
        "distinct-2": 0.946969696969697,
        "vocab_size-2": 125,
        "unique-2": 120,
        "entropy-2": 6.926895823871119,
        "cond_entropy-2": 0.709260049423057,
        "distinct-3": 0.9758064516129032,
        "vocab_size-3": 121,
        "unique-3": 119,
        "entropy-3": 6.899721411175866,
        "cond_entropy-3": -0.03237583315349486,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 4.602988159880492,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7982456140350878,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.250237519536943,
        "distinct-2-nopunct": 0.9905660377358491,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.7090525300348824,
        "cond_entropy-2-nopunct": 0.4878363072555245,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 98,
        "unique-3-nopunct": 98,
        "entropy-3-nopunct": 6.614709844115218,
        "cond_entropy-3-nopunct": -0.09280244718268442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.46153846153846156,
            "3": 0.6896551724137931
        },
        "nist": 4.295715349073785,
        "rouge1": {
            "precision": 0.7768,
            "recall": 0.6633,
            "fmeasure": 0.70116
        },
        "rouge2": {
            "precision": 0.50134,
            "recall": 0.42027,
            "fmeasure": 0.44689
        },
        "rougeL": {
            "precision": 0.63994,
            "recall": 0.54625,
            "fmeasure": 0.57837
        },
        "rougeLsum": {
            "precision": 0.63994,
            "recall": 0.54625,
            "fmeasure": 0.57837
        },
        "bleu": 26.87924,
        "meteor": 0.3326697246616615,
        "bertscore": {
            "precision": 0.91619,
            "recall": 0.90094,
            "f1": 0.90613
        },
        "nubia": {
            "semantic_relation": 3.93919,
            "contradiction": 1.84253,
            "irrelevancy": 37.05227,
            "logical_agreement": 61.1052,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.58469,
            "nubia_score": 0.61474
        },
        "bleurt": 0.04279
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.7,
        "total_length": 255,
        "mean_pred_length": 14.166666666666666,
        "std_pred_length": 3.562926387738658,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.5647058823529412,
        "vocab_size-1": 144,
        "unique-1": 116,
        "entropy-1": 6.409475644746657,
        "distinct-2": 0.8523206751054853,
        "vocab_size-2": 202,
        "unique-2": 183,
        "entropy-2": 7.487168720274771,
        "cond_entropy-2": 0.8813603760852954,
        "distinct-3": 0.9497716894977168,
        "vocab_size-3": 208,
        "unique-3": 197,
        "entropy-3": 7.674330438596615,
        "cond_entropy-3": 0.220167843962156,
        "total_length-nopunct": 226,
        "mean_pred_length-nopunct": 12.555555555555555,
        "std_pred_length-nopunct": 3.419262789650915,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6194690265486725,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.490285767947633,
        "distinct-2-nopunct": 0.8509615384615384,
        "vocab_size-2-nopunct": 177,
        "unique-2-nopunct": 160,
        "entropy-2-nopunct": 7.29095335619985,
        "cond_entropy-2-nopunct": 0.8921636791407517,
        "distinct-3-nopunct": 0.9526315789473684,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 172,
        "entropy-3-nopunct": 7.475118766225695,
        "cond_entropy-3-nopunct": 0.21769569694656124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20454545454545456,
            "2": 0.423728813559322,
            "3": 0.7763975155279503
        },
        "nist": 6.072876366381295,
        "rouge1": {
            "precision": 0.77704,
            "recall": 0.73146,
            "fmeasure": 0.74168
        },
        "rouge2": {
            "precision": 0.55466,
            "recall": 0.52456,
            "fmeasure": 0.52867
        },
        "rougeL": {
            "precision": 0.65666,
            "recall": 0.61505,
            "fmeasure": 0.62485
        },
        "rougeLsum": {
            "precision": 0.65666,
            "recall": 0.61505,
            "fmeasure": 0.62485
        },
        "bleu": 46.20145,
        "meteor": 0.3884144210213653,
        "bertscore": {
            "precision": 0.93628,
            "recall": 0.92599,
            "f1": 0.92904
        },
        "nubia": {
            "semantic_relation": 4.39047,
            "contradiction": 6.98273,
            "irrelevancy": 29.65723,
            "logical_agreement": 63.36004,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.64753,
            "nubia_score": 0.79294
        },
        "bleurt": 0.29569
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 56,
        "msttr-100": 0.73889,
        "msttr-100_nopunct": 0.78625,
        "total_length": 947,
        "mean_pred_length": 16.910714285714285,
        "std_pred_length": 5.251791482485782,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.515311510031679,
        "vocab_size-1": 488,
        "unique-1": 401,
        "entropy-1": 7.814778808495529,
        "distinct-2": 0.8855218855218855,
        "vocab_size-2": 789,
        "unique-2": 732,
        "entropy-2": 9.511131049869482,
        "cond_entropy-2": 1.4969519221429326,
        "distinct-3": 0.9700598802395209,
        "vocab_size-3": 810,
        "unique-3": 793,
        "entropy-3": 9.637345501123297,
        "cond_entropy-3": 0.13227387211094863,
        "total_length-nopunct": 831,
        "mean_pred_length-nopunct": 14.839285714285714,
        "std_pred_length-nopunct": 4.63979981755019,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5752105896510229,
        "vocab_size-1-nopunct": 478,
        "unique-1-nopunct": 398,
        "entropy-1-nopunct": 7.999732740217127,
        "distinct-2-nopunct": 0.895483870967742,
        "vocab_size-2-nopunct": 694,
        "unique-2-nopunct": 651,
        "entropy-2-nopunct": 9.328416730056365,
        "cond_entropy-2-nopunct": 1.4207733945880354,
        "distinct-3-nopunct": 0.972183588317107,
        "vocab_size-3-nopunct": 699,
        "unique-3-nopunct": 685,
        "entropy-3-nopunct": 9.426552028583394,
        "cond_entropy-3-nopunct": 0.11451593139360895,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20105820105820105,
            "2": 0.43037974683544306,
            "3": 0.7694704049844237
        },
        "nist": 6.967867380986907,
        "rouge1": {
            "precision": 0.76121,
            "recall": 0.73137,
            "fmeasure": 0.73659
        },
        "rouge2": {
            "precision": 0.51955,
            "recall": 0.49712,
            "fmeasure": 0.50095
        },
        "rougeL": {
            "precision": 0.66104,
            "recall": 0.63705,
            "fmeasure": 0.6401
        },
        "rougeLsum": {
            "precision": 0.66104,
            "recall": 0.63705,
            "fmeasure": 0.6401
        },
        "bleu": 45.01882,
        "meteor": 0.39062630092515493,
        "bertscore": {
            "precision": 0.92057,
            "recall": 0.92053,
            "f1": 0.91933
        },
        "nubia": {
            "semantic_relation": 4.1656,
            "contradiction": 3.79879,
            "irrelevancy": 39.27816,
            "logical_agreement": 56.92305,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.74159,
            "nubia_score": 0.71452
        },
        "bleurt": 0.21227
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "total_length": 329,
        "mean_pred_length": 17.31578947368421,
        "std_pred_length": 6.000461662756041,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.574468085106383,
        "vocab_size-1": 189,
        "unique-1": 151,
        "entropy-1": 6.897837011485213,
        "distinct-2": 0.896774193548387,
        "vocab_size-2": 278,
        "unique-2": 252,
        "entropy-2": 8.047029082665647,
        "cond_entropy-2": 1.0102543404005824,
        "distinct-3": 0.9518900343642611,
        "vocab_size-3": 277,
        "unique-3": 263,
        "entropy-3": 8.088655411636806,
        "cond_entropy-3": 0.03337177098968367,
        "total_length-nopunct": 284,
        "mean_pred_length-nopunct": 14.947368421052632,
        "std_pred_length-nopunct": 4.999722984015966,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.647887323943662,
        "vocab_size-1-nopunct": 184,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 7.003926014556006,
        "distinct-2-nopunct": 0.909433962264151,
        "vocab_size-2-nopunct": 241,
        "unique-2-nopunct": 222,
        "entropy-2-nopunct": 7.8450762381052686,
        "cond_entropy-2-nopunct": 0.8855675857909279,
        "distinct-3-nopunct": 0.9512195121951219,
        "vocab_size-3-nopunct": 234,
        "unique-3-nopunct": 222,
        "entropy-3-nopunct": 7.844953529729518,
        "cond_entropy-3-nopunct": 0.002807165258792308,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21311475409836064,
            "2": 0.423728813559322,
            "3": 0.7004830917874396
        },
        "nist": 5.575280536612353,
        "rouge1": {
            "precision": 0.72209,
            "recall": 0.69781,
            "fmeasure": 0.70298
        },
        "rouge2": {
            "precision": 0.45772,
            "recall": 0.4418,
            "fmeasure": 0.44361
        },
        "rougeL": {
            "precision": 0.61034,
            "recall": 0.60026,
            "fmeasure": 0.59911
        },
        "rougeLsum": {
            "precision": 0.61034,
            "recall": 0.60026,
            "fmeasure": 0.59911
        },
        "bleu": 38.05085,
        "meteor": 0.3555514837934185,
        "bertscore": {
            "precision": 0.91106,
            "recall": 0.90817,
            "f1": 0.90726
        },
        "nubia": {
            "semantic_relation": 3.90146,
            "contradiction": 15.52957,
            "irrelevancy": 42.81633,
            "logical_agreement": 41.6541,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.44303,
            "nubia_score": 0.66067
        },
        "bleurt": 0.09184
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.77,
        "total_length": 206,
        "mean_pred_length": 15.846153846153847,
        "std_pred_length": 3.324643505380663,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6359223300970874,
        "vocab_size-1": 131,
        "unique-1": 110,
        "entropy-1": 6.552177207821702,
        "distinct-2": 0.9430051813471503,
        "vocab_size-2": 182,
        "unique-2": 176,
        "entropy-2": 7.453830677153223,
        "cond_entropy-2": 0.7288062507608978,
        "distinct-3": 1.0,
        "vocab_size-3": 180,
        "unique-3": 180,
        "entropy-3": 7.491853096329661,
        "cond_entropy-3": 0.03692321185139147,
        "total_length-nopunct": 182,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.1622776601683795,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 126,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.620075478371025,
        "distinct-2-nopunct": 0.9467455621301775,
        "vocab_size-2-nopunct": 160,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 7.266235131535647,
        "cond_entropy-2-nopunct": 0.6966942632460611,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 156,
        "unique-3-nopunct": 156,
        "entropy-3-nopunct": 7.285402218862266,
        "cond_entropy-3-nopunct": 0.030387446055470974,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4074074074074074,
            "2": 0.18181818181818182,
            "3": 0.9210526315789473
        },
        "nist": 6.6548605351518315,
        "rouge1": {
            "precision": 0.85304,
            "recall": 0.88455,
            "fmeasure": 0.85979
        },
        "rouge2": {
            "precision": 0.66673,
            "recall": 0.69002,
            "fmeasure": 0.66873
        },
        "rougeL": {
            "precision": 0.76323,
            "recall": 0.78985,
            "fmeasure": 0.76741
        },
        "rougeLsum": {
            "precision": 0.76323,
            "recall": 0.78985,
            "fmeasure": 0.76741
        },
        "bleu": 61.33504,
        "meteor": 0.49394025053465385,
        "bertscore": {
            "precision": 0.96076,
            "recall": 0.96905,
            "f1": 0.96236
        },
        "nubia": {
            "semantic_relation": 4.68421,
            "contradiction": 0.30333,
            "irrelevancy": 29.80633,
            "logical_agreement": 69.89034,
            "grammar_ref": 5.1809,
            "grammar_hyp": 4.98728,
            "nubia_score": 0.88501
        },
        "bleurt": 0.56846
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.74,
        "msttr-100_nopunct": NaN,
        "total_length": 108,
        "mean_pred_length": 15.428571428571429,
        "std_pred_length": 4.716449719776908,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 78,
        "unique-1": 61,
        "entropy-1": 6.058949914582626,
        "distinct-2": 0.9306930693069307,
        "vocab_size-2": 94,
        "unique-2": 87,
        "entropy-2": 6.519597621365641,
        "cond_entropy-2": 0.314311851918296,
        "distinct-3": 0.9574468085106383,
        "vocab_size-3": 90,
        "unique-3": 86,
        "entropy-3": 6.4694824686989,
        "cond_entropy-3": -0.03979284384011486,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 13.428571428571429,
        "std_pred_length-nopunct": 4.435478484645721,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.776595744680851,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 6.049165713333725,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.305012461365964,
        "cond_entropy-2-nopunct": 0.28501872468059575,
        "distinct-3-nopunct": 0.9625,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.246928094887356,
        "cond_entropy-3-nopunct": -0.046015400961366165,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1282051282051282,
            "2": 0.4444444444444444,
            "3": 0.7936507936507936
        },
        "nist": 4.821744670524031,
        "rouge1": {
            "precision": 0.70083,
            "recall": 0.72062,
            "fmeasure": 0.70082
        },
        "rouge2": {
            "precision": 0.52907,
            "recall": 0.54556,
            "fmeasure": 0.53031
        },
        "rougeL": {
            "precision": 0.65831,
            "recall": 0.68125,
            "fmeasure": 0.65886
        },
        "rougeLsum": {
            "precision": 0.65831,
            "recall": 0.68125,
            "fmeasure": 0.65886
        },
        "bleu": 46.68802,
        "meteor": 0.4093021518597602,
        "bertscore": {
            "precision": 0.92258,
            "recall": 0.94058,
            "f1": 0.93038
        },
        "nubia": {
            "semantic_relation": 4.27826,
            "contradiction": 18.70028,
            "irrelevancy": 30.63311,
            "logical_agreement": 50.66661,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.29754,
            "nubia_score": 0.75547
        },
        "bleurt": 0.26412
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.7,
        "total_length": 231,
        "mean_pred_length": 19.25,
        "std_pred_length": 6.417748826496718,
        "median_pred_length": 18.5,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.4935064935064935,
        "vocab_size-1": 114,
        "unique-1": 80,
        "entropy-1": 6.168979443390954,
        "distinct-2": 0.7945205479452054,
        "vocab_size-2": 174,
        "unique-2": 153,
        "entropy-2": 7.22632526079545,
        "cond_entropy-2": 0.9800264732575239,
        "distinct-3": 0.8743961352657005,
        "vocab_size-3": 181,
        "unique-3": 167,
        "entropy-3": 7.387283682208216,
        "cond_entropy-3": 0.1830914725512943,
        "total_length-nopunct": 192,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.898979485566356,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5625,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.13885820508077,
        "distinct-2-nopunct": 0.8166666666666667,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 132,
        "entropy-2-nopunct": 6.988501102251175,
        "cond_entropy-2-nopunct": 0.8766506663446247,
        "distinct-3-nopunct": 0.8928571428571429,
        "vocab_size-3-nopunct": 150,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.131160857416127,
        "cond_entropy-3-nopunct": 0.1488515642657555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.5833333333333334,
            "3": 0.8273381294964028
        },
        "nist": 6.2139761313636495,
        "rouge1": {
            "precision": 0.7734,
            "recall": 0.76404,
            "fmeasure": 0.7582
        },
        "rouge2": {
            "precision": 0.60987,
            "recall": 0.60736,
            "fmeasure": 0.60044
        },
        "rougeL": {
            "precision": 0.72195,
            "recall": 0.72376,
            "fmeasure": 0.71239
        },
        "rougeLsum": {
            "precision": 0.72195,
            "recall": 0.72376,
            "fmeasure": 0.71239
        },
        "bleu": 61.1167,
        "meteor": 0.4331044748345907,
        "bertscore": {
            "precision": 0.93099,
            "recall": 0.93966,
            "f1": 0.9341
        },
        "nubia": {
            "semantic_relation": 4.12162,
            "contradiction": 9.62165,
            "irrelevancy": 32.32735,
            "logical_agreement": 58.051,
            "grammar_ref": 4.07585,
            "grammar_hyp": 3.98356,
            "nubia_score": 0.7289
        },
        "bleurt": 0.35893
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76833,
        "total_length": 668,
        "mean_pred_length": 15.181818181818182,
        "std_pred_length": 4.349883631007361,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.5074850299401198,
        "vocab_size-1": 339,
        "unique-1": 269,
        "entropy-1": 7.418704057656517,
        "distinct-2": 0.8221153846153846,
        "vocab_size-2": 513,
        "unique-2": 454,
        "entropy-2": 8.821401718956704,
        "cond_entropy-2": 1.1866967248289138,
        "distinct-3": 0.9086206896551724,
        "vocab_size-3": 527,
        "unique-3": 491,
        "entropy-3": 8.973334025311303,
        "cond_entropy-3": 0.17405482272539535,
        "total_length-nopunct": 601,
        "mean_pred_length-nopunct": 13.659090909090908,
        "std_pred_length-nopunct": 4.182991436205901,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5540765391014975,
        "vocab_size-1-nopunct": 333,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.5631313924067305,
        "distinct-2-nopunct": 0.8204667863554758,
        "vocab_size-2-nopunct": 457,
        "unique-2-nopunct": 407,
        "entropy-2-nopunct": 8.643927526430309,
        "cond_entropy-2-nopunct": 1.1736761566226392,
        "distinct-3-nopunct": 0.9064327485380117,
        "vocab_size-3-nopunct": 465,
        "unique-3-nopunct": 434,
        "entropy-3-nopunct": 8.788753538943997,
        "cond_entropy-3-nopunct": 0.17376312479162825,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24285714285714285,
            "2": 0.6153846153846154,
            "3": 0.7391304347826086
        },
        "nist": 6.955868195113026,
        "rouge1": {
            "precision": 0.75892,
            "recall": 0.7328,
            "fmeasure": 0.735
        },
        "rouge2": {
            "precision": 0.55248,
            "recall": 0.54265,
            "fmeasure": 0.54003
        },
        "rougeL": {
            "precision": 0.68359,
            "recall": 0.66862,
            "fmeasure": 0.66539
        },
        "rougeLsum": {
            "precision": 0.68359,
            "recall": 0.66862,
            "fmeasure": 0.66539
        },
        "bleu": 49.71793,
        "meteor": 0.40301172182053824,
        "bertscore": {
            "precision": 0.93433,
            "recall": 0.92963,
            "f1": 0.93002
        },
        "nubia": {
            "semantic_relation": 4.20636,
            "contradiction": 6.22887,
            "irrelevancy": 35.68095,
            "logical_agreement": 58.09019,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.49152,
            "nubia_score": 0.73951
        },
        "bleurt": 0.2958
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 3.299831645537222,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.78,
        "vocab_size-1": 39,
        "unique-1": 31,
        "entropy-1": 5.158562939644919,
        "distinct-2": 0.9574468085106383,
        "vocab_size-2": 45,
        "unique-2": 43,
        "entropy-2": 5.469482468698917,
        "cond_entropy-2": 0.2407278747609327,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.004248142131249435,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8222222222222222,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.102746985122408,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.297079327540667,
        "cond_entropy-2-nopunct": 0.19831611226639376,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.029992126993434953,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.18181818181818182,
            "3": 0.65625
        },
        "nist": 3.2658068340432584,
        "rouge1": {
            "precision": 0.59932,
            "recall": 0.52496,
            "fmeasure": 0.54907
        },
        "rouge2": {
            "precision": 0.3455,
            "recall": 0.33838,
            "fmeasure": 0.33079
        },
        "rougeL": {
            "precision": 0.44055,
            "recall": 0.43148,
            "fmeasure": 0.42359
        },
        "rougeLsum": {
            "precision": 0.44055,
            "recall": 0.43148,
            "fmeasure": 0.42359
        },
        "bleu": 22.7024,
        "meteor": 0.25776326336469946,
        "bertscore": {
            "precision": 0.87358,
            "recall": 0.85608,
            "f1": 0.8554
        },
        "nubia": {
            "semantic_relation": 3.82362,
            "contradiction": 30.43307,
            "irrelevancy": 50.65408,
            "logical_agreement": 18.91285,
            "grammar_ref": 4.07664,
            "grammar_hyp": 3.79096,
            "nubia_score": 0.66725
        },
        "bleurt": -0.04744
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "total_length": 244,
        "mean_pred_length": 16.266666666666666,
        "std_pred_length": 4.986203187017375,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6639344262295082,
        "vocab_size-1": 162,
        "unique-1": 138,
        "entropy-1": 6.82254828010713,
        "distinct-2": 0.9781659388646288,
        "vocab_size-2": 224,
        "unique-2": 219,
        "entropy-2": 7.795535665826207,
        "cond_entropy-2": 0.8355075583216728,
        "distinct-3": 1.0,
        "vocab_size-3": 214,
        "unique-3": 214,
        "entropy-3": 7.741466986401113,
        "cond_entropy-3": -0.051007829733180035,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 14.733333333333333,
        "std_pred_length-nopunct": 5.157087894883658,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7149321266968326,
        "vocab_size-1-nopunct": 158,
        "unique-1-nopunct": 136,
        "entropy-1-nopunct": 6.890651818742711,
        "distinct-2-nopunct": 0.9757281553398058,
        "vocab_size-2-nopunct": 201,
        "unique-2-nopunct": 196,
        "entropy-2-nopunct": 7.63795683786283,
        "cond_entropy-2-nopunct": 0.8126388109149165,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 191,
        "entropy-3-nopunct": 7.577428828035749,
        "cond_entropy-3-nopunct": -0.05671567820506159,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.38461538461538464,
            "3": 0.8072916666666666
        },
        "nist": 5.833340306978876,
        "rouge1": {
            "precision": 0.81579,
            "recall": 0.7329,
            "fmeasure": 0.76353
        },
        "rouge2": {
            "precision": 0.60627,
            "recall": 0.54534,
            "fmeasure": 0.56809
        },
        "rougeL": {
            "precision": 0.7409,
            "recall": 0.66066,
            "fmeasure": 0.69045
        },
        "rougeLsum": {
            "precision": 0.7409,
            "recall": 0.66066,
            "fmeasure": 0.69045
        },
        "bleu": 50.44351,
        "meteor": 0.41194016569268244,
        "bertscore": {
            "precision": 0.94602,
            "recall": 0.9359,
            "f1": 0.9392
        },
        "nubia": {
            "semantic_relation": 4.36607,
            "contradiction": 7.55597,
            "irrelevancy": 23.85157,
            "logical_agreement": 68.59246,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.62899,
            "nubia_score": 0.74111
        },
        "bleurt": 0.37494
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "total_length": 382,
        "mean_pred_length": 16.608695652173914,
        "std_pred_length": 5.071138543242898,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.6047120418848168,
        "vocab_size-1": 231,
        "unique-1": 197,
        "entropy-1": 7.062837744243658,
        "distinct-2": 0.9220055710306406,
        "vocab_size-2": 331,
        "unique-2": 313,
        "entropy-2": 8.30707721212507,
        "cond_entropy-2": 1.1004986128102998,
        "distinct-3": 0.9761904761904762,
        "vocab_size-3": 328,
        "unique-3": 322,
        "entropy-3": 8.340204997170702,
        "cond_entropy-3": 0.04550143057848941,
        "total_length-nopunct": 328,
        "mean_pred_length-nopunct": 14.26086956521739,
        "std_pred_length-nopunct": 4.162121023921502,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6859756097560976,
        "vocab_size-1-nopunct": 225,
        "unique-1-nopunct": 197,
        "entropy-1-nopunct": 7.207729813367122,
        "distinct-2-nopunct": 0.9377049180327869,
        "vocab_size-2-nopunct": 286,
        "unique-2-nopunct": 274,
        "entropy-2-nopunct": 8.106340217751546,
        "cond_entropy-2-nopunct": 0.9735643319190795,
        "distinct-3-nopunct": 0.9893617021276596,
        "vocab_size-3-nopunct": 279,
        "unique-3-nopunct": 277,
        "entropy-3-nopunct": 8.115597850618107,
        "cond_entropy-3-nopunct": 0.017645859597223125,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3132530120481928,
            "3": 0.7366255144032922
        },
        "nist": 6.226127583120005,
        "rouge1": {
            "precision": 0.75214,
            "recall": 0.70525,
            "fmeasure": 0.71378
        },
        "rouge2": {
            "precision": 0.52818,
            "recall": 0.50345,
            "fmeasure": 0.50415
        },
        "rougeL": {
            "precision": 0.65751,
            "recall": 0.62095,
            "fmeasure": 0.62632
        },
        "rougeLsum": {
            "precision": 0.65751,
            "recall": 0.62095,
            "fmeasure": 0.62632
        },
        "bleu": 45.04461,
        "meteor": 0.3659494447925335,
        "bertscore": {
            "precision": 0.92813,
            "recall": 0.91352,
            "f1": 0.91889
        },
        "nubia": {
            "semantic_relation": 4.06227,
            "contradiction": 9.46148,
            "irrelevancy": 32.28776,
            "logical_agreement": 58.25076,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.41671,
            "nubia_score": 0.70057
        },
        "bleurt": 0.18653
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.77,
        "msttr-100_nopunct": NaN,
        "total_length": 105,
        "mean_pred_length": 17.5,
        "std_pred_length": 3.640054944640259,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7523809523809524,
        "vocab_size-1": 79,
        "unique-1": 67,
        "entropy-1": 6.070590194566364,
        "distinct-2": 1.0,
        "vocab_size-2": 99,
        "unique-2": 99,
        "entropy-2": 6.62935662007962,
        "cond_entropy-2": 0.48050674333305443,
        "distinct-3": 1.0,
        "vocab_size-3": 93,
        "unique-3": 93,
        "entropy-3": 6.539158811108037,
        "cond_entropy-3": -0.0901978089715783,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 3.815174380753199,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8152173913043478,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.045581864197924,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.426264754702099,
        "cond_entropy-2-nopunct": 0.41403033877342343,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.10433665981473575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.0,
            "3": 0.8846153846153846
        },
        "nist": 5.366354669112182,
        "rouge1": {
            "precision": 0.79619,
            "recall": 0.89071,
            "fmeasure": 0.83199
        },
        "rouge2": {
            "precision": 0.61234,
            "recall": 0.65708,
            "fmeasure": 0.62657
        },
        "rougeL": {
            "precision": 0.72607,
            "recall": 0.80715,
            "fmeasure": 0.75643
        },
        "rougeLsum": {
            "precision": 0.72607,
            "recall": 0.80715,
            "fmeasure": 0.75643
        },
        "bleu": 56.32458,
        "meteor": 0.46677588810392745,
        "bertscore": {
            "precision": 0.94345,
            "recall": 0.96149,
            "f1": 0.94879
        },
        "nubia": {
            "semantic_relation": 4.75464,
            "contradiction": 0.61803,
            "irrelevancy": 11.15282,
            "logical_agreement": 88.22915,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.40284,
            "nubia_score": 0.90297
        },
        "bleurt": 0.47875
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.735,
        "total_length": 289,
        "mean_pred_length": 15.210526315789474,
        "std_pred_length": 5.540083101869797,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5536332179930796,
        "vocab_size-1": 160,
        "unique-1": 125,
        "entropy-1": 6.671441823529255,
        "distinct-2": 0.8814814814814815,
        "vocab_size-2": 238,
        "unique-2": 216,
        "entropy-2": 7.805022715623975,
        "cond_entropy-2": 0.9613866080002353,
        "distinct-3": 0.952191235059761,
        "vocab_size-3": 239,
        "unique-3": 229,
        "entropy-3": 7.869910984212411,
        "cond_entropy-3": 0.07749410423431226,
        "total_length-nopunct": 264,
        "mean_pred_length-nopunct": 13.894736842105264,
        "std_pred_length-nopunct": 5.543082335023826,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5946969696969697,
        "vocab_size-1-nopunct": 157,
        "unique-1-nopunct": 124,
        "entropy-1-nopunct": 6.741597110977966,
        "distinct-2-nopunct": 0.8775510204081632,
        "vocab_size-2-nopunct": 215,
        "unique-2-nopunct": 195,
        "entropy-2-nopunct": 7.6534376206954375,
        "cond_entropy-2-nopunct": 0.9924655838367523,
        "distinct-3-nopunct": 0.9513274336283186,
        "vocab_size-3-nopunct": 215,
        "unique-3-nopunct": 206,
        "entropy-3-nopunct": 7.716153409298724,
        "cond_entropy-3-nopunct": 0.08209988616008275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23376623376623376,
            "2": 0.27450980392156865,
            "3": 0.6681034482758621
        },
        "nist": 5.201669717398667,
        "rouge1": {
            "precision": 0.76033,
            "recall": 0.66183,
            "fmeasure": 0.69149
        },
        "rouge2": {
            "precision": 0.55335,
            "recall": 0.49018,
            "fmeasure": 0.50701
        },
        "rougeL": {
            "precision": 0.69017,
            "recall": 0.59659,
            "fmeasure": 0.62441
        },
        "rougeLsum": {
            "precision": 0.69017,
            "recall": 0.59659,
            "fmeasure": 0.62441
        },
        "bleu": 44.95517,
        "meteor": 0.35748070742107446,
        "bertscore": {
            "precision": 0.92546,
            "recall": 0.90069,
            "f1": 0.91174
        },
        "nubia": {
            "semantic_relation": 4.04086,
            "contradiction": 8.85517,
            "irrelevancy": 33.75411,
            "logical_agreement": 57.39071,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.70621,
            "nubia_score": 0.64863
        },
        "bleurt": 0.18704
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.72,
        "total_length": 168,
        "mean_pred_length": 16.8,
        "std_pred_length": 5.491812087098392,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.625,
        "vocab_size-1": 105,
        "unique-1": 85,
        "entropy-1": 6.210499937993157,
        "distinct-2": 0.9177215189873418,
        "vocab_size-2": 145,
        "unique-2": 134,
        "entropy-2": 7.129668248149731,
        "cond_entropy-2": 0.8320367427333831,
        "distinct-3": 0.9797297297297297,
        "vocab_size-3": 145,
        "unique-3": 142,
        "entropy-3": 7.168912825088407,
        "cond_entropy-3": 0.0402997289626968,
        "total_length-nopunct": 151,
        "mean_pred_length-nopunct": 15.1,
        "std_pred_length-nopunct": 5.5578772926361015,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6688741721854304,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.212617633433803,
        "distinct-2-nopunct": 0.9219858156028369,
        "vocab_size-2-nopunct": 130,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.972815359460287,
        "cond_entropy-2-nopunct": 0.8033746484198994,
        "distinct-3-nopunct": 0.9770992366412213,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 125,
        "entropy-3-nopunct": 6.9876214748198935,
        "cond_entropy-3-nopunct": -0.004297434808788722,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3225806451612903,
            "2": 0.275,
            "3": 0.7117117117117117
        },
        "nist": 5.108890717466978,
        "rouge1": {
            "precision": 0.72174,
            "recall": 0.70113,
            "fmeasure": 0.70221
        },
        "rouge2": {
            "precision": 0.4412,
            "recall": 0.43424,
            "fmeasure": 0.43226
        },
        "rougeL": {
            "precision": 0.63293,
            "recall": 0.61858,
            "fmeasure": 0.61786
        },
        "rougeLsum": {
            "precision": 0.63293,
            "recall": 0.61858,
            "fmeasure": 0.61786
        },
        "bleu": 35.10329,
        "meteor": 0.33138004267774984,
        "bertscore": {
            "precision": 0.90456,
            "recall": 0.9097,
            "f1": 0.90446
        },
        "nubia": {
            "semantic_relation": 4.14071,
            "contradiction": 19.5979,
            "irrelevancy": 33.37757,
            "logical_agreement": 47.02453,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.6259,
            "nubia_score": 0.71037
        },
        "bleurt": 0.12946
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.65,
        "total_length": 278,
        "mean_pred_length": 18.533333333333335,
        "std_pred_length": 5.377318621353542,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.5143884892086331,
        "vocab_size-1": 143,
        "unique-1": 103,
        "entropy-1": 6.52626225600109,
        "distinct-2": 0.870722433460076,
        "vocab_size-2": 229,
        "unique-2": 202,
        "entropy-2": 7.75080325731203,
        "cond_entropy-2": 1.1074068336771195,
        "distinct-3": 0.9435483870967742,
        "vocab_size-3": 234,
        "unique-3": 220,
        "entropy-3": 7.841293084580446,
        "cond_entropy-3": 0.09985166589625569,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 5.148462553682086,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5582329317269076,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 103,
        "entropy-1-nopunct": 6.551762666564582,
        "distinct-2-nopunct": 0.8675213675213675,
        "vocab_size-2-nopunct": 203,
        "unique-2-nopunct": 179,
        "entropy-2-nopunct": 7.5721833626995565,
        "cond_entropy-2-nopunct": 1.0885987473363152,
        "distinct-3-nopunct": 0.9452054794520548,
        "vocab_size-3-nopunct": 207,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 7.665198018505291,
        "cond_entropy-3-nopunct": 0.10430561632287137,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.25,
            "3": 0.7368421052631579
        },
        "nist": 5.188913068656887,
        "rouge1": {
            "precision": 0.68241,
            "recall": 0.67329,
            "fmeasure": 0.66728
        },
        "rouge2": {
            "precision": 0.40163,
            "recall": 0.40093,
            "fmeasure": 0.39457
        },
        "rougeL": {
            "precision": 0.57151,
            "recall": 0.56537,
            "fmeasure": 0.56044
        },
        "rougeLsum": {
            "precision": 0.57151,
            "recall": 0.56537,
            "fmeasure": 0.56044
        },
        "bleu": 35.18104,
        "meteor": 0.35133183399436746,
        "bertscore": {
            "precision": 0.8901,
            "recall": 0.90594,
            "f1": 0.89682
        },
        "nubia": {
            "semantic_relation": 4.11784,
            "contradiction": 5.49528,
            "irrelevancy": 45.96715,
            "logical_agreement": 48.53757,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.51165,
            "nubia_score": 0.69056
        },
        "bleurt": 0.11253
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 90,
        "mean_pred_length": 15.0,
        "std_pred_length": 6.027713773341708,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 66,
        "unique-1": 54,
        "entropy-1": 5.813035497109658,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 81,
        "unique-2": 78,
        "entropy-2": 6.320888851350189,
        "cond_entropy-2": 0.4181303199653244,
        "distinct-3": 0.9871794871794872,
        "vocab_size-3": 77,
        "unique-3": 76,
        "entropy-3": 6.259761193221231,
        "cond_entropy-3": -0.05563315263446058,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.795831523312719,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7948717948717948,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.7632348348468625,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.086591668108984,
        "cond_entropy-2-nopunct": 0.3529818930411831,
        "distinct-3-nopunct": 0.9848484848484849,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.014091089055431,
        "cond_entropy-3-nopunct": -0.08007633662931363,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.2222222222222222,
            "3": 0.5324675324675324
        },
        "nist": 2.652786973947847,
        "rouge1": {
            "precision": 0.71304,
            "recall": 0.50011,
            "fmeasure": 0.57867
        },
        "rouge2": {
            "precision": 0.36588,
            "recall": 0.28961,
            "fmeasure": 0.31719
        },
        "rougeL": {
            "precision": 0.55779,
            "recall": 0.43471,
            "fmeasure": 0.47784
        },
        "rougeLsum": {
            "precision": 0.55779,
            "recall": 0.43471,
            "fmeasure": 0.47784
        },
        "bleu": 16.25933,
        "meteor": 0.2553743742040002,
        "bertscore": {
            "precision": 0.90643,
            "recall": 0.85123,
            "f1": 0.8744
        },
        "nubia": {
            "semantic_relation": 3.66363,
            "contradiction": 9.02383,
            "irrelevancy": 32.66797,
            "logical_agreement": 58.3082,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.17228,
            "nubia_score": 0.53115
        },
        "bleurt": -0.1113
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 898,
        "msttr-100": 0.7024,
        "msttr-100_nopunct": 0.7569,
        "total_length": 10032,
        "mean_pred_length": 11.171492204899778,
        "std_pred_length": 3.82373175044778,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 27,
        "distinct-1": 0.3256578947368421,
        "vocab_size-1": 3267,
        "unique-1": 2457,
        "entropy-1": 8.983610555094153,
        "distinct-2": 0.6582001313772717,
        "vocab_size-2": 6012,
        "unique-2": 5183,
        "entropy-2": 11.793179002330465,
        "cond_entropy-2": 2.272073073961904,
        "distinct-3": 0.8076736279747451,
        "vocab_size-3": 6652,
        "unique-3": 6017,
        "entropy-3": 12.41977958320091,
        "cond_entropy-3": 0.5934680072435494,
        "total_length-nopunct": 8738,
        "mean_pred_length-nopunct": 9.730512249443207,
        "std_pred_length-nopunct": 3.3720295786437897,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.3725108720531014,
        "vocab_size-1-nopunct": 3255,
        "unique-1-nopunct": 2455,
        "entropy-1-nopunct": 9.44533028475914,
        "distinct-2-nopunct": 0.6830357142857143,
        "vocab_size-2-nopunct": 5355,
        "unique-2-nopunct": 4691,
        "entropy-2-nopunct": 11.65701159839948,
        "cond_entropy-2-nopunct": 2.4070250747465987,
        "distinct-3-nopunct": 0.817199654278306,
        "vocab_size-3-nopunct": 5673,
        "unique-3-nopunct": 5151,
        "entropy-3-nopunct": 12.20504438668868,
        "cond_entropy-3-nopunct": 0.6346827595120687,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25059856344772546,
            "2": 0.5437100213219617,
            "3": 0.7512483817273904
        },
        "nist": 8.742711206148448,
        "rouge1": {
            "precision": 0.73656,
            "recall": 0.72255,
            "fmeasure": 0.71312
        },
        "rouge2": {
            "precision": 0.54971,
            "recall": 0.54136,
            "fmeasure": 0.53235
        },
        "rougeL": {
            "precision": 0.69622,
            "recall": 0.6867,
            "fmeasure": 0.67598
        },
        "rougeLsum": {
            "precision": 0.69622,
            "recall": 0.6867,
            "fmeasure": 0.67598
        },
        "bleu": 50.30034,
        "meteor": 0.4054919446387927,
        "bertscore": {
            "precision": 0.92864,
            "recall": 0.92547,
            "f1": 0.92537
        },
        "nubia": {
            "semantic_relation": 4.04808,
            "contradiction": 9.80562,
            "irrelevancy": 33.59942,
            "logical_agreement": 56.59496,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.01377,
            "nubia_score": 0.70247
        },
        "bleurt": 0.3123
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 389,
        "msttr-100": 0.30394,
        "msttr-100_nopunct": 0.29852,
        "total_length": 6675,
        "mean_pred_length": 17.159383033419022,
        "std_pred_length": 4.348600889535973,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.030711610486891385,
        "vocab_size-1": 205,
        "unique-1": 30,
        "entropy-1": 6.132908144629586,
        "distinct-2": 0.09863188036907414,
        "vocab_size-2": 620,
        "unique-2": 149,
        "entropy-2": 7.895123238678635,
        "cond_entropy-2": 1.6446781086828826,
        "distinct-3": 0.16550788536544006,
        "vocab_size-3": 976,
        "unique-3": 298,
        "entropy-3": 8.826224180145843,
        "cond_entropy-3": 0.944320829487691,
        "total_length-nopunct": 6152,
        "mean_pred_length-nopunct": 15.814910025706942,
        "std_pred_length-nopunct": 4.03030726655621,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.03299739921976593,
        "vocab_size-1-nopunct": 203,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 6.182005901235226,
        "distinct-2-nopunct": 0.10098906819364914,
        "vocab_size-2-nopunct": 582,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.77800479616853,
        "cond_entropy-2-nopunct": 1.665155901289113,
        "distinct-3-nopunct": 0.1708224786006699,
        "vocab_size-3-nopunct": 918,
        "unique-3-nopunct": 282,
        "entropy-3-nopunct": 8.764670667818455,
        "cond_entropy-3-nopunct": 0.973025780280725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6347373556675883
        },
        "nist": 4.54721127260106,
        "rouge1": {
            "precision": 0.69545,
            "recall": 0.65137,
            "fmeasure": 0.65873
        },
        "rouge2": {
            "precision": 0.42298,
            "recall": 0.39284,
            "fmeasure": 0.39857
        },
        "rougeL": {
            "precision": 0.54005,
            "recall": 0.50093,
            "fmeasure": 0.50918
        },
        "rougeLsum": {
            "precision": 0.54005,
            "recall": 0.50093,
            "fmeasure": 0.50918
        },
        "bleu": 27.01379,
        "meteor": 0.33229698874180014,
        "bertscore": {
            "precision": 0.90729,
            "recall": 0.89736,
            "f1": 0.90182
        },
        "nubia": {
            "semantic_relation": 4.0789,
            "contradiction": 4.0139,
            "irrelevancy": 35.68419,
            "logical_agreement": 60.30191,
            "grammar_ref": 5.31197,
            "grammar_hyp": 5.00677,
            "nubia_score": 0.70849
        },
        "bleurt": 0.07415
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.77,
        "total_length": 183,
        "mean_pred_length": 16.636363636363637,
        "std_pred_length": 4.676298599858795,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6284153005464481,
        "vocab_size-1": 115,
        "unique-1": 89,
        "entropy-1": 6.41194335238578,
        "distinct-2": 0.9418604651162791,
        "vocab_size-2": 162,
        "unique-2": 155,
        "entropy-2": 7.293968897131351,
        "cond_entropy-2": 0.750264369718193,
        "distinct-3": 1.0,
        "vocab_size-3": 161,
        "unique-3": 161,
        "entropy-3": 7.330916878114602,
        "cond_entropy-3": 0.04598682839490082,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 14.454545454545455,
        "std_pred_length-nopunct": 4.250425355476712,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6855345911949685,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.408803672505378,
        "distinct-2-nopunct": 0.9391891891891891,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.069217639262978,
        "cond_entropy-2-nopunct": 0.70733877831548,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 137,
        "unique-3-nopunct": 137,
        "entropy-3-nopunct": 7.098032082960511,
        "cond_entropy-3-nopunct": 0.03277497647145622,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.2857142857142857,
            "3": 0.6692913385826772
        },
        "nist": 4.831468367032386,
        "rouge1": {
            "precision": 0.67276,
            "recall": 0.66995,
            "fmeasure": 0.66066
        },
        "rouge2": {
            "precision": 0.44287,
            "recall": 0.46015,
            "fmeasure": 0.44402
        },
        "rougeL": {
            "precision": 0.59046,
            "recall": 0.5848,
            "fmeasure": 0.57979
        },
        "rougeLsum": {
            "precision": 0.59046,
            "recall": 0.5848,
            "fmeasure": 0.57979
        },
        "bleu": 37.75767,
        "meteor": 0.3243165913286603,
        "bertscore": {
            "precision": 0.8968,
            "recall": 0.90032,
            "f1": 0.89399
        },
        "nubia": {
            "semantic_relation": 3.82938,
            "contradiction": 10.57784,
            "irrelevancy": 47.34408,
            "logical_agreement": 42.07808,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.36934,
            "nubia_score": 0.63655
        },
        "bleurt": 0.04761
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.692,
        "msttr-100_nopunct": 0.755,
        "total_length": 537,
        "mean_pred_length": 17.322580645161292,
        "std_pred_length": 5.00571993323118,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5381750465549349,
        "vocab_size-1": 289,
        "unique-1": 231,
        "entropy-1": 7.1911805684039285,
        "distinct-2": 0.8735177865612648,
        "vocab_size-2": 442,
        "unique-2": 406,
        "entropy-2": 8.645758536692403,
        "cond_entropy-2": 1.3158893644122605,
        "distinct-3": 0.9515789473684211,
        "vocab_size-3": 452,
        "unique-3": 430,
        "entropy-3": 8.793352361108425,
        "cond_entropy-3": 0.16539232163304612,
        "total_length-nopunct": 483,
        "mean_pred_length-nopunct": 15.580645161290322,
        "std_pred_length-nopunct": 4.811104048387654,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.587991718426501,
        "vocab_size-1-nopunct": 284,
        "unique-1-nopunct": 230,
        "entropy-1-nopunct": 7.30556776004313,
        "distinct-2-nopunct": 0.8716814159292036,
        "vocab_size-2-nopunct": 394,
        "unique-2-nopunct": 362,
        "entropy-2-nopunct": 8.472543665457996,
        "cond_entropy-2-nopunct": 1.2571301867890678,
        "distinct-3-nopunct": 0.9453681710213777,
        "vocab_size-3-nopunct": 398,
        "unique-3-nopunct": 376,
        "entropy-3-nopunct": 8.606619683156246,
        "cond_entropy-3-nopunct": 0.15729856925565258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20253164556962025,
            "2": 0.4111111111111111,
            "3": 0.6845070422535211
        },
        "nist": 5.935648002596438,
        "rouge1": {
            "precision": 0.69555,
            "recall": 0.67984,
            "fmeasure": 0.67591
        },
        "rouge2": {
            "precision": 0.45839,
            "recall": 0.44771,
            "fmeasure": 0.44618
        },
        "rougeL": {
            "precision": 0.57259,
            "recall": 0.56617,
            "fmeasure": 0.55976
        },
        "rougeLsum": {
            "precision": 0.57259,
            "recall": 0.56617,
            "fmeasure": 0.55976
        },
        "bleu": 38.76698,
        "meteor": 0.3589976076125233,
        "bertscore": {
            "precision": 0.905,
            "recall": 0.90136,
            "f1": 0.90149
        },
        "nubia": {
            "semantic_relation": 3.93802,
            "contradiction": 10.4629,
            "irrelevancy": 37.26034,
            "logical_agreement": 52.27677,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.50352,
            "nubia_score": 0.66634
        },
        "bleurt": 0.11456
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "total_length": 339,
        "mean_pred_length": 16.142857142857142,
        "std_pred_length": 3.481730744843983,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6076696165191741,
        "vocab_size-1": 206,
        "unique-1": 170,
        "entropy-1": 6.9949463568475,
        "distinct-2": 0.940251572327044,
        "vocab_size-2": 299,
        "unique-2": 288,
        "entropy-2": 8.16233483270284,
        "cond_entropy-2": 0.9704558700494187,
        "distinct-3": 0.9932659932659933,
        "vocab_size-3": 295,
        "unique-3": 293,
        "entropy-3": 8.20085110733278,
        "cond_entropy-3": 0.04242708464411181,
        "total_length-nopunct": 299,
        "mean_pred_length-nopunct": 14.238095238095237,
        "std_pred_length-nopunct": 3.160843195290684,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6722408026755853,
        "vocab_size-1-nopunct": 201,
        "unique-1-nopunct": 169,
        "entropy-1-nopunct": 7.109325586771342,
        "distinct-2-nopunct": 0.9496402877697842,
        "vocab_size-2-nopunct": 264,
        "unique-2-nopunct": 257,
        "entropy-2-nopunct": 7.98541799546172,
        "cond_entropy-2-nopunct": 0.9294133991049255,
        "distinct-3-nopunct": 0.9961089494163424,
        "vocab_size-3-nopunct": 256,
        "unique-3-nopunct": 255,
        "entropy-3-nopunct": 7.99784244802659,
        "cond_entropy-3-nopunct": 0.023334898566727703,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.4787234042553192,
            "3": 0.7474226804123711
        },
        "nist": 6.186396183066123,
        "rouge1": {
            "precision": 0.70929,
            "recall": 0.69514,
            "fmeasure": 0.69269
        },
        "rouge2": {
            "precision": 0.46522,
            "recall": 0.46429,
            "fmeasure": 0.45713
        },
        "rougeL": {
            "precision": 0.57955,
            "recall": 0.57606,
            "fmeasure": 0.57235
        },
        "rougeLsum": {
            "precision": 0.57955,
            "recall": 0.57606,
            "fmeasure": 0.57235
        },
        "bleu": 41.08175,
        "meteor": 0.36795288288779077,
        "bertscore": {
            "precision": 0.92107,
            "recall": 0.91822,
            "f1": 0.91765
        },
        "nubia": {
            "semantic_relation": 3.94215,
            "contradiction": 11.04089,
            "irrelevancy": 44.35673,
            "logical_agreement": 44.60238,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.69128,
            "nubia_score": 0.64863
        },
        "bleurt": 0.1906
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.25
        },
        "nist": 0.9004550478590886,
        "rouge1": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.25,
            "fmeasure": 0.26087
        },
        "bleu": 4.10053,
        "meteor": 0.20820514588127764,
        "bertscore": {
            "precision": 0.80906,
            "recall": 0.8319,
            "f1": 0.82032
        },
        "nubia": {
            "semantic_relation": 2.63837,
            "contradiction": 0.39848,
            "irrelevancy": 99.52784,
            "logical_agreement": 0.07367,
            "grammar_ref": 3.85254,
            "grammar_hyp": 4.92055,
            "nubia_score": 0.21817
        },
        "bleurt": -0.57268
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76,
        "total_length": 668,
        "mean_pred_length": 15.904761904761905,
        "std_pred_length": 4.341436693349135,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5434131736526946,
        "vocab_size-1": 363,
        "unique-1": 288,
        "entropy-1": 7.544141974751226,
        "distinct-2": 0.8961661341853036,
        "vocab_size-2": 561,
        "unique-2": 514,
        "entropy-2": 9.04509342755158,
        "cond_entropy-2": 1.2787870149893028,
        "distinct-3": 0.9743150684931506,
        "vocab_size-3": 569,
        "unique-3": 555,
        "entropy-3": 9.137162080280333,
        "cond_entropy-3": 0.09940917946501587,
        "total_length-nopunct": 589,
        "mean_pred_length-nopunct": 14.023809523809524,
        "std_pred_length-nopunct": 4.148941891719102,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6061120543293718,
        "vocab_size-1-nopunct": 357,
        "unique-1-nopunct": 288,
        "entropy-1-nopunct": 7.739374620807911,
        "distinct-2-nopunct": 0.8957952468007313,
        "vocab_size-2-nopunct": 490,
        "unique-2-nopunct": 450,
        "entropy-2-nopunct": 8.845728969720732,
        "cond_entropy-2-nopunct": 1.191612456601023,
        "distinct-3-nopunct": 0.9801980198019802,
        "vocab_size-3-nopunct": 495,
        "unique-3-nopunct": 485,
        "entropy-3-nopunct": 8.940535617243047,
        "cond_entropy-3-nopunct": 0.10567012916400244,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22413793103448276,
            "2": 0.5188679245283019,
            "3": 0.7865168539325843
        },
        "nist": 6.9365359001435,
        "rouge1": {
            "precision": 0.76575,
            "recall": 0.7596,
            "fmeasure": 0.75556
        },
        "rouge2": {
            "precision": 0.51558,
            "recall": 0.51531,
            "fmeasure": 0.50999
        },
        "rougeL": {
            "precision": 0.65676,
            "recall": 0.65277,
            "fmeasure": 0.64851
        },
        "rougeLsum": {
            "precision": 0.65676,
            "recall": 0.65277,
            "fmeasure": 0.64851
        },
        "bleu": 43.93937,
        "meteor": 0.4039489199341569,
        "bertscore": {
            "precision": 0.93193,
            "recall": 0.92932,
            "f1": 0.92925
        },
        "nubia": {
            "semantic_relation": 4.24335,
            "contradiction": 9.64753,
            "irrelevancy": 33.80386,
            "logical_agreement": 56.54861,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.53892,
            "nubia_score": 0.74955
        },
        "bleurt": 0.26409
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.77333,
        "total_length": 379,
        "mean_pred_length": 16.47826086956522,
        "std_pred_length": 5.88195150414932,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5989445910290238,
        "vocab_size-1": 227,
        "unique-1": 192,
        "entropy-1": 7.036693816156359,
        "distinct-2": 0.9241573033707865,
        "vocab_size-2": 329,
        "unique-2": 311,
        "entropy-2": 8.301185775102896,
        "cond_entropy-2": 1.1204939904312834,
        "distinct-3": 0.9819819819819819,
        "vocab_size-3": 327,
        "unique-3": 322,
        "entropy-3": 8.34107540159933,
        "cond_entropy-3": 0.03766652914717862,
        "total_length-nopunct": 322,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.0819373231595195,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6863354037267081,
        "vocab_size-1-nopunct": 221,
        "unique-1-nopunct": 190,
        "entropy-1-nopunct": 7.231931547205996,
        "distinct-2-nopunct": 0.9364548494983278,
        "vocab_size-2-nopunct": 280,
        "unique-2-nopunct": 267,
        "entropy-2-nopunct": 8.077264874930748,
        "cond_entropy-2-nopunct": 0.9178808197321026,
        "distinct-3-nopunct": 0.9927536231884058,
        "vocab_size-3-nopunct": 274,
        "unique-3-nopunct": 272,
        "entropy-3-nopunct": 8.09403170315494,
        "cond_entropy-3-nopunct": 0.02899489482980049,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2602739726027397,
            "2": 0.37209302325581395,
            "3": 0.7905982905982906
        },
        "nist": 6.720708681433587,
        "rouge1": {
            "precision": 0.78128,
            "recall": 0.73932,
            "fmeasure": 0.75114
        },
        "rouge2": {
            "precision": 0.60066,
            "recall": 0.5681,
            "fmeasure": 0.57712
        },
        "rougeL": {
            "precision": 0.6958,
            "recall": 0.67294,
            "fmeasure": 0.67695
        },
        "rougeLsum": {
            "precision": 0.6958,
            "recall": 0.67294,
            "fmeasure": 0.67695
        },
        "bleu": 54.26662,
        "meteor": 0.41213715688460734,
        "bertscore": {
            "precision": 0.94347,
            "recall": 0.93164,
            "f1": 0.93353
        },
        "nubia": {
            "semantic_relation": 4.23838,
            "contradiction": 6.83576,
            "irrelevancy": 31.19928,
            "logical_agreement": 61.96495,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.47397,
            "nubia_score": 0.74797
        },
        "bleurt": 0.35326
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 17.4,
        "std_pred_length": 7.49933330370107,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.735632183908046,
        "vocab_size-1": 64,
        "unique-1": 56,
        "entropy-1": 5.705714007487603,
        "distinct-2": 0.9878048780487805,
        "vocab_size-2": 81,
        "unique-2": 80,
        "entropy-2": 6.333161760715647,
        "cond_entropy-2": 0.5591359856945771,
        "distinct-3": 1.0,
        "vocab_size-3": 77,
        "unique-3": 77,
        "entropy-3": 6.266786540694905,
        "cond_entropy-3": -0.06479143794915666,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 5.946427498927402,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8108108108108109,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.709189176322821,
        "distinct-2-nopunct": 0.9855072463768116,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.079538949531787,
        "cond_entropy-2-nopunct": 0.40660080141956517,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.0,
        "cond_entropy-3-nopunct": -0.07727445677816912,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 5.119041651523298,
        "rouge1": {
            "precision": 0.831,
            "recall": 0.69831,
            "fmeasure": 0.75695
        },
        "rouge2": {
            "precision": 0.57333,
            "recall": 0.48354,
            "fmeasure": 0.52324
        },
        "rougeL": {
            "precision": 0.74722,
            "recall": 0.62732,
            "fmeasure": 0.68026
        },
        "rougeLsum": {
            "precision": 0.74722,
            "recall": 0.62732,
            "fmeasure": 0.68026
        },
        "bleu": 45.70138,
        "meteor": 0.3904906376764797,
        "bertscore": {
            "precision": 0.94968,
            "recall": 0.92472,
            "f1": 0.93697
        },
        "nubia": {
            "semantic_relation": 4.26885,
            "contradiction": 0.39828,
            "irrelevancy": 20.85735,
            "logical_agreement": 78.74437,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.87061,
            "nubia_score": 0.76165
        },
        "bleurt": 0.36311
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.9,
        "vocab_size-1": 36,
        "unique-1": 33,
        "entropy-1": 5.103055907333276,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": -0.004366621150304511,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.969815782426808,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": -0.00423427279894796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.42857142857142855,
            "3": 0.8928571428571429
        },
        "nist": 5.265308084279512,
        "rouge1": {
            "precision": 0.91481,
            "recall": 0.81136,
            "fmeasure": 0.8526
        },
        "rouge2": {
            "precision": 0.71252,
            "recall": 0.62542,
            "fmeasure": 0.65634
        },
        "rougeL": {
            "precision": 0.85926,
            "recall": 0.76231,
            "fmeasure": 0.79861
        },
        "rougeLsum": {
            "precision": 0.85926,
            "recall": 0.76231,
            "fmeasure": 0.79861
        },
        "bleu": 56.37268,
        "meteor": 0.4515306845091101,
        "bertscore": {
            "precision": 0.9462,
            "recall": 0.94736,
            "f1": 0.94672
        },
        "nubia": {
            "semantic_relation": 4.60654,
            "contradiction": 0.67578,
            "irrelevancy": 33.11553,
            "logical_agreement": 66.20869,
            "grammar_ref": 5.80868,
            "grammar_hyp": 6.18013,
            "nubia_score": 0.81953
        },
        "bleurt": 0.27137
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.67,
        "total_length": 146,
        "mean_pred_length": 14.6,
        "std_pred_length": 5.553377350765928,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5273972602739726,
        "vocab_size-1": 77,
        "unique-1": 54,
        "entropy-1": 5.7206706149332645,
        "distinct-2": 0.7794117647058824,
        "vocab_size-2": 106,
        "unique-2": 91,
        "entropy-2": 6.4962596942363025,
        "cond_entropy-2": 0.6738406559683899,
        "distinct-3": 0.8650793650793651,
        "vocab_size-3": 109,
        "unique-3": 99,
        "entropy-3": 6.650935356208148,
        "cond_entropy-3": 0.1479863283843453,
        "total_length-nopunct": 131,
        "mean_pred_length-nopunct": 13.1,
        "std_pred_length-nopunct": 5.146843692983109,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5725190839694656,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.732221659560976,
        "distinct-2-nopunct": 0.7851239669421488,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.3267248861031575,
        "cond_entropy-2-nopunct": 0.6048926969355761,
        "distinct-3-nopunct": 0.8648648648648649,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.460006717892788,
        "cond_entropy-3-nopunct": 0.131042719269552,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06779661016949153,
            "2": 0.11538461538461539,
            "3": 0.6568627450980392
        },
        "nist": 3.83770725175417,
        "rouge1": {
            "precision": 0.6668,
            "recall": 0.63714,
            "fmeasure": 0.62219
        },
        "rouge2": {
            "precision": 0.39451,
            "recall": 0.39046,
            "fmeasure": 0.37048
        },
        "rougeL": {
            "precision": 0.53306,
            "recall": 0.52808,
            "fmeasure": 0.50663
        },
        "rougeLsum": {
            "precision": 0.53306,
            "recall": 0.52808,
            "fmeasure": 0.50663
        },
        "bleu": 20.71631,
        "meteor": 0.3097775219533083,
        "bertscore": {
            "precision": 0.90696,
            "recall": 0.90014,
            "f1": 0.90078
        },
        "nubia": {
            "semantic_relation": 3.9137,
            "contradiction": 9.06417,
            "irrelevancy": 40.78387,
            "logical_agreement": 50.15196,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.47629,
            "nubia_score": 0.63581
        },
        "bleurt": 0.19414
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.722,
        "msttr-100_nopunct": 0.764,
        "total_length": 578,
        "mean_pred_length": 16.514285714285716,
        "std_pred_length": 6.03499995772957,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5536332179930796,
        "vocab_size-1": 320,
        "unique-1": 256,
        "entropy-1": 7.424093318505531,
        "distinct-2": 0.9097605893186004,
        "vocab_size-2": 494,
        "unique-2": 464,
        "entropy-2": 8.85672648829798,
        "cond_entropy-2": 1.3167357481869022,
        "distinct-3": 0.9744094488188977,
        "vocab_size-3": 495,
        "unique-3": 484,
        "entropy-3": 8.93453158637002,
        "cond_entropy-3": 0.08958239429779913,
        "total_length-nopunct": 517,
        "mean_pred_length-nopunct": 14.771428571428572,
        "std_pred_length-nopunct": 5.575895645086802,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6073500967117988,
        "vocab_size-1-nopunct": 314,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.559711116050359,
        "distinct-2-nopunct": 0.9107883817427386,
        "vocab_size-2-nopunct": 439,
        "unique-2-nopunct": 414,
        "entropy-2-nopunct": 8.682404722267671,
        "cond_entropy-2-nopunct": 1.1996510179958408,
        "distinct-3-nopunct": 0.9753914988814317,
        "vocab_size-3-nopunct": 436,
        "unique-3-nopunct": 427,
        "entropy-3-nopunct": 8.75153644622961,
        "cond_entropy-3-nopunct": 0.0804672082765638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26804123711340205,
            "2": 0.32432432432432434,
            "3": 0.7374301675977654
        },
        "nist": 6.406876026840465,
        "rouge1": {
            "precision": 0.72053,
            "recall": 0.68281,
            "fmeasure": 0.68917
        },
        "rouge2": {
            "precision": 0.48134,
            "recall": 0.45242,
            "fmeasure": 0.45872
        },
        "rougeL": {
            "precision": 0.63431,
            "recall": 0.60433,
            "fmeasure": 0.60872
        },
        "rougeLsum": {
            "precision": 0.63431,
            "recall": 0.60433,
            "fmeasure": 0.60872
        },
        "bleu": 40.15942,
        "meteor": 0.3470357537585133,
        "bertscore": {
            "precision": 0.92449,
            "recall": 0.91083,
            "f1": 0.91517
        },
        "nubia": {
            "semantic_relation": 3.93197,
            "contradiction": 12.12434,
            "irrelevancy": 41.15729,
            "logical_agreement": 46.71837,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.66771,
            "nubia_score": 0.64251
        },
        "bleurt": 0.15545
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.76833,
        "total_length": 705,
        "mean_pred_length": 16.785714285714285,
        "std_pred_length": 4.925810130544708,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.548936170212766,
        "vocab_size-1": 387,
        "unique-1": 312,
        "entropy-1": 7.663707007365485,
        "distinct-2": 0.9019607843137255,
        "vocab_size-2": 598,
        "unique-2": 553,
        "entropy-2": 9.136660898824442,
        "cond_entropy-2": 1.2860537360527386,
        "distinct-3": 0.9694041867954911,
        "vocab_size-3": 602,
        "unique-3": 585,
        "entropy-3": 9.214826632126503,
        "cond_entropy-3": 0.0844790582202951,
        "total_length-nopunct": 624,
        "mean_pred_length-nopunct": 14.857142857142858,
        "std_pred_length-nopunct": 4.506986262467196,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6121794871794872,
        "vocab_size-1-nopunct": 382,
        "unique-1-nopunct": 312,
        "entropy-1-nopunct": 7.845781396480812,
        "distinct-2-nopunct": 0.9020618556701031,
        "vocab_size-2-nopunct": 525,
        "unique-2-nopunct": 488,
        "entropy-2-nopunct": 8.943288815530057,
        "cond_entropy-2-nopunct": 1.1674496390186437,
        "distinct-3-nopunct": 0.9685185185185186,
        "vocab_size-3-nopunct": 523,
        "unique-3-nopunct": 508,
        "entropy-3-nopunct": 9.011056754450165,
        "cond_entropy-3-nopunct": 0.08068777067654463,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19130434782608696,
            "2": 0.5053763440860215,
            "3": 0.7913223140495868
        },
        "nist": 7.033592841529103,
        "rouge1": {
            "precision": 0.78439,
            "recall": 0.78926,
            "fmeasure": 0.78096
        },
        "rouge2": {
            "precision": 0.57745,
            "recall": 0.58119,
            "fmeasure": 0.57465
        },
        "rougeL": {
            "precision": 0.68673,
            "recall": 0.69252,
            "fmeasure": 0.68316
        },
        "rougeLsum": {
            "precision": 0.68673,
            "recall": 0.69252,
            "fmeasure": 0.68316
        },
        "bleu": 50.1086,
        "meteor": 0.4254924471058902,
        "bertscore": {
            "precision": 0.93753,
            "recall": 0.94068,
            "f1": 0.93786
        },
        "nubia": {
            "semantic_relation": 4.34612,
            "contradiction": 12.13089,
            "irrelevancy": 25.22962,
            "logical_agreement": 62.63949,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.54044,
            "nubia_score": 0.77725
        },
        "bleurt": 0.36009
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.78,
        "total_length": 221,
        "mean_pred_length": 14.733333333333333,
        "std_pred_length": 4.878068834647125,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6515837104072398,
        "vocab_size-1": 144,
        "unique-1": 120,
        "entropy-1": 6.650205212896527,
        "distinct-2": 0.9466019417475728,
        "vocab_size-2": 195,
        "unique-2": 186,
        "entropy-2": 7.57237540580299,
        "cond_entropy-2": 0.771489337865622,
        "distinct-3": 0.9842931937172775,
        "vocab_size-3": 188,
        "unique-3": 185,
        "entropy-3": 7.5460152154703035,
        "cond_entropy-3": -0.03833989284209337,
        "total_length-nopunct": 196,
        "mean_pred_length-nopunct": 13.066666666666666,
        "std_pred_length-nopunct": 4.434210439550903,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7091836734693877,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.722893149081751,
        "distinct-2-nopunct": 0.9502762430939227,
        "vocab_size-2-nopunct": 172,
        "unique-2-nopunct": 165,
        "entropy-2-nopunct": 7.392057074904574,
        "cond_entropy-2-nopunct": 0.7080445911411681,
        "distinct-3-nopunct": 0.9879518072289156,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 162,
        "entropy-3-nopunct": 7.35094304580474,
        "cond_entropy-3-nopunct": -0.05047000993577084,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1346153846153846,
            "2": 0.3181818181818182,
            "3": 0.7834394904458599
        },
        "nist": 5.48532142691655,
        "rouge1": {
            "precision": 0.7883,
            "recall": 0.72429,
            "fmeasure": 0.74786
        },
        "rouge2": {
            "precision": 0.55124,
            "recall": 0.50699,
            "fmeasure": 0.52071
        },
        "rougeL": {
            "precision": 0.6751,
            "recall": 0.62596,
            "fmeasure": 0.64339
        },
        "rougeLsum": {
            "precision": 0.6751,
            "recall": 0.62596,
            "fmeasure": 0.64339
        },
        "bleu": 44.80419,
        "meteor": 0.37785764960847334,
        "bertscore": {
            "precision": 0.9311,
            "recall": 0.92301,
            "f1": 0.92644
        },
        "nubia": {
            "semantic_relation": 4.26414,
            "contradiction": 7.72808,
            "irrelevancy": 41.02556,
            "logical_agreement": 51.24636,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.77741,
            "nubia_score": 0.70984
        },
        "bleurt": 0.3001
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 21.333333333333332,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 21.0,
        "min_pred_length": 18,
        "max_pred_length": 25,
        "distinct-1": 0.65625,
        "vocab_size-1": 42,
        "unique-1": 31,
        "entropy-1": 5.119707868318166,
        "distinct-2": 0.8688524590163934,
        "vocab_size-2": 53,
        "unique-2": 46,
        "entropy-2": 5.656067050642169,
        "cond_entropy-2": 0.5017032625351885,
        "distinct-3": 0.9482758620689655,
        "vocab_size-3": 55,
        "unique-3": 52,
        "entropy-3": 5.754532719265501,
        "cond_entropy-3": 0.11267275242957327,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 3.681787005729087,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.093530485431945,
        "distinct-2-nopunct": 0.8490566037735849,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.411790501692188,
        "cond_entropy-2-nopunct": 0.35866517305038026,
        "distinct-3-nopunct": 0.94,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.523856189774728,
        "cond_entropy-3-nopunct": 0.13103348525479475,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5,
            "3": 0.8055555555555556
        },
        "nist": 3.607848475176596,
        "rouge1": {
            "precision": 0.61204,
            "recall": 0.69403,
            "fmeasure": 0.64619
        },
        "rouge2": {
            "precision": 0.39841,
            "recall": 0.46741,
            "fmeasure": 0.42712
        },
        "rougeL": {
            "precision": 0.45278,
            "recall": 0.52992,
            "fmeasure": 0.48468
        },
        "rougeLsum": {
            "precision": 0.45278,
            "recall": 0.52992,
            "fmeasure": 0.48468
        },
        "bleu": 28.65792,
        "meteor": 0.403064468911382,
        "bertscore": {
            "precision": 0.87206,
            "recall": 0.92413,
            "f1": 0.89528
        },
        "nubia": {
            "semantic_relation": 3.99544,
            "contradiction": 0.49457,
            "irrelevancy": 60.09694,
            "logical_agreement": 39.40849,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.13993,
            "nubia_score": 0.69336
        },
        "bleurt": -0.06404
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 221,
        "mean_pred_length": 15.785714285714286,
        "std_pred_length": 4.945106837334564,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.6515837104072398,
        "vocab_size-1": 144,
        "unique-1": 115,
        "entropy-1": 6.71621748052741,
        "distinct-2": 0.9516908212560387,
        "vocab_size-2": 197,
        "unique-2": 188,
        "entropy-2": 7.593221800484019,
        "cond_entropy-2": 0.7656509059425398,
        "distinct-3": 0.9948186528497409,
        "vocab_size-3": 192,
        "unique-3": 191,
        "entropy-3": 7.582094342967541,
        "cond_entropy-3": -0.02457972591951716,
        "total_length-nopunct": 196,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.551294949163998,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7091836734693877,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.741347527025923,
        "distinct-2-nopunct": 0.9560439560439561,
        "vocab_size-2-nopunct": 174,
        "unique-2-nopunct": 167,
        "entropy-2-nopunct": 7.4157348187582555,
        "cond_entropy-2-nopunct": 0.7099487474305843,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 168,
        "unique-3-nopunct": 168,
        "entropy-3-nopunct": 7.392317422778791,
        "cond_entropy-3-nopunct": -0.034614345391833695,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19672131147540983,
            "2": 0.45714285714285713,
            "3": 0.6666666666666666
        },
        "nist": 5.0276678082898885,
        "rouge1": {
            "precision": 0.7419,
            "recall": 0.67401,
            "fmeasure": 0.69817
        },
        "rouge2": {
            "precision": 0.49647,
            "recall": 0.45915,
            "fmeasure": 0.46964
        },
        "rougeL": {
            "precision": 0.62066,
            "recall": 0.55849,
            "fmeasure": 0.58044
        },
        "rougeLsum": {
            "precision": 0.62066,
            "recall": 0.55849,
            "fmeasure": 0.58044
        },
        "bleu": 39.85584,
        "meteor": 0.3560806949183795,
        "bertscore": {
            "precision": 0.92104,
            "recall": 0.91377,
            "f1": 0.91494
        },
        "nubia": {
            "semantic_relation": 4.07408,
            "contradiction": 9.69598,
            "irrelevancy": 43.8818,
            "logical_agreement": 46.42223,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.72769,
            "nubia_score": 0.69176
        },
        "bleurt": 0.18452
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 75,
        "msttr-100": 0.71167,
        "msttr-100_nopunct": 0.756,
        "total_length": 1244,
        "mean_pred_length": 16.586666666666666,
        "std_pred_length": 5.7806420250887545,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.4654340836012862,
        "vocab_size-1": 579,
        "unique-1": 444,
        "entropy-1": 7.878012914402145,
        "distinct-2": 0.8203592814371258,
        "vocab_size-2": 959,
        "unique-2": 843,
        "entropy-2": 9.713341048788433,
        "cond_entropy-2": 1.6161170424020215,
        "distinct-3": 0.9122486288848263,
        "vocab_size-3": 998,
        "unique-3": 937,
        "entropy-3": 9.88411568248002,
        "cond_entropy-3": 0.17782166015584464,
        "total_length-nopunct": 1078,
        "mean_pred_length-nopunct": 14.373333333333333,
        "std_pred_length-nopunct": 5.061681758291627,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5296846011131725,
        "vocab_size-1-nopunct": 571,
        "unique-1-nopunct": 442,
        "entropy-1-nopunct": 8.130799086646793,
        "distinct-2-nopunct": 0.8344965104685942,
        "vocab_size-2-nopunct": 837,
        "unique-2-nopunct": 749,
        "entropy-2-nopunct": 9.516398554850802,
        "cond_entropy-2-nopunct": 1.4780095792736352,
        "distinct-3-nopunct": 0.9256465517241379,
        "vocab_size-3-nopunct": 859,
        "unique-3-nopunct": 816,
        "entropy-3-nopunct": 9.676529595558726,
        "cond_entropy-3-nopunct": 0.1793747100836019,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2641509433962264,
            "2": 0.44907407407407407,
            "3": 0.7974522292993631
        },
        "nist": 7.788982461027905,
        "rouge1": {
            "precision": 0.79006,
            "recall": 0.7496,
            "fmeasure": 0.75487
        },
        "rouge2": {
            "precision": 0.58642,
            "recall": 0.55909,
            "fmeasure": 0.56082
        },
        "rougeL": {
            "precision": 0.70323,
            "recall": 0.67125,
            "fmeasure": 0.67331
        },
        "rougeLsum": {
            "precision": 0.70323,
            "recall": 0.67125,
            "fmeasure": 0.67331
        },
        "bleu": 50.2657,
        "meteor": 0.40773453258548814,
        "bertscore": {
            "precision": 0.93839,
            "recall": 0.93273,
            "f1": 0.93304
        },
        "nubia": {
            "semantic_relation": 4.15867,
            "contradiction": 6.90539,
            "irrelevancy": 31.7482,
            "logical_agreement": 61.34641,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.90085,
            "nubia_score": 0.71673
        },
        "bleurt": 0.27292
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.78,
        "total_length": 271,
        "mean_pred_length": 15.055555555555555,
        "std_pred_length": 4.7078211783067525,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5904059040590406,
        "vocab_size-1": 160,
        "unique-1": 131,
        "entropy-1": 6.628000760255723,
        "distinct-2": 0.8972332015810277,
        "vocab_size-2": 227,
        "unique-2": 208,
        "entropy-2": 7.741249466161748,
        "cond_entropy-2": 0.9420542425009405,
        "distinct-3": 0.9574468085106383,
        "vocab_size-3": 225,
        "unique-3": 215,
        "entropy-3": 7.791410563586261,
        "cond_entropy-3": 0.05165639084400938,
        "total_length-nopunct": 231,
        "mean_pred_length-nopunct": 12.833333333333334,
        "std_pred_length-nopunct": 3.4520525295346633,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6753246753246753,
        "vocab_size-1-nopunct": 156,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.755375367859197,
        "distinct-2-nopunct": 0.9061032863849765,
        "vocab_size-2-nopunct": 193,
        "unique-2-nopunct": 179,
        "entropy-2-nopunct": 7.507449657988472,
        "cond_entropy-2-nopunct": 0.8306410794438798,
        "distinct-3-nopunct": 0.958974358974359,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 179,
        "entropy-3-nopunct": 7.525279031698364,
        "cond_entropy-3-nopunct": 0.03880721637796085,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17307692307692307,
            "2": 0.3448275862068966,
            "3": 0.8097826086956522
        },
        "nist": 5.846004296597835,
        "rouge1": {
            "precision": 0.76755,
            "recall": 0.76584,
            "fmeasure": 0.75845
        },
        "rouge2": {
            "precision": 0.50962,
            "recall": 0.51616,
            "fmeasure": 0.5064
        },
        "rougeL": {
            "precision": 0.66239,
            "recall": 0.66801,
            "fmeasure": 0.65806
        },
        "rougeLsum": {
            "precision": 0.66239,
            "recall": 0.66801,
            "fmeasure": 0.65806
        },
        "bleu": 40.61985,
        "meteor": 0.4060653279681538,
        "bertscore": {
            "precision": 0.92672,
            "recall": 0.93037,
            "f1": 0.92688
        },
        "nubia": {
            "semantic_relation": 4.277,
            "contradiction": 1.19756,
            "irrelevancy": 38.11553,
            "logical_agreement": 60.68691,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.73599,
            "nubia_score": 0.73402
        },
        "bleurt": 0.23704
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 12.8,
        "std_pred_length": 4.534313619501853,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.78125,
        "vocab_size-1": 50,
        "unique-1": 42,
        "entropy-1": 5.463054250365621,
        "distinct-2": 1.0,
        "vocab_size-2": 59,
        "unique-2": 59,
        "entropy-2": 5.882643049361836,
        "cond_entropy-2": 0.26831910872054415,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.12775554719837257,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 11.2,
        "std_pred_length-nopunct": 4.1182520563948,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.485926350629036,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.21801159638447945,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.14886338591448275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.625,
            "3": 0.7142857142857143
        },
        "nist": 5.438788288223865,
        "rouge1": {
            "precision": 0.81309,
            "recall": 0.73608,
            "fmeasure": 0.7705
        },
        "rouge2": {
            "precision": 0.59792,
            "recall": 0.5345,
            "fmeasure": 0.56286
        },
        "rougeL": {
            "precision": 0.71252,
            "recall": 0.67631,
            "fmeasure": 0.68983
        },
        "rougeLsum": {
            "precision": 0.71252,
            "recall": 0.67631,
            "fmeasure": 0.68983
        },
        "bleu": 51.43528,
        "meteor": 0.40453890981000834,
        "bertscore": {
            "precision": 0.95295,
            "recall": 0.93222,
            "f1": 0.94188
        },
        "nubia": {
            "semantic_relation": 3.99898,
            "contradiction": 67.4582,
            "irrelevancy": 7.00088,
            "logical_agreement": 25.54092,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.67847,
            "nubia_score": 0.59133
        },
        "bleurt": 0.34156
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.68667,
        "msttr-100_nopunct": 0.695,
        "total_length": 312,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 5.734883511361751,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.5993589743589743,
        "vocab_size-1": 187,
        "unique-1": 157,
        "entropy-1": 6.839342476842207,
        "distinct-2": 0.9183673469387755,
        "vocab_size-2": 270,
        "unique-2": 255,
        "entropy-2": 8.009963373711091,
        "cond_entropy-2": 1.0228052746073537,
        "distinct-3": 0.9855072463768116,
        "vocab_size-3": 272,
        "unique-3": 268,
        "entropy-3": 8.079538949531752,
        "cond_entropy-3": 0.08194790002447647,
        "total_length-nopunct": 280,
        "mean_pred_length-nopunct": 15.555555555555555,
        "std_pred_length-nopunct": 4.991350543381379,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.9197679412294955,
        "distinct-2-nopunct": 0.9236641221374046,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 231,
        "entropy-2-nopunct": 7.851077820198481,
        "cond_entropy-2-nopunct": 1.006772746766211,
        "distinct-3-nopunct": 0.9959016393442623,
        "vocab_size-3-nopunct": 243,
        "unique-3-nopunct": 242,
        "entropy-3-nopunct": 7.922540616251369,
        "cond_entropy-3-nopunct": 0.08491448975829348,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3235294117647059,
            "2": 0.5070422535211268,
            "3": 0.7096774193548387
        },
        "nist": 5.949282402602795,
        "rouge1": {
            "precision": 0.70481,
            "recall": 0.7134,
            "fmeasure": 0.70151
        },
        "rouge2": {
            "precision": 0.47843,
            "recall": 0.49036,
            "fmeasure": 0.47779
        },
        "rougeL": {
            "precision": 0.60112,
            "recall": 0.64046,
            "fmeasure": 0.60882
        },
        "rougeLsum": {
            "precision": 0.60112,
            "recall": 0.64046,
            "fmeasure": 0.60882
        },
        "bleu": 38.43976,
        "meteor": 0.37827269170945166,
        "bertscore": {
            "precision": 0.91752,
            "recall": 0.91584,
            "f1": 0.91536
        },
        "nubia": {
            "semantic_relation": 3.91693,
            "contradiction": 12.87706,
            "irrelevancy": 38.36273,
            "logical_agreement": 48.76021,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.3574,
            "nubia_score": 0.67348
        },
        "bleurt": 0.12419
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "msttr-100": 0.7335,
        "msttr-100_nopunct": 0.7766,
        "total_length": 6040,
        "mean_pred_length": 16.824512534818943,
        "std_pred_length": 6.391573554775873,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.4107615894039735,
        "vocab_size-1": 2481,
        "unique-1": 2002,
        "entropy-1": 9.13639206869244,
        "distinct-2": 0.82855131138884,
        "vocab_size-2": 4707,
        "unique-2": 4393,
        "entropy-2": 11.814749530095085,
        "cond_entropy-2": 2.439551293449295,
        "distinct-3": 0.9419391206313416,
        "vocab_size-3": 5013,
        "unique-3": 4904,
        "entropy-3": 12.13789038809739,
        "cond_entropy-3": 0.3501290598751253,
        "total_length-nopunct": 5302,
        "mean_pred_length-nopunct": 14.768802228412257,
        "std_pred_length-nopunct": 5.605859097900192,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.46586193889098454,
        "vocab_size-1-nopunct": 2470,
        "unique-1-nopunct": 2000,
        "entropy-1-nopunct": 9.508298312289694,
        "distinct-2-nopunct": 0.8662755411693304,
        "vocab_size-2-nopunct": 4282,
        "unique-2-nopunct": 4020,
        "entropy-2-nopunct": 11.83432502405552,
        "cond_entropy-2-nopunct": 2.473535029941496,
        "distinct-3-nopunct": 0.9766579406631762,
        "vocab_size-3-nopunct": 4477,
        "unique-3-nopunct": 4399,
        "entropy-3-nopunct": 12.108830455399254,
        "cond_entropy-3-nopunct": 0.2973132492546235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "local_recall": {
            "1": 0.042705314009661835,
            "2": 0.12362637362637363,
            "3": 0.2250879249706917,
            "4": 0.3271954674220963,
            "5": 0.37317397078353254,
            "6": 0.4458128078817734,
            "7": 0.5570776255707762,
            "8": 0.6121031746031746,
            "9": 0.7266187050359713
        },
        "nist": 8.462516084828478,
        "rouge1": {
            "precision": 0.67828,
            "recall": 0.62888,
            "fmeasure": 0.63869
        },
        "rouge2": {
            "precision": 0.47041,
            "recall": 0.4316,
            "fmeasure": 0.43622
        },
        "rougeL": {
            "precision": 0.64192,
            "recall": 0.59949,
            "fmeasure": 0.60558
        },
        "rougeLsum": {
            "precision": 0.64192,
            "recall": 0.59949,
            "fmeasure": 0.60558
        },
        "bleu": 43.07873,
        "sari": 44.85407,
        "meteor": 0.31279786543162263,
        "bertscore": {
            "precision": 0.87553,
            "recall": 0.89799,
            "f1": 0.8823
        },
        "nubia": {
            "semantic_relation": 3.45895,
            "contradiction": 11.14496,
            "irrelevancy": 30.67967,
            "logical_agreement": 58.17536,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.0392,
            "nubia_score": 0.38563
        },
        "bleurt": -0.61066
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 63,
        "mean_pred_length": 15.75,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.6984126984126984,
        "vocab_size-1": 44,
        "unique-1": 34,
        "entropy-1": 5.2584828994500095,
        "distinct-2": 0.9322033898305084,
        "vocab_size-2": 55,
        "unique-2": 52,
        "entropy-2": 5.734255125596355,
        "cond_entropy-2": 0.38891100743787077,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": 0.057896436929426844,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.2264741182543775,
        "distinct-2-nopunct": 0.9423076923076923,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.570538035407183,
        "cond_entropy-2-nopunct": 0.35826700781610676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.00777044655655436,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.375,
            "3": 0.6896551724137931
        },
        "nist": 3.924712835393004,
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.7446,
            "fmeasure": 0.73898
        },
        "rouge2": {
            "precision": 0.59182,
            "recall": 0.59947,
            "fmeasure": 0.56423
        },
        "rougeL": {
            "precision": 0.79722,
            "recall": 0.72801,
            "fmeasure": 0.72209
        },
        "rougeLsum": {
            "precision": 0.79722,
            "recall": 0.72801,
            "fmeasure": 0.72209
        },
        "bleu": 34.89315,
        "meteor": 0.37140913013884136,
        "bertscore": {
            "precision": 0.93939,
            "recall": 0.93119,
            "f1": 0.92935
        },
        "nubia": {
            "semantic_relation": 4.45089,
            "contradiction": 0.93933,
            "irrelevancy": 40.28165,
            "logical_agreement": 58.77903,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.39902,
            "nubia_score": 0.77874
        },
        "bleurt": 0.2214
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 1.7853571071357126,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 42,
        "unique-1": 34,
        "entropy-1": 5.17307176022725,
        "distinct-2": 0.9811320754716981,
        "vocab_size-2": 52,
        "unique-2": 51,
        "entropy-2": 5.690184605506592,
        "cond_entropy-2": 0.41596705312368,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.07239428391737851,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 1.7853571071357126,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7755102040816326,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.051247793616499,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.44740865188523,
        "cond_entropy-2-nopunct": 0.44624637386861776,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.08552060390671311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.2857142857142857,
            "3": 0.7297297297297297
        },
        "nist": 3.7656100502306664,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.74625,
            "fmeasure": 0.70885
        },
        "rouge2": {
            "precision": 0.42727,
            "recall": 0.47362,
            "fmeasure": 0.44101
        },
        "rougeL": {
            "precision": 0.59028,
            "recall": 0.65644,
            "fmeasure": 0.61289
        },
        "rougeLsum": {
            "precision": 0.59028,
            "recall": 0.65644,
            "fmeasure": 0.61289
        },
        "bleu": 39.65619,
        "meteor": 0.3654434728155834,
        "bertscore": {
            "precision": 0.89956,
            "recall": 0.90813,
            "f1": 0.89687
        },
        "nubia": {
            "semantic_relation": 3.28368,
            "contradiction": 22.43553,
            "irrelevancy": 62.64138,
            "logical_agreement": 14.92308,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.49444,
            "nubia_score": 0.5479
        },
        "bleurt": 0.11061
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 46,
        "msttr-100": 0.74143,
        "msttr-100_nopunct": 0.79167,
        "total_length": 707,
        "mean_pred_length": 15.369565217391305,
        "std_pred_length": 5.096284646903902,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5657708628005658,
        "vocab_size-1": 400,
        "unique-1": 333,
        "entropy-1": 7.6763584791766775,
        "distinct-2": 0.9228441754916793,
        "vocab_size-2": 610,
        "unique-2": 583,
        "entropy-2": 9.16440681639322,
        "cond_entropy-2": 1.2675358868711506,
        "distinct-3": 0.9853658536585366,
        "vocab_size-3": 606,
        "unique-3": 597,
        "entropy-3": 9.235174307543701,
        "cond_entropy-3": 0.08278144834587725,
        "total_length-nopunct": 622,
        "mean_pred_length-nopunct": 13.521739130434783,
        "std_pred_length-nopunct": 4.875578585218653,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6334405144694534,
        "vocab_size-1-nopunct": 394,
        "unique-1-nopunct": 331,
        "entropy-1-nopunct": 7.891435499521982,
        "distinct-2-nopunct": 0.9236111111111112,
        "vocab_size-2-nopunct": 532,
        "unique-2-nopunct": 511,
        "entropy-2-nopunct": 8.961322609222895,
        "cond_entropy-2-nopunct": 1.1555198526648358,
        "distinct-3-nopunct": 0.9886792452830189,
        "vocab_size-3-nopunct": 524,
        "unique-3-nopunct": 518,
        "entropy-3-nopunct": 9.027207040016613,
        "cond_entropy-3-nopunct": 0.08021595917508119,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.44525547445255476,
            "3": 0.717391304347826
        },
        "nist": 6.429953036352095,
        "rouge1": {
            "precision": 0.78969,
            "recall": 0.72773,
            "fmeasure": 0.74469
        },
        "rouge2": {
            "precision": 0.55431,
            "recall": 0.52606,
            "fmeasure": 0.53139
        },
        "rougeL": {
            "precision": 0.69193,
            "recall": 0.64532,
            "fmeasure": 0.65673
        },
        "rougeLsum": {
            "precision": 0.69193,
            "recall": 0.64532,
            "fmeasure": 0.65673
        },
        "bleu": 44.00173,
        "meteor": 0.36819348066807145,
        "bertscore": {
            "precision": 0.92917,
            "recall": 0.92106,
            "f1": 0.92391
        },
        "nubia": {
            "semantic_relation": 4.17758,
            "contradiction": 13.04886,
            "irrelevancy": 35.18604,
            "logical_agreement": 51.76509,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.7302,
            "nubia_score": 0.70374
        },
        "bleurt": 0.30826
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.430632409490749,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.15916418769779478,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 5.016137706633773,
        "rouge1": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 0.97917,
            "fmeasure": 0.97059
        },
        "rougeL": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "rougeLsum": {
            "precision": 0.98333,
            "recall": 1.0,
            "fmeasure": 0.99123
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.56394,
            "irrelevancy": 0.56148,
            "logical_agreement": 98.87458,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.6994,
            "nubia_score": 1.0
        },
        "bleurt": 0.95532
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.75,
        "total_length": 280,
        "mean_pred_length": 16.470588235294116,
        "std_pred_length": 4.666749051834989,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.5714285714285714,
        "vocab_size-1": 160,
        "unique-1": 128,
        "entropy-1": 6.560789594942498,
        "distinct-2": 0.8897338403041825,
        "vocab_size-2": 234,
        "unique-2": 213,
        "entropy-2": 7.778818715693214,
        "cond_entropy-2": 1.0552060023962762,
        "distinct-3": 0.9512195121951219,
        "vocab_size-3": 234,
        "unique-3": 223,
        "entropy-3": 7.841884881346743,
        "cond_entropy-3": 0.08104057480467375,
        "total_length-nopunct": 238,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.940737464575112,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6554621848739496,
        "vocab_size-1-nopunct": 156,
        "unique-1-nopunct": 128,
        "entropy-1-nopunct": 6.685285620549836,
        "distinct-2-nopunct": 0.8914027149321267,
        "vocab_size-2-nopunct": 197,
        "unique-2-nopunct": 180,
        "entropy-2-nopunct": 7.5270361138963775,
        "cond_entropy-2-nopunct": 0.9121669930157621,
        "distinct-3-nopunct": 0.9558823529411765,
        "vocab_size-3-nopunct": 195,
        "unique-3-nopunct": 186,
        "entropy-3-nopunct": 7.584190047853849,
        "cond_entropy-3-nopunct": 0.05438300049380534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12307692307692308,
            "2": 0.543859649122807,
            "3": 0.8255813953488372
        },
        "nist": 6.3481941933631925,
        "rouge1": {
            "precision": 0.80881,
            "recall": 0.77609,
            "fmeasure": 0.78292
        },
        "rouge2": {
            "precision": 0.57571,
            "recall": 0.56791,
            "fmeasure": 0.56525
        },
        "rougeL": {
            "precision": 0.70148,
            "recall": 0.67639,
            "fmeasure": 0.68233
        },
        "rougeLsum": {
            "precision": 0.70148,
            "recall": 0.67639,
            "fmeasure": 0.68233
        },
        "bleu": 48.95322,
        "meteor": 0.40879042295669143,
        "bertscore": {
            "precision": 0.94801,
            "recall": 0.93865,
            "f1": 0.94192
        },
        "nubia": {
            "semantic_relation": 4.27597,
            "contradiction": 10.54987,
            "irrelevancy": 29.03888,
            "logical_agreement": 60.41125,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.68447,
            "nubia_score": 0.75313
        },
        "bleurt": 0.27182
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966054,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518528,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "nist": 1.7503473569799732,
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.48148,
            "fmeasure": 0.37778
        },
        "rougeL": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "rougeLsum": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "bleu": 18.29565,
        "meteor": 0.35356235305705724,
        "bertscore": {
            "precision": 0.87103,
            "recall": 0.90546,
            "f1": 0.88791
        },
        "nubia": {
            "semantic_relation": 3.99409,
            "contradiction": 0.26568,
            "irrelevancy": 22.76223,
            "logical_agreement": 76.97209,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.24002,
            "nubia_score": 0.64181
        },
        "bleurt": 0.12284
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.755,
        "total_length": 282,
        "mean_pred_length": 17.625,
        "std_pred_length": 5.395310463726809,
        "median_pred_length": 18.5,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5921985815602837,
        "vocab_size-1": 167,
        "unique-1": 137,
        "entropy-1": 6.735247065955914,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 247,
        "unique-2": 235,
        "entropy-2": 7.881355132845261,
        "cond_entropy-2": 1.010264118201191,
        "distinct-3": 1.0,
        "vocab_size-3": 250,
        "unique-3": 250,
        "entropy-3": 7.9657842846621,
        "cond_entropy-3": 0.08756049918685926,
        "total_length-nopunct": 250,
        "mean_pred_length-nopunct": 15.625,
        "std_pred_length-nopunct": 4.794202227691277,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.648,
        "vocab_size-1-nopunct": 162,
        "unique-1-nopunct": 136,
        "entropy-1-nopunct": 6.7870587091038175,
        "distinct-2-nopunct": 0.9316239316239316,
        "vocab_size-2-nopunct": 218,
        "unique-2-nopunct": 209,
        "entropy-2-nopunct": 7.698293512290695,
        "cond_entropy-2-nopunct": 0.9850580797177217,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 218,
        "unique-3-nopunct": 218,
        "entropy-3-nopunct": 7.7681843247769145,
        "cond_entropy-3-nopunct": 0.08251989192054228,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.325,
            "3": 0.8663101604278075
        },
        "nist": 6.589942500287009,
        "rouge1": {
            "precision": 0.79025,
            "recall": 0.80035,
            "fmeasure": 0.78729
        },
        "rouge2": {
            "precision": 0.56759,
            "recall": 0.58727,
            "fmeasure": 0.5703
        },
        "rougeL": {
            "precision": 0.6794,
            "recall": 0.68903,
            "fmeasure": 0.6767
        },
        "rougeLsum": {
            "precision": 0.6794,
            "recall": 0.68903,
            "fmeasure": 0.6767
        },
        "bleu": 53.12575,
        "meteor": 0.42442935679575133,
        "bertscore": {
            "precision": 0.93657,
            "recall": 0.94053,
            "f1": 0.93752
        },
        "nubia": {
            "semantic_relation": 4.32521,
            "contradiction": 6.56188,
            "irrelevancy": 30.0196,
            "logical_agreement": 63.41853,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.68359,
            "nubia_score": 0.78038
        },
        "bleurt": 0.29542
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 81,
        "mean_pred_length": 20.25,
        "std_pred_length": 6.339361166552983,
        "median_pred_length": 19.5,
        "min_pred_length": 14,
        "max_pred_length": 28,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 63,
        "unique-1": 52,
        "entropy-1": 5.8120118855739555,
        "distinct-2": 0.961038961038961,
        "vocab_size-2": 74,
        "unique-2": 71,
        "entropy-2": 6.188864462772827,
        "cond_entropy-2": 0.30037663524097075,
        "distinct-3": 0.9863013698630136,
        "vocab_size-3": 72,
        "unique-3": 71,
        "entropy-3": 6.162427298606055,
        "cond_entropy-3": -0.022167461266938637,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 18.25,
        "std_pred_length-nopunct": 5.356071321407137,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8082191780821918,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.7411274698092924,
        "distinct-2-nopunct": 0.9710144927536232,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.05055344228541,
        "cond_entropy-2-nopunct": 0.3354373979295064,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.024618182211253017,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.7,
            "3": 0.8163265306122449
        },
        "nist": 4.938270009690305,
        "rouge1": {
            "precision": 0.73514,
            "recall": 0.78942,
            "fmeasure": 0.75771
        },
        "rouge2": {
            "precision": 0.51523,
            "recall": 0.57619,
            "fmeasure": 0.54212
        },
        "rougeL": {
            "precision": 0.59635,
            "recall": 0.67003,
            "fmeasure": 0.63003
        },
        "rougeLsum": {
            "precision": 0.59635,
            "recall": 0.67003,
            "fmeasure": 0.63003
        },
        "bleu": 41.94012,
        "meteor": 0.39005926826036363,
        "bertscore": {
            "precision": 0.93054,
            "recall": 0.90958,
            "f1": 0.91926
        },
        "nubia": {
            "semantic_relation": 4.04532,
            "contradiction": 11.19004,
            "irrelevancy": 30.54159,
            "logical_agreement": 58.26837,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.89138,
            "nubia_score": 0.73478
        },
        "bleurt": 0.20418
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.76333,
        "msttr-100_nopunct": 0.79333,
        "total_length": 392,
        "mean_pred_length": 15.68,
        "std_pred_length": 5.205535515199181,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.6326530612244898,
        "vocab_size-1": 248,
        "unique-1": 214,
        "entropy-1": 7.278014276947024,
        "distinct-2": 0.9237057220708447,
        "vocab_size-2": 339,
        "unique-2": 321,
        "entropy-2": 8.338357438093878,
        "cond_entropy-2": 0.9131465052381109,
        "distinct-3": 0.9853801169590644,
        "vocab_size-3": 337,
        "unique-3": 333,
        "entropy-3": 8.386405475405878,
        "cond_entropy-3": 0.05837543605092295,
        "total_length-nopunct": 350,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.138093031466052,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6942857142857143,
        "vocab_size-1-nopunct": 243,
        "unique-1-nopunct": 214,
        "entropy-1-nopunct": 7.39353152898692,
        "distinct-2-nopunct": 0.9292307692307692,
        "vocab_size-2-nopunct": 302,
        "unique-2-nopunct": 289,
        "entropy-2-nopunct": 8.170359523260448,
        "cond_entropy-2-nopunct": 0.8520341160309296,
        "distinct-3-nopunct": 0.99,
        "vocab_size-3-nopunct": 297,
        "unique-3-nopunct": 295,
        "entropy-3-nopunct": 8.206302398822059,
        "cond_entropy-3-nopunct": 0.04710424094945492,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16071428571428573,
            "2": 0.37209302325581395,
            "3": 0.8214285714285714
        },
        "nist": 6.8479837415477585,
        "rouge1": {
            "precision": 0.84632,
            "recall": 0.78881,
            "fmeasure": 0.8115
        },
        "rouge2": {
            "precision": 0.66685,
            "recall": 0.63786,
            "fmeasure": 0.64957
        },
        "rougeL": {
            "precision": 0.75693,
            "recall": 0.70778,
            "fmeasure": 0.72706
        },
        "rougeLsum": {
            "precision": 0.75693,
            "recall": 0.70778,
            "fmeasure": 0.72706
        },
        "bleu": 58.95451,
        "meteor": 0.4470521045857838,
        "bertscore": {
            "precision": 0.95035,
            "recall": 0.93997,
            "f1": 0.94436
        },
        "nubia": {
            "semantic_relation": 4.26809,
            "contradiction": 16.81958,
            "irrelevancy": 15.9512,
            "logical_agreement": 67.22922,
            "grammar_ref": 4.85173,
            "grammar_hyp": 5.09394,
            "nubia_score": 0.72151
        },
        "bleurt": 0.39094
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.715,
        "total_length": 242,
        "mean_pred_length": 17.285714285714285,
        "std_pred_length": 4.977500397195528,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.5661157024793388,
        "vocab_size-1": 137,
        "unique-1": 108,
        "entropy-1": 6.426558718679203,
        "distinct-2": 0.8771929824561403,
        "vocab_size-2": 200,
        "unique-2": 182,
        "entropy-2": 7.511752817020589,
        "cond_entropy-2": 0.9953545692204709,
        "distinct-3": 0.9345794392523364,
        "vocab_size-3": 200,
        "unique-3": 186,
        "entropy-3": 7.61062586490579,
        "cond_entropy-3": 0.10119043461432012,
        "total_length-nopunct": 215,
        "mean_pred_length-nopunct": 15.357142857142858,
        "std_pred_length-nopunct": 4.653833179789122,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6186046511627907,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 6.431523334728635,
        "distinct-2-nopunct": 0.8706467661691543,
        "vocab_size-2-nopunct": 175,
        "unique-2-nopunct": 159,
        "entropy-2-nopunct": 7.306677159094992,
        "cond_entropy-2-nopunct": 0.9403848945810772,
        "distinct-3-nopunct": 0.93048128342246,
        "vocab_size-3-nopunct": 174,
        "unique-3-nopunct": 161,
        "entropy-3-nopunct": 7.407857026732536,
        "cond_entropy-3-nopunct": 0.11626673100214967,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.3333333333333333,
            "3": 0.7470588235294118
        },
        "nist": 5.8493036486790055,
        "rouge1": {
            "precision": 0.76205,
            "recall": 0.73876,
            "fmeasure": 0.74187
        },
        "rouge2": {
            "precision": 0.55095,
            "recall": 0.52977,
            "fmeasure": 0.53504
        },
        "rougeL": {
            "precision": 0.64527,
            "recall": 0.61552,
            "fmeasure": 0.62673
        },
        "rougeLsum": {
            "precision": 0.64527,
            "recall": 0.61552,
            "fmeasure": 0.62673
        },
        "bleu": 45.26622,
        "meteor": 0.3892480586999342,
        "bertscore": {
            "precision": 0.93363,
            "recall": 0.93719,
            "f1": 0.93396
        },
        "nubia": {
            "semantic_relation": 4.44314,
            "contradiction": 3.34937,
            "irrelevancy": 19.10769,
            "logical_agreement": 77.54294,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.76152,
            "nubia_score": 0.80833
        },
        "bleurt": 0.35362
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 4.829966150010236,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.123627393192269,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9032258064516129,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.7362967135428935,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.13671183998771327,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.7777777777777778
        },
        "nist": 3.6216202203718404,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.6286,
            "fmeasure": 0.69967
        },
        "rouge2": {
            "precision": 0.56053,
            "recall": 0.38772,
            "fmeasure": 0.43676
        },
        "rougeL": {
            "precision": 0.63864,
            "recall": 0.46686,
            "fmeasure": 0.51557
        },
        "rougeLsum": {
            "precision": 0.63864,
            "recall": 0.46686,
            "fmeasure": 0.51557
        },
        "bleu": 18.19998,
        "meteor": 0.3320534663279007,
        "bertscore": {
            "precision": 0.91327,
            "recall": 0.91934,
            "f1": 0.91376
        },
        "nubia": {
            "semantic_relation": 4.51208,
            "contradiction": 0.12688,
            "irrelevancy": 44.45485,
            "logical_agreement": 55.41826,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.65673,
            "nubia_score": 0.88061
        },
        "bleurt": 0.18907
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8,
        "total_length": 114,
        "mean_pred_length": 14.25,
        "std_pred_length": 4.736823830374104,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 22,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 84,
        "unique-1": 72,
        "entropy-1": 6.101450733592346,
        "distinct-2": 0.9905660377358491,
        "vocab_size-2": 105,
        "unique-2": 104,
        "entropy-2": 6.7090525300348824,
        "cond_entropy-2": 0.4363896666744409,
        "distinct-3": 1.0,
        "vocab_size-3": 98,
        "unique-3": 98,
        "entropy-3": 6.614709844115218,
        "cond_entropy-3": -0.09280244718268442,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 12.875,
        "std_pred_length-nopunct": 4.456385867493972,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7961165048543689,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.156120037056138,
        "distinct-2-nopunct": 0.9894736842105263,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.548802976752,
        "cond_entropy-2-nopunct": 0.4268202441276307,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.442943495848723,
        "cond_entropy-3-nopunct": -0.10392360673509339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.4166666666666667,
            "3": 0.8026315789473685
        },
        "nist": 5.2095606058972574,
        "rouge1": {
            "precision": 0.74065,
            "recall": 0.68783,
            "fmeasure": 0.70755
        },
        "rouge2": {
            "precision": 0.51754,
            "recall": 0.47232,
            "fmeasure": 0.49054
        },
        "rougeL": {
            "precision": 0.67607,
            "recall": 0.66579,
            "fmeasure": 0.66402
        },
        "rougeLsum": {
            "precision": 0.67607,
            "recall": 0.66579,
            "fmeasure": 0.66402
        },
        "bleu": 44.54501,
        "meteor": 0.4050361792590112,
        "bertscore": {
            "precision": 0.93071,
            "recall": 0.92749,
            "f1": 0.92523
        },
        "nubia": {
            "semantic_relation": 4.36586,
            "contradiction": 0.70994,
            "irrelevancy": 33.78199,
            "logical_agreement": 65.50808,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.6768,
            "nubia_score": 0.80917
        },
        "bleurt": 0.35085
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "total_length": 278,
        "mean_pred_length": 16.352941176470587,
        "std_pred_length": 4.3106049318967665,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.5683453237410072,
        "vocab_size-1": 158,
        "unique-1": 121,
        "entropy-1": 6.658547110038354,
        "distinct-2": 0.9272030651340997,
        "vocab_size-2": 242,
        "unique-2": 225,
        "entropy-2": 7.876527548277416,
        "cond_entropy-2": 1.0678911561151079,
        "distinct-3": 0.9754098360655737,
        "vocab_size-3": 238,
        "unique-3": 232,
        "entropy-3": 7.881557009693995,
        "cond_entropy-3": 0.007379599207456424,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 14.647058823529411,
        "std_pred_length-nopunct": 4.324229635173907,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6144578313253012,
        "vocab_size-1-nopunct": 153,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.719960804848833,
        "distinct-2-nopunct": 0.9267241379310345,
        "vocab_size-2-nopunct": 215,
        "unique-2-nopunct": 200,
        "entropy-2-nopunct": 7.704921620108901,
        "cond_entropy-2-nopunct": 1.0363003590587323,
        "distinct-3-nopunct": 0.9813953488372092,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.710983547263855,
        "cond_entropy-3-nopunct": 0.008861970761083065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.4897959183673469,
            "3": 0.7634408602150538
        },
        "nist": 6.066386090293401,
        "rouge1": {
            "precision": 0.7302,
            "recall": 0.7385,
            "fmeasure": 0.72057
        },
        "rouge2": {
            "precision": 0.4927,
            "recall": 0.5346,
            "fmeasure": 0.50208
        },
        "rougeL": {
            "precision": 0.599,
            "recall": 0.63028,
            "fmeasure": 0.60065
        },
        "rougeLsum": {
            "precision": 0.599,
            "recall": 0.63028,
            "fmeasure": 0.60065
        },
        "bleu": 42.10726,
        "meteor": 0.379209199514728,
        "bertscore": {
            "precision": 0.92633,
            "recall": 0.92575,
            "f1": 0.92188
        },
        "nubia": {
            "semantic_relation": 4.29143,
            "contradiction": 19.21959,
            "irrelevancy": 25.89345,
            "logical_agreement": 54.88696,
            "grammar_ref": 4.21928,
            "grammar_hyp": 3.952,
            "nubia_score": 0.762
        },
        "bleurt": 0.32892
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 76,
        "mean_pred_length": 15.2,
        "std_pred_length": 5.979966555090422,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 56,
        "unique-1": 47,
        "entropy-1": 5.573135243507481,
        "distinct-2": 0.971830985915493,
        "vocab_size-2": 69,
        "unique-2": 67,
        "entropy-2": 6.093409091335662,
        "cond_entropy-2": 0.41871045133466134,
        "distinct-3": 1.0,
        "vocab_size-3": 66,
        "unique-3": 66,
        "entropy-3": 6.044394119358462,
        "cond_entropy-3": -0.0447469395401679,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 3.2619012860600183,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8253968253968254,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.516652145584778,
        "distinct-2-nopunct": 0.9827586206896551,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.823498236506881,
        "cond_entropy-2-nopunct": 0.30198706314373713,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.727920454563195,
        "cond_entropy-3-nopunct": -0.09232469150776919,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.1875,
            "3": 0.675
        },
        "nist": 3.5859711659303755,
        "rouge1": {
            "precision": 0.64113,
            "recall": 0.61756,
            "fmeasure": 0.61193
        },
        "rouge2": {
            "precision": 0.37211,
            "recall": 0.37832,
            "fmeasure": 0.35975
        },
        "rougeL": {
            "precision": 0.55372,
            "recall": 0.55467,
            "fmeasure": 0.53296
        },
        "rougeLsum": {
            "precision": 0.55372,
            "recall": 0.55467,
            "fmeasure": 0.53296
        },
        "bleu": 19.12904,
        "meteor": 0.31721492908353655,
        "bertscore": {
            "precision": 0.9105,
            "recall": 0.89499,
            "f1": 0.89717
        },
        "nubia": {
            "semantic_relation": 3.60933,
            "contradiction": 4.9438,
            "irrelevancy": 30.97266,
            "logical_agreement": 64.08353,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.05565,
            "nubia_score": 0.56132
        },
        "bleurt": -0.03929
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.7425,
        "msttr-100_nopunct": 0.8,
        "total_length": 416,
        "mean_pred_length": 16.64,
        "std_pred_length": 5.439705874401667,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6057692307692307,
        "vocab_size-1": 252,
        "unique-1": 213,
        "entropy-1": 7.241199198708373,
        "distinct-2": 0.959079283887468,
        "vocab_size-2": 375,
        "unique-2": 365,
        "entropy-2": 8.51509186890759,
        "cond_entropy-2": 1.1210742213339857,
        "distinct-3": 1.0,
        "vocab_size-3": 366,
        "unique-3": 366,
        "entropy-3": 8.515699838283988,
        "cond_entropy-3": 0.007160765032228332,
        "total_length-nopunct": 363,
        "mean_pred_length-nopunct": 14.52,
        "std_pred_length-nopunct": 4.809324276860524,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6749311294765841,
        "vocab_size-1-nopunct": 245,
        "unique-1-nopunct": 212,
        "entropy-1-nopunct": 7.345109370071446,
        "distinct-2-nopunct": 0.9526627218934911,
        "vocab_size-2-nopunct": 322,
        "unique-2-nopunct": 312,
        "entropy-2-nopunct": 8.289903770588872,
        "cond_entropy-2-nopunct": 1.016933296071881,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 313,
        "unique-3-nopunct": 313,
        "entropy-3-nopunct": 8.290018846932586,
        "cond_entropy-3-nopunct": 0.008978947405472127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.53125,
            "3": 0.7921146953405018
        },
        "nist": 6.8548023869087995,
        "rouge1": {
            "precision": 0.79077,
            "recall": 0.7816,
            "fmeasure": 0.77823
        },
        "rouge2": {
            "precision": 0.58548,
            "recall": 0.58103,
            "fmeasure": 0.57576
        },
        "rougeL": {
            "precision": 0.67883,
            "recall": 0.66717,
            "fmeasure": 0.66555
        },
        "rougeLsum": {
            "precision": 0.67883,
            "recall": 0.66717,
            "fmeasure": 0.66555
        },
        "bleu": 49.4505,
        "meteor": 0.4187654750502633,
        "bertscore": {
            "precision": 0.94391,
            "recall": 0.94107,
            "f1": 0.94126
        },
        "nubia": {
            "semantic_relation": 4.25536,
            "contradiction": 8.25113,
            "irrelevancy": 18.53124,
            "logical_agreement": 73.21763,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.64997,
            "nubia_score": 0.76802
        },
        "bleurt": 0.35957
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "nist": 2.3557006939344536,
        "rouge1": {
            "precision": 0.73684,
            "recall": 0.76413,
            "fmeasure": 0.75012
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.46187,
            "fmeasure": 0.45291
        },
        "rougeL": {
            "precision": 0.47368,
            "recall": 0.49123,
            "fmeasure": 0.48222
        },
        "rougeLsum": {
            "precision": 0.47368,
            "recall": 0.49123,
            "fmeasure": 0.48222
        },
        "bleu": 18.60534,
        "meteor": 0.35858518042052556,
        "bertscore": {
            "precision": 0.89461,
            "recall": 0.90247,
            "f1": 0.89852
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.05867,
            "irrelevancy": 4.25523,
            "logical_agreement": 95.6861,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.17577,
            "nubia_score": 1.0
        },
        "bleurt": 0.41479
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.7,
        "total_length": 148,
        "mean_pred_length": 14.8,
        "std_pred_length": 4.512205669071391,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6216216216216216,
        "vocab_size-1": 92,
        "unique-1": 78,
        "entropy-1": 5.904374843845138,
        "distinct-2": 0.8913043478260869,
        "vocab_size-2": 123,
        "unique-2": 113,
        "entropy-2": 6.835687612905679,
        "cond_entropy-2": 0.785164249270429,
        "distinct-3": 0.9609375,
        "vocab_size-3": 123,
        "unique-3": 118,
        "entropy-3": 6.921875,
        "cond_entropy-3": 0.1075027655218565,
        "total_length-nopunct": 129,
        "mean_pred_length-nopunct": 12.9,
        "std_pred_length-nopunct": 3.83275357934736,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6821705426356589,
        "vocab_size-1-nopunct": 88,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 5.9237787606889265,
        "distinct-2-nopunct": 0.8991596638655462,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 100,
        "entropy-2-nopunct": 6.628838902346571,
        "cond_entropy-2-nopunct": 0.7964423681058976,
        "distinct-3-nopunct": 0.981651376146789,
        "vocab_size-3-nopunct": 107,
        "unique-3-nopunct": 105,
        "entropy-3-nopunct": 6.731487077070493,
        "cond_entropy-3-nopunct": 0.12704990508736083,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.23529411764705882,
            "3": 0.8584905660377359
        },
        "nist": 6.043159962175485,
        "rouge1": {
            "precision": 0.79579,
            "recall": 0.77682,
            "fmeasure": 0.78119
        },
        "rouge2": {
            "precision": 0.55708,
            "recall": 0.56726,
            "fmeasure": 0.55685
        },
        "rougeL": {
            "precision": 0.69586,
            "recall": 0.70278,
            "fmeasure": 0.69347
        },
        "rougeLsum": {
            "precision": 0.69586,
            "recall": 0.70278,
            "fmeasure": 0.69347
        },
        "bleu": 56.64752,
        "meteor": 0.4410603734272865,
        "bertscore": {
            "precision": 0.94078,
            "recall": 0.94805,
            "f1": 0.94368
        },
        "nubia": {
            "semantic_relation": 4.67653,
            "contradiction": 0.93665,
            "irrelevancy": 26.06981,
            "logical_agreement": 72.99354,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.11476,
            "nubia_score": 0.8587
        },
        "bleurt": 0.39688
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.74,
        "total_length": 236,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 7.564537145273478,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 34,
        "distinct-1": 0.6186440677966102,
        "vocab_size-1": 146,
        "unique-1": 118,
        "entropy-1": 6.563026168629218,
        "distinct-2": 0.9776785714285714,
        "vocab_size-2": 219,
        "unique-2": 216,
        "entropy-2": 7.755971997931109,
        "cond_entropy-2": 1.1362765326760682,
        "distinct-3": 1.0,
        "vocab_size-3": 212,
        "unique-3": 212,
        "entropy-3": 7.727920454563212,
        "cond_entropy-3": -0.02514307596456096,
        "total_length-nopunct": 200,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 6.168918507773915,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.705,
        "vocab_size-1-nopunct": 141,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.739892373625264,
        "distinct-2-nopunct": 0.973404255319149,
        "vocab_size-2-nopunct": 183,
        "unique-2-nopunct": 180,
        "entropy-2-nopunct": 7.493366644207835,
        "cond_entropy-2-nopunct": 0.8005357907623153,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 176,
        "unique-3-nopunct": 176,
        "entropy-3-nopunct": 7.459431618637307,
        "cond_entropy-3-nopunct": -0.029760784152119135,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.15384615384615385,
            "3": 0.7
        },
        "nist": 5.065219709890122,
        "rouge1": {
            "precision": 0.7693,
            "recall": 0.69271,
            "fmeasure": 0.724
        },
        "rouge2": {
            "precision": 0.52236,
            "recall": 0.47079,
            "fmeasure": 0.49131
        },
        "rougeL": {
            "precision": 0.6848,
            "recall": 0.61538,
            "fmeasure": 0.64326
        },
        "rougeLsum": {
            "precision": 0.6848,
            "recall": 0.61538,
            "fmeasure": 0.64326
        },
        "bleu": 35.35141,
        "meteor": 0.33279380417981996,
        "bertscore": {
            "precision": 0.91843,
            "recall": 0.9004,
            "f1": 0.90797
        },
        "nubia": {
            "semantic_relation": 3.97674,
            "contradiction": 12.50969,
            "irrelevancy": 33.52668,
            "logical_agreement": 53.96363,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.22028,
            "nubia_score": 0.68142
        },
        "bleurt": 0.2045
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.163856189774723,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.3577729776130983,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.025555977074987163,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.163856189774723,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.3577729776130983,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.025555977074987163,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.6470588235294118
        },
        "nist": 2.7392670229220775,
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.62488,
            "fmeasure": 0.60965
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.4,
            "fmeasure": 0.38462
        },
        "rougeL": {
            "precision": 0.45238,
            "recall": 0.47483,
            "fmeasure": 0.4633
        },
        "rougeLsum": {
            "precision": 0.45238,
            "recall": 0.47483,
            "fmeasure": 0.4633
        },
        "bleu": 24.69242,
        "meteor": 0.2846462736556132,
        "bertscore": {
            "precision": 0.88709,
            "recall": 0.9024,
            "f1": 0.89425
        },
        "nubia": {
            "semantic_relation": 3.23442,
            "contradiction": 3.22203,
            "irrelevancy": 67.17745,
            "logical_agreement": 29.60052,
            "grammar_ref": 4.71547,
            "grammar_hyp": 4.91338,
            "nubia_score": 0.4575
        },
        "bleurt": -0.4302
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.81,
        "total_length": 139,
        "mean_pred_length": 19.857142857142858,
        "std_pred_length": 5.642405045180428,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.7050359712230215,
        "vocab_size-1": 98,
        "unique-1": 82,
        "entropy-1": 6.291347098337495,
        "distinct-2": 0.9848484848484849,
        "vocab_size-2": 130,
        "unique-2": 128,
        "entropy-2": 7.0140910890554125,
        "cond_entropy-2": 0.6075406408747757,
        "distinct-3": 1.0,
        "vocab_size-3": 125,
        "unique-3": 125,
        "entropy-3": 6.965784284662096,
        "cond_entropy-3": -0.04660983469636636,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 17.285714285714285,
        "std_pred_length-nopunct": 4.919764387920733,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.768595041322314,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.3289121795452274,
        "distinct-2-nopunct": 0.9824561403508771,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.797802294866508,
        "cond_entropy-2-nopunct": 0.4963432504450075,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 107,
        "unique-3-nopunct": 107,
        "entropy-3-nopunct": 6.741466986401138,
        "cond_entropy-3-nopunct": -0.05403985019350118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35294117647058826,
            "2": 0.7419354838709677,
            "3": 0.7777777777777778
        },
        "nist": 5.928228170718141,
        "rouge1": {
            "precision": 0.79153,
            "recall": 0.77682,
            "fmeasure": 0.78274
        },
        "rouge2": {
            "precision": 0.53815,
            "recall": 0.52553,
            "fmeasure": 0.53076
        },
        "rougeL": {
            "precision": 0.69358,
            "recall": 0.67625,
            "fmeasure": 0.68373
        },
        "rougeLsum": {
            "precision": 0.69358,
            "recall": 0.67625,
            "fmeasure": 0.68373
        },
        "bleu": 52.80737,
        "meteor": 0.4244826096041821,
        "bertscore": {
            "precision": 0.93289,
            "recall": 0.92633,
            "f1": 0.92877
        },
        "nubia": {
            "semantic_relation": 4.35334,
            "contradiction": 0.77317,
            "irrelevancy": 27.17339,
            "logical_agreement": 72.05344,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.37735,
            "nubia_score": 0.80851
        },
        "bleurt": 0.32438
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 4.301162633521313,
        "median_pred_length": 9.5,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 30,
        "unique-1": 22,
        "entropy-1": 4.7089873002588,
        "distinct-2": 0.9,
        "vocab_size-2": 36,
        "unique-2": 33,
        "entropy-2": 5.103055907333277,
        "cond_entropy-2": 0.26911303891232496,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 34,
        "unique-3": 32,
        "entropy-3": 5.058813890331199,
        "cond_entropy-3": -0.07547844060717561,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 3.905124837953327,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.642149881636906,
        "distinct-2-nopunct": 0.9117647058823529,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.8887896794220005,
        "cond_entropy-2-nopunct": 0.2246746661905212,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.840223928941852,
        "cond_entropy-3-nopunct": -0.12774016228444893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.42857142857142855,
            "3": 0.7096774193548387
        },
        "nist": 3.617349416815832,
        "rouge1": {
            "precision": 0.85894,
            "recall": 0.71949,
            "fmeasure": 0.76439
        },
        "rouge2": {
            "precision": 0.69577,
            "recall": 0.59599,
            "fmeasure": 0.62561
        },
        "rougeL": {
            "precision": 0.85894,
            "recall": 0.71949,
            "fmeasure": 0.76439
        },
        "rougeLsum": {
            "precision": 0.85894,
            "recall": 0.71949,
            "fmeasure": 0.76439
        },
        "bleu": 48.60206,
        "meteor": 0.4141893970139452,
        "bertscore": {
            "precision": 0.95631,
            "recall": 0.94166,
            "f1": 0.94843
        },
        "nubia": {
            "semantic_relation": 4.33447,
            "contradiction": 0.4253,
            "irrelevancy": 21.8712,
            "logical_agreement": 77.7035,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.12813,
            "nubia_score": 0.86752
        },
        "bleurt": 0.39252
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 37,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.736,
        "total_length": 639,
        "mean_pred_length": 17.27027027027027,
        "std_pred_length": 5.759357362089218,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5446009389671361,
        "vocab_size-1": 348,
        "unique-1": 282,
        "entropy-1": 7.507924701023056,
        "distinct-2": 0.8870431893687708,
        "vocab_size-2": 534,
        "unique-2": 500,
        "entropy-2": 8.925951284887557,
        "cond_entropy-2": 1.2624821140891318,
        "distinct-3": 0.9628318584070796,
        "vocab_size-3": 544,
        "unique-3": 530,
        "entropy-3": 9.056682875875005,
        "cond_entropy-3": 0.14246405646919735,
        "total_length-nopunct": 569,
        "mean_pred_length-nopunct": 15.378378378378379,
        "std_pred_length-nopunct": 5.298400326418529,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6010544815465729,
        "vocab_size-1-nopunct": 342,
        "unique-1-nopunct": 280,
        "entropy-1-nopunct": 7.663531479364991,
        "distinct-2-nopunct": 0.8853383458646616,
        "vocab_size-2-nopunct": 471,
        "unique-2-nopunct": 443,
        "entropy-2-nopunct": 8.734866111431966,
        "cond_entropy-2-nopunct": 1.153715245950689,
        "distinct-3-nopunct": 0.9636363636363636,
        "vocab_size-3-nopunct": 477,
        "unique-3-nopunct": 466,
        "entropy-3-nopunct": 8.865901558388234,
        "cond_entropy-3-nopunct": 0.15498575804838569,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.45918367346938777,
            "3": 0.7318840579710145
        },
        "nist": 6.452235952841465,
        "rouge1": {
            "precision": 0.72811,
            "recall": 0.74098,
            "fmeasure": 0.72221
        },
        "rouge2": {
            "precision": 0.48211,
            "recall": 0.49364,
            "fmeasure": 0.47979
        },
        "rougeL": {
            "precision": 0.62178,
            "recall": 0.6292,
            "fmeasure": 0.61522
        },
        "rougeLsum": {
            "precision": 0.62178,
            "recall": 0.6292,
            "fmeasure": 0.61522
        },
        "bleu": 41.4895,
        "meteor": 0.3748108578602283,
        "bertscore": {
            "precision": 0.92336,
            "recall": 0.91985,
            "f1": 0.92068
        },
        "nubia": {
            "semantic_relation": 4.08403,
            "contradiction": 16.28764,
            "irrelevancy": 32.5688,
            "logical_agreement": 51.14356,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.59017,
            "nubia_score": 0.72038
        },
        "bleurt": 0.19167
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.775,
        "total_length": 260,
        "mean_pred_length": 16.25,
        "std_pred_length": 5.629165124598851,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 33,
        "distinct-1": 0.6076923076923076,
        "vocab_size-1": 158,
        "unique-1": 132,
        "entropy-1": 6.7404364877436125,
        "distinct-2": 0.889344262295082,
        "vocab_size-2": 217,
        "unique-2": 206,
        "entropy-2": 7.627670383046152,
        "cond_entropy-2": 0.7386621767661552,
        "distinct-3": 0.9385964912280702,
        "vocab_size-3": 214,
        "unique-3": 209,
        "entropy-3": 7.662587727220431,
        "cond_entropy-3": 0.0460013054785064,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 13.8125,
        "std_pred_length-nopunct": 3.503904072602445,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6968325791855203,
        "vocab_size-1-nopunct": 154,
        "unique-1-nopunct": 132,
        "entropy-1-nopunct": 6.870968355991255,
        "distinct-2-nopunct": 0.8975609756097561,
        "vocab_size-2-nopunct": 184,
        "unique-2-nopunct": 176,
        "entropy-2-nopunct": 7.394901092541346,
        "cond_entropy-2-nopunct": 0.5906202841325424,
        "distinct-3-nopunct": 0.9365079365079365,
        "vocab_size-3-nopunct": 177,
        "unique-3-nopunct": 174,
        "entropy-3-nopunct": 7.377962416690339,
        "cond_entropy-3-nopunct": 0.007152668653864503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2926829268292683,
            "3": 0.8054054054054054
        },
        "nist": 6.5884916944064305,
        "rouge1": {
            "precision": 0.80574,
            "recall": 0.7805,
            "fmeasure": 0.78692
        },
        "rouge2": {
            "precision": 0.58456,
            "recall": 0.57766,
            "fmeasure": 0.57707
        },
        "rougeL": {
            "precision": 0.73811,
            "recall": 0.71576,
            "fmeasure": 0.7213
        },
        "rougeLsum": {
            "precision": 0.73811,
            "recall": 0.71576,
            "fmeasure": 0.7213
        },
        "bleu": 56.46488,
        "meteor": 0.4418481783162633,
        "bertscore": {
            "precision": 0.95148,
            "recall": 0.95283,
            "f1": 0.95031
        },
        "nubia": {
            "semantic_relation": 4.47848,
            "contradiction": 1.75301,
            "irrelevancy": 23.56861,
            "logical_agreement": 74.67838,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.3181,
            "nubia_score": 0.83605
        },
        "bleurt": 0.45943
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.72,
        "total_length": 177,
        "mean_pred_length": 14.75,
        "std_pred_length": 2.9190466480228325,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.6045197740112994,
        "vocab_size-1": 107,
        "unique-1": 86,
        "entropy-1": 6.183463135967996,
        "distinct-2": 0.9151515151515152,
        "vocab_size-2": 151,
        "unique-2": 142,
        "entropy-2": 7.167807744535729,
        "cond_entropy-2": 0.8170122386327497,
        "distinct-3": 0.9738562091503268,
        "vocab_size-3": 149,
        "unique-3": 145,
        "entropy-3": 7.2051002609932855,
        "cond_entropy-3": 0.052862278787773734,
        "total_length-nopunct": 152,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 2.8382310609877335,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6776315789473685,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.227451211924021,
        "distinct-2-nopunct": 0.9142857142857143,
        "vocab_size-2-nopunct": 128,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.923890963358096,
        "cond_entropy-2-nopunct": 0.7696234344214412,
        "distinct-3-nopunct": 0.984375,
        "vocab_size-3-nopunct": 126,
        "unique-3-nopunct": 124,
        "entropy-3-nopunct": 6.96875,
        "cond_entropy-3-nopunct": 0.056302041665685684,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.27586206896551724,
            "3": 0.8099173553719008
        },
        "nist": 5.909670361804442,
        "rouge1": {
            "precision": 0.82337,
            "recall": 0.74858,
            "fmeasure": 0.77836
        },
        "rouge2": {
            "precision": 0.5923,
            "recall": 0.53823,
            "fmeasure": 0.5594
        },
        "rougeL": {
            "precision": 0.74932,
            "recall": 0.68332,
            "fmeasure": 0.7091
        },
        "rougeLsum": {
            "precision": 0.74932,
            "recall": 0.68332,
            "fmeasure": 0.7091
        },
        "bleu": 51.5417,
        "meteor": 0.42944336192721577,
        "bertscore": {
            "precision": 0.95965,
            "recall": 0.94816,
            "f1": 0.95258
        },
        "nubia": {
            "semantic_relation": 4.71301,
            "contradiction": 0.39259,
            "irrelevancy": 6.06681,
            "logical_agreement": 93.54061,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.24685,
            "nubia_score": 0.91235
        },
        "bleurt": 0.54253
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 1.8027756377319946,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 45,
        "unique-1": 39,
        "entropy-1": 5.370537733604885,
        "distinct-2": 0.98,
        "vocab_size-2": 49,
        "unique-2": 48,
        "entropy-2": 5.603856189774728,
        "cond_entropy-2": 0.10406643765452553,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.07681597284814654,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 1.479019945774904,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9148936170212766,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.384376085720193,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.379753126795121,
        "cond_entropy-2-nopunct": 0.011210786745390881,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.08958048455779835,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.2,
            "3": 0.5892857142857143
        },
        "nist": 3.783741252927306,
        "rouge1": {
            "precision": 0.8557,
            "recall": 0.67895,
            "fmeasure": 0.73929
        },
        "rouge2": {
            "precision": 0.6711,
            "recall": 0.569,
            "fmeasure": 0.60247
        },
        "rougeL": {
            "precision": 0.72881,
            "recall": 0.61766,
            "fmeasure": 0.65714
        },
        "rougeLsum": {
            "precision": 0.72881,
            "recall": 0.61766,
            "fmeasure": 0.65714
        },
        "bleu": 50.51134,
        "meteor": 0.3633308264694072,
        "bertscore": {
            "precision": 0.93962,
            "recall": 0.89961,
            "f1": 0.91769
        },
        "nubia": {
            "semantic_relation": 4.19816,
            "contradiction": 0.25248,
            "irrelevancy": 16.77765,
            "logical_agreement": 82.96988,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.49554,
            "nubia_score": 0.73703
        },
        "bleurt": 0.34801
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.926427859887888,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.10674500480228637,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9142857142857143,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.957854445516392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.058216983055033575,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.5555555555555556,
            "3": 0.8181818181818182
        },
        "nist": 3.9744589489518507,
        "rouge1": {
            "precision": 0.69048,
            "recall": 0.84492,
            "fmeasure": 0.74635
        },
        "rouge2": {
            "precision": 0.54815,
            "recall": 0.66111,
            "fmeasure": 0.58528
        },
        "rougeL": {
            "precision": 0.69048,
            "recall": 0.84492,
            "fmeasure": 0.74635
        },
        "rougeLsum": {
            "precision": 0.69048,
            "recall": 0.84492,
            "fmeasure": 0.74635
        },
        "bleu": 59.83268,
        "meteor": 0.42563660201812387,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.93358,
            "f1": 0.92544
        },
        "nubia": {
            "semantic_relation": 4.24622,
            "contradiction": 14.34165,
            "irrelevancy": 46.81568,
            "logical_agreement": 38.84266,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.37291,
            "nubia_score": 0.75958
        },
        "bleurt": 0.50715
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 3.7202150475476548,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.6164383561643836,
        "vocab_size-1": 45,
        "unique-1": 32,
        "entropy-1": 5.20161955220307,
        "distinct-2": 0.8529411764705882,
        "vocab_size-2": 58,
        "unique-2": 51,
        "entropy-2": 5.760041333801956,
        "cond_entropy-2": 0.4603539074657697,
        "distinct-3": 0.9365079365079365,
        "vocab_size-3": 59,
        "unique-3": 56,
        "entropy-3": 5.838313455211611,
        "cond_entropy-3": 0.028783550537886164,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 13.2,
        "std_pred_length-nopunct": 3.4292856398964493,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6515151515151515,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.157586164616325,
        "distinct-2-nopunct": 0.8852459016393442,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.676478730934573,
        "cond_entropy-2-nopunct": 0.5136327674911608,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.735926350629038,
        "cond_entropy-3-nopunct": -0.00275942439522011,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.7619047619047619
        },
        "nist": 3.972350027450302,
        "rouge1": {
            "precision": 0.722,
            "recall": 0.75207,
            "fmeasure": 0.7251
        },
        "rouge2": {
            "precision": 0.52771,
            "recall": 0.58144,
            "fmeasure": 0.54318
        },
        "rougeL": {
            "precision": 0.58355,
            "recall": 0.63027,
            "fmeasure": 0.59564
        },
        "rougeLsum": {
            "precision": 0.58355,
            "recall": 0.63027,
            "fmeasure": 0.59564
        },
        "bleu": 33.02543,
        "meteor": 0.3501792621874316,
        "bertscore": {
            "precision": 0.9154,
            "recall": 0.92213,
            "f1": 0.91509
        },
        "nubia": {
            "semantic_relation": 4.22826,
            "contradiction": 15.55011,
            "irrelevancy": 41.63215,
            "logical_agreement": 42.81774,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.59847,
            "nubia_score": 0.7601
        },
        "bleurt": 0.22873
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76333,
        "total_length": 352,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.422166387140533,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6136363636363636,
        "vocab_size-1": 216,
        "unique-1": 188,
        "entropy-1": 6.988203791898016,
        "distinct-2": 0.9573170731707317,
        "vocab_size-2": 314,
        "unique-2": 303,
        "entropy-2": 8.261181149513103,
        "cond_entropy-2": 1.063427183384677,
        "distinct-3": 1.0,
        "vocab_size-3": 304,
        "unique-3": 304,
        "entropy-3": 8.247927513443585,
        "cond_entropy-3": -0.005645410666482214,
        "total_length-nopunct": 311,
        "mean_pred_length-nopunct": 12.958333333333334,
        "std_pred_length-nopunct": 4.138026569379284,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6816720257234726,
        "vocab_size-1-nopunct": 212,
        "unique-1-nopunct": 186,
        "entropy-1-nopunct": 7.155914596423502,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 273,
        "unique-2-nopunct": 262,
        "entropy-2-nopunct": 8.054768806555662,
        "cond_entropy-2-nopunct": 0.9664903971295903,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 263,
        "unique-3-nopunct": 263,
        "entropy-3-nopunct": 8.038918989292329,
        "cond_entropy-3-nopunct": -0.005799190332294735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06382978723404255,
            "2": 0.32558139534883723,
            "3": 0.7890295358649789
        },
        "nist": 5.725642911932594,
        "rouge1": {
            "precision": 0.76522,
            "recall": 0.72068,
            "fmeasure": 0.73443
        },
        "rouge2": {
            "precision": 0.50832,
            "recall": 0.47376,
            "fmeasure": 0.48555
        },
        "rougeL": {
            "precision": 0.69883,
            "recall": 0.64929,
            "fmeasure": 0.66585
        },
        "rougeLsum": {
            "precision": 0.69883,
            "recall": 0.64929,
            "fmeasure": 0.66585
        },
        "bleu": 37.99591,
        "meteor": 0.38131627942930857,
        "bertscore": {
            "precision": 0.9318,
            "recall": 0.92592,
            "f1": 0.92708
        },
        "nubia": {
            "semantic_relation": 4.27099,
            "contradiction": 7.19331,
            "irrelevancy": 34.21371,
            "logical_agreement": 58.59297,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.6574,
            "nubia_score": 0.76217
        },
        "bleurt": 0.29416
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "total_length": 179,
        "mean_pred_length": 16.272727272727273,
        "std_pred_length": 4.825894341813454,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.6759776536312849,
        "vocab_size-1": 121,
        "unique-1": 98,
        "entropy-1": 6.469720562333121,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 162,
        "unique-2": 158,
        "entropy-2": 7.308984089445456,
        "cond_entropy-2": 0.7277021849114405,
        "distinct-3": 0.9936305732484076,
        "vocab_size-3": 156,
        "unique-3": 155,
        "entropy-3": 7.281881895388438,
        "cond_entropy-3": -0.02126355286802528,
        "total_length-nopunct": 159,
        "mean_pred_length-nopunct": 14.454545454545455,
        "std_pred_length-nopunct": 4.755162483862553,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7358490566037735,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 98,
        "entropy-1-nopunct": 6.502857876545521,
        "distinct-2-nopunct": 0.9594594594594594,
        "vocab_size-2-nopunct": 142,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.114858771034353,
        "cond_entropy-2-nopunct": 0.6654487043950764,
        "distinct-3-nopunct": 0.9927007299270073,
        "vocab_size-3-nopunct": 136,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 7.083433542814526,
        "cond_entropy-3-nopunct": -0.03112931186550341,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08108108108108109,
            "2": 0.425,
            "3": 0.6050420168067226
        },
        "nist": 3.808350257296136,
        "rouge1": {
            "precision": 0.65639,
            "recall": 0.57591,
            "fmeasure": 0.5961
        },
        "rouge2": {
            "precision": 0.40919,
            "recall": 0.34523,
            "fmeasure": 0.36337
        },
        "rougeL": {
            "precision": 0.54846,
            "recall": 0.47581,
            "fmeasure": 0.49323
        },
        "rougeLsum": {
            "precision": 0.54846,
            "recall": 0.47581,
            "fmeasure": 0.49323
        },
        "bleu": 29.3854,
        "meteor": 0.28150180554843995,
        "bertscore": {
            "precision": 0.88212,
            "recall": 0.8706,
            "f1": 0.87424
        },
        "nubia": {
            "semantic_relation": 3.40687,
            "contradiction": 16.10268,
            "irrelevancy": 33.86696,
            "logical_agreement": 50.03036,
            "grammar_ref": 4.70623,
            "grammar_hyp": 5.07226,
            "nubia_score": 0.50244
        },
        "bleurt": -0.1389
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.6525,
        "msttr-100_nopunct": 0.7,
        "total_length": 400,
        "mean_pred_length": 17.391304347826086,
        "std_pred_length": 5.010763462047454,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.52,
        "vocab_size-1": 208,
        "unique-1": 162,
        "entropy-1": 6.868505383091828,
        "distinct-2": 0.8567639257294429,
        "vocab_size-2": 323,
        "unique-2": 297,
        "entropy-2": 8.173779517272106,
        "cond_entropy-2": 1.1496102230939673,
        "distinct-3": 0.9491525423728814,
        "vocab_size-3": 336,
        "unique-3": 326,
        "entropy-3": 8.342282024725337,
        "cond_entropy-3": 0.16069772506195226,
        "total_length-nopunct": 354,
        "mean_pred_length-nopunct": 15.391304347826088,
        "std_pred_length-nopunct": 4.361283521034911,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5734463276836158,
        "vocab_size-1-nopunct": 203,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 6.9687029247084205,
        "distinct-2-nopunct": 0.8610271903323263,
        "vocab_size-2-nopunct": 285,
        "unique-2-nopunct": 262,
        "entropy-2-nopunct": 7.996396423689554,
        "cond_entropy-2-nopunct": 1.064757126690778,
        "distinct-3-nopunct": 0.9577922077922078,
        "vocab_size-3-nopunct": 295,
        "unique-3-nopunct": 287,
        "entropy-3-nopunct": 8.166933009843678,
        "cond_entropy-3-nopunct": 0.1477669611563782,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25333333333333335,
            "2": 0.5573770491803278,
            "3": 0.7754237288135594
        },
        "nist": 6.0370915099927895,
        "rouge1": {
            "precision": 0.73197,
            "recall": 0.77637,
            "fmeasure": 0.74548
        },
        "rouge2": {
            "precision": 0.52809,
            "recall": 0.55667,
            "fmeasure": 0.53583
        },
        "rougeL": {
            "precision": 0.62431,
            "recall": 0.66759,
            "fmeasure": 0.63849
        },
        "rougeLsum": {
            "precision": 0.62431,
            "recall": 0.66759,
            "fmeasure": 0.63849
        },
        "bleu": 45.36207,
        "meteor": 0.406662357382184,
        "bertscore": {
            "precision": 0.91645,
            "recall": 0.9254,
            "f1": 0.91919
        },
        "nubia": {
            "semantic_relation": 4.30723,
            "contradiction": 7.36773,
            "irrelevancy": 33.07486,
            "logical_agreement": 59.55741,
            "grammar_ref": 4.22562,
            "grammar_hyp": 3.87319,
            "nubia_score": 0.79612
        },
        "bleurt": 0.26604
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.74,
        "total_length": 284,
        "mean_pred_length": 15.777777777777779,
        "std_pred_length": 5.3287016925696875,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6338028169014085,
        "vocab_size-1": 180,
        "unique-1": 153,
        "entropy-1": 6.866058005887779,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 252,
        "unique-2": 242,
        "entropy-2": 7.936824634733093,
        "cond_entropy-2": 0.9170313057065799,
        "distinct-3": 0.9879032258064516,
        "vocab_size-3": 245,
        "unique-3": 242,
        "entropy-3": 7.930002761999805,
        "cond_entropy-3": 0.0017758708708749205,
        "total_length-nopunct": 250,
        "mean_pred_length-nopunct": 13.88888888888889,
        "std_pred_length-nopunct": 4.6294814791110355,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.696,
        "vocab_size-1-nopunct": 174,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 6.934429675406078,
        "distinct-2-nopunct": 0.9439655172413793,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 210,
        "entropy-2-nopunct": 7.7307836890744195,
        "cond_entropy-2-nopunct": 0.8763729057658228,
        "distinct-3-nopunct": 0.985981308411215,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 208,
        "entropy-3-nopunct": 7.713429603223543,
        "cond_entropy-3-nopunct": -0.006655247023962804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2111111111111111,
            "2": 0.34,
            "3": 0.7272727272727273
        },
        "nist": 5.958293154431671,
        "rouge1": {
            "precision": 0.75292,
            "recall": 0.70264,
            "fmeasure": 0.71156
        },
        "rouge2": {
            "precision": 0.53489,
            "recall": 0.51261,
            "fmeasure": 0.50981
        },
        "rougeL": {
            "precision": 0.65787,
            "recall": 0.64424,
            "fmeasure": 0.63388
        },
        "rougeLsum": {
            "precision": 0.65787,
            "recall": 0.64424,
            "fmeasure": 0.63388
        },
        "bleu": 47.61204,
        "meteor": 0.3916929722291515,
        "bertscore": {
            "precision": 0.93007,
            "recall": 0.9198,
            "f1": 0.91995
        },
        "nubia": {
            "semantic_relation": 4.04253,
            "contradiction": 13.09897,
            "irrelevancy": 22.73115,
            "logical_agreement": 64.16988,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.42827,
            "nubia_score": 0.69268
        },
        "bleurt": 0.20817
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.68,
        "total_length": 187,
        "mean_pred_length": 15.583333333333334,
        "std_pred_length": 5.122797629767894,
        "median_pred_length": 16.5,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.5989304812834224,
        "vocab_size-1": 112,
        "unique-1": 86,
        "entropy-1": 6.275541770276056,
        "distinct-2": 0.8914285714285715,
        "vocab_size-2": 156,
        "unique-2": 142,
        "entropy-2": 7.209698754652362,
        "cond_entropy-2": 0.8315109919561179,
        "distinct-3": 0.9631901840490797,
        "vocab_size-3": 157,
        "unique-3": 152,
        "entropy-3": 7.270477310659546,
        "cond_entropy-3": 0.07855860684247229,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 5.018714974971183,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.631578947368421,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.268591275070159,
        "distinct-2-nopunct": 0.8930817610062893,
        "vocab_size-2-nopunct": 142,
        "unique-2-nopunct": 130,
        "entropy-2-nopunct": 7.072224700526526,
        "cond_entropy-2-nopunct": 0.874112497010273,
        "distinct-3-nopunct": 0.9591836734693877,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 136,
        "entropy-3-nopunct": 7.112904402644768,
        "cond_entropy-3-nopunct": 0.0603252739351855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.2903225806451613,
            "3": 0.6335877862595419
        },
        "nist": 4.768160243689047,
        "rouge1": {
            "precision": 0.67827,
            "recall": 0.65315,
            "fmeasure": 0.64411
        },
        "rouge2": {
            "precision": 0.48511,
            "recall": 0.479,
            "fmeasure": 0.466
        },
        "rougeL": {
            "precision": 0.59782,
            "recall": 0.58204,
            "fmeasure": 0.57024
        },
        "rougeLsum": {
            "precision": 0.59782,
            "recall": 0.58204,
            "fmeasure": 0.57024
        },
        "bleu": 39.30055,
        "meteor": 0.32918866120708534,
        "bertscore": {
            "precision": 0.90475,
            "recall": 0.89615,
            "f1": 0.8991
        },
        "nubia": {
            "semantic_relation": 3.62271,
            "contradiction": 8.21879,
            "irrelevancy": 54.59426,
            "logical_agreement": 37.18695,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.81528,
            "nubia_score": 0.53774
        },
        "bleurt": -0.05424
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.8333333333333334
        },
        "nist": 1.6844129532345626,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.2,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "bleu": 11.0448,
        "meteor": 0.32113104578927515,
        "bertscore": {
            "precision": 0.84972,
            "recall": 0.88149,
            "f1": 0.86531
        },
        "nubia": {
            "semantic_relation": 3.40073,
            "contradiction": 2.68055,
            "irrelevancy": 66.26028,
            "logical_agreement": 31.05917,
            "grammar_ref": 6.80479,
            "grammar_hyp": 5.43908,
            "nubia_score": 0.5901
        },
        "bleurt": 0.06133
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": 0.02961067210860199,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.20184123230257,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.221928094887362,
        "cond_entropy-2-nopunct": -0.020389327891398017,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.021369002496408336,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.625,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.2260686272617063,
        "rouge1": {
            "precision": 0.65217,
            "recall": 0.72744,
            "fmeasure": 0.68347
        },
        "rouge2": {
            "precision": 0.43939,
            "recall": 0.49383,
            "fmeasure": 0.4619
        },
        "rougeL": {
            "precision": 0.53623,
            "recall": 0.58709,
            "fmeasure": 0.55649
        },
        "rougeLsum": {
            "precision": 0.53623,
            "recall": 0.58709,
            "fmeasure": 0.55649
        },
        "bleu": 35.21556,
        "meteor": 0.4358757824271386,
        "bertscore": {
            "precision": 0.9208,
            "recall": 0.95039,
            "f1": 0.93536
        },
        "nubia": {
            "semantic_relation": 3.59531,
            "contradiction": 99.21571,
            "irrelevancy": 0.68811,
            "logical_agreement": 0.09618,
            "grammar_ref": 3.99891,
            "grammar_hyp": 5.18454,
            "nubia_score": 0.44166
        },
        "bleurt": -0.26126
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.775,
        "total_length": 467,
        "mean_pred_length": 15.064516129032258,
        "std_pred_length": 5.041348282731948,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.5331905781584583,
        "vocab_size-1": 249,
        "unique-1": 186,
        "entropy-1": 7.170901820726807,
        "distinct-2": 0.8876146788990825,
        "vocab_size-2": 387,
        "unique-2": 359,
        "entropy-2": 8.47607825496887,
        "cond_entropy-2": 1.088160302637145,
        "distinct-3": 0.9580246913580247,
        "vocab_size-3": 388,
        "unique-3": 376,
        "entropy-3": 8.567297449607768,
        "cond_entropy-3": 0.10863965924148297,
        "total_length-nopunct": 408,
        "mean_pred_length-nopunct": 13.161290322580646,
        "std_pred_length-nopunct": 4.558556465016646,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5980392156862745,
        "vocab_size-1-nopunct": 244,
        "unique-1-nopunct": 185,
        "entropy-1-nopunct": 7.332417076476638,
        "distinct-2-nopunct": 0.8859416445623343,
        "vocab_size-2-nopunct": 334,
        "unique-2-nopunct": 310,
        "entropy-2-nopunct": 8.257735709458858,
        "cond_entropy-2-nopunct": 0.9879590672707164,
        "distinct-3-nopunct": 0.9624277456647399,
        "vocab_size-3-nopunct": 333,
        "unique-3-nopunct": 323,
        "entropy-3-nopunct": 8.352938451606384,
        "cond_entropy-3-nopunct": 0.11178156474112314,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1836734693877551,
            "2": 0.5051546391752577,
            "3": 0.7416107382550335
        },
        "nist": 6.054276645689224,
        "rouge1": {
            "precision": 0.74257,
            "recall": 0.68894,
            "fmeasure": 0.70205
        },
        "rouge2": {
            "precision": 0.487,
            "recall": 0.45701,
            "fmeasure": 0.46252
        },
        "rougeL": {
            "precision": 0.61533,
            "recall": 0.58178,
            "fmeasure": 0.58523
        },
        "rougeLsum": {
            "precision": 0.61533,
            "recall": 0.58178,
            "fmeasure": 0.58523
        },
        "bleu": 43.59567,
        "meteor": 0.38153122164734155,
        "bertscore": {
            "precision": 0.9241,
            "recall": 0.92154,
            "f1": 0.92133
        },
        "nubia": {
            "semantic_relation": 4.04841,
            "contradiction": 4.17879,
            "irrelevancy": 33.48364,
            "logical_agreement": 62.33757,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.51828,
            "nubia_score": 0.68863
        },
        "bleurt": 0.25192
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.76333,
        "total_length": 342,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.047146145152359,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.6257309941520468,
        "vocab_size-1": 214,
        "unique-1": 183,
        "entropy-1": 7.012414712388597,
        "distinct-2": 0.9380804953560371,
        "vocab_size-2": 303,
        "unique-2": 290,
        "entropy-2": 8.18950981141604,
        "cond_entropy-2": 1.058529520846143,
        "distinct-3": 0.9835526315789473,
        "vocab_size-3": 299,
        "unique-3": 294,
        "entropy-3": 8.215032776601479,
        "cond_entropy-3": 0.031351025456120556,
        "total_length-nopunct": 302,
        "mean_pred_length-nopunct": 15.894736842105264,
        "std_pred_length-nopunct": 3.9053908334924516,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6920529801324503,
        "vocab_size-1-nopunct": 209,
        "unique-1-nopunct": 182,
        "entropy-1-nopunct": 7.129642517715996,
        "distinct-2-nopunct": 0.9363957597173145,
        "vocab_size-2-nopunct": 265,
        "unique-2-nopunct": 254,
        "entropy-2-nopunct": 7.9922928171118475,
        "cond_entropy-2-nopunct": 0.9264894591505687,
        "distinct-3-nopunct": 0.9848484848484849,
        "vocab_size-3-nopunct": 260,
        "unique-3-nopunct": 256,
        "entropy-3-nopunct": 8.014091089055432,
        "cond_entropy-3-nopunct": 0.03276396546128226,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.45054945054945056,
            "3": 0.6820809248554913
        },
        "nist": 4.736172096471342,
        "rouge1": {
            "precision": 0.62008,
            "recall": 0.6284,
            "fmeasure": 0.61122
        },
        "rouge2": {
            "precision": 0.37979,
            "recall": 0.39649,
            "fmeasure": 0.38015
        },
        "rougeL": {
            "precision": 0.54054,
            "recall": 0.5631,
            "fmeasure": 0.53832
        },
        "rougeLsum": {
            "precision": 0.54054,
            "recall": 0.5631,
            "fmeasure": 0.53832
        },
        "bleu": 32.81311,
        "meteor": 0.31190236533960514,
        "bertscore": {
            "precision": 0.88055,
            "recall": 0.90009,
            "f1": 0.88758
        },
        "nubia": {
            "semantic_relation": 3.84263,
            "contradiction": 13.41597,
            "irrelevancy": 45.91052,
            "logical_agreement": 40.67351,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.52887,
            "nubia_score": 0.62906
        },
        "bleurt": 0.05333
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 11.6,
        "std_pred_length": 4.223742416388575,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.8103448275862069,
        "vocab_size-1": 47,
        "unique-1": 40,
        "entropy-1": 5.403420167944807,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.14833356325003225,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.1429579538420431,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.521363372331802,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.443856189774728,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.07021912877717221,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.16992500144231248,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.625,
            "3": 0.7894736842105263
        },
        "nist": 3.919252681997977,
        "rouge1": {
            "precision": 0.74303,
            "recall": 0.76328,
            "fmeasure": 0.74979
        },
        "rouge2": {
            "precision": 0.43648,
            "recall": 0.41721,
            "fmeasure": 0.42483
        },
        "rougeL": {
            "precision": 0.68735,
            "recall": 0.69714,
            "fmeasure": 0.68963
        },
        "rougeLsum": {
            "precision": 0.68735,
            "recall": 0.69714,
            "fmeasure": 0.68963
        },
        "bleu": 31.6446,
        "meteor": 0.40179960581387913,
        "bertscore": {
            "precision": 0.92196,
            "recall": 0.92364,
            "f1": 0.92266
        },
        "nubia": {
            "semantic_relation": 4.15984,
            "contradiction": 17.37806,
            "irrelevancy": 29.38251,
            "logical_agreement": 53.23943,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.32805,
            "nubia_score": 0.78574
        },
        "bleurt": 0.29788
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.75,
        "total_length": 319,
        "mean_pred_length": 18.764705882352942,
        "std_pred_length": 4.332224150475757,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.5705329153605015,
        "vocab_size-1": 182,
        "unique-1": 138,
        "entropy-1": 6.887315051181074,
        "distinct-2": 0.8708609271523179,
        "vocab_size-2": 263,
        "unique-2": 230,
        "entropy-2": 7.960675259255808,
        "cond_entropy-2": 0.9912606790286949,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 266,
        "unique-3": 247,
        "entropy-3": 8.021484775718786,
        "cond_entropy-3": 0.07386706439694492,
        "total_length-nopunct": 281,
        "mean_pred_length-nopunct": 16.529411764705884,
        "std_pred_length-nopunct": 3.8058414399110143,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6298932384341637,
        "vocab_size-1-nopunct": 177,
        "unique-1-nopunct": 138,
        "entropy-1-nopunct": 6.9547393195295335,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 228,
        "unique-2-nopunct": 197,
        "entropy-2-nopunct": 7.752275121332839,
        "cond_entropy-2-nopunct": 0.8697126162417634,
        "distinct-3-nopunct": 0.9271255060728745,
        "vocab_size-3-nopunct": 229,
        "unique-3-nopunct": 211,
        "entropy-3-nopunct": 7.802618243730454,
        "cond_entropy-3-nopunct": 0.06639989554105771,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18,
            "2": 0.5,
            "3": 0.7641509433962265
        },
        "nist": 5.560733901142356,
        "rouge1": {
            "precision": 0.69773,
            "recall": 0.74911,
            "fmeasure": 0.70876
        },
        "rouge2": {
            "precision": 0.46193,
            "recall": 0.50309,
            "fmeasure": 0.47017
        },
        "rougeL": {
            "precision": 0.59027,
            "recall": 0.64116,
            "fmeasure": 0.60095
        },
        "rougeLsum": {
            "precision": 0.59027,
            "recall": 0.64116,
            "fmeasure": 0.60095
        },
        "bleu": 38.11481,
        "meteor": 0.37778239067261565,
        "bertscore": {
            "precision": 0.89897,
            "recall": 0.9213,
            "f1": 0.90713
        },
        "nubia": {
            "semantic_relation": 4.01527,
            "contradiction": 13.5553,
            "irrelevancy": 49.03166,
            "logical_agreement": 37.41304,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.41478,
            "nubia_score": 0.66254
        },
        "bleurt": 0.04657
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 107,
        "mean_pred_length": 17.833333333333332,
        "std_pred_length": 4.099457958749614,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.6448598130841121,
        "vocab_size-1": 69,
        "unique-1": 50,
        "entropy-1": 5.770920524420167,
        "distinct-2": 0.9405940594059405,
        "vocab_size-2": 95,
        "unique-2": 89,
        "entropy-2": 6.5393996015636615,
        "cond_entropy-2": 0.6725731738520065,
        "distinct-3": 0.9789473684210527,
        "vocab_size-3": 93,
        "unique-3": 91,
        "entropy-3": 6.527750345173053,
        "cond_entropy-3": -0.004145348105057383,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 15.833333333333334,
        "std_pred_length-nopunct": 3.8042374035044424,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.703132488040027,
        "distinct-2-nopunct": 0.9325842696629213,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.340901970292251,
        "cond_entropy-2-nopunct": 0.6737283442942958,
        "distinct-3-nopunct": 0.9759036144578314,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.326846660262594,
        "cond_entropy-3-nopunct": -0.0043084574507982875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.4166666666666667,
            "3": 0.7916666666666666
        },
        "nist": 3.920322376761787,
        "rouge1": {
            "precision": 0.64571,
            "recall": 0.73354,
            "fmeasure": 0.65867
        },
        "rouge2": {
            "precision": 0.43886,
            "recall": 0.48851,
            "fmeasure": 0.44262
        },
        "rougeL": {
            "precision": 0.55808,
            "recall": 0.61943,
            "fmeasure": 0.56513
        },
        "rougeLsum": {
            "precision": 0.55808,
            "recall": 0.61943,
            "fmeasure": 0.56513
        },
        "bleu": 35.726,
        "meteor": 0.3827092020391425,
        "bertscore": {
            "precision": 0.87285,
            "recall": 0.8921,
            "f1": 0.88124
        },
        "nubia": {
            "semantic_relation": 3.93811,
            "contradiction": 1.38216,
            "irrelevancy": 62.51788,
            "logical_agreement": 36.09996,
            "grammar_ref": 4.25456,
            "grammar_hyp": 3.92288,
            "nubia_score": 0.67951
        },
        "bleurt": 0.02766
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.79,
        "total_length": 194,
        "mean_pred_length": 17.636363636363637,
        "std_pred_length": 5.514818504764764,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.6855670103092784,
        "vocab_size-1": 133,
        "unique-1": 114,
        "entropy-1": 6.601140293577837,
        "distinct-2": 0.9672131147540983,
        "vocab_size-2": 177,
        "unique-2": 172,
        "entropy-2": 7.446000999474401,
        "cond_entropy-2": 0.7489982633922984,
        "distinct-3": 1.0,
        "vocab_size-3": 172,
        "unique-3": 172,
        "entropy-3": 7.426264754702066,
        "cond_entropy-3": -0.015278760894947455,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 15.545454545454545,
        "std_pred_length-nopunct": 5.0876613016848085,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7543859649122807,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.669236909807851,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 155,
        "unique-2-nopunct": 151,
        "entropy-2-nopunct": 7.254710047998846,
        "cond_entropy-2-nopunct": 0.6270344454105923,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 149,
        "unique-3-nopunct": 149,
        "entropy-3-nopunct": 7.21916852046217,
        "cond_entropy-3-nopunct": -0.030579121390546606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.3684210526315789,
            "3": 0.7928571428571428
        },
        "nist": 5.450524619461197,
        "rouge1": {
            "precision": 0.72529,
            "recall": 0.75905,
            "fmeasure": 0.72418
        },
        "rouge2": {
            "precision": 0.51767,
            "recall": 0.54377,
            "fmeasure": 0.51636
        },
        "rougeL": {
            "precision": 0.66355,
            "recall": 0.68358,
            "fmeasure": 0.65867
        },
        "rougeLsum": {
            "precision": 0.66355,
            "recall": 0.68358,
            "fmeasure": 0.65867
        },
        "bleu": 45.43375,
        "meteor": 0.42775290493848456,
        "bertscore": {
            "precision": 0.90676,
            "recall": 0.91778,
            "f1": 0.91124
        },
        "nubia": {
            "semantic_relation": 3.87231,
            "contradiction": 24.31195,
            "irrelevancy": 28.97111,
            "logical_agreement": 46.71693,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.13045,
            "nubia_score": 0.69643
        },
        "bleurt": 0.12112
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 14.285714285714286,
        "std_pred_length": 5.390846361175202,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.73,
        "vocab_size-1": 73,
        "unique-1": 62,
        "entropy-1": 5.892501910677062,
        "distinct-2": 0.989247311827957,
        "vocab_size-2": 92,
        "unique-2": 91,
        "entropy-2": 6.51765343476395,
        "cond_entropy-2": 0.5149332977358909,
        "distinct-3": 1.0,
        "vocab_size-3": 86,
        "unique-3": 86,
        "entropy-3": 6.426264754702099,
        "cond_entropy-3": -0.08963824245244507,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 4.712120714991612,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.797752808988764,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.936227673314682,
        "distinct-2-nopunct": 0.9878048780487805,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.333161760715647,
        "cond_entropy-2-nopunct": 0.44298945695660685,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.228818690495891,
        "cond_entropy-3-nopunct": -0.1020666474555363,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.46153846153846156,
            "2": 0.5555555555555556,
            "3": 0.6153846153846154
        },
        "nist": 4.710230577905028,
        "rouge1": {
            "precision": 0.67339,
            "recall": 0.64471,
            "fmeasure": 0.65245
        },
        "rouge2": {
            "precision": 0.45698,
            "recall": 0.41945,
            "fmeasure": 0.43229
        },
        "rougeL": {
            "precision": 0.58022,
            "recall": 0.57066,
            "fmeasure": 0.56896
        },
        "rougeLsum": {
            "precision": 0.58022,
            "recall": 0.57066,
            "fmeasure": 0.56896
        },
        "bleu": 36.12429,
        "meteor": 0.32308918890179256,
        "bertscore": {
            "precision": 0.9216,
            "recall": 0.91203,
            "f1": 0.91666
        },
        "nubia": {
            "semantic_relation": 4.20814,
            "contradiction": 16.22639,
            "irrelevancy": 21.83327,
            "logical_agreement": 61.94034,
            "grammar_ref": 4.57813,
            "grammar_hyp": 3.94777,
            "nubia_score": 0.77378
        },
        "bleurt": 0.25947
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.58,
        "msttr-100_nopunct": NaN,
        "total_length": 108,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.24037034920393,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.5462962962962963,
        "vocab_size-1": 59,
        "unique-1": 43,
        "entropy-1": 5.44900266475923,
        "distinct-2": 0.73,
        "vocab_size-2": 73,
        "unique-2": 61,
        "entropy-2": 5.947759785030366,
        "cond_entropy-2": 0.3632279072634622,
        "distinct-3": 0.7717391304347826,
        "vocab_size-3": 71,
        "unique-3": 62,
        "entropy-3": 5.936605434317894,
        "cond_entropy-3": 0.049375771439210105,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 3.072051431861127,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6063829787234043,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.474527283216672,
        "distinct-2-nopunct": 0.7209302325581395,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.7098735863946946,
        "cond_entropy-2-nopunct": 0.2971900758849988,
        "distinct-3-nopunct": 0.7692307692307693,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.695658629118662,
        "cond_entropy-3-nopunct": 0.04644054716575048,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.9012345679012346
        },
        "nist": 5.636276545043579,
        "rouge1": {
            "precision": 0.86421,
            "recall": 0.8696,
            "fmeasure": 0.86515
        },
        "rouge2": {
            "precision": 0.77308,
            "recall": 0.76695,
            "fmeasure": 0.7689
        },
        "rougeL": {
            "precision": 0.83376,
            "recall": 0.83589,
            "fmeasure": 0.83332
        },
        "rougeLsum": {
            "precision": 0.83376,
            "recall": 0.83589,
            "fmeasure": 0.83332
        },
        "bleu": 67.27583,
        "meteor": 0.4938439157060303,
        "bertscore": {
            "precision": 0.9584,
            "recall": 0.9681,
            "f1": 0.96252
        },
        "nubia": {
            "semantic_relation": 4.47299,
            "contradiction": 0.53901,
            "irrelevancy": 22.15168,
            "logical_agreement": 77.30931,
            "grammar_ref": 5.07225,
            "grammar_hyp": 4.88979,
            "nubia_score": 0.85774
        },
        "bleurt": 0.65449
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.625
        },
        "nist": 2.0818734482105152,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.625,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "bleu": 15.44788,
        "meteor": 0.35772595517358696,
        "bertscore": {
            "precision": 0.97848,
            "recall": 0.92917,
            "f1": 0.95319
        },
        "nubia": {
            "semantic_relation": 4.89215,
            "contradiction": 0.31878,
            "irrelevancy": 0.49621,
            "logical_agreement": 99.18501,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.92558,
            "nubia_score": 0.97134
        },
        "bleurt": 0.71323
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 4.496912521077347,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 5.0124798907455554,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.33886297311400265,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.1043366598147359,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 4.027681991198191,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8292682926829268,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.948896211882388,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.3312936009876985,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.8125,
            "3": 1.0
        },
        "nist": 4.232729479706662,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.76865,
            "fmeasure": 0.72138
        },
        "rouge2": {
            "precision": 0.51786,
            "recall": 0.54167,
            "fmeasure": 0.51877
        },
        "rougeL": {
            "precision": 0.63971,
            "recall": 0.66259,
            "fmeasure": 0.63805
        },
        "rougeLsum": {
            "precision": 0.63971,
            "recall": 0.66259,
            "fmeasure": 0.63805
        },
        "bleu": 55.26099,
        "meteor": 0.4695187730218488,
        "bertscore": {
            "precision": 0.90937,
            "recall": 0.92101,
            "f1": 0.91377
        },
        "nubia": {
            "semantic_relation": 3.51622,
            "contradiction": 0.30776,
            "irrelevancy": 65.55788,
            "logical_agreement": 34.13436,
            "grammar_ref": 4.86076,
            "grammar_hyp": 4.66595,
            "nubia_score": 0.56024
        },
        "bleurt": 0.1106
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.73,
        "total_length": 200,
        "mean_pred_length": 15.384615384615385,
        "std_pred_length": 4.0485222667510055,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.595,
        "vocab_size-1": 119,
        "unique-1": 97,
        "entropy-1": 6.30001623531806,
        "distinct-2": 0.9144385026737968,
        "vocab_size-2": 171,
        "unique-2": 161,
        "entropy-2": 7.330817604504907,
        "cond_entropy-2": 0.8595409703696991,
        "distinct-3": 0.9827586206896551,
        "vocab_size-3": 171,
        "unique-3": 168,
        "entropy-3": 7.408460737228018,
        "cond_entropy-3": 0.0937868058264173,
        "total_length-nopunct": 173,
        "mean_pred_length-nopunct": 13.307692307692308,
        "std_pred_length-nopunct": 3.450409460308585,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6705202312138728,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.437833591949589,
        "distinct-2-nopunct": 0.9125,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.094388270158825,
        "cond_entropy-2-nopunct": 0.7151382267293032,
        "distinct-3-nopunct": 0.9863945578231292,
        "vocab_size-3-nopunct": 145,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.172461460482613,
        "cond_entropy-3-nopunct": 0.09819575985761904,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.23529411764705882,
            "3": 0.7908496732026143
        },
        "nist": 5.59377397475131,
        "rouge1": {
            "precision": 0.7586,
            "recall": 0.74713,
            "fmeasure": 0.74927
        },
        "rouge2": {
            "precision": 0.57899,
            "recall": 0.5691,
            "fmeasure": 0.57158
        },
        "rougeL": {
            "precision": 0.65337,
            "recall": 0.64049,
            "fmeasure": 0.64398
        },
        "rougeLsum": {
            "precision": 0.65337,
            "recall": 0.64049,
            "fmeasure": 0.64398
        },
        "bleu": 48.42777,
        "meteor": 0.42217674012477807,
        "bertscore": {
            "precision": 0.9385,
            "recall": 0.93586,
            "f1": 0.93693
        },
        "nubia": {
            "semantic_relation": 4.36995,
            "contradiction": 9.22919,
            "irrelevancy": 11.3362,
            "logical_agreement": 79.43461,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.74038,
            "nubia_score": 0.79346
        },
        "bleurt": 0.52038
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.0,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 32,
        "unique-1": 30,
        "entropy-1": 4.892147223664533,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.2116554868668507,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9666666666666667,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.840223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": -0.028107102122342922,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.4473684210526316
        },
        "nist": 1.608287126346894,
        "rouge1": {
            "precision": 0.72556,
            "recall": 0.58574,
            "fmeasure": 0.61618
        },
        "rouge2": {
            "precision": 0.49145,
            "recall": 0.41715,
            "fmeasure": 0.42842
        },
        "rougeL": {
            "precision": 0.64662,
            "recall": 0.54897,
            "fmeasure": 0.56607
        },
        "rougeLsum": {
            "precision": 0.64662,
            "recall": 0.54897,
            "fmeasure": 0.56607
        },
        "bleu": 24.96706,
        "meteor": 0.2629642652448984,
        "bertscore": {
            "precision": 0.93927,
            "recall": 0.91778,
            "f1": 0.92764
        },
        "nubia": {
            "semantic_relation": 3.53929,
            "contradiction": 9.07663,
            "irrelevancy": 68.41946,
            "logical_agreement": 22.50392,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.67013,
            "nubia_score": 0.41719
        },
        "bleurt": -0.10391
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.82,
        "total_length": 182,
        "mean_pred_length": 18.2,
        "std_pred_length": 4.749736834815167,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 130,
        "unique-1": 113,
        "entropy-1": 6.644198332907088,
        "distinct-2": 0.9941860465116279,
        "vocab_size-2": 171,
        "unique-2": 170,
        "entropy-2": 7.414636847725322,
        "cond_entropy-2": 0.6547794337713901,
        "distinct-3": 1.0,
        "vocab_size-3": 162,
        "unique-3": 162,
        "entropy-3": 7.339850002884606,
        "cond_entropy-3": -0.07406907280512748,
        "total_length-nopunct": 162,
        "mean_pred_length-nopunct": 16.2,
        "std_pred_length-nopunct": 4.331281565541543,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7716049382716049,
        "vocab_size-1-nopunct": 125,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.693891960205016,
        "distinct-2-nopunct": 0.993421052631579,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.234769618706724,
        "cond_entropy-2-nopunct": 0.5833748981516848,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 142,
        "entropy-3-nopunct": 7.149747119504689,
        "cond_entropy-3-nopunct": -0.08409588689665021,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.6842105263157895,
            "3": 0.7524752475247525
        },
        "nist": 5.329550346491309,
        "rouge1": {
            "precision": 0.69905,
            "recall": 0.72481,
            "fmeasure": 0.69556
        },
        "rouge2": {
            "precision": 0.49503,
            "recall": 0.48403,
            "fmeasure": 0.48149
        },
        "rougeL": {
            "precision": 0.59485,
            "recall": 0.61486,
            "fmeasure": 0.59282
        },
        "rougeLsum": {
            "precision": 0.59485,
            "recall": 0.61486,
            "fmeasure": 0.59282
        },
        "bleu": 48.71463,
        "meteor": 0.40104010089913594,
        "bertscore": {
            "precision": 0.91683,
            "recall": 0.91953,
            "f1": 0.91665
        },
        "nubia": {
            "semantic_relation": 4.23155,
            "contradiction": 0.75642,
            "irrelevancy": 38.82567,
            "logical_agreement": 60.41791,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.66851,
            "nubia_score": 0.76806
        },
        "bleurt": 0.25521
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.71,
        "total_length": 197,
        "mean_pred_length": 16.416666666666668,
        "std_pred_length": 4.698551786336816,
        "median_pred_length": 15.5,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.5989847715736041,
        "vocab_size-1": 118,
        "unique-1": 95,
        "entropy-1": 6.298589696078646,
        "distinct-2": 0.9567567567567568,
        "vocab_size-2": 177,
        "unique-2": 171,
        "entropy-2": 7.434084163219003,
        "cond_entropy-2": 0.999428508629657,
        "distinct-3": 0.9942196531791907,
        "vocab_size-3": 172,
        "unique-3": 171,
        "entropy-3": 7.423067533995107,
        "cond_entropy-3": -0.004267683746639451,
        "total_length-nopunct": 176,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 4.784233364802441,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6534090909090909,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.341998149885038,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 156,
        "unique-2-nopunct": 150,
        "entropy-2-nopunct": 7.247795907057129,
        "cond_entropy-2-nopunct": 0.9814636207393154,
        "distinct-3-nopunct": 0.993421052631579,
        "vocab_size-3-nopunct": 151,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.234769618706724,
        "cond_entropy-3-nopunct": -0.010940280648182123,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2236842105263158,
            "2": 0.45161290322580644,
            "3": 0.6442307692307693
        },
        "nist": 4.617864661222999,
        "rouge1": {
            "precision": 0.61834,
            "recall": 0.66781,
            "fmeasure": 0.63172
        },
        "rouge2": {
            "precision": 0.39231,
            "recall": 0.435,
            "fmeasure": 0.40468
        },
        "rougeL": {
            "precision": 0.5454,
            "recall": 0.59834,
            "fmeasure": 0.56005
        },
        "rougeLsum": {
            "precision": 0.5454,
            "recall": 0.59834,
            "fmeasure": 0.56005
        },
        "bleu": 33.39797,
        "meteor": 0.34091312270623475,
        "bertscore": {
            "precision": 0.88877,
            "recall": 0.89729,
            "f1": 0.88726
        },
        "nubia": {
            "semantic_relation": 3.78677,
            "contradiction": 7.18542,
            "irrelevancy": 49.62194,
            "logical_agreement": 43.19264,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.31445,
            "nubia_score": 0.65311
        },
        "bleurt": 0.03825
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548847,
        "cond_entropy-2": 0.031262576450960075,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": 0.03310859910983795,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.037401197654111,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": 0.03310859910983795,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": 0.03518489863155644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.6111111111111112
        },
        "nist": 1.4286953131548308,
        "rouge1": {
            "precision": 0.82353,
            "recall": 0.5066,
            "fmeasure": 0.62714
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.18773,
            "fmeasure": 0.23449
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.30864,
            "fmeasure": 0.35167
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.30864,
            "fmeasure": 0.35167
        },
        "bleu": 21.18764,
        "meteor": 0.23699358232435813,
        "bertscore": {
            "precision": 0.87248,
            "recall": 0.84132,
            "f1": 0.85662
        },
        "nubia": {
            "semantic_relation": 3.12228,
            "contradiction": 0.09272,
            "irrelevancy": 99.76071,
            "logical_agreement": 0.14658,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.35723,
            "nubia_score": 0.45957
        },
        "bleurt": -0.29186
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.556088322639177,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.14708752563454366,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.1815094589235713,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.4,
            "3": 0.6842105263157895
        },
        "nist": 4.5080855074076185,
        "rouge1": {
            "precision": 0.72708,
            "recall": 0.79722,
            "fmeasure": 0.75894
        },
        "rouge2": {
            "precision": 0.34815,
            "recall": 0.34755,
            "fmeasure": 0.34502
        },
        "rougeL": {
            "precision": 0.40208,
            "recall": 0.4287,
            "fmeasure": 0.41427
        },
        "rougeLsum": {
            "precision": 0.40208,
            "recall": 0.4287,
            "fmeasure": 0.41427
        },
        "bleu": 35.56114,
        "meteor": 0.37147598399031234,
        "bertscore": {
            "precision": 0.91437,
            "recall": 0.9245,
            "f1": 0.91872
        },
        "nubia": {
            "semantic_relation": 4.11371,
            "contradiction": 13.52561,
            "irrelevancy": 44.41814,
            "logical_agreement": 42.05625,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.69286,
            "nubia_score": 0.6646
        },
        "bleurt": 0.0937
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 96,
        "mean_pred_length": 13.714285714285714,
        "std_pred_length": 5.062870041905529,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.7604166666666666,
        "vocab_size-1": 73,
        "unique-1": 61,
        "entropy-1": 5.967418620355073,
        "distinct-2": 0.9887640449438202,
        "vocab_size-2": 88,
        "unique-2": 87,
        "entropy-2": 6.453261520854051,
        "cond_entropy-2": 0.3601466326139752,
        "distinct-3": 1.0,
        "vocab_size-3": 82,
        "unique-3": 82,
        "entropy-3": 6.357552004618087,
        "cond_entropy-3": -0.09379118244587505,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 11.857142857142858,
        "std_pred_length-nopunct": 4.421653583012046,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8433734939759037,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.034501328859095,
        "distinct-2-nopunct": 0.9868421052631579,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.221611723969907,
        "cond_entropy-2-nopunct": 0.2184757466557446,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.108524456778164,
        "cond_entropy-3-nopunct": -0.11041754941903971,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.375,
            "3": 0.7721518987341772
        },
        "nist": 5.077700298096523,
        "rouge1": {
            "precision": 0.84496,
            "recall": 0.78656,
            "fmeasure": 0.8021
        },
        "rouge2": {
            "precision": 0.62961,
            "recall": 0.60162,
            "fmeasure": 0.60851
        },
        "rougeL": {
            "precision": 0.68996,
            "recall": 0.66368,
            "fmeasure": 0.67106
        },
        "rougeLsum": {
            "precision": 0.68996,
            "recall": 0.66368,
            "fmeasure": 0.67106
        },
        "bleu": 49.76526,
        "meteor": 0.4127054462441916,
        "bertscore": {
            "precision": 0.95659,
            "recall": 0.93954,
            "f1": 0.9464
        },
        "nubia": {
            "semantic_relation": 4.41072,
            "contradiction": 0.53616,
            "irrelevancy": 23.57952,
            "logical_agreement": 75.88432,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.73361,
            "nubia_score": 0.8029
        },
        "bleurt": 0.43925
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.8,
        "total_length": 134,
        "mean_pred_length": 16.75,
        "std_pred_length": 4.4651427748729375,
        "median_pred_length": 15.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.7238805970149254,
        "vocab_size-1": 97,
        "unique-1": 83,
        "entropy-1": 6.234745232127496,
        "distinct-2": 0.9603174603174603,
        "vocab_size-2": 121,
        "unique-2": 117,
        "entropy-2": 6.891923673482754,
        "cond_entropy-2": 0.5539980224047711,
        "distinct-3": 1.0,
        "vocab_size-3": 118,
        "unique-3": 118,
        "entropy-3": 6.882643049361832,
        "cond_entropy-3": -0.0034937597129610686,
        "total_length-nopunct": 118,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 4.235268586524354,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.788135593220339,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.237397579129482,
        "distinct-2-nopunct": 0.9636363636363636,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 103,
        "entropy-2-nopunct": 6.701769827141364,
        "cond_entropy-2-nopunct": 0.511299191301492,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.6724253419715,
        "cond_entropy-3-nopunct": -0.023102141139796688,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5625,
            "3": 0.7183098591549296
        },
        "nist": 4.754956853585978,
        "rouge1": {
            "precision": 0.75098,
            "recall": 0.67291,
            "fmeasure": 0.6949
        },
        "rouge2": {
            "precision": 0.52066,
            "recall": 0.45667,
            "fmeasure": 0.47768
        },
        "rougeL": {
            "precision": 0.61327,
            "recall": 0.55705,
            "fmeasure": 0.57255
        },
        "rougeLsum": {
            "precision": 0.61327,
            "recall": 0.55705,
            "fmeasure": 0.57255
        },
        "bleu": 37.93156,
        "meteor": 0.3524735792399498,
        "bertscore": {
            "precision": 0.92277,
            "recall": 0.92807,
            "f1": 0.92369
        },
        "nubia": {
            "semantic_relation": 3.95986,
            "contradiction": 27.13362,
            "irrelevancy": 31.74795,
            "logical_agreement": 41.11843,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.31984,
            "nubia_score": 0.68168
        },
        "bleurt": 0.29726
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.67,
        "total_length": 153,
        "mean_pred_length": 19.125,
        "std_pred_length": 7.523920188306094,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 34,
        "distinct-1": 0.6078431372549019,
        "vocab_size-1": 93,
        "unique-1": 70,
        "entropy-1": 6.141530673337292,
        "distinct-2": 0.896551724137931,
        "vocab_size-2": 130,
        "unique-2": 117,
        "entropy-2": 6.962600296881664,
        "cond_entropy-2": 0.802567670995417,
        "distinct-3": 0.9343065693430657,
        "vocab_size-3": 128,
        "unique-3": 119,
        "entropy-3": 6.966645221646644,
        "cond_entropy-3": 0.01673448932754079,
        "total_length-nopunct": 135,
        "mean_pred_length-nopunct": 16.875,
        "std_pred_length-nopunct": 5.925316447245666,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6592592592592592,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.1141841379530595,
        "distinct-2-nopunct": 0.9133858267716536,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.8095123442354275,
        "cond_entropy-2-nopunct": 0.7480923926822627,
        "distinct-3-nopunct": 0.9411764705882353,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 105,
        "entropy-3-nopunct": 6.777170704484414,
        "cond_entropy-3-nopunct": -0.020296440252764603,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.32142857142857145,
            "2": 0.52,
            "3": 0.7684210526315789
        },
        "nist": 5.681859610231377,
        "rouge1": {
            "precision": 0.79351,
            "recall": 0.74134,
            "fmeasure": 0.7518
        },
        "rouge2": {
            "precision": 0.54966,
            "recall": 0.52634,
            "fmeasure": 0.52611
        },
        "rougeL": {
            "precision": 0.71068,
            "recall": 0.65141,
            "fmeasure": 0.66589
        },
        "rougeLsum": {
            "precision": 0.71068,
            "recall": 0.65141,
            "fmeasure": 0.66589
        },
        "bleu": 47.16141,
        "meteor": 0.3586356650193897,
        "bertscore": {
            "precision": 0.93682,
            "recall": 0.92074,
            "f1": 0.92774
        },
        "nubia": {
            "semantic_relation": 4.04428,
            "contradiction": 13.00095,
            "irrelevancy": 37.5768,
            "logical_agreement": 49.42225,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.67841,
            "nubia_score": 0.67869
        },
        "bleurt": 0.03333
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.685557397915997,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.696969696969697,
        "vocab_size-1": 69,
        "unique-1": 58,
        "entropy-1": 5.764217827233712,
        "distinct-2": 0.946236559139785,
        "vocab_size-2": 88,
        "unique-2": 83,
        "entropy-2": 6.431631929387608,
        "cond_entropy-2": 0.5564577339038795,
        "distinct-3": 0.9770114942528736,
        "vocab_size-3": 85,
        "unique-3": 83,
        "entropy-3": 6.396966484354469,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.2489314482696545,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7558139534883721,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.745691208039531,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.196928094887356,
        "cond_entropy-2-nopunct": 0.4897799028475247,
        "distinct-3-nopunct": 0.972972972972973,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.155399311574901,
        "cond_entropy-3-nopunct": -0.03139364817733154,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 5.022000623102575,
        "rouge1": {
            "precision": 0.7811,
            "recall": 0.75819,
            "fmeasure": 0.76247
        },
        "rouge2": {
            "precision": 0.50505,
            "recall": 0.49649,
            "fmeasure": 0.49561
        },
        "rougeL": {
            "precision": 0.63958,
            "recall": 0.6362,
            "fmeasure": 0.63215
        },
        "rougeLsum": {
            "precision": 0.63958,
            "recall": 0.6362,
            "fmeasure": 0.63215
        },
        "bleu": 42.28151,
        "meteor": 0.3961682628036876,
        "bertscore": {
            "precision": 0.93778,
            "recall": 0.92452,
            "f1": 0.92902
        },
        "nubia": {
            "semantic_relation": 4.47606,
            "contradiction": 3.62418,
            "irrelevancy": 29.13714,
            "logical_agreement": 67.23868,
            "grammar_ref": 5.40206,
            "grammar_hyp": 4.91719,
            "nubia_score": 0.84041
        },
        "bleurt": 0.29495
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.79,
        "total_length": 176,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.4666979068286325,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.6306818181818182,
        "vocab_size-1": 111,
        "unique-1": 86,
        "entropy-1": 6.375430661810532,
        "distinct-2": 0.896969696969697,
        "vocab_size-2": 148,
        "unique-2": 133,
        "entropy-2": 7.148140396063992,
        "cond_entropy-2": 0.6720714646299184,
        "distinct-3": 0.948051948051948,
        "vocab_size-3": 146,
        "unique-3": 138,
        "entropy-3": 7.162890436798814,
        "cond_entropy-3": 0.03033445631921551,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 14.272727272727273,
        "std_pred_length-nopunct": 6.091587479182166,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6751592356687898,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.386319099629667,
        "distinct-2-nopunct": 0.8835616438356164,
        "vocab_size-2-nopunct": 129,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.943249216414266,
        "cond_entropy-2-nopunct": 0.6116651725509092,
        "distinct-3-nopunct": 0.9407407407407408,
        "vocab_size-3-nopunct": 127,
        "unique-3-nopunct": 119,
        "entropy-3-nopunct": 6.958297078532335,
        "cond_entropy-3-nopunct": 0.02773177891155442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15625,
            "2": 0.5,
            "3": 0.9024390243902439
        },
        "nist": 6.370384397533851,
        "rouge1": {
            "precision": 0.857,
            "recall": 0.86128,
            "fmeasure": 0.85771
        },
        "rouge2": {
            "precision": 0.72293,
            "recall": 0.73458,
            "fmeasure": 0.7275
        },
        "rougeL": {
            "precision": 0.79854,
            "recall": 0.81073,
            "fmeasure": 0.80342
        },
        "rougeLsum": {
            "precision": 0.79854,
            "recall": 0.81073,
            "fmeasure": 0.80342
        },
        "bleu": 64.80446,
        "meteor": 0.49798651606402944,
        "bertscore": {
            "precision": 0.96595,
            "recall": 0.96374,
            "f1": 0.96474
        },
        "nubia": {
            "semantic_relation": 4.67694,
            "contradiction": 5.27147,
            "irrelevancy": 8.16079,
            "logical_agreement": 86.56774,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.17166,
            "nubia_score": 0.90613
        },
        "bleurt": 0.5861
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 1.0
        },
        "nist": 3.4611336801875883,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.95833,
            "fmeasure": 0.83974
        },
        "rouge2": {
            "precision": 0.42308,
            "recall": 0.56061,
            "fmeasure": 0.48106
        },
        "rougeL": {
            "precision": 0.60714,
            "recall": 0.78333,
            "fmeasure": 0.68269
        },
        "rougeLsum": {
            "precision": 0.60714,
            "recall": 0.78333,
            "fmeasure": 0.68269
        },
        "bleu": 32.17294,
        "meteor": 0.4625541219460653,
        "bertscore": {
            "precision": 0.83674,
            "recall": 0.95125,
            "f1": 0.89033
        },
        "nubia": {
            "semantic_relation": 4.23771,
            "contradiction": 1.1144,
            "irrelevancy": 94.62948,
            "logical_agreement": 4.25612,
            "grammar_ref": 4.59758,
            "grammar_hyp": 4.08603,
            "nubia_score": 0.75956
        },
        "bleurt": 0.52576
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.78,
        "total_length": 227,
        "mean_pred_length": 16.214285714285715,
        "std_pred_length": 4.522618890936209,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6123348017621145,
        "vocab_size-1": 139,
        "unique-1": 104,
        "entropy-1": 6.648873378003882,
        "distinct-2": 0.9107981220657277,
        "vocab_size-2": 194,
        "unique-2": 178,
        "entropy-2": 7.543372120215718,
        "cond_entropy-2": 0.721655937616542,
        "distinct-3": 0.9547738693467337,
        "vocab_size-3": 190,
        "unique-3": 181,
        "entropy-3": 7.546172359237127,
        "cond_entropy-3": 0.0162611686703907,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 14.214285714285714,
        "std_pred_length-nopunct": 3.9492959847940248,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6683417085427136,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.7055975180452405,
        "distinct-2-nopunct": 0.9081081081081082,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 154,
        "entropy-2-nopunct": 7.332706392937039,
        "cond_entropy-2-nopunct": 0.6813487637295351,
        "distinct-3-nopunct": 0.9532163742690059,
        "vocab_size-3-nopunct": 163,
        "unique-3-nopunct": 155,
        "entropy-3-nopunct": 7.324285263423903,
        "cond_entropy-3-nopunct": 0.007844665493348852,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08823529411764706,
            "2": 0.4375,
            "3": 0.9038461538461539
        },
        "nist": 6.329792578111987,
        "rouge1": {
            "precision": 0.82095,
            "recall": 0.84042,
            "fmeasure": 0.82681
        },
        "rouge2": {
            "precision": 0.69806,
            "recall": 0.70058,
            "fmeasure": 0.69659
        },
        "rougeL": {
            "precision": 0.73048,
            "recall": 0.74713,
            "fmeasure": 0.73532
        },
        "rougeLsum": {
            "precision": 0.73048,
            "recall": 0.74713,
            "fmeasure": 0.73532
        },
        "bleu": 66.24746,
        "meteor": 0.47733794546454866,
        "bertscore": {
            "precision": 0.94578,
            "recall": 0.93543,
            "f1": 0.93942
        },
        "nubia": {
            "semantic_relation": 4.35846,
            "contradiction": 13.14305,
            "irrelevancy": 18.70175,
            "logical_agreement": 68.1552,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.78519,
            "nubia_score": 0.77263
        },
        "bleurt": 0.44866
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.8,
        "total_length": 219,
        "mean_pred_length": 15.642857142857142,
        "std_pred_length": 3.8841646069492923,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6712328767123288,
        "vocab_size-1": 147,
        "unique-1": 128,
        "entropy-1": 6.65879352267166,
        "distinct-2": 0.9560975609756097,
        "vocab_size-2": 196,
        "unique-2": 191,
        "entropy-2": 7.574554367777008,
        "cond_entropy-2": 0.7573130069647789,
        "distinct-3": 0.9895287958115183,
        "vocab_size-3": 189,
        "unique-3": 187,
        "entropy-3": 7.5564864196587855,
        "cond_entropy-3": -0.01037705678735731,
        "total_length-nopunct": 195,
        "mean_pred_length-nopunct": 13.928571428571429,
        "std_pred_length-nopunct": 3.8998953413481994,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7282051282051282,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 125,
        "entropy-1-nopunct": 6.72375663040743,
        "distinct-2-nopunct": 0.9502762430939227,
        "vocab_size-2-nopunct": 172,
        "unique-2-nopunct": 167,
        "entropy-2-nopunct": 7.381007351147667,
        "cond_entropy-2-nopunct": 0.7113118758014518,
        "distinct-3-nopunct": 0.9880239520958084,
        "vocab_size-3-nopunct": 165,
        "unique-3-nopunct": 163,
        "entropy-3-nopunct": 7.359752196665645,
        "cond_entropy-3-nopunct": -0.011292642487435245,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.37209302325581395,
            "3": 0.781021897810219
        },
        "nist": 5.738047225611132,
        "rouge1": {
            "precision": 0.72088,
            "recall": 0.67743,
            "fmeasure": 0.69207
        },
        "rouge2": {
            "precision": 0.50887,
            "recall": 0.47419,
            "fmeasure": 0.48569
        },
        "rougeL": {
            "precision": 0.66659,
            "recall": 0.627,
            "fmeasure": 0.64049
        },
        "rougeLsum": {
            "precision": 0.66659,
            "recall": 0.627,
            "fmeasure": 0.64049
        },
        "bleu": 44.36828,
        "meteor": 0.3900535392211788,
        "bertscore": {
            "precision": 0.93255,
            "recall": 0.92795,
            "f1": 0.92986
        },
        "nubia": {
            "semantic_relation": 4.00564,
            "contradiction": 17.64503,
            "irrelevancy": 27.34906,
            "logical_agreement": 55.00591,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.48066,
            "nubia_score": 0.67484
        },
        "bleurt": 0.30269
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74,
        "total_length": 231,
        "mean_pred_length": 14.4375,
        "std_pred_length": 3.7909225460301874,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.6103896103896104,
        "vocab_size-1": 141,
        "unique-1": 117,
        "entropy-1": 6.518548887691669,
        "distinct-2": 0.9209302325581395,
        "vocab_size-2": 198,
        "unique-2": 184,
        "entropy-2": 7.577239884463098,
        "cond_entropy-2": 0.8602314733276661,
        "distinct-3": 0.9597989949748744,
        "vocab_size-3": 191,
        "unique-3": 183,
        "entropy-3": 7.556222610493409,
        "cond_entropy-3": -0.0072723119495127705,
        "total_length-nopunct": 202,
        "mean_pred_length-nopunct": 12.625,
        "std_pred_length-nopunct": 3.461845606031557,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6782178217821783,
        "vocab_size-1-nopunct": 137,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.638827880250192,
        "distinct-2-nopunct": 0.9139784946236559,
        "vocab_size-2-nopunct": 170,
        "unique-2-nopunct": 157,
        "entropy-2-nopunct": 7.352304577225448,
        "cond_entropy-2-nopunct": 0.7787466573977057,
        "distinct-3-nopunct": 0.9588235294117647,
        "vocab_size-3-nopunct": 163,
        "unique-3-nopunct": 156,
        "entropy-3-nopunct": 7.327037994961202,
        "cond_entropy-3-nopunct": -0.013562654369367903,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1951219512195122,
            "2": 0.391304347826087,
            "3": 0.7439024390243902
        },
        "nist": 5.687382466733547,
        "rouge1": {
            "precision": 0.73914,
            "recall": 0.72948,
            "fmeasure": 0.72985
        },
        "rouge2": {
            "precision": 0.49881,
            "recall": 0.49577,
            "fmeasure": 0.4941
        },
        "rougeL": {
            "precision": 0.62161,
            "recall": 0.60613,
            "fmeasure": 0.61007
        },
        "rougeLsum": {
            "precision": 0.62161,
            "recall": 0.60613,
            "fmeasure": 0.61007
        },
        "bleu": 42.08185,
        "meteor": 0.3864321939962304,
        "bertscore": {
            "precision": 0.92304,
            "recall": 0.92129,
            "f1": 0.92181
        },
        "nubia": {
            "semantic_relation": 4.4586,
            "contradiction": 4.97926,
            "irrelevancy": 31.58878,
            "logical_agreement": 63.43196,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.4018,
            "nubia_score": 0.81919
        },
        "bleurt": 0.35166
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.77,
        "total_length": 237,
        "mean_pred_length": 18.23076923076923,
        "std_pred_length": 7.0944598770269724,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.6244725738396625,
        "vocab_size-1": 148,
        "unique-1": 112,
        "entropy-1": 6.777391650561545,
        "distinct-2": 0.9241071428571429,
        "vocab_size-2": 207,
        "unique-2": 192,
        "entropy-2": 7.648829140788254,
        "cond_entropy-2": 0.8085725159651452,
        "distinct-3": 0.976303317535545,
        "vocab_size-3": 206,
        "unique-3": 201,
        "entropy-3": 7.673705823778302,
        "cond_entropy-3": 0.03464367425302602,
        "total_length-nopunct": 210,
        "mean_pred_length-nopunct": 16.153846153846153,
        "std_pred_length-nopunct": 6.4312476818703015,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.680952380952381,
        "vocab_size-1-nopunct": 143,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 6.8223527510780695,
        "distinct-2-nopunct": 0.934010152284264,
        "vocab_size-2-nopunct": 184,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 7.482408291515593,
        "cond_entropy-2-nopunct": 0.7108659133559426,
        "distinct-3-nopunct": 0.9836956521739131,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 178,
        "entropy-3-nopunct": 7.490953260404852,
        "cond_entropy-3-nopunct": 0.009797161076754988,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16901408450704225,
            "2": 0.4716981132075472,
            "3": 0.6904761904761905
        },
        "nist": 4.669782902628738,
        "rouge1": {
            "precision": 0.63509,
            "recall": 0.65278,
            "fmeasure": 0.63244
        },
        "rouge2": {
            "precision": 0.33571,
            "recall": 0.36012,
            "fmeasure": 0.3418
        },
        "rougeL": {
            "precision": 0.4736,
            "recall": 0.50255,
            "fmeasure": 0.47969
        },
        "rougeLsum": {
            "precision": 0.4736,
            "recall": 0.50255,
            "fmeasure": 0.47969
        },
        "bleu": 28.99527,
        "meteor": 0.33409457943478776,
        "bertscore": {
            "precision": 0.88278,
            "recall": 0.88848,
            "f1": 0.8842
        },
        "nubia": {
            "semantic_relation": 3.68091,
            "contradiction": 25.40586,
            "irrelevancy": 51.17812,
            "logical_agreement": 23.41601,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.32999,
            "nubia_score": 0.58091
        },
        "bleurt": -0.07311
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.7,
        "total_length": 170,
        "mean_pred_length": 18.88888888888889,
        "std_pred_length": 5.566655577722377,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.6588235294117647,
        "vocab_size-1": 112,
        "unique-1": 95,
        "entropy-1": 6.255426729106411,
        "distinct-2": 0.968944099378882,
        "vocab_size-2": 156,
        "unique-2": 152,
        "entropy-2": 7.264116334622903,
        "cond_entropy-2": 0.9836503661797624,
        "distinct-3": 0.993421052631579,
        "vocab_size-3": 151,
        "unique-3": 150,
        "entropy-3": 7.234769618706724,
        "cond_entropy-3": -0.025391420577850606,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 17.444444444444443,
        "std_pred_length-nopunct": 5.678636595191394,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6942675159235668,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.244220810888591,
        "distinct-2-nopunct": 0.9662162162162162,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.136785206830544,
        "cond_entropy-2-nopunct": 0.9564400678475444,
        "distinct-3-nopunct": 0.9928057553956835,
        "vocab_size-3-nopunct": 138,
        "unique-3-nopunct": 137,
        "entropy-3-nopunct": 7.104552583514889,
        "cond_entropy-3-nopunct": -0.027527490731604494,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.3125,
            "3": 0.7739130434782608
        },
        "nist": 5.399862461686898,
        "rouge1": {
            "precision": 0.75162,
            "recall": 0.77286,
            "fmeasure": 0.75019
        },
        "rouge2": {
            "precision": 0.50607,
            "recall": 0.5337,
            "fmeasure": 0.51215
        },
        "rougeL": {
            "precision": 0.64279,
            "recall": 0.66748,
            "fmeasure": 0.64481
        },
        "rougeLsum": {
            "precision": 0.64279,
            "recall": 0.66748,
            "fmeasure": 0.64481
        },
        "bleu": 37.20645,
        "meteor": 0.3704237683770028,
        "bertscore": {
            "precision": 0.92426,
            "recall": 0.92722,
            "f1": 0.92546
        },
        "nubia": {
            "semantic_relation": 4.33921,
            "contradiction": 4.03529,
            "irrelevancy": 28.33532,
            "logical_agreement": 67.62939,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.35399,
            "nubia_score": 0.7979
        },
        "bleurt": 0.22499
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 9,
        "unique-1": 7,
        "entropy-1": 3.0957952550009344,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.262496476250065,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.9219280948873623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.29244135099939467,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.5175220807009246,
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.93939,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.80476,
            "fmeasure": 0.70392
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "bleu": 60.76796,
        "meteor": 0.4912092865802179,
        "bertscore": {
            "precision": 0.95103,
            "recall": 0.96123,
            "f1": 0.95272
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.25117,
            "irrelevancy": 30.21179,
            "logical_agreement": 69.53704,
            "grammar_ref": 3.38649,
            "grammar_hyp": 2.86426,
            "nubia_score": 0.97277
        },
        "bleurt": 0.67878
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.72,
        "total_length": 163,
        "mean_pred_length": 16.3,
        "std_pred_length": 4.473253849269008,
        "median_pred_length": 16.5,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6625766871165644,
        "vocab_size-1": 108,
        "unique-1": 87,
        "entropy-1": 6.332851006752917,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 144,
        "unique-2": 136,
        "entropy-2": 7.134806878626205,
        "cond_entropy-2": 0.6753509467870518,
        "distinct-3": 0.993006993006993,
        "vocab_size-3": 142,
        "unique-3": 141,
        "entropy-3": 7.145885322792383,
        "cond_entropy-3": 0.012657532562405163,
        "total_length-nopunct": 145,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7103448275862069,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.317435641560043,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 126,
        "unique-2-nopunct": 118,
        "entropy-2-nopunct": 6.937890504442234,
        "cond_entropy-2-nopunct": 0.6695269701751411,
        "distinct-3-nopunct": 0.992,
        "vocab_size-3-nopunct": 124,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.949784284662096,
        "cond_entropy-3-nopunct": 0.015007787628563824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.45161290322580644,
            "3": 0.8367346938775511
        },
        "nist": 5.636811593832534,
        "rouge1": {
            "precision": 0.73221,
            "recall": 0.74785,
            "fmeasure": 0.72974
        },
        "rouge2": {
            "precision": 0.50108,
            "recall": 0.52425,
            "fmeasure": 0.50555
        },
        "rougeL": {
            "precision": 0.6445,
            "recall": 0.65563,
            "fmeasure": 0.64166
        },
        "rougeLsum": {
            "precision": 0.6445,
            "recall": 0.65563,
            "fmeasure": 0.64166
        },
        "bleu": 48.85618,
        "meteor": 0.4100433535496861,
        "bertscore": {
            "precision": 0.90669,
            "recall": 0.9138,
            "f1": 0.90883
        },
        "nubia": {
            "semantic_relation": 3.9996,
            "contradiction": 7.4706,
            "irrelevancy": 59.00228,
            "logical_agreement": 33.52712,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.20119,
            "nubia_score": 0.69409
        },
        "bleurt": 0.17118
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 112,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.782329983125268,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.625,
        "vocab_size-1": 70,
        "unique-1": 54,
        "entropy-1": 5.726200366301637,
        "distinct-2": 0.9142857142857143,
        "vocab_size-2": 96,
        "unique-2": 90,
        "entropy-2": 6.521248731890015,
        "cond_entropy-2": 0.7565573314536651,
        "distinct-3": 0.9693877551020408,
        "vocab_size-3": 95,
        "unique-3": 92,
        "entropy-3": 6.5534853543193,
        "cond_entropy-3": 0.04602210712755942,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 5.8901508937395155,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6701030927835051,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.618314829158882,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.266690179590881,
        "cond_entropy-2-nopunct": 0.7024996403342141,
        "distinct-3-nopunct": 0.963855421686747,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.3027502747204265,
        "cond_entropy-3-nopunct": 0.043001545938821356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5882352941176471,
            "3": 0.6521739130434783
        },
        "nist": 4.183854281580135,
        "rouge1": {
            "precision": 0.68446,
            "recall": 0.6861,
            "fmeasure": 0.67669
        },
        "rouge2": {
            "precision": 0.4961,
            "recall": 0.49459,
            "fmeasure": 0.48892
        },
        "rougeL": {
            "precision": 0.61779,
            "recall": 0.62225,
            "fmeasure": 0.61224
        },
        "rougeLsum": {
            "precision": 0.61779,
            "recall": 0.62225,
            "fmeasure": 0.61224
        },
        "bleu": 35.51131,
        "meteor": 0.3626451225092255,
        "bertscore": {
            "precision": 0.8968,
            "recall": 0.90665,
            "f1": 0.90109
        },
        "nubia": {
            "semantic_relation": 3.85115,
            "contradiction": 0.4231,
            "irrelevancy": 60.72944,
            "logical_agreement": 38.84746,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.12208,
            "nubia_score": 0.68575
        },
        "bleurt": 0.00044
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.69,
        "total_length": 182,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0178174601214955,
        "median_pred_length": 12.5,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.5934065934065934,
        "vocab_size-1": 108,
        "unique-1": 87,
        "entropy-1": 6.1231223356574285,
        "distinct-2": 0.9226190476190477,
        "vocab_size-2": 155,
        "unique-2": 148,
        "entropy-2": 7.195772482251088,
        "cond_entropy-2": 0.8707599284672788,
        "distinct-3": 0.9935064935064936,
        "vocab_size-3": 153,
        "unique-3": 152,
        "entropy-3": 7.253799527707908,
        "cond_entropy-3": 0.0629077543359712,
        "total_length-nopunct": 163,
        "mean_pred_length-nopunct": 11.642857142857142,
        "std_pred_length-nopunct": 3.6175592177430285,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6503067484662577,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.200889196910421,
        "distinct-2-nopunct": 0.9261744966442953,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.024406439867177,
        "cond_entropy-2-nopunct": 0.8938849134384289,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 7.076815597050856,
        "cond_entropy-3-nopunct": 0.0577918914675868,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.26666666666666666,
            "3": 0.75
        },
        "nist": 5.304391883277724,
        "rouge1": {
            "precision": 0.7213,
            "recall": 0.71569,
            "fmeasure": 0.70445
        },
        "rouge2": {
            "precision": 0.52373,
            "recall": 0.50515,
            "fmeasure": 0.50358
        },
        "rougeL": {
            "precision": 0.68984,
            "recall": 0.67245,
            "fmeasure": 0.66724
        },
        "rougeLsum": {
            "precision": 0.68984,
            "recall": 0.67245,
            "fmeasure": 0.66724
        },
        "bleu": 42.14104,
        "meteor": 0.40455257395026384,
        "bertscore": {
            "precision": 0.92727,
            "recall": 0.91697,
            "f1": 0.92064
        },
        "nubia": {
            "semantic_relation": 4.14328,
            "contradiction": 12.73987,
            "irrelevancy": 22.30512,
            "logical_agreement": 64.95501,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.21634,
            "nubia_score": 0.73083
        },
        "bleurt": 0.2678
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 13.6,
        "std_pred_length": 3.7735924528226414,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.75,
        "vocab_size-1": 51,
        "unique-1": 43,
        "entropy-1": 5.431151216499009,
        "distinct-2": 0.9682539682539683,
        "vocab_size-2": 61,
        "unique-2": 60,
        "entropy-2": 5.901805518703674,
        "cond_entropy-2": 0.33846251886053574,
        "distinct-3": 1.0,
        "vocab_size-3": 58,
        "unique-3": 58,
        "entropy-3": 5.85798099512757,
        "cond_entropy-3": -0.03731810936952603,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.794733192202055,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8166666666666667,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.43581288716701,
        "distinct-2-nopunct": 0.9636363636363636,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.69490721348532,
        "cond_entropy-2-nopunct": 0.301919572540267,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.042405773706665637,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.13333333333333333,
            "3": 0.8214285714285714
        },
        "nist": 4.728096146637358,
        "rouge1": {
            "precision": 0.9068,
            "recall": 0.71648,
            "fmeasure": 0.79686
        },
        "rouge2": {
            "precision": 0.72523,
            "recall": 0.56609,
            "fmeasure": 0.63275
        },
        "rougeL": {
            "precision": 0.77342,
            "recall": 0.62019,
            "fmeasure": 0.68533
        },
        "rougeLsum": {
            "precision": 0.77342,
            "recall": 0.62019,
            "fmeasure": 0.68533
        },
        "bleu": 52.89248,
        "meteor": 0.415206971803089,
        "bertscore": {
            "precision": 0.95578,
            "recall": 0.92023,
            "f1": 0.93725
        },
        "nubia": {
            "semantic_relation": 4.33745,
            "contradiction": 19.73353,
            "irrelevancy": 18.37558,
            "logical_agreement": 61.89088,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.9441,
            "nubia_score": 0.72572
        },
        "bleurt": 0.33179
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "total_length": 110,
        "mean_pred_length": 15.714285714285714,
        "std_pred_length": 4.199125273342591,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.6636363636363637,
        "vocab_size-1": 73,
        "unique-1": 58,
        "entropy-1": 5.820536218327292,
        "distinct-2": 0.9029126213592233,
        "vocab_size-2": 93,
        "unique-2": 86,
        "entropy-2": 6.46557928929815,
        "cond_entropy-2": 0.5195506439026776,
        "distinct-3": 0.96875,
        "vocab_size-3": 93,
        "unique-3": 90,
        "entropy-3": 6.522462500721161,
        "cond_entropy-3": 0.0521587183521406,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 4.120630029101703,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.711340206185567,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.774767481183962,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.261243235194514,
        "cond_entropy-2-nopunct": 0.5284315043108164,
        "distinct-3-nopunct": 0.9759036144578314,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.326846660262594,
        "cond_entropy-3-nopunct": 0.060956063958978755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.55,
            "3": 0.8307692307692308
        },
        "nist": 5.03677182838246,
        "rouge1": {
            "precision": 0.72882,
            "recall": 0.76843,
            "fmeasure": 0.74311
        },
        "rouge2": {
            "precision": 0.48355,
            "recall": 0.49116,
            "fmeasure": 0.47971
        },
        "rougeL": {
            "precision": 0.64342,
            "recall": 0.65781,
            "fmeasure": 0.64222
        },
        "rougeLsum": {
            "precision": 0.64342,
            "recall": 0.65781,
            "fmeasure": 0.64222
        },
        "bleu": 43.37672,
        "meteor": 0.3866843428691539,
        "bertscore": {
            "precision": 0.90047,
            "recall": 0.91778,
            "f1": 0.90661
        },
        "nubia": {
            "semantic_relation": 4.11553,
            "contradiction": 14.04801,
            "irrelevancy": 48.45019,
            "logical_agreement": 37.50181,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.66164,
            "nubia_score": 0.74235
        },
        "bleurt": 0.11164
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.67,
        "total_length": 151,
        "mean_pred_length": 16.77777777777778,
        "std_pred_length": 5.9212944864329895,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6490066225165563,
        "vocab_size-1": 98,
        "unique-1": 80,
        "entropy-1": 6.165689379611415,
        "distinct-2": 0.9577464788732394,
        "vocab_size-2": 136,
        "unique-2": 132,
        "entropy-2": 7.0511555702089135,
        "cond_entropy-2": 0.8055678683258092,
        "distinct-3": 1.0,
        "vocab_size-3": 133,
        "unique-3": 133,
        "entropy-3": 7.055282435501199,
        "cond_entropy-3": 0.010798473891244654,
        "total_length-nopunct": 138,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 5.754225500544022,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6739130434782609,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.123161997961056,
        "distinct-2-nopunct": 0.9534883720930233,
        "vocab_size-2-nopunct": 123,
        "unique-2-nopunct": 119,
        "entropy-2-nopunct": 6.902700123640291,
        "cond_entropy-2-nopunct": 0.8327804677672677,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 120,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.906890595608536,
        "cond_entropy-3-nopunct": 0.003996673518597812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.2857142857142857,
            "3": 0.7532467532467533
        },
        "nist": 4.16226340451298,
        "rouge1": {
            "precision": 0.63666,
            "recall": 0.67411,
            "fmeasure": 0.63948
        },
        "rouge2": {
            "precision": 0.42809,
            "recall": 0.48189,
            "fmeasure": 0.44086
        },
        "rougeL": {
            "precision": 0.58854,
            "recall": 0.63436,
            "fmeasure": 0.59456
        },
        "rougeLsum": {
            "precision": 0.58854,
            "recall": 0.63436,
            "fmeasure": 0.59456
        },
        "bleu": 34.9347,
        "meteor": 0.31232433614922417,
        "bertscore": {
            "precision": 0.89387,
            "recall": 0.88628,
            "f1": 0.8887
        },
        "nubia": {
            "semantic_relation": 3.73581,
            "contradiction": 20.08706,
            "irrelevancy": 24.01012,
            "logical_agreement": 55.90282,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.79378,
            "nubia_score": 0.60475
        },
        "bleurt": 0.18698
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 8.5,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.8484848484848485,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.741363816328152,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.1678667071574541,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015322,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.04896868761125603,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6176470588235294
        },
        "nist": 2.8759216813945607,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.51916,
            "fmeasure": 0.6199
        },
        "rouge2": {
            "precision": 0.475,
            "recall": 0.32619,
            "fmeasure": 0.38536
        },
        "rougeL": {
            "precision": 0.53968,
            "recall": 0.37001,
            "fmeasure": 0.43743
        },
        "rougeLsum": {
            "precision": 0.53968,
            "recall": 0.37001,
            "fmeasure": 0.43743
        },
        "bleu": 42.32181,
        "meteor": 0.3552691785420604,
        "bertscore": {
            "precision": 0.92725,
            "recall": 0.89135,
            "f1": 0.90811
        },
        "nubia": {
            "semantic_relation": 3.15154,
            "contradiction": 1.18369,
            "irrelevancy": 38.51713,
            "logical_agreement": 60.29919,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.72822,
            "nubia_score": 0.4103
        },
        "bleurt": 0.09671
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69387,
        "msttr-100_nopunct": 0.71444,
        "total_length": 6210,
        "mean_pred_length": 12.42,
        "std_pred_length": 6.3796238133607845,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 30,
        "distinct-1": 0.16280193236714977,
        "vocab_size-1": 1011,
        "unique-1": 583,
        "entropy-1": 7.82236287532779,
        "distinct-2": 0.49947460595446586,
        "vocab_size-2": 2852,
        "unique-2": 2033,
        "entropy-2": 10.687110450261812,
        "cond_entropy-2": 2.633099289513709,
        "distinct-3": 0.7195777351247601,
        "vocab_size-3": 3749,
        "unique-3": 3156,
        "entropy-3": 11.479607518567523,
        "cond_entropy-3": 0.8159552146950603,
        "total_length-nopunct": 5495,
        "mean_pred_length-nopunct": 10.99,
        "std_pred_length-nopunct": 5.951630028824036,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.18198362147406733,
        "vocab_size-1-nopunct": 1000,
        "unique-1-nopunct": 580,
        "entropy-1-nopunct": 7.987484125263137,
        "distinct-2-nopunct": 0.5091091091091091,
        "vocab_size-2-nopunct": 2543,
        "unique-2-nopunct": 1845,
        "entropy-2-nopunct": 10.503938594640795,
        "cond_entropy-2-nopunct": 2.6368054052255068,
        "distinct-3-nopunct": 0.7284252669039146,
        "vocab_size-3-nopunct": 3275,
        "unique-3-nopunct": 2802,
        "entropy-3-nopunct": 11.27247759737522,
        "cond_entropy-3-nopunct": 0.8106464482005702,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5729204836936607
        },
        "nist": 6.093418079670253,
        "rouge1": {
            "precision": 0.57829,
            "recall": 0.56095,
            "fmeasure": 0.55799
        },
        "rouge2": {
            "precision": 0.36568,
            "recall": 0.35318,
            "fmeasure": 0.35133
        },
        "rougeL": {
            "precision": 0.52047,
            "recall": 0.50315,
            "fmeasure": 0.50133
        },
        "rougeLsum": {
            "precision": 0.52047,
            "recall": 0.50315,
            "fmeasure": 0.50133
        },
        "bleu": 32.77413,
        "meteor": 0.31793938700921864,
        "bertscore": {
            "precision": 0.86925,
            "recall": 0.86619,
            "f1": 0.86721
        },
        "nubia": {
            "semantic_relation": 3.62953,
            "contradiction": 5.62891,
            "irrelevancy": 25.96307,
            "logical_agreement": 68.40802,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.63017,
            "nubia_score": 0.6423
        },
        "bleurt": -0.08119
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.73,
        "total_length": 224,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.566962103755937,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6116071428571429,
        "vocab_size-1": 137,
        "unique-1": 111,
        "entropy-1": 6.544542685144508,
        "distinct-2": 0.9238095238095239,
        "vocab_size-2": 194,
        "unique-2": 181,
        "entropy-2": 7.5487460533700945,
        "cond_entropy-2": 0.8866019178297939,
        "distinct-3": 0.9846938775510204,
        "vocab_size-3": 193,
        "unique-3": 190,
        "entropy-3": 7.584097599217235,
        "cond_entropy-3": 0.04207089533767505,
        "total_length-nopunct": 202,
        "mean_pred_length-nopunct": 14.428571428571429,
        "std_pred_length-nopunct": 4.7616666607139875,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6584158415841584,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.587484412204557,
        "distinct-2-nopunct": 0.925531914893617,
        "vocab_size-2-nopunct": 174,
        "unique-2-nopunct": 163,
        "entropy-2-nopunct": 7.390999024538487,
        "cond_entropy-2-nopunct": 0.8602606277209861,
        "distinct-3-nopunct": 0.9885057471264368,
        "vocab_size-3-nopunct": 172,
        "unique-3-nopunct": 170,
        "entropy-3-nopunct": 7.419954990101582,
        "cond_entropy-3-nopunct": 0.036371239011110876,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.5681818181818182,
            "3": 0.85
        },
        "nist": 6.250344413158718,
        "rouge1": {
            "precision": 0.82312,
            "recall": 0.81878,
            "fmeasure": 0.81177
        },
        "rouge2": {
            "precision": 0.64438,
            "recall": 0.65405,
            "fmeasure": 0.64139
        },
        "rougeL": {
            "precision": 0.71435,
            "recall": 0.72833,
            "fmeasure": 0.71227
        },
        "rougeLsum": {
            "precision": 0.71435,
            "recall": 0.72833,
            "fmeasure": 0.71227
        },
        "bleu": 58.71132,
        "meteor": 0.43592964052787503,
        "bertscore": {
            "precision": 0.94942,
            "recall": 0.9472,
            "f1": 0.94647
        },
        "nubia": {
            "semantic_relation": 4.31317,
            "contradiction": 7.00053,
            "irrelevancy": 41.28705,
            "logical_agreement": 51.71242,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.82562,
            "nubia_score": 0.75775
        },
        "bleurt": 0.41364
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 15.6,
        "std_pred_length": 5.122499389946279,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.717948717948718,
        "vocab_size-1": 56,
        "unique-1": 47,
        "entropy-1": 5.4897886751318685,
        "distinct-2": 0.9726027397260274,
        "vocab_size-2": 71,
        "unique-2": 69,
        "entropy-2": 6.135030038332083,
        "cond_entropy-2": 0.590146400442014,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.04353818821791301,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 14.2,
        "std_pred_length-nopunct": 5.3814496188294845,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7464788732394366,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.416537874279752,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.983788058752401,
        "cond_entropy-2-nopunct": 0.6227963394139215,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.930737337562883,
        "cond_entropy-3-nopunct": -0.04808301130376398,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.84
        },
        "nist": 5.712672898598493,
        "rouge1": {
            "precision": 0.81793,
            "recall": 0.83338,
            "fmeasure": 0.81989
        },
        "rouge2": {
            "precision": 0.65713,
            "recall": 0.67312,
            "fmeasure": 0.65904
        },
        "rougeL": {
            "precision": 0.78826,
            "recall": 0.80143,
            "fmeasure": 0.78883
        },
        "rougeLsum": {
            "precision": 0.78826,
            "recall": 0.80143,
            "fmeasure": 0.78883
        },
        "bleu": 63.79066,
        "meteor": 0.4749620558599345,
        "bertscore": {
            "precision": 0.96117,
            "recall": 0.95662,
            "f1": 0.95885
        },
        "nubia": {
            "semantic_relation": 4.55525,
            "contradiction": 7.06853,
            "irrelevancy": 14.77092,
            "logical_agreement": 78.16055,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.8688,
            "nubia_score": 0.82998
        },
        "bleurt": 0.41793
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 2.9231267955022466,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "bleu": 32.99293,
        "meteor": 0.38963765889179386,
        "bertscore": {
            "precision": 0.95884,
            "recall": 0.93577,
            "f1": 0.94716
        },
        "nubia": {
            "semantic_relation": 3.97704,
            "contradiction": 6.41984,
            "irrelevancy": 1.33751,
            "logical_agreement": 92.24265,
            "grammar_ref": 5.11392,
            "grammar_hyp": 5.04775,
            "nubia_score": 0.5462
        },
        "bleurt": 0.64728
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.875,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.726409765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.13205351234730073,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.625053839880556,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.14708752563454353,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7931034482758621
        },
        "nist": 4.209667789070077,
        "rouge1": {
            "precision": 0.85526,
            "recall": 0.79481,
            "fmeasure": 0.82368
        },
        "rouge2": {
            "precision": 0.57828,
            "recall": 0.55019,
            "fmeasure": 0.56367
        },
        "rougeL": {
            "precision": 0.53947,
            "recall": 0.51542,
            "fmeasure": 0.527
        },
        "rougeLsum": {
            "precision": 0.53947,
            "recall": 0.51542,
            "fmeasure": 0.527
        },
        "bleu": 34.07347,
        "meteor": 0.44410034819212113,
        "bertscore": {
            "precision": 0.95633,
            "recall": 0.9483,
            "f1": 0.9523
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51166,
            "irrelevancy": 0.45892,
            "logical_agreement": 99.02943,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.50727,
            "nubia_score": 0.95678
        },
        "bleurt": 0.45044
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.031128874149275,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7428571428571429,
        "vocab_size-1": 52,
        "unique-1": 39,
        "entropy-1": 5.554073552566534,
        "distinct-2": 0.9242424242424242,
        "vocab_size-2": 61,
        "unique-2": 56,
        "entropy-2": 5.892878967843309,
        "cond_entropy-2": 0.30162284490328883,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 60,
        "unique-3": 58,
        "entropy-3": 5.889680181354615,
        "cond_entropy-3": 0.0065763845768089324,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 3.766629793329841,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7936507936507936,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.540616828193142,
        "distinct-2-nopunct": 0.9152542372881356,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.713151523938108,
        "cond_entropy-2-nopunct": 0.18518982085051686,
        "distinct-3-nopunct": 0.9636363636363636,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.708632440797383,
        "cond_entropy-3-nopunct": 0.007807573253727385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.8333333333333334,
            "3": 0.9148936170212766
        },
        "nist": 5.810120237987532,
        "rouge1": {
            "precision": 0.86228,
            "recall": 0.85752,
            "fmeasure": 0.85984
        },
        "rouge2": {
            "precision": 0.72495,
            "recall": 0.7346,
            "fmeasure": 0.72791
        },
        "rougeL": {
            "precision": 0.74145,
            "recall": 0.75572,
            "fmeasure": 0.74607
        },
        "rougeLsum": {
            "precision": 0.74145,
            "recall": 0.75572,
            "fmeasure": 0.74607
        },
        "bleu": 70.78493,
        "meteor": 0.5039930911509026,
        "bertscore": {
            "precision": 0.96744,
            "recall": 0.9616,
            "f1": 0.96448
        },
        "nubia": {
            "semantic_relation": 4.59054,
            "contradiction": 9.57433,
            "irrelevancy": 18.73381,
            "logical_agreement": 71.69186,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.37731,
            "nubia_score": 0.8362
        },
        "bleurt": 0.55107
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.69,
        "total_length": 126,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.594682917363407,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6349206349206349,
        "vocab_size-1": 80,
        "unique-1": 59,
        "entropy-1": 5.994023451976661,
        "distinct-2": 0.8803418803418803,
        "vocab_size-2": 103,
        "unique-2": 89,
        "entropy-2": 6.6310484802671485,
        "cond_entropy-2": 0.5075319363563994,
        "distinct-3": 0.8888888888888888,
        "vocab_size-3": 96,
        "unique-3": 84,
        "entropy-3": 6.532665279941236,
        "cond_entropy-3": -0.07844018038289875,
        "total_length-nopunct": 113,
        "mean_pred_length-nopunct": 12.555555555555555,
        "std_pred_length-nopunct": 4.4748956812449485,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6902654867256637,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 6.038934051463926,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.450439718141096,
        "cond_entropy-2-nopunct": 0.4694980147402685,
        "distinct-3-nopunct": 0.8842105263157894,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.338276660962526,
        "cond_entropy-3-nopunct": -0.099005162441723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.43243243243243246,
            "2": 0.4,
            "3": 0.8352941176470589
        },
        "nist": 5.735516719896034,
        "rouge1": {
            "precision": 0.81648,
            "recall": 0.75496,
            "fmeasure": 0.77558
        },
        "rouge2": {
            "precision": 0.63083,
            "recall": 0.60457,
            "fmeasure": 0.61078
        },
        "rougeL": {
            "precision": 0.74086,
            "recall": 0.72264,
            "fmeasure": 0.72136
        },
        "rougeLsum": {
            "precision": 0.74086,
            "recall": 0.72264,
            "fmeasure": 0.72136
        },
        "bleu": 57.95891,
        "meteor": 0.4027215857724816,
        "bertscore": {
            "precision": 0.94737,
            "recall": 0.92511,
            "f1": 0.93538
        },
        "nubia": {
            "semantic_relation": 4.05217,
            "contradiction": 0.55834,
            "irrelevancy": 34.5214,
            "logical_agreement": 64.92026,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.10086,
            "nubia_score": 0.67197
        },
        "bleurt": 0.22945
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.65,
        "msttr-100_nopunct": NaN,
        "total_length": 115,
        "mean_pred_length": 14.375,
        "std_pred_length": 4.240798863421843,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.6347826086956522,
        "vocab_size-1": 73,
        "unique-1": 57,
        "entropy-1": 5.837547416177123,
        "distinct-2": 0.8411214953271028,
        "vocab_size-2": 90,
        "unique-2": 81,
        "entropy-2": 6.362688247962066,
        "cond_entropy-2": 0.37620196335634337,
        "distinct-3": 0.8787878787878788,
        "vocab_size-3": 87,
        "unique-3": 81,
        "entropy-3": 6.341181619948498,
        "cond_entropy-3": 0.009101754890583767,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 12.375,
        "std_pred_length-nopunct": 4.270172713134681,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6868686868686869,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.789371615068793,
        "distinct-2-nopunct": 0.8351648351648352,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.1146689532666425,
        "cond_entropy-2-nopunct": 0.399142173803199,
        "distinct-3-nopunct": 0.8795180722891566,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.0886004251925065,
        "cond_entropy-3-nopunct": 0.01182310440124067,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.25,
            "3": 0.7446808510638298
        },
        "nist": 5.141610605662028,
        "rouge1": {
            "precision": 0.84815,
            "recall": 0.79465,
            "fmeasure": 0.81158
        },
        "rouge2": {
            "precision": 0.68936,
            "recall": 0.65955,
            "fmeasure": 0.66827
        },
        "rougeL": {
            "precision": 0.79755,
            "recall": 0.75152,
            "fmeasure": 0.76621
        },
        "rougeLsum": {
            "precision": 0.79755,
            "recall": 0.75152,
            "fmeasure": 0.76621
        },
        "bleu": 49.94917,
        "meteor": 0.43468407264757813,
        "bertscore": {
            "precision": 0.96367,
            "recall": 0.95346,
            "f1": 0.95834
        },
        "nubia": {
            "semantic_relation": 4.68111,
            "contradiction": 0.22584,
            "irrelevancy": 5.25306,
            "logical_agreement": 94.5211,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.38949,
            "nubia_score": 0.92379
        },
        "bleurt": 0.68805
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.73667,
        "total_length": 355,
        "mean_pred_length": 16.136363636363637,
        "std_pred_length": 4.693278119196883,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5830985915492958,
        "vocab_size-1": 207,
        "unique-1": 163,
        "entropy-1": 7.018623954756171,
        "distinct-2": 0.8828828828828829,
        "vocab_size-2": 294,
        "unique-2": 270,
        "entropy-2": 8.094711737883687,
        "cond_entropy-2": 0.8873295228660095,
        "distinct-3": 0.954983922829582,
        "vocab_size-3": 297,
        "unique-3": 285,
        "entropy-3": 8.185884033782298,
        "cond_entropy-3": 0.09844774876720026,
        "total_length-nopunct": 315,
        "mean_pred_length-nopunct": 14.318181818181818,
        "std_pred_length-nopunct": 4.236061245547927,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6412698412698413,
        "vocab_size-1-nopunct": 202,
        "unique-1-nopunct": 163,
        "entropy-1-nopunct": 7.126227653445792,
        "distinct-2-nopunct": 0.8873720136518771,
        "vocab_size-2-nopunct": 260,
        "unique-2-nopunct": 241,
        "entropy-2-nopunct": 7.914759926035579,
        "cond_entropy-2-nopunct": 0.8330738443526774,
        "distinct-3-nopunct": 0.9630996309963099,
        "vocab_size-3-nopunct": 261,
        "unique-3-nopunct": 252,
        "entropy-3-nopunct": 8.005562740607843,
        "cond_entropy-3-nopunct": 0.09445597849509994,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.3888888888888889,
            "3": 0.857707509881423
        },
        "nist": 6.323101889929171,
        "rouge1": {
            "precision": 0.80436,
            "recall": 0.85114,
            "fmeasure": 0.81654
        },
        "rouge2": {
            "precision": 0.6461,
            "recall": 0.67255,
            "fmeasure": 0.65103
        },
        "rougeL": {
            "precision": 0.73396,
            "recall": 0.77002,
            "fmeasure": 0.74321
        },
        "rougeLsum": {
            "precision": 0.73396,
            "recall": 0.77002,
            "fmeasure": 0.74321
        },
        "bleu": 55.12195,
        "meteor": 0.4660617963573492,
        "bertscore": {
            "precision": 0.94701,
            "recall": 0.95604,
            "f1": 0.9509
        },
        "nubia": {
            "semantic_relation": 4.51155,
            "contradiction": 0.64544,
            "irrelevancy": 32.6745,
            "logical_agreement": 66.68005,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.16137,
            "nubia_score": 0.84799
        },
        "bleurt": 0.4744
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.77333,
        "total_length": 353,
        "mean_pred_length": 17.65,
        "std_pred_length": 5.943694137487224,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.5722379603399433,
        "vocab_size-1": 202,
        "unique-1": 156,
        "entropy-1": 6.995707544045097,
        "distinct-2": 0.9159159159159159,
        "vocab_size-2": 305,
        "unique-2": 286,
        "entropy-2": 8.186391392577324,
        "cond_entropy-2": 1.0659619613249682,
        "distinct-3": 0.9936102236421726,
        "vocab_size-3": 311,
        "unique-3": 309,
        "entropy-3": 8.277239294216931,
        "cond_entropy-3": 0.09678956135174072,
        "total_length-nopunct": 312,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 5.739337940912697,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6314102564102564,
        "vocab_size-1-nopunct": 197,
        "unique-1-nopunct": 156,
        "entropy-1-nopunct": 7.081834721184209,
        "distinct-2-nopunct": 0.9143835616438356,
        "vocab_size-2-nopunct": 267,
        "unique-2-nopunct": 251,
        "entropy-2-nopunct": 7.990288043446874,
        "cond_entropy-2-nopunct": 0.9683382107997105,
        "distinct-3-nopunct": 0.9963235294117647,
        "vocab_size-3-nopunct": 271,
        "unique-3-nopunct": 270,
        "entropy-3-nopunct": 8.080109900073882,
        "cond_entropy-3-nopunct": 0.10081718864418435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22972972972972974,
            "2": 0.5846153846153846,
            "3": 0.8473684210526315
        },
        "nist": 6.094671826931433,
        "rouge1": {
            "precision": 0.77558,
            "recall": 0.81724,
            "fmeasure": 0.78377
        },
        "rouge2": {
            "precision": 0.59146,
            "recall": 0.64587,
            "fmeasure": 0.60419
        },
        "rougeL": {
            "precision": 0.67913,
            "recall": 0.70641,
            "fmeasure": 0.681
        },
        "rougeLsum": {
            "precision": 0.67913,
            "recall": 0.70641,
            "fmeasure": 0.681
        },
        "bleu": 51.36471,
        "meteor": 0.4326712347663179,
        "bertscore": {
            "precision": 0.93552,
            "recall": 0.94084,
            "f1": 0.93718
        },
        "nubia": {
            "semantic_relation": 4.20606,
            "contradiction": 9.87336,
            "irrelevancy": 26.09114,
            "logical_agreement": 64.0355,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.3887,
            "nubia_score": 0.72156
        },
        "bleurt": 0.31088
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.0,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 14,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.243300368538956,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.05825539871387721,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.16992500144231232,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "nist": 2.719176065758202,
        "rouge1": {
            "precision": 0.72159,
            "recall": 0.65934,
            "fmeasure": 0.68481
        },
        "rouge2": {
            "precision": 0.46429,
            "recall": 0.42521,
            "fmeasure": 0.44033
        },
        "rougeL": {
            "precision": 0.70644,
            "recall": 0.62399,
            "fmeasure": 0.6567
        },
        "rougeLsum": {
            "precision": 0.70644,
            "recall": 0.62399,
            "fmeasure": 0.6567
        },
        "bleu": 28.27762,
        "meteor": 0.4095400688144249,
        "bertscore": {
            "precision": 0.92676,
            "recall": 0.89705,
            "f1": 0.91066
        },
        "nubia": {
            "semantic_relation": 4.23479,
            "contradiction": 2.97207,
            "irrelevancy": 13.77567,
            "logical_agreement": 83.25226,
            "grammar_ref": 5.15434,
            "grammar_hyp": 5.22261,
            "nubia_score": 0.72559
        },
        "bleurt": 0.34266
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 10.25,
        "std_pred_length": 2.277608394786075,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 14,
        "distinct-1": 0.7560975609756098,
        "vocab_size-1": 31,
        "unique-1": 25,
        "entropy-1": 4.784142858171084,
        "distinct-2": 0.918918918918919,
        "vocab_size-2": 34,
        "unique-2": 31,
        "entropy-2": 5.047291203466791,
        "cond_entropy-2": 0.10892230707375619,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 32,
        "unique-3": 31,
        "entropy-3": 4.9837880587523955,
        "cond_entropy-3": -0.10445318566443551,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 9.25,
        "std_pred_length-nopunct": 2.277608394786075,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8108108108108109,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.7902702574039004,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.923181998146335,
        "cond_entropy-2-nopunct": 0.12311575386062314,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.789015477886192,
        "cond_entropy-3-nopunct": -0.11744760698950202,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.16666666666666666,
            "3": 0.45
        },
        "nist": 1.4447417230702708,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.44586,
            "fmeasure": 0.52359
        },
        "rouge2": {
            "precision": 0.35731,
            "recall": 0.22802,
            "fmeasure": 0.27204
        },
        "rougeL": {
            "precision": 0.57804,
            "recall": 0.40209,
            "fmeasure": 0.46478
        },
        "rougeLsum": {
            "precision": 0.57804,
            "recall": 0.40209,
            "fmeasure": 0.46478
        },
        "bleu": 10.46465,
        "meteor": 0.22369667189186548,
        "bertscore": {
            "precision": 0.92602,
            "recall": 0.88172,
            "f1": 0.90297
        },
        "nubia": {
            "semantic_relation": 3.9464,
            "contradiction": 10.45092,
            "irrelevancy": 27.53158,
            "logical_agreement": 62.01751,
            "grammar_ref": 4.84918,
            "grammar_hyp": 5.60553,
            "nubia_score": 0.55918
        },
        "bleurt": 0.07383
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.744,
        "msttr-100_nopunct": 0.8125,
        "total_length": 558,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.924253049418836,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.5663082437275986,
        "vocab_size-1": 316,
        "unique-1": 253,
        "entropy-1": 7.525624320172915,
        "distinct-2": 0.8937381404174574,
        "vocab_size-2": 471,
        "unique-2": 431,
        "entropy-2": 8.791582396529414,
        "cond_entropy-2": 1.1045680743142685,
        "distinct-3": 0.9576612903225806,
        "vocab_size-3": 475,
        "unique-3": 455,
        "entropy-3": 8.867996940422726,
        "cond_entropy-3": 0.09204434108767988,
        "total_length-nopunct": 481,
        "mean_pred_length-nopunct": 15.516129032258064,
        "std_pred_length-nopunct": 4.648072564407298,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6465696465696466,
        "vocab_size-1-nopunct": 311,
        "unique-1-nopunct": 253,
        "entropy-1-nopunct": 7.744539946409432,
        "distinct-2-nopunct": 0.9155555555555556,
        "vocab_size-2-nopunct": 412,
        "unique-2-nopunct": 385,
        "entropy-2-nopunct": 8.612290003521393,
        "cond_entropy-2-nopunct": 0.9333966899062707,
        "distinct-3-nopunct": 0.9689737470167065,
        "vocab_size-3-nopunct": 406,
        "unique-3-nopunct": 393,
        "entropy-3-nopunct": 8.648753927732749,
        "cond_entropy-3-nopunct": 0.046598117095816335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21296296296296297,
            "2": 0.3125,
            "3": 0.8405405405405405
        },
        "nist": 7.093366533509727,
        "rouge1": {
            "precision": 0.78241,
            "recall": 0.79523,
            "fmeasure": 0.77462
        },
        "rouge2": {
            "precision": 0.58812,
            "recall": 0.60369,
            "fmeasure": 0.5858
        },
        "rougeL": {
            "precision": 0.67322,
            "recall": 0.69419,
            "fmeasure": 0.67165
        },
        "rougeLsum": {
            "precision": 0.67322,
            "recall": 0.69419,
            "fmeasure": 0.67165
        },
        "bleu": 55.05914,
        "meteor": 0.4309854262514945,
        "bertscore": {
            "precision": 0.93932,
            "recall": 0.94092,
            "f1": 0.93774
        },
        "nubia": {
            "semantic_relation": 4.27841,
            "contradiction": 10.21924,
            "irrelevancy": 25.09107,
            "logical_agreement": 64.68969,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.55716,
            "nubia_score": 0.75757
        },
        "bleurt": 0.32902
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.51543,
        "msttr-100_nopunct": 0.52671,
        "total_length": 9415,
        "mean_pred_length": 18.83,
        "std_pred_length": 6.461044807150001,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.13372278279341476,
        "vocab_size-1": 1259,
        "unique-1": 499,
        "entropy-1": 8.003740912488697,
        "distinct-2": 0.3846326416152552,
        "vocab_size-2": 3429,
        "unique-2": 2016,
        "entropy-2": 10.849034127206847,
        "cond_entropy-2": 2.781637387908235,
        "distinct-3": 0.588116458704694,
        "vocab_size-3": 4949,
        "unique-3": 3583,
        "entropy-3": 11.790087127742696,
        "cond_entropy-3": 1.0143930532017855,
        "total_length-nopunct": 8535,
        "mean_pred_length-nopunct": 17.07,
        "std_pred_length-nopunct": 6.1599594154507225,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.14669009958992385,
        "vocab_size-1-nopunct": 1252,
        "unique-1-nopunct": 499,
        "entropy-1-nopunct": 8.176858276910416,
        "distinct-2-nopunct": 0.39191039203484757,
        "vocab_size-2-nopunct": 3149,
        "unique-2-nopunct": 1907,
        "entropy-2-nopunct": 10.732420754716195,
        "cond_entropy-2-nopunct": 2.7157212278141936,
        "distinct-3-nopunct": 0.594293297942933,
        "vocab_size-3-nopunct": 4478,
        "unique-3-nopunct": 3298,
        "entropy-3-nopunct": 11.639915237737616,
        "cond_entropy-3-nopunct": 0.9791464397017943,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.1844237991697964,
            "2": 0.509670851713607,
            "3": 0.7380329094988781,
            "4": 0.2,
            "5": 0.3888888888888889
        },
        "nist": 6.678451642864437,
        "rouge1": {
            "precision": 0.7772,
            "recall": 0.67734,
            "fmeasure": 0.71092
        },
        "rouge2": {
            "precision": 0.5166,
            "recall": 0.44818,
            "fmeasure": 0.47038
        },
        "rougeL": {
            "precision": 0.63377,
            "recall": 0.55292,
            "fmeasure": 0.57977
        },
        "rougeLsum": {
            "precision": 0.63377,
            "recall": 0.55292,
            "fmeasure": 0.57977
        },
        "bleu": 38.97128,
        "meteor": 0.3237573566730572,
        "bertscore": {
            "precision": 0.91951,
            "recall": 0.89977,
            "f1": 0.90795
        },
        "nubia": {
            "semantic_relation": 4.12271,
            "contradiction": 7.24592,
            "irrelevancy": 11.07442,
            "logical_agreement": 81.67966,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.80758,
            "nubia_score": 0.67037
        },
        "bleurt": 0.04889
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.67,
        "total_length": 115,
        "mean_pred_length": 19.166666666666668,
        "std_pred_length": 7.425556469981821,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6521739130434783,
        "vocab_size-1": 75,
        "unique-1": 56,
        "entropy-1": 5.894548777585328,
        "distinct-2": 0.9174311926605505,
        "vocab_size-2": 100,
        "unique-2": 93,
        "entropy-2": 6.5846980862448055,
        "cond_entropy-2": 0.6691002044407265,
        "distinct-3": 0.9611650485436893,
        "vocab_size-3": 99,
        "unique-3": 95,
        "entropy-3": 6.608830624270614,
        "cond_entropy-3": 0.0348210567752244,
        "total_length-nopunct": 104,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 7.272474743090476,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6826923076923077,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.810022805312946,
        "distinct-2-nopunct": 0.9081632653061225,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.410628211462156,
        "cond_entropy-2-nopunct": 0.6551207273427674,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.436605434317896,
        "cond_entropy-3-nopunct": 0.039286894550500245,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.14893617021276595,
            "3": 0.8064516129032258
        },
        "nist": 3.831680592236916,
        "rouge1": {
            "precision": 0.69762,
            "recall": 0.61537,
            "fmeasure": 0.63412
        },
        "rouge2": {
            "precision": 0.46258,
            "recall": 0.40333,
            "fmeasure": 0.41778
        },
        "rougeL": {
            "precision": 0.63272,
            "recall": 0.56044,
            "fmeasure": 0.57628
        },
        "rougeLsum": {
            "precision": 0.63272,
            "recall": 0.56044,
            "fmeasure": 0.57628
        },
        "bleu": 33.74692,
        "meteor": 0.3012763181996979,
        "bertscore": {
            "precision": 0.90287,
            "recall": 0.87958,
            "f1": 0.8905
        },
        "nubia": {
            "semantic_relation": 3.68642,
            "contradiction": 15.09963,
            "irrelevancy": 26.55908,
            "logical_agreement": 58.34129,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.55387,
            "nubia_score": 0.62362
        },
        "bleurt": 0.00733
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 4.5,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.7931034482758621,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.418157288156418,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.2952356737826916,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.220175521464345,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.27241854983266217,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9473684210526315
        },
        "nist": 3.7044248254359062,
        "rouge1": {
            "precision": 0.79074,
            "recall": 0.92857,
            "fmeasure": 0.84818
        },
        "rouge2": {
            "precision": 0.49346,
            "recall": 0.56495,
            "fmeasure": 0.52341
        },
        "rougeL": {
            "precision": 0.53889,
            "recall": 0.61843,
            "fmeasure": 0.57277
        },
        "rougeLsum": {
            "precision": 0.53889,
            "recall": 0.61843,
            "fmeasure": 0.57277
        },
        "bleu": 49.9458,
        "meteor": 0.4795016491855714,
        "bertscore": {
            "precision": 0.94501,
            "recall": 0.95722,
            "f1": 0.95105
        },
        "nubia": {
            "semantic_relation": 4.29471,
            "contradiction": 0.42302,
            "irrelevancy": 49.42993,
            "logical_agreement": 50.14705,
            "grammar_ref": 5.56806,
            "grammar_hyp": 5.30443,
            "nubia_score": 0.78092
        },
        "bleurt": 0.33002
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.81,
        "total_length": 186,
        "mean_pred_length": 16.90909090909091,
        "std_pred_length": 5.195357113538018,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6559139784946236,
        "vocab_size-1": 122,
        "unique-1": 97,
        "entropy-1": 6.499636075686001,
        "distinct-2": 0.9428571428571428,
        "vocab_size-2": 165,
        "unique-2": 156,
        "entropy-2": 7.332611754677089,
        "cond_entropy-2": 0.7205211794250649,
        "distinct-3": 0.9878048780487805,
        "vocab_size-3": 162,
        "unique-3": 160,
        "entropy-3": 7.333161760715666,
        "cond_entropy-3": 0.008504840969678414,
        "total_length-nopunct": 164,
        "mean_pred_length-nopunct": 14.909090909090908,
        "std_pred_length-nopunct": 5.418059791182306,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7195121951219512,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.550889938992867,
        "distinct-2-nopunct": 0.934640522875817,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 134,
        "entropy-2-nopunct": 7.121734983201368,
        "cond_entropy-2-nopunct": 0.6119451763729552,
        "distinct-3-nopunct": 0.9859154929577465,
        "vocab_size-3-nopunct": 140,
        "unique-3-nopunct": 138,
        "entropy-3-nopunct": 7.121578105420181,
        "cond_entropy-3-nopunct": 0.010351442320223834,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.05555555555555555,
            "2": 0.4,
            "3": 0.7446808510638298
        },
        "nist": 5.361361985530863,
        "rouge1": {
            "precision": 0.75918,
            "recall": 0.6998,
            "fmeasure": 0.72305
        },
        "rouge2": {
            "precision": 0.51055,
            "recall": 0.46873,
            "fmeasure": 0.48479
        },
        "rougeL": {
            "precision": 0.61121,
            "recall": 0.55404,
            "fmeasure": 0.57672
        },
        "rougeLsum": {
            "precision": 0.61121,
            "recall": 0.55404,
            "fmeasure": 0.57672
        },
        "bleu": 38.83568,
        "meteor": 0.37854416230015875,
        "bertscore": {
            "precision": 0.92656,
            "recall": 0.92313,
            "f1": 0.92454
        },
        "nubia": {
            "semantic_relation": 4.32817,
            "contradiction": 2.66037,
            "irrelevancy": 33.92636,
            "logical_agreement": 63.41326,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.7142,
            "nubia_score": 0.76644
        },
        "bleurt": 0.27738
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 1.247219128924647,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.5853658536585366,
        "vocab_size-1": 24,
        "unique-1": 14,
        "entropy-1": 4.338663284842052,
        "distinct-2": 0.7368421052631579,
        "vocab_size-2": 28,
        "unique-2": 18,
        "entropy-2": 4.7216117239699,
        "cond_entropy-2": 0.33825840379007743,
        "distinct-3": 0.7428571428571429,
        "vocab_size-3": 26,
        "unique-3": 17,
        "entropy-3": 4.614997302659251,
        "cond_entropy-3": -0.11864449649861893,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6052631578947368,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.273728829005325,
        "distinct-2-nopunct": 0.7428571428571429,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.614997302659251,
        "cond_entropy-2-nopunct": 0.36762836089149165,
        "distinct-3-nopunct": 0.75,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.5,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.2,
            "3": 0.6551724137931034
        },
        "nist": 3.9157317054726906,
        "rouge1": {
            "precision": 0.68543,
            "recall": 0.7011,
            "fmeasure": 0.69271
        },
        "rouge2": {
            "precision": 0.54701,
            "recall": 0.56061,
            "fmeasure": 0.55333
        },
        "rougeL": {
            "precision": 0.66162,
            "recall": 0.68085,
            "fmeasure": 0.67064
        },
        "rougeLsum": {
            "precision": 0.66162,
            "recall": 0.68085,
            "fmeasure": 0.67064
        },
        "bleu": 57.93645,
        "meteor": 0.4046625376175628,
        "bertscore": {
            "precision": 0.93747,
            "recall": 0.93199,
            "f1": 0.93447
        },
        "nubia": {
            "semantic_relation": 3.99625,
            "contradiction": 0.30828,
            "irrelevancy": 53.6804,
            "logical_agreement": 46.01132,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.51207,
            "nubia_score": 0.68102
        },
        "bleurt": 0.12348
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.5,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.403856189774722,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.05361880976054911,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "nist": 2.8017114286660356,
        "rouge1": {
            "precision": 0.54808,
            "recall": 0.73611,
            "fmeasure": 0.61889
        },
        "rouge2": {
            "precision": 0.37879,
            "recall": 0.48788,
            "fmeasure": 0.42087
        },
        "rougeL": {
            "precision": 0.54808,
            "recall": 0.73611,
            "fmeasure": 0.61889
        },
        "rougeLsum": {
            "precision": 0.54808,
            "recall": 0.73611,
            "fmeasure": 0.61889
        },
        "bleu": 41.16293,
        "meteor": 0.4553212384739789,
        "bertscore": {
            "precision": 0.88124,
            "recall": 0.93975,
            "f1": 0.90924
        },
        "nubia": {
            "semantic_relation": 3.2944,
            "contradiction": 45.06609,
            "irrelevancy": 29.6934,
            "logical_agreement": 25.24052,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.29682,
            "nubia_score": 0.55816
        },
        "bleurt": 0.24348
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 3.9319229794768673,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.79259,
            "fmeasure": 0.77895
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.90606,
            "fmeasure": 0.89177
        },
        "bleu": 70.71068,
        "meteor": 0.5023397349274512,
        "bertscore": {
            "precision": 0.99214,
            "recall": 0.99214,
            "f1": 0.99214
        },
        "nubia": {
            "semantic_relation": 3.63608,
            "contradiction": 98.85014,
            "irrelevancy": 0.58732,
            "logical_agreement": 0.56253,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.05889,
            "nubia_score": 0.64216
        },
        "bleurt": 0.62958
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 63,
        "mean_pred_length": 12.6,
        "std_pred_length": 4.882622246293481,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 49,
        "unique-1": 40,
        "entropy-1": 5.451574915900495,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 56,
        "unique-2": 54,
        "entropy-2": 5.789015477886191,
        "cond_entropy-2": 0.18259374411605117,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.09232469150776919,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 10.8,
        "std_pred_length-nopunct": 4.069397989875161,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.393595372453709,
        "distinct-2-nopunct": 0.9795918367346939,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.5738935175845965,
        "cond_entropy-2-nopunct": 0.17634836244820806,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.10982368002336564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.625,
            "3": 0.8421052631578947
        },
        "nist": 4.6423894649636175,
        "rouge1": {
            "precision": 0.77266,
            "recall": 0.78025,
            "fmeasure": 0.77296
        },
        "rouge2": {
            "precision": 0.56556,
            "recall": 0.57071,
            "fmeasure": 0.56544
        },
        "rougeL": {
            "precision": 0.73159,
            "recall": 0.74553,
            "fmeasure": 0.73546
        },
        "rougeLsum": {
            "precision": 0.73159,
            "recall": 0.74553,
            "fmeasure": 0.73546
        },
        "bleu": 53.01659,
        "meteor": 0.44241298465100876,
        "bertscore": {
            "precision": 0.94019,
            "recall": 0.92737,
            "f1": 0.93359
        },
        "nubia": {
            "semantic_relation": 4.06225,
            "contradiction": 11.09066,
            "irrelevancy": 30.86387,
            "logical_agreement": 58.04547,
            "grammar_ref": 5.12632,
            "grammar_hyp": 4.71134,
            "nubia_score": 0.72445
        },
        "bleurt": 0.36773
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 4.642796092394707,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.851063829787234,
        "vocab_size-1": 40,
        "unique-1": 36,
        "entropy-1": 5.198101883546502,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.17757003968693236,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.10187961401921372,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.7416573867739413,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8809523809523809,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.106603137064476,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.20077710377579597,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.4,
            "3": 0.8285714285714286
        },
        "nist": 5.014088209345542,
        "rouge1": {
            "precision": 0.8558,
            "recall": 0.77356,
            "fmeasure": 0.80432
        },
        "rouge2": {
            "precision": 0.67654,
            "recall": 0.6082,
            "fmeasure": 0.63314
        },
        "rougeL": {
            "precision": 0.70928,
            "recall": 0.63405,
            "fmeasure": 0.66105
        },
        "rougeLsum": {
            "precision": 0.70928,
            "recall": 0.63405,
            "fmeasure": 0.66105
        },
        "bleu": 57.16604,
        "meteor": 0.4758233755025672,
        "bertscore": {
            "precision": 0.9607,
            "recall": 0.95099,
            "f1": 0.95578
        },
        "nubia": {
            "semantic_relation": 4.62968,
            "contradiction": 1.31513,
            "irrelevancy": 10.73211,
            "logical_agreement": 87.95276,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.42471,
            "nubia_score": 0.79681
        },
        "bleurt": 0.33295
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "total_length": 117,
        "mean_pred_length": 16.714285714285715,
        "std_pred_length": 5.146823867043378,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.7094017094017094,
        "vocab_size-1": 83,
        "unique-1": 73,
        "entropy-1": 5.964465737685611,
        "distinct-2": 0.9727272727272728,
        "vocab_size-2": 107,
        "unique-2": 104,
        "entropy-2": 6.726814258979213,
        "cond_entropy-2": 0.6413467796470494,
        "distinct-3": 0.9902912621359223,
        "vocab_size-3": 102,
        "unique-3": 101,
        "entropy-3": 6.667083051455081,
        "cond_entropy-3": -0.05602423488513044,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 14.714285714285714,
        "std_pred_length-nopunct": 5.062870041905529,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7669902912621359,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 5.960975712103611,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 90,
        "entropy-2-nopunct": 6.5224625007211605,
        "cond_entropy-2-nopunct": 0.6039729730504435,
        "distinct-3-nopunct": 0.9887640449438202,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.453261520854051,
        "cond_entropy-3-nopunct": -0.075521204586219,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.26666666666666666,
            "3": 0.8181818181818182
        },
        "nist": 5.566500828075398,
        "rouge1": {
            "precision": 0.76058,
            "recall": 0.76003,
            "fmeasure": 0.75515
        },
        "rouge2": {
            "precision": 0.53363,
            "recall": 0.55264,
            "fmeasure": 0.53667
        },
        "rougeL": {
            "precision": 0.68824,
            "recall": 0.71316,
            "fmeasure": 0.69403
        },
        "rougeLsum": {
            "precision": 0.68824,
            "recall": 0.71316,
            "fmeasure": 0.69403
        },
        "bleu": 45.54166,
        "meteor": 0.44301247881115496,
        "bertscore": {
            "precision": 0.94141,
            "recall": 0.94603,
            "f1": 0.94162
        },
        "nubia": {
            "semantic_relation": 4.34562,
            "contradiction": 5.98095,
            "irrelevancy": 33.15133,
            "logical_agreement": 60.86772,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.57452,
            "nubia_score": 0.7882
        },
        "bleurt": 0.35587
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 103,
        "mean_pred_length": 17.166666666666668,
        "std_pred_length": 5.145116346811045,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7281553398058253,
        "vocab_size-1": 75,
        "unique-1": 65,
        "entropy-1": 5.885089484037751,
        "distinct-2": 0.9690721649484536,
        "vocab_size-2": 94,
        "unique-2": 92,
        "entropy-2": 6.53027482670092,
        "cond_entropy-2": 0.5750701445645702,
        "distinct-3": 1.0,
        "vocab_size-3": 91,
        "unique-3": 91,
        "entropy-3": 6.507794640198703,
        "cond_entropy-3": -0.017888668997624348,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 4.988876515698588,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.776595744680851,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.885060160512229,
        "distinct-2-nopunct": 0.9659090909090909,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.382671533385448,
        "cond_entropy-2-nopunct": 0.5432610563617514,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.019502937163561582,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2222222222222222,
            "3": 0.8888888888888888
        },
        "nist": 5.9737811665868925,
        "rouge1": {
            "precision": 0.82673,
            "recall": 0.83717,
            "fmeasure": 0.82746
        },
        "rouge2": {
            "precision": 0.64401,
            "recall": 0.66195,
            "fmeasure": 0.64986
        },
        "rougeL": {
            "precision": 0.74802,
            "recall": 0.77925,
            "fmeasure": 0.75728
        },
        "rougeLsum": {
            "precision": 0.74802,
            "recall": 0.77925,
            "fmeasure": 0.75728
        },
        "bleu": 58.41472,
        "meteor": 0.44304053166452734,
        "bertscore": {
            "precision": 0.95405,
            "recall": 0.95799,
            "f1": 0.95593
        },
        "nubia": {
            "semantic_relation": 4.30299,
            "contradiction": 10.6782,
            "irrelevancy": 46.51792,
            "logical_agreement": 42.80388,
            "grammar_ref": 4.74863,
            "grammar_hyp": 4.81071,
            "nubia_score": 0.70518
        },
        "bleurt": 0.18664
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 16.5,
        "std_pred_length": 6.075908711186061,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 72,
        "unique-1": 61,
        "entropy-1": 5.872853054528292,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 90,
        "unique-2": 87,
        "entropy-2": 6.4746426820757765,
        "cond_entropy-2": 0.5257614653848116,
        "distinct-3": 0.9770114942528736,
        "vocab_size-3": 85,
        "unique-3": 83,
        "entropy-3": 6.396966484354471,
        "cond_entropy-3": -0.0732268095121767,
        "total_length-nopunct": 91,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 6.039223643997813,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7582417582417582,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.834341755416894,
        "distinct-2-nopunct": 0.9647058823529412,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.33880270084359,
        "cond_entropy-2-nopunct": 0.551998796117174,
        "distinct-3-nopunct": 0.9746835443037974,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.2531478367846995,
        "cond_entropy-3-nopunct": -0.08029373226439633,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.4090909090909091,
            "3": 0.8115942028985508
        },
        "nist": 5.073004488518161,
        "rouge1": {
            "precision": 0.7326,
            "recall": 0.7036,
            "fmeasure": 0.7068
        },
        "rouge2": {
            "precision": 0.53508,
            "recall": 0.51916,
            "fmeasure": 0.51872
        },
        "rougeL": {
            "precision": 0.66601,
            "recall": 0.63179,
            "fmeasure": 0.63732
        },
        "rougeLsum": {
            "precision": 0.66601,
            "recall": 0.63179,
            "fmeasure": 0.63732
        },
        "bleu": 46.64332,
        "meteor": 0.4152194489625967,
        "bertscore": {
            "precision": 0.93911,
            "recall": 0.91874,
            "f1": 0.92806
        },
        "nubia": {
            "semantic_relation": 4.51897,
            "contradiction": 0.58788,
            "irrelevancy": 21.19178,
            "logical_agreement": 78.22033,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.59378,
            "nubia_score": 0.81792
        },
        "bleurt": 0.31591
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 88,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 6.209312003399052,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.7613636363636364,
        "vocab_size-1": 67,
        "unique-1": 55,
        "entropy-1": 5.855801897287715,
        "distinct-2": 0.9878048780487805,
        "vocab_size-2": 81,
        "unique-2": 80,
        "entropy-2": 6.333161760715648,
        "cond_entropy-2": 0.33238429420562576,
        "distinct-3": 1.0,
        "vocab_size-3": 76,
        "unique-3": 76,
        "entropy-3": 6.247927513443591,
        "cond_entropy-3": -0.10962449117449807,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 5.880759588125784,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8266666666666667,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.807356817503397,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.108524456778164,
        "cond_entropy-2-nopunct": 0.32332374417267684,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 5.97727992349992,
        "cond_entropy-3-nopunct": -0.13124453327825242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.125,
            "3": 0.717948717948718
        },
        "nist": 3.9573697816193816,
        "rouge1": {
            "precision": 0.82943,
            "recall": 0.62785,
            "fmeasure": 0.69203
        },
        "rouge2": {
            "precision": 0.58378,
            "recall": 0.44681,
            "fmeasure": 0.4884
        },
        "rougeL": {
            "precision": 0.68432,
            "recall": 0.53256,
            "fmeasure": 0.58072
        },
        "rougeLsum": {
            "precision": 0.68432,
            "recall": 0.53256,
            "fmeasure": 0.58072
        },
        "bleu": 48.3569,
        "meteor": 0.3551336070952472,
        "bertscore": {
            "precision": 0.94063,
            "recall": 0.89494,
            "f1": 0.91423
        },
        "nubia": {
            "semantic_relation": 4.14283,
            "contradiction": 0.22769,
            "irrelevancy": 1.08859,
            "logical_agreement": 98.68372,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.48441,
            "nubia_score": 0.70839
        },
        "bleurt": 0.3102
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.81,
        "total_length": 307,
        "mean_pred_length": 15.35,
        "std_pred_length": 5.4614558498627455,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.6612377850162866,
        "vocab_size-1": 203,
        "unique-1": 170,
        "entropy-1": 7.161400816254353,
        "distinct-2": 0.9547038327526133,
        "vocab_size-2": 274,
        "unique-2": 263,
        "entropy-2": 8.067345951065896,
        "cond_entropy-2": 0.7014268694000122,
        "distinct-3": 0.9850187265917603,
        "vocab_size-3": 263,
        "unique-3": 259,
        "entropy-3": 8.03073338487104,
        "cond_entropy-3": -0.029304627946935176,
        "total_length-nopunct": 267,
        "mean_pred_length-nopunct": 13.35,
        "std_pred_length-nopunct": 4.819491674440366,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7340823970037453,
        "vocab_size-1-nopunct": 196,
        "unique-1-nopunct": 169,
        "entropy-1-nopunct": 7.272406088129765,
        "distinct-2-nopunct": 0.951417004048583,
        "vocab_size-2-nopunct": 235,
        "unique-2-nopunct": 225,
        "entropy-2-nopunct": 7.843104073689971,
        "cond_entropy-2-nopunct": 0.6345271226903285,
        "distinct-3-nopunct": 0.9823788546255506,
        "vocab_size-3-nopunct": 223,
        "unique-3-nopunct": 219,
        "entropy-3-nopunct": 7.7913061965419965,
        "cond_entropy-3-nopunct": -0.04252359010874083,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13636363636363635,
            "2": 0.5151515151515151,
            "3": 0.8106796116504854
        },
        "nist": 6.307967109516967,
        "rouge1": {
            "precision": 0.80876,
            "recall": 0.73636,
            "fmeasure": 0.75856
        },
        "rouge2": {
            "precision": 0.61088,
            "recall": 0.54978,
            "fmeasure": 0.56868
        },
        "rougeL": {
            "precision": 0.7255,
            "recall": 0.66051,
            "fmeasure": 0.67926
        },
        "rougeLsum": {
            "precision": 0.7255,
            "recall": 0.66051,
            "fmeasure": 0.67926
        },
        "bleu": 48.88323,
        "meteor": 0.4191994997587881,
        "bertscore": {
            "precision": 0.94223,
            "recall": 0.92934,
            "f1": 0.93264
        },
        "nubia": {
            "semantic_relation": 4.16322,
            "contradiction": 21.02125,
            "irrelevancy": 17.5458,
            "logical_agreement": 61.43295,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.89957,
            "nubia_score": 0.70145
        },
        "bleurt": 0.31344
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.68,
        "total_length": 131,
        "mean_pred_length": 21.833333333333332,
        "std_pred_length": 4.487637339278753,
        "median_pred_length": 24.0,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.648854961832061,
        "vocab_size-1": 85,
        "unique-1": 68,
        "entropy-1": 5.965878678233705,
        "distinct-2": 0.936,
        "vocab_size-2": 117,
        "unique-2": 112,
        "entropy-2": 6.808907160866601,
        "cond_entropy-2": 0.8013934863559753,
        "distinct-3": 0.9915966386554622,
        "vocab_size-3": 118,
        "unique-3": 117,
        "entropy-3": 6.878011040618867,
        "cond_entropy-3": 0.07701365069994708,
        "total_length-nopunct": 119,
        "mean_pred_length-nopunct": 19.833333333333332,
        "std_pred_length-nopunct": 4.258977446393546,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.680672268907563,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 5.890752398802141,
        "distinct-2-nopunct": 0.9469026548672567,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.682040551137004,
        "cond_entropy-2-nopunct": 0.8217255831871776,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 107,
        "unique-3-nopunct": 107,
        "entropy-3-nopunct": 6.741466986401138,
        "cond_entropy-3-nopunct": 0.05782672000873278,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2830188679245283,
            "2": 0.6216216216216216,
            "3": 0.6190476190476191
        },
        "nist": 3.861451965421801,
        "rouge1": {
            "precision": 0.54373,
            "recall": 0.58777,
            "fmeasure": 0.54477
        },
        "rouge2": {
            "precision": 0.29777,
            "recall": 0.34083,
            "fmeasure": 0.30249
        },
        "rougeL": {
            "precision": 0.40024,
            "recall": 0.46427,
            "fmeasure": 0.41704
        },
        "rougeLsum": {
            "precision": 0.40024,
            "recall": 0.46427,
            "fmeasure": 0.41704
        },
        "bleu": 20.36913,
        "meteor": 0.3067910836974564,
        "bertscore": {
            "precision": 0.88453,
            "recall": 0.89294,
            "f1": 0.8859
        },
        "nubia": {
            "semantic_relation": 3.83196,
            "contradiction": 4.33712,
            "irrelevancy": 54.31033,
            "logical_agreement": 41.35255,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.27099,
            "nubia_score": 0.62509
        },
        "bleurt": -0.09839
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7275,
        "msttr-100_nopunct": 0.78,
        "total_length": 479,
        "mean_pred_length": 16.517241379310345,
        "std_pred_length": 4.575954316561003,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5594989561586639,
        "vocab_size-1": 268,
        "unique-1": 207,
        "entropy-1": 7.3394834403993165,
        "distinct-2": 0.9088888888888889,
        "vocab_size-2": 409,
        "unique-2": 382,
        "entropy-2": 8.602905962351336,
        "cond_entropy-2": 1.0789460579438548,
        "distinct-3": 0.9714964370546318,
        "vocab_size-3": 409,
        "unique-3": 399,
        "entropy-3": 8.657083133269875,
        "cond_entropy-3": 0.05920183038915471,
        "total_length-nopunct": 409,
        "mean_pred_length-nopunct": 14.10344827586207,
        "std_pred_length-nopunct": 3.7540307311053325,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6381418092909535,
        "vocab_size-1-nopunct": 261,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 7.520180078975859,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 350,
        "unique-2-nopunct": 329,
        "entropy-2-nopunct": 8.389252475480715,
        "cond_entropy-2-nopunct": 0.9373159995688012,
        "distinct-3-nopunct": 0.98005698005698,
        "vocab_size-3-nopunct": 344,
        "unique-3-nopunct": 337,
        "entropy-3-nopunct": 8.415441180418537,
        "cond_entropy-3-nopunct": 0.04111033129865725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23684210526315788,
            "2": 0.4925373134328358,
            "3": 0.8082595870206489
        },
        "nist": 7.0313143617751885,
        "rouge1": {
            "precision": 0.83533,
            "recall": 0.8011,
            "fmeasure": 0.80661
        },
        "rouge2": {
            "precision": 0.63971,
            "recall": 0.62607,
            "fmeasure": 0.62678
        },
        "rougeL": {
            "precision": 0.77299,
            "recall": 0.73404,
            "fmeasure": 0.74316
        },
        "rougeLsum": {
            "precision": 0.77299,
            "recall": 0.73404,
            "fmeasure": 0.74316
        },
        "bleu": 55.90766,
        "meteor": 0.43497480279902406,
        "bertscore": {
            "precision": 0.95086,
            "recall": 0.94666,
            "f1": 0.94792
        },
        "nubia": {
            "semantic_relation": 4.32696,
            "contradiction": 17.35769,
            "irrelevancy": 15.46995,
            "logical_agreement": 67.17235,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.81772,
            "nubia_score": 0.76755
        },
        "bleurt": 0.42873
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 15.5,
        "std_pred_length": 5.123475382979799,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.6935483870967742,
        "vocab_size-1": 43,
        "unique-1": 35,
        "entropy-1": 5.1152283679513335,
        "distinct-2": 0.8448275862068966,
        "vocab_size-2": 49,
        "unique-2": 42,
        "entropy-2": 5.513153408920674,
        "cond_entropy-2": 0.3178538645855851,
        "distinct-3": 0.9259259259259259,
        "vocab_size-3": 50,
        "unique-3": 46,
        "entropy-3": 5.606739354015319,
        "cond_entropy-3": 0.11912872925811879,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7037037037037037,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.939776160848589,
        "distinct-2-nopunct": 0.82,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.243856189774725,
        "cond_entropy-2-nopunct": 0.3492889362313264,
        "distinct-3-nopunct": 0.9130434782608695,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.34964891257875,
        "cond_entropy-3-nopunct": 0.11883620106489694,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "nist": 4.050875041181197,
        "rouge1": {
            "precision": 0.67929,
            "recall": 0.75681,
            "fmeasure": 0.71056
        },
        "rouge2": {
            "precision": 0.49038,
            "recall": 0.51637,
            "fmeasure": 0.50206
        },
        "rougeL": {
            "precision": 0.54942,
            "recall": 0.61091,
            "fmeasure": 0.57407
        },
        "rougeLsum": {
            "precision": 0.54942,
            "recall": 0.61091,
            "fmeasure": 0.57407
        },
        "bleu": 42.07567,
        "meteor": 0.44868020429597677,
        "bertscore": {
            "precision": 0.91252,
            "recall": 0.94745,
            "f1": 0.92921
        },
        "nubia": {
            "semantic_relation": 4.39608,
            "contradiction": 0.29553,
            "irrelevancy": 48.16709,
            "logical_agreement": 51.53738,
            "grammar_ref": 5.27719,
            "grammar_hyp": 4.91029,
            "nubia_score": 0.8375
        },
        "bleurt": 0.28775
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": -0.03214388408660256,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.0346217911747682,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.6111111111111112
        },
        "nist": 3.7971116812867303,
        "rouge1": {
            "precision": 0.65417,
            "recall": 0.57248,
            "fmeasure": 0.5907
        },
        "rouge2": {
            "precision": 0.4963,
            "recall": 0.37063,
            "fmeasure": 0.41614
        },
        "rougeL": {
            "precision": 0.62292,
            "recall": 0.53424,
            "fmeasure": 0.557
        },
        "rougeLsum": {
            "precision": 0.62292,
            "recall": 0.53424,
            "fmeasure": 0.557
        },
        "bleu": 40.35279,
        "meteor": 0.34602076148166255,
        "bertscore": {
            "precision": 0.91289,
            "recall": 0.90825,
            "f1": 0.90476
        },
        "nubia": {
            "semantic_relation": 3.7624,
            "contradiction": 44.70186,
            "irrelevancy": 7.06197,
            "logical_agreement": 48.23617,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.75209,
            "nubia_score": 0.51459
        },
        "bleurt": -0.12696
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "total_length": 121,
        "mean_pred_length": 15.125,
        "std_pred_length": 3.059309562630104,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7355371900826446,
        "vocab_size-1": 89,
        "unique-1": 78,
        "entropy-1": 6.153834931239157,
        "distinct-2": 0.9646017699115044,
        "vocab_size-2": 109,
        "unique-2": 106,
        "entropy-2": 6.742702081865087,
        "cond_entropy-2": 0.4186089774997671,
        "distinct-3": 0.9904761904761905,
        "vocab_size-3": 104,
        "unique-3": 103,
        "entropy-3": 6.695197898618494,
        "cond_entropy-3": -0.04160118282369897,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 2.5860201081971503,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8018867924528302,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.199249699682926,
        "distinct-2-nopunct": 0.9591836734693877,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.525374257358448,
        "cond_entropy-2-nopunct": 0.36928135399225676,
        "distinct-3-nopunct": 0.9888888888888889,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.46963087410744,
        "cond_entropy-3-nopunct": -0.047802442205939585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5666666666666667,
            "3": 0.7397260273972602
        },
        "nist": 5.394908439846706,
        "rouge1": {
            "precision": 0.72474,
            "recall": 0.74077,
            "fmeasure": 0.72594
        },
        "rouge2": {
            "precision": 0.48385,
            "recall": 0.49997,
            "fmeasure": 0.48659
        },
        "rougeL": {
            "precision": 0.60716,
            "recall": 0.6167,
            "fmeasure": 0.60534
        },
        "rougeLsum": {
            "precision": 0.60716,
            "recall": 0.6167,
            "fmeasure": 0.60534
        },
        "bleu": 42.47055,
        "meteor": 0.3962183529594521,
        "bertscore": {
            "precision": 0.92075,
            "recall": 0.92452,
            "f1": 0.92064
        },
        "nubia": {
            "semantic_relation": 4.31091,
            "contradiction": 13.57179,
            "irrelevancy": 25.39731,
            "logical_agreement": 61.0309,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.81968,
            "nubia_score": 0.74104
        },
        "bleurt": 0.24357
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 3.7574673462380614,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.7,
            "fmeasure": 0.65385
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "bleu": 65.8037,
        "meteor": 0.9555555555555555,
        "bertscore": {
            "precision": 0.97544,
            "recall": 0.97544,
            "f1": 0.97544
        },
        "nubia": {
            "semantic_relation": 4.11383,
            "contradiction": 0.4147,
            "irrelevancy": 35.64603,
            "logical_agreement": 63.93928,
            "grammar_ref": 4.09688,
            "grammar_hyp": 3.81746,
            "nubia_score": 0.76218
        },
        "bleurt": 0.34708
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.68,
        "total_length": 130,
        "mean_pred_length": 18.571428571428573,
        "std_pred_length": 4.531071864901058,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.6461538461538462,
        "vocab_size-1": 84,
        "unique-1": 67,
        "entropy-1": 6.004163100077034,
        "distinct-2": 0.926829268292683,
        "vocab_size-2": 114,
        "unique-2": 105,
        "entropy-2": 6.796173041924594,
        "cond_entropy-2": 0.7555692305973543,
        "distinct-3": 0.9655172413793104,
        "vocab_size-3": 112,
        "unique-3": 108,
        "entropy-3": 6.789015477886177,
        "cond_entropy-3": -0.015567992970288373,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 17.142857142857142,
        "std_pred_length-nopunct": 4.61143211187685,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6833333333333333,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 5.997329497818438,
        "distinct-2-nopunct": 0.9380530973451328,
        "vocab_size-2-nopunct": 106,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.696285157105471,
        "cond_entropy-2-nopunct": 0.7199019219819894,
        "distinct-3-nopunct": 0.9622641509433962,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 98,
        "entropy-3-nopunct": 6.652448756449977,
        "cond_entropy-3-nopunct": -0.04508869653123366,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.7142857142857143,
            "3": 0.7681159420289855
        },
        "nist": 5.256903930417678,
        "rouge1": {
            "precision": 0.73279,
            "recall": 0.71016,
            "fmeasure": 0.70751
        },
        "rouge2": {
            "precision": 0.54505,
            "recall": 0.48403,
            "fmeasure": 0.50217
        },
        "rougeL": {
            "precision": 0.6561,
            "recall": 0.63875,
            "fmeasure": 0.63492
        },
        "rougeLsum": {
            "precision": 0.6561,
            "recall": 0.63875,
            "fmeasure": 0.63492
        },
        "bleu": 53.38482,
        "meteor": 0.3973433427967635,
        "bertscore": {
            "precision": 0.9158,
            "recall": 0.91063,
            "f1": 0.91214
        },
        "nubia": {
            "semantic_relation": 4.13685,
            "contradiction": 29.6946,
            "irrelevancy": 14.32356,
            "logical_agreement": 55.98184,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.60097,
            "nubia_score": 0.71858
        },
        "bleurt": 0.0781
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.65,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 3.681787005729087,
        "median_pred_length": 17.5,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.6132075471698113,
        "vocab_size-1": 65,
        "unique-1": 48,
        "entropy-1": 5.63768566727415,
        "distinct-2": 0.88,
        "vocab_size-2": 88,
        "unique-2": 76,
        "entropy-2": 6.4038561897747375,
        "cond_entropy-2": 0.7154882049935388,
        "distinct-3": 0.9042553191489362,
        "vocab_size-3": 85,
        "unique-3": 76,
        "entropy-3": 6.363099489975496,
        "cond_entropy-3": -0.04671414660772556,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 4.189935029992179,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6428571428571429,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.602461278033195,
        "distinct-2-nopunct": 0.8804347826086957,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.284431521274413,
        "cond_entropy-2-nopunct": 0.7262473236378694,
        "distinct-3-nopunct": 0.9069767441860465,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.2402182430741915,
        "cond_entropy-3-nopunct": -0.0507855734479383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.625,
            "3": 0.875
        },
        "nist": 5.298835936741438,
        "rouge1": {
            "precision": 0.79028,
            "recall": 0.83827,
            "fmeasure": 0.81057
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.62879,
            "fmeasure": 0.59977
        },
        "rougeL": {
            "precision": 0.6679,
            "recall": 0.71577,
            "fmeasure": 0.68913
        },
        "rougeLsum": {
            "precision": 0.6679,
            "recall": 0.71577,
            "fmeasure": 0.68913
        },
        "bleu": 52.61191,
        "meteor": 0.4677936830362815,
        "bertscore": {
            "precision": 0.93954,
            "recall": 0.94716,
            "f1": 0.94269
        },
        "nubia": {
            "semantic_relation": 4.40765,
            "contradiction": 16.07921,
            "irrelevancy": 17.951,
            "logical_agreement": 65.96979,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.08686,
            "nubia_score": 0.84915
        },
        "bleurt": 0.42937
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 1.0
        },
        "nist": 2.9344531218659795,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.82639,
            "fmeasure": 0.80065
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.53571,
            "fmeasure": 0.51667
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.71528,
            "fmeasure": 0.68954
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.71528,
            "fmeasure": 0.68954
        },
        "bleu": 29.84746,
        "meteor": 0.5138508773447042,
        "bertscore": {
            "precision": 0.92559,
            "recall": 0.9385,
            "f1": 0.93139
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32445,
            "irrelevancy": 0.45783,
            "logical_agreement": 99.21772,
            "grammar_ref": 6.12307,
            "grammar_hyp": 5.78398,
            "nubia_score": 1.0
        },
        "bleurt": 0.6589
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.73,
        "total_length": 117,
        "mean_pred_length": 14.625,
        "std_pred_length": 3.5333235062756425,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6837606837606838,
        "vocab_size-1": 80,
        "unique-1": 66,
        "entropy-1": 5.959004117163815,
        "distinct-2": 0.908256880733945,
        "vocab_size-2": 99,
        "unique-2": 91,
        "entropy-2": 6.57084693941612,
        "cond_entropy-2": 0.4585481875675007,
        "distinct-3": 0.9504950495049505,
        "vocab_size-3": 96,
        "unique-3": 92,
        "entropy-3": 6.551727448076895,
        "cond_entropy-3": -0.023290787548265354,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 12.875,
        "std_pred_length-nopunct": 3.2572035551988456,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7378640776699029,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 5.942527804046428,
        "distinct-2-nopunct": 0.9052631578947369,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.3644895556538215,
        "cond_entropy-2-nopunct": 0.4635594546083997,
        "distinct-3-nopunct": 0.9540229885057471,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.342312605019257,
        "cond_entropy-3-nopunct": -0.02628122165275452,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.4,
            "3": 0.9130434782608695
        },
        "nist": 5.8956804648231875,
        "rouge1": {
            "precision": 0.79132,
            "recall": 0.76667,
            "fmeasure": 0.77454
        },
        "rouge2": {
            "precision": 0.57673,
            "recall": 0.5779,
            "fmeasure": 0.57431
        },
        "rougeL": {
            "precision": 0.68863,
            "recall": 0.67963,
            "fmeasure": 0.68051
        },
        "rougeLsum": {
            "precision": 0.68863,
            "recall": 0.67963,
            "fmeasure": 0.68051
        },
        "bleu": 54.01759,
        "meteor": 0.45765719712887415,
        "bertscore": {
            "precision": 0.93677,
            "recall": 0.95237,
            "f1": 0.94425
        },
        "nubia": {
            "semantic_relation": 4.44147,
            "contradiction": 4.48244,
            "irrelevancy": 33.86062,
            "logical_agreement": 61.65694,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.44968,
            "nubia_score": 0.82506
        },
        "bleurt": 0.29848
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5
        },
        "nist": 1.6754530754585606,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.69444,
            "fmeasure": 0.64286
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.32727,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.51429
        },
        "bleu": 13.35434,
        "meteor": 0.3150777603805283,
        "bertscore": {
            "precision": 0.91294,
            "recall": 0.89244,
            "f1": 0.90071
        },
        "nubia": {
            "semantic_relation": 3.68617,
            "contradiction": 0.37648,
            "irrelevancy": 33.24476,
            "logical_agreement": 66.37875,
            "grammar_ref": 6.47099,
            "grammar_hyp": 6.62454,
            "nubia_score": 0.59197
        },
        "bleurt": 0.00083
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 88,
        "mean_pred_length": 17.6,
        "std_pred_length": 6.019966777316964,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6590909090909091,
        "vocab_size-1": 58,
        "unique-1": 44,
        "entropy-1": 5.547151221620325,
        "distinct-2": 0.9397590361445783,
        "vocab_size-2": 78,
        "unique-2": 73,
        "entropy-2": 6.254557503636088,
        "cond_entropy-2": 0.6468814565261666,
        "distinct-3": 1.0,
        "vocab_size-3": 78,
        "unique-3": 78,
        "entropy-3": 6.285402218862257,
        "cond_entropy-3": 0.012926890079426122,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 5.083306010855534,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.717948717948718,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.557570168437035,
        "distinct-2-nopunct": 0.958904109589041,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.107632778058109,
        "cond_entropy-2-nopunct": 0.550805044571821,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.087462841250345,
        "cond_entropy-3-nopunct": -0.0141264235120307,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.5,
            "3": 0.7301587301587301
        },
        "nist": 4.533284735092326,
        "rouge1": {
            "precision": 0.83813,
            "recall": 0.72696,
            "fmeasure": 0.77155
        },
        "rouge2": {
            "precision": 0.64532,
            "recall": 0.56324,
            "fmeasure": 0.59578
        },
        "rougeL": {
            "precision": 0.78936,
            "recall": 0.70356,
            "fmeasure": 0.73634
        },
        "rougeLsum": {
            "precision": 0.78936,
            "recall": 0.70356,
            "fmeasure": 0.73634
        },
        "bleu": 57.76312,
        "meteor": 0.40485453724204173,
        "bertscore": {
            "precision": 0.95717,
            "recall": 0.9415,
            "f1": 0.94618
        },
        "nubia": {
            "semantic_relation": 4.15736,
            "contradiction": 3.31172,
            "irrelevancy": 40.28204,
            "logical_agreement": 56.40624,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.31915,
            "nubia_score": 0.72327
        },
        "bleurt": 0.22334
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.72,
        "total_length": 115,
        "mean_pred_length": 16.428571428571427,
        "std_pred_length": 3.8861344310672696,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6521739130434783,
        "vocab_size-1": 75,
        "unique-1": 60,
        "entropy-1": 5.79890300460692,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 99,
        "unique-2": 90,
        "entropy-2": 6.5882208354967915,
        "cond_entropy-2": 0.713543148667995,
        "distinct-3": 0.9306930693069307,
        "vocab_size-3": 94,
        "unique-3": 87,
        "entropy-3": 6.519597621365641,
        "cond_entropy-3": -0.05707205901563421,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 15.428571428571429,
        "std_pred_length-nopunct": 4.304719763805532,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6759259259259259,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.784075138047893,
        "distinct-2-nopunct": 0.9108910891089109,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.479993660969601,
        "cond_entropy-2-nopunct": 0.7533015580584405,
        "distinct-3-nopunct": 0.925531914893617,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.405652681464859,
        "cond_entropy-3-nopunct": -0.0610694395847956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.42857142857142855,
            "3": 0.7333333333333333
        },
        "nist": 5.267407803851569,
        "rouge1": {
            "precision": 0.79703,
            "recall": 0.72568,
            "fmeasure": 0.75267
        },
        "rouge2": {
            "precision": 0.61053,
            "recall": 0.54269,
            "fmeasure": 0.56866
        },
        "rougeL": {
            "precision": 0.69194,
            "recall": 0.64484,
            "fmeasure": 0.6594
        },
        "rougeLsum": {
            "precision": 0.69194,
            "recall": 0.64484,
            "fmeasure": 0.6594
        },
        "bleu": 45.5196,
        "meteor": 0.3872092962277678,
        "bertscore": {
            "precision": 0.9388,
            "recall": 0.92165,
            "f1": 0.92861
        },
        "nubia": {
            "semantic_relation": 4.0316,
            "contradiction": 22.14541,
            "irrelevancy": 32.93512,
            "logical_agreement": 44.91947,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.71468,
            "nubia_score": 0.67244
        },
        "bleurt": 0.16429
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 18,
        "entropy-1": 4.3565583354166755,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.23916418769779482,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.220175521464346,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.2724185498326622,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.45454545454545453,
            "3": 0.7222222222222222
        },
        "nist": 3.9113860550823047,
        "rouge1": {
            "precision": 0.75649,
            "recall": 0.6713,
            "fmeasure": 0.68808
        },
        "rouge2": {
            "precision": 0.34487,
            "recall": 0.39345,
            "fmeasure": 0.36384
        },
        "rougeL": {
            "precision": 0.66883,
            "recall": 0.6844,
            "fmeasure": 0.66347
        },
        "rougeLsum": {
            "precision": 0.66883,
            "recall": 0.6844,
            "fmeasure": 0.66347
        },
        "bleu": 31.99087,
        "meteor": 0.37014992260032603,
        "bertscore": {
            "precision": 0.91681,
            "recall": 0.91787,
            "f1": 0.90804
        },
        "nubia": {
            "semantic_relation": 3.97327,
            "contradiction": 0.29492,
            "irrelevancy": 47.10508,
            "logical_agreement": 52.6,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.2968,
            "nubia_score": 0.68976
        },
        "bleurt": 0.12671
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 15.142857142857142,
        "std_pred_length": 1.7261494247992246,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.6886792452830188,
        "vocab_size-1": 73,
        "unique-1": 60,
        "entropy-1": 5.8711964553826865,
        "distinct-2": 0.9595959595959596,
        "vocab_size-2": 95,
        "unique-2": 91,
        "entropy-2": 6.548548539271537,
        "cond_entropy-2": 0.5394286853015637,
        "distinct-3": 0.9891304347826086,
        "vocab_size-3": 91,
        "unique-3": 90,
        "entropy-3": 6.501822825622244,
        "cond_entropy-3": -0.0405772727182489,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 13.285714285714286,
        "std_pred_length-nopunct": 1.1605769149479943,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7526881720430108,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.881510859938891,
        "distinct-2-nopunct": 0.9534883720930233,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.333241498888145,
        "cond_entropy-2-nopunct": 0.49363221636999854,
        "distinct-3-nopunct": 0.9873417721518988,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.278464292480902,
        "cond_entropy-3-nopunct": -0.059192867284488804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.8351648351648352
        },
        "nist": 5.682219949076183,
        "rouge1": {
            "precision": 0.86489,
            "recall": 0.82024,
            "fmeasure": 0.83921
        },
        "rouge2": {
            "precision": 0.663,
            "recall": 0.63428,
            "fmeasure": 0.64624
        },
        "rougeL": {
            "precision": 0.76696,
            "recall": 0.73073,
            "fmeasure": 0.74611
        },
        "rougeLsum": {
            "precision": 0.76696,
            "recall": 0.73073,
            "fmeasure": 0.74611
        },
        "bleu": 57.23817,
        "meteor": 0.44461118920223675,
        "bertscore": {
            "precision": 0.97364,
            "recall": 0.96293,
            "f1": 0.96805
        },
        "nubia": {
            "semantic_relation": 4.56232,
            "contradiction": 10.45301,
            "irrelevancy": 3.42763,
            "logical_agreement": 86.11937,
            "grammar_ref": 4.9924,
            "grammar_hyp": 4.95446,
            "nubia_score": 0.84045
        },
        "bleurt": 0.53929
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.7275,
        "msttr-100_nopunct": 0.78,
        "total_length": 486,
        "mean_pred_length": 15.67741935483871,
        "std_pred_length": 4.665502059725492,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5617283950617284,
        "vocab_size-1": 273,
        "unique-1": 219,
        "entropy-1": 7.293398228997581,
        "distinct-2": 0.9252747252747253,
        "vocab_size-2": 421,
        "unique-2": 395,
        "entropy-2": 8.66404344281078,
        "cond_entropy-2": 1.1521261863689363,
        "distinct-3": 0.9740566037735849,
        "vocab_size-3": 413,
        "unique-3": 403,
        "entropy-3": 8.67425326705815,
        "cond_entropy-3": 0.01760618759763741,
        "total_length-nopunct": 420,
        "mean_pred_length-nopunct": 13.548387096774194,
        "std_pred_length-nopunct": 3.925423418110002,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6357142857142857,
        "vocab_size-1-nopunct": 267,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 7.507511618993999,
        "distinct-2-nopunct": 0.9331619537275064,
        "vocab_size-2-nopunct": 363,
        "unique-2-nopunct": 345,
        "entropy-2-nopunct": 8.450968046823672,
        "cond_entropy-2-nopunct": 1.014982876050947,
        "distinct-3-nopunct": 0.9860335195530726,
        "vocab_size-3-nopunct": 353,
        "unique-3-nopunct": 349,
        "entropy-3-nopunct": 8.453774192062681,
        "cond_entropy-3-nopunct": 0.010438567705692,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.5822784810126582,
            "3": 0.78125
        },
        "nist": 6.780904178981766,
        "rouge1": {
            "precision": 0.78115,
            "recall": 0.75738,
            "fmeasure": 0.76261
        },
        "rouge2": {
            "precision": 0.58308,
            "recall": 0.57631,
            "fmeasure": 0.57521
        },
        "rougeL": {
            "precision": 0.68196,
            "recall": 0.6645,
            "fmeasure": 0.66578
        },
        "rougeLsum": {
            "precision": 0.68196,
            "recall": 0.6645,
            "fmeasure": 0.66578
        },
        "bleu": 51.30286,
        "meteor": 0.42307167776045995,
        "bertscore": {
            "precision": 0.93576,
            "recall": 0.93487,
            "f1": 0.93405
        },
        "nubia": {
            "semantic_relation": 4.38531,
            "contradiction": 4.41904,
            "irrelevancy": 31.19781,
            "logical_agreement": 64.38315,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.61659,
            "nubia_score": 0.7868
        },
        "bleurt": 0.38932
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 10.571428571428571,
        "std_pred_length": 1.5907898179514348,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.6486486486486487,
        "vocab_size-1": 48,
        "unique-1": 37,
        "entropy-1": 5.254439386398451,
        "distinct-2": 0.8656716417910447,
        "vocab_size-2": 58,
        "unique-2": 49,
        "entropy-2": 5.797432474039858,
        "cond_entropy-2": 0.3494649294355968,
        "distinct-3": 0.8833333333333333,
        "vocab_size-3": 53,
        "unique-3": 46,
        "entropy-3": 5.6735572622751835,
        "cond_entropy-3": -0.12586526151592062,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 9.142857142857142,
        "std_pred_length-nopunct": 1.5518257844571737,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.71875,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.277114648336087,
        "distinct-2-nopunct": 0.8771929824561403,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.587275979077018,
        "cond_entropy-2-nopunct": 0.36384900550667887,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.443856189774728,
        "cond_entropy-3-nopunct": -0.14903382439001703,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5384615384615384,
            "3": 0.8214285714285714
        },
        "nist": 4.796119966747062,
        "rouge1": {
            "precision": 0.84663,
            "recall": 0.77388,
            "fmeasure": 0.80347
        },
        "rouge2": {
            "precision": 0.6869,
            "recall": 0.63027,
            "fmeasure": 0.65319
        },
        "rougeL": {
            "precision": 0.83565,
            "recall": 0.76289,
            "fmeasure": 0.79248
        },
        "rougeLsum": {
            "precision": 0.83565,
            "recall": 0.76289,
            "fmeasure": 0.79248
        },
        "bleu": 60.37253,
        "meteor": 0.4750016337303929,
        "bertscore": {
            "precision": 0.96246,
            "recall": 0.95657,
            "f1": 0.95925
        },
        "nubia": {
            "semantic_relation": 4.31909,
            "contradiction": 15.53426,
            "irrelevancy": 20.18547,
            "logical_agreement": 64.28027,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.16321,
            "nubia_score": 0.78448
        },
        "bleurt": 0.50375
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 0.9472807507835431,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.5291
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.69801,
            "fmeasure": 0.81667
        },
        "bleu": 47.87975,
        "meteor": 0.4180407844493463,
        "bertscore": {
            "precision": 0.9769,
            "recall": 0.93775,
            "f1": 0.95692
        },
        "nubia": {
            "semantic_relation": 4.92558,
            "contradiction": 0.44819,
            "irrelevancy": 0.47684,
            "logical_agreement": 99.07497,
            "grammar_ref": 3.61542,
            "grammar_hyp": 4.58816,
            "nubia_score": 0.99864
        },
        "bleurt": 0.78138
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.6739130434782609,
        "vocab_size-1": 31,
        "unique-1": 24,
        "entropy-1": 4.656729282558594,
        "distinct-2": 0.9534883720930233,
        "vocab_size-2": 41,
        "unique-2": 39,
        "entropy-2": 5.333241498888144,
        "cond_entropy-2": 0.6264101353605213,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.004336659814735832,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6904761904761905,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.556140863760576,
        "distinct-2-nopunct": 0.9487179487179487,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.182838116298145,
        "cond_entropy-2-nopunct": 0.6653775006671736,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.004366106308824779,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "nist": 4.266908960730434,
        "rouge1": {
            "precision": 0.83761,
            "recall": 0.78371,
            "fmeasure": 0.80054
        },
        "rouge2": {
            "precision": 0.56481,
            "recall": 0.50199,
            "fmeasure": 0.52531
        },
        "rougeL": {
            "precision": 0.67296,
            "recall": 0.64127,
            "fmeasure": 0.6518
        },
        "rougeLsum": {
            "precision": 0.67296,
            "recall": 0.64127,
            "fmeasure": 0.6518
        },
        "bleu": 26.87762,
        "meteor": 0.39504854735676104,
        "bertscore": {
            "precision": 0.95015,
            "recall": 0.93842,
            "f1": 0.94394
        },
        "nubia": {
            "semantic_relation": 4.64149,
            "contradiction": 0.64519,
            "irrelevancy": 1.01035,
            "logical_agreement": 98.34445,
            "grammar_ref": 4.67072,
            "grammar_hyp": 3.99346,
            "nubia_score": 0.92284
        },
        "bleurt": 0.53334
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.031128874149275,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 39,
        "unique-1": 33,
        "entropy-1": 5.0092456038951285,
        "distinct-2": 0.98,
        "vocab_size-2": 49,
        "unique-2": 48,
        "entropy-2": 5.603856189774728,
        "cond_entropy-2": 0.4942619377410644,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.07681597284814654,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 3.766629793329841,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7551020408163265,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.956247343982751,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.447408651885229,
        "cond_entropy-2-nopunct": 0.5496913079142531,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.08552060390671311,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.8461538461538461,
            "3": 0.9166666666666666
        },
        "nist": 4.725473350780454,
        "rouge1": {
            "precision": 0.77032,
            "recall": 0.86906,
            "fmeasure": 0.81014
        },
        "rouge2": {
            "precision": 0.53031,
            "recall": 0.60327,
            "fmeasure": 0.55864
        },
        "rougeL": {
            "precision": 0.70088,
            "recall": 0.7973,
            "fmeasure": 0.73968
        },
        "rougeLsum": {
            "precision": 0.70088,
            "recall": 0.7973,
            "fmeasure": 0.73968
        },
        "bleu": 52.52034,
        "meteor": 0.4568397660919181,
        "bertscore": {
            "precision": 0.93787,
            "recall": 0.94516,
            "f1": 0.93903
        },
        "nubia": {
            "semantic_relation": 4.54623,
            "contradiction": 3.40061,
            "irrelevancy": 20.966,
            "logical_agreement": 75.6334,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.2534,
            "nubia_score": 0.78069
        },
        "bleurt": 0.42809
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "total_length": 220,
        "mean_pred_length": 15.714285714285714,
        "std_pred_length": 5.724989974146823,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6181818181818182,
        "vocab_size-1": 136,
        "unique-1": 109,
        "entropy-1": 6.528690779978055,
        "distinct-2": 0.9223300970873787,
        "vocab_size-2": 190,
        "unique-2": 175,
        "entropy-2": 7.527496218920289,
        "cond_entropy-2": 0.8992113479938904,
        "distinct-3": 0.953125,
        "vocab_size-3": 183,
        "unique-3": 174,
        "entropy-3": 7.491212500721177,
        "cond_entropy-3": -0.0351063207216274,
        "total_length-nopunct": 194,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 5.166611805721464,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6701030927835051,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.571667121722007,
        "distinct-2-nopunct": 0.9277777777777778,
        "vocab_size-2-nopunct": 167,
        "unique-2-nopunct": 155,
        "entropy-2-nopunct": 7.343214832428753,
        "cond_entropy-2-nopunct": 0.8293001556318116,
        "distinct-3-nopunct": 0.9518072289156626,
        "vocab_size-3-nopunct": 158,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.278653889178234,
        "cond_entropy-3-nopunct": -0.07009747521068097,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2876712328767123,
            "2": 0.5076923076923077,
            "3": 0.7304347826086957
        },
        "nist": 5.253635511325613,
        "rouge1": {
            "precision": 0.75128,
            "recall": 0.68016,
            "fmeasure": 0.70303
        },
        "rouge2": {
            "precision": 0.53992,
            "recall": 0.48049,
            "fmeasure": 0.49804
        },
        "rougeL": {
            "precision": 0.62625,
            "recall": 0.56957,
            "fmeasure": 0.58636
        },
        "rougeLsum": {
            "precision": 0.62625,
            "recall": 0.56957,
            "fmeasure": 0.58636
        },
        "bleu": 38.74507,
        "meteor": 0.36477741363322985,
        "bertscore": {
            "precision": 0.92462,
            "recall": 0.91962,
            "f1": 0.92128
        },
        "nubia": {
            "semantic_relation": 3.90381,
            "contradiction": 10.43262,
            "irrelevancy": 45.60024,
            "logical_agreement": 43.96714,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.32556,
            "nubia_score": 0.66028
        },
        "bleurt": 0.04186
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.9090909090909091
        },
        "nist": 3.0475141666221517,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.71795,
            "fmeasure": 0.64583
        },
        "rouge2": {
            "precision": 0.34375,
            "recall": 0.42262,
            "fmeasure": 0.37857
        },
        "rougeL": {
            "precision": 0.32353,
            "recall": 0.40256,
            "fmeasure": 0.35833
        },
        "rougeLsum": {
            "precision": 0.32353,
            "recall": 0.40256,
            "fmeasure": 0.35833
        },
        "bleu": 32.77177,
        "meteor": 0.4310283599070166,
        "bertscore": {
            "precision": 0.86413,
            "recall": 0.87615,
            "f1": 0.8701
        },
        "nubia": {
            "semantic_relation": 3.56731,
            "contradiction": 0.12193,
            "irrelevancy": 99.76348,
            "logical_agreement": 0.11458,
            "grammar_ref": 4.56931,
            "grammar_hyp": 3.00136,
            "nubia_score": 0.76274
        },
        "bleurt": 0.02062
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.76,
        "total_length": 144,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.082762530298219,
        "median_pred_length": 18.5,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.625,
        "vocab_size-1": 90,
        "unique-1": 73,
        "entropy-1": 6.002278819536056,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 128,
        "unique-2": 122,
        "entropy-2": 6.9587144956302796,
        "cond_entropy-2": 0.8681981125038649,
        "distinct-3": 0.9921875,
        "vocab_size-3": 127,
        "unique-3": 126,
        "entropy-3": 6.984375,
        "cond_entropy-3": 0.03370727597096482,
        "total_length-nopunct": 120,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.949747468305833,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7083333333333334,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.003620227003132,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.729186283645418,
        "cond_entropy-2-nopunct": 0.7900853686855519,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.7004397181411,
        "cond_entropy-3-nopunct": -0.022733593318786542,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08,
            "2": 0.36363636363636365,
            "3": 0.6382978723404256
        },
        "nist": 4.40183129406613,
        "rouge1": {
            "precision": 0.65797,
            "recall": 0.62142,
            "fmeasure": 0.62229
        },
        "rouge2": {
            "precision": 0.4076,
            "recall": 0.3938,
            "fmeasure": 0.38981
        },
        "rougeL": {
            "precision": 0.56069,
            "recall": 0.51828,
            "fmeasure": 0.52188
        },
        "rougeLsum": {
            "precision": 0.56069,
            "recall": 0.51828,
            "fmeasure": 0.52188
        },
        "bleu": 35.19352,
        "meteor": 0.31733081945219793,
        "bertscore": {
            "precision": 0.89636,
            "recall": 0.89291,
            "f1": 0.89066
        },
        "nubia": {
            "semantic_relation": 3.62847,
            "contradiction": 22.88048,
            "irrelevancy": 29.45868,
            "logical_agreement": 47.66084,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.74767,
            "nubia_score": 0.56828
        },
        "bleurt": -0.02447
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.81,
        "total_length": 149,
        "mean_pred_length": 13.545454545454545,
        "std_pred_length": 3.962635403218794,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7046979865771812,
        "vocab_size-1": 105,
        "unique-1": 89,
        "entropy-1": 6.336773045243562,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 132,
        "unique-2": 128,
        "entropy-2": 7.0106275364569575,
        "cond_entropy-2": 0.46843856673799916,
        "distinct-3": 1.0,
        "vocab_size-3": 127,
        "unique-3": 127,
        "entropy-3": 6.988684686772147,
        "cond_entropy-3": -0.01346358886957074,
        "total_length-nopunct": 133,
        "mean_pred_length-nopunct": 12.090909090909092,
        "std_pred_length-nopunct": 3.5020655062287678,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7593984962406015,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.388603559558351,
        "distinct-2-nopunct": 0.9508196721311475,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.8200014768716954,
        "cond_entropy-2-nopunct": 0.49150830776720145,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 111,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.794415866350121,
        "cond_entropy-3-nopunct": -0.014611786489114044,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.3157894736842105,
            "3": 0.7580645161290323
        },
        "nist": 5.332313492452771,
        "rouge1": {
            "precision": 0.80225,
            "recall": 0.7254,
            "fmeasure": 0.756
        },
        "rouge2": {
            "precision": 0.60985,
            "recall": 0.55998,
            "fmeasure": 0.57955
        },
        "rougeL": {
            "precision": 0.71251,
            "recall": 0.6478,
            "fmeasure": 0.67287
        },
        "rougeLsum": {
            "precision": 0.71251,
            "recall": 0.6478,
            "fmeasure": 0.67287
        },
        "bleu": 49.27095,
        "meteor": 0.4013251817282538,
        "bertscore": {
            "precision": 0.94675,
            "recall": 0.92924,
            "f1": 0.93646
        },
        "nubia": {
            "semantic_relation": 4.4498,
            "contradiction": 3.03693,
            "irrelevancy": 16.48411,
            "logical_agreement": 80.47896,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.50613,
            "nubia_score": 0.81892
        },
        "bleurt": 0.43671
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 11.333333333333334,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 4.829966150010236,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": -0.004234272798947963,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.14684138832927116,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.664497779200463,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.04349873228287957,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6153846153846154,
            "3": 0.5185185185185185
        },
        "nist": 2.0927930803021164,
        "rouge1": {
            "precision": 0.90303,
            "recall": 0.58554,
            "fmeasure": 0.68201
        },
        "rouge2": {
            "precision": 0.73519,
            "recall": 0.43073,
            "fmeasure": 0.51544
        },
        "rougeL": {
            "precision": 0.8697,
            "recall": 0.55221,
            "fmeasure": 0.64868
        },
        "rougeLsum": {
            "precision": 0.8697,
            "recall": 0.55221,
            "fmeasure": 0.64868
        },
        "bleu": 35.24995,
        "meteor": 0.3093915178250699,
        "bertscore": {
            "precision": 0.93238,
            "recall": 0.86471,
            "f1": 0.89466
        },
        "nubia": {
            "semantic_relation": 4.10812,
            "contradiction": 0.34782,
            "irrelevancy": 1.96079,
            "logical_agreement": 97.69139,
            "grammar_ref": 4.97796,
            "grammar_hyp": 6.09516,
            "nubia_score": 0.58809
        },
        "bleurt": 0.17031
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.75,
        "total_length": 286,
        "mean_pred_length": 15.88888888888889,
        "std_pred_length": 6.0082248153758995,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.5909090909090909,
        "vocab_size-1": 169,
        "unique-1": 141,
        "entropy-1": 6.639214191019426,
        "distinct-2": 0.9216417910447762,
        "vocab_size-2": 247,
        "unique-2": 233,
        "entropy-2": 7.885997166179791,
        "cond_entropy-2": 1.0896373047216417,
        "distinct-3": 0.98,
        "vocab_size-3": 245,
        "unique-3": 240,
        "entropy-3": 7.9257842846621,
        "cond_entropy-3": 0.04475374423027607,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 13.944444444444445,
        "std_pred_length-nopunct": 5.410609148517817,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6613545816733067,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 6.792522808593955,
        "distinct-2-nopunct": 0.927038626609442,
        "vocab_size-2-nopunct": 216,
        "unique-2-nopunct": 205,
        "entropy-2-nopunct": 7.694616294850335,
        "cond_entropy-2-nopunct": 0.9760092519920622,
        "distinct-3-nopunct": 0.9813953488372092,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.7109835472638535,
        "cond_entropy-3-nopunct": 0.025912635187863527,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13636363636363635,
            "2": 0.2857142857142857,
            "3": 0.7315789473684211
        },
        "nist": 5.253140932876754,
        "rouge1": {
            "precision": 0.71667,
            "recall": 0.70931,
            "fmeasure": 0.69842
        },
        "rouge2": {
            "precision": 0.51482,
            "recall": 0.49243,
            "fmeasure": 0.49328
        },
        "rougeL": {
            "precision": 0.63492,
            "recall": 0.62864,
            "fmeasure": 0.61917
        },
        "rougeLsum": {
            "precision": 0.63492,
            "recall": 0.62864,
            "fmeasure": 0.61917
        },
        "bleu": 40.56897,
        "meteor": 0.38346357423261257,
        "bertscore": {
            "precision": 0.90725,
            "recall": 0.91106,
            "f1": 0.90698
        },
        "nubia": {
            "semantic_relation": 4.09685,
            "contradiction": 10.20594,
            "irrelevancy": 22.25765,
            "logical_agreement": 67.53641,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.7721,
            "nubia_score": 0.7081
        },
        "bleurt": 0.2547
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.7068905956085185,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.051189449246730766,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.8571428571428571
        },
        "nist": 3.38490235118082,
        "rouge1": {
            "precision": 0.59573,
            "recall": 0.63587,
            "fmeasure": 0.59837
        },
        "rouge2": {
            "precision": 0.32738,
            "recall": 0.29167,
            "fmeasure": 0.30206
        },
        "rougeL": {
            "precision": 0.46838,
            "recall": 0.46784,
            "fmeasure": 0.45637
        },
        "rougeLsum": {
            "precision": 0.46838,
            "recall": 0.46784,
            "fmeasure": 0.45637
        },
        "bleu": 39.27674,
        "meteor": 0.37560963224140004,
        "bertscore": {
            "precision": 0.89743,
            "recall": 0.90757,
            "f1": 0.89659
        },
        "nubia": {
            "semantic_relation": 4.06573,
            "contradiction": 0.3827,
            "irrelevancy": 47.0015,
            "logical_agreement": 52.6158,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.85623,
            "nubia_score": 0.74673
        },
        "bleurt": 0.19648
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.83,
        "total_length": 129,
        "mean_pred_length": 16.125,
        "std_pred_length": 5.3253521010351985,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.7364341085271318,
        "vocab_size-1": 95,
        "unique-1": 83,
        "entropy-1": 6.268665627967267,
        "distinct-2": 0.9586776859504132,
        "vocab_size-2": 116,
        "unique-2": 113,
        "entropy-2": 6.819689683555595,
        "cond_entropy-2": 0.4377100767886769,
        "distinct-3": 1.0,
        "vocab_size-3": 113,
        "unique-3": 113,
        "entropy-3": 6.8201789624152065,
        "cond_entropy-3": 0.007510415406080109,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 3.59687364248454,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8090909090909091,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.266548890951115,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.5743861262852255,
        "cond_entropy-2-nopunct": 0.348214554751647,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 6.554588851677623,
        "cond_entropy-3-nopunct": -0.011453511570453781,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.038461538461538464,
            "2": 0.4375,
            "3": 0.875
        },
        "nist": 5.775968297904077,
        "rouge1": {
            "precision": 0.90575,
            "recall": 0.8452,
            "fmeasure": 0.87268
        },
        "rouge2": {
            "precision": 0.71021,
            "recall": 0.66519,
            "fmeasure": 0.68541
        },
        "rougeL": {
            "precision": 0.74147,
            "recall": 0.69538,
            "fmeasure": 0.71613
        },
        "rougeLsum": {
            "precision": 0.74147,
            "recall": 0.69538,
            "fmeasure": 0.71613
        },
        "bleu": 55.89083,
        "meteor": 0.46838868462860717,
        "bertscore": {
            "precision": 0.95561,
            "recall": 0.95758,
            "f1": 0.95626
        },
        "nubia": {
            "semantic_relation": 4.35128,
            "contradiction": 7.36122,
            "irrelevancy": 10.02888,
            "logical_agreement": 82.6099,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.02072,
            "nubia_score": 0.76031
        },
        "bleurt": 0.44576
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 106,
        "mean_pred_length": 13.25,
        "std_pred_length": 3.799671038392666,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7075471698113207,
        "vocab_size-1": 75,
        "unique-1": 59,
        "entropy-1": 5.967267714156673,
        "distinct-2": 0.8877551020408163,
        "vocab_size-2": 87,
        "unique-2": 77,
        "entropy-2": 6.3825171145013035,
        "cond_entropy-2": 0.2324455424186133,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 85,
        "unique-3": 80,
        "entropy-3": 6.380741985218552,
        "cond_entropy-3": 0.018864224460727094,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 11.25,
        "std_pred_length-nopunct": 3.3819373146171707,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7888888888888889,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.9959732020731025,
        "distinct-2-nopunct": 0.9146341463414634,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.17761435215268,
        "cond_entropy-2-nopunct": 0.2178245543972773,
        "distinct-3-nopunct": 0.9594594594594594,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.128372284547874,
        "cond_entropy-3-nopunct": -0.029789348419357348,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24324324324324326,
            "2": 0.7,
            "3": 0.8166666666666667
        },
        "nist": 5.538380261884535,
        "rouge1": {
            "precision": 0.86264,
            "recall": 0.76007,
            "fmeasure": 0.79067
        },
        "rouge2": {
            "precision": 0.60831,
            "recall": 0.54022,
            "fmeasure": 0.55831
        },
        "rougeL": {
            "precision": 0.71341,
            "recall": 0.63026,
            "fmeasure": 0.65227
        },
        "rougeLsum": {
            "precision": 0.71341,
            "recall": 0.63026,
            "fmeasure": 0.65227
        },
        "bleu": 44.92416,
        "meteor": 0.408608893282417,
        "bertscore": {
            "precision": 0.94877,
            "recall": 0.92967,
            "f1": 0.93477
        },
        "nubia": {
            "semantic_relation": 4.44994,
            "contradiction": 7.15878,
            "irrelevancy": 6.49671,
            "logical_agreement": 86.34451,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.33323,
            "nubia_score": 0.78117
        },
        "bleurt": 0.41194
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.715,
        "total_length": 264,
        "mean_pred_length": 15.529411764705882,
        "std_pred_length": 4.778846120374094,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6174242424242424,
        "vocab_size-1": 163,
        "unique-1": 130,
        "entropy-1": 6.76445624176628,
        "distinct-2": 0.8987854251012146,
        "vocab_size-2": 222,
        "unique-2": 202,
        "entropy-2": 7.726687525098215,
        "cond_entropy-2": 0.802097685357464,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 220,
        "unique-3": 210,
        "entropy-3": 7.758533529205233,
        "cond_entropy-3": 0.0395353737169299,
        "total_length-nopunct": 238,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.61455497822475,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6680672268907563,
        "vocab_size-1-nopunct": 159,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.840586854153551,
        "distinct-2-nopunct": 0.9004524886877828,
        "vocab_size-2-nopunct": 199,
        "unique-2-nopunct": 182,
        "entropy-2-nopunct": 7.5672922087028915,
        "cond_entropy-2-nopunct": 0.773478942580625,
        "distinct-3-nopunct": 0.9607843137254902,
        "vocab_size-3-nopunct": 196,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.593993969422477,
        "cond_entropy-3-nopunct": 0.03528203504164958,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17777777777777778,
            "2": 0.3058823529411765,
            "3": 0.7103825136612022
        },
        "nist": 4.917644422604466,
        "rouge1": {
            "precision": 0.74352,
            "recall": 0.66944,
            "fmeasure": 0.69002
        },
        "rouge2": {
            "precision": 0.52653,
            "recall": 0.45652,
            "fmeasure": 0.47942
        },
        "rougeL": {
            "precision": 0.66452,
            "recall": 0.59965,
            "fmeasure": 0.61759
        },
        "rougeLsum": {
            "precision": 0.66452,
            "recall": 0.59965,
            "fmeasure": 0.61759
        },
        "bleu": 36.44553,
        "meteor": 0.35331808654914065,
        "bertscore": {
            "precision": 0.92757,
            "recall": 0.90578,
            "f1": 0.91497
        },
        "nubia": {
            "semantic_relation": 3.97265,
            "contradiction": 12.5823,
            "irrelevancy": 28.69529,
            "logical_agreement": 58.72242,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.41004,
            "nubia_score": 0.64926
        },
        "bleurt": 0.13013
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1986532337201607,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "bleurt": 0.99035
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 63,
        "mean_pred_length": 15.75,
        "std_pred_length": 9.807522622966516,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 49,
        "unique-1": 40,
        "entropy-1": 5.443793566762826,
        "distinct-2": 0.9830508474576272,
        "vocab_size-2": 58,
        "unique-2": 57,
        "entropy-2": 5.848744744277091,
        "cond_entropy-2": 0.305526523733735,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.10128333583718159,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 7.327175444876422,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8979591836734694,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.410628211462147,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.05492102999224406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.13430109171159124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.21052631578947367,
            "3": 0.8
        },
        "nist": 3.8337609951858003,
        "rouge1": {
            "precision": 0.58547,
            "recall": 0.46875,
            "fmeasure": 0.4807
        },
        "rouge2": {
            "precision": 0.41225,
            "recall": 0.29777,
            "fmeasure": 0.30899
        },
        "rougeL": {
            "precision": 0.55849,
            "recall": 0.42847,
            "fmeasure": 0.44885
        },
        "rougeLsum": {
            "precision": 0.55849,
            "recall": 0.42847,
            "fmeasure": 0.44885
        },
        "bleu": 39.62306,
        "meteor": 0.2838496997626781,
        "bertscore": {
            "precision": 0.83416,
            "recall": 0.83867,
            "f1": 0.8258
        },
        "nubia": {
            "semantic_relation": 3.48993,
            "contradiction": 26.53718,
            "irrelevancy": 51.86941,
            "logical_agreement": 21.59341,
            "grammar_ref": 4.83501,
            "grammar_hyp": 5.05817,
            "nubia_score": 0.50501
        },
        "bleurt": -0.40977
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.82,
        "total_length": 159,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 4.760952285695233,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 106,
        "unique-1": 87,
        "entropy-1": 6.314877054101315,
        "distinct-2": 0.94,
        "vocab_size-2": 141,
        "unique-2": 133,
        "entropy-2": 7.10378610714811,
        "cond_entropy-2": 0.6887894071177753,
        "distinct-3": 0.9574468085106383,
        "vocab_size-3": 135,
        "unique-3": 129,
        "entropy-3": 7.0544449694200555,
        "cond_entropy-3": -0.041360334535644104,
        "total_length-nopunct": 147,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 4.876246279442598,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7074829931972789,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.337883648998939,
        "distinct-2-nopunct": 0.9347826086956522,
        "vocab_size-2-nopunct": 129,
        "unique-2-nopunct": 121,
        "entropy-2-nopunct": 6.972619474878432,
        "cond_entropy-2-nopunct": 0.6909394364775835,
        "distinct-3-nopunct": 0.9534883720930233,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 6.918203999609287,
        "cond_entropy-3-nopunct": -0.044933732345895865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.3877551020408163,
            "3": 0.7183098591549296
        },
        "nist": 4.623704462553045,
        "rouge1": {
            "precision": 0.58289,
            "recall": 0.6261,
            "fmeasure": 0.59053
        },
        "rouge2": {
            "precision": 0.31439,
            "recall": 0.34671,
            "fmeasure": 0.32139
        },
        "rougeL": {
            "precision": 0.51464,
            "recall": 0.56994,
            "fmeasure": 0.52866
        },
        "rougeLsum": {
            "precision": 0.51464,
            "recall": 0.56994,
            "fmeasure": 0.52866
        },
        "bleu": 28.16073,
        "meteor": 0.3310814962088994,
        "bertscore": {
            "precision": 0.89397,
            "recall": 0.90107,
            "f1": 0.8949
        },
        "nubia": {
            "semantic_relation": 3.65293,
            "contradiction": 6.71289,
            "irrelevancy": 40.7273,
            "logical_agreement": 52.5598,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.54715,
            "nubia_score": 0.59969
        },
        "bleurt": -0.00066
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.6956521739130435,
        "vocab_size-1": 16,
        "unique-1": 9,
        "entropy-1": 3.9148663038831004,
        "distinct-2": 0.7272727272727273,
        "vocab_size-2": 16,
        "unique-2": 10,
        "entropy-2": 3.9139770731827506,
        "cond_entropy-2": -0.018675791965170118,
        "distinct-3": 0.7619047619047619,
        "vocab_size-3": 16,
        "unique-3": 11,
        "entropy-3": 3.916126946588283,
        "cond_entropy-3": -0.019495148239489106,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.9148663038831004,
        "distinct-2-nopunct": 0.7272727272727273,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.9139770731827506,
        "cond_entropy-2-nopunct": -0.018675791965170118,
        "distinct-3-nopunct": 0.7619047619047619,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.916126946588283,
        "cond_entropy-3-nopunct": -0.019495148239489106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.4666666666666667
        },
        "nist": 1.7664318093777598,
        "rouge1": {
            "precision": 0.43478,
            "recall": 0.46898,
            "fmeasure": 0.45118
        },
        "rouge2": {
            "precision": 0.22727,
            "recall": 0.24603,
            "fmeasure": 0.23625
        },
        "rougeL": {
            "precision": 0.3913,
            "recall": 0.42208,
            "fmeasure": 0.40606
        },
        "rougeLsum": {
            "precision": 0.3913,
            "recall": 0.42208,
            "fmeasure": 0.40606
        },
        "bleu": 13.56698,
        "meteor": 0.23680870064875797,
        "bertscore": {
            "precision": 0.87161,
            "recall": 0.81435,
            "f1": 0.84201
        },
        "nubia": {
            "semantic_relation": 3.13011,
            "contradiction": 37.34867,
            "irrelevancy": 61.86161,
            "logical_agreement": 0.78972,
            "grammar_ref": 3.42286,
            "grammar_hyp": 4.37522,
            "nubia_score": 0.4088
        },
        "bleurt": -0.2944
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.72,
        "total_length": 150,
        "mean_pred_length": 18.75,
        "std_pred_length": 6.49519052838329,
        "median_pred_length": 18.5,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.6466666666666666,
        "vocab_size-1": 97,
        "unique-1": 75,
        "entropy-1": 6.260043774648195,
        "distinct-2": 0.8943661971830986,
        "vocab_size-2": 127,
        "unique-2": 115,
        "entropy-2": 6.9190788976584665,
        "cond_entropy-2": 0.5752232559143273,
        "distinct-3": 0.9552238805970149,
        "vocab_size-3": 128,
        "unique-3": 122,
        "entropy-3": 6.976536951651809,
        "cond_entropy-3": 0.0712292911184896,
        "total_length-nopunct": 135,
        "mean_pred_length-nopunct": 16.875,
        "std_pred_length-nopunct": 6.352902879786531,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6814814814814815,
        "vocab_size-1-nopunct": 92,
        "unique-1-nopunct": 72,
        "entropy-1-nopunct": 6.231962912248539,
        "distinct-2-nopunct": 0.8976377952755905,
        "vocab_size-2-nopunct": 114,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.76226824974724,
        "cond_entropy-2-nopunct": 0.5631703688191819,
        "distinct-3-nopunct": 0.957983193277311,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 109,
        "entropy-3-nopunct": 6.810784149862564,
        "cond_entropy-3-nopunct": 0.0637371731926136,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.5,
            "3": 0.8811881188118812
        },
        "nist": 5.697320491192216,
        "rouge1": {
            "precision": 0.81899,
            "recall": 0.87519,
            "fmeasure": 0.83978
        },
        "rouge2": {
            "precision": 0.62647,
            "recall": 0.65845,
            "fmeasure": 0.63518
        },
        "rougeL": {
            "precision": 0.6492,
            "recall": 0.7364,
            "fmeasure": 0.68396
        },
        "rougeLsum": {
            "precision": 0.6492,
            "recall": 0.7364,
            "fmeasure": 0.68396
        },
        "bleu": 51.68988,
        "meteor": 0.4596016124817662,
        "bertscore": {
            "precision": 0.94739,
            "recall": 0.95339,
            "f1": 0.94841
        },
        "nubia": {
            "semantic_relation": 4.61734,
            "contradiction": 2.35046,
            "irrelevancy": 23.01454,
            "logical_agreement": 74.63499,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.52114,
            "nubia_score": 0.86673
        },
        "bleurt": 0.50425
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.875
        },
        "nist": 3.033201102543045,
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.825,
            "fmeasure": 0.75355
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.56085,
            "fmeasure": 0.50774
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.825,
            "fmeasure": 0.75355
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.825,
            "fmeasure": 0.75355
        },
        "bleu": 42.50281,
        "meteor": 0.4329119207003679,
        "bertscore": {
            "precision": 0.93341,
            "recall": 0.96502,
            "f1": 0.94895
        },
        "nubia": {
            "semantic_relation": 4.38564,
            "contradiction": 0.33133,
            "irrelevancy": 10.94402,
            "logical_agreement": 88.72465,
            "grammar_ref": 5.68329,
            "grammar_hyp": 4.98633,
            "nubia_score": 0.81864
        },
        "bleurt": 0.56282
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 6.819090848492928,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.6607142857142857,
        "vocab_size-1": 37,
        "unique-1": 24,
        "entropy-1": 5.030394654123197,
        "distinct-2": 0.9038461538461539,
        "vocab_size-2": 47,
        "unique-2": 42,
        "entropy-2": 5.508132025833403,
        "cond_entropy-2": 0.38365739232054424,
        "distinct-3": 0.9375,
        "vocab_size-3": 45,
        "unique-3": 42,
        "entropy-3": 5.4599625007211605,
        "cond_entropy-3": -0.032143884086602556,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 6.576473218982953,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.973660689688187,
        "distinct-2-nopunct": 0.8913043478260869,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.306170651709185,
        "cond_entropy-2-nopunct": 0.3690487011589607,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.249460279921618,
        "cond_entropy-3-nopunct": -0.05981596184968097,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.725
        },
        "nist": 4.4995212417496395,
        "rouge1": {
            "precision": 0.7306,
            "recall": 0.71471,
            "fmeasure": 0.71719
        },
        "rouge2": {
            "precision": 0.53636,
            "recall": 0.52163,
            "fmeasure": 0.52371
        },
        "rougeL": {
            "precision": 0.63535,
            "recall": 0.62269,
            "fmeasure": 0.62278
        },
        "rougeLsum": {
            "precision": 0.63535,
            "recall": 0.62269,
            "fmeasure": 0.62278
        },
        "bleu": 48.66345,
        "meteor": 0.4466564929449444,
        "bertscore": {
            "precision": 0.93838,
            "recall": 0.93206,
            "f1": 0.93512
        },
        "nubia": {
            "semantic_relation": 4.59024,
            "contradiction": 0.2949,
            "irrelevancy": 25.2111,
            "logical_agreement": 74.494,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.94626,
            "nubia_score": 0.85204
        },
        "bleurt": 0.29748
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 2.5,
        "median_pred_length": 17.5,
        "min_pred_length": 15,
        "max_pred_length": 20,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 25,
        "unique-1": 18,
        "entropy-1": 4.454721860532484,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 31,
        "unique-2": 29,
        "entropy-2": 4.923181998146335,
        "cond_entropy-2": 0.44873657133581435,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": 0.03883444909293795,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.250752013250441,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.680813428089397,
        "cond_entropy-2-nopunct": 0.4750413394224453,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.03103131238874396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nist": 5.637926300046651,
        "rouge1": {
            "precision": 0.91871,
            "recall": 0.95995,
            "fmeasure": 0.93805
        },
        "rouge2": {
            "precision": 0.84656,
            "recall": 0.88403,
            "fmeasure": 0.86407
        },
        "rougeL": {
            "precision": 0.91871,
            "recall": 0.95995,
            "fmeasure": 0.93805
        },
        "rougeLsum": {
            "precision": 0.91871,
            "recall": 0.95995,
            "fmeasure": 0.93805
        },
        "bleu": 90.76074,
        "meteor": 0.6235053567670109,
        "bertscore": {
            "precision": 0.9827,
            "recall": 0.9932,
            "f1": 0.9879
        },
        "nubia": {
            "semantic_relation": 4.88875,
            "contradiction": 0.34568,
            "irrelevancy": 36.65442,
            "logical_agreement": 62.99989,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.63716,
            "nubia_score": 0.97425
        },
        "bleurt": 0.75189
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 91,
        "mean_pred_length": 18.2,
        "std_pred_length": 4.1182520563948,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.6043956043956044,
        "vocab_size-1": 55,
        "unique-1": 36,
        "entropy-1": 5.467913426098802,
        "distinct-2": 0.8023255813953488,
        "vocab_size-2": 69,
        "unique-2": 54,
        "entropy-2": 6.01336039418667,
        "cond_entropy-2": 0.47090935873976164,
        "distinct-3": 0.8518518518518519,
        "vocab_size-3": 69,
        "unique-3": 58,
        "entropy-3": 6.034234107796177,
        "cond_entropy-3": 0.04636163709812506,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 16.2,
        "std_pred_length-nopunct": 3.4871191548325386,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6419753086419753,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.398310959594615,
        "distinct-2-nopunct": 0.8026315789473685,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.833325210755076,
        "cond_entropy-2-nopunct": 0.496957609271638,
        "distinct-3-nopunct": 0.8591549295774648,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.857424760319273,
        "cond_entropy-3-nopunct": 0.053296894823962174,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.14285714285714285,
            "3": 0.859375
        },
        "nist": 5.580655576868107,
        "rouge1": {
            "precision": 0.81088,
            "recall": 0.87666,
            "fmeasure": 0.82625
        },
        "rouge2": {
            "precision": 0.64683,
            "recall": 0.69158,
            "fmeasure": 0.66145
        },
        "rougeL": {
            "precision": 0.64832,
            "recall": 0.71743,
            "fmeasure": 0.66801
        },
        "rougeLsum": {
            "precision": 0.64832,
            "recall": 0.71743,
            "fmeasure": 0.66801
        },
        "bleu": 61.26163,
        "meteor": 0.45872434526805994,
        "bertscore": {
            "precision": 0.9464,
            "recall": 0.95926,
            "f1": 0.95209
        },
        "nubia": {
            "semantic_relation": 4.50928,
            "contradiction": 0.33178,
            "irrelevancy": 22.73038,
            "logical_agreement": 76.93785,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.54202,
            "nubia_score": 0.88208
        },
        "bleurt": 0.58796
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.6583123951777,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 17,
        "distinct-1": 0.7931034482758621,
        "vocab_size-1": 46,
        "unique-1": 38,
        "entropy-1": 5.375222374437916,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 51,
        "unique-2": 48,
        "entropy-2": 5.643776391052357,
        "cond_entropy-2": 0.15616576629515586,
        "distinct-3": 0.96,
        "vocab_size-3": 48,
        "unique-3": 46,
        "entropy-3": 5.563856189774728,
        "cond_entropy-3": -0.0710313123887439,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 1.299038105676658,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8301886792452831,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.35056196399716,
        "distinct-2-nopunct": 0.9387755102040817,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.492260864523372,
        "cond_entropy-2-nopunct": 0.17250367526629495,
        "distinct-3-nopunct": 0.9555555555555556,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.402964207440784,
        "cond_entropy-3-nopunct": -0.07841230334108928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4444444444444444,
            "3": 0.8478260869565217
        },
        "nist": 5.595341975674415,
        "rouge1": {
            "precision": 0.83196,
            "recall": 0.8131,
            "fmeasure": 0.82147
        },
        "rouge2": {
            "precision": 0.67788,
            "recall": 0.65684,
            "fmeasure": 0.66597
        },
        "rougeL": {
            "precision": 0.77427,
            "recall": 0.75891,
            "fmeasure": 0.76538
        },
        "rougeLsum": {
            "precision": 0.77427,
            "recall": 0.75891,
            "fmeasure": 0.76538
        },
        "bleu": 71.60574,
        "meteor": 0.4709186024232505,
        "bertscore": {
            "precision": 0.96247,
            "recall": 0.95504,
            "f1": 0.95634
        },
        "nubia": {
            "semantic_relation": 4.6985,
            "contradiction": 13.44953,
            "irrelevancy": 5.98098,
            "logical_agreement": 80.56949,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.48365,
            "nubia_score": 0.89201
        },
        "bleurt": 0.50871
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 76,
        "mean_pred_length": 19.0,
        "std_pred_length": 6.442049363362563,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6973684210526315,
        "vocab_size-1": 53,
        "unique-1": 37,
        "entropy-1": 5.548987836091434,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 66,
        "unique-2": 61,
        "entropy-2": 5.99277378613449,
        "cond_entropy-2": 0.4548381543403972,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 66,
        "unique-3": 64,
        "entropy-3": 6.028639311838579,
        "cond_entropy-3": 0.046286185428078025,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.284902544988268,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.420009133144317,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.773557262275184,
        "cond_entropy-2-nopunct": 0.3755475202545809,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.735926350629038,
        "cond_entropy-3-nopunct": -0.045964244979485855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.3333333333333333,
            "3": 0.717948717948718
        },
        "nist": 4.279251035187947,
        "rouge1": {
            "precision": 0.64696,
            "recall": 0.73485,
            "fmeasure": 0.67512
        },
        "rouge2": {
            "precision": 0.40194,
            "recall": 0.45251,
            "fmeasure": 0.4171
        },
        "rougeL": {
            "precision": 0.55129,
            "recall": 0.63264,
            "fmeasure": 0.57939
        },
        "rougeLsum": {
            "precision": 0.55129,
            "recall": 0.63264,
            "fmeasure": 0.57939
        },
        "bleu": 36.51203,
        "meteor": 0.39437072421376246,
        "bertscore": {
            "precision": 0.89689,
            "recall": 0.93081,
            "f1": 0.90838
        },
        "nubia": {
            "semantic_relation": 3.99947,
            "contradiction": 9.45618,
            "irrelevancy": 42.6565,
            "logical_agreement": 47.88732,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.44488,
            "nubia_score": 0.7097
        },
        "bleurt": -0.02387
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.070656113151927,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.2673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.794653473544342,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.3148841634647017,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6153846153846154,
            "2": 1.0,
            "3": 0.2857142857142857
        },
        "nist": 3.307227002023638,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.58405,
            "fmeasure": 0.5518
        },
        "rouge2": {
            "precision": 0.35185,
            "recall": 0.39461,
            "fmeasure": 0.3685
        },
        "rougeL": {
            "precision": 0.36842,
            "recall": 0.41026,
            "fmeasure": 0.38682
        },
        "rougeLsum": {
            "precision": 0.36842,
            "recall": 0.41026,
            "fmeasure": 0.38682
        },
        "bleu": 43.8113,
        "meteor": 0.3545009134706633,
        "bertscore": {
            "precision": 0.90254,
            "recall": 0.8786,
            "f1": 0.89041
        },
        "nubia": {
            "semantic_relation": 2.84151,
            "contradiction": 28.68066,
            "irrelevancy": 61.5216,
            "logical_agreement": 9.79774,
            "grammar_ref": 4.13721,
            "grammar_hyp": 3.19237,
            "nubia_score": 0.40953
        },
        "bleurt": -0.36402
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.0615528128088303,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 40,
        "unique-1": 35,
        "entropy-1": 5.158562939644919,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.23328538598860132,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.1312445332782525,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.5811388300841898,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.135234743489787,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.21911303891232498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.75,
            "3": 0.7619047619047619
        },
        "nist": 4.593171423120515,
        "rouge1": {
            "precision": 0.6893,
            "recall": 0.79899,
            "fmeasure": 0.73485
        },
        "rouge2": {
            "precision": 0.44434,
            "recall": 0.52785,
            "fmeasure": 0.47782
        },
        "rougeL": {
            "precision": 0.61101,
            "recall": 0.72058,
            "fmeasure": 0.65646
        },
        "rougeLsum": {
            "precision": 0.61101,
            "recall": 0.72058,
            "fmeasure": 0.65646
        },
        "bleu": 42.63654,
        "meteor": 0.37887625892536547,
        "bertscore": {
            "precision": 0.9162,
            "recall": 0.92606,
            "f1": 0.92044
        },
        "nubia": {
            "semantic_relation": 3.75341,
            "contradiction": 24.55604,
            "irrelevancy": 43.05722,
            "logical_agreement": 32.38674,
            "grammar_ref": 4.75156,
            "grammar_hyp": 4.79258,
            "nubia_score": 0.56401
        },
        "bleurt": 0.24109
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 12,
        "entropy-1": 3.921928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.34705205013517054,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.826874881864637,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.3108863768876157,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.5
        },
        "nist": 3.540013232957842,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.625,
            "fmeasure": 0.68182
        },
        "rouge2": {
            "precision": 0.57895,
            "recall": 0.47826,
            "fmeasure": 0.52381
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.375,
            "fmeasure": 0.40909
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.375,
            "fmeasure": 0.40909
        },
        "bleu": 34.40873,
        "meteor": 0.34132228587361996,
        "bertscore": {
            "precision": 0.90961,
            "recall": 0.86667,
            "f1": 0.88762
        },
        "nubia": {
            "semantic_relation": 3.36802,
            "contradiction": 72.15792,
            "irrelevancy": 23.51895,
            "logical_agreement": 4.32313,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.44997,
            "nubia_score": 0.48688
        },
        "bleurt": -0.17563
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.037537158749660605,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nist": 4.104459546984439,
        "rouge1": {
            "precision": 0.7451,
            "recall": 0.85205,
            "fmeasure": 0.78711
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.575,
            "fmeasure": 0.52885
        },
        "rougeL": {
            "precision": 0.54902,
            "recall": 0.74153,
            "fmeasure": 0.62465
        },
        "rougeLsum": {
            "precision": 0.54902,
            "recall": 0.74153,
            "fmeasure": 0.62465
        },
        "bleu": 34.83155,
        "meteor": 0.4407427869909554,
        "bertscore": {
            "precision": 0.92039,
            "recall": 0.9343,
            "f1": 0.92729
        },
        "nubia": {
            "semantic_relation": 4.64448,
            "contradiction": 6.54198,
            "irrelevancy": 49.06338,
            "logical_agreement": 44.39463,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.06377,
            "nubia_score": 0.86116
        },
        "bleurt": 0.18232
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 22.666666666666668,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 23.0,
        "min_pred_length": 22,
        "max_pred_length": 23,
        "distinct-1": 0.5735294117647058,
        "vocab_size-1": 39,
        "unique-1": 19,
        "entropy-1": 5.071000848915581,
        "distinct-2": 0.7230769230769231,
        "vocab_size-2": 47,
        "unique-2": 29,
        "entropy-2": 5.468521659182302,
        "cond_entropy-2": 0.3982805945283264,
        "distinct-3": 0.7580645161290323,
        "vocab_size-3": 47,
        "unique-3": 32,
        "entropy-3": 5.470325342644937,
        "cond_entropy-3": 0.028602690906807837,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 20.666666666666668,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5806451612903226,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.936141222019716,
        "distinct-2-nopunct": 0.711864406779661,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 5.306371862921159,
        "cond_entropy-2-nopunct": 0.42199615386926675,
        "distinct-3-nopunct": 0.75,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 5.307354922057607,
        "cond_entropy-3-nopunct": 0.031854729838619936,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.2903225806451613,
            "3": 0.76
        },
        "nist": 3.5792320116293834,
        "rouge1": {
            "precision": 0.59318,
            "recall": 0.6326,
            "fmeasure": 0.60763
        },
        "rouge2": {
            "precision": 0.37684,
            "recall": 0.4057,
            "fmeasure": 0.38821
        },
        "rougeL": {
            "precision": 0.44859,
            "recall": 0.53844,
            "fmeasure": 0.48183
        },
        "rougeLsum": {
            "precision": 0.44859,
            "recall": 0.53844,
            "fmeasure": 0.48183
        },
        "bleu": 29.10961,
        "meteor": 0.26424489108052135,
        "bertscore": {
            "precision": 0.87656,
            "recall": 0.86937,
            "f1": 0.87096
        },
        "nubia": {
            "semantic_relation": 3.62587,
            "contradiction": 0.97794,
            "irrelevancy": 78.49427,
            "logical_agreement": 20.52779,
            "grammar_ref": 3.62435,
            "grammar_hyp": 2.931,
            "nubia_score": 0.67261
        },
        "bleurt": -0.06997
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.6144838329894124,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.96078,
            "fmeasure": 0.94819
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.7619,
            "fmeasure": 0.769
        },
        "rougeL": {
            "precision": 0.89583,
            "recall": 0.87712,
            "fmeasure": 0.88563
        },
        "rougeLsum": {
            "precision": 0.89583,
            "recall": 0.87712,
            "fmeasure": 0.88563
        },
        "bleu": 78.93575,
        "meteor": 0.5305475968023703,
        "bertscore": {
            "precision": 0.97737,
            "recall": 0.97443,
            "f1": 0.97475
        },
        "nubia": {
            "semantic_relation": 4.80996,
            "contradiction": 0.22818,
            "irrelevancy": 0.49433,
            "logical_agreement": 99.27749,
            "grammar_ref": 4.24096,
            "grammar_hyp": 3.78167,
            "nubia_score": 0.97089
        },
        "bleurt": 0.73059
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 142,
        "mean_pred_length": 17.75,
        "std_pred_length": 4.351723796382303,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.6830985915492958,
        "vocab_size-1": 97,
        "unique-1": 75,
        "entropy-1": 6.2747130111347476,
        "distinct-2": 0.9328358208955224,
        "vocab_size-2": 125,
        "unique-2": 116,
        "entropy-2": 6.931760832248823,
        "cond_entropy-2": 0.5626357943421032,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 120,
        "unique-3": 114,
        "entropy-3": 6.882041828261831,
        "cond_entropy-3": -0.041190219338808426,
        "total_length-nopunct": 132,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 4.06201920231798,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7121212121212122,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.267095945615057,
        "distinct-2-nopunct": 0.9274193548387096,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 6.809035020064282,
        "cond_entropy-2-nopunct": 0.584022827593969,
        "distinct-3-nopunct": 0.9482758620689655,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.754532719265489,
        "cond_entropy-3-nopunct": -0.053111866983440795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.4230769230769231,
            "3": 0.7211538461538461
        },
        "nist": 4.728871046133845,
        "rouge1": {
            "precision": 0.71229,
            "recall": 0.70353,
            "fmeasure": 0.70016
        },
        "rouge2": {
            "precision": 0.44865,
            "recall": 0.4453,
            "fmeasure": 0.44348
        },
        "rougeL": {
            "precision": 0.55453,
            "recall": 0.53497,
            "fmeasure": 0.53837
        },
        "rougeLsum": {
            "precision": 0.55453,
            "recall": 0.53497,
            "fmeasure": 0.53837
        },
        "bleu": 33.1549,
        "meteor": 0.34491783292800365,
        "bertscore": {
            "precision": 0.92275,
            "recall": 0.90956,
            "f1": 0.91466
        },
        "nubia": {
            "semantic_relation": 3.94664,
            "contradiction": 16.31124,
            "irrelevancy": 25.94464,
            "logical_agreement": 57.74411,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.66317,
            "nubia_score": 0.64782
        },
        "bleurt": 0.2104
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.875,
        "vocab_size-1": 42,
        "unique-1": 38,
        "entropy-1": 5.303508854797682,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.10144365121215095,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.297079327540667,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": -0.004351101352409332,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.660377358490566
        },
        "nist": 3.2939008980824696,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.74159,
            "fmeasure": 0.78872
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.68957,
            "fmeasure": 0.72121
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.71034,
            "fmeasure": 0.74705
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.71034,
            "fmeasure": 0.74705
        },
        "bleu": 51.28249,
        "meteor": 0.3868556291837769,
        "bertscore": {
            "precision": 0.96908,
            "recall": 0.93874,
            "f1": 0.9535
        },
        "nubia": {
            "semantic_relation": 4.46717,
            "contradiction": 0.20795,
            "irrelevancy": 31.24937,
            "logical_agreement": 68.54268,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.74718,
            "nubia_score": 0.7458
        },
        "bleurt": 0.56158
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 17.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.7636363636363637,
        "vocab_size-1": 42,
        "unique-1": 38,
        "entropy-1": 5.090159487506411,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.608999573868721,
        "cond_entropy-2": 0.4977569262971584,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": 0.011308646426431946,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 3.299831645537222,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7884615384615384,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.060802700278785,
        "distinct-2-nopunct": 0.9591836734693877,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.517671323662893,
        "cond_entropy-2-nopunct": 0.496030073457312,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": 0.01221923155405388,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.8,
            "3": 0.6060606060606061
        },
        "nist": 3.3304167427097413,
        "rouge1": {
            "precision": 0.73005,
            "recall": 0.65951,
            "fmeasure": 0.68048
        },
        "rouge2": {
            "precision": 0.47063,
            "recall": 0.41937,
            "fmeasure": 0.43626
        },
        "rougeL": {
            "precision": 0.62803,
            "recall": 0.59777,
            "fmeasure": 0.6052
        },
        "rougeLsum": {
            "precision": 0.62803,
            "recall": 0.59777,
            "fmeasure": 0.6052
        },
        "bleu": 35.26082,
        "meteor": 0.29941923201535964,
        "bertscore": {
            "precision": 0.91619,
            "recall": 0.91869,
            "f1": 0.91678
        },
        "nubia": {
            "semantic_relation": 4.00594,
            "contradiction": 74.98637,
            "irrelevancy": 23.49517,
            "logical_agreement": 1.51845,
            "grammar_ref": 3.79025,
            "grammar_hyp": 3.98338,
            "nubia_score": 0.61847
        },
        "bleurt": 0.18774
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.642796092394707,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.75,
        "vocab_size-1": 33,
        "unique-1": 27,
        "entropy-1": 4.851365993588127,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.3859252640295669,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.05699291222712945,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 4.189935029992178,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.771928094887363,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.1553993115749,
        "cond_entropy-2-nopunct": 0.4280658112821278,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.06316699496684555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3076923076923077,
            "3": 0.8333333333333334
        },
        "nist": 4.9117773200106,
        "rouge1": {
            "precision": 0.75553,
            "recall": 0.78691,
            "fmeasure": 0.76104
        },
        "rouge2": {
            "precision": 0.54141,
            "recall": 0.54019,
            "fmeasure": 0.53317
        },
        "rougeL": {
            "precision": 0.62855,
            "recall": 0.68912,
            "fmeasure": 0.64429
        },
        "rougeLsum": {
            "precision": 0.62855,
            "recall": 0.68912,
            "fmeasure": 0.64429
        },
        "bleu": 54.21922,
        "meteor": 0.43311518731175286,
        "bertscore": {
            "precision": 0.91215,
            "recall": 0.94725,
            "f1": 0.9285
        },
        "nubia": {
            "semantic_relation": 4.21007,
            "contradiction": 1.11186,
            "irrelevancy": 59.19426,
            "logical_agreement": 39.69388,
            "grammar_ref": 4.38609,
            "grammar_hyp": 4.12594,
            "nubia_score": 0.70611
        },
        "bleurt": 0.29073
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 2.5,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.1757358691004915,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.15446975243603325,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064474,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.17139956434903564,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9411764705882353
        },
        "nist": 4.149306504606683,
        "rouge1": {
            "precision": 0.83974,
            "recall": 0.73624,
            "fmeasure": 0.78111
        },
        "rouge2": {
            "precision": 0.58135,
            "recall": 0.5078,
            "fmeasure": 0.53908
        },
        "rougeL": {
            "precision": 0.80609,
            "recall": 0.70581,
            "fmeasure": 0.74916
        },
        "rougeLsum": {
            "precision": 0.80609,
            "recall": 0.70581,
            "fmeasure": 0.74916
        },
        "bleu": 55.24706,
        "meteor": 0.4137558829677262,
        "bertscore": {
            "precision": 0.94919,
            "recall": 0.92931,
            "f1": 0.93906
        },
        "nubia": {
            "semantic_relation": 4.37921,
            "contradiction": 0.94678,
            "irrelevancy": 0.83951,
            "logical_agreement": 98.21371,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.55362,
            "nubia_score": 0.71691
        },
        "bleurt": 0.3245
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nist": 2.4088216118712005,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.9,
            "fmeasure": 0.76364
        },
        "rouge2": {
            "precision": 0.40909,
            "recall": 0.57937,
            "fmeasure": 0.47778
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.7875,
            "fmeasure": 0.66818
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.7875,
            "fmeasure": 0.66818
        },
        "bleu": 39.83287,
        "meteor": 0.5003427248492872,
        "bertscore": {
            "precision": 0.92625,
            "recall": 0.97141,
            "f1": 0.94829
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.36503,
            "irrelevancy": 1.513,
            "logical_agreement": 98.12197,
            "grammar_ref": 6.57359,
            "grammar_hyp": 5.21545,
            "nubia_score": 1.0
        },
        "bleurt": 0.62554
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 10.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 8.0,
        "min_pred_length": 6,
        "max_pred_length": 16,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.415061012203069,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.680813428089397,
        "cond_entropy-2": 0.1442932028512463,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.08659166810897904,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 4.320493798938574,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.3845171317931,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.1634083318910209,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.09740698270430062,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.16666666666666666,
            "3": 0.7727272727272727
        },
        "nist": 3.958775142318579,
        "rouge1": {
            "precision": 0.71806,
            "recall": 0.71697,
            "fmeasure": 0.69373
        },
        "rouge2": {
            "precision": 0.51587,
            "recall": 0.50132,
            "fmeasure": 0.48943
        },
        "rougeL": {
            "precision": 0.69722,
            "recall": 0.68364,
            "fmeasure": 0.66809
        },
        "rougeLsum": {
            "precision": 0.69722,
            "recall": 0.68364,
            "fmeasure": 0.66809
        },
        "bleu": 50.7678,
        "meteor": 0.35878410733778726,
        "bertscore": {
            "precision": 0.93711,
            "recall": 0.9218,
            "f1": 0.91956
        },
        "nubia": {
            "semantic_relation": 3.83787,
            "contradiction": 5.08385,
            "irrelevancy": 27.76052,
            "logical_agreement": 67.15563,
            "grammar_ref": 5.1114,
            "grammar_hyp": 4.8271,
            "nubia_score": 0.63479
        },
        "bleurt": 0.04462
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "total_length": 116,
        "mean_pred_length": 14.5,
        "std_pred_length": 4.527692569068709,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6896551724137931,
        "vocab_size-1": 80,
        "unique-1": 62,
        "entropy-1": 6.031478383223016,
        "distinct-2": 0.9351851851851852,
        "vocab_size-2": 101,
        "unique-2": 94,
        "entropy-2": 6.625257872533829,
        "cond_entropy-2": 0.46055746056300007,
        "distinct-3": 0.97,
        "vocab_size-3": 97,
        "unique-3": 94,
        "entropy-3": 6.583856189774739,
        "cond_entropy-3": -0.031031312388743973,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 12.625,
        "std_pred_length-nopunct": 3.7059917700933984,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7623762376237624,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 6.100146849320097,
        "distinct-2-nopunct": 0.9247311827956989,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.388621176699435,
        "cond_entropy-2-nopunct": 0.33647988724441175,
        "distinct-3-nopunct": 0.9647058823529412,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.33880270084359,
        "cond_entropy-3-nopunct": -0.03565022791150594,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.8584905660377359
        },
        "nist": 5.937944715315738,
        "rouge1": {
            "precision": 0.93208,
            "recall": 0.85643,
            "fmeasure": 0.88749
        },
        "rouge2": {
            "precision": 0.85019,
            "recall": 0.79088,
            "fmeasure": 0.81526
        },
        "rougeL": {
            "precision": 0.88736,
            "recall": 0.82199,
            "fmeasure": 0.84919
        },
        "rougeLsum": {
            "precision": 0.88736,
            "recall": 0.82199,
            "fmeasure": 0.84919
        },
        "bleu": 68.43679,
        "meteor": 0.48732108082792247,
        "bertscore": {
            "precision": 0.97175,
            "recall": 0.95153,
            "f1": 0.96099
        },
        "nubia": {
            "semantic_relation": 4.41557,
            "contradiction": 2.84712,
            "irrelevancy": 13.4008,
            "logical_agreement": 83.75209,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.34398,
            "nubia_score": 0.78606
        },
        "bleurt": 0.59335
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.5,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7741935483870968,
        "vocab_size-1": 24,
        "unique-1": 19,
        "entropy-1": 4.438067278128811,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.3175777881889729,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.307354922057605,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.35462325762194935,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "nist": 3.598157022532455,
        "rouge1": {
            "precision": 0.73947,
            "recall": 0.87308,
            "fmeasure": 0.79375
        },
        "rouge2": {
            "precision": 0.51852,
            "recall": 0.59444,
            "fmeasure": 0.54762
        },
        "rougeL": {
            "precision": 0.68684,
            "recall": 0.79615,
            "fmeasure": 0.73125
        },
        "rougeLsum": {
            "precision": 0.68684,
            "recall": 0.79615,
            "fmeasure": 0.73125
        },
        "bleu": 37.46855,
        "meteor": 0.43099214983493384,
        "bertscore": {
            "precision": 0.93422,
            "recall": 0.93784,
            "f1": 0.93597
        },
        "nubia": {
            "semantic_relation": 4.86363,
            "contradiction": 0.71612,
            "irrelevancy": 7.53846,
            "logical_agreement": 91.74541,
            "grammar_ref": 3.96214,
            "grammar_hyp": 3.62766,
            "nubia_score": 0.89813
        },
        "bleurt": 0.49581
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 86,
        "mean_pred_length": 17.2,
        "std_pred_length": 8.37615663654877,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.7441860465116279,
        "vocab_size-1": 64,
        "unique-1": 54,
        "entropy-1": 5.775101964004424,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 78,
        "unique-2": 76,
        "entropy-2": 6.256456330018399,
        "cond_entropy-2": 0.4227841679089034,
        "distinct-3": 1.0,
        "vocab_size-3": 76,
        "unique-3": 76,
        "entropy-3": 6.247927513443591,
        "cond_entropy-3": -0.003042390728362201,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 6.019966777316965,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.734521664779756,
        "distinct-2-nopunct": 0.9841269841269841,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.945533891753889,
        "cond_entropy-2-nopunct": 0.23902343145592614,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.08481616975165486,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.125,
            "3": 0.7402597402597403
        },
        "nist": 4.016095398973017,
        "rouge1": {
            "precision": 0.87206,
            "recall": 0.69859,
            "fmeasure": 0.7688
        },
        "rouge2": {
            "precision": 0.65429,
            "recall": 0.52473,
            "fmeasure": 0.57525
        },
        "rougeL": {
            "precision": 0.70635,
            "recall": 0.56839,
            "fmeasure": 0.62334
        },
        "rougeLsum": {
            "precision": 0.70635,
            "recall": 0.56839,
            "fmeasure": 0.62334
        },
        "bleu": 46.0786,
        "meteor": 0.3990989044240829,
        "bertscore": {
            "precision": 0.95447,
            "recall": 0.93478,
            "f1": 0.94446
        },
        "nubia": {
            "semantic_relation": 4.24423,
            "contradiction": 6.90652,
            "irrelevancy": 15.39636,
            "logical_agreement": 77.69712,
            "grammar_ref": 4.65184,
            "grammar_hyp": 5.008,
            "nubia_score": 0.71824
        },
        "bleurt": 0.35196
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 14.8,
        "std_pred_length": 5.912698199637793,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.7027027027027027,
        "vocab_size-1": 52,
        "unique-1": 43,
        "entropy-1": 5.393500116877551,
        "distinct-2": 0.9420289855072463,
        "vocab_size-2": 65,
        "unique-2": 61,
        "entropy-2": 5.992582427792657,
        "cond_entropy-2": 0.4547778418349549,
        "distinct-3": 0.96875,
        "vocab_size-3": 62,
        "unique-3": 60,
        "entropy-3": 5.9375,
        "cond_entropy-3": -0.04602445677816912,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 4.534313619501853,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.363608500731241,
        "distinct-2-nopunct": 0.9491525423728814,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.780948134107599,
        "cond_entropy-2-nopunct": 0.4712711163652409,
        "distinct-3-nopunct": 0.9814814814814815,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.717850465126429,
        "cond_entropy-3-nopunct": -0.05368147312429848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.125,
            "3": 0.8035714285714286
        },
        "nist": 4.891564759499665,
        "rouge1": {
            "precision": 0.85083,
            "recall": 0.81378,
            "fmeasure": 0.82927
        },
        "rouge2": {
            "precision": 0.68242,
            "recall": 0.65826,
            "fmeasure": 0.6681
        },
        "rougeL": {
            "precision": 0.7825,
            "recall": 0.73401,
            "fmeasure": 0.75498
        },
        "rougeLsum": {
            "precision": 0.7825,
            "recall": 0.73401,
            "fmeasure": 0.75498
        },
        "bleu": 48.6489,
        "meteor": 0.41386934422582494,
        "bertscore": {
            "precision": 0.95544,
            "recall": 0.93963,
            "f1": 0.94659
        },
        "nubia": {
            "semantic_relation": 4.41253,
            "contradiction": 7.30742,
            "irrelevancy": 17.09078,
            "logical_agreement": 75.6018,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.27495,
            "nubia_score": 0.83211
        },
        "bleurt": 0.37501
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.69,
        "total_length": 208,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.762159772503841,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.5913461538461539,
        "vocab_size-1": 123,
        "unique-1": 89,
        "entropy-1": 6.418711878324289,
        "distinct-2": 0.841025641025641,
        "vocab_size-2": 164,
        "unique-2": 136,
        "entropy-2": 7.277767941921481,
        "cond_entropy-2": 0.6978086050422002,
        "distinct-3": 0.9065934065934066,
        "vocab_size-3": 165,
        "unique-3": 148,
        "entropy-3": 7.320981453385525,
        "cond_entropy-3": 0.05576466989134022,
        "total_length-nopunct": 190,
        "mean_pred_length-nopunct": 14.615384615384615,
        "std_pred_length-nopunct": 3.498097538739099,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6263157894736842,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.44094153282538,
        "distinct-2-nopunct": 0.8305084745762712,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 7.115827795809047,
        "cond_entropy-2-nopunct": 0.7352019860433957,
        "distinct-3-nopunct": 0.9024390243902439,
        "vocab_size-3-nopunct": 148,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.162430053398589,
        "cond_entropy-3-nopunct": 0.05619439664783262,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.5490196078431373,
            "3": 0.7723577235772358
        },
        "nist": 5.488154513455948,
        "rouge1": {
            "precision": 0.73099,
            "recall": 0.73581,
            "fmeasure": 0.71825
        },
        "rouge2": {
            "precision": 0.49768,
            "recall": 0.52988,
            "fmeasure": 0.50415
        },
        "rougeL": {
            "precision": 0.59655,
            "recall": 0.61231,
            "fmeasure": 0.59233
        },
        "rougeLsum": {
            "precision": 0.59655,
            "recall": 0.61231,
            "fmeasure": 0.59233
        },
        "bleu": 44.71871,
        "meteor": 0.3926969795569968,
        "bertscore": {
            "precision": 0.90578,
            "recall": 0.91103,
            "f1": 0.90672
        },
        "nubia": {
            "semantic_relation": 4.30646,
            "contradiction": 5.67761,
            "irrelevancy": 51.85754,
            "logical_agreement": 42.46486,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.72341,
            "nubia_score": 0.75673
        },
        "bleurt": 0.10209
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.33373,
            "irrelevancy": 0.59046,
            "logical_agreement": 99.07581,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.68645,
            "nubia_score": 1.0
        },
        "bleurt": 1.00634
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.6451714496047405,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.79167,
            "fmeasure": 0.7451
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "bleu": 55.83948,
        "meteor": 0.4336185492206869,
        "bertscore": {
            "precision": 0.94907,
            "recall": 0.93812,
            "f1": 0.94353
        },
        "nubia": {
            "semantic_relation": 4.99771,
            "contradiction": 0.25029,
            "irrelevancy": 0.44471,
            "logical_agreement": 99.30501,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.0976,
            "nubia_score": 0.99587
        },
        "bleurt": 0.67063
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 17,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 33,
        "unique-1": 26,
        "entropy-1": 4.927798970294786,
        "distinct-2": 0.9743589743589743,
        "vocab_size-2": 38,
        "unique-2": 37,
        "entropy-2": 5.234120167580196,
        "cond_entropy-2": 0.2201331935748592,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.059921661864380305,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8378378378378378,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.8647266763812915,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838573,
        "cond_entropy-2-nopunct": 0.19432969627325647,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.06875040183120604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.8571428571428571,
            "3": 0.7272727272727273
        },
        "nist": 4.683329068599412,
        "rouge1": {
            "precision": 0.78024,
            "recall": 0.71561,
            "fmeasure": 0.74044
        },
        "rouge2": {
            "precision": 0.52747,
            "recall": 0.46884,
            "fmeasure": 0.49186
        },
        "rougeL": {
            "precision": 0.64562,
            "recall": 0.57854,
            "fmeasure": 0.60552
        },
        "rougeLsum": {
            "precision": 0.64562,
            "recall": 0.57854,
            "fmeasure": 0.60552
        },
        "bleu": 51.1607,
        "meteor": 0.3913850901642365,
        "bertscore": {
            "precision": 0.93729,
            "recall": 0.93083,
            "f1": 0.93389
        },
        "nubia": {
            "semantic_relation": 4.40279,
            "contradiction": 0.18261,
            "irrelevancy": 32.63241,
            "logical_agreement": 67.18498,
            "grammar_ref": 3.54742,
            "grammar_hyp": 3.3885,
            "nubia_score": 0.8921
        },
        "bleurt": 0.36689
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.68,
        "total_length": 129,
        "mean_pred_length": 16.125,
        "std_pred_length": 5.206666399914632,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5813953488372093,
        "vocab_size-1": 75,
        "unique-1": 58,
        "entropy-1": 5.750936345460729,
        "distinct-2": 0.8760330578512396,
        "vocab_size-2": 106,
        "unique-2": 94,
        "entropy-2": 6.648161687669944,
        "cond_entropy-2": 0.7822032536116837,
        "distinct-3": 0.9380530973451328,
        "vocab_size-3": 106,
        "unique-3": 99,
        "entropy-3": 6.696285157105471,
        "cond_entropy-3": 0.0495890658677037,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 12.875,
        "std_pred_length-nopunct": 3.3330729064933458,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6699029126213593,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.698649983864252,
        "distinct-2-nopunct": 0.8842105263157894,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.309277845150279,
        "cond_entropy-2-nopunct": 0.6727626438813175,
        "distinct-3-nopunct": 0.9310344827586207,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 75,
        "entropy-3-nopunct": 6.305012461365965,
        "cond_entropy-3-nopunct": 0.019695789841498373,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2926829268292683,
            "2": 0.47619047619047616,
            "3": 0.8125
        },
        "nist": 4.060112655814927,
        "rouge1": {
            "precision": 0.62723,
            "recall": 0.69661,
            "fmeasure": 0.64985
        },
        "rouge2": {
            "precision": 0.44507,
            "recall": 0.51743,
            "fmeasure": 0.46658
        },
        "rougeL": {
            "precision": 0.57098,
            "recall": 0.65987,
            "fmeasure": 0.60231
        },
        "rougeLsum": {
            "precision": 0.57098,
            "recall": 0.65987,
            "fmeasure": 0.60231
        },
        "bleu": 35.80503,
        "meteor": 0.4004102508898472,
        "bertscore": {
            "precision": 0.89514,
            "recall": 0.91903,
            "f1": 0.90314
        },
        "nubia": {
            "semantic_relation": 3.4438,
            "contradiction": 26.50707,
            "irrelevancy": 42.11352,
            "logical_agreement": 31.3794,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.61717,
            "nubia_score": 0.52678
        },
        "bleurt": 0.09589
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 82,
        "mean_pred_length": 20.5,
        "std_pred_length": 3.840572873934304,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.7560975609756098,
        "vocab_size-1": 62,
        "unique-1": 53,
        "entropy-1": 5.698820145703409,
        "distinct-2": 0.9871794871794872,
        "vocab_size-2": 77,
        "unique-2": 76,
        "entropy-2": 6.259761193221231,
        "cond_entropy-2": 0.5337620723062165,
        "distinct-3": 1.0,
        "vocab_size-3": 74,
        "unique-3": 74,
        "entropy-3": 6.2094533656289554,
        "cond_entropy-3": -0.04892182620627175,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 18.75,
        "std_pred_length-nopunct": 3.766629793329841,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7733333333333333,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.598670358111354,
        "distinct-2-nopunct": 0.9859154929577465,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.12157810542017,
        "cond_entropy-2-nopunct": 0.5584090618093658,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.05380718277825282,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.9,
            "3": 0.8333333333333334
        },
        "nist": 5.628932603935881,
        "rouge1": {
            "precision": 0.80066,
            "recall": 0.81128,
            "fmeasure": 0.80057
        },
        "rouge2": {
            "precision": 0.53782,
            "recall": 0.55627,
            "fmeasure": 0.54441
        },
        "rougeL": {
            "precision": 0.67438,
            "recall": 0.68617,
            "fmeasure": 0.67596
        },
        "rougeLsum": {
            "precision": 0.67438,
            "recall": 0.68617,
            "fmeasure": 0.67596
        },
        "bleu": 53.68008,
        "meteor": 0.4501523366064072,
        "bertscore": {
            "precision": 0.93999,
            "recall": 0.94526,
            "f1": 0.94169
        },
        "nubia": {
            "semantic_relation": 4.25051,
            "contradiction": 1.22804,
            "irrelevancy": 47.83607,
            "logical_agreement": 50.93588,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.59055,
            "nubia_score": 0.67875
        },
        "bleurt": 0.30569
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "nist": 2.55922317558127,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.81818,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.46154,
            "recall": 0.6,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.63636,
            "fmeasure": 0.56
        },
        "bleu": 34.46073,
        "meteor": 0.3946343248134507,
        "bertscore": {
            "precision": 0.86572,
            "recall": 0.90337,
            "f1": 0.88414
        },
        "nubia": {
            "semantic_relation": 4.24922,
            "contradiction": 0.08815,
            "irrelevancy": 99.71957,
            "logical_agreement": 0.19227,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.57605,
            "nubia_score": 0.87191
        },
        "bleurt": -0.01097
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.77,
        "total_length": 154,
        "mean_pred_length": 15.4,
        "std_pred_length": 4.294182110716778,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6948051948051948,
        "vocab_size-1": 107,
        "unique-1": 89,
        "entropy-1": 6.394308495663954,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 140,
        "unique-2": 136,
        "entropy-2": 7.1143694458867754,
        "cond_entropy-2": 0.5715227067270368,
        "distinct-3": 0.9776119402985075,
        "vocab_size-3": 131,
        "unique-3": 128,
        "entropy-3": 7.021313071054795,
        "cond_entropy-3": -0.0889104378502114,
        "total_length-nopunct": 137,
        "mean_pred_length-nopunct": 13.7,
        "std_pred_length-nopunct": 4.124318125460256,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7518248175182481,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.438743623708979,
        "distinct-2-nopunct": 0.968503937007874,
        "vocab_size-2-nopunct": 123,
        "unique-2-nopunct": 119,
        "entropy-2-nopunct": 6.925692560787896,
        "cond_entropy-2-nopunct": 0.5185073787465925,
        "distinct-3-nopunct": 0.9743589743589743,
        "vocab_size-3-nopunct": 114,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.819082668301332,
        "cond_entropy-3-nopunct": -0.10977295864175284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2391304347826087,
            "2": 0.6296296296296297,
            "3": 0.7789473684210526
        },
        "nist": 5.56929875728852,
        "rouge1": {
            "precision": 0.75363,
            "recall": 0.74752,
            "fmeasure": 0.73092
        },
        "rouge2": {
            "precision": 0.51426,
            "recall": 0.4922,
            "fmeasure": 0.49563
        },
        "rougeL": {
            "precision": 0.61019,
            "recall": 0.60089,
            "fmeasure": 0.59267
        },
        "rougeLsum": {
            "precision": 0.61019,
            "recall": 0.60089,
            "fmeasure": 0.59267
        },
        "bleu": 50.22462,
        "meteor": 0.3975917783495336,
        "bertscore": {
            "precision": 0.92199,
            "recall": 0.92234,
            "f1": 0.9214
        },
        "nubia": {
            "semantic_relation": 4.30739,
            "contradiction": 6.57324,
            "irrelevancy": 23.86981,
            "logical_agreement": 69.55695,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.15983,
            "nubia_score": 0.73789
        },
        "bleurt": 0.32599
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 20,
        "distinct-1": 0.7678571428571429,
        "vocab_size-1": 43,
        "unique-1": 34,
        "entropy-1": 5.271640636343323,
        "distinct-2": 0.9433962264150944,
        "vocab_size-2": 50,
        "unique-2": 48,
        "entropy-2": 5.600469746975206,
        "cond_entropy-2": 0.32141671171005765,
        "distinct-3": 0.98,
        "vocab_size-3": 49,
        "unique-3": 48,
        "entropy-3": 5.603856189774728,
        "cond_entropy-3": 0.01103348525479485,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7735849056603774,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.199618567770743,
        "distinct-2-nopunct": 0.94,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.508758439731459,
        "cond_entropy-2-nopunct": 0.34083798516825603,
        "distinct-3-nopunct": 0.9787234042553191,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.512035660188278,
        "cond_entropy-3-nopunct": 0.011900481097880139,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.125,
            "3": 0.9166666666666666
        },
        "nist": 4.856065099928478,
        "rouge1": {
            "precision": 0.73443,
            "recall": 0.75812,
            "fmeasure": 0.7424
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.44005,
            "fmeasure": 0.4364
        },
        "rougeL": {
            "precision": 0.54524,
            "recall": 0.5644,
            "fmeasure": 0.5526
        },
        "rougeLsum": {
            "precision": 0.54524,
            "recall": 0.5644,
            "fmeasure": 0.5526
        },
        "bleu": 37.56793,
        "meteor": 0.38217681812268295,
        "bertscore": {
            "precision": 0.91469,
            "recall": 0.9168,
            "f1": 0.90949
        },
        "nubia": {
            "semantic_relation": 4.04654,
            "contradiction": 1.20602,
            "irrelevancy": 15.5675,
            "logical_agreement": 83.22648,
            "grammar_ref": 4.10939,
            "grammar_hyp": 3.99847,
            "nubia_score": 0.72044
        },
        "bleurt": 0.13988
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8529411764705882,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.7711426205984715,
        "distinct-2": 0.96875,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.9375,
        "cond_entropy-2": 0.12362739319226894,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.026442737724814782,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.556088322639177,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.14708752563454355,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.03103131238874394,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "nist": 3.3133406752777246,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.81766,
            "fmeasure": 0.65911
        },
        "rouge2": {
            "precision": 0.40826,
            "recall": 0.62131,
            "fmeasure": 0.49037
        },
        "rougeL": {
            "precision": 0.52593,
            "recall": 0.77188,
            "fmeasure": 0.62302
        },
        "rougeLsum": {
            "precision": 0.52593,
            "recall": 0.77188,
            "fmeasure": 0.62302
        },
        "bleu": 34.74448,
        "meteor": 0.4263042556433313,
        "bertscore": {
            "precision": 0.87704,
            "recall": 0.94461,
            "f1": 0.90246
        },
        "nubia": {
            "semantic_relation": 4.39518,
            "contradiction": 0.36295,
            "irrelevancy": 33.32409,
            "logical_agreement": 66.31296,
            "grammar_ref": 4.76014,
            "grammar_hyp": 3.90225,
            "nubia_score": 0.85027
        },
        "bleurt": 0.28039
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 3.7712361663282534,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.8275862068965517,
        "vocab_size-1": 48,
        "unique-1": 43,
        "entropy-1": 5.431172589917856,
        "distinct-2": 0.9818181818181818,
        "vocab_size-2": 54,
        "unique-2": 53,
        "entropy-2": 5.744996077161019,
        "cond_entropy-2": 0.300740309345514,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.04245845692202902,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8846153846153846,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.416691881561028,
        "distinct-2-nopunct": 0.9795918367346939,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.5738935175845965,
        "cond_entropy-2-nopunct": 0.17457395254888125,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.047669627188630194,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.6190476190476191
        },
        "nist": 3.147472918828366,
        "rouge1": {
            "precision": 0.84473,
            "recall": 0.61698,
            "fmeasure": 0.71259
        },
        "rouge2": {
            "precision": 0.54793,
            "recall": 0.39343,
            "fmeasure": 0.45766
        },
        "rougeL": {
            "precision": 0.7442,
            "recall": 0.54286,
            "fmeasure": 0.62733
        },
        "rougeLsum": {
            "precision": 0.7442,
            "recall": 0.54286,
            "fmeasure": 0.62733
        },
        "bleu": 32.68528,
        "meteor": 0.31925619528527366,
        "bertscore": {
            "precision": 0.93733,
            "recall": 0.87575,
            "f1": 0.90531
        },
        "nubia": {
            "semantic_relation": 4.05436,
            "contradiction": 0.88342,
            "irrelevancy": 31.29884,
            "logical_agreement": 67.81774,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.68507,
            "nubia_score": 0.73145
        },
        "bleurt": 0.16719
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 18.5,
        "std_pred_length": 3.5,
        "median_pred_length": 17.5,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 58,
        "unique-1": 50,
        "entropy-1": 5.663986771350571,
        "distinct-2": 1.0,
        "vocab_size-2": 70,
        "unique-2": 70,
        "entropy-2": 6.129283016944973,
        "cond_entropy-2": 0.3821800509817353,
        "distinct-3": 1.0,
        "vocab_size-3": 66,
        "unique-3": 66,
        "entropy-3": 6.044394119358462,
        "cond_entropy-3": -0.08488889758651334,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 3.112474899497183,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.6025237254929845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 59,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.882643049361836,
        "cond_entropy-2-nopunct": 0.3055265237337352,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.7813597135246555,
        "cond_entropy-3-nopunct": -0.10128333583718159,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.6727272727272727
        },
        "nist": 4.165079813494481,
        "rouge1": {
            "precision": 0.66812,
            "recall": 0.59242,
            "fmeasure": 0.62439
        },
        "rouge2": {
            "precision": 0.36346,
            "recall": 0.32743,
            "fmeasure": 0.34223
        },
        "rougeL": {
            "precision": 0.57063,
            "recall": 0.50362,
            "fmeasure": 0.53205
        },
        "rougeLsum": {
            "precision": 0.57063,
            "recall": 0.50362,
            "fmeasure": 0.53205
        },
        "bleu": 21.39953,
        "meteor": 0.3055012702520582,
        "bertscore": {
            "precision": 0.88286,
            "recall": 0.87441,
            "f1": 0.87627
        },
        "nubia": {
            "semantic_relation": 3.73442,
            "contradiction": 22.62333,
            "irrelevancy": 62.27013,
            "logical_agreement": 15.10654,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.04979,
            "nubia_score": 0.61075
        },
        "bleurt": -0.11863
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.01117167855772,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.94444,
            "fmeasure": 0.94444
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.66362,
            "contradiction": 2.49017,
            "irrelevancy": 1.24853,
            "logical_agreement": 96.2613,
            "grammar_ref": 6.06085,
            "grammar_hyp": 5.70692,
            "nubia_score": 0.90186
        },
        "bleurt": 0.77386
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.9303644234652384,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.58333,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.27273,
            "fmeasure": 0.27273
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "bleu": 15.7278,
        "meteor": 0.3294273531188452,
        "bertscore": {
            "precision": 0.88259,
            "recall": 0.85608,
            "f1": 0.86913
        },
        "nubia": {
            "semantic_relation": 4.22334,
            "contradiction": 0.30959,
            "irrelevancy": 87.2795,
            "logical_agreement": 12.4109,
            "grammar_ref": 5.68739,
            "grammar_hyp": 4.43337,
            "nubia_score": 0.84632
        },
        "bleurt": 0.51324
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 22.0,
        "std_pred_length": 1.4142135623730951,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 24,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 48,
        "unique-1": 37,
        "entropy-1": 5.404020445017695,
        "distinct-2": 0.9682539682539683,
        "vocab_size-2": 61,
        "unique-2": 59,
        "entropy-2": 5.913787860007855,
        "cond_entropy-2": 0.46478699468633555,
        "distinct-3": 1.0,
        "vocab_size-3": 60,
        "unique-3": 60,
        "entropy-3": 5.906890595608517,
        "cond_entropy-3": -0.003722661224731365,
        "total_length-nopunct": 61,
        "mean_pred_length-nopunct": 20.333333333333332,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7540983606557377,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.348609878475557,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.789015477886191,
        "cond_entropy-2-nopunct": 0.4532742610875639,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.7813597135246555,
        "cond_entropy-3-nopunct": -0.0038940088756396055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.7857142857142857
        },
        "nist": 4.36879361579719,
        "rouge1": {
            "precision": 0.65943,
            "recall": 0.74672,
            "fmeasure": 0.69255
        },
        "rouge2": {
            "precision": 0.4821,
            "recall": 0.56635,
            "fmeasure": 0.51742
        },
        "rougeL": {
            "precision": 0.5951,
            "recall": 0.70439,
            "fmeasure": 0.64074
        },
        "rougeLsum": {
            "precision": 0.5951,
            "recall": 0.70439,
            "fmeasure": 0.64074
        },
        "bleu": 50.86818,
        "meteor": 0.40954472515043944,
        "bertscore": {
            "precision": 0.90907,
            "recall": 0.92002,
            "f1": 0.91291
        },
        "nubia": {
            "semantic_relation": 4.07403,
            "contradiction": 0.38442,
            "irrelevancy": 93.94921,
            "logical_agreement": 5.66637,
            "grammar_ref": 4.0888,
            "grammar_hyp": 3.66213,
            "nubia_score": 0.77958
        },
        "bleurt": 0.13301
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nist": 2.6800881679382393,
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.71818,
            "fmeasure": 0.70707
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.42963,
            "fmeasure": 0.41404
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.67879,
            "fmeasure": 0.65657
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.67879,
            "fmeasure": 0.65657
        },
        "bleu": 24.80842,
        "meteor": 0.3786498446582787,
        "bertscore": {
            "precision": 0.94992,
            "recall": 0.95727,
            "f1": 0.95249
        },
        "nubia": {
            "semantic_relation": 4.11304,
            "contradiction": 99.47807,
            "irrelevancy": 0.18782,
            "logical_agreement": 0.33411,
            "grammar_ref": 5.84412,
            "grammar_hyp": 6.68212,
            "nubia_score": 0.47517
        },
        "bleurt": 0.12558
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910023,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.21860008985574886,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.9321380397593733,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.2553308213320601,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6428571428571429
        },
        "nist": 2.789998880905167,
        "rouge1": {
            "precision": 0.7193,
            "recall": 0.63059,
            "fmeasure": 0.67195
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.33529,
            "fmeasure": 0.33383
        },
        "rougeL": {
            "precision": 0.61404,
            "recall": 0.58466,
            "fmeasure": 0.5982
        },
        "rougeLsum": {
            "precision": 0.61404,
            "recall": 0.58466,
            "fmeasure": 0.5982
        },
        "bleu": 19.15598,
        "meteor": 0.31540180313384764,
        "bertscore": {
            "precision": 0.89243,
            "recall": 0.87334,
            "f1": 0.87787
        },
        "nubia": {
            "semantic_relation": 4.23806,
            "contradiction": 0.44087,
            "irrelevancy": 1.9095,
            "logical_agreement": 97.64964,
            "grammar_ref": 4.70322,
            "grammar_hyp": 4.23487,
            "nubia_score": 0.78835
        },
        "bleurt": 0.12203
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.8,
        "msttr-100_nopunct": 0.84,
        "total_length": 137,
        "mean_pred_length": 17.125,
        "std_pred_length": 5.206666399914632,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.7445255474452555,
        "vocab_size-1": 102,
        "unique-1": 90,
        "entropy-1": 6.327230467219803,
        "distinct-2": 0.9844961240310077,
        "vocab_size-2": 127,
        "unique-2": 125,
        "entropy-2": 6.9802195034852526,
        "cond_entropy-2": 0.5484535980602023,
        "distinct-3": 1.0,
        "vocab_size-3": 121,
        "unique-3": 121,
        "entropy-3": 6.918863237274603,
        "cond_entropy-3": -0.05930616690899028,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.943429983321297,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8032786885245902,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.353372076105954,
        "distinct-2-nopunct": 0.9824561403508771,
        "vocab_size-2-nopunct": 112,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.797802294866507,
        "cond_entropy-2-nopunct": 0.48494707921367347,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.727920454563184,
        "cond_entropy-3-nopunct": -0.06723371054493885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1951219512195122,
            "2": 0.36,
            "3": 0.8840579710144928
        },
        "nist": 4.707355819615038,
        "rouge1": {
            "precision": 0.65229,
            "recall": 0.71877,
            "fmeasure": 0.67076
        },
        "rouge2": {
            "precision": 0.37321,
            "recall": 0.39638,
            "fmeasure": 0.37893
        },
        "rougeL": {
            "precision": 0.53486,
            "recall": 0.56412,
            "fmeasure": 0.54287
        },
        "rougeLsum": {
            "precision": 0.53486,
            "recall": 0.56412,
            "fmeasure": 0.54287
        },
        "bleu": 30.37983,
        "meteor": 0.3524796036890074,
        "bertscore": {
            "precision": 0.88943,
            "recall": 0.91887,
            "f1": 0.89991
        },
        "nubia": {
            "semantic_relation": 3.46449,
            "contradiction": 3.54037,
            "irrelevancy": 62.20632,
            "logical_agreement": 34.2533,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.46424,
            "nubia_score": 0.52243
        },
        "bleurt": 0.01031
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 5.5,
        "median_pred_length": 22.5,
        "min_pred_length": 17,
        "max_pred_length": 28,
        "distinct-1": 0.7111111111111111,
        "vocab_size-1": 32,
        "unique-1": 24,
        "entropy-1": 4.800310530134924,
        "distinct-2": 0.9534883720930233,
        "vocab_size-2": 41,
        "unique-2": 39,
        "entropy-2": 5.333241498888144,
        "cond_entropy-2": 0.5185841113669291,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": 0.028848225525741795,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5695322390610205,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.40033842357581106,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.026442737724814765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7857142857142857
        },
        "nist": 3.3028794427498998,
        "rouge1": {
            "precision": 0.77841,
            "recall": 0.76992,
            "fmeasure": 0.77341
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.5675,
            "fmeasure": 0.56645
        },
        "rougeL": {
            "precision": 0.64205,
            "recall": 0.6413,
            "fmeasure": 0.64104
        },
        "rougeLsum": {
            "precision": 0.64205,
            "recall": 0.6413,
            "fmeasure": 0.64104
        },
        "bleu": 35.64773,
        "meteor": 0.3818902289284431,
        "bertscore": {
            "precision": 0.92367,
            "recall": 0.92985,
            "f1": 0.92414
        },
        "nubia": {
            "semantic_relation": 3.72933,
            "contradiction": 50.08615,
            "irrelevancy": 1.74134,
            "logical_agreement": 48.17251,
            "grammar_ref": 3.82725,
            "grammar_hyp": 3.52728,
            "nubia_score": 0.68666
        },
        "bleurt": 0.35616
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 28,
        "unique-1": 21,
        "entropy-1": 4.668912825088411,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.43411536560173103,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.5,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.4068905956085186,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "nist": 5.015904633481679,
        "rouge1": {
            "precision": 0.92823,
            "recall": 0.90455,
            "fmeasure": 0.91608
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.74474,
            "fmeasure": 0.75541
        },
        "rougeL": {
            "precision": 0.79665,
            "recall": 0.77955,
            "fmeasure": 0.78788
        },
        "rougeLsum": {
            "precision": 0.79665,
            "recall": 0.77955,
            "fmeasure": 0.78788
        },
        "bleu": 70.60818,
        "meteor": 0.4989708003265706,
        "bertscore": {
            "precision": 0.96952,
            "recall": 0.97019,
            "f1": 0.96986
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.52155,
            "irrelevancy": 2.11834,
            "logical_agreement": 97.36011,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.22523,
            "nubia_score": 0.98646
        },
        "bleurt": 0.65399
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 1.5,
        "median_pred_length": 13.5,
        "min_pred_length": 12,
        "max_pred_length": 15,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.04896868761125603,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.05628729973432274,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.375,
            "3": 0.8
        },
        "nist": 4.573214330220901,
        "rouge1": {
            "precision": 0.86905,
            "recall": 0.74403,
            "fmeasure": 0.80079
        },
        "rouge2": {
            "precision": 0.72821,
            "recall": 0.61586,
            "fmeasure": 0.66645
        },
        "rougeL": {
            "precision": 0.77814,
            "recall": 0.66284,
            "fmeasure": 0.71504
        },
        "rougeLsum": {
            "precision": 0.77814,
            "recall": 0.66284,
            "fmeasure": 0.71504
        },
        "bleu": 58.35087,
        "meteor": 0.43918591243855404,
        "bertscore": {
            "precision": 0.94147,
            "recall": 0.91567,
            "f1": 0.92613
        },
        "nubia": {
            "semantic_relation": 4.43214,
            "contradiction": 0.31623,
            "irrelevancy": 10.93261,
            "logical_agreement": 88.75116,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.41394,
            "nubia_score": 0.85245
        },
        "bleurt": 0.42491
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 7.5,
        "median_pred_length": 18.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.8647266763812915,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.22711215137782992,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9032258064516129,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.7362967135428935,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.13671183998771325,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8709677419354839
        },
        "nist": 5.357795498833953,
        "rouge1": {
            "precision": 0.95,
            "recall": 0.74435,
            "fmeasure": 0.83036
        },
        "rouge2": {
            "precision": 0.67222,
            "recall": 0.53558,
            "fmeasure": 0.59296
        },
        "rougeL": {
            "precision": 0.85,
            "recall": 0.6723,
            "fmeasure": 0.74712
        },
        "rougeLsum": {
            "precision": 0.85,
            "recall": 0.6723,
            "fmeasure": 0.74712
        },
        "bleu": 78.72664,
        "meteor": 0.43980344095031104,
        "bertscore": {
            "precision": 0.95472,
            "recall": 0.9366,
            "f1": 0.94241
        },
        "nubia": {
            "semantic_relation": 3.52399,
            "contradiction": 44.57211,
            "irrelevancy": 1.52676,
            "logical_agreement": 53.90113,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.85359,
            "nubia_score": 0.51507
        },
        "bleurt": 0.19745
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 89,
        "mean_pred_length": 17.8,
        "std_pred_length": 6.305553108173778,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.6966292134831461,
        "vocab_size-1": 62,
        "unique-1": 50,
        "entropy-1": 5.639737610810135,
        "distinct-2": 0.9404761904761905,
        "vocab_size-2": 79,
        "unique-2": 74,
        "entropy-2": 6.273269803731141,
        "cond_entropy-2": 0.5450838432346388,
        "distinct-3": 0.9873417721518988,
        "vocab_size-3": 78,
        "unique-3": 77,
        "entropy-3": 6.278464292480902,
        "cond_entropy-3": 0.012729148183152586,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 16.4,
        "std_pred_length-nopunct": 5.607138307550474,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7317073170731707,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.616161912917218,
        "distinct-2-nopunct": 0.935064935064935,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.136916410824775,
        "cond_entropy-2-nopunct": 0.5559096986673528,
        "distinct-3-nopunct": 0.9861111111111112,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.14214722366454,
        "cond_entropy-3-nopunct": 0.00036068296963327013,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8428571428571429
        },
        "nist": 5.207928612882899,
        "rouge1": {
            "precision": 0.82966,
            "recall": 0.76719,
            "fmeasure": 0.79175
        },
        "rouge2": {
            "precision": 0.65212,
            "recall": 0.59566,
            "fmeasure": 0.6145
        },
        "rougeL": {
            "precision": 0.71836,
            "recall": 0.67756,
            "fmeasure": 0.69106
        },
        "rougeLsum": {
            "precision": 0.71836,
            "recall": 0.67756,
            "fmeasure": 0.69106
        },
        "bleu": 51.3379,
        "meteor": 0.41936701187516506,
        "bertscore": {
            "precision": 0.93479,
            "recall": 0.92792,
            "f1": 0.92958
        },
        "nubia": {
            "semantic_relation": 4.5985,
            "contradiction": 0.17673,
            "irrelevancy": 23.67916,
            "logical_agreement": 76.14412,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.38162,
            "nubia_score": 0.875
        },
        "bleurt": 0.41102
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "nist": 2.9898332363522426,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "bleu": 61.0195,
        "meteor": 0.5064321156600579,
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "bleurt": 0.83294
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 4.322904116447646,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7169811320754716,
        "vocab_size-1": 38,
        "unique-1": 28,
        "entropy-1": 5.0814173884030005,
        "distinct-2": 0.8775510204081632,
        "vocab_size-2": 43,
        "unique-2": 38,
        "entropy-2": 5.354406017540444,
        "cond_entropy-2": 0.16249908351786518,
        "distinct-3": 0.9333333333333333,
        "vocab_size-3": 42,
        "unique-3": 39,
        "entropy-3": 5.358519762996339,
        "cond_entropy-3": 0.02725186337365455,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 4.02336923485777,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7659574468085106,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.038319436645929,
        "distinct-2-nopunct": 0.8604651162790697,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.12963946395411,
        "cond_entropy-2-nopunct": 0.10248549613157173,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.131556065016094,
        "cond_entropy-3-nopunct": 0.03233970780536746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8775510204081632
        },
        "nist": 5.166228900079013,
        "rouge1": {
            "precision": 0.925,
            "recall": 0.88462,
            "fmeasure": 0.90217
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.8125,
            "fmeasure": 0.82143
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.86538,
            "fmeasure": 0.88043
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.86538,
            "fmeasure": 0.88043
        },
        "bleu": 79.52165,
        "meteor": 0.5479974600032286,
        "bertscore": {
            "precision": 0.97799,
            "recall": 0.96234,
            "f1": 0.96989
        },
        "nubia": {
            "semantic_relation": 4.71946,
            "contradiction": 2.87481,
            "irrelevancy": 1.15248,
            "logical_agreement": 95.97271,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.08325,
            "nubia_score": 0.89063
        },
        "bleurt": 0.80322
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.8444444444444444,
        "vocab_size-1": 38,
        "unique-1": 33,
        "entropy-1": 5.147191429566853,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.15653307650059683,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.10691520391651191,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8780487804878049,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.095237675297021,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.1733988641455933,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.5714285714285714,
            "3": 0.6818181818181818
        },
        "nist": 4.089753496903314,
        "rouge1": {
            "precision": 0.73939,
            "recall": 0.58388,
            "fmeasure": 0.63926
        },
        "rouge2": {
            "precision": 0.32222,
            "recall": 0.24935,
            "fmeasure": 0.27565
        },
        "rougeL": {
            "precision": 0.567,
            "recall": 0.45725,
            "fmeasure": 0.49662
        },
        "rougeLsum": {
            "precision": 0.567,
            "recall": 0.45725,
            "fmeasure": 0.49662
        },
        "bleu": 32.79949,
        "meteor": 0.30696614687750573,
        "bertscore": {
            "precision": 0.90966,
            "recall": 0.87576,
            "f1": 0.8907
        },
        "nubia": {
            "semantic_relation": 3.51159,
            "contradiction": 41.13634,
            "irrelevancy": 20.5536,
            "logical_agreement": 38.31006,
            "grammar_ref": 4.68806,
            "grammar_hyp": 5.11738,
            "nubia_score": 0.49715
        },
        "bleurt": 0.08261
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 1.8196280208181093,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.90909,
            "fmeasure": 0.6689
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.44762,
            "fmeasure": 0.30952
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.79545,
            "fmeasure": 0.58528
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.79545,
            "fmeasure": 0.58528
        },
        "bleu": 18.20705,
        "meteor": 0.37623273707123395,
        "bertscore": {
            "precision": 0.81291,
            "recall": 0.93177,
            "f1": 0.86829
        },
        "nubia": {
            "semantic_relation": 3.78478,
            "contradiction": 0.09138,
            "irrelevancy": 99.78031,
            "logical_agreement": 0.12831,
            "grammar_ref": 4.68733,
            "grammar_hyp": 4.8835,
            "nubia_score": 0.56632
        },
        "bleurt": -0.09978
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 21.0,
        "std_pred_length": 5.338539126015656,
        "median_pred_length": 23.5,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 64,
        "unique-1": 50,
        "entropy-1": 5.856370398866214,
        "distinct-2": 0.925,
        "vocab_size-2": 74,
        "unique-2": 68,
        "entropy-2": 6.171928094887358,
        "cond_entropy-2": 0.28291895343973206,
        "distinct-3": 0.9605263157894737,
        "vocab_size-3": 73,
        "unique-3": 70,
        "entropy-3": 6.168980145022538,
        "cond_entropy-3": 0.004946786977275827,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 18.25,
        "std_pred_length-nopunct": 4.815340071064556,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.821917808219178,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.795921990357236,
        "distinct-2-nopunct": 0.9420289855072463,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.992582427792657,
        "cond_entropy-2-nopunct": 0.20500261532081074,
        "distinct-3-nopunct": 0.9692307692307692,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.960829351489996,
        "cond_entropy-3-nopunct": -0.04000279759586847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.7222222222222222
        },
        "nist": 4.029059919376869,
        "rouge1": {
            "precision": 0.79816,
            "recall": 0.70661,
            "fmeasure": 0.74033
        },
        "rouge2": {
            "precision": 0.6163,
            "recall": 0.54655,
            "fmeasure": 0.57196
        },
        "rougeL": {
            "precision": 0.69282,
            "recall": 0.62114,
            "fmeasure": 0.64678
        },
        "rougeLsum": {
            "precision": 0.69282,
            "recall": 0.62114,
            "fmeasure": 0.64678
        },
        "bleu": 36.13008,
        "meteor": 0.3389013904161726,
        "bertscore": {
            "precision": 0.93128,
            "recall": 0.89942,
            "f1": 0.91472
        },
        "nubia": {
            "semantic_relation": 4.0197,
            "contradiction": 25.10137,
            "irrelevancy": 44.25561,
            "logical_agreement": 30.64302,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.22894,
            "nubia_score": 0.6819
        },
        "bleurt": 0.17974
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.70388,
        "msttr-100_nopunct": 0.72847,
        "total_length": 6724,
        "mean_pred_length": 13.448,
        "std_pred_length": 6.694422753307413,
        "median_pred_length": 12.0,
        "min_pred_length": 3,
        "max_pred_length": 30,
        "distinct-1": 0.1644854253420583,
        "vocab_size-1": 1106,
        "unique-1": 635,
        "entropy-1": 7.9469253780744395,
        "distinct-2": 0.5062660668380463,
        "vocab_size-2": 3151,
        "unique-2": 2260,
        "entropy-2": 10.854216256141845,
        "cond_entropy-2": 2.712832966142913,
        "distinct-3": 0.722921034241789,
        "vocab_size-3": 4138,
        "unique-3": 3464,
        "entropy-3": 11.65527166167585,
        "cond_entropy-3": 0.8304739073108568,
        "total_length-nopunct": 5963,
        "mean_pred_length-nopunct": 11.926,
        "std_pred_length-nopunct": 6.232537524957231,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.183464698977025,
        "vocab_size-1-nopunct": 1094,
        "unique-1-nopunct": 633,
        "entropy-1-nopunct": 8.1030738441409,
        "distinct-2-nopunct": 0.5202269815119898,
        "vocab_size-2-nopunct": 2842,
        "unique-2-nopunct": 2086,
        "entropy-2-nopunct": 10.693562863147665,
        "cond_entropy-2-nopunct": 2.722044602051639,
        "distinct-3-nopunct": 0.7334273624823695,
        "vocab_size-3-nopunct": 3640,
        "unique-3-nopunct": 3082,
        "entropy-3-nopunct": 11.470517005302124,
        "cond_entropy-3-nopunct": 0.8173746900532026,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5614585051971622
        },
        "nist": 6.103615547905705,
        "rouge1": {
            "precision": 0.58353,
            "recall": 0.5556,
            "fmeasure": 0.55619
        },
        "rouge2": {
            "precision": 0.35673,
            "recall": 0.33667,
            "fmeasure": 0.33785
        },
        "rougeL": {
            "precision": 0.51915,
            "recall": 0.49402,
            "fmeasure": 0.49478
        },
        "rougeLsum": {
            "precision": 0.51915,
            "recall": 0.49402,
            "fmeasure": 0.49478
        },
        "bleu": 31.26644,
        "meteor": 0.309427703691384,
        "bertscore": {
            "precision": 0.87228,
            "recall": 0.86482,
            "f1": 0.868
        },
        "nubia": {
            "semantic_relation": 3.62408,
            "contradiction": 6.61423,
            "irrelevancy": 23.25583,
            "logical_agreement": 70.12994,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.60242,
            "nubia_score": 0.63736
        },
        "bleurt": -0.08114
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 4.673328578219169,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.7123287671232876,
        "vocab_size-1": 52,
        "unique-1": 44,
        "entropy-1": 5.395084662564907,
        "distinct-2": 0.9117647058823529,
        "vocab_size-2": 62,
        "unique-2": 57,
        "entropy-2": 5.899890966218529,
        "cond_entropy-2": 0.3925130537586051,
        "distinct-3": 0.9682539682539683,
        "vocab_size-3": 61,
        "unique-3": 59,
        "entropy-3": 5.913787860007857,
        "cond_entropy-3": 0.028783550537886157,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 5.403702434442518,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7384615384615385,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.308423629081277,
        "distinct-2-nopunct": 0.9,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.694309137239126,
        "cond_entropy-2-nopunct": 0.4287141901534514,
        "distinct-3-nopunct": 0.9636363636363636,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 51,
        "entropy-3-nopunct": 5.708632440797383,
        "cond_entropy-3-nopunct": 0.015467072500931534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.8125,
            "3": 0.8095238095238095
        },
        "nist": 5.126962638861576,
        "rouge1": {
            "precision": 0.84373,
            "recall": 0.80069,
            "fmeasure": 0.79123
        },
        "rouge2": {
            "precision": 0.56778,
            "recall": 0.57988,
            "fmeasure": 0.55515
        },
        "rougeL": {
            "precision": 0.74124,
            "recall": 0.72848,
            "fmeasure": 0.71046
        },
        "rougeLsum": {
            "precision": 0.74124,
            "recall": 0.72848,
            "fmeasure": 0.71046
        },
        "bleu": 51.9752,
        "meteor": 0.43030282343161824,
        "bertscore": {
            "precision": 0.92822,
            "recall": 0.93082,
            "f1": 0.92661
        },
        "nubia": {
            "semantic_relation": 4.19739,
            "contradiction": 18.80596,
            "irrelevancy": 18.9389,
            "logical_agreement": 62.25514,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.31696,
            "nubia_score": 0.78853
        },
        "bleurt": 0.34313
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.74,
        "total_length": 239,
        "mean_pred_length": 15.933333333333334,
        "std_pred_length": 5.246797965320266,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.606694560669456,
        "vocab_size-1": 145,
        "unique-1": 112,
        "entropy-1": 6.648944307416031,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 208,
        "unique-2": 194,
        "entropy-2": 7.657757712216826,
        "cond_entropy-2": 0.8457592467636452,
        "distinct-3": 0.9856459330143541,
        "vocab_size-3": 206,
        "unique-3": 203,
        "entropy-3": 7.6786509981096085,
        "cond_entropy-3": -0.0006901081481880655,
        "total_length-nopunct": 212,
        "mean_pred_length-nopunct": 14.133333333333333,
        "std_pred_length-nopunct": 4.883532419149984,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.660377358490566,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 6.700059564345434,
        "distinct-2-nopunct": 0.934010152284264,
        "vocab_size-2-nopunct": 184,
        "unique-2-nopunct": 172,
        "entropy-2-nopunct": 7.486240207770231,
        "cond_entropy-2-nopunct": 0.8086065995327891,
        "distinct-3-nopunct": 0.989010989010989,
        "vocab_size-3-nopunct": 180,
        "unique-3-nopunct": 178,
        "entropy-3-nopunct": 7.485816618220692,
        "cond_entropy-3-nopunct": -0.00021933583919958761,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2553191489361702,
            "2": 0.4444444444444444,
            "3": 0.8193548387096774
        },
        "nist": 6.109000890489995,
        "rouge1": {
            "precision": 0.75266,
            "recall": 0.77984,
            "fmeasure": 0.75714
        },
        "rouge2": {
            "precision": 0.57988,
            "recall": 0.58739,
            "fmeasure": 0.57413
        },
        "rougeL": {
            "precision": 0.67406,
            "recall": 0.70492,
            "fmeasure": 0.6811
        },
        "rougeLsum": {
            "precision": 0.67406,
            "recall": 0.70492,
            "fmeasure": 0.6811
        },
        "bleu": 51.26725,
        "meteor": 0.4429906354691219,
        "bertscore": {
            "precision": 0.94789,
            "recall": 0.94729,
            "f1": 0.94535
        },
        "nubia": {
            "semantic_relation": 4.29587,
            "contradiction": 15.7619,
            "irrelevancy": 32.89564,
            "logical_agreement": 51.34246,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.49332,
            "nubia_score": 0.77049
        },
        "bleurt": 0.22701
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 75,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.830951894845301,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6533333333333333,
        "vocab_size-1": 49,
        "unique-1": 35,
        "entropy-1": 5.388558023713832,
        "distinct-2": 0.8,
        "vocab_size-2": 56,
        "unique-2": 46,
        "entropy-2": 5.679143374026015,
        "cond_entropy-2": 0.2363182550823275,
        "distinct-3": 0.8923076923076924,
        "vocab_size-3": 58,
        "unique-3": 52,
        "entropy-3": 5.795369543764403,
        "cond_entropy-3": 0.15085229611677198,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 13.8,
        "std_pred_length-nopunct": 5.67097875150313,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6811594202898551,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.340125181290429,
        "distinct-2-nopunct": 0.78125,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.507659765557392,
        "cond_entropy-2-nopunct": 0.1963157776644395,
        "distinct-3-nopunct": 0.8813559322033898,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.632560210342118,
        "cond_entropy-3-nopunct": 0.14967504092393377,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.847457627118644
        },
        "nist": 4.9624202734213005,
        "rouge1": {
            "precision": 0.86125,
            "recall": 0.88323,
            "fmeasure": 0.87029
        },
        "rouge2": {
            "precision": 0.75077,
            "recall": 0.76976,
            "fmeasure": 0.75899
        },
        "rougeL": {
            "precision": 0.82051,
            "recall": 0.84197,
            "fmeasure": 0.8299
        },
        "rougeLsum": {
            "precision": 0.82051,
            "recall": 0.84197,
            "fmeasure": 0.8299
        },
        "bleu": 60.50453,
        "meteor": 0.4683088278971453,
        "bertscore": {
            "precision": 0.97662,
            "recall": 0.97171,
            "f1": 0.97368
        },
        "nubia": {
            "semantic_relation": 4.58934,
            "contradiction": 0.60136,
            "irrelevancy": 0.87367,
            "logical_agreement": 98.52497,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.60132,
            "nubia_score": 0.87792
        },
        "bleurt": 0.75634
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "nist": 1.871569948038403,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.6,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "bleu": 35.49481,
        "meteor": 0.4964095982072904,
        "bertscore": {
            "precision": 0.91515,
            "recall": 0.93955,
            "f1": 0.92719
        },
        "nubia": {
            "semantic_relation": 3.79177,
            "contradiction": 4.95623,
            "irrelevancy": 54.57702,
            "logical_agreement": 40.46676,
            "grammar_ref": 7.84225,
            "grammar_hyp": 6.86058,
            "nubia_score": 0.64873
        },
        "bleurt": -0.03416
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.048968687611256,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.05923165719793805,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2,
            "3": 0.85
        },
        "nist": 4.17026917185515,
        "rouge1": {
            "precision": 0.89044,
            "recall": 0.79401,
            "fmeasure": 0.83615
        },
        "rouge2": {
            "precision": 0.69167,
            "recall": 0.62222,
            "fmeasure": 0.6522
        },
        "rougeL": {
            "precision": 0.74942,
            "recall": 0.6831,
            "fmeasure": 0.71202
        },
        "rougeLsum": {
            "precision": 0.74942,
            "recall": 0.6831,
            "fmeasure": 0.71202
        },
        "bleu": 46.69339,
        "meteor": 0.4936977289435061,
        "bertscore": {
            "precision": 0.96768,
            "recall": 0.959,
            "f1": 0.96319
        },
        "nubia": {
            "semantic_relation": 4.6455,
            "contradiction": 0.28465,
            "irrelevancy": 32.23595,
            "logical_agreement": 67.4794,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.30101,
            "nubia_score": 0.90155
        },
        "bleurt": 0.43811
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.0286497677077553,
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "bleu": 70.16879,
        "meteor": 0.5613051214200641,
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        },
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        },
        "bleurt": 0.76221
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 26,
        "unique-1": 24,
        "entropy-1": 4.664497779200462,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": -0.02999212699343526,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.96,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5638561897747225,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.03333771197858132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.3333333333333333,
            "3": 0.7894736842105263
        },
        "nist": 4.461235224063537,
        "rouge1": {
            "precision": 0.71104,
            "recall": 0.73958,
            "fmeasure": 0.72263
        },
        "rouge2": {
            "precision": 0.59872,
            "recall": 0.62879,
            "fmeasure": 0.61196
        },
        "rougeL": {
            "precision": 0.69913,
            "recall": 0.75,
            "fmeasure": 0.72177
        },
        "rougeLsum": {
            "precision": 0.69913,
            "recall": 0.75,
            "fmeasure": 0.72177
        },
        "bleu": 61.80365,
        "meteor": 0.41070033517167764,
        "bertscore": {
            "precision": 0.90808,
            "recall": 0.93174,
            "f1": 0.91863
        },
        "nubia": {
            "semantic_relation": 4.44209,
            "contradiction": 0.74537,
            "irrelevancy": 50.36146,
            "logical_agreement": 48.89317,
            "grammar_ref": 5.62679,
            "grammar_hyp": 5.547,
            "nubia_score": 0.76457
        },
        "bleurt": 0.38418
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.884183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.3867829713016689,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.452819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.4905497624194164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.875
        },
        "nist": 2.681857998677189,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "rouge2": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.88736,
            "fmeasure": 0.78602
        },
        "bleu": 45.80519,
        "meteor": 0.4761015269167852,
        "bertscore": {
            "precision": 0.9279,
            "recall": 0.97925,
            "f1": 0.95289
        },
        "nubia": {
            "semantic_relation": 2.77373,
            "contradiction": 76.40398,
            "irrelevancy": 22.87083,
            "logical_agreement": 0.72519,
            "grammar_ref": 3.57757,
            "grammar_hyp": 2.84842,
            "nubia_score": 0.46355
        },
        "bleurt": 0.43685
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.053508854797679,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.4931597815168772,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.053508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.4931597815168772,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.16666666666666666,
            "3": 0.38461538461538464
        },
        "nist": 0.6960964537206139,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.39961,
            "fmeasure": 0.51062
        },
        "rouge2": {
            "precision": 0.24638,
            "recall": 0.13056,
            "fmeasure": 0.17056
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.24072,
            "fmeasure": 0.31209
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.24072,
            "fmeasure": 0.31209
        },
        "bleu": 7.82455,
        "meteor": 0.17453018636360018,
        "bertscore": {
            "precision": 0.87065,
            "recall": 0.82517,
            "f1": 0.8473
        },
        "nubia": {
            "semantic_relation": 3.41958,
            "contradiction": 0.9399,
            "irrelevancy": 97.10717,
            "logical_agreement": 1.95293,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.52926,
            "nubia_score": 0.37147
        },
        "bleurt": -0.68922
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.548394345536403,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.17135584433198398,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.532665279941249,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.12896868761125613,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.6086956521739131
        },
        "nist": 3.3146079693497037,
        "rouge1": {
            "precision": 0.70604,
            "recall": 0.65041,
            "fmeasure": 0.67419
        },
        "rouge2": {
            "precision": 0.27885,
            "recall": 0.32222,
            "fmeasure": 0.29143
        },
        "rougeL": {
            "precision": 0.55769,
            "recall": 0.599,
            "fmeasure": 0.56518
        },
        "rougeLsum": {
            "precision": 0.55769,
            "recall": 0.599,
            "fmeasure": 0.56518
        },
        "bleu": 15.53981,
        "meteor": 0.35745809948650337,
        "bertscore": {
            "precision": 0.9086,
            "recall": 0.92999,
            "f1": 0.91826
        },
        "nubia": {
            "semantic_relation": 4.09253,
            "contradiction": 0.21849,
            "irrelevancy": 70.22588,
            "logical_agreement": 29.55563,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.71554,
            "nubia_score": 0.68274
        },
        "bleurt": 0.12077
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.7,
        "total_length": 163,
        "mean_pred_length": 16.3,
        "std_pred_length": 4.817675788178362,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.588957055214724,
        "vocab_size-1": 96,
        "unique-1": 75,
        "entropy-1": 6.101389274616664,
        "distinct-2": 0.8758169934640523,
        "vocab_size-2": 134,
        "unique-2": 118,
        "entropy-2": 6.991016028953006,
        "cond_entropy-2": 0.7959407012258237,
        "distinct-3": 0.972027972027972,
        "vocab_size-3": 139,
        "unique-3": 135,
        "entropy-3": 7.103927280834341,
        "cond_entropy-3": 0.12454564445051712,
        "total_length-nopunct": 146,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 4.779121258139408,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.636986301369863,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.1260147138310375,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 119,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.817206315499127,
        "cond_entropy-2-nopunct": 0.7487705982006918,
        "distinct-3-nopunct": 0.9761904761904762,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.929660875880877,
        "cond_entropy-3-nopunct": 0.12596698306039814,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2916666666666667,
            "2": 0.6538461538461539,
            "3": 0.8990825688073395
        },
        "nist": 6.417183446367968,
        "rouge1": {
            "precision": 0.85478,
            "recall": 0.85618,
            "fmeasure": 0.85409
        },
        "rouge2": {
            "precision": 0.6859,
            "recall": 0.70113,
            "fmeasure": 0.69224
        },
        "rougeL": {
            "precision": 0.74149,
            "recall": 0.75731,
            "fmeasure": 0.74576
        },
        "rougeLsum": {
            "precision": 0.74149,
            "recall": 0.75731,
            "fmeasure": 0.74576
        },
        "bleu": 66.83647,
        "meteor": 0.47453102583277096,
        "bertscore": {
            "precision": 0.95648,
            "recall": 0.95355,
            "f1": 0.95468
        },
        "nubia": {
            "semantic_relation": 4.21987,
            "contradiction": 29.53351,
            "irrelevancy": 21.92941,
            "logical_agreement": 48.53708,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.85359,
            "nubia_score": 0.734
        },
        "bleurt": 0.49224
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143
        },
        "nist": 1.4080828133113008,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.54762,
            "fmeasure": 0.51648
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.10096,
            "fmeasure": 0.0943
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.45635,
            "fmeasure": 0.4304
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.45635,
            "fmeasure": 0.4304
        },
        "bleu": 6.43717,
        "meteor": 0.1897866405696467,
        "bertscore": {
            "precision": 0.83068,
            "recall": 0.90336,
            "f1": 0.8655
        },
        "nubia": {
            "semantic_relation": 2.91621,
            "contradiction": 48.68431,
            "irrelevancy": 50.83343,
            "logical_agreement": 0.48226,
            "grammar_ref": 5.58883,
            "grammar_hyp": 3.99997,
            "nubia_score": 0.41291
        },
        "bleurt": 0.22623
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 2.5,
        "median_pred_length": 23.5,
        "min_pred_length": 21,
        "max_pred_length": 26,
        "distinct-1": 0.8936170212765957,
        "vocab_size-1": 42,
        "unique-1": 39,
        "entropy-1": 5.309700021798343,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.19303702252596933,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.0655883416275766,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 22.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 22.5,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.236080318455742,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.20208084451956165,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.06871275008401433,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.75
        },
        "nist": 3.9485802212299634,
        "rouge1": {
            "precision": 0.68269,
            "recall": 0.74791,
            "fmeasure": 0.71363
        },
        "rouge2": {
            "precision": 0.42316,
            "recall": 0.46544,
            "fmeasure": 0.44317
        },
        "rougeL": {
            "precision": 0.5359,
            "recall": 0.58797,
            "fmeasure": 0.5606
        },
        "rougeLsum": {
            "precision": 0.5359,
            "recall": 0.58797,
            "fmeasure": 0.5606
        },
        "bleu": 37.5292,
        "meteor": 0.3715079578697366,
        "bertscore": {
            "precision": 0.90958,
            "recall": 0.91125,
            "f1": 0.9104
        },
        "nubia": {
            "semantic_relation": 4.0007,
            "contradiction": 1.88098,
            "irrelevancy": 31.00956,
            "logical_agreement": 67.10945,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.47356,
            "nubia_score": 0.56746
        },
        "bleurt": 0.11457
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 737,
        "msttr-100": 0.2851,
        "msttr-100_nopunct": 0.27949,
        "total_length": 14945,
        "mean_pred_length": 20.278154681139757,
        "std_pred_length": 3.6494973335339354,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.016527266644362663,
        "vocab_size-1": 247,
        "unique-1": 52,
        "entropy-1": 5.91478826159868,
        "distinct-2": 0.05919200450450451,
        "vocab_size-2": 841,
        "unique-2": 230,
        "entropy-2": 7.798586397497183,
        "cond_entropy-2": 1.8197766371627029,
        "distinct-3": 0.10986563729492985,
        "vocab_size-3": 1480,
        "unique-3": 481,
        "entropy-3": 8.885060474075882,
        "cond_entropy-3": 1.1261761202622909,
        "total_length-nopunct": 13851,
        "mean_pred_length-nopunct": 18.793758480325643,
        "std_pred_length-nopunct": 3.520563990721841,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.017471662695834236,
        "vocab_size-1-nopunct": 242,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.942870187445537,
        "distinct-2-nopunct": 0.06107976208631996,
        "vocab_size-2-nopunct": 801,
        "unique-2-nopunct": 225,
        "entropy-2-nopunct": 7.718759264391355,
        "cond_entropy-2-nopunct": 1.8442892798416457,
        "distinct-3-nopunct": 0.1144057526056395,
        "vocab_size-3-nopunct": 1416,
        "unique-3-nopunct": 464,
        "entropy-3-nopunct": 8.851137798278344,
        "cond_entropy-3-nopunct": 1.1420050882758555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6754073512694202
        },
        "nist": 4.899588104126804,
        "rouge1": {
            "precision": 0.71732,
            "recall": 0.69588,
            "fmeasure": 0.69567
        },
        "rouge2": {
            "precision": 0.43947,
            "recall": 0.42596,
            "fmeasure": 0.42573
        },
        "rougeL": {
            "precision": 0.54378,
            "recall": 0.52746,
            "fmeasure": 0.52748
        },
        "rougeLsum": {
            "precision": 0.54378,
            "recall": 0.52746,
            "fmeasure": 0.52748
        },
        "bleu": 29.98303,
        "meteor": 0.35198103232115624,
        "bertscore": {
            "precision": 0.91432,
            "recall": 0.90405,
            "f1": 0.90878
        },
        "nubia": {
            "semantic_relation": 4.25754,
            "contradiction": 3.33179,
            "irrelevancy": 25.33833,
            "logical_agreement": 71.32988,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.72051,
            "nubia_score": 0.75579
        },
        "bleurt": 0.16763
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 36,
        "unique-1": 28,
        "entropy-1": 5.055958151615122,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 40,
        "unique-2": 37,
        "entropy-2": 5.286729870981167,
        "cond_entropy-2": 0.15281646148609582,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": 0.04566334018526421,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.993391529870107,
        "distinct-2-nopunct": 0.8974358974358975,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.0802740137340425,
        "cond_entropy-2-nopunct": 0.11756909101075651,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.114369445886754,
        "cond_entropy-3-nopunct": 0.051189449246730793,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 1.0
        },
        "nist": 5.187199069971218,
        "rouge1": {
            "precision": 0.88287,
            "recall": 0.97454,
            "fmeasure": 0.92251
        },
        "rouge2": {
            "precision": 0.85132,
            "recall": 0.96498,
            "fmeasure": 0.8981
        },
        "rougeL": {
            "precision": 0.87546,
            "recall": 0.97596,
            "fmeasure": 0.91763
        },
        "rougeLsum": {
            "precision": 0.87546,
            "recall": 0.97596,
            "fmeasure": 0.91763
        },
        "bleu": 82.12549,
        "meteor": 0.5890646732423985,
        "bertscore": {
            "precision": 0.97094,
            "recall": 0.98603,
            "f1": 0.97676
        },
        "nubia": {
            "semantic_relation": 4.54485,
            "contradiction": 0.53232,
            "irrelevancy": 47.15769,
            "logical_agreement": 52.30999,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.74708,
            "nubia_score": 0.85186
        },
        "bleurt": 0.65616
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1850,
        "msttr-100": 0.69044,
        "msttr-100_nopunct": 0.73314,
        "total_length": 25261,
        "mean_pred_length": 13.654594594594595,
        "std_pred_length": 4.067822709067249,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 35,
        "distinct-1": 0.25315704049720916,
        "vocab_size-1": 6395,
        "unique-1": 4740,
        "entropy-1": 9.130938185197758,
        "distinct-2": 0.5899363547050532,
        "vocab_size-2": 13811,
        "unique-2": 12054,
        "entropy-2": 12.35072718939756,
        "cond_entropy-2": 2.8090829221191207,
        "distinct-3": 0.7512638560363619,
        "vocab_size-3": 16198,
        "unique-3": 14961,
        "entropy-3": 13.16597798107683,
        "cond_entropy-3": 0.8801077019576105,
        "total_length-nopunct": 22027,
        "mean_pred_length-nopunct": 11.906486486486486,
        "std_pred_length-nopunct": 3.61310094877428,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.28955372951377856,
        "vocab_size-1-nopunct": 6378,
        "unique-1-nopunct": 4737,
        "entropy-1-nopunct": 9.565393027513032,
        "distinct-2-nopunct": 0.6089606978242553,
        "vocab_size-2-nopunct": 12287,
        "unique-2-nopunct": 10874,
        "entropy-2-nopunct": 12.184856957894068,
        "cond_entropy-2-nopunct": 2.8806293022225393,
        "distinct-3-nopunct": 0.7589349047852895,
        "vocab_size-3-nopunct": 13909,
        "unique-3-nopunct": 12887,
        "entropy-3-nopunct": 12.966061886703336,
        "cond_entropy-3-nopunct": 0.9419867462856987,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2325278810408922,
            "2": 0.48873615883925164,
            "3": 0.7879614233455271
        },
        "nist": 9.509645129326097,
        "rouge1": {
            "precision": 0.7433,
            "recall": 0.73819,
            "fmeasure": 0.72805
        },
        "rouge2": {
            "precision": 0.54507,
            "recall": 0.54049,
            "fmeasure": 0.53332
        },
        "rougeL": {
            "precision": 0.67246,
            "recall": 0.67039,
            "fmeasure": 0.65974
        },
        "rougeLsum": {
            "precision": 0.67246,
            "recall": 0.67039,
            "fmeasure": 0.65974
        },
        "bleu": 51.36355,
        "meteor": 0.409459757045744,
        "bertscore": {
            "precision": 0.92794,
            "recall": 0.92762,
            "f1": 0.92596
        },
        "nubia": {
            "semantic_relation": 4.18768,
            "contradiction": 7.92186,
            "irrelevancy": 30.81418,
            "logical_agreement": 61.26396,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.60767,
            "nubia_score": 0.74113
        },
        "bleurt": 0.327
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 30,
        "entropy-1": 4.945038697540247,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.07435228927748015,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.839700558686835,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.08765939298884755,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.7
        },
        "nist": 3.7097136647986204,
        "rouge1": {
            "precision": 0.55869,
            "recall": 0.52965,
            "fmeasure": 0.53111
        },
        "rouge2": {
            "precision": 0.30357,
            "recall": 0.28131,
            "fmeasure": 0.28636
        },
        "rougeL": {
            "precision": 0.50313,
            "recall": 0.49402,
            "fmeasure": 0.4877
        },
        "rougeLsum": {
            "precision": 0.50313,
            "recall": 0.49402,
            "fmeasure": 0.4877
        },
        "bleu": 33.63281,
        "meteor": 0.32662461348187233,
        "bertscore": {
            "precision": 0.90573,
            "recall": 0.90803,
            "f1": 0.90619
        },
        "nubia": {
            "semantic_relation": 3.33919,
            "contradiction": 31.29114,
            "irrelevancy": 51.73027,
            "logical_agreement": 16.97859,
            "grammar_ref": 5.06451,
            "grammar_hyp": 5.16749,
            "nubia_score": 0.52195
        },
        "bleurt": -0.10634
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.334962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.05628729973432274,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.06613640645429872,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.25,
            "3": 0.6875
        },
        "nist": 3.701301946847802,
        "rouge1": {
            "precision": 0.65741,
            "recall": 0.59391,
            "fmeasure": 0.62077
        },
        "rouge2": {
            "precision": 0.47159,
            "recall": 0.42607,
            "fmeasure": 0.44421
        },
        "rougeL": {
            "precision": 0.56019,
            "recall": 0.50783,
            "fmeasure": 0.52949
        },
        "rougeLsum": {
            "precision": 0.56019,
            "recall": 0.50783,
            "fmeasure": 0.52949
        },
        "bleu": 37.00414,
        "meteor": 0.31172673625669906,
        "bertscore": {
            "precision": 0.88555,
            "recall": 0.88429,
            "f1": 0.87793
        },
        "nubia": {
            "semantic_relation": 2.9043,
            "contradiction": 92.59227,
            "irrelevancy": 6.58198,
            "logical_agreement": 0.82575,
            "grammar_ref": 5.19402,
            "grammar_hyp": 6.1937,
            "nubia_score": 0.22947
        },
        "bleurt": -0.46201
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "msttr-100": 0.72186,
        "msttr-100_nopunct": 0.76608,
        "total_length": 5919,
        "mean_pred_length": 16.487465181058496,
        "std_pred_length": 6.381050810966033,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.36644703497212366,
        "vocab_size-1": 2169,
        "unique-1": 1626,
        "entropy-1": 8.933928092885886,
        "distinct-2": 0.8136690647482014,
        "vocab_size-2": 4524,
        "unique-2": 4166,
        "entropy-2": 11.735549383537792,
        "cond_entropy-2": 2.579190027158555,
        "distinct-3": 0.9400115362430301,
        "vocab_size-3": 4889,
        "unique-3": 4776,
        "entropy-3": 12.094510919957978,
        "cond_entropy-3": 0.39263398940719585,
        "total_length-nopunct": 5195,
        "mean_pred_length-nopunct": 14.470752089136491,
        "std_pred_length-nopunct": 5.584360098287219,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.41539942252165546,
        "vocab_size-1-nopunct": 2158,
        "unique-1-nopunct": 1624,
        "entropy-1-nopunct": 9.282178756949888,
        "distinct-2-nopunct": 0.8521505376344086,
        "vocab_size-2-nopunct": 4121,
        "unique-2-nopunct": 3819,
        "entropy-2-nopunct": 11.763549338268149,
        "cond_entropy-2-nopunct": 2.6404161382300835,
        "distinct-3-nopunct": 0.9769935224480679,
        "vocab_size-3-nopunct": 4374,
        "unique-3-nopunct": 4294,
        "entropy-3-nopunct": 12.076930605037107,
        "cond_entropy-3-nopunct": 0.3410636985700448,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "local_recall": {
            "1": 0.04521739130434783,
            "2": 0.1401098901098901,
            "3": 0.23563892145369286,
            "4": 0.3611898016997167,
            "5": 0.4555112881806109,
            "6": 0.5049261083743842,
            "7": 0.6267123287671232,
            "8": 0.7192460317460317,
            "9": 0.8546762589928057
        },
        "nist": 10.233613036479877,
        "rouge1": {
            "precision": 0.78564,
            "recall": 0.71638,
            "fmeasure": 0.73662
        },
        "rouge2": {
            "precision": 0.6045,
            "recall": 0.55004,
            "fmeasure": 0.5612
        },
        "rougeL": {
            "precision": 0.7417,
            "recall": 0.68649,
            "fmeasure": 0.69927
        },
        "rougeLsum": {
            "precision": 0.7417,
            "recall": 0.68649,
            "fmeasure": 0.69927
        },
        "bleu": 59.40703,
        "sari": 44.51292,
        "meteor": 0.38903266818706533,
        "bertscore": {
            "precision": 0.93522,
            "recall": 0.9295,
            "f1": 0.92749
        },
        "nubia": {
            "semantic_relation": 3.87249,
            "contradiction": 5.34691,
            "irrelevancy": 28.9078,
            "logical_agreement": 65.7453,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.04245,
            "nubia_score": 0.56335
        },
        "bleurt": -0.00226
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 80,
        "mean_pred_length": 20.0,
        "std_pred_length": 4.58257569495584,
        "median_pred_length": 19.0,
        "min_pred_length": 15,
        "max_pred_length": 27,
        "distinct-1": 0.825,
        "vocab_size-1": 66,
        "unique-1": 59,
        "entropy-1": 5.893619813556227,
        "distinct-2": 1.0,
        "vocab_size-2": 76,
        "unique-2": 76,
        "entropy-2": 6.247927513443591,
        "cond_entropy-2": 0.31428593177105174,
        "distinct-3": 1.0,
        "vocab_size-3": 72,
        "unique-3": 72,
        "entropy-3": 6.1699250014423175,
        "cond_entropy-3": -0.0780025120012733,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 18.25,
        "std_pred_length-nopunct": 4.322904116447646,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8767123287671232,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.895170106765958,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.108524456778164,
        "cond_entropy-2-nopunct": 0.23043576752607847,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.08615664374971463,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6428571428571429,
            "2": 0.6,
            "3": 0.6865671641791045
        },
        "nist": 4.847915811699643,
        "rouge1": {
            "precision": 0.83272,
            "recall": 0.72244,
            "fmeasure": 0.75658
        },
        "rouge2": {
            "precision": 0.55842,
            "recall": 0.47944,
            "fmeasure": 0.5012
        },
        "rougeL": {
            "precision": 0.69658,
            "recall": 0.6227,
            "fmeasure": 0.64298
        },
        "rougeLsum": {
            "precision": 0.69658,
            "recall": 0.6227,
            "fmeasure": 0.64298
        },
        "bleu": 39.58763,
        "meteor": 0.37930304319905433,
        "bertscore": {
            "precision": 0.94379,
            "recall": 0.91692,
            "f1": 0.92975
        },
        "nubia": {
            "semantic_relation": 4.11136,
            "contradiction": 24.69209,
            "irrelevancy": 47.47626,
            "logical_agreement": 27.83165,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.47671,
            "nubia_score": 0.64781
        },
        "bleurt": 0.08347
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.7872340425531915,
        "vocab_size-1": 37,
        "unique-1": 28,
        "entropy-1": 5.112995500567779,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 42,
        "unique-2": 40,
        "entropy-2": 5.368522527728205,
        "cond_entropy-2": 0.17757003968693233,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.004318638409457535,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 5.054171731446283,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.221928094887364,
        "cond_entropy-2-nopunct": 0.19566334018526416,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.004366621150304504,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.25,
            "3": 0.5862068965517241
        },
        "nist": 2.463032497217847,
        "rouge1": {
            "precision": 0.46102,
            "recall": 0.56532,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.19896,
            "recall": 0.21725,
            "fmeasure": 0.20601
        },
        "rougeL": {
            "precision": 0.37649,
            "recall": 0.40178,
            "fmeasure": 0.38637
        },
        "rougeLsum": {
            "precision": 0.37649,
            "recall": 0.40178,
            "fmeasure": 0.38637
        },
        "bleu": 15.13334,
        "meteor": 0.25600874103780136,
        "bertscore": {
            "precision": 0.82692,
            "recall": 0.84992,
            "f1": 0.83286
        },
        "nubia": {
            "semantic_relation": 3.59411,
            "contradiction": 29.58182,
            "irrelevancy": 57.48695,
            "logical_agreement": 12.93123,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.73548,
            "nubia_score": 0.52088
        },
        "bleurt": -0.23298
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "nist": 4.904360462230019,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.80952,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.69048,
            "fmeasure": 0.74359
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.69048,
            "fmeasure": 0.74359
        },
        "bleu": 73.63897,
        "meteor": 0.4778547483222343,
        "bertscore": {
            "precision": 0.97008,
            "recall": 0.95941,
            "f1": 0.96471
        },
        "nubia": {
            "semantic_relation": 4.57217,
            "contradiction": 0.2535,
            "irrelevancy": 0.45855,
            "logical_agreement": 99.28795,
            "grammar_ref": 5.70189,
            "grammar_hyp": 5.04993,
            "nubia_score": 0.91021
        },
        "bleurt": 0.42742
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 7.039570693980958,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 30,
        "distinct-1": 0.7258064516129032,
        "vocab_size-1": 45,
        "unique-1": 34,
        "entropy-1": 5.316941874833214,
        "distinct-2": 0.9491525423728814,
        "vocab_size-2": 56,
        "unique-2": 54,
        "entropy-2": 5.7681534306810995,
        "cond_entropy-2": 0.415817713587906,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": 0.04533486380582463,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 4.898979485566356,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7592592592592593,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.171373150231489,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.579192253693785,
        "cond_entropy-2-nopunct": 0.40292779083083996,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": 0.011597315044732853,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.6086956521739131,
            "3": 0.6470588235294118
        },
        "nist": 3.1940751319685146,
        "rouge1": {
            "precision": 0.491,
            "recall": 0.66983,
            "fmeasure": 0.56371
        },
        "rouge2": {
            "precision": 0.20459,
            "recall": 0.30579,
            "fmeasure": 0.24203
        },
        "rougeL": {
            "precision": 0.39927,
            "recall": 0.53303,
            "fmeasure": 0.453
        },
        "rougeLsum": {
            "precision": 0.39927,
            "recall": 0.53303,
            "fmeasure": 0.453
        },
        "bleu": 15.69659,
        "meteor": 0.2967406660046673,
        "bertscore": {
            "precision": 0.83022,
            "recall": 0.89119,
            "f1": 0.85868
        },
        "nubia": {
            "semantic_relation": 3.91401,
            "contradiction": 2.6902,
            "irrelevancy": 62.22245,
            "logical_agreement": 35.08735,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.09644,
            "nubia_score": 0.69966
        },
        "bleurt": -0.00949
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 86,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 4.6785562825394,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.6744186046511628,
        "vocab_size-1": 58,
        "unique-1": 46,
        "entropy-1": 5.513133068504647,
        "distinct-2": 0.9375,
        "vocab_size-2": 75,
        "unique-2": 70,
        "entropy-2": 6.196928094887357,
        "cond_entropy-2": 0.558407715293438,
        "distinct-3": 0.9864864864864865,
        "vocab_size-3": 73,
        "unique-3": 72,
        "entropy-3": 6.182426338601928,
        "cond_entropy-3": -0.00436662115030452,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 12.833333333333334,
        "std_pred_length-nopunct": 4.258977446393546,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.510102612039184,
        "distinct-2-nopunct": 0.9295774647887324,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 6.008902049082143,
        "cond_entropy-2-nopunct": 0.5486600507321803,
        "distinct-3-nopunct": 0.9846153846153847,
        "vocab_size-3-nopunct": 64,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 5.991598582259227,
        "cond_entropy-3-nopunct": -0.01968699878391999,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.7777777777777778,
            "3": 0.782608695652174
        },
        "nist": 5.100069186846454,
        "rouge1": {
            "precision": 0.8745,
            "recall": 0.80938,
            "fmeasure": 0.83397
        },
        "rouge2": {
            "precision": 0.65198,
            "recall": 0.6173,
            "fmeasure": 0.62865
        },
        "rougeL": {
            "precision": 0.82242,
            "recall": 0.76705,
            "fmeasure": 0.78774
        },
        "rougeLsum": {
            "precision": 0.82242,
            "recall": 0.76705,
            "fmeasure": 0.78774
        },
        "bleu": 50.54042,
        "meteor": 0.44506406686288186,
        "bertscore": {
            "precision": 0.96392,
            "recall": 0.94517,
            "f1": 0.9539
        },
        "nubia": {
            "semantic_relation": 4.42583,
            "contradiction": 22.81429,
            "irrelevancy": 27.46693,
            "logical_agreement": 49.71878,
            "grammar_ref": 4.9652,
            "grammar_hyp": 5.22252,
            "nubia_score": 0.77093
        },
        "bleurt": 0.46476
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 7.483314773547883,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.8222222222222222,
        "vocab_size-1": 37,
        "unique-1": 30,
        "entropy-1": 5.119522262948262,
        "distinct-2": 0.9761904761904762,
        "vocab_size-2": 41,
        "unique-2": 40,
        "entropy-2": 5.344698375159715,
        "cond_entropy-2": 0.20415212411964445,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.05563315263446058,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 6.79869268479038,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.037401197654114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.10992693207280962,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.4117647058823529,
            "3": 0.75
        },
        "nist": 2.6290358722442755,
        "rouge1": {
            "precision": 0.61667,
            "recall": 0.69907,
            "fmeasure": 0.63789
        },
        "rouge2": {
            "precision": 0.44055,
            "recall": 0.47757,
            "fmeasure": 0.44824
        },
        "rougeL": {
            "precision": 0.57222,
            "recall": 0.65939,
            "fmeasure": 0.59611
        },
        "rougeLsum": {
            "precision": 0.57222,
            "recall": 0.65939,
            "fmeasure": 0.59611
        },
        "bleu": 24.29186,
        "meteor": 0.29193019433838296,
        "bertscore": {
            "precision": 0.89225,
            "recall": 0.92736,
            "f1": 0.90644
        },
        "nubia": {
            "semantic_relation": 3.93573,
            "contradiction": 8.97784,
            "irrelevancy": 47.76434,
            "logical_agreement": 43.25782,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.08706,
            "nubia_score": 0.72311
        },
        "bleurt": 0.13969
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.25
        },
        "nist": 2.340822795263013,
        "rouge1": {
            "precision": 0.3125,
            "recall": 0.39683,
            "fmeasure": 0.34667
        },
        "rouge2": {
            "precision": 0.13333,
            "recall": 0.15385,
            "fmeasure": 0.14286
        },
        "rougeL": {
            "precision": 0.21875,
            "recall": 0.26984,
            "fmeasure": 0.24
        },
        "rougeLsum": {
            "precision": 0.21875,
            "recall": 0.26984,
            "fmeasure": 0.24
        },
        "bleu": 24.79798,
        "meteor": 0.24726302058836602,
        "bertscore": {
            "precision": 0.89051,
            "recall": 0.90108,
            "f1": 0.89576
        },
        "nubia": {
            "semantic_relation": 2.61375,
            "contradiction": 0.73855,
            "irrelevancy": 49.79604,
            "logical_agreement": 49.4654,
            "grammar_ref": 5.77141,
            "grammar_hyp": 4.03241,
            "nubia_score": 0.43539
        },
        "bleurt": -0.26154
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.3764992953429935,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "bleurt": 0.91462
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2186000898557489,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.433288378057127,
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rougeLsum": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "bleu": 78.39204,
        "meteor": 0.5347033086663171,
        "bertscore": {
            "precision": 0.96805,
            "recall": 0.97648,
            "f1": 0.97224
        },
        "nubia": {
            "semantic_relation": 4.85453,
            "contradiction": 0.33848,
            "irrelevancy": 2.11318,
            "logical_agreement": 97.54834,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.31084,
            "nubia_score": 0.99053
        },
        "bleurt": 0.61374
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 12,
        "unique-1": 9,
        "entropy-1": 3.350209029099897,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 16,
        "unique-2": 15,
        "entropy-2": 3.969815782426811,
        "cond_entropy-2": 0.6678253399352899,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": 0.037537158749660585,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.180832987205441,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.36409674109368645,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 3.000515756377562,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.67582,
            "fmeasure": 0.68376
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.21445,
            "fmeasure": 0.21797
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.56044,
            "fmeasure": 0.57455
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.56044,
            "fmeasure": 0.57455
        },
        "bleu": 25.02447,
        "meteor": 0.3516586468876016,
        "bertscore": {
            "precision": 0.9152,
            "recall": 0.88421,
            "f1": 0.89944
        },
        "nubia": {
            "semantic_relation": 4.23991,
            "contradiction": 1.04261,
            "irrelevancy": 8.78143,
            "logical_agreement": 90.17595,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.26336,
            "nubia_score": 0.77427
        },
        "bleurt": 0.29599
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 20.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.7543859649122807,
        "vocab_size-1": 43,
        "unique-1": 33,
        "entropy-1": 5.288687382433968,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 51,
        "unique-2": 48,
        "entropy-2": 5.643776391052356,
        "cond_entropy-2": 0.29726901589669724,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 50,
        "unique-3": 49,
        "entropy-3": 5.63320965569699,
        "cond_entropy-3": -0.043246473917463175,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8478260869565217,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.202803532096936,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.22258390334656097,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.1043366598147359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.0,
            "3": 0.6944444444444444
        },
        "nist": 4.403457668838478,
        "rouge1": {
            "precision": 0.62435,
            "recall": 0.58953,
            "fmeasure": 0.60377
        },
        "rouge2": {
            "precision": 0.42527,
            "recall": 0.38547,
            "fmeasure": 0.4037
        },
        "rougeL": {
            "precision": 0.61817,
            "recall": 0.58424,
            "fmeasure": 0.59807
        },
        "rougeLsum": {
            "precision": 0.61817,
            "recall": 0.58424,
            "fmeasure": 0.59807
        },
        "bleu": 43.41838,
        "meteor": 0.3968154262748418,
        "bertscore": {
            "precision": 0.91915,
            "recall": 0.90987,
            "f1": 0.91448
        },
        "nubia": {
            "semantic_relation": 4.2514,
            "contradiction": 0.31743,
            "irrelevancy": 16.06733,
            "logical_agreement": 83.61524,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.03834,
            "nubia_score": 0.82715
        },
        "bleurt": 0.2349
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "nist": 2.887230128501382,
        "rouge1": {
            "precision": 0.7963,
            "recall": 0.66285,
            "fmeasure": 0.72204
        },
        "rouge2": {
            "precision": 0.45098,
            "recall": 0.37205,
            "fmeasure": 0.40684
        },
        "rougeL": {
            "precision": 0.48148,
            "recall": 0.40122,
            "fmeasure": 0.43683
        },
        "rougeLsum": {
            "precision": 0.48148,
            "recall": 0.40122,
            "fmeasure": 0.43683
        },
        "bleu": 13.34871,
        "meteor": 0.35287308365613235,
        "bertscore": {
            "precision": 0.90555,
            "recall": 0.85798,
            "f1": 0.87489
        },
        "nubia": {
            "semantic_relation": 3.76673,
            "contradiction": 0.27637,
            "irrelevancy": 2.01485,
            "logical_agreement": 97.70878,
            "grammar_ref": 4.86737,
            "grammar_hyp": 5.92147,
            "nubia_score": 0.518
        },
        "bleurt": 0.06286
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.0,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.03462179117476817,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.03912675144043812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "nist": 3.3776495051717044,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.70244,
            "fmeasure": 0.78144
        },
        "rouge2": {
            "precision": 0.73214,
            "recall": 0.56273,
            "fmeasure": 0.62103
        },
        "rougeL": {
            "precision": 0.79808,
            "recall": 0.6326,
            "fmeasure": 0.69185
        },
        "rougeLsum": {
            "precision": 0.79808,
            "recall": 0.6326,
            "fmeasure": 0.69185
        },
        "bleu": 50.82494,
        "meteor": 0.3961348749055277,
        "bertscore": {
            "precision": 0.96473,
            "recall": 0.92829,
            "f1": 0.94593
        },
        "nubia": {
            "semantic_relation": 4.369,
            "contradiction": 0.3869,
            "irrelevancy": 0.58127,
            "logical_agreement": 99.03183,
            "grammar_ref": 5.26806,
            "grammar_hyp": 5.09202,
            "nubia_score": 0.77192
        },
        "bleurt": 0.43399
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nist": 3.5579098675041347,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "bleu": 73.48889,
        "meteor": 0.9384615384615386,
        "bertscore": {
            "precision": 0.98143,
            "recall": 0.98247,
            "f1": 0.98195
        },
        "nubia": {
            "semantic_relation": 4.61305,
            "contradiction": 1.00975,
            "irrelevancy": 33.27064,
            "logical_agreement": 65.71961,
            "grammar_ref": 4.85143,
            "grammar_hyp": 4.81815,
            "nubia_score": 0.82757
        },
        "bleurt": 0.54425
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966062,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "nist": 4.514053391810574,
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "bleu": 90.3602,
        "meteor": 0.572472684946071,
        "bertscore": {
            "precision": 0.98423,
            "recall": 0.98839,
            "f1": 0.98631
        },
        "nubia": {
            "semantic_relation": 3.74862,
            "contradiction": 97.6993,
            "irrelevancy": 1.77644,
            "logical_agreement": 0.52426,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.18253,
            "nubia_score": 0.52622
        },
        "bleurt": 0.72398
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.68,
        "vocab_size-1": 17,
        "unique-1": 10,
        "entropy-1": 3.973660689688184,
        "distinct-2": 0.782608695652174,
        "vocab_size-2": 18,
        "unique-2": 13,
        "entropy-2": 4.088779347361361,
        "cond_entropy-2": 0.08644000550678686,
        "distinct-3": 0.8095238095238095,
        "vocab_size-3": 17,
        "unique-3": 13,
        "entropy-3": 4.011365041826378,
        "cond_entropy-3": -0.03600643804015717,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.788754913993502,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.8219280948873626,
        "cond_entropy-2-nopunct": 0.10024085135823842,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.7254805569978675,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.6666666666666666,
            "3": 0.9375
        },
        "nist": 5.13452162136698,
        "rouge1": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.92468,
            "recall": 0.9594,
            "fmeasure": 0.93956
        },
        "rougeL": {
            "precision": 0.87963,
            "recall": 0.91667,
            "fmeasure": 0.89583
        },
        "rougeLsum": {
            "precision": 0.87963,
            "recall": 0.91667,
            "fmeasure": 0.89583
        },
        "bleu": 87.75834,
        "meteor": 0.9733333333333333,
        "bertscore": {
            "precision": 0.99687,
            "recall": 0.99687,
            "f1": 0.99687
        },
        "nubia": {
            "semantic_relation": 4.80195,
            "contradiction": 0.90889,
            "irrelevancy": 16.31863,
            "logical_agreement": 82.77249,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.31198,
            "nubia_score": 0.94393
        },
        "bleurt": 0.6943
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.8026650113020075,
        "distinct-2": 0.9302325581395349,
        "vocab_size-2": 40,
        "unique-2": 37,
        "entropy-2": 5.286729870981167,
        "cond_entropy-2": 0.4237812162396588,
        "distinct-3": 0.975,
        "vocab_size-3": 39,
        "unique-3": 38,
        "entropy-3": 5.271928094887364,
        "cond_entropy-3": -0.004336659814735806,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7674418604651163,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.765651453386593,
        "distinct-2-nopunct": 0.925,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.171928094887363,
        "cond_entropy-2-nopunct": 0.4308226390994313,
        "distinct-3-nopunct": 0.972972972972973,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.1553993115749,
        "cond_entropy-3-nopunct": -0.03139364817733154,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5384615384615384,
            "3": 0.76
        },
        "nist": 4.148904479844848,
        "rouge1": {
            "precision": 0.7216,
            "recall": 0.69414,
            "fmeasure": 0.70185
        },
        "rouge2": {
            "precision": 0.54995,
            "recall": 0.53236,
            "fmeasure": 0.53484
        },
        "rougeL": {
            "precision": 0.70926,
            "recall": 0.69626,
            "fmeasure": 0.69545
        },
        "rougeLsum": {
            "precision": 0.70926,
            "recall": 0.69626,
            "fmeasure": 0.69545
        },
        "bleu": 40.5568,
        "meteor": 0.4018160657902513,
        "bertscore": {
            "precision": 0.92767,
            "recall": 0.92602,
            "f1": 0.92579
        },
        "nubia": {
            "semantic_relation": 4.12632,
            "contradiction": 0.17345,
            "irrelevancy": 39.85076,
            "logical_agreement": 59.97579,
            "grammar_ref": 4.28129,
            "grammar_hyp": 3.97847,
            "nubia_score": 0.81189
        },
        "bleurt": 0.1703
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.0,
        "median_pred_length": 20.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 30,
        "entropy-1": 4.971928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.24178889224043365,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.8365916681089764,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.2704790162786154,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.9047619047619048
        },
        "nist": 4.073769372415743,
        "rouge1": {
            "precision": 0.81042,
            "recall": 0.86343,
            "fmeasure": 0.83473
        },
        "rouge2": {
            "precision": 0.67018,
            "recall": 0.72157,
            "fmeasure": 0.69314
        },
        "rougeL": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "rougeLsum": {
            "precision": 0.78542,
            "recall": 0.83449,
            "fmeasure": 0.80793
        },
        "bleu": 59.56191,
        "meteor": 0.5055762173065844,
        "bertscore": {
            "precision": 0.94308,
            "recall": 0.95612,
            "f1": 0.9461
        },
        "nubia": {
            "semantic_relation": 3.53158,
            "contradiction": 49.22291,
            "irrelevancy": 45.78439,
            "logical_agreement": 4.9927,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.22454,
            "nubia_score": 0.64787
        },
        "bleurt": 0.488
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.8627450980392157,
        "vocab_size-1": 44,
        "unique-1": 40,
        "entropy-1": 5.353510390863844,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.20971762763487764,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.287782031835944,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.2238830957527494,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.0995356735509143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.11764705882352941,
            "3": 0.8611111111111112
        },
        "nist": 4.013951788439556,
        "rouge1": {
            "precision": 0.77249,
            "recall": 0.74897,
            "fmeasure": 0.75913
        },
        "rouge2": {
            "precision": 0.49231,
            "recall": 0.47573,
            "fmeasure": 0.48295
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.55433,
            "fmeasure": 0.56168
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.55433,
            "fmeasure": 0.56168
        },
        "bleu": 37.41525,
        "meteor": 0.3944989442560533,
        "bertscore": {
            "precision": 0.9464,
            "recall": 0.93976,
            "f1": 0.94306
        },
        "nubia": {
            "semantic_relation": 4.43121,
            "contradiction": 0.58354,
            "irrelevancy": 9.60633,
            "logical_agreement": 89.81013,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.49688,
            "nubia_score": 0.78947
        },
        "bleurt": 0.20846
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.4838561897747224,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.10777297761309836,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.10777297761309836,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.061400544664143256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.6956521739130435
        },
        "nist": 1.6425919516707836,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.49733,
            "fmeasure": 0.59192
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.20588,
            "fmeasure": 0.24138
        },
        "rougeL": {
            "precision": 0.48,
            "recall": 0.34286,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.48,
            "recall": 0.34286,
            "fmeasure": 0.4
        },
        "bleu": 9.74751,
        "meteor": 0.3065187016374829,
        "bertscore": {
            "precision": 0.9013,
            "recall": 0.89196,
            "f1": 0.89618
        },
        "nubia": {
            "semantic_relation": 3.49145,
            "contradiction": 5.18436,
            "irrelevancy": 93.38895,
            "logical_agreement": 1.42669,
            "grammar_ref": 5.19058,
            "grammar_hyp": 5.16083,
            "nubia_score": 0.3938
        },
        "bleurt": -0.12525
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.928203230275509,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.59375,
        "vocab_size-1": 38,
        "unique-1": 20,
        "entropy-1": 5.064464015923012,
        "distinct-2": 0.8,
        "vocab_size-2": 48,
        "unique-2": 36,
        "entropy-2": 5.5068905956085175,
        "cond_entropy-2": 0.425547520254581,
        "distinct-3": 0.875,
        "vocab_size-3": 49,
        "unique-3": 42,
        "entropy-3": 5.557354922057608,
        "cond_entropy-3": 0.07903575502051417,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 3.960744879438715,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.673469387755102,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.930836884843231,
        "distinct-2-nopunct": 0.8444444444444444,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.180741985218565,
        "cond_entropy-2-nopunct": 0.310693807866176,
        "distinct-3-nopunct": 0.9024390243902439,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.16243005339857,
        "cond_entropy-3-nopunct": 0.012040371703043045,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3888888888888889,
            "3": 1.0
        },
        "nist": 3.281938024226555,
        "rouge1": {
            "precision": 0.67157,
            "recall": 0.73455,
            "fmeasure": 0.69416
        },
        "rouge2": {
            "precision": 0.54688,
            "recall": 0.57395,
            "fmeasure": 0.55008
        },
        "rougeL": {
            "precision": 0.65588,
            "recall": 0.72078,
            "fmeasure": 0.67964
        },
        "rougeLsum": {
            "precision": 0.65588,
            "recall": 0.72078,
            "fmeasure": 0.67964
        },
        "bleu": 38.51458,
        "meteor": 0.35193446480766316,
        "bertscore": {
            "precision": 0.90488,
            "recall": 0.90799,
            "f1": 0.90556
        },
        "nubia": {
            "semantic_relation": 4.41873,
            "contradiction": 9.63289,
            "irrelevancy": 6.20587,
            "logical_agreement": 84.16125,
            "grammar_ref": 4.6519,
            "grammar_hyp": 4.5397,
            "nubia_score": 0.76338
        },
        "bleurt": 0.25932
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.50789957099271,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "bleurt": 0.89367
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "nist": 2.2694939111836114,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.9375,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.71429,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.9375,
            "fmeasure": 0.71429
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.9375,
            "fmeasure": 0.71429
        },
        "bleu": 36.61926,
        "meteor": 0.47249523163783624,
        "bertscore": {
            "precision": 0.86329,
            "recall": 0.96101,
            "f1": 0.90953
        },
        "nubia": {
            "semantic_relation": 3.7563,
            "contradiction": 0.4695,
            "irrelevancy": 99.15521,
            "logical_agreement": 0.3753,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.1026,
            "nubia_score": 0.48487
        },
        "bleurt": -0.85422
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 16,
        "unique-1": 8,
        "entropy-1": 3.91829583405449,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 17,
        "unique-2": 12,
        "entropy-2": 4.004886164091841,
        "cond_entropy-2": 0.05628729973432271,
        "distinct-3": 0.8,
        "vocab_size-3": 16,
        "unique-3": 12,
        "entropy-3": 3.9219280948873623,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.82306798227366,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.821928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.7254805569978675,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "nist": 4.480121590342234,
        "rouge1": {
            "precision": 0.89394,
            "recall": 0.875,
            "fmeasure": 0.88337
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.75421,
            "fmeasure": 0.7594
        },
        "rougeL": {
            "precision": 0.89394,
            "recall": 0.875,
            "fmeasure": 0.88337
        },
        "rougeLsum": {
            "precision": 0.89394,
            "recall": 0.875,
            "fmeasure": 0.88337
        },
        "bleu": 70.45495,
        "meteor": 0.5257633658119866,
        "bertscore": {
            "precision": 0.97869,
            "recall": 0.96479,
            "f1": 0.97164
        },
        "nubia": {
            "semantic_relation": 4.79162,
            "contradiction": 2.20392,
            "irrelevancy": 0.89241,
            "logical_agreement": 96.90368,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.31724,
            "nubia_score": 0.86985
        },
        "bleurt": 0.83367
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6111111111111112
        },
        "nist": 2.15490148077859,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.51754,
            "fmeasure": 0.60012
        },
        "rouge2": {
            "precision": 0.51282,
            "recall": 0.37061,
            "fmeasure": 0.4296
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.51084,
            "fmeasure": 0.56891
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.51084,
            "fmeasure": 0.56891
        },
        "bleu": 34.27988,
        "meteor": 0.29043171582316757,
        "bertscore": {
            "precision": 0.88871,
            "recall": 0.82963,
            "f1": 0.8564
        },
        "nubia": {
            "semantic_relation": 2.94859,
            "contradiction": 99.32369,
            "irrelevancy": 0.48778,
            "logical_agreement": 0.18853,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.80184,
            "nubia_score": 0.35496
        },
        "bleurt": -0.38976
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.7272727272727273
        },
        "nist": 2.574789305470339,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.75,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.6404,
            "fmeasure": 0.5456
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.76389,
            "fmeasure": 0.66179
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.76389,
            "fmeasure": 0.66179
        },
        "bleu": 19.69222,
        "meteor": 0.42226872726830433,
        "bertscore": {
            "precision": 0.89233,
            "recall": 0.95223,
            "f1": 0.91261
        },
        "nubia": {
            "semantic_relation": 4.28654,
            "contradiction": 0.81862,
            "irrelevancy": 36.11994,
            "logical_agreement": 63.06144,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.46514,
            "nubia_score": 0.73774
        },
        "bleurt": 0.59732
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 20.333333333333332,
        "std_pred_length": 3.299831645537222,
        "median_pred_length": 21.0,
        "min_pred_length": 16,
        "max_pred_length": 24,
        "distinct-1": 0.7540983606557377,
        "vocab_size-1": 46,
        "unique-1": 37,
        "entropy-1": 5.323859468568559,
        "distinct-2": 1.0,
        "vocab_size-2": 58,
        "unique-2": 58,
        "entropy-2": 5.85798099512757,
        "cond_entropy-2": 0.48353094215934755,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.0766212816029123,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7962962962962963,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.231467826117351,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.47174690856274054,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.08746284125033933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.6875,
            "3": 0.9642857142857143
        },
        "nist": 5.071702352296512,
        "rouge1": {
            "precision": 0.81462,
            "recall": 0.83104,
            "fmeasure": 0.81797
        },
        "rouge2": {
            "precision": 0.58521,
            "recall": 0.62122,
            "fmeasure": 0.59915
        },
        "rougeL": {
            "precision": 0.75643,
            "recall": 0.78384,
            "fmeasure": 0.76576
        },
        "rougeLsum": {
            "precision": 0.75643,
            "recall": 0.78384,
            "fmeasure": 0.76576
        },
        "bleu": 55.15878,
        "meteor": 0.45023960236680494,
        "bertscore": {
            "precision": 0.95451,
            "recall": 0.95966,
            "f1": 0.9542
        },
        "nubia": {
            "semantic_relation": 4.16404,
            "contradiction": 22.40234,
            "irrelevancy": 22.28502,
            "logical_agreement": 55.31264,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.35288,
            "nubia_score": 0.72423
        },
        "bleurt": 0.43003
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.62,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 14.285714285714286,
        "std_pred_length": 3.843892584878203,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.62,
        "vocab_size-1": 62,
        "unique-1": 41,
        "entropy-1": 5.620050785698695,
        "distinct-2": 0.7956989247311828,
        "vocab_size-2": 74,
        "unique-2": 55,
        "entropy-2": 6.130556660570403,
        "cond_entropy-2": 0.3762602122279364,
        "distinct-3": 0.8488372093023255,
        "vocab_size-3": 73,
        "unique-3": 60,
        "entropy-3": 6.12393917330675,
        "cond_entropy-3": -0.043126614545468296,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 12.857142857142858,
        "std_pred_length-nopunct": 3.719776161797582,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6555555555555556,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.594863585738552,
        "distinct-2-nopunct": 0.8192771084337349,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 6.013593648214401,
        "cond_entropy-2-nopunct": 0.4220906236100277,
        "distinct-3-nopunct": 0.868421052631579,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.984769618706748,
        "cond_entropy-3-nopunct": -0.04816454948228654,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.7083333333333334,
            "3": 0.6739130434782609
        },
        "nist": 4.374691524022121,
        "rouge1": {
            "precision": 0.57668,
            "recall": 0.64839,
            "fmeasure": 0.60315
        },
        "rouge2": {
            "precision": 0.28998,
            "recall": 0.33711,
            "fmeasure": 0.3064
        },
        "rougeL": {
            "precision": 0.43877,
            "recall": 0.51788,
            "fmeasure": 0.46962
        },
        "rougeLsum": {
            "precision": 0.43877,
            "recall": 0.51788,
            "fmeasure": 0.46962
        },
        "bleu": 28.19744,
        "meteor": 0.3328563027890679,
        "bertscore": {
            "precision": 0.90159,
            "recall": 0.90363,
            "f1": 0.90233
        },
        "nubia": {
            "semantic_relation": 3.77409,
            "contradiction": 29.45691,
            "irrelevancy": 25.22111,
            "logical_agreement": 45.32198,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.61787,
            "nubia_score": 0.62285
        },
        "bleurt": 0.19738
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 23.0,
        "std_pred_length": 4.0,
        "median_pred_length": 23.0,
        "min_pred_length": 19,
        "max_pred_length": 27,
        "distinct-1": 0.6739130434782609,
        "vocab_size-1": 31,
        "unique-1": 17,
        "entropy-1": 4.854977445140415,
        "distinct-2": 0.8409090909090909,
        "vocab_size-2": 37,
        "unique-2": 30,
        "entropy-2": 5.141249800455477,
        "cond_entropy-2": 0.3166625603567269,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 38,
        "unique-3": 34,
        "entropy-3": 5.201841232302572,
        "cond_entropy-3": 0.07574294699860605,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.650661513678569,
        "distinct-2-nopunct": 0.8378378378378378,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.885129041304629,
        "cond_entropy-2-nopunct": 0.24175080898733547,
        "distinct-3-nopunct": 0.9142857142857143,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.957854445516392,
        "cond_entropy-3-nopunct": 0.09125822274458811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.06666666666666667,
            "3": 0.7878787878787878
        },
        "nist": 3.599482817253398,
        "rouge1": {
            "precision": 0.81014,
            "recall": 0.68232,
            "fmeasure": 0.73593
        },
        "rouge2": {
            "precision": 0.53463,
            "recall": 0.46199,
            "fmeasure": 0.49387
        },
        "rougeL": {
            "precision": 0.73043,
            "recall": 0.62823,
            "fmeasure": 0.67226
        },
        "rougeLsum": {
            "precision": 0.73043,
            "recall": 0.62823,
            "fmeasure": 0.67226
        },
        "bleu": 41.05602,
        "meteor": 0.40222927985195756,
        "bertscore": {
            "precision": 0.93606,
            "recall": 0.91612,
            "f1": 0.9258
        },
        "nubia": {
            "semantic_relation": 4.28322,
            "contradiction": 0.43393,
            "irrelevancy": 46.99854,
            "logical_agreement": 52.56753,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.80925,
            "nubia_score": 0.71495
        },
        "bleurt": 0.24525
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 15,
        "distinct-1": 0.8611111111111112,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.871178126382214,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.05628729973432271,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.13750352374993471,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.08349873228287957,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "nist": 3.826094663031975,
        "rouge1": {
            "precision": 0.714,
            "recall": 0.57589,
            "fmeasure": 0.62543
        },
        "rouge2": {
            "precision": 0.48889,
            "recall": 0.38002,
            "fmeasure": 0.41648
        },
        "rougeL": {
            "precision": 0.58384,
            "recall": 0.47967,
            "fmeasure": 0.51632
        },
        "rougeLsum": {
            "precision": 0.58384,
            "recall": 0.47967,
            "fmeasure": 0.51632
        },
        "bleu": 37.9832,
        "meteor": 0.365502736830962,
        "bertscore": {
            "precision": 0.91176,
            "recall": 0.89928,
            "f1": 0.90497
        },
        "nubia": {
            "semantic_relation": 3.50141,
            "contradiction": 43.7161,
            "irrelevancy": 23.19077,
            "logical_agreement": 33.09313,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.81593,
            "nubia_score": 0.50192
        },
        "bleurt": 0.13211
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.5,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 4.8625759375402735,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.03883444909293795,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9655172413793104,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.789015477886192,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": -0.029019418890029344,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9629629629629629
        },
        "nist": 4.982855333410896,
        "rouge1": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "rougeLsum": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "bleu": 91.53254,
        "meteor": 0.6276979374374717,
        "bertscore": {
            "precision": 0.99594,
            "recall": 0.99594,
            "f1": 0.99594
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31768,
            "irrelevancy": 0.57052,
            "logical_agreement": 99.11181,
            "grammar_ref": 5.04945,
            "grammar_hyp": 4.81437,
            "nubia_score": 1.0
        },
        "bleurt": 0.87023
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 14.6,
        "std_pred_length": 4.5431266766402185,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7945205479452054,
        "vocab_size-1": 58,
        "unique-1": 48,
        "entropy-1": 5.708736675609289,
        "distinct-2": 0.9117647058823529,
        "vocab_size-2": 62,
        "unique-2": 56,
        "entropy-2": 5.910992253015051,
        "cond_entropy-2": 0.06689967949277727,
        "distinct-3": 0.9206349206349206,
        "vocab_size-3": 58,
        "unique-3": 53,
        "entropy-3": 5.818549764769761,
        "cond_entropy-3": -0.07843688600439114,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 4.454211490264018,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.835820895522388,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.715197026214083,
        "distinct-2-nopunct": 0.9032258064516129,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.760647923290097,
        "cond_entropy-2-nopunct": 0.04149058774082766,
        "distinct-3-nopunct": 0.9122807017543859,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.65745141767351,
        "cond_entropy-3-nopunct": -0.10376243657301071,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 1.0,
            "3": 0.8
        },
        "nist": 4.331752128267709,
        "rouge1": {
            "precision": 0.66136,
            "recall": 0.74505,
            "fmeasure": 0.69593
        },
        "rouge2": {
            "precision": 0.48417,
            "recall": 0.5567,
            "fmeasure": 0.51322
        },
        "rougeL": {
            "precision": 0.56855,
            "recall": 0.65088,
            "fmeasure": 0.60267
        },
        "rougeLsum": {
            "precision": 0.56855,
            "recall": 0.65088,
            "fmeasure": 0.60267
        },
        "bleu": 45.9021,
        "meteor": 0.45077145566952176,
        "bertscore": {
            "precision": 0.92246,
            "recall": 0.94589,
            "f1": 0.9297
        },
        "nubia": {
            "semantic_relation": 4.16595,
            "contradiction": 18.45645,
            "irrelevancy": 34.61166,
            "logical_agreement": 46.93189,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.18003,
            "nubia_score": 0.73094
        },
        "bleurt": 0.34987
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 1.9767769323620341,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.53704,
            "fmeasure": 0.61275
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "bleu": 24.839,
        "meteor": 0.41910267807653556,
        "bertscore": {
            "precision": 0.97642,
            "recall": 0.95148,
            "f1": 0.96379
        },
        "nubia": {
            "semantic_relation": 4.74089,
            "contradiction": 0.54392,
            "irrelevancy": 0.53393,
            "logical_agreement": 98.92214,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.75139,
            "nubia_score": 0.91626
        },
        "bleurt": 0.604
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.08248290463863,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 4.950419141294112,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.36736052822139054,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.10691520391651191,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7948717948717948,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.782590924645919,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.42923501798108654,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.0,
            "3": 0.7083333333333334
        },
        "nist": 4.19954222619377,
        "rouge1": {
            "precision": 0.61889,
            "recall": 0.67647,
            "fmeasure": 0.63673
        },
        "rouge2": {
            "precision": 0.45406,
            "recall": 0.51111,
            "fmeasure": 0.4721
        },
        "rougeL": {
            "precision": 0.54746,
            "recall": 0.63191,
            "fmeasure": 0.57909
        },
        "rougeLsum": {
            "precision": 0.54746,
            "recall": 0.63191,
            "fmeasure": 0.57909
        },
        "bleu": 47.43167,
        "meteor": 0.3687825669985493,
        "bertscore": {
            "precision": 0.91679,
            "recall": 0.91771,
            "f1": 0.91581
        },
        "nubia": {
            "semantic_relation": 3.0725,
            "contradiction": 34.38458,
            "irrelevancy": 34.30663,
            "logical_agreement": 31.30879,
            "grammar_ref": 4.11451,
            "grammar_hyp": 4.04504,
            "nubia_score": 0.45513
        },
        "bleurt": 0.04776
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 6.5,
        "median_pred_length": 20.5,
        "min_pred_length": 14,
        "max_pred_length": 27,
        "distinct-1": 0.7804878048780488,
        "vocab_size-1": 32,
        "unique-1": 27,
        "entropy-1": 4.784142858171084,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 36,
        "unique-2": 33,
        "entropy-2": 5.131556065016094,
        "cond_entropy-2": 0.3255367528166505,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 36,
        "unique-3": 35,
        "entropy-3": 5.1553993115749,
        "cond_entropy-3": 0.0321592548748094,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7837837837837838,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.628108095241737,
        "distinct-2-nopunct": 0.9142857142857143,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.957854445516392,
        "cond_entropy-2-nopunct": 0.36296608001107206,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.9837880587523955,
        "cond_entropy-3-nopunct": 0.03632322362560796,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.9615384615384616
        },
        "nist": 5.124986902654583,
        "rouge1": {
            "precision": 0.84382,
            "recall": 0.8845,
            "fmeasure": 0.86243
        },
        "rouge2": {
            "precision": 0.72421,
            "recall": 0.75638,
            "fmeasure": 0.73873
        },
        "rougeL": {
            "precision": 0.84382,
            "recall": 0.8845,
            "fmeasure": 0.86243
        },
        "rougeLsum": {
            "precision": 0.84382,
            "recall": 0.8845,
            "fmeasure": 0.86243
        },
        "bleu": 80.62953,
        "meteor": 0.5606754619218952,
        "bertscore": {
            "precision": 0.9752,
            "recall": 0.97978,
            "f1": 0.97668
        },
        "nubia": {
            "semantic_relation": 4.99122,
            "contradiction": 0.26512,
            "irrelevancy": 1.76437,
            "logical_agreement": 97.97051,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.73039,
            "nubia_score": 0.98833
        },
        "bleurt": 0.78427
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 3.766629793329841,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 40,
        "unique-1": 29,
        "entropy-1": 5.172091077082349,
        "distinct-2": 0.8235294117647058,
        "vocab_size-2": 42,
        "unique-2": 34,
        "entropy-2": 5.304682449772214,
        "cond_entropy-2": 0.02351440299906092,
        "distinct-3": 0.8723404255319149,
        "vocab_size-3": 41,
        "unique-3": 35,
        "entropy-3": 5.299269702741468,
        "cond_entropy-3": 0.025884520390471018,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 3.112474899497183,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7659574468085106,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 5.054380872862171,
        "distinct-2-nopunct": 0.813953488372093,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.036616208140156,
        "cond_entropy-2-nopunct": 0.02876631005151801,
        "distinct-3-nopunct": 0.8717948717948718,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 5.0289919624519905,
        "cond_entropy-3-nopunct": 0.03233970780536746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8780487804878049
        },
        "nist": 5.075451372074672,
        "rouge1": {
            "precision": 0.975,
            "recall": 0.90219,
            "fmeasure": 0.93493
        },
        "rouge2": {
            "precision": 0.90351,
            "recall": 0.84739,
            "fmeasure": 0.87321
        },
        "rougeL": {
            "precision": 0.94167,
            "recall": 0.86414,
            "fmeasure": 0.89827
        },
        "rougeLsum": {
            "precision": 0.94167,
            "recall": 0.86414,
            "fmeasure": 0.89827
        },
        "bleu": 66.38835,
        "meteor": 0.49986636120405137,
        "bertscore": {
            "precision": 0.96965,
            "recall": 0.97043,
            "f1": 0.96866
        },
        "nubia": {
            "semantic_relation": 4.68639,
            "contradiction": 0.28189,
            "irrelevancy": 8.75455,
            "logical_agreement": 90.96356,
            "grammar_ref": 5.18336,
            "grammar_hyp": 4.93848,
            "nubia_score": 0.91588
        },
        "bleurt": 0.64044
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "nist": 2.6330370023236713,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "bleu": 42.95749,
        "meteor": 0.42350497485471644,
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        },
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        },
        "bleurt": 0.45492
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.7992518527004338,
        "rouge1": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98039
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.50734,
            "irrelevancy": 0.72277,
            "logical_agreement": 97.76989,
            "grammar_ref": 5.94246,
            "grammar_hyp": 5.94702,
            "nubia_score": 0.97697
        },
        "bleurt": 0.79398
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 11.666666666666666,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.9428571428571428,
        "vocab_size-1": 33,
        "unique-1": 32,
        "entropy-1": 4.993429088311721,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": -0.12928301694496638,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.14201900487242786,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.954196310386877,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": -0.14684138832927116,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.16349873228287956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.3333333333333333,
            "3": 0.7666666666666667
        },
        "nist": 2.887371735048589,
        "rouge1": {
            "precision": 0.7713,
            "recall": 0.67664,
            "fmeasure": 0.71426
        },
        "rouge2": {
            "precision": 0.60141,
            "recall": 0.43443,
            "fmeasure": 0.49659
        },
        "rougeL": {
            "precision": 0.72685,
            "recall": 0.64642,
            "fmeasure": 0.67839
        },
        "rougeLsum": {
            "precision": 0.72685,
            "recall": 0.64642,
            "fmeasure": 0.67839
        },
        "bleu": 44.9828,
        "meteor": 0.38852805047207817,
        "bertscore": {
            "precision": 0.92495,
            "recall": 0.90787,
            "f1": 0.90433
        },
        "nubia": {
            "semantic_relation": 3.91229,
            "contradiction": 0.26401,
            "irrelevancy": 55.53437,
            "logical_agreement": 44.20162,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.72,
            "nubia_score": 0.67847
        },
        "bleurt": 0.05718
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 171,
        "mean_pred_length": 17.1,
        "std_pred_length": 2.9137604568666933,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.6023391812865497,
        "vocab_size-1": 103,
        "unique-1": 82,
        "entropy-1": 6.170351954831103,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 140,
        "unique-2": 123,
        "entropy-2": 7.04824746814984,
        "cond_entropy-2": 0.7490490825838029,
        "distinct-3": 0.9271523178807947,
        "vocab_size-3": 140,
        "unique-3": 129,
        "entropy-3": 7.09270937508665,
        "cond_entropy-3": 0.049936702298719604,
        "total_length-nopunct": 148,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 2.6381811916545836,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6621621621621622,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.165859917209406,
        "distinct-2-nopunct": 0.8768115942028986,
        "vocab_size-2-nopunct": 121,
        "unique-2-nopunct": 108,
        "entropy-2-nopunct": 6.836714492978696,
        "cond_entropy-2-nopunct": 0.7464772894228793,
        "distinct-3-nopunct": 0.9296875,
        "vocab_size-3-nopunct": 119,
        "unique-3-nopunct": 110,
        "entropy-3-nopunct": 6.859375,
        "cond_entropy-3-nopunct": 0.043895660443135094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.7948717948717948
        },
        "nist": 5.133971732433428,
        "rouge1": {
            "precision": 0.82087,
            "recall": 0.73731,
            "fmeasure": 0.76831
        },
        "rouge2": {
            "precision": 0.61152,
            "recall": 0.55053,
            "fmeasure": 0.57167
        },
        "rougeL": {
            "precision": 0.68144,
            "recall": 0.60241,
            "fmeasure": 0.63018
        },
        "rougeLsum": {
            "precision": 0.68144,
            "recall": 0.60241,
            "fmeasure": 0.63018
        },
        "bleu": 46.75272,
        "meteor": 0.38729191651832484,
        "bertscore": {
            "precision": 0.93342,
            "recall": 0.91502,
            "f1": 0.92317
        },
        "nubia": {
            "semantic_relation": 4.24277,
            "contradiction": 13.97045,
            "irrelevancy": 14.66432,
            "logical_agreement": 71.36523,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.11913,
            "nubia_score": 0.76683
        },
        "bleurt": 0.26644
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 69,
        "mean_pred_length": 11.5,
        "std_pred_length": 4.752192476461084,
        "median_pred_length": 8.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.5362318840579711,
        "vocab_size-1": 37,
        "unique-1": 26,
        "entropy-1": 4.809267348202159,
        "distinct-2": 0.7777777777777778,
        "vocab_size-2": 49,
        "unique-2": 42,
        "entropy-2": 5.441177740788533,
        "cond_entropy-2": 0.5094622600011167,
        "distinct-3": 0.8245614035087719,
        "vocab_size-3": 47,
        "unique-3": 42,
        "entropy-3": 5.415794619238118,
        "cond_entropy-3": -0.052370391829270904,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.9157800414902435,
        "median_pred_length-nopunct": 7.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.55,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.671241170818224,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.217488427929136,
        "cond_entropy-2-nopunct": 0.5661370079601189,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.18872187554087,
        "cond_entropy-3-nopunct": -0.0606518244040513,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.23076923076923078,
            "3": 0.8809523809523809
        },
        "nist": 5.347579032065134,
        "rouge1": {
            "precision": 0.8967,
            "recall": 0.85954,
            "fmeasure": 0.87345
        },
        "rouge2": {
            "precision": 0.73644,
            "recall": 0.7182,
            "fmeasure": 0.72422
        },
        "rougeL": {
            "precision": 0.83373,
            "recall": 0.80714,
            "fmeasure": 0.81659
        },
        "rougeLsum": {
            "precision": 0.83373,
            "recall": 0.80714,
            "fmeasure": 0.81659
        },
        "bleu": 64.88577,
        "meteor": 0.49616129899254097,
        "bertscore": {
            "precision": 0.97671,
            "recall": 0.97802,
            "f1": 0.97722
        },
        "nubia": {
            "semantic_relation": 4.4448,
            "contradiction": 17.05358,
            "irrelevancy": 0.55456,
            "logical_agreement": 82.39186,
            "grammar_ref": 4.0718,
            "grammar_hyp": 3.93892,
            "nubia_score": 0.87147
        },
        "bleurt": 0.68626
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0
        },
        "nist": 3.9025183150183156,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.81667,
            "fmeasure": 0.79841
        },
        "rouge2": {
            "precision": 0.57692,
            "recall": 0.6039,
            "fmeasure": 0.58796
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 0.81667,
            "fmeasure": 0.79841
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 0.81667,
            "fmeasure": 0.79841
        },
        "bleu": 56.36883,
        "meteor": 0.5422615380435467,
        "bertscore": {
            "precision": 0.94916,
            "recall": 0.96441,
            "f1": 0.95673
        },
        "nubia": {
            "semantic_relation": 4.66352,
            "contradiction": 0.53785,
            "irrelevancy": 0.64165,
            "logical_agreement": 98.8205,
            "grammar_ref": 5.25223,
            "grammar_hyp": 4.9224,
            "nubia_score": 0.86301
        },
        "bleurt": 0.67297
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.82,
        "total_length": 115,
        "mean_pred_length": 16.428571428571427,
        "std_pred_length": 3.5398604838182477,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.7565217391304347,
        "vocab_size-1": 87,
        "unique-1": 76,
        "entropy-1": 6.161394099091715,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 106,
        "unique-2": 104,
        "entropy-2": 6.717850465126421,
        "cond_entropy-2": 0.40635147402517774,
        "distinct-3": 0.9900990099009901,
        "vocab_size-3": 100,
        "unique-3": 99,
        "entropy-3": 6.63840950255376,
        "cond_entropy-3": -0.0768740392136541,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 14.714285714285714,
        "std_pred_length-nopunct": 3.806546455564065,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8155339805825242,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.201877741155139,
        "distinct-2-nopunct": 0.9791666666666666,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.543295834054494,
        "cond_entropy-2-nopunct": 0.36633850438057974,
        "distinct-3-nopunct": 0.9887640449438202,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.45326152085405,
        "cond_entropy-3-nopunct": -0.09799311469857855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.855072463768116
        },
        "nist": 4.997635087332451,
        "rouge1": {
            "precision": 0.76186,
            "recall": 0.79359,
            "fmeasure": 0.76934
        },
        "rouge2": {
            "precision": 0.5698,
            "recall": 0.59335,
            "fmeasure": 0.57645
        },
        "rougeL": {
            "precision": 0.64844,
            "recall": 0.68141,
            "fmeasure": 0.65893
        },
        "rougeLsum": {
            "precision": 0.64844,
            "recall": 0.68141,
            "fmeasure": 0.65893
        },
        "bleu": 47.89675,
        "meteor": 0.42516376403846634,
        "bertscore": {
            "precision": 0.92263,
            "recall": 0.94124,
            "f1": 0.92996
        },
        "nubia": {
            "semantic_relation": 4.16918,
            "contradiction": 0.26991,
            "irrelevancy": 67.00407,
            "logical_agreement": 32.72602,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.36133,
            "nubia_score": 0.75374
        },
        "bleurt": 0.34421
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964168,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.2857142857142857
        },
        "nist": 2.043432296960215,
        "rouge1": {
            "precision": 0.28125,
            "recall": 0.33929,
            "fmeasure": 0.30714
        },
        "rouge2": {
            "precision": 0.1,
            "recall": 0.12238,
            "fmeasure": 0.10989
        },
        "rougeL": {
            "precision": 0.28125,
            "recall": 0.33929,
            "fmeasure": 0.30714
        },
        "rougeLsum": {
            "precision": 0.28125,
            "recall": 0.33929,
            "fmeasure": 0.30714
        },
        "bleu": 8.54916,
        "meteor": 0.1880601306768347,
        "bertscore": {
            "precision": 0.83189,
            "recall": 0.84673,
            "f1": 0.83925
        },
        "nubia": {
            "semantic_relation": 3.44153,
            "contradiction": 3.3579,
            "irrelevancy": 91.01716,
            "logical_agreement": 5.62494,
            "grammar_ref": 5.74657,
            "grammar_hyp": 4.48274,
            "nubia_score": 0.5568
        },
        "bleurt": 0.01353
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.8378378378378378,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.844324311457953,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.13550616686149178,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.13326653086346418,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.779094498080774,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.12099272632218087,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.8461538461538461,
            "3": 0.9166666666666666
        },
        "nist": 3.9004951693840617,
        "rouge1": {
            "precision": 0.72821,
            "recall": 0.82241,
            "fmeasure": 0.75833
        },
        "rouge2": {
            "precision": 0.60317,
            "recall": 0.64534,
            "fmeasure": 0.61455
        },
        "rougeL": {
            "precision": 0.72821,
            "recall": 0.82241,
            "fmeasure": 0.75833
        },
        "rougeLsum": {
            "precision": 0.72821,
            "recall": 0.82241,
            "fmeasure": 0.75833
        },
        "bleu": 45.48402,
        "meteor": 0.47907527112624404,
        "bertscore": {
            "precision": 0.91546,
            "recall": 0.95813,
            "f1": 0.93438
        },
        "nubia": {
            "semantic_relation": 4.58161,
            "contradiction": 0.39127,
            "irrelevancy": 33.58847,
            "logical_agreement": 66.02027,
            "grammar_ref": 5.27099,
            "grammar_hyp": 5.05411,
            "nubia_score": 0.90203
        },
        "bleurt": 0.51267
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.681880802803401,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.4083801270078083,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.4548223999466066,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.45971762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": 0.040223928941851894,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "nist": 2.1681907449941207,
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.69697,
            "fmeasure": 0.56158
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.75962,
            "fmeasure": 0.62258
        },
        "bleu": 41.12176,
        "meteor": 0.40391483707176334,
        "bertscore": {
            "precision": 0.90347,
            "recall": 0.9293,
            "f1": 0.9162
        },
        "nubia": {
            "semantic_relation": 2.95457,
            "contradiction": 64.17541,
            "irrelevancy": 35.36587,
            "logical_agreement": 0.45872,
            "grammar_ref": 3.96979,
            "grammar_hyp": 2.83545,
            "nubia_score": 0.47583
        },
        "bleurt": 0.43351
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.251192788981044,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "bleurt": 0.64779
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846629,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.4375
        },
        "nist": 2.2842336386635522,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.54127,
            "fmeasure": 0.53233
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.23684,
            "fmeasure": 0.23504
        },
        "rougeL": {
            "precision": 0.31746,
            "recall": 0.32222,
            "fmeasure": 0.31978
        },
        "rougeLsum": {
            "precision": 0.31746,
            "recall": 0.32222,
            "fmeasure": 0.31978
        },
        "bleu": 10.41442,
        "meteor": 0.28357680622749865,
        "bertscore": {
            "precision": 0.81733,
            "recall": 0.81053,
            "f1": 0.81392
        },
        "nubia": {
            "semantic_relation": 3.70851,
            "contradiction": 0.08167,
            "irrelevancy": 99.73877,
            "logical_agreement": 0.17957,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.14003,
            "nubia_score": 0.63772
        },
        "bleurt": -0.34282
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "nist": 4.770721208389991,
        "rouge1": {
            "precision": 0.97222,
            "recall": 0.84455,
            "fmeasure": 0.9019
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.73333,
            "fmeasure": 0.78484
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "bleu": 80.52254,
        "meteor": 0.5469432736955866,
        "bertscore": {
            "precision": 0.99811,
            "recall": 0.98882,
            "f1": 0.99345
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.11768,
            "irrelevancy": 0.47514,
            "logical_agreement": 99.40718,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.71917,
            "nubia_score": 0.98117
        },
        "bleurt": 0.74939
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "nist": 2.4716507688868106,
        "rouge1": {
            "precision": 0.45833,
            "recall": 0.58111,
            "fmeasure": 0.5073
        },
        "rouge2": {
            "precision": 0.17778,
            "recall": 0.24444,
            "fmeasure": 0.20444
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.40107,
            "fmeasure": 0.34792
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.40107,
            "fmeasure": 0.34792
        },
        "bleu": 8.76884,
        "meteor": 0.3453438643797205,
        "bertscore": {
            "precision": 0.86454,
            "recall": 0.90884,
            "f1": 0.87885
        },
        "nubia": {
            "semantic_relation": 3.80731,
            "contradiction": 0.11158,
            "irrelevancy": 99.77181,
            "logical_agreement": 0.11662,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.2323,
            "nubia_score": 0.68512
        },
        "bleurt": 0.01086
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.5,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.8285714285714286,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.729283016944964,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.27874746604985035,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8484848484848485,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.680757755722092,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.2968989652219703,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7
        },
        "nist": 3.798285625328822,
        "rouge1": {
            "precision": 0.77451,
            "recall": 0.67822,
            "fmeasure": 0.72237
        },
        "rouge2": {
            "precision": 0.44792,
            "recall": 0.40741,
            "fmeasure": 0.42611
        },
        "rougeL": {
            "precision": 0.68627,
            "recall": 0.60585,
            "fmeasure": 0.64279
        },
        "rougeLsum": {
            "precision": 0.68627,
            "recall": 0.60585,
            "fmeasure": 0.64279
        },
        "bleu": 39.19268,
        "meteor": 0.3672295836767385,
        "bertscore": {
            "precision": 0.90916,
            "recall": 0.85643,
            "f1": 0.87996
        },
        "nubia": {
            "semantic_relation": 3.37606,
            "contradiction": 0.14393,
            "irrelevancy": 32.29015,
            "logical_agreement": 67.56592,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.1989,
            "nubia_score": 0.54
        },
        "bleurt": -0.04861
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.018549068142959,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.90476,
            "fmeasure": 0.85348
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "bleu": 69.85342,
        "meteor": 0.5255759325753065,
        "bertscore": {
            "precision": 0.95785,
            "recall": 0.97999,
            "f1": 0.96524
        },
        "nubia": {
            "semantic_relation": 4.40194,
            "contradiction": 0.18499,
            "irrelevancy": 63.6692,
            "logical_agreement": 36.14582,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.41374,
            "nubia_score": 0.97573
        },
        "bleurt": 0.6035
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 3.8394774001865306,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.5100926958304425,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.875
        },
        "nist": 1.9586018459095638,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.7,
            "fmeasure": 0.58333
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.81818,
            "fmeasure": 0.69231
        },
        "bleu": 34.7725,
        "meteor": 0.3740871848793107,
        "bertscore": {
            "precision": 0.84529,
            "recall": 0.92292,
            "f1": 0.8824
        },
        "nubia": {
            "semantic_relation": 3.44037,
            "contradiction": 4.07123,
            "irrelevancy": 95.53116,
            "logical_agreement": 0.39761,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.00134,
            "nubia_score": 0.49027
        },
        "bleurt": -0.31834
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.7804878048780488,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.851335236272632,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.31142814040444916,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.11864449649861893,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8108108108108109,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.77702093319652,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.34859771091550745,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.8461538461538461
        },
        "nist": 4.106855905429318,
        "rouge1": {
            "precision": 0.70646,
            "recall": 0.79875,
            "fmeasure": 0.73581
        },
        "rouge2": {
            "precision": 0.37179,
            "recall": 0.4438,
            "fmeasure": 0.39645
        },
        "rougeL": {
            "precision": 0.59313,
            "recall": 0.69304,
            "fmeasure": 0.62333
        },
        "rougeLsum": {
            "precision": 0.59313,
            "recall": 0.69304,
            "fmeasure": 0.62333
        },
        "bleu": 24.71433,
        "meteor": 0.3924516002530844,
        "bertscore": {
            "precision": 0.92083,
            "recall": 0.93867,
            "f1": 0.92934
        },
        "nubia": {
            "semantic_relation": 3.93469,
            "contradiction": 20.61306,
            "irrelevancy": 33.3137,
            "logical_agreement": 46.07324,
            "grammar_ref": 4.63208,
            "grammar_hyp": 3.86697,
            "nubia_score": 0.69397
        },
        "bleurt": 0.41249
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 18.25,
        "std_pred_length": 6.219927652312364,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.8082191780821918,
        "vocab_size-1": 59,
        "unique-1": 53,
        "entropy-1": 5.682707435473809,
        "distinct-2": 0.9855072463768116,
        "vocab_size-2": 68,
        "unique-2": 67,
        "entropy-2": 6.079538949531787,
        "cond_entropy-2": 0.35731819509366514,
        "distinct-3": 1.0,
        "vocab_size-3": 65,
        "unique-3": 65,
        "entropy-3": 6.022367813028458,
        "cond_entropy-3": -0.055387412980483844,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 16.25,
        "std_pred_length-nopunct": 6.057020719792859,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.599140505269581,
        "distinct-2-nopunct": 0.9836065573770492,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.897950452316981,
        "cond_entropy-2-nopunct": 0.3265625573922505,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.832890014164737,
        "cond_entropy-3-nopunct": -0.06275960409989874,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3684210526315789,
            "3": 0.5925925925925926
        },
        "nist": 3.5593176960583284,
        "rouge1": {
            "precision": 0.6374,
            "recall": 0.50854,
            "fmeasure": 0.5397
        },
        "rouge2": {
            "precision": 0.30322,
            "recall": 0.22753,
            "fmeasure": 0.252
        },
        "rougeL": {
            "precision": 0.54524,
            "recall": 0.38754,
            "fmeasure": 0.42744
        },
        "rougeLsum": {
            "precision": 0.54524,
            "recall": 0.38754,
            "fmeasure": 0.42744
        },
        "bleu": 28.06901,
        "meteor": 0.28695776508533166,
        "bertscore": {
            "precision": 0.86956,
            "recall": 0.84483,
            "f1": 0.85513
        },
        "nubia": {
            "semantic_relation": 3.34346,
            "contradiction": 23.78687,
            "irrelevancy": 57.45117,
            "logical_agreement": 18.76196,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.14949,
            "nubia_score": 0.46809
        },
        "bleurt": -0.27481
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.944797625754069,
        "rouge1": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.94444,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.73925,
            "contradiction": 0.27952,
            "irrelevancy": 59.63412,
            "logical_agreement": 40.08636,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.19529,
            "nubia_score": 0.89159
        },
        "bleurt": 0.56963
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "nist": 2.181323233007252,
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.61111,
            "fmeasure": 0.52943
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.16566,
            "fmeasure": 0.14178
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.38194,
            "fmeasure": 0.3309
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.38194,
            "fmeasure": 0.3309
        },
        "bleu": 11.26871,
        "meteor": 0.2976796296412124,
        "bertscore": {
            "precision": 0.85993,
            "recall": 0.86904,
            "f1": 0.85878
        },
        "nubia": {
            "semantic_relation": 3.96457,
            "contradiction": 0.81973,
            "irrelevancy": 23.50819,
            "logical_agreement": 75.67208,
            "grammar_ref": 5.53377,
            "grammar_hyp": 4.61178,
            "nubia_score": 0.72333
        },
        "bleurt": -0.24077
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nist": 3.55640580371446,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.59903,
            "fmeasure": 0.6595
        },
        "rouge2": {
            "precision": 0.35556,
            "recall": 0.26768,
            "fmeasure": 0.30163
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.33445,
            "fmeasure": 0.36546
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.33445,
            "fmeasure": 0.36546
        },
        "bleu": 39.84681,
        "meteor": 0.2774384877363323,
        "bertscore": {
            "precision": 0.86562,
            "recall": 0.84284,
            "f1": 0.85408
        },
        "nubia": {
            "semantic_relation": 3.09413,
            "contradiction": 2.64481,
            "irrelevancy": 64.71694,
            "logical_agreement": 32.63825,
            "grammar_ref": 4.61776,
            "grammar_hyp": 3.5821,
            "nubia_score": 0.49502
        },
        "bleurt": -0.44029
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.5,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 4.862575937540274,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.038834449092938005,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9310344827586207,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.720049960644813,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.04505465518404477,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.8846153846153846
        },
        "nist": 4.619901295721799,
        "rouge1": {
            "precision": 0.92063,
            "recall": 0.87067,
            "fmeasure": 0.89282
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.78139,
            "fmeasure": 0.79036
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.70158,
            "fmeasure": 0.70772
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.70158,
            "fmeasure": 0.70772
        },
        "bleu": 63.34013,
        "meteor": 0.4729401024828698,
        "bertscore": {
            "precision": 0.95825,
            "recall": 0.94144,
            "f1": 0.94786
        },
        "nubia": {
            "semantic_relation": 4.40444,
            "contradiction": 1.43244,
            "irrelevancy": 1.39514,
            "logical_agreement": 97.17242,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.61623,
            "nubia_score": 0.77079
        },
        "bleurt": 0.5013
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.440636352673264,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.21361197172017118,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8846153846153846,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.440636352673264,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.21361197172017118,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.058893689053568274,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3,
            "3": 0.6666666666666666
        },
        "nist": 2.1269412788981175,
        "rouge1": {
            "precision": 0.52564,
            "recall": 0.56174,
            "fmeasure": 0.54288
        },
        "rouge2": {
            "precision": 0.18667,
            "recall": 0.25408,
            "fmeasure": 0.21202
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.33855,
            "fmeasure": 0.32226
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.33855,
            "fmeasure": 0.32226
        },
        "bleu": 6.39477,
        "meteor": 0.2986978248304982,
        "bertscore": {
            "precision": 0.8606,
            "recall": 0.86896,
            "f1": 0.8624
        },
        "nubia": {
            "semantic_relation": 4.30514,
            "contradiction": 0.05074,
            "irrelevancy": 99.18436,
            "logical_agreement": 0.7649,
            "grammar_ref": 4.57081,
            "grammar_hyp": 3.58424,
            "nubia_score": 0.75968
        },
        "bleurt": 0.1178
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.6875,
        "vocab_size-1": 22,
        "unique-1": 15,
        "entropy-1": 4.2621987351738495,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 28,
        "unique-2": 26,
        "entropy-2": 4.773557262275186,
        "cond_entropy-2": 0.4938786114230791,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": 0.043321469306228495,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.186569246460625,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.664497779200463,
        "cond_entropy-2-nopunct": 0.5293800576789717,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8666666666666667,
            "3": 0.75
        },
        "nist": 4.773164941685649,
        "rouge1": {
            "precision": 0.77451,
            "recall": 0.8127,
            "fmeasure": 0.78825
        },
        "rouge2": {
            "precision": 0.63702,
            "recall": 0.65696,
            "fmeasure": 0.64222
        },
        "rougeL": {
            "precision": 0.77451,
            "recall": 0.8127,
            "fmeasure": 0.78825
        },
        "rougeLsum": {
            "precision": 0.77451,
            "recall": 0.8127,
            "fmeasure": 0.78825
        },
        "bleu": 65.40788,
        "meteor": 0.47170239090155236,
        "bertscore": {
            "precision": 0.97328,
            "recall": 0.96878,
            "f1": 0.96219
        },
        "nubia": {
            "semantic_relation": 3.87452,
            "contradiction": 50.03233,
            "irrelevancy": 0.51592,
            "logical_agreement": 49.45175,
            "grammar_ref": 4.13759,
            "grammar_hyp": 3.87961,
            "nubia_score": 0.69235
        },
        "bleurt": 0.58584
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.905124837953327,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.5757575757575758,
        "vocab_size-1": 38,
        "unique-1": 24,
        "entropy-1": 4.889260316971677,
        "distinct-2": 0.7903225806451613,
        "vocab_size-2": 49,
        "unique-2": 36,
        "entropy-2": 5.534841471677197,
        "cond_entropy-2": 0.6434141822439706,
        "distinct-3": 0.7931034482758621,
        "vocab_size-3": 46,
        "unique-3": 34,
        "entropy-3": 5.444187891679293,
        "cond_entropy-3": -0.06173255663861324,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 4.264680527307995,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5873015873015873,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.842614154367154,
        "distinct-2-nopunct": 0.7796610169491526,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.4419650832601425,
        "cond_entropy-2-nopunct": 0.6593282691731795,
        "distinct-3-nopunct": 0.7818181818181819,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 5.344996077161022,
        "cond_entropy-3-nopunct": -0.08310151765536346,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7843137254901961
        },
        "nist": 4.152266867716938,
        "rouge1": {
            "precision": 0.76525,
            "recall": 0.77203,
            "fmeasure": 0.76156
        },
        "rouge2": {
            "precision": 0.63294,
            "recall": 0.64162,
            "fmeasure": 0.63056
        },
        "rougeL": {
            "precision": 0.75388,
            "recall": 0.76013,
            "fmeasure": 0.74994
        },
        "rougeLsum": {
            "precision": 0.75388,
            "recall": 0.76013,
            "fmeasure": 0.74994
        },
        "bleu": 53.36148,
        "meteor": 0.420605758158709,
        "bertscore": {
            "precision": 0.93497,
            "recall": 0.9468,
            "f1": 0.9405
        },
        "nubia": {
            "semantic_relation": 3.82689,
            "contradiction": 48.57502,
            "irrelevancy": 10.8651,
            "logical_agreement": 40.55988,
            "grammar_ref": 3.98368,
            "grammar_hyp": 4.12275,
            "nubia_score": 0.6201
        },
        "bleurt": 0.40816
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8666666666666667
        },
        "nist": 2.7910011142063147,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.4902,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "bleu": 33.40891,
        "meteor": 0.424582730950162,
        "bertscore": {
            "precision": 0.96668,
            "recall": 0.9373,
            "f1": 0.95176
        },
        "nubia": {
            "semantic_relation": 4.98459,
            "contradiction": 0.13212,
            "irrelevancy": 0.41925,
            "logical_agreement": 99.44863,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.453,
            "nubia_score": 0.98464
        },
        "bleurt": 0.50996
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.709235782687254,
        "rouge1": {
            "precision": 0.82051,
            "recall": 0.82051,
            "fmeasure": 0.82051
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.67778,
            "fmeasure": 0.65657
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.77622,
            "fmeasure": 0.73077
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.77622,
            "fmeasure": 0.73077
        },
        "bleu": 73.76993,
        "meteor": 0.5205559484776897,
        "bertscore": {
            "precision": 0.93851,
            "recall": 0.9602,
            "f1": 0.93501
        },
        "nubia": {
            "semantic_relation": 4.80287,
            "contradiction": 0.54415,
            "irrelevancy": 18.10238,
            "logical_agreement": 81.35347,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.36386,
            "nubia_score": 0.91113
        },
        "bleurt": 0.42437
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 2.3648189689631285,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.84175,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.39167,
            "fmeasure": 0.34242
        },
        "rougeL": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "bleu": 10.88697,
        "meteor": 0.37885739133291024,
        "bertscore": {
            "precision": 0.87464,
            "recall": 0.91728,
            "f1": 0.89545
        },
        "nubia": {
            "semantic_relation": 4.05623,
            "contradiction": 3.3209,
            "irrelevancy": 92.48141,
            "logical_agreement": 4.19768,
            "grammar_ref": 6.0554,
            "grammar_hyp": 5.98883,
            "nubia_score": 0.50759
        },
        "bleurt": -0.38963
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "nist": 1.5492179020951657,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.52564,
            "fmeasure": 0.62714
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.40598,
            "fmeasure": 0.49206
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.52564,
            "fmeasure": 0.62714
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.52564,
            "fmeasure": 0.62714
        },
        "bleu": 31.12878,
        "meteor": 0.2991390203477699,
        "bertscore": {
            "precision": 0.93927,
            "recall": 0.87081,
            "f1": 0.90374
        },
        "nubia": {
            "semantic_relation": 3.49514,
            "contradiction": 0.61993,
            "irrelevancy": 0.79676,
            "logical_agreement": 98.58332,
            "grammar_ref": 5.35534,
            "grammar_hyp": 5.67203,
            "nubia_score": 0.49332
        },
        "bleurt": -0.05673
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 13,
        "unique-1": 10,
        "entropy-1": 3.5724694587701364,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.4597176276348775,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.452819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.4238830957527497,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "nist": 1.4445275803277893,
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.55443,
            "fmeasure": 0.65769
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.44567,
            "fmeasure": 0.53297
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.38384,
            "fmeasure": 0.45532
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.38384,
            "fmeasure": 0.45532
        },
        "bleu": 29.41656,
        "meteor": 0.28624390674733835,
        "bertscore": {
            "precision": 0.89349,
            "recall": 0.84932,
            "f1": 0.87084
        },
        "nubia": {
            "semantic_relation": 3.54179,
            "contradiction": 2.50144,
            "irrelevancy": 1.06051,
            "logical_agreement": 96.43805,
            "grammar_ref": 5.07625,
            "grammar_hyp": 4.69366,
            "nubia_score": 0.52555
        },
        "bleurt": -0.19939
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nist": 3.898626692302749,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.371,
            "irrelevancy": 0.46802,
            "logical_agreement": 99.16099,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.2666,
            "nubia_score": 1.0
        },
        "bleurt": 0.90186
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 4.0,
        "median_pred_length": 21.0,
        "min_pred_length": 17,
        "max_pred_length": 25,
        "distinct-1": 0.5714285714285714,
        "vocab_size-1": 24,
        "unique-1": 13,
        "entropy-1": 4.397687958235492,
        "distinct-2": 0.65,
        "vocab_size-2": 26,
        "unique-2": 16,
        "entropy-2": 4.546439344671015,
        "cond_entropy-2": 0.19848285966268867,
        "distinct-3": 0.6842105263157895,
        "vocab_size-3": 26,
        "unique-3": 17,
        "entropy-3": 4.556752184325417,
        "cond_entropy-3": 0.051128037034209234,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5675675675675675,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.1885226220933465,
        "distinct-2-nopunct": 0.6571428571428571,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.35729587384057,
        "cond_entropy-2-nopunct": 0.22711215137783008,
        "distinct-3-nopunct": 0.696969696969697,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.369707376737533,
        "cond_entropy-3-nopunct": 0.0591986024790465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.6
        },
        "nist": 3.22431575701425,
        "rouge1": {
            "precision": 0.62092,
            "recall": 0.69964,
            "fmeasure": 0.65556
        },
        "rouge2": {
            "precision": 0.35539,
            "recall": 0.44859,
            "fmeasure": 0.39576
        },
        "rougeL": {
            "precision": 0.47603,
            "recall": 0.56227,
            "fmeasure": 0.5138
        },
        "rougeLsum": {
            "precision": 0.47603,
            "recall": 0.56227,
            "fmeasure": 0.5138
        },
        "bleu": 24.36335,
        "meteor": 0.3574580110799593,
        "bertscore": {
            "precision": 0.88752,
            "recall": 0.87763,
            "f1": 0.88044
        },
        "nubia": {
            "semantic_relation": 4.44161,
            "contradiction": 16.36119,
            "irrelevancy": 18.69192,
            "logical_agreement": 64.9469,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.14107,
            "nubia_score": 0.89754
        },
        "bleurt": -0.11896
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 5.0,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.378783493486177,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660255,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.315824333525706,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.2178561159133974,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.03462179117476821,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.56
        },
        "nist": 3.1671178219234912,
        "rouge1": {
            "precision": 0.84491,
            "recall": 0.75,
            "fmeasure": 0.77132
        },
        "rouge2": {
            "precision": 0.69328,
            "recall": 0.66468,
            "fmeasure": 0.65758
        },
        "rougeL": {
            "precision": 0.77083,
            "recall": 0.71182,
            "fmeasure": 0.72056
        },
        "rougeLsum": {
            "precision": 0.77083,
            "recall": 0.71182,
            "fmeasure": 0.72056
        },
        "bleu": 34.30741,
        "meteor": 0.3367066898716941,
        "bertscore": {
            "precision": 0.96038,
            "recall": 0.92501,
            "f1": 0.94198
        },
        "nubia": {
            "semantic_relation": 4.24165,
            "contradiction": 0.18932,
            "irrelevancy": 72.5496,
            "logical_agreement": 27.26108,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.63342,
            "nubia_score": 0.79268
        },
        "bleurt": 0.25584
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.775,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.7439427079182686,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.38386386470375694,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.6871792978845495,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.3057541296022394,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.75
        },
        "nist": 4.242179964910005,
        "rouge1": {
            "precision": 0.83754,
            "recall": 0.76852,
            "fmeasure": 0.78513
        },
        "rouge2": {
            "precision": 0.60707,
            "recall": 0.56665,
            "fmeasure": 0.57211
        },
        "rougeL": {
            "precision": 0.72811,
            "recall": 0.66944,
            "fmeasure": 0.68196
        },
        "rougeLsum": {
            "precision": 0.72811,
            "recall": 0.66944,
            "fmeasure": 0.68196
        },
        "bleu": 39.18488,
        "meteor": 0.42015842725746666,
        "bertscore": {
            "precision": 0.93241,
            "recall": 0.93043,
            "f1": 0.92663
        },
        "nubia": {
            "semantic_relation": 3.93149,
            "contradiction": 0.63777,
            "irrelevancy": 60.82171,
            "logical_agreement": 38.54053,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.3124,
            "nubia_score": 0.66773
        },
        "bleurt": 0.15108
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.090634124990776,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "bleu": 76.11606,
        "meteor": 0.5715186082473627,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        },
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "bleurt": 0.48581
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.482634504257068,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2983,
            "irrelevancy": 0.53829,
            "logical_agreement": 99.16341,
            "grammar_ref": 5.3705,
            "grammar_hyp": 5.33734,
            "nubia_score": 0.99191
        },
        "bleurt": 0.76845
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.152391277629865,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.25454711376829514,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.152391277629865,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.25454711376829514,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6190476190476191
        },
        "nist": 0.8609984582018549,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.6108,
            "fmeasure": 0.6998
        },
        "rouge2": {
            "precision": 0.68254,
            "recall": 0.49573,
            "fmeasure": 0.56998
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.6108,
            "fmeasure": 0.6998
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.6108,
            "fmeasure": 0.6998
        },
        "bleu": 34.9745,
        "meteor": 0.36326014662776723,
        "bertscore": {
            "precision": 0.9461,
            "recall": 0.8919,
            "f1": 0.9182
        },
        "nubia": {
            "semantic_relation": 2.67397,
            "contradiction": 97.6144,
            "irrelevancy": 2.04844,
            "logical_agreement": 0.33716,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.88559,
            "nubia_score": 0.19922
        },
        "bleurt": -0.13726
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "nist": 4.3901903858606435,
        "rouge1": {
            "precision": 0.75556,
            "recall": 0.84444,
            "fmeasure": 0.79111
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.56614,
            "fmeasure": 0.52588
        },
        "rougeL": {
            "precision": 0.71111,
            "recall": 0.8,
            "fmeasure": 0.74667
        },
        "rougeLsum": {
            "precision": 0.71111,
            "recall": 0.8,
            "fmeasure": 0.74667
        },
        "bleu": 47.38611,
        "meteor": 0.45940402833353244,
        "bertscore": {
            "precision": 0.96037,
            "recall": 0.95405,
            "f1": 0.9572
        },
        "nubia": {
            "semantic_relation": 4.53868,
            "contradiction": 1.21641,
            "irrelevancy": 45.90237,
            "logical_agreement": 52.88122,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.1422,
            "nubia_score": 0.73832
        },
        "bleurt": 0.30575
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.23529411764705882
        },
        "nist": 0.23714726374929274,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.31357,
            "fmeasure": 0.3963
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.28139,
            "fmeasure": 0.36007
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.31357,
            "fmeasure": 0.3963
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.31357,
            "fmeasure": 0.3963
        },
        "bleu": 15.95195,
        "meteor": 0.16770542764783455,
        "bertscore": {
            "precision": 0.87903,
            "recall": 0.81542,
            "f1": 0.84604
        },
        "nubia": {
            "semantic_relation": 2.88761,
            "contradiction": 77.78286,
            "irrelevancy": 21.34026,
            "logical_agreement": 0.87689,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.65259,
            "nubia_score": 0.36741
        },
        "bleurt": -0.24908
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857,
            "3": 1.0
        },
        "nist": 2.8204580279315103,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.72365,
            "fmeasure": 0.72311
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.34722,
            "fmeasure": 0.37162
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63248,
            "fmeasure": 0.67429
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63248,
            "fmeasure": 0.67429
        },
        "bleu": 48.32698,
        "meteor": 0.37194330680678134,
        "bertscore": {
            "precision": 0.93117,
            "recall": 0.90925,
            "f1": 0.92008
        },
        "nubia": {
            "semantic_relation": 4.58758,
            "contradiction": 0.13568,
            "irrelevancy": 0.81852,
            "logical_agreement": 99.0458,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.82569,
            "nubia_score": 0.87078
        },
        "bleurt": 0.43562
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 6.103277807866851,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 50,
        "unique-1": 43,
        "entropy-1": 5.569103624400615,
        "distinct-2": 1.0,
        "vocab_size-2": 54,
        "unique-2": 54,
        "entropy-2": 5.7548875021634665,
        "cond_entropy-2": 0.11912872925811868,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.11103131238874385,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 6.103277807866851,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.532665279941246,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.643856189774728,
        "cond_entropy-2-nopunct": 0.12896868761125616,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.8,
            "3": 0.6444444444444445
        },
        "nist": 3.9301171517090907,
        "rouge1": {
            "precision": 0.74699,
            "recall": 0.75243,
            "fmeasure": 0.74438
        },
        "rouge2": {
            "precision": 0.46446,
            "recall": 0.43965,
            "fmeasure": 0.44852
        },
        "rougeL": {
            "precision": 0.63011,
            "recall": 0.61729,
            "fmeasure": 0.61981
        },
        "rougeLsum": {
            "precision": 0.63011,
            "recall": 0.61729,
            "fmeasure": 0.61981
        },
        "bleu": 37.69411,
        "meteor": 0.3953770817206697,
        "bertscore": {
            "precision": 0.91787,
            "recall": 0.90681,
            "f1": 0.91092
        },
        "nubia": {
            "semantic_relation": 4.3526,
            "contradiction": 0.37271,
            "irrelevancy": 39.97949,
            "logical_agreement": 59.6478,
            "grammar_ref": 4.34153,
            "grammar_hyp": 4.98134,
            "nubia_score": 0.72919
        },
        "bleurt": 0.23337
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.7557427659075784,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.625,
            "fmeasure": 0.58824
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "bleu": 18.55329,
        "meteor": 0.375492664465321,
        "bertscore": {
            "precision": 0.96197,
            "recall": 0.94041,
            "f1": 0.94986
        },
        "nubia": {
            "semantic_relation": 4.93198,
            "contradiction": 0.24987,
            "irrelevancy": 0.47729,
            "logical_agreement": 99.27284,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.96887,
            "nubia_score": 0.98236
        },
        "bleurt": 0.6057
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 2.8284271247461903,
        "median_pred_length": 22.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.6333333333333333,
        "vocab_size-1": 38,
        "unique-1": 25,
        "entropy-1": 4.9882336709624555,
        "distinct-2": 0.9122807017543859,
        "vocab_size-2": 52,
        "unique-2": 47,
        "entropy-2": 5.657451417673508,
        "cond_entropy-2": 0.5953613693299363,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 52,
        "unique-3": 50,
        "entropy-3": 5.680813428089393,
        "cond_entropy-3": 0.03310859910983803,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6792452830188679,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.944717152594763,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.483856189774728,
        "cond_entropy-2-nopunct": 0.5861312352980642,
        "distinct-3-nopunct": 0.9787234042553191,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.512035660188278,
        "cond_entropy-3-nopunct": 0.038392236370997854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.42857142857142855,
            "3": 0.6756756756756757
        },
        "nist": 3.3598261908674085,
        "rouge1": {
            "precision": 0.6368,
            "recall": 0.70505,
            "fmeasure": 0.66711
        },
        "rouge2": {
            "precision": 0.48433,
            "recall": 0.54021,
            "fmeasure": 0.5091
        },
        "rougeL": {
            "precision": 0.54466,
            "recall": 0.60952,
            "fmeasure": 0.57381
        },
        "rougeLsum": {
            "precision": 0.54466,
            "recall": 0.60952,
            "fmeasure": 0.57381
        },
        "bleu": 33.03701,
        "meteor": 0.34510402310548877,
        "bertscore": {
            "precision": 0.87724,
            "recall": 0.86971,
            "f1": 0.87336
        },
        "nubia": {
            "semantic_relation": 3.79953,
            "contradiction": 17.35793,
            "irrelevancy": 27.22122,
            "logical_agreement": 55.42085,
            "grammar_ref": 4.591,
            "grammar_hyp": 3.94572,
            "nubia_score": 0.68101
        },
        "bleurt": 0.03338
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.65,
        "msttr-100_nopunct": NaN,
        "total_length": 101,
        "mean_pred_length": 16.833333333333332,
        "std_pred_length": 3.975620147292188,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.6435643564356436,
        "vocab_size-1": 65,
        "unique-1": 47,
        "entropy-1": 5.7089609581881495,
        "distinct-2": 0.8315789473684211,
        "vocab_size-2": 79,
        "unique-2": 63,
        "entropy-2": 6.23301350306779,
        "cond_entropy-2": 0.4207444200696826,
        "distinct-3": 0.8539325842696629,
        "vocab_size-3": 76,
        "unique-3": 63,
        "entropy-3": 6.183598599505732,
        "cond_entropy-3": -0.049178357139830875,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.1622776601683795,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.727909901861184,
        "distinct-2-nopunct": 0.8452380952380952,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 6.0827936132549505,
        "cond_entropy-2-nopunct": 0.38564155861769855,
        "distinct-3-nopunct": 0.8717948717948718,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 6.028991962451999,
        "cond_entropy-3-nopunct": -0.055633152634460614,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35,
            "2": 0.55,
            "3": 0.7741935483870968
        },
        "nist": 5.3031931562601216,
        "rouge1": {
            "precision": 0.76497,
            "recall": 0.82038,
            "fmeasure": 0.78836
        },
        "rouge2": {
            "precision": 0.59848,
            "recall": 0.63975,
            "fmeasure": 0.61546
        },
        "rougeL": {
            "precision": 0.67711,
            "recall": 0.7432,
            "fmeasure": 0.70617
        },
        "rougeLsum": {
            "precision": 0.67711,
            "recall": 0.7432,
            "fmeasure": 0.70617
        },
        "bleu": 44.69776,
        "meteor": 0.4442359986353882,
        "bertscore": {
            "precision": 0.92901,
            "recall": 0.93006,
            "f1": 0.92547
        },
        "nubia": {
            "semantic_relation": 4.50249,
            "contradiction": 3.71746,
            "irrelevancy": 42.12573,
            "logical_agreement": 54.15681,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.11672,
            "nubia_score": 0.85593
        },
        "bleurt": 0.27259
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 1.9527842367379504,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.80513,
            "fmeasure": 0.874
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.75926,
            "fmeasure": 0.82745
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.80513,
            "fmeasure": 0.874
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.80513,
            "fmeasure": 0.874
        },
        "bleu": 89.48393,
        "meteor": 0.5511535195670813,
        "bertscore": {
            "precision": 0.97989,
            "recall": 0.96276,
            "f1": 0.97125
        },
        "nubia": {
            "semantic_relation": 3.95615,
            "contradiction": 0.28345,
            "irrelevancy": 0.52465,
            "logical_agreement": 99.1919,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.30028,
            "nubia_score": 0.72506
        },
        "bleurt": 0.304
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.75
        },
        "nist": 1.9438230237901655,
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.65833,
            "fmeasure": 0.74817
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.52632,
            "fmeasure": 0.64516
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.54167,
            "fmeasure": 0.61581
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.54167,
            "fmeasure": 0.61581
        },
        "bleu": 53.47161,
        "meteor": 0.3970655806086951,
        "bertscore": {
            "precision": 0.95582,
            "recall": 0.92292,
            "f1": 0.93908
        },
        "nubia": {
            "semantic_relation": 4.65753,
            "contradiction": 0.28054,
            "irrelevancy": 0.47929,
            "logical_agreement": 99.24018,
            "grammar_ref": 3.95052,
            "grammar_hyp": 4.96557,
            "nubia_score": 0.82061
        },
        "bleurt": 0.42696
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.040223928941851936,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.773557262275186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.5,
            "3": 0.92
        },
        "nist": 4.536626171301248,
        "rouge1": {
            "precision": 0.8663,
            "recall": 0.87979,
            "fmeasure": 0.87288
        },
        "rouge2": {
            "precision": 0.61667,
            "recall": 0.62368,
            "fmeasure": 0.62009
        },
        "rougeL": {
            "precision": 0.74725,
            "recall": 0.75678,
            "fmeasure": 0.7519
        },
        "rougeLsum": {
            "precision": 0.74725,
            "recall": 0.75678,
            "fmeasure": 0.7519
        },
        "bleu": 43.8321,
        "meteor": 0.4349194945887192,
        "bertscore": {
            "precision": 0.9644,
            "recall": 0.96611,
            "f1": 0.96525
        },
        "nubia": {
            "semantic_relation": 4.69297,
            "contradiction": 0.41697,
            "irrelevancy": 2.71071,
            "logical_agreement": 96.87231,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.4463,
            "nubia_score": 0.91345
        },
        "bleurt": 0.55196
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518528,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.3644688753708625,
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.92857,
            "fmeasure": 0.92857
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.80952,
            "fmeasure": 0.80952
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.80952,
            "fmeasure": 0.80952
        },
        "bleu": 57.34952,
        "meteor": 0.4880727997863187,
        "bertscore": {
            "precision": 0.96953,
            "recall": 0.98034,
            "f1": 0.97491
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.53626,
            "irrelevancy": 3.49148,
            "logical_agreement": 95.97226,
            "grammar_ref": 4.18993,
            "grammar_hyp": 3.95279,
            "nubia_score": 0.99042
        },
        "bleurt": 0.66005
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.8708286933869707,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 13,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 29,
        "entropy-1": 4.781687083026442,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.22604247528930613,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.16992500144231223,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.8708286933869707,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.791879432707955,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.2553762633838381,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.1926450779423958,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4,
            "3": 0.76
        },
        "nist": 4.2612252119893235,
        "rouge1": {
            "precision": 0.71247,
            "recall": 0.67937,
            "fmeasure": 0.69368
        },
        "rouge2": {
            "precision": 0.46077,
            "recall": 0.43398,
            "fmeasure": 0.44574
        },
        "rougeL": {
            "precision": 0.65691,
            "recall": 0.63214,
            "fmeasure": 0.64251
        },
        "rougeLsum": {
            "precision": 0.65691,
            "recall": 0.63214,
            "fmeasure": 0.64251
        },
        "bleu": 50.22085,
        "meteor": 0.39890273206501947,
        "bertscore": {
            "precision": 0.93709,
            "recall": 0.93486,
            "f1": 0.93507
        },
        "nubia": {
            "semantic_relation": 4.29336,
            "contradiction": 0.23243,
            "irrelevancy": 50.15224,
            "logical_agreement": 49.61533,
            "grammar_ref": 4.98306,
            "grammar_hyp": 5.44632,
            "nubia_score": 0.73599
        },
        "bleurt": 0.44136
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.7931034482758621,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.444187891679296,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 25,
        "unique-2": 23,
        "entropy-2": 4.606739354015323,
        "cond_entropy-2": 0.11912872925811885,
        "distinct-3": 0.96,
        "vocab_size-3": 24,
        "unique-3": 23,
        "entropy-3": 4.5638561897747225,
        "cond_entropy-3": -0.03103131238874396,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.3845171317931,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.4838561897747224,
        "cond_entropy-2-nopunct": 0.08896868761125602,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.436605434317882,
        "cond_entropy-3-nopunct": -0.07681597284814654,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "nist": 3.4812760429245895,
        "rouge1": {
            "precision": 0.76471,
            "recall": 0.83791,
            "fmeasure": 0.79677
        },
        "rouge2": {
            "precision": 0.61458,
            "recall": 0.6337,
            "fmeasure": 0.62337
        },
        "rougeL": {
            "precision": 0.7549,
            "recall": 0.79524,
            "fmeasure": 0.77352
        },
        "rougeLsum": {
            "precision": 0.7549,
            "recall": 0.79524,
            "fmeasure": 0.77352
        },
        "bleu": 52.42734,
        "meteor": 0.42232840091189033,
        "bertscore": {
            "precision": 0.92725,
            "recall": 0.93597,
            "f1": 0.93157
        },
        "nubia": {
            "semantic_relation": 4.79162,
            "contradiction": 0.22034,
            "irrelevancy": 15.01106,
            "logical_agreement": 84.7686,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.41877,
            "nubia_score": 0.91734
        },
        "bleurt": 0.65109
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.0,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.9,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.681727678869737,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.07028173724063808,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.6375375112660535,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.0759650846282366,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.8,
            "3": 0.64
        },
        "nist": 4.266784948714657,
        "rouge1": {
            "precision": 0.78519,
            "recall": 0.73603,
            "fmeasure": 0.75702
        },
        "rouge2": {
            "precision": 0.50109,
            "recall": 0.4838,
            "fmeasure": 0.49069
        },
        "rougeL": {
            "precision": 0.67407,
            "recall": 0.64108,
            "fmeasure": 0.65395
        },
        "rougeLsum": {
            "precision": 0.67407,
            "recall": 0.64108,
            "fmeasure": 0.65395
        },
        "bleu": 40.96365,
        "meteor": 0.3610037998694073,
        "bertscore": {
            "precision": 0.93469,
            "recall": 0.92412,
            "f1": 0.92521
        },
        "nubia": {
            "semantic_relation": 4.48895,
            "contradiction": 49.93548,
            "irrelevancy": 0.37126,
            "logical_agreement": 49.69326,
            "grammar_ref": 4.18803,
            "grammar_hyp": 3.83127,
            "nubia_score": 0.85668
        },
        "bleurt": 0.42498
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1699250014423126,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "bleurt": 0.99428
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.5909090909090909,
        "vocab_size-1": 13,
        "unique-1": 5,
        "entropy-1": 3.6069367321753214,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.2002408513582384,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 15,
        "unique-3": 12,
        "entropy-3": 3.8365916681089787,
        "cond_entropy-3": 0.07021912877717246,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.484183719779189,
        "distinct-2-nopunct": 0.7222222222222222,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.6143694458867563,
        "cond_entropy-2-nopunct": 0.22326843445292066,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": 0.08007499855768763,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 3.230079466649772,
        "rouge1": {
            "precision": 0.88333,
            "recall": 0.73625,
            "fmeasure": 0.79848
        },
        "rouge2": {
            "precision": 0.62963,
            "recall": 0.52153,
            "fmeasure": 0.56708
        },
        "rougeL": {
            "precision": 0.81667,
            "recall": 0.68634,
            "fmeasure": 0.74204
        },
        "rougeLsum": {
            "precision": 0.81667,
            "recall": 0.68634,
            "fmeasure": 0.74204
        },
        "bleu": 51.27433,
        "meteor": 0.47136021973086945,
        "bertscore": {
            "precision": 0.97594,
            "recall": 0.96355,
            "f1": 0.96971
        },
        "nubia": {
            "semantic_relation": 4.91042,
            "contradiction": 0.31934,
            "irrelevancy": 0.58738,
            "logical_agreement": 99.09328,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.76507,
            "nubia_score": 0.96575
        },
        "bleurt": 0.48843
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.96,
        "vocab_size-1": 24,
        "unique-1": 23,
        "entropy-1": 4.5638561897747225,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.024439644279765072,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.39231742277876,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.07038932789139804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nist": 4.310869332791932,
        "rouge1": {
            "precision": 0.84127,
            "recall": 0.89825,
            "fmeasure": 0.8687
        },
        "rouge2": {
            "precision": 0.71667,
            "recall": 0.76706,
            "fmeasure": 0.74089
        },
        "rougeL": {
            "precision": 0.79365,
            "recall": 0.84737,
            "fmeasure": 0.81951
        },
        "rougeLsum": {
            "precision": 0.79365,
            "recall": 0.84737,
            "fmeasure": 0.81951
        },
        "bleu": 70.49307,
        "meteor": 0.5015044211827853,
        "bertscore": {
            "precision": 0.95685,
            "recall": 0.971,
            "f1": 0.96387
        },
        "nubia": {
            "semantic_relation": 3.86371,
            "contradiction": 86.5631,
            "irrelevancy": 12.22021,
            "logical_agreement": 1.21669,
            "grammar_ref": 3.98302,
            "grammar_hyp": 4.17369,
            "nubia_score": 0.57928
        },
        "bleurt": 0.09732
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.1625371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.6402239289418516,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.11475004073479993,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.3684210526315789
        },
        "nist": 1.1189083611939228,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.44796,
            "fmeasure": 0.50855
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.14069,
            "fmeasure": 0.16074
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.22398,
            "fmeasure": 0.25427
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.22398,
            "fmeasure": 0.25427
        },
        "bleu": 4.94851,
        "meteor": 0.2544170918314956,
        "bertscore": {
            "precision": 0.8713,
            "recall": 0.844,
            "f1": 0.85743
        },
        "nubia": {
            "semantic_relation": 3.87169,
            "contradiction": 57.93507,
            "irrelevancy": 38.59443,
            "logical_agreement": 3.4705,
            "grammar_ref": 4.34096,
            "grammar_hyp": 5.33933,
            "nubia_score": 0.41166
        },
        "bleurt": 0.15026
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 8.0,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.683542362433229,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838574,
        "cond_entropy-2": 0.3148841634647017,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.0249628412503394,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8064516129032258,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.51839711669891,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.24601959865813777,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.14285714285714285,
            "3": 0.8571428571428571
        },
        "nist": 4.630427911448185,
        "rouge1": {
            "precision": 0.78704,
            "recall": 0.80694,
            "fmeasure": 0.79584
        },
        "rouge2": {
            "precision": 0.51838,
            "recall": 0.53414,
            "fmeasure": 0.52546
        },
        "rougeL": {
            "precision": 0.46296,
            "recall": 0.49491,
            "fmeasure": 0.47758
        },
        "rougeLsum": {
            "precision": 0.46296,
            "recall": 0.49491,
            "fmeasure": 0.47758
        },
        "bleu": 50.36366,
        "meteor": 0.4583834672344512,
        "bertscore": {
            "precision": 0.93154,
            "recall": 0.93847,
            "f1": 0.93498
        },
        "nubia": {
            "semantic_relation": 4.69864,
            "contradiction": 12.89241,
            "irrelevancy": 2.29093,
            "logical_agreement": 84.81666,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.523,
            "nubia_score": 0.80358
        },
        "bleurt": 0.26948
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819113,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765365,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7222222222222222
        },
        "nist": 2.956599148311473,
        "rouge1": {
            "precision": 0.69841,
            "recall": 0.7218,
            "fmeasure": 0.70952
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.54127,
            "fmeasure": 0.54553
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.37518,
            "fmeasure": 0.378
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.37518,
            "fmeasure": 0.378
        },
        "bleu": 47.1548,
        "meteor": 0.3651492865615115,
        "bertscore": {
            "precision": 0.91468,
            "recall": 0.91371,
            "f1": 0.91419
        },
        "nubia": {
            "semantic_relation": 4.40507,
            "contradiction": 0.35496,
            "irrelevancy": 6.86532,
            "logical_agreement": 92.77971,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.37804,
            "nubia_score": 0.84109
        },
        "bleurt": -0.25382
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.8181818181818182
        },
        "nist": 3.301668508816657,
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "bleu": 51.3748,
        "meteor": 0.46254426713722036,
        "bertscore": {
            "precision": 0.96467,
            "recall": 0.93971,
            "f1": 0.95203
        },
        "nubia": {
            "semantic_relation": 4.87068,
            "contradiction": 0.11888,
            "irrelevancy": 92.77312,
            "logical_agreement": 7.108,
            "grammar_ref": 4.80739,
            "grammar_hyp": 4.43668,
            "nubia_score": 1.0
        },
        "bleurt": 0.71801
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064474,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.35294117647058826
        },
        "nist": 2.6330548099952993,
        "rouge1": {
            "precision": 0.48333,
            "recall": 0.40278,
            "fmeasure": 0.43939
        },
        "rouge2": {
            "precision": 0.21053,
            "recall": 0.18496,
            "fmeasure": 0.19683
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.37121,
            "fmeasure": 0.39971
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.37121,
            "fmeasure": 0.39971
        },
        "bleu": 9.56041,
        "meteor": 0.18574559250132655,
        "bertscore": {
            "precision": 0.80625,
            "recall": 0.7892,
            "f1": 0.79764
        },
        "nubia": {
            "semantic_relation": 3.60841,
            "contradiction": 0.06684,
            "irrelevancy": 98.73493,
            "logical_agreement": 1.19823,
            "grammar_ref": 3.8277,
            "grammar_hyp": 3.92992,
            "nubia_score": 0.60081
        },
        "bleurt": -0.13913
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 2.8284271247461903,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 24,
        "distinct-1": 0.4666666666666667,
        "vocab_size-1": 28,
        "unique-1": 16,
        "entropy-1": 4.415061012203069,
        "distinct-2": 0.6491228070175439,
        "vocab_size-2": 37,
        "unique-2": 25,
        "entropy-2": 4.990784751006844,
        "cond_entropy-2": 0.5840656467023099,
        "distinct-3": 0.7592592592592593,
        "vocab_size-3": 41,
        "unique-3": 34,
        "entropy-3": 5.162294909570876,
        "cond_entropy-3": 0.18125674725798605,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 18.666666666666668,
        "std_pred_length-nopunct": 3.7712361663282534,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.48214285714285715,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.351823225551768,
        "distinct-2-nopunct": 0.660377358490566,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.897731775317914,
        "cond_entropy-2-nopunct": 0.5307513816166256,
        "distinct-3-nopunct": 0.76,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.043856189774726,
        "cond_entropy-3-nopunct": 0.1159357352115254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.8333333333333334,
            "3": 0.5526315789473685
        },
        "nist": 3.3471553853138545,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.62432,
            "fmeasure": 0.59638
        },
        "rouge2": {
            "precision": 0.36876,
            "recall": 0.40705,
            "fmeasure": 0.38177
        },
        "rougeL": {
            "precision": 0.52315,
            "recall": 0.5709,
            "fmeasure": 0.54021
        },
        "rougeLsum": {
            "precision": 0.52315,
            "recall": 0.5709,
            "fmeasure": 0.54021
        },
        "bleu": 36.88182,
        "meteor": 0.31293309710041645,
        "bertscore": {
            "precision": 0.85916,
            "recall": 0.84935,
            "f1": 0.85361
        },
        "nubia": {
            "semantic_relation": 3.46314,
            "contradiction": 3.56102,
            "irrelevancy": 67.97028,
            "logical_agreement": 28.46869,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.05023,
            "nubia_score": 0.50367
        },
        "bleurt": -0.52431
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.7291666666666666,
        "vocab_size-1": 35,
        "unique-1": 23,
        "entropy-1": 5.027569011092752,
        "distinct-2": 0.8444444444444444,
        "vocab_size-2": 38,
        "unique-2": 31,
        "entropy-2": 5.180741985218562,
        "cond_entropy-2": 0.08466837338629603,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 38,
        "unique-3": 34,
        "entropy-3": 5.201841232302571,
        "cond_entropy-3": 0.04332146930622846,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 4.189935029992178,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.775,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.871928094887363,
        "distinct-2-nopunct": 0.8648648648648649,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.939183095358683,
        "cond_entropy-2-nopunct": 0.07671445993077655,
        "distinct-3-nopunct": 0.9117647058823529,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.910992253015045,
        "cond_entropy-3-nopunct": -0.03375523026096319,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7241379310344828
        },
        "nist": 3.3624571139023716,
        "rouge1": {
            "precision": 0.64121,
            "recall": 0.70045,
            "fmeasure": 0.65476
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.28208,
            "fmeasure": 0.26135
        },
        "rougeL": {
            "precision": 0.47063,
            "recall": 0.48183,
            "fmeasure": 0.46575
        },
        "rougeLsum": {
            "precision": 0.47063,
            "recall": 0.48183,
            "fmeasure": 0.46575
        },
        "bleu": 12.03122,
        "meteor": 0.34880679526299085,
        "bertscore": {
            "precision": 0.91038,
            "recall": 0.91943,
            "f1": 0.9141
        },
        "nubia": {
            "semantic_relation": 4.06513,
            "contradiction": 13.97374,
            "irrelevancy": 67.10388,
            "logical_agreement": 18.92238,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.45801,
            "nubia_score": 0.65272
        },
        "bleurt": -0.01047
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 2.7109047337507373,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "bleu": 53.10725,
        "meteor": 0.5033950705050299,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        },
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "bleurt": 0.22576
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 1.2346185812310722,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.44444,
            "fmeasure": 0.37778
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.09091,
            "fmeasure": 0.09091
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.25,
            "fmeasure": 0.25
        },
        "bleu": 7.41049,
        "meteor": 0.17869724780849322,
        "bertscore": {
            "precision": 0.75639,
            "recall": 0.85486,
            "f1": 0.80261
        },
        "nubia": {
            "semantic_relation": 3.17725,
            "contradiction": 0.09981,
            "irrelevancy": 99.74809,
            "logical_agreement": 0.15211,
            "grammar_ref": 5.08958,
            "grammar_hyp": 4.17665,
            "nubia_score": 0.51606
        },
        "bleurt": -0.2397
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": -0.034621791174768185,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": -0.08750352374993502,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.8365916681089787,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.6530437207411035,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        },
        "bleurt": 0.9828
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.6458333333333334,
        "vocab_size-1": 31,
        "unique-1": 20,
        "entropy-1": 4.7618421881310145,
        "distinct-2": 0.8222222222222222,
        "vocab_size-2": 37,
        "unique-2": 31,
        "entropy-2": 5.091853096329674,
        "cond_entropy-2": 0.27922142898992847,
        "distinct-3": 0.8809523809523809,
        "vocab_size-3": 37,
        "unique-3": 32,
        "entropy-3": 5.154222184683524,
        "cond_entropy-3": 0.09094051692527608,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 1.247219128924647,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.675,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.553055907333276,
        "distinct-2-nopunct": 0.8108108108108109,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.77702093319652,
        "cond_entropy-2-nopunct": 0.24346918969948758,
        "distinct-3-nopunct": 0.8529411764705882,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.793345194191515,
        "cond_entropy-3-nopunct": 0.05448006385668387,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5263157894736842
        },
        "nist": 2.4694161552372482,
        "rouge1": {
            "precision": 0.59658,
            "recall": 0.48951,
            "fmeasure": 0.52055
        },
        "rouge2": {
            "precision": 0.30159,
            "recall": 0.23557,
            "fmeasure": 0.25299
        },
        "rougeL": {
            "precision": 0.52991,
            "recall": 0.45176,
            "fmeasure": 0.47235
        },
        "rougeLsum": {
            "precision": 0.52991,
            "recall": 0.45176,
            "fmeasure": 0.47235
        },
        "bleu": 10.04639,
        "meteor": 0.2540437964583844,
        "bertscore": {
            "precision": 0.87398,
            "recall": 0.83223,
            "f1": 0.85231
        },
        "nubia": {
            "semantic_relation": 3.19829,
            "contradiction": 11.72942,
            "irrelevancy": 47.95122,
            "logical_agreement": 40.31935,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.17768,
            "nubia_score": 0.4396
        },
        "bleurt": -0.25442
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 45,
        "unique-1": 42,
        "entropy-1": 5.366353960119797,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.19607133530042764,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.7416573867739413,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8958333333333334,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.301428324170393,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.20932705059600293,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.0995356735509143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.07692307692307693,
            "3": 0.7560975609756098
        },
        "nist": 3.397448092223018,
        "rouge1": {
            "precision": 0.75364,
            "recall": 0.68121,
            "fmeasure": 0.71106
        },
        "rouge2": {
            "precision": 0.51465,
            "recall": 0.47765,
            "fmeasure": 0.49227
        },
        "rougeL": {
            "precision": 0.57771,
            "recall": 0.5406,
            "fmeasure": 0.55554
        },
        "rougeLsum": {
            "precision": 0.57771,
            "recall": 0.5406,
            "fmeasure": 0.55554
        },
        "bleu": 39.51804,
        "meteor": 0.3664667231772902,
        "bertscore": {
            "precision": 0.92475,
            "recall": 0.90654,
            "f1": 0.91533
        },
        "nubia": {
            "semantic_relation": 3.62865,
            "contradiction": 7.90056,
            "irrelevancy": 57.4661,
            "logical_agreement": 34.63335,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.36055,
            "nubia_score": 0.55248
        },
        "bleurt": -0.0647
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.816496580927726,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 24,
        "unique-1": 16,
        "entropy-1": 4.476064195050471,
        "distinct-2": 0.8,
        "vocab_size-2": 24,
        "unique-2": 18,
        "entropy-2": 4.506890595608519,
        "cond_entropy-2": -0.07083685708326805,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 22,
        "unique-3": 17,
        "entropy-3": 4.384517131793101,
        "cond_entropy-3": -0.07792901937097599,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.440223928941853,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.310443057719026,
        "cond_entropy-2-nopunct": -0.07792901937097599,
        "distinct-3-nopunct": 0.7916666666666666,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.16829583405449,
        "cond_entropy-3-nopunct": -0.08659166810897906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.088015729955181,
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.83333,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.74074,
            "fmeasure": 0.7451
        },
        "rougeL": {
            "precision": 0.81481,
            "recall": 0.8,
            "fmeasure": 0.80702
        },
        "rougeLsum": {
            "precision": 0.81481,
            "recall": 0.8,
            "fmeasure": 0.80702
        },
        "bleu": 70.40724,
        "meteor": 0.4935212995985068,
        "bertscore": {
            "precision": 0.97106,
            "recall": 0.95591,
            "f1": 0.96329
        },
        "nubia": {
            "semantic_relation": 4.61906,
            "contradiction": 0.45756,
            "irrelevancy": 7.24989,
            "logical_agreement": 92.29256,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.86083,
            "nubia_score": 0.85237
        },
        "bleurt": 0.6945
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5384615384615384
        },
        "nist": 0.7562219259746819,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.41717,
            "fmeasure": 0.46667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.25397,
            "fmeasure": 0.28594
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.35758,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.35758,
            "fmeasure": 0.4
        },
        "bleu": 19.41226,
        "meteor": 0.24495880103709006,
        "bertscore": {
            "precision": 0.80328,
            "recall": 0.85098,
            "f1": 0.82644
        },
        "nubia": {
            "semantic_relation": 2.91241,
            "contradiction": 0.1078,
            "irrelevancy": 99.76149,
            "logical_agreement": 0.13072,
            "grammar_ref": 4.44297,
            "grammar_hyp": 5.46948,
            "nubia_score": 0.19276
        },
        "bleurt": -0.42801
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.69041575982343,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.7205882352941176,
        "vocab_size-1": 49,
        "unique-1": 35,
        "entropy-1": 5.458714495630292,
        "distinct-2": 0.953125,
        "vocab_size-2": 61,
        "unique-2": 58,
        "entropy-2": 5.90625,
        "cond_entropy-2": 0.36183227597096496,
        "distinct-3": 0.9833333333333333,
        "vocab_size-3": 59,
        "unique-3": 58,
        "entropy-3": 5.873557262275184,
        "cond_entropy-3": -0.02644273772481477,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 3.840572873934304,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7580645161290323,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.4258916732552045,
        "distinct-2-nopunct": 0.9482758620689655,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.754532719265502,
        "cond_entropy-2-nopunct": 0.3650758485711015,
        "distinct-3-nopunct": 0.9814814814814815,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.717850465126429,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3125,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "nist": 4.4397693567908405,
        "rouge1": {
            "precision": 0.68164,
            "recall": 0.75186,
            "fmeasure": 0.6926
        },
        "rouge2": {
            "precision": 0.41633,
            "recall": 0.47088,
            "fmeasure": 0.434
        },
        "rougeL": {
            "precision": 0.51245,
            "recall": 0.6071,
            "fmeasure": 0.53891
        },
        "rougeLsum": {
            "precision": 0.51245,
            "recall": 0.6071,
            "fmeasure": 0.53891
        },
        "bleu": 45.03815,
        "meteor": 0.38030220894100286,
        "bertscore": {
            "precision": 0.9167,
            "recall": 0.91532,
            "f1": 0.91596
        },
        "nubia": {
            "semantic_relation": 4.62364,
            "contradiction": 4.33639,
            "irrelevancy": 16.89207,
            "logical_agreement": 78.77154,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.06488,
            "nubia_score": 0.82352
        },
        "bleurt": 0.51686
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.12385402685271857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.9090909090909091
        },
        "nist": 3.656662528378316,
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.8254,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.82051,
            "recall": 0.73077,
            "fmeasure": 0.76612
        },
        "rougeL": {
            "precision": 0.92857,
            "recall": 0.8254,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.92857,
            "recall": 0.8254,
            "fmeasure": 0.86667
        },
        "bleu": 81.53551,
        "meteor": 0.9666666666666666,
        "bertscore": {
            "precision": 0.99541,
            "recall": 0.99541,
            "f1": 0.99541
        },
        "nubia": {
            "semantic_relation": 4.09425,
            "contradiction": 0.18847,
            "irrelevancy": 0.4462,
            "logical_agreement": 99.36533,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.78048,
            "nubia_score": 0.75491
        },
        "bleurt": 0.46305
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.16992500144231232,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.5384615384615384,
            "3": 0.8888888888888888
        },
        "nist": 2.4433310349772324,
        "rouge1": {
            "precision": 0.89205,
            "recall": 0.72298,
            "fmeasure": 0.79672
        },
        "rouge2": {
            "precision": 0.63571,
            "recall": 0.50379,
            "fmeasure": 0.56025
        },
        "rougeL": {
            "precision": 0.81534,
            "recall": 0.65909,
            "fmeasure": 0.72713
        },
        "rougeLsum": {
            "precision": 0.81534,
            "recall": 0.65909,
            "fmeasure": 0.72713
        },
        "bleu": 44.55713,
        "meteor": 0.3815790759665763,
        "bertscore": {
            "precision": 0.92391,
            "recall": 0.89712,
            "f1": 0.91025
        },
        "nubia": {
            "semantic_relation": 3.80649,
            "contradiction": 45.98289,
            "irrelevancy": 7.00999,
            "logical_agreement": 47.00713,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.54906,
            "nubia_score": 0.55833
        },
        "bleurt": 0.02033
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064473,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.2417888922404337,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6
        },
        "nist": 2.8168536038030654,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.63889,
            "fmeasure": 0.62407
        },
        "rouge2": {
            "precision": 0.3913,
            "recall": 0.45,
            "fmeasure": 0.4186
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.41071,
            "fmeasure": 0.39167
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.41071,
            "fmeasure": 0.39167
        },
        "bleu": 21.39774,
        "meteor": 0.3582082340400954,
        "bertscore": {
            "precision": 0.87898,
            "recall": 0.88107,
            "f1": 0.88002
        },
        "nubia": {
            "semantic_relation": 3.81349,
            "contradiction": 14.06796,
            "irrelevancy": 79.64366,
            "logical_agreement": 6.28838,
            "grammar_ref": 6.02354,
            "grammar_hyp": 5.41424,
            "nubia_score": 0.61863
        },
        "bleurt": -0.15152
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.6168746059562227,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.4125371587496607,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.5,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.44022392894185186,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5333333333333333
        },
        "nist": 2.174980327720768,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.52941,
            "fmeasure": 0.54545
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.375,
            "fmeasure": 0.3871
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.41176,
            "fmeasure": 0.42424
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.41176,
            "fmeasure": 0.42424
        },
        "bleu": 29.48994,
        "meteor": 0.2797479719018012,
        "bertscore": {
            "precision": 0.92319,
            "recall": 0.88293,
            "f1": 0.90261
        },
        "nubia": {
            "semantic_relation": 3.10505,
            "contradiction": 5.12975,
            "irrelevancy": 92.51277,
            "logical_agreement": 2.35748,
            "grammar_ref": 3.58521,
            "grammar_hyp": 3.21947,
            "nubia_score": 0.49697
        },
        "bleurt": -0.08415
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.029992126993435262,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.9
        },
        "nist": 3.501485888292335,
        "rouge1": {
            "precision": 0.82143,
            "recall": 0.8544,
            "fmeasure": 0.8373
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.5609,
            "fmeasure": 0.54923
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.66758,
            "fmeasure": 0.65476
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.66758,
            "fmeasure": 0.65476
        },
        "bleu": 41.88217,
        "meteor": 0.4317238939390762,
        "bertscore": {
            "precision": 0.94576,
            "recall": 0.95363,
            "f1": 0.94968
        },
        "nubia": {
            "semantic_relation": 4.81732,
            "contradiction": 40.47361,
            "irrelevancy": 2.50555,
            "logical_agreement": 57.02085,
            "grammar_ref": 4.1674,
            "grammar_hyp": 4.32261,
            "nubia_score": 0.82083
        },
        "bleurt": 0.47897
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 3.5,
        "median_pred_length": 15.5,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.8387096774193549,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.607264455478377,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.2056773572290925,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8620689655172413,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.556088322639176,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.2211615997086176,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "nist": 3.725646974842638,
        "rouge1": {
            "precision": 0.77189,
            "recall": 0.8828,
            "fmeasure": 0.81758
        },
        "rouge2": {
            "precision": 0.56176,
            "recall": 0.61706,
            "fmeasure": 0.5834
        },
        "rougeL": {
            "precision": 0.68098,
            "recall": 0.7578,
            "fmeasure": 0.71232
        },
        "rougeLsum": {
            "precision": 0.68098,
            "recall": 0.7578,
            "fmeasure": 0.71232
        },
        "bleu": 49.49996,
        "meteor": 0.4892028586075503,
        "bertscore": {
            "precision": 0.93406,
            "recall": 0.93069,
            "f1": 0.93234
        },
        "nubia": {
            "semantic_relation": 4.58738,
            "contradiction": 14.08301,
            "irrelevancy": 12.19346,
            "logical_agreement": 73.72353,
            "grammar_ref": 5.29605,
            "grammar_hyp": 4.81247,
            "nubia_score": 0.85465
        },
        "bleurt": 0.30433
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.098214829261011,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2797,
            "irrelevancy": 0.5863,
            "logical_agreement": 99.13399,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.67996,
            "nubia_score": 0.98883
        },
        "bleurt": 0.94053
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 12.25,
        "std_pred_length": 4.9180788932265,
        "median_pred_length": 10.5,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7551020408163265,
        "vocab_size-1": 37,
        "unique-1": 30,
        "entropy-1": 5.027875405295545,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.33836297448476577,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.13430109171159124,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 10.25,
        "std_pred_length-nopunct": 3.6996621467371855,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7804878048780488,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.851335236272631,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": 0.4128442664747434,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.16505924627049623,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.4,
            "3": 0.7037037037037037
        },
        "nist": 2.848450022959143,
        "rouge1": {
            "precision": 0.78052,
            "recall": 0.62151,
            "fmeasure": 0.67949
        },
        "rouge2": {
            "precision": 0.60417,
            "recall": 0.46902,
            "fmeasure": 0.51456
        },
        "rougeL": {
            "precision": 0.7677,
            "recall": 0.59374,
            "fmeasure": 0.65677
        },
        "rougeLsum": {
            "precision": 0.7677,
            "recall": 0.59374,
            "fmeasure": 0.65677
        },
        "bleu": 51.16508,
        "meteor": 0.40191846412228516,
        "bertscore": {
            "precision": 0.92939,
            "recall": 0.91113,
            "f1": 0.91361
        },
        "nubia": {
            "semantic_relation": 3.49453,
            "contradiction": 33.26467,
            "irrelevancy": 19.0466,
            "logical_agreement": 47.68874,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.42786,
            "nubia_score": 0.56773
        },
        "bleurt": 0.07804
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.440636352673265,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.08264309517020867,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.316827716832514,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.09517868111048418,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "nist": 4.4452311884848825,
        "rouge1": {
            "precision": 0.92857,
            "recall": 0.87454,
            "fmeasure": 0.89667
        },
        "rouge2": {
            "precision": 0.76795,
            "recall": 0.72863,
            "fmeasure": 0.74387
        },
        "rougeL": {
            "precision": 0.88312,
            "recall": 0.837,
            "fmeasure": 0.85556
        },
        "rougeLsum": {
            "precision": 0.88312,
            "recall": 0.837,
            "fmeasure": 0.85556
        },
        "bleu": 68.43292,
        "meteor": 0.5482955419726004,
        "bertscore": {
            "precision": 0.97659,
            "recall": 0.97441,
            "f1": 0.97548
        },
        "nubia": {
            "semantic_relation": 4.70485,
            "contradiction": 0.18465,
            "irrelevancy": 0.43333,
            "logical_agreement": 99.38202,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.7626,
            "nubia_score": 0.89844
        },
        "bleurt": 0.65386
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 7.5,
        "std_pred_length": 1.5,
        "median_pred_length": 7.5,
        "min_pred_length": 6,
        "max_pred_length": 9,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.05260472362127269,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.24100809950379498,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 6.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 6.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.05918991768561316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.2895066171949847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.45454545454545453
        },
        "nist": 2.5557101028891687,
        "rouge1": {
            "precision": 0.40972,
            "recall": 0.50556,
            "fmeasure": 0.44643
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.23333,
            "fmeasure": 0.19444
        },
        "rougeL": {
            "precision": 0.34722,
            "recall": 0.42222,
            "fmeasure": 0.375
        },
        "rougeLsum": {
            "precision": 0.34722,
            "recall": 0.42222,
            "fmeasure": 0.375
        },
        "bleu": 18.18663,
        "meteor": 0.24589140979387575,
        "bertscore": {
            "precision": 0.86306,
            "recall": 0.83555,
            "f1": 0.84904
        },
        "nubia": {
            "semantic_relation": 3.32354,
            "contradiction": 34.31606,
            "irrelevancy": 14.5463,
            "logical_agreement": 51.13764,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.80738,
            "nubia_score": 0.51698
        },
        "bleurt": -0.02612
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 8.73053390247253,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 28,
        "entropy-1": 5.038319436645929,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 43,
        "unique-2": 42,
        "entropy-2": 5.413977073182751,
        "cond_entropy-2": 0.30279219887618086,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.05309912621433559,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 7.318166133366716,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8048780487804879,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.930484321585717,
        "distinct-2-nopunct": 0.9736842105263158,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.19529593449622,
        "cond_entropy-2-nopunct": 0.2985274826235791,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.06150163935576179,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.9354838709677419
        },
        "nist": 4.472972116577912,
        "rouge1": {
            "precision": 0.77037,
            "recall": 0.86851,
            "fmeasure": 0.81409
        },
        "rouge2": {
            "precision": 0.54083,
            "recall": 0.63294,
            "fmeasure": 0.58104
        },
        "rougeL": {
            "precision": 0.65926,
            "recall": 0.7386,
            "fmeasure": 0.69423
        },
        "rougeLsum": {
            "precision": 0.65926,
            "recall": 0.7386,
            "fmeasure": 0.69423
        },
        "bleu": 49.43739,
        "meteor": 0.4720549683108749,
        "bertscore": {
            "precision": 0.93694,
            "recall": 0.94651,
            "f1": 0.94165
        },
        "nubia": {
            "semantic_relation": 4.36986,
            "contradiction": 0.92884,
            "irrelevancy": 62.55274,
            "logical_agreement": 36.51842,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.81841,
            "nubia_score": 0.80057
        },
        "bleurt": 0.13218
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9
        },
        "nist": 2.5627041598215734,
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.80556,
            "fmeasure": 0.69048
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.57576,
            "fmeasure": 0.48718
        },
        "rougeL": {
            "precision": 0.60417,
            "recall": 0.80556,
            "fmeasure": 0.69048
        },
        "rougeLsum": {
            "precision": 0.60417,
            "recall": 0.80556,
            "fmeasure": 0.69048
        },
        "bleu": 40.71221,
        "meteor": 0.45606843158906946,
        "bertscore": {
            "precision": 0.87865,
            "recall": 0.94305,
            "f1": 0.90972
        },
        "nubia": {
            "semantic_relation": 3.95686,
            "contradiction": 0.29911,
            "irrelevancy": 98.68895,
            "logical_agreement": 1.01194,
            "grammar_ref": 5.64121,
            "grammar_hyp": 4.68552,
            "nubia_score": 0.70873
        },
        "bleurt": 0.01546
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.43063240949075,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 24,
        "unique-2": 22,
        "entropy-2": 4.546593564294937,
        "cond_entropy-2": 0.1284325045223723,
        "distinct-3": 0.96,
        "vocab_size-3": 24,
        "unique-3": 23,
        "entropy-3": 4.5638561897747225,
        "cond_entropy-3": 0.023416471633632495,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.373660689688184,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.13922662353657628,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": 0.025555977074987166,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.9
        },
        "nist": 4.2964630442156935,
        "rouge1": {
            "precision": 0.75641,
            "recall": 0.73742,
            "fmeasure": 0.74673
        },
        "rouge2": {
            "precision": 0.36,
            "recall": 0.58547,
            "fmeasure": 0.43208
        },
        "rougeL": {
            "precision": 0.48718,
            "recall": 0.47483,
            "fmeasure": 0.48089
        },
        "rougeLsum": {
            "precision": 0.48718,
            "recall": 0.47483,
            "fmeasure": 0.48089
        },
        "bleu": 46.84382,
        "meteor": 0.3828706023320467,
        "bertscore": {
            "precision": 0.92743,
            "recall": 0.91119,
            "f1": 0.91924
        },
        "nubia": {
            "semantic_relation": 3.37694,
            "contradiction": 2.01107,
            "irrelevancy": 65.19231,
            "logical_agreement": 32.79662,
            "grammar_ref": 4.65446,
            "grammar_hyp": 3.92582,
            "nubia_score": 0.43463
        },
        "bleurt": -0.2712
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 1.5793601131730561,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84259,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.82143,
            "fmeasure": 0.9011
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.84259,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.84259,
            "fmeasure": 0.91389
        },
        "bleu": 88.24969,
        "meteor": 0.521097683465774,
        "bertscore": {
            "precision": 0.98629,
            "recall": 0.97615,
            "f1": 0.98119
        },
        "nubia": {
            "semantic_relation": 4.6027,
            "contradiction": 0.21773,
            "irrelevancy": 0.53648,
            "logical_agreement": 99.24579,
            "grammar_ref": 5.14316,
            "grammar_hyp": 6.09338,
            "nubia_score": 0.76995
        },
        "bleurt": 0.44755
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 3.0,
        "median_pred_length": 19.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.5526315789473685,
        "vocab_size-1": 21,
        "unique-1": 10,
        "entropy-1": 4.198603750787606,
        "distinct-2": 0.6944444444444444,
        "vocab_size-2": 25,
        "unique-2": 15,
        "entropy-2": 4.537844793048881,
        "cond_entropy-2": 0.3419812512977199,
        "distinct-3": 0.7352941176470589,
        "vocab_size-3": 25,
        "unique-3": 16,
        "entropy-3": 4.558051076544457,
        "cond_entropy-3": 0.057387472224599625,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5555555555555556,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 4.117861029749889,
        "distinct-2-nopunct": 0.6764705882352942,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.4182014441278845,
        "cond_entropy-2-nopunct": 0.3156099862210445,
        "distinct-3-nopunct": 0.71875,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.4375,
        "cond_entropy-3-nopunct": 0.061127393192269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.42857142857142855,
            "3": 0.75
        },
        "nist": 4.0456457915708,
        "rouge1": {
            "precision": 0.59633,
            "recall": 0.74532,
            "fmeasure": 0.65579
        },
        "rouge2": {
            "precision": 0.45739,
            "recall": 0.5843,
            "fmeasure": 0.50769
        },
        "rougeL": {
            "precision": 0.47272,
            "recall": 0.66007,
            "fmeasure": 0.54456
        },
        "rougeLsum": {
            "precision": 0.47272,
            "recall": 0.66007,
            "fmeasure": 0.54456
        },
        "bleu": 52.36997,
        "meteor": 0.4078754353667242,
        "bertscore": {
            "precision": 0.89915,
            "recall": 0.92737,
            "f1": 0.91105
        },
        "nubia": {
            "semantic_relation": 3.82183,
            "contradiction": 9.42284,
            "irrelevancy": 62.90918,
            "logical_agreement": 27.66798,
            "grammar_ref": 3.56015,
            "grammar_hyp": 2.85507,
            "nubia_score": 0.69545
        },
        "bleurt": 0.03124
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.589898095464287,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219046,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5714285714285714
        },
        "nist": 1.6272183241024296,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.54412,
            "fmeasure": 0.63837
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.21196,
            "fmeasure": 0.24904
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.40196,
            "fmeasure": 0.46859
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.40196,
            "fmeasure": 0.46859
        },
        "bleu": 12.601,
        "meteor": 0.2968596719701763,
        "bertscore": {
            "precision": 0.92845,
            "recall": 0.88849,
            "f1": 0.90803
        },
        "nubia": {
            "semantic_relation": 4.09073,
            "contradiction": 11.09649,
            "irrelevancy": 15.96256,
            "logical_agreement": 72.94095,
            "grammar_ref": 4.95035,
            "grammar_hyp": 5.72111,
            "nubia_score": 0.53576
        },
        "bleurt": 0.1688
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "nist": 1.4,
        "rouge1": {
            "precision": 0.46667,
            "recall": 1.0,
            "fmeasure": 0.63636
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.66667,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 1.0,
            "fmeasure": 0.63636
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 1.0,
            "fmeasure": 0.63636
        },
        "bleu": 13.38016,
        "meteor": 0.4174260185898619,
        "bertscore": {
            "precision": 0.83931,
            "recall": 0.94741,
            "f1": 0.89009
        },
        "nubia": {
            "semantic_relation": 4.37682,
            "contradiction": 0.15683,
            "irrelevancy": 55.48466,
            "logical_agreement": 44.35851,
            "grammar_ref": 5.74517,
            "grammar_hyp": 3.84829,
            "nubia_score": 0.73824
        },
        "bleurt": 0.56117
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.0,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.648955904159992,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.410328648695188,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.6150610122030695,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.21313888009778093,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.92
        },
        "nist": 5.038907372582962,
        "rouge1": {
            "precision": 0.92105,
            "recall": 0.88261,
            "fmeasure": 0.90049
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.70654,
            "fmeasure": 0.72207
        },
        "rougeL": {
            "precision": 0.73684,
            "recall": 0.71522,
            "fmeasure": 0.72527
        },
        "rougeLsum": {
            "precision": 0.73684,
            "recall": 0.71522,
            "fmeasure": 0.72527
        },
        "bleu": 63.22424,
        "meteor": 0.44636130420165854,
        "bertscore": {
            "precision": 0.94083,
            "recall": 0.93985,
            "f1": 0.93825
        },
        "nubia": {
            "semantic_relation": 4.47775,
            "contradiction": 13.83929,
            "irrelevancy": 19.0866,
            "logical_agreement": 67.0741,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.31931,
            "nubia_score": 0.837
        },
        "bleurt": 0.37282
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.323856189774722,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.27443964427976497,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.2864255422923785,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9090909090909091
        },
        "nist": 2.2015648727862445,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.91667,
            "fmeasure": 0.64706
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.45455,
            "fmeasure": 0.3125
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.75,
            "fmeasure": 0.52941
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.75,
            "fmeasure": 0.52941
        },
        "bleu": 19.59946,
        "meteor": 0.3999643768051795,
        "bertscore": {
            "precision": 0.86901,
            "recall": 0.9363,
            "f1": 0.89426
        },
        "nubia": {
            "semantic_relation": 3.92439,
            "contradiction": 0.09984,
            "irrelevancy": 93.86001,
            "logical_agreement": 6.04014,
            "grammar_ref": 4.00353,
            "grammar_hyp": 3.23831,
            "nubia_score": 0.44417
        },
        "bleurt": 0.19472
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "msttr-100": 0.66621,
        "msttr-100_nopunct": 0.68709,
        "total_length": 9588,
        "mean_pred_length": 19.176,
        "std_pred_length": 6.304365471639474,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.13756779307467668,
        "vocab_size-1": 1319,
        "unique-1": 581,
        "entropy-1": 8.024995905147938,
        "distinct-2": 0.3887544014084507,
        "vocab_size-2": 3533,
        "unique-2": 2179,
        "entropy-2": 10.872709403034,
        "cond_entropy-2": 2.7820066281167892,
        "distinct-3": 0.5925710293432697,
        "vocab_size-3": 5089,
        "unique-3": 3775,
        "entropy-3": 11.817115083412634,
        "cond_entropy-3": 1.0250598684050467,
        "total_length-nopunct": 8688,
        "mean_pred_length-nopunct": 17.376,
        "std_pred_length-nopunct": 6.017526402102446,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.15078268876611417,
        "vocab_size-1-nopunct": 1310,
        "unique-1-nopunct": 580,
        "entropy-1-nopunct": 8.192887535039672,
        "distinct-2-nopunct": 0.3935026868588178,
        "vocab_size-2-nopunct": 3222,
        "unique-2-nopunct": 2027,
        "entropy-2-nopunct": 10.74283618055417,
        "cond_entropy-2-nopunct": 2.712185551045593,
        "distinct-3-nopunct": 0.5996357960457857,
        "vocab_size-3-nopunct": 4610,
        "unique-3-nopunct": 3469,
        "entropy-3-nopunct": 11.671500076413444,
        "cond_entropy-3-nopunct": 1.0051985757411002,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "local_recall": {
            "1": 0.19046623458080703,
            "2": 0.5098039215686274,
            "3": 0.7392005735794945,
            "4": 0.7777777777777778,
            "5": 0.5454545454545454
        },
        "nist": 6.560663919105954,
        "rouge1": {
            "precision": 0.77486,
            "recall": 0.67246,
            "fmeasure": 0.70686
        },
        "rouge2": {
            "precision": 0.51358,
            "recall": 0.44229,
            "fmeasure": 0.46521
        },
        "rougeL": {
            "precision": 0.63094,
            "recall": 0.5481,
            "fmeasure": 0.57515
        },
        "rougeLsum": {
            "precision": 0.63094,
            "recall": 0.5481,
            "fmeasure": 0.57515
        },
        "bleu": 39.20938,
        "meteor": 0.3256944367450032,
        "bertscore": {
            "precision": 0.92016,
            "recall": 0.90095,
            "f1": 0.90885
        },
        "nubia": {
            "semantic_relation": 4.00461,
            "contradiction": 18.99223,
            "irrelevancy": 9.15247,
            "logical_agreement": 71.8553,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.759,
            "nubia_score": 0.63441
        },
        "bleurt": 0.0515
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 40,
        "unique-1": 37,
        "entropy-1": 5.260456902679035,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": -0.004318638409457556,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.142664355548852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": -0.004358782212904644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.4,
            "3": 0.6944444444444444
        },
        "nist": 3.7057627736381047,
        "rouge1": {
            "precision": 0.79373,
            "recall": 0.69815,
            "fmeasure": 0.73335
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.49624,
            "fmeasure": 0.51561
        },
        "rougeL": {
            "precision": 0.77151,
            "recall": 0.68025,
            "fmeasure": 0.71353
        },
        "rougeLsum": {
            "precision": 0.77151,
            "recall": 0.68025,
            "fmeasure": 0.71353
        },
        "bleu": 42.5476,
        "meteor": 0.3526453652084928,
        "bertscore": {
            "precision": 0.94731,
            "recall": 0.91974,
            "f1": 0.93284
        },
        "nubia": {
            "semantic_relation": 4.24894,
            "contradiction": 2.21627,
            "irrelevancy": 10.51628,
            "logical_agreement": 87.26745,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.55949,
            "nubia_score": 0.72751
        },
        "bleurt": 0.33386
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "nist": 1.077067708633815,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.5,
            "fmeasure": 0.36364
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.8,
            "fmeasure": 0.61538
        },
        "bleu": 15.85117,
        "meteor": 0.4157242800169579,
        "bertscore": {
            "precision": 0.88308,
            "recall": 0.96214,
            "f1": 0.92092
        },
        "nubia": {
            "semantic_relation": 4.32515,
            "contradiction": 0.1052,
            "irrelevancy": 99.78136,
            "logical_agreement": 0.11345,
            "grammar_ref": 6.34893,
            "grammar_hyp": 4.71705,
            "nubia_score": 1.0
        },
        "bleurt": 0.52633
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 20.0,
        "std_pred_length": 7.694153624668538,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 34,
        "distinct-1": 0.66,
        "vocab_size-1": 66,
        "unique-1": 48,
        "entropy-1": 5.7929203504767255,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 85,
        "unique-2": 76,
        "entropy-2": 6.351383108308175,
        "cond_entropy-2": 0.5023545125237624,
        "distinct-3": 0.9222222222222223,
        "vocab_size-3": 83,
        "unique-3": 76,
        "entropy-3": 6.336297540774107,
        "cond_entropy-3": -0.0029482064216790277,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 16.4,
        "std_pred_length-nopunct": 4.963869458396343,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7439024390243902,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.758534742681943,
        "distinct-2-nopunct": 0.8961038961038961,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 6.058994332902697,
        "cond_entropy-2-nopunct": 0.29279886046698095,
        "distinct-3-nopunct": 0.9027777777777778,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.975480556997873,
        "cond_entropy-3-nopunct": -0.08297265036370018,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5294117647058824,
            "3": 0.8571428571428571
        },
        "nist": 4.351734071711822,
        "rouge1": {
            "precision": 0.69426,
            "recall": 0.71964,
            "fmeasure": 0.68761
        },
        "rouge2": {
            "precision": 0.54264,
            "recall": 0.55135,
            "fmeasure": 0.53027
        },
        "rougeL": {
            "precision": 0.63397,
            "recall": 0.64138,
            "fmeasure": 0.62008
        },
        "rougeLsum": {
            "precision": 0.63397,
            "recall": 0.64138,
            "fmeasure": 0.62008
        },
        "bleu": 41.45803,
        "meteor": 0.38955692093093003,
        "bertscore": {
            "precision": 0.9214,
            "recall": 0.91738,
            "f1": 0.91682
        },
        "nubia": {
            "semantic_relation": 3.88449,
            "contradiction": 14.15393,
            "irrelevancy": 33.78368,
            "logical_agreement": 52.06239,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.5347,
            "nubia_score": 0.662
        },
        "bleurt": 0.01347
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 42,
        "unique-1": 40,
        "entropy-1": 5.341744485170485,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": -0.0519166259318668,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.10691520391651191,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.975609756097561,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.308771516813203,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": -0.05699291222712946,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9130434782608695
        },
        "nist": 4.510678373837726,
        "rouge1": {
            "precision": 0.84444,
            "recall": 0.83303,
            "fmeasure": 0.83452
        },
        "rouge2": {
            "precision": 0.69048,
            "recall": 0.68129,
            "fmeasure": 0.68252
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.69189,
            "fmeasure": 0.69286
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.69189,
            "fmeasure": 0.69286
        },
        "bleu": 56.77945,
        "meteor": 0.47972574609058444,
        "bertscore": {
            "precision": 0.94441,
            "recall": 0.96005,
            "f1": 0.95135
        },
        "nubia": {
            "semantic_relation": 4.26448,
            "contradiction": 3.93801,
            "irrelevancy": 62.40273,
            "logical_agreement": 33.65926,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.12895,
            "nubia_score": 0.68033
        },
        "bleurt": 0.36133
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 0.5,
        "median_pred_length": 18.5,
        "min_pred_length": 18,
        "max_pred_length": 19,
        "distinct-1": 0.8918918918918919,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.993237149412738,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.09125822274458809,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9666666666666667,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.840223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": -0.06382138783662868,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.6190476190476191
        },
        "nist": 4.1316926403105025,
        "rouge1": {
            "precision": 0.62542,
            "recall": 0.53632,
            "fmeasure": 0.57352
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.31588,
            "fmeasure": 0.33987
        },
        "rougeL": {
            "precision": 0.37709,
            "recall": 0.32495,
            "fmeasure": 0.34685
        },
        "rougeLsum": {
            "precision": 0.37709,
            "recall": 0.32495,
            "fmeasure": 0.34685
        },
        "bleu": 43.15507,
        "meteor": 0.3284504002751452,
        "bertscore": {
            "precision": 0.91582,
            "recall": 0.89929,
            "f1": 0.90696
        },
        "nubia": {
            "semantic_relation": 3.66565,
            "contradiction": 1.36138,
            "irrelevancy": 44.68393,
            "logical_agreement": 53.95468,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.76269,
            "nubia_score": 0.53804
        },
        "bleurt": -0.15287
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 4.153311931459037,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.7758620689655172,
        "vocab_size-1": 45,
        "unique-1": 38,
        "entropy-1": 5.299971892082739,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.31106443252849475,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.07103131238874393,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.958039891549808,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.156565630242722,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.36589115707794645,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.08362548565920487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.5909090909090909,
            "3": 0.43243243243243246
        },
        "nist": 3.3940683701472154,
        "rouge1": {
            "precision": 0.65053,
            "recall": 0.54558,
            "fmeasure": 0.57908
        },
        "rouge2": {
            "precision": 0.43361,
            "recall": 0.39125,
            "fmeasure": 0.40343
        },
        "rougeL": {
            "precision": 0.53981,
            "recall": 0.48415,
            "fmeasure": 0.50125
        },
        "rougeLsum": {
            "precision": 0.53981,
            "recall": 0.48415,
            "fmeasure": 0.50125
        },
        "bleu": 35.69838,
        "meteor": 0.290691011077518,
        "bertscore": {
            "precision": 0.91872,
            "recall": 0.8897,
            "f1": 0.90346
        },
        "nubia": {
            "semantic_relation": 3.11475,
            "contradiction": 32.89301,
            "irrelevancy": 17.59033,
            "logical_agreement": 49.51666,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.92872,
            "nubia_score": 0.46515
        },
        "bleurt": 0.12744
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.65,
        "vocab_size-1": 13,
        "unique-1": 8,
        "entropy-1": 3.546439344671015,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 17,
        "unique-2": 15,
        "entropy-2": 4.03740119765411,
        "cond_entropy-2": 0.4483579713775801,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 17,
        "unique-3": 16,
        "entropy-3": 4.058813890331201,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.454822399946607,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.45971762763487756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": 0.040223928941851894,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0,
            "3": 0.5
        },
        "nist": 0.9503348319950335,
        "rouge1": {
            "precision": 0.3,
            "recall": 0.48214,
            "fmeasure": 0.35802
        },
        "rouge2": {
            "precision": 0.08772,
            "recall": 0.14444,
            "fmeasure": 0.1051
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.30357,
            "fmeasure": 0.23457
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.30357,
            "fmeasure": 0.23457
        },
        "bleu": 4.14114,
        "meteor": 0.23409707586600698,
        "bertscore": {
            "precision": 0.70608,
            "recall": 0.77073,
            "f1": 0.70241
        },
        "nubia": {
            "semantic_relation": 2.33559,
            "contradiction": 0.33938,
            "irrelevancy": 99.32843,
            "logical_agreement": 0.33219,
            "grammar_ref": 4.92688,
            "grammar_hyp": 2.78665,
            "nubia_score": 0.32221
        },
        "bleurt": -0.15294
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "nist": 1.1227137604546689,
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.40179,
            "fmeasure": 0.34314
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.59028,
            "fmeasure": 0.51316
        },
        "bleu": 14.99111,
        "meteor": 0.2731132551770082,
        "bertscore": {
            "precision": 0.82556,
            "recall": 0.86442,
            "f1": 0.84455
        },
        "nubia": {
            "semantic_relation": 3.78915,
            "contradiction": 2.88897,
            "irrelevancy": 55.44136,
            "logical_agreement": 41.66967,
            "grammar_ref": 4.73918,
            "grammar_hyp": 3.671,
            "nubia_score": 0.66998
        },
        "bleurt": 0.34221
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.0,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 20,
        "entropy-1": 4.52164063634332,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660255,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.2626923908396215,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.05923165719793805,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.7272727272727273,
            "3": 0.8181818181818182
        },
        "nist": 4.228816981627299,
        "rouge1": {
            "precision": 0.69259,
            "recall": 0.67018,
            "fmeasure": 0.67417
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.4663,
            "fmeasure": 0.47593
        },
        "rougeL": {
            "precision": 0.65185,
            "recall": 0.58532,
            "fmeasure": 0.59839
        },
        "rougeLsum": {
            "precision": 0.65185,
            "recall": 0.58532,
            "fmeasure": 0.59839
        },
        "bleu": 47.25227,
        "meteor": 0.3677859840513157,
        "bertscore": {
            "precision": 0.94881,
            "recall": 0.94299,
            "f1": 0.94052
        },
        "nubia": {
            "semantic_relation": 4.2113,
            "contradiction": 7.4841,
            "irrelevancy": 19.21909,
            "logical_agreement": 73.29681,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.21305,
            "nubia_score": 0.74546
        },
        "bleurt": 0.14215
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 3.019315628789926,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.71053,
            "fmeasure": 0.75142
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.5037,
            "fmeasure": 0.53448
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.65132,
            "fmeasure": 0.6888
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.65132,
            "fmeasure": 0.6888
        },
        "bleu": 46.24167,
        "meteor": 0.3740860170193576,
        "bertscore": {
            "precision": 0.92163,
            "recall": 0.88273,
            "f1": 0.90145
        },
        "nubia": {
            "semantic_relation": 4.87026,
            "contradiction": 0.57966,
            "irrelevancy": 1.47541,
            "logical_agreement": 97.94493,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.98107,
            "nubia_score": 0.86455
        },
        "bleurt": 0.11742
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.5,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.556088322639176,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.14708752563454358,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.504706483564823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.11916418769779472,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nist": 4.22187608197715,
        "rouge1": {
            "precision": 0.65,
            "recall": 0.75273,
            "fmeasure": 0.68211
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.47492,
            "fmeasure": 0.41083
        },
        "rougeL": {
            "precision": 0.61667,
            "recall": 0.72321,
            "fmeasure": 0.65083
        },
        "rougeLsum": {
            "precision": 0.61667,
            "recall": 0.72321,
            "fmeasure": 0.65083
        },
        "bleu": 29.87829,
        "meteor": 0.3929938045114562,
        "bertscore": {
            "precision": 0.93586,
            "recall": 0.95028,
            "f1": 0.94286
        },
        "nubia": {
            "semantic_relation": 4.2729,
            "contradiction": 3.51291,
            "irrelevancy": 55.4116,
            "logical_agreement": 41.07548,
            "grammar_ref": 4.46901,
            "grammar_hyp": 4.56947,
            "nubia_score": 0.69131
        },
        "bleurt": 0.39578
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 3.5,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.403856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.05361880976054911,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.05923165719793805,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.3333333333333333,
            "3": 0.7058823529411765
        },
        "nist": 4.147924154671347,
        "rouge1": {
            "precision": 0.67917,
            "recall": 0.61975,
            "fmeasure": 0.64523
        },
        "rouge2": {
            "precision": 0.4881,
            "recall": 0.44471,
            "fmeasure": 0.46281
        },
        "rougeL": {
            "precision": 0.64583,
            "recall": 0.59034,
            "fmeasure": 0.61398
        },
        "rougeLsum": {
            "precision": 0.64583,
            "recall": 0.59034,
            "fmeasure": 0.61398
        },
        "bleu": 32.85454,
        "meteor": 0.41894798703034797,
        "bertscore": {
            "precision": 0.93941,
            "recall": 0.92899,
            "f1": 0.93417
        },
        "nubia": {
            "semantic_relation": 4.14871,
            "contradiction": 44.97384,
            "irrelevancy": 3.12663,
            "logical_agreement": 51.89952,
            "grammar_ref": 4.56502,
            "grammar_hyp": 5.45179,
            "nubia_score": 0.63631
        },
        "bleurt": 0.55905
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69219,
        "msttr-100_nopunct": 0.72161,
        "total_length": 6406,
        "mean_pred_length": 12.812,
        "std_pred_length": 6.436820333052648,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.1582891039650328,
        "vocab_size-1": 1014,
        "unique-1": 564,
        "entropy-1": 7.861713588462955,
        "distinct-2": 0.4871317304436167,
        "vocab_size-2": 2877,
        "unique-2": 2015,
        "entropy-2": 10.723947825761938,
        "cond_entropy-2": 2.6462947480433643,
        "distinct-3": 0.7069922308546059,
        "vocab_size-3": 3822,
        "unique-3": 3130,
        "entropy-3": 11.539368429732784,
        "cond_entropy-3": 0.8515557655410466,
        "total_length-nopunct": 5661,
        "mean_pred_length-nopunct": 11.322,
        "std_pred_length-nopunct": 5.99419018717291,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.17700052994170642,
        "vocab_size-1-nopunct": 1002,
        "unique-1-nopunct": 560,
        "entropy-1-nopunct": 8.037724664493961,
        "distinct-2-nopunct": 0.5018407285409804,
        "vocab_size-2-nopunct": 2590,
        "unique-2-nopunct": 1859,
        "entropy-2-nopunct": 10.555652924752716,
        "cond_entropy-2-nopunct": 2.6594740110077972,
        "distinct-3-nopunct": 0.7166452166452166,
        "vocab_size-3-nopunct": 3341,
        "unique-3-nopunct": 2775,
        "entropy-3-nopunct": 11.33745674313069,
        "cond_entropy-3-nopunct": 0.8376241280309304,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.554981930820857
        },
        "nist": 6.013694551238981,
        "rouge1": {
            "precision": 0.57646,
            "recall": 0.54613,
            "fmeasure": 0.54925
        },
        "rouge2": {
            "precision": 0.352,
            "recall": 0.3299,
            "fmeasure": 0.33251
        },
        "rougeL": {
            "precision": 0.51451,
            "recall": 0.48699,
            "fmeasure": 0.48971
        },
        "rougeLsum": {
            "precision": 0.51451,
            "recall": 0.48699,
            "fmeasure": 0.48971
        },
        "bleu": 30.32191,
        "meteor": 0.30509118006647645,
        "bertscore": {
            "precision": 0.86758,
            "recall": 0.85983,
            "f1": 0.86319
        },
        "nubia": {
            "semantic_relation": 3.56701,
            "contradiction": 6.82075,
            "irrelevancy": 23.47074,
            "logical_agreement": 69.70851,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.63709,
            "nubia_score": 0.62435
        },
        "bleurt": -0.12077
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nist": 2.311677369670145,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.375,
            "fmeasure": 0.35294
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "bleu": 19.35831,
        "meteor": 0.2991277726949984,
        "bertscore": {
            "precision": 0.94048,
            "recall": 0.93372,
            "f1": 0.93602
        },
        "nubia": {
            "semantic_relation": 3.54425,
            "contradiction": 15.74122,
            "irrelevancy": 83.67349,
            "logical_agreement": 0.58529,
            "grammar_ref": 5.49813,
            "grammar_hyp": 4.47843,
            "nubia_score": 0.4677
        },
        "bleurt": 0.45469
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.24294728142281322,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.186704345910023,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.17098104223670127,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9230769230769231
        },
        "nist": 2.159106076031089,
        "rouge1": {
            "precision": 0.57576,
            "recall": 0.82738,
            "fmeasure": 0.67836
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.53846,
            "fmeasure": 0.41176
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.57143,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.57143,
            "fmeasure": 0.44444
        },
        "bleu": 23.11466,
        "meteor": 0.4372184167706372,
        "bertscore": {
            "precision": 0.88282,
            "recall": 0.93526,
            "f1": 0.90828
        },
        "nubia": {
            "semantic_relation": 4.1125,
            "contradiction": 98.86537,
            "irrelevancy": 0.49597,
            "logical_agreement": 0.63867,
            "grammar_ref": 5.0526,
            "grammar_hyp": 4.30987,
            "nubia_score": 0.71924
        },
        "bleurt": 0.24159
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 3.0877627602658655,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.54545,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.4,
            "fmeasure": 0.42105
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.36364,
            "fmeasure": 0.38095
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.36364,
            "fmeasure": 0.38095
        },
        "bleu": 32.64971,
        "meteor": 0.2847273877462696,
        "bertscore": {
            "precision": 0.86227,
            "recall": 0.88449,
            "f1": 0.87159
        },
        "nubia": {
            "semantic_relation": 2.81317,
            "contradiction": 98.54735,
            "irrelevancy": 0.88196,
            "logical_agreement": 0.5707,
            "grammar_ref": 4.59968,
            "grammar_hyp": 4.75054,
            "nubia_score": 0.27093
        },
        "bleurt": -0.07618
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.03600643804015718,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.03912675144043812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6842105263157895
        },
        "nist": 2.4457324615573395,
        "rouge1": {
            "precision": 0.71759,
            "recall": 0.69192,
            "fmeasure": 0.69988
        },
        "rouge2": {
            "precision": 0.34848,
            "recall": 0.34881,
            "fmeasure": 0.34578
        },
        "rougeL": {
            "precision": 0.53704,
            "recall": 0.51498,
            "fmeasure": 0.52214
        },
        "rougeLsum": {
            "precision": 0.53704,
            "recall": 0.51498,
            "fmeasure": 0.52214
        },
        "bleu": 11.80207,
        "meteor": 0.36130959206901175,
        "bertscore": {
            "precision": 0.91747,
            "recall": 0.88844,
            "f1": 0.90202
        },
        "nubia": {
            "semantic_relation": 4.05261,
            "contradiction": 0.23036,
            "irrelevancy": 0.89021,
            "logical_agreement": 98.87942,
            "grammar_ref": 4.70186,
            "grammar_hyp": 5.03309,
            "nubia_score": 0.66065
        },
        "bleurt": 0.29262
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.316827716832514,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.15200091267862392,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "nist": 1.1565812505658084,
        "rouge1": {
            "precision": 0.2,
            "recall": 0.34231,
            "fmeasure": 0.25152
        },
        "rouge2": {
            "precision": 0.02632,
            "recall": 0.04167,
            "fmeasure": 0.03226
        },
        "rougeL": {
            "precision": 0.15,
            "recall": 0.25385,
            "fmeasure": 0.18788
        },
        "rougeLsum": {
            "precision": 0.15,
            "recall": 0.25385,
            "fmeasure": 0.18788
        },
        "bleu": 4.33426,
        "meteor": 0.14364494088556143,
        "bertscore": {
            "precision": 0.72637,
            "recall": 0.72589,
            "f1": 0.72613
        },
        "nubia": {
            "semantic_relation": 1.43452,
            "contradiction": 2.31454,
            "irrelevancy": 97.14458,
            "logical_agreement": 0.54088,
            "grammar_ref": 4.19915,
            "grammar_hyp": 5.33946,
            "nubia_score": 0.07799
        },
        "bleurt": -1.2823
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.476859065460503,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.88081,
            "fmeasure": 0.83419
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.74286,
            "fmeasure": 0.69841
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.88081,
            "fmeasure": 0.83419
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.88081,
            "fmeasure": 0.83419
        },
        "bleu": 60.58515,
        "meteor": 0.5061815011591995,
        "bertscore": {
            "precision": 0.97287,
            "recall": 0.96187,
            "f1": 0.96734
        },
        "nubia": {
            "semantic_relation": 4.64259,
            "contradiction": 0.62065,
            "irrelevancy": 27.66147,
            "logical_agreement": 71.71789,
            "grammar_ref": 5.20931,
            "grammar_hyp": 4.99922,
            "nubia_score": 0.81828
        },
        "bleurt": 0.35354
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.9629629629629629,
        "vocab_size-1": 26,
        "unique-1": 25,
        "entropy-1": 4.6808134280893965,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.11103131238874399,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.6666666666666666,
            "3": 0.7692307692307693
        },
        "nist": 2.926826964254986,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.78958,
            "fmeasure": 0.84691
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.69411,
            "fmeasure": 0.73569
        },
        "rougeL": {
            "precision": 0.85556,
            "recall": 0.72917,
            "fmeasure": 0.77558
        },
        "rougeLsum": {
            "precision": 0.85556,
            "recall": 0.72917,
            "fmeasure": 0.77558
        },
        "bleu": 64.3957,
        "meteor": 0.4608541797623991,
        "bertscore": {
            "precision": 0.97618,
            "recall": 0.94723,
            "f1": 0.96125
        },
        "nubia": {
            "semantic_relation": 4.11905,
            "contradiction": 49.43527,
            "irrelevancy": 0.55011,
            "logical_agreement": 50.01461,
            "grammar_ref": 4.54027,
            "grammar_hyp": 4.77007,
            "nubia_score": 0.65944
        },
        "bleurt": 0.44058
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.55,
        "total_length": 115,
        "mean_pred_length": 14.375,
        "std_pred_length": 3.5685256059050494,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.5043478260869565,
        "vocab_size-1": 58,
        "unique-1": 31,
        "entropy-1": 5.4475060859834405,
        "distinct-2": 0.794392523364486,
        "vocab_size-2": 85,
        "unique-2": 65,
        "entropy-2": 6.3161419863607025,
        "cond_entropy-2": 0.7488590005612709,
        "distinct-3": 0.8686868686868687,
        "vocab_size-3": 86,
        "unique-3": 73,
        "entropy-3": 6.366730357453356,
        "cond_entropy-3": 0.06475604786358326,
        "total_length-nopunct": 105,
        "mean_pred_length-nopunct": 13.125,
        "std_pred_length-nopunct": 3.3330729064933458,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5333333333333333,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.430739270327944,
        "distinct-2-nopunct": 0.7835051546391752,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 6.151358460699231,
        "cond_entropy-2-nopunct": 0.7688984427216263,
        "distinct-3-nopunct": 0.8539325842696629,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.183598599505734,
        "cond_entropy-3-nopunct": 0.04351511129169452,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.5945945945945946,
            "3": 0.6438356164383562
        },
        "nist": 4.377455656060372,
        "rouge1": {
            "precision": 0.7763,
            "recall": 0.66512,
            "fmeasure": 0.70868
        },
        "rouge2": {
            "precision": 0.55869,
            "recall": 0.49018,
            "fmeasure": 0.51681
        },
        "rougeL": {
            "precision": 0.68459,
            "recall": 0.59286,
            "fmeasure": 0.6286
        },
        "rougeLsum": {
            "precision": 0.68459,
            "recall": 0.59286,
            "fmeasure": 0.6286
        },
        "bleu": 46.23225,
        "meteor": 0.34262525986331105,
        "bertscore": {
            "precision": 0.91056,
            "recall": 0.88387,
            "f1": 0.89533
        },
        "nubia": {
            "semantic_relation": 3.571,
            "contradiction": 34.65953,
            "irrelevancy": 25.34969,
            "logical_agreement": 39.99078,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.09473,
            "nubia_score": 0.59454
        },
        "bleurt": 0.13227
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.6682958340544896,
        "distinct-2": 0.6818181818181818,
        "vocab_size-2": 15,
        "unique-2": 8,
        "entropy-2": 3.82306798227366,
        "cond_entropy-2": 0.14719639064341364,
        "distinct-3": 0.7,
        "vocab_size-3": 14,
        "unique-3": 8,
        "entropy-3": 3.721928094887362,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.5503407095463877,
        "distinct-2-nopunct": 0.65,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.621928094887362,
        "cond_entropy-2-nopunct": 0.16249647625006503,
        "distinct-3-nopunct": 0.6666666666666666,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 3.503258334775645,
        "cond_entropy-3-nopunct": -0.04089198233393863,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 3.263714811730922,
        "rouge1": {
            "precision": 0.65152,
            "recall": 0.74038,
            "fmeasure": 0.67128
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.42727,
            "fmeasure": 0.37864
        },
        "rougeL": {
            "precision": 0.5303,
            "recall": 0.63568,
            "fmeasure": 0.55897
        },
        "rougeLsum": {
            "precision": 0.5303,
            "recall": 0.63568,
            "fmeasure": 0.55897
        },
        "bleu": 27.50573,
        "meteor": 0.40613532491511645,
        "bertscore": {
            "precision": 0.90247,
            "recall": 0.94149,
            "f1": 0.92027
        },
        "nubia": {
            "semantic_relation": 3.86027,
            "contradiction": 0.31503,
            "irrelevancy": 66.18484,
            "logical_agreement": 33.50013,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.75196,
            "nubia_score": 0.6654
        },
        "bleurt": -0.0783
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "nist": 1.7990385038524417,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "bleu": 20.16495,
        "meteor": 0.861811391223156,
        "bertscore": {
            "precision": 0.94225,
            "recall": 0.97743,
            "f1": 0.95951
        },
        "nubia": {
            "semantic_relation": 4.21377,
            "contradiction": 0.17851,
            "irrelevancy": 33.78877,
            "logical_agreement": 66.03272,
            "grammar_ref": 5.27628,
            "grammar_hyp": 4.69427,
            "nubia_score": 0.81239
        },
        "bleurt": 0.49066
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 5.5,
        "median_pred_length": 23.5,
        "min_pred_length": 18,
        "max_pred_length": 29,
        "distinct-1": 0.851063829787234,
        "vocab_size-1": 40,
        "unique-1": 37,
        "entropy-1": 5.163854213877633,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.44740865188523,
        "cond_entropy-2": 0.30092042190982127,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.019076713720599832,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8409090909090909,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.042055982805473,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.344698375159715,
        "cond_entropy-2-nopunct": 0.3225174226319462,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.020389327891398017,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0,
            "3": 0.5128205128205128
        },
        "nist": 3.955110060100466,
        "rouge1": {
            "precision": 0.66776,
            "recall": 0.53217,
            "fmeasure": 0.58876
        },
        "rouge2": {
            "precision": 0.38942,
            "recall": 0.29983,
            "fmeasure": 0.33674
        },
        "rougeL": {
            "precision": 0.48184,
            "recall": 0.40857,
            "fmeasure": 0.4417
        },
        "rougeLsum": {
            "precision": 0.48184,
            "recall": 0.40857,
            "fmeasure": 0.4417
        },
        "bleu": 37.9056,
        "meteor": 0.26964998869364565,
        "bertscore": {
            "precision": 0.87992,
            "recall": 0.83863,
            "f1": 0.85861
        },
        "nubia": {
            "semantic_relation": 2.98432,
            "contradiction": 48.72246,
            "irrelevancy": 4.65614,
            "logical_agreement": 46.6214,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.56575,
            "nubia_score": 0.42408
        },
        "bleurt": -0.29648
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.323856189774722,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.27443964427976514,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.8333333333333334,
            "3": 0.6
        },
        "nist": 1.9267990898795473,
        "rouge1": {
            "precision": 0.53968,
            "recall": 0.69281,
            "fmeasure": 0.60624
        },
        "rouge2": {
            "precision": 0.28333,
            "recall": 0.40152,
            "fmeasure": 0.32975
        },
        "rougeL": {
            "precision": 0.26984,
            "recall": 0.34641,
            "fmeasure": 0.30312
        },
        "rougeLsum": {
            "precision": 0.26984,
            "recall": 0.34641,
            "fmeasure": 0.30312
        },
        "bleu": 15.26847,
        "meteor": 0.320846468860825,
        "bertscore": {
            "precision": 0.77848,
            "recall": 0.82904,
            "f1": 0.79527
        },
        "nubia": {
            "semantic_relation": 3.42872,
            "contradiction": 89.21999,
            "irrelevancy": 5.57654,
            "logical_agreement": 5.20346,
            "grammar_ref": 4.69116,
            "grammar_hyp": 3.60943,
            "nubia_score": 0.58112
        },
        "bleurt": -0.38577
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6416041678685933,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.4769363694743175,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "nist": 3.6643779994262076,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.93333,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.53333,
            "fmeasure": 0.51613
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.53333,
            "fmeasure": 0.51613
        },
        "bleu": 55.64293,
        "meteor": 0.49102193871620886,
        "bertscore": {
            "precision": 0.95759,
            "recall": 0.96381,
            "f1": 0.96069
        },
        "nubia": {
            "semantic_relation": 4.9347,
            "contradiction": 0.41479,
            "irrelevancy": 2.55872,
            "logical_agreement": 97.02649,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.79392,
            "nubia_score": 0.98378
        },
        "bleurt": 0.50338
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 2.5,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.262692390839622,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.05923165719793805,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.06613640645429873,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.576690127727686,
        "rouge1": {
            "precision": 0.90598,
            "recall": 0.94302,
            "fmeasure": 0.92341
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.82738,
            "fmeasure": 0.80833
        },
        "rougeL": {
            "precision": 0.86752,
            "recall": 0.90456,
            "fmeasure": 0.88495
        },
        "rougeLsum": {
            "precision": 0.86752,
            "recall": 0.90456,
            "fmeasure": 0.88495
        },
        "bleu": 70.68064,
        "meteor": 0.5304102780876586,
        "bertscore": {
            "precision": 0.97242,
            "recall": 0.97115,
            "f1": 0.96915
        },
        "nubia": {
            "semantic_relation": 4.59102,
            "contradiction": 0.84347,
            "irrelevancy": 33.70932,
            "logical_agreement": 65.44722,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.60242,
            "nubia_score": 0.80458
        },
        "bleurt": 0.54633
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.144219710220949,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 0.7857142857142857
        },
        "nist": 4.4488238176630786,
        "rouge1": {
            "precision": 0.80702,
            "recall": 0.7582,
            "fmeasure": 0.78028
        },
        "rouge2": {
            "precision": 0.62963,
            "recall": 0.54882,
            "fmeasure": 0.58519
        },
        "rougeL": {
            "precision": 0.70175,
            "recall": 0.61632,
            "fmeasure": 0.65497
        },
        "rougeLsum": {
            "precision": 0.70175,
            "recall": 0.61632,
            "fmeasure": 0.65497
        },
        "bleu": 52.63514,
        "meteor": 0.40971321883778533,
        "bertscore": {
            "precision": 0.9481,
            "recall": 0.92419,
            "f1": 0.93599
        },
        "nubia": {
            "semantic_relation": 4.2534,
            "contradiction": 70.31264,
            "irrelevancy": 16.27467,
            "logical_agreement": 13.41269,
            "grammar_ref": 4.95426,
            "grammar_hyp": 4.6559,
            "nubia_score": 0.68493
        },
        "bleurt": 0.21907
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.02136900249640835,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "nist": 1.9724163251485751,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.65385,
            "fmeasure": 0.77273
        },
        "rouge2": {
            "precision": 0.62745,
            "recall": 0.41538,
            "fmeasure": 0.49982
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.5,
            "fmeasure": 0.59091
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.5,
            "fmeasure": 0.59091
        },
        "bleu": 31.95625,
        "meteor": 0.32863115856117786,
        "bertscore": {
            "precision": 0.96421,
            "recall": 0.91518,
            "f1": 0.93897
        },
        "nubia": {
            "semantic_relation": 3.53288,
            "contradiction": 6.38527,
            "irrelevancy": 1.48021,
            "logical_agreement": 92.13452,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.40096,
            "nubia_score": 0.51911
        },
        "bleurt": 0.10223
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 4.306797170061882,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.82353,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70238
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "bleu": 69.04427,
        "meteor": 0.5500501807094148,
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.97025,
            "f1": 0.97145
        },
        "nubia": {
            "semantic_relation": 4.27928,
            "contradiction": 0.25448,
            "irrelevancy": 0.49291,
            "logical_agreement": 99.25261,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.38971,
            "nubia_score": 0.78008
        },
        "bleurt": 0.47554
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.2775418301849517,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "bleu": 11.33958,
        "meteor": 0.31127891035349853,
        "bertscore": {
            "precision": 0.8573,
            "recall": 0.88842,
            "f1": 0.87258
        },
        "nubia": {
            "semantic_relation": 3.94411,
            "contradiction": 0.52809,
            "irrelevancy": 90.87595,
            "logical_agreement": 8.59595,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.74554,
            "nubia_score": 0.60532
        },
        "bleurt": -0.04695
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.8571428571428571
        },
        "nist": 2.8441645853579183,
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.65625,
            "fmeasure": 0.57857
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.70588,
            "fmeasure": 0.64242
        },
        "bleu": 44.5345,
        "meteor": 0.4505163353501177,
        "bertscore": {
            "precision": 0.89821,
            "recall": 0.93375,
            "f1": 0.91564
        },
        "nubia": {
            "semantic_relation": 4.19399,
            "contradiction": 0.18495,
            "irrelevancy": 94.22535,
            "logical_agreement": 5.5897,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.31806,
            "nubia_score": 0.76494
        },
        "bleurt": 0.30287
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064474,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064474,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.22961067210860203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.8888888888888888
        },
        "nist": 1.9618375097242198,
        "rouge1": {
            "precision": 0.4697,
            "recall": 0.57346,
            "fmeasure": 0.51562
        },
        "rouge2": {
            "precision": 0.19048,
            "recall": 0.26111,
            "fmeasure": 0.22022
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.34056,
            "fmeasure": 0.30269
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.34056,
            "fmeasure": 0.30269
        },
        "bleu": 12.58221,
        "meteor": 0.28723090395593437,
        "bertscore": {
            "precision": 0.83182,
            "recall": 0.868,
            "f1": 0.84824
        },
        "nubia": {
            "semantic_relation": 2.55451,
            "contradiction": 23.10491,
            "irrelevancy": 70.4213,
            "logical_agreement": 6.47379,
            "grammar_ref": 3.5564,
            "grammar_hyp": 4.16596,
            "nubia_score": 0.31353
        },
        "bleurt": -0.27561
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.061482186720775,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": 0.10024085135823842,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.040891982333938634,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.892407118592875,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.11923459263989908,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.04723891230848747,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "nist": 1.7577114281254704,
        "rouge1": {
            "precision": 0.71795,
            "recall": 0.48077,
            "fmeasure": 0.56239
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.31132,
            "fmeasure": 0.38749
        },
        "rougeL": {
            "precision": 0.71795,
            "recall": 0.48077,
            "fmeasure": 0.56239
        },
        "rougeLsum": {
            "precision": 0.71795,
            "recall": 0.48077,
            "fmeasure": 0.56239
        },
        "bleu": 27.07109,
        "meteor": 0.2851386040250059,
        "bertscore": {
            "precision": 0.87658,
            "recall": 0.8369,
            "f1": 0.85543
        },
        "nubia": {
            "semantic_relation": 3.40048,
            "contradiction": 0.17057,
            "irrelevancy": 49.72166,
            "logical_agreement": 50.10778,
            "grammar_ref": 4.47266,
            "grammar_hyp": 3.87854,
            "nubia_score": 0.62479
        },
        "bleurt": -0.27287
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 4.5,
        "median_pred_length": 12.5,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.373660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.08644000550678685,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.243300368538955,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.10024085135823842,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8947368421052632
        },
        "nist": 3.0047909496716065,
        "rouge1": {
            "precision": 0.88571,
            "recall": 0.69166,
            "fmeasure": 0.76041
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.47863,
            "fmeasure": 0.496
        },
        "rougeL": {
            "precision": 0.58571,
            "recall": 0.53247,
            "fmeasure": 0.55464
        },
        "rougeLsum": {
            "precision": 0.58571,
            "recall": 0.53247,
            "fmeasure": 0.55464
        },
        "bleu": 50.13106,
        "meteor": 0.42294625629195537,
        "bertscore": {
            "precision": 0.95519,
            "recall": 0.94669,
            "f1": 0.9509
        },
        "nubia": {
            "semantic_relation": 3.85584,
            "contradiction": 1.52934,
            "irrelevancy": 1.51948,
            "logical_agreement": 96.95118,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.10397,
            "nubia_score": 0.6747
        },
        "bleurt": 0.25176
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 71,
        "mean_pred_length": 14.2,
        "std_pred_length": 4.019950248448357,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.704225352112676,
        "vocab_size-1": 50,
        "unique-1": 39,
        "entropy-1": 5.395045585343079,
        "distinct-2": 0.8787878787878788,
        "vocab_size-2": 58,
        "unique-2": 51,
        "entropy-2": 5.7905321875075,
        "cond_entropy-2": 0.2767573172609476,
        "distinct-3": 0.9016393442622951,
        "vocab_size-3": 55,
        "unique-3": 49,
        "entropy-3": 5.734016026087476,
        "cond_entropy-3": -0.0357078063502645,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.286335345030997,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7833333333333333,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.400815129331846,
        "distinct-2-nopunct": 0.8727272727272727,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.513089031667139,
        "cond_entropy-2-nopunct": 0.15828076290590146,
        "distinct-3-nopunct": 0.9,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.443856189774724,
        "cond_entropy-3-nopunct": -0.042405773706665637,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.8043478260869565
        },
        "nist": 4.98908214967068,
        "rouge1": {
            "precision": 0.8381,
            "recall": 0.81172,
            "fmeasure": 0.82191
        },
        "rouge2": {
            "precision": 0.71317,
            "recall": 0.69335,
            "fmeasure": 0.70095
        },
        "rougeL": {
            "precision": 0.77365,
            "recall": 0.8036,
            "fmeasure": 0.77492
        },
        "rougeLsum": {
            "precision": 0.77365,
            "recall": 0.8036,
            "fmeasure": 0.77492
        },
        "bleu": 60.04551,
        "meteor": 0.4395873420311443,
        "bertscore": {
            "precision": 0.94596,
            "recall": 0.95135,
            "f1": 0.94774
        },
        "nubia": {
            "semantic_relation": 4.37343,
            "contradiction": 16.72629,
            "irrelevancy": 10.62962,
            "logical_agreement": 72.64408,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.65385,
            "nubia_score": 0.80626
        },
        "bleurt": 0.50754
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 9,
        "unique-1": 7,
        "entropy-1": 3.0957952550009344,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.262496476250065,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.9219280948873623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.29244135099939467,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 0.6179519972810469,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.57857,
            "fmeasure": 0.7
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.60317,
            "fmeasure": 0.72115
        },
        "bleu": 30.67489,
        "meteor": 0.4466946348571188,
        "bertscore": {
            "precision": 0.97564,
            "recall": 0.89184,
            "f1": 0.93186
        },
        "nubia": {
            "semantic_relation": 4.15284,
            "contradiction": 0.35397,
            "irrelevancy": 0.51105,
            "logical_agreement": 99.13498,
            "grammar_ref": 2.70093,
            "grammar_hyp": 2.8924,
            "nubia_score": 0.88513
        },
        "bleurt": 0.26056
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.42857142857142855
        },
        "nist": 1.3958920781800714,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.2037,
            "fmeasure": 0.21164
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.38462,
            "fmeasure": 0.43478
        },
        "bleu": 8.60612,
        "meteor": 0.23484797711253358,
        "bertscore": {
            "precision": 0.89235,
            "recall": 0.85571,
            "f1": 0.87365
        },
        "nubia": {
            "semantic_relation": 3.48593,
            "contradiction": 5.45948,
            "irrelevancy": 89.32513,
            "logical_agreement": 5.2154,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.57908,
            "nubia_score": 0.48361
        },
        "bleurt": -0.19069
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2221,
        "msttr-100": 0.72961,
        "msttr-100_nopunct": 0.78266,
        "total_length": 33618,
        "mean_pred_length": 15.136425033768573,
        "std_pred_length": 4.0256753198221285,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.25409007079540724,
        "vocab_size-1": 8542,
        "unique-1": 6150,
        "entropy-1": 9.672349003374658,
        "distinct-2": 0.6462400866324808,
        "vocab_size-2": 20290,
        "unique-2": 17650,
        "entropy-2": 13.423165928330716,
        "cond_entropy-2": 3.363096706769961,
        "distinct-3": 0.8420276939950644,
        "vocab_size-3": 24567,
        "unique-3": 22874,
        "entropy-3": 14.310620161030284,
        "cond_entropy-3": 0.8929223694172741,
        "total_length-nopunct": 29353,
        "mean_pred_length-nopunct": 13.216118865375957,
        "std_pred_length-nopunct": 3.714620767881405,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.29046434776683816,
        "vocab_size-1-nopunct": 8526,
        "unique-1-nopunct": 6150,
        "entropy-1-nopunct": 10.178505715960082,
        "distinct-2-nopunct": 0.6830679640277163,
        "vocab_size-2-nopunct": 18533,
        "unique-2-nopunct": 16449,
        "entropy-2-nopunct": 13.341991118506133,
        "cond_entropy-2-nopunct": 3.3506737907214528,
        "distinct-3-nopunct": 0.8676086869254546,
        "vocab_size-3-nopunct": 21613,
        "unique-3-nopunct": 20288,
        "entropy-3-nopunct": 14.194805039828342,
        "cond_entropy-3-nopunct": 0.9271963673112225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.210902466367713,
            "2": 0.45233938547486036,
            "3": 0.7981738035264484
        },
        "nist": 10.347219513680784,
        "rouge1": {
            "precision": 0.78045,
            "recall": 0.75908,
            "fmeasure": 0.75958
        },
        "rouge2": {
            "precision": 0.55211,
            "recall": 0.53745,
            "fmeasure": 0.53726
        },
        "rougeL": {
            "precision": 0.67449,
            "recall": 0.65922,
            "fmeasure": 0.65788
        },
        "rougeLsum": {
            "precision": 0.67449,
            "recall": 0.65922,
            "fmeasure": 0.65788
        },
        "bleu": 49.23965,
        "meteor": 0.41238587623883705,
        "bertscore": {
            "precision": 0.93532,
            "recall": 0.93284,
            "f1": 0.93253
        },
        "nubia": {
            "semantic_relation": 4.32918,
            "contradiction": 7.48844,
            "irrelevancy": 27.71824,
            "logical_agreement": 64.79332,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.7129,
            "nubia_score": 0.76675
        },
        "bleurt": 0.32702
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.423065265165703,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "bleurt": 0.94038
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.72,
        "vocab_size-1": 18,
        "unique-1": 13,
        "entropy-1": 4.003856189774724,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 20,
        "unique-2": 16,
        "entropy-2": 4.251629167387823,
        "cond_entropy-2": 0.2744396442797651,
        "distinct-3": 0.8695652173913043,
        "vocab_size-3": 20,
        "unique-3": 17,
        "entropy-3": 4.2626923908396215,
        "cond_entropy-3": 0.025555977074987166,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.003856189774724,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.251629167387823,
        "cond_entropy-2-nopunct": 0.2744396442797651,
        "distinct-3-nopunct": 0.8695652173913043,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.2626923908396215,
        "cond_entropy-3-nopunct": 0.025555977074987166,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.8571428571428571
        },
        "nist": 3.4303294717710595,
        "rouge1": {
            "precision": 0.69333,
            "recall": 0.81667,
            "fmeasure": 0.7486
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.54539,
            "fmeasure": 0.49711
        },
        "rougeL": {
            "precision": 0.44,
            "recall": 0.64167,
            "fmeasure": 0.52069
        },
        "rougeLsum": {
            "precision": 0.44,
            "recall": 0.64167,
            "fmeasure": 0.52069
        },
        "bleu": 38.61305,
        "meteor": 0.397275727360782,
        "bertscore": {
            "precision": 0.89506,
            "recall": 0.90084,
            "f1": 0.89794
        },
        "nubia": {
            "semantic_relation": 3.9779,
            "contradiction": 71.05728,
            "irrelevancy": 25.97854,
            "logical_agreement": 2.96418,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.30783,
            "nubia_score": 0.66879
        },
        "bleurt": -0.49343
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4444444444444444
        },
        "nist": 1.6609640474436813,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "bleu": 12.54931,
        "meteor": 0.2497917181849062,
        "bertscore": {
            "precision": 0.87569,
            "recall": 0.89844,
            "f1": 0.88692
        },
        "nubia": {
            "semantic_relation": 3.91509,
            "contradiction": 4.26281,
            "irrelevancy": 87.48299,
            "logical_agreement": 8.25419,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.12667,
            "nubia_score": 0.73928
        },
        "bleurt": 0.23686
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 11.25,
        "std_pred_length": 2.0463381929681126,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 13,
        "distinct-1": 0.6888888888888889,
        "vocab_size-1": 31,
        "unique-1": 22,
        "entropy-1": 4.763966707392708,
        "distinct-2": 0.9024390243902439,
        "vocab_size-2": 37,
        "unique-2": 33,
        "entropy-2": 5.16243005339857,
        "cond_entropy-2": 0.2743547010241032,
        "distinct-3": 0.918918918918919,
        "vocab_size-3": 34,
        "unique-3": 31,
        "entropy-3": 5.047291203466791,
        "cond_entropy-3": -0.09404458493507994,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.8708286933869707,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.725,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.703055907333276,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.947702779220088,
        "cond_entropy-2-nopunct": 0.2856326705039354,
        "distinct-3-nopunct": 0.90625,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.8125,
        "cond_entropy-3-nopunct": -0.1386750014423123,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "nist": 5.55421600412142,
        "rouge1": {
            "precision": 0.94823,
            "recall": 0.88211,
            "fmeasure": 0.9066
        },
        "rouge2": {
            "precision": 0.88561,
            "recall": 0.82143,
            "fmeasure": 0.84266
        },
        "rougeL": {
            "precision": 0.94066,
            "recall": 0.86068,
            "fmeasure": 0.88817
        },
        "rougeLsum": {
            "precision": 0.94066,
            "recall": 0.86068,
            "fmeasure": 0.88817
        },
        "bleu": 85.5968,
        "meteor": 0.5731905554767702,
        "bertscore": {
            "precision": 0.99263,
            "recall": 0.9822,
            "f1": 0.98617
        },
        "nubia": {
            "semantic_relation": 4.76457,
            "contradiction": 2.27896,
            "irrelevancy": 12.491,
            "logical_agreement": 85.23004,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.6001,
            "nubia_score": 0.92265
        },
        "bleurt": 0.68011
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4,
            "3": 1.0
        },
        "nist": 3.2866794379597706,
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.89744,
            "fmeasure": 0.77333
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "bleu": 65.15133,
        "meteor": 0.529059933593805,
        "bertscore": {
            "precision": 0.93213,
            "recall": 0.98656,
            "f1": 0.9436
        },
        "nubia": {
            "semantic_relation": 4.55545,
            "contradiction": 1.67199,
            "irrelevancy": 54.10654,
            "logical_agreement": 44.22148,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.94977,
            "nubia_score": 0.66237
        },
        "bleurt": 0.25275
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6901165175936654,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.20971762763487733,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.4565647621309536,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.24009914803219046,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 4.026196058544812,
        "rouge1": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rouge2": {
            "precision": 0.82353,
            "recall": 0.91071,
            "fmeasure": 0.86413
        },
        "rougeL": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rougeLsum": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "bleu": 69.0167,
        "meteor": 0.6108178404694528,
        "bertscore": {
            "precision": 0.98423,
            "recall": 0.99714,
            "f1": 0.99064
        },
        "nubia": {
            "semantic_relation": 4.96299,
            "contradiction": 0.14795,
            "irrelevancy": 3.49378,
            "logical_agreement": 96.35828,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.07239,
            "nubia_score": 0.98909
        },
        "bleurt": 0.81116
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.5625
        },
        "nist": 1.5982245915424167,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.47826,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.34091,
            "fmeasure": 0.40336
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.47826,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.47826,
            "fmeasure": 0.61111
        },
        "bleu": 34.01102,
        "meteor": 0.3496300493456508,
        "bertscore": {
            "precision": 0.97321,
            "recall": 0.91953,
            "f1": 0.93834
        },
        "nubia": {
            "semantic_relation": 3.8252,
            "contradiction": 35.4933,
            "irrelevancy": 2.38998,
            "logical_agreement": 62.11671,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.52825,
            "nubia_score": 0.53725
        },
        "bleurt": 0.40241
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 1.5,
        "median_pred_length": 20.5,
        "min_pred_length": 19,
        "max_pred_length": 22,
        "distinct-1": 0.7073170731707317,
        "vocab_size-1": 29,
        "unique-1": 22,
        "entropy-1": 4.585564578900931,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 36,
        "unique-2": 33,
        "entropy-2": 5.131556065016094,
        "cond_entropy-2": 0.5342985335878375,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": 0.08621330892886339,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7105263157894737,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.46762529095929,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.003258334775643,
        "cond_entropy-2-nopunct": 0.5789831672877053,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": 0.09400842804332116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.2222222222222222,
            "3": 0.7647058823529411
        },
        "nist": 2.7925588214781194,
        "rouge1": {
            "precision": 0.5172,
            "recall": 0.76923,
            "fmeasure": 0.59581
        },
        "rouge2": {
            "precision": 0.28529,
            "recall": 0.38922,
            "fmeasure": 0.31772
        },
        "rougeL": {
            "precision": 0.45238,
            "recall": 0.65076,
            "fmeasure": 0.51471
        },
        "rougeLsum": {
            "precision": 0.45238,
            "recall": 0.65076,
            "fmeasure": 0.51471
        },
        "bleu": 18.54383,
        "meteor": 0.3661786684947903,
        "bertscore": {
            "precision": 0.88298,
            "recall": 0.92287,
            "f1": 0.89571
        },
        "nubia": {
            "semantic_relation": 3.45857,
            "contradiction": 43.88844,
            "irrelevancy": 54.10473,
            "logical_agreement": 2.00682,
            "grammar_ref": 4.30067,
            "grammar_hyp": 3.43539,
            "nubia_score": 0.49574
        },
        "bleurt": 0.13044
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.96655480858378,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 32,
        "unique-1": 23,
        "entropy-1": 4.769974678246913,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 40,
        "unique-2": 35,
        "entropy-2": 5.269630874107453,
        "cond_entropy-2": 0.44832455064408017,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 39,
        "unique-3": 36,
        "entropy-3": 5.249460279921619,
        "cond_entropy-3": -0.051916625931866786,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 4.496912521077347,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.678419619169109,
        "distinct-2-nopunct": 0.9024390243902439,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.16243005339857,
        "cond_entropy-2-nopunct": 0.4923771658978665,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.142664355548852,
        "cond_entropy-3-nopunct": -0.05699291222712946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8387096774193549
        },
        "nist": 3.7375636414431725,
        "rouge1": {
            "precision": 0.77646,
            "recall": 0.8771,
            "fmeasure": 0.81083
        },
        "rouge2": {
            "precision": 0.67273,
            "recall": 0.73131,
            "fmeasure": 0.6915
        },
        "rougeL": {
            "precision": 0.74471,
            "recall": 0.81987,
            "fmeasure": 0.77
        },
        "rougeLsum": {
            "precision": 0.74471,
            "recall": 0.81987,
            "fmeasure": 0.77
        },
        "bleu": 52.6563,
        "meteor": 0.5044439755361613,
        "bertscore": {
            "precision": 0.92711,
            "recall": 0.94802,
            "f1": 0.93672
        },
        "nubia": {
            "semantic_relation": 4.43417,
            "contradiction": 0.76411,
            "irrelevancy": 33.33212,
            "logical_agreement": 65.90377,
            "grammar_ref": 3.77014,
            "grammar_hyp": 3.85096,
            "nubia_score": 0.72249
        },
        "bleurt": 0.45857
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "nist": 1.8698036872250576,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.7,
            "fmeasure": 0.61153
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.27381,
            "fmeasure": 0.23094
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.48148,
            "fmeasure": 0.41404
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.48148,
            "fmeasure": 0.41404
        },
        "bleu": 14.45892,
        "meteor": 0.28832147879749986,
        "bertscore": {
            "precision": 0.84299,
            "recall": 0.91565,
            "f1": 0.87782
        },
        "nubia": {
            "semantic_relation": 2.94787,
            "contradiction": 0.21582,
            "irrelevancy": 99.61172,
            "logical_agreement": 0.17246,
            "grammar_ref": 5.1757,
            "grammar_hyp": 4.98107,
            "nubia_score": 0.33463
        },
        "bleurt": -0.44746
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 3.0476314089081704,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.69841,
            "fmeasure": 0.77273
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "bleu": 86.68779,
        "meteor": 0.5570133484098374,
        "bertscore": {
            "precision": 0.99092,
            "recall": 0.97079,
            "f1": 0.98075
        },
        "nubia": {
            "semantic_relation": 4.22675,
            "contradiction": 0.58601,
            "irrelevancy": 0.55339,
            "logical_agreement": 98.8606,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.5844,
            "nubia_score": 0.77636
        },
        "bleurt": 0.30208
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.8,
        "vocab_size-1": 24,
        "unique-1": 18,
        "entropy-1": 4.506890595608518,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 27,
        "unique-2": 26,
        "entropy-2": 4.735926350629034,
        "cond_entropy-2": 0.18617861216337128,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.029992126993435266,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8148148148148148,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.3845171317931,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.2089686876112561,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.875,
            "3": 0.4
        },
        "nist": 2.2343181770007106,
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.70833,
            "fmeasure": 0.6098
        },
        "rouge2": {
            "precision": 0.2861,
            "recall": 0.4212,
            "fmeasure": 0.33905
        },
        "rougeL": {
            "precision": 0.51389,
            "recall": 0.67824,
            "fmeasure": 0.58094
        },
        "rougeLsum": {
            "precision": 0.51389,
            "recall": 0.67824,
            "fmeasure": 0.58094
        },
        "bleu": 15.0652,
        "meteor": 0.2854012803176627,
        "bertscore": {
            "precision": 0.8766,
            "recall": 0.89701,
            "f1": 0.88658
        },
        "nubia": {
            "semantic_relation": 3.94305,
            "contradiction": 15.0187,
            "irrelevancy": 56.99333,
            "logical_agreement": 27.98798,
            "grammar_ref": 4.27476,
            "grammar_hyp": 4.085,
            "nubia_score": 0.61182
        },
        "bleurt": 0.17682
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.548645758111165,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "bleu": 100.0,
        "meteor": 0.5161210442123606,
        "bertscore": {
            "precision": 0.98951,
            "recall": 0.9715,
            "f1": 0.98042
        },
        "nubia": {
            "semantic_relation": 4.65439,
            "contradiction": 0.55881,
            "irrelevancy": 1.76619,
            "logical_agreement": 97.675,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.54703,
            "nubia_score": 0.85279
        },
        "bleurt": 0.7198
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nist": 0.19003668623571202,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.2963,
            "fmeasure": 0.38095
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.07692,
            "fmeasure": 0.1
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.22222,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.22222,
            "fmeasure": 0.28571
        },
        "bleu": 2.39312,
        "meteor": 0.12284204619153719,
        "bertscore": {
            "precision": 0.8744,
            "recall": 0.81241,
            "f1": 0.84157
        },
        "nubia": {
            "semantic_relation": 2.23263,
            "contradiction": 71.71604,
            "irrelevancy": 16.23069,
            "logical_agreement": 12.05327,
            "grammar_ref": 4.95946,
            "grammar_hyp": 6.10195,
            "nubia_score": 0.1122
        },
        "bleurt": -0.33252
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.1365257343456969,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.14421971022094907,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "nist": 3.220065255780316,
        "rouge1": {
            "precision": 0.71212,
            "recall": 0.7995,
            "fmeasure": 0.75288
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.42963,
            "fmeasure": 0.40359
        },
        "rougeL": {
            "precision": 0.60606,
            "recall": 0.69444,
            "fmeasure": 0.64463
        },
        "rougeLsum": {
            "precision": 0.60606,
            "recall": 0.69444,
            "fmeasure": 0.64463
        },
        "bleu": 18.18523,
        "meteor": 0.40910304984754253,
        "bertscore": {
            "precision": 0.93026,
            "recall": 0.9616,
            "f1": 0.93622
        },
        "nubia": {
            "semantic_relation": 4.50134,
            "contradiction": 0.63296,
            "irrelevancy": 38.43066,
            "logical_agreement": 60.93637,
            "grammar_ref": 4.42639,
            "grammar_hyp": 3.81245,
            "nubia_score": 0.89303
        },
        "bleurt": 0.53196
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nist": 2.9211152056479777,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.83333,
            "fmeasure": 0.68182
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.46061,
            "fmeasure": 0.35238
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.58333,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.58333,
            "fmeasure": 0.48485
        },
        "bleu": 13.9508,
        "meteor": 0.42919650333815856,
        "bertscore": {
            "precision": 0.85844,
            "recall": 0.91708,
            "f1": 0.87512
        },
        "nubia": {
            "semantic_relation": 4.41335,
            "contradiction": 3.46921,
            "irrelevancy": 67.46956,
            "logical_agreement": 29.06123,
            "grammar_ref": 5.75818,
            "grammar_hyp": 4.95052,
            "nubia_score": 0.7923
        },
        "bleurt": 0.06204
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.76,
        "vocab_size-1": 19,
        "unique-1": 14,
        "entropy-1": 4.133660689688185,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.38922662353657617,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.02555597707498716,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.970573095811684,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.397404256625438,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "nist": 3.354016195374793,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.89474,
            "fmeasure": 0.82927
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.72222,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.84211,
            "fmeasure": 0.78049
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.84211,
            "fmeasure": 0.78049
        },
        "bleu": 49.89095,
        "meteor": 0.541005391823665,
        "bertscore": {
            "precision": 0.96747,
            "recall": 0.98144,
            "f1": 0.9744
        },
        "nubia": {
            "semantic_relation": 3.89611,
            "contradiction": 69.80441,
            "irrelevancy": 27.35129,
            "logical_agreement": 2.8443,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.24504,
            "nubia_score": 0.69132
        },
        "bleurt": 0.61498
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 3.2860710481699047,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.76282,
            "fmeasure": 0.68567
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.58286,
            "fmeasure": 0.54454
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.71154,
            "fmeasure": 0.67141
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.71154,
            "fmeasure": 0.67141
        },
        "bleu": 75.33808,
        "meteor": 0.506755908421319,
        "bertscore": {
            "precision": 0.96671,
            "recall": 0.96947,
            "f1": 0.94794
        },
        "nubia": {
            "semantic_relation": 4.13404,
            "contradiction": 0.15948,
            "irrelevancy": 0.41726,
            "logical_agreement": 99.42326,
            "grammar_ref": 4.62626,
            "grammar_hyp": 4.25404,
            "nubia_score": 0.74012
        },
        "bleurt": 0.29806
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "nist": 1.0909514646162273,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.3125,
            "fmeasure": 0.40724
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "bleu": 31.85036,
        "meteor": 0.3769465296142278,
        "bertscore": {
            "precision": 0.94653,
            "recall": 0.89087,
            "f1": 0.91786
        },
        "nubia": {
            "semantic_relation": 3.4502,
            "contradiction": 1.65058,
            "irrelevancy": 0.74865,
            "logical_agreement": 97.60076,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.46862,
            "nubia_score": 0.42783
        },
        "bleurt": 0.09535
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2222222222222222,
            "3": 0.5
        },
        "nist": 1.5966562549167245,
        "rouge1": {
            "precision": 0.76471,
            "recall": 0.5166,
            "fmeasure": 0.61389
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.2899,
            "fmeasure": 0.34706
        },
        "rougeL": {
            "precision": 0.5098,
            "recall": 0.28244,
            "fmeasure": 0.36348
        },
        "rougeLsum": {
            "precision": 0.5098,
            "recall": 0.28244,
            "fmeasure": 0.36348
        },
        "bleu": 27.19717,
        "meteor": 0.3088669897877822,
        "bertscore": {
            "precision": 0.91828,
            "recall": 0.88938,
            "f1": 0.9022
        },
        "nubia": {
            "semantic_relation": 4.31358,
            "contradiction": 3.43136,
            "irrelevancy": 25.66466,
            "logical_agreement": 70.90398,
            "grammar_ref": 3.59602,
            "grammar_hyp": 4.63491,
            "nubia_score": 0.63554
        },
        "bleurt": -0.07122
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nist": 2.7369968230962227,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.86667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.7037,
            "fmeasure": 0.71429
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.83333,
            "fmeasure": 0.875
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.83333,
            "fmeasure": 0.875
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.132,
            "contradiction": 37.88177,
            "irrelevancy": 4.91853,
            "logical_agreement": 57.19971,
            "grammar_ref": 7.45181,
            "grammar_hyp": 7.51977,
            "nubia_score": 0.62683
        },
        "bleurt": 0.19863
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.5555555555555556,
        "vocab_size-1": 10,
        "unique-1": 2,
        "entropy-1": 3.281036112553423,
        "distinct-2": 0.5625,
        "vocab_size-2": 9,
        "unique-2": 2,
        "entropy-2": 3.125,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 0.5714285714285714,
        "vocab_size-3": 8,
        "unique-3": 2,
        "entropy-3": 2.950212064914747,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.5625,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 3.125,
        "distinct-2-nopunct": 0.5714285714285714,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 2,
        "entropy-2-nopunct": 2.950212064914747,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 0.5833333333333334,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 2.7516291673878226,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.42857142857142855,
            "3": 0.5789473684210527
        },
        "nist": 1.697035321823286,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.56818,
            "fmeasure": 0.70175
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.46667,
            "fmeasure": 0.58645
        },
        "rougeL": {
            "precision": 0.85417,
            "recall": 0.52178,
            "fmeasure": 0.64254
        },
        "rougeLsum": {
            "precision": 0.85417,
            "recall": 0.52178,
            "fmeasure": 0.64254
        },
        "bleu": 42.50183,
        "meteor": 0.3176788270369236,
        "bertscore": {
            "precision": 0.89417,
            "recall": 0.79726,
            "f1": 0.83688
        },
        "nubia": {
            "semantic_relation": 4.26335,
            "contradiction": 0.17796,
            "irrelevancy": 17.03002,
            "logical_agreement": 82.79202,
            "grammar_ref": 4.70595,
            "grammar_hyp": 6.39652,
            "nubia_score": 0.58349
        },
        "bleurt": -0.17927
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.629358976048761,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.4,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "bleu": 9.42516,
        "meteor": 0.19752025008014962,
        "bertscore": {
            "precision": 0.88456,
            "recall": 0.87867,
            "f1": 0.87984
        },
        "nubia": {
            "semantic_relation": 4.74265,
            "contradiction": 0.56702,
            "irrelevancy": 0.54956,
            "logical_agreement": 98.88342,
            "grammar_ref": 3.90557,
            "grammar_hyp": 4.08981,
            "nubia_score": 0.88998
        },
        "bleurt": -0.18719
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 2.0,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 11,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 13,
        "unique-1": 8,
        "entropy-1": 3.6143694458867563,
        "distinct-2": 0.8125,
        "vocab_size-2": 13,
        "unique-2": 10,
        "entropy-2": 3.625,
        "cond_entropy-2": -0.04492500144231237,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 12,
        "unique-3": 10,
        "entropy-3": 3.521640636343319,
        "cond_entropy-3": -0.04978793508525297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.5,
        "distinct-2-nopunct": 0.7857142857142857,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.3787834934861767,
        "cond_entropy-2-nopunct": -0.1212165065138244,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.2516291673878226,
        "cond_entropy-3-nopunct": -0.1390590880031147,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9375
        },
        "nist": 4.502216352645386,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.93452,
            "fmeasure": 0.96544
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.85354,
            "fmeasure": 0.88312
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.93452,
            "fmeasure": 0.96544
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.93452,
            "fmeasure": 0.96544
        },
        "bleu": 85.38814,
        "meteor": 0.5952438063456653,
        "bertscore": {
            "precision": 0.99861,
            "recall": 0.99306,
            "f1": 0.99582
        },
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.56303,
            "irrelevancy": 0.53913,
            "logical_agreement": 98.89784,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.03959,
            "nubia_score": 0.96672
        },
        "bleurt": 0.87464
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 26,
        "unique-1": 20,
        "entropy-1": 4.572469458770135,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.39721762763487756,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.389898095464288,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.39777905872072056,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7142857142857143,
            "2": 0.6,
            "3": 0.391304347826087
        },
        "nist": 2.8482105992003977,
        "rouge1": {
            "precision": 0.58533,
            "recall": 0.53449,
            "fmeasure": 0.48422
        },
        "rouge2": {
            "precision": 0.28704,
            "recall": 0.28111,
            "fmeasure": 0.24082
        },
        "rougeL": {
            "precision": 0.35486,
            "recall": 0.44512,
            "fmeasure": 0.33677
        },
        "rougeLsum": {
            "precision": 0.35486,
            "recall": 0.44512,
            "fmeasure": 0.33677
        },
        "bleu": 19.83003,
        "meteor": 0.2281027490481822,
        "bertscore": {
            "precision": 0.87301,
            "recall": 0.81766,
            "f1": 0.83558
        },
        "nubia": {
            "semantic_relation": 3.85371,
            "contradiction": 13.87435,
            "irrelevancy": 82.08043,
            "logical_agreement": 4.04523,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.93397,
            "nubia_score": 0.4745
        },
        "bleurt": -0.06873
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 6.0,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 20,
        "unique-1": 12,
        "entropy-1": 4.235926350629033,
        "distinct-2": 0.8846153846153846,
        "vocab_size-2": 23,
        "unique-2": 20,
        "entropy-2": 4.46967048737186,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 23,
        "unique-3": 22,
        "entropy-3": 4.501629167387823,
        "cond_entropy-3": 0.051189449246730766,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.083856189774723,
        "distinct-2-nopunct": 0.8695652173913043,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.2626923908396215,
        "cond_entropy-2-nopunct": 0.18405359236924476,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.297079327540665,
        "cond_entropy-3-nopunct": 0.011612609578890444,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.7368421052631579
        },
        "nist": 4.104019304152478,
        "rouge1": {
            "precision": 0.78439,
            "recall": 0.71801,
            "fmeasure": 0.74672
        },
        "rouge2": {
            "precision": 0.55065,
            "recall": 0.50196,
            "fmeasure": 0.52256
        },
        "rougeL": {
            "precision": 0.6455,
            "recall": 0.63399,
            "fmeasure": 0.63773
        },
        "rougeLsum": {
            "precision": 0.6455,
            "recall": 0.63399,
            "fmeasure": 0.63773
        },
        "bleu": 20.58358,
        "meteor": 0.36509385182972576,
        "bertscore": {
            "precision": 0.90655,
            "recall": 0.87457,
            "f1": 0.88557
        },
        "nubia": {
            "semantic_relation": 4.40198,
            "contradiction": 1.10871,
            "irrelevancy": 23.96534,
            "logical_agreement": 74.92596,
            "grammar_ref": 6.00658,
            "grammar_hyp": 6.56575,
            "nubia_score": 0.73886
        },
        "bleurt": -0.2874
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.8888888888888888
        },
        "nist": 3.80697505858275,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.87879,
            "fmeasure": 0.84058
        },
        "rouge2": {
            "precision": 0.51515,
            "recall": 0.56667,
            "fmeasure": 0.53968
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.78788,
            "fmeasure": 0.75362
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.78788,
            "fmeasure": 0.75362
        },
        "bleu": 49.47995,
        "meteor": 0.4623407079430669,
        "bertscore": {
            "precision": 0.96423,
            "recall": 0.9657,
            "f1": 0.96496
        },
        "nubia": {
            "semantic_relation": 4.68889,
            "contradiction": 0.52091,
            "irrelevancy": 0.54061,
            "logical_agreement": 98.93848,
            "grammar_ref": 4.98843,
            "grammar_hyp": 4.66568,
            "nubia_score": 0.8851
        },
        "bleurt": 0.56066
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.7407407407407407,
        "vocab_size-1": 20,
        "unique-1": 14,
        "entropy-1": 4.208410187268527,
        "distinct-2": 0.8846153846153846,
        "vocab_size-2": 23,
        "unique-2": 20,
        "entropy-2": 4.46967048737186,
        "cond_entropy-2": 0.24381711990698776,
        "distinct-3": 0.96,
        "vocab_size-3": 24,
        "unique-3": 23,
        "entropy-3": 4.5638561897747225,
        "cond_entropy-3": 0.06341647163363251,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.16829583405449,
        "distinct-2-nopunct": 0.9130434782608695,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.349648912578752,
        "cond_entropy-2-nopunct": 0.15599075968368278,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": 0.07223329894392083,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5925925925925926
        },
        "nist": 2.656684780320107,
        "rouge1": {
            "precision": 0.86111,
            "recall": 0.63258,
            "fmeasure": 0.72932
        },
        "rouge2": {
            "precision": 0.7971,
            "recall": 0.57863,
            "fmeasure": 0.67048
        },
        "rougeL": {
            "precision": 0.86111,
            "recall": 0.63258,
            "fmeasure": 0.72932
        },
        "rougeLsum": {
            "precision": 0.86111,
            "recall": 0.63258,
            "fmeasure": 0.72932
        },
        "bleu": 48.5307,
        "meteor": 0.35430367830204545,
        "bertscore": {
            "precision": 0.95568,
            "recall": 0.85251,
            "f1": 0.90115
        },
        "nubia": {
            "semantic_relation": 2.96844,
            "contradiction": 97.84885,
            "irrelevancy": 1.31269,
            "logical_agreement": 0.83846,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.19421,
            "nubia_score": 0.39151
        },
        "bleurt": -0.0161
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.2626923908396215,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.059231657197938034,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.06613640645429873,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0,
            "3": 0.8
        },
        "nist": 3.4667220030053705,
        "rouge1": {
            "precision": 0.6803,
            "recall": 0.775,
            "fmeasure": 0.7176
        },
        "rouge2": {
            "precision": 0.51296,
            "recall": 0.56296,
            "fmeasure": 0.52963
        },
        "rougeL": {
            "precision": 0.6197,
            "recall": 0.73333,
            "fmeasure": 0.6598
        },
        "rougeLsum": {
            "precision": 0.6197,
            "recall": 0.73333,
            "fmeasure": 0.6598
        },
        "bleu": 54.20085,
        "meteor": 0.4594380372139235,
        "bertscore": {
            "precision": 0.93054,
            "recall": 0.93952,
            "f1": 0.93499
        },
        "nubia": {
            "semantic_relation": 4.20598,
            "contradiction": 0.26417,
            "irrelevancy": 49.69373,
            "logical_agreement": 50.0421,
            "grammar_ref": 5.47595,
            "grammar_hyp": 4.81585,
            "nubia_score": 0.8149
        },
        "bleurt": 0.32613
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 18,
        "unique-1": 13,
        "entropy-1": 4.088779347361362,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 19,
        "unique-2": 17,
        "entropy-2": 4.201841232302569,
        "cond_entropy-2": 0.05923165719793805,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": 0.06613640645429873,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.011365041826379,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.03740119765411,
        "cond_entropy-2-nopunct": 0.013504827506930314,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": 0.016005916042047978,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8235294117647058
        },
        "nist": 3.004705572609214,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.82222,
            "fmeasure": 0.75197
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.65079,
            "fmeasure": 0.59035
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.69722,
            "fmeasure": 0.63433
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.69722,
            "fmeasure": 0.63433
        },
        "bleu": 39.60914,
        "meteor": 0.4180407844493462,
        "bertscore": {
            "precision": 0.92118,
            "recall": 0.93128,
            "f1": 0.92545
        },
        "nubia": {
            "semantic_relation": 4.30453,
            "contradiction": 0.70885,
            "irrelevancy": 63.65019,
            "logical_agreement": 35.64096,
            "grammar_ref": 4.99735,
            "grammar_hyp": 4.95347,
            "nubia_score": 0.68166
        },
        "bleurt": 0.37413
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.932138039759373,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8365916681089787,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": 0.03753715874966059,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.707713228286067,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.94444,
            "fmeasure": 0.72371
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.81481,
            "fmeasure": 0.58667
        },
        "rougeL": {
            "precision": 0.56863,
            "recall": 0.96667,
            "fmeasure": 0.71605
        },
        "rougeLsum": {
            "precision": 0.56863,
            "recall": 0.96667,
            "fmeasure": 0.71605
        },
        "bleu": 45.80519,
        "meteor": 0.4997702403048333,
        "bertscore": {
            "precision": 0.91312,
            "recall": 0.97164,
            "f1": 0.94147
        },
        "nubia": {
            "semantic_relation": 4.4493,
            "contradiction": 0.23654,
            "irrelevancy": 89.29951,
            "logical_agreement": 10.46395,
            "grammar_ref": 4.2439,
            "grammar_hyp": 3.32368,
            "nubia_score": 0.86007
        },
        "bleurt": 0.21952
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 37.0,
        "std_pred_length": 0.0,
        "median_pred_length": 37.0,
        "min_pred_length": 37,
        "max_pred_length": 37,
        "distinct-1": 0.6216216216216216,
        "vocab_size-1": 23,
        "unique-1": 15,
        "entropy-1": 4.293931663441729,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 32,
        "unique-2": 29,
        "entropy-2": 4.926733681937769,
        "cond_entropy-2": 0.5937351742543733,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": 0.20949765842161017,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.136842188131013,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.3192467380386163,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": 0.026778753489375345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.5625
        },
        "nist": 2.7976857451394888,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.6936,
            "fmeasure": 0.6156
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.42484,
            "fmeasure": 0.37273
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.52189,
            "fmeasure": 0.46239
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.52189,
            "fmeasure": 0.46239
        },
        "bleu": 29.05857,
        "meteor": 0.34134508693357746,
        "bertscore": {
            "precision": 0.9102,
            "recall": 0.8784,
            "f1": 0.89402
        },
        "nubia": {
            "semantic_relation": 3.17984,
            "contradiction": 93.32704,
            "irrelevancy": 3.77378,
            "logical_agreement": 2.89918,
            "grammar_ref": 4.78465,
            "grammar_hyp": 4.7335,
            "nubia_score": 0.44157
        },
        "bleurt": -0.16629
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964166,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.75
        },
        "nist": 2.84954950651644,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.65241,
            "fmeasure": 0.73835
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.46032,
            "fmeasure": 0.52468
        },
        "rougeL": {
            "precision": 0.59524,
            "recall": 0.459,
            "fmeasure": 0.51673
        },
        "rougeLsum": {
            "precision": 0.59524,
            "recall": 0.459,
            "fmeasure": 0.51673
        },
        "bleu": 34.16581,
        "meteor": 0.37060886515159003,
        "bertscore": {
            "precision": 0.94522,
            "recall": 0.93299,
            "f1": 0.93906
        },
        "nubia": {
            "semantic_relation": 4.21871,
            "contradiction": 0.38555,
            "irrelevancy": 33.69289,
            "logical_agreement": 65.92156,
            "grammar_ref": 3.28677,
            "grammar_hyp": 4.11563,
            "nubia_score": 0.73112
        },
        "bleurt": 0.3584
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5
        },
        "nist": 1.5623847717153199,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.38636,
            "fmeasure": 0.46023
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.13853,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.29924,
            "fmeasure": 0.35227
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.29924,
            "fmeasure": 0.35227
        },
        "bleu": 19.81705,
        "meteor": 0.31942330884521747,
        "bertscore": {
            "precision": 0.8807,
            "recall": 0.87704,
            "f1": 0.87886
        },
        "nubia": {
            "semantic_relation": 3.31477,
            "contradiction": 1.17662,
            "irrelevancy": 98.4564,
            "logical_agreement": 0.36698,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.71906,
            "nubia_score": 0.33273
        },
        "bleurt": -0.50962
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.64,
        "vocab_size-1": 16,
        "unique-1": 7,
        "entropy-1": 3.923856189774724,
        "distinct-2": 0.6956521739130435,
        "vocab_size-2": 16,
        "unique-2": 9,
        "entropy-2": 3.914866303883101,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 0.7619047619047619,
        "vocab_size-3": 16,
        "unique-3": 11,
        "entropy-3": 3.916126946588284,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6521739130434783,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.8279097821439705,
        "distinct-2-nopunct": 0.7142857142857143,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.8208888513501886,
        "cond_entropy-2-nopunct": -0.03600643804015718,
        "distinct-3-nopunct": 0.7894736842105263,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.826874881864637,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "nist": 3.5116167764900608,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.80189,
            "fmeasure": 0.76769
        },
        "rouge2": {
            "precision": 0.5303,
            "recall": 0.56197,
            "fmeasure": 0.53963
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.76435,
            "fmeasure": 0.72821
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.76435,
            "fmeasure": 0.72821
        },
        "bleu": 40.84257,
        "meteor": 0.4460791410906078,
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.94854,
            "f1": 0.94365
        },
        "nubia": {
            "semantic_relation": 4.23888,
            "contradiction": 1.05291,
            "irrelevancy": 8.70231,
            "logical_agreement": 90.24479,
            "grammar_ref": 5.01983,
            "grammar_hyp": 5.27485,
            "nubia_score": 0.63683
        },
        "bleurt": 0.56107
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 17,
        "entropy-1": 4.3845171317931,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": 0.2532445236699311,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": 0.023416471633632502,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.315824333525707,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.4838561897747224,
        "cond_entropy-2-nopunct": 0.18341647163363248,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": 0.10777297761309834,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4666666666666667
        },
        "nist": 1.2609029705085284,
        "rouge1": {
            "precision": 0.26923,
            "recall": 0.41176,
            "fmeasure": 0.32558
        },
        "rouge2": {
            "precision": 0.16,
            "recall": 0.25,
            "fmeasure": 0.19512
        },
        "rougeL": {
            "precision": 0.19231,
            "recall": 0.29412,
            "fmeasure": 0.23256
        },
        "rougeLsum": {
            "precision": 0.19231,
            "recall": 0.29412,
            "fmeasure": 0.23256
        },
        "bleu": 14.61178,
        "meteor": 0.20326368596694702,
        "bertscore": {
            "precision": 0.77115,
            "recall": 0.79445,
            "f1": 0.78263
        },
        "nubia": {
            "semantic_relation": 1.92508,
            "contradiction": 16.62051,
            "irrelevancy": 83.16098,
            "logical_agreement": 0.2185,
            "grammar_ref": 4.28272,
            "grammar_hyp": 4.05981,
            "nubia_score": 0.23597
        },
        "bleurt": -0.47352
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548847,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983795,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.024962841250339415,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.625
        },
        "nist": 1.1060527391144788,
        "rouge1": {
            "precision": 0.38889,
            "recall": 0.66111,
            "fmeasure": 0.48889
        },
        "rouge2": {
            "precision": 0.17647,
            "recall": 0.31313,
            "fmeasure": 0.22527
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.56667,
            "fmeasure": 0.41905
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.56667,
            "fmeasure": 0.41905
        },
        "bleu": 6.33686,
        "meteor": 0.23036071983622422,
        "bertscore": {
            "precision": 0.79822,
            "recall": 0.85283,
            "f1": 0.82462
        },
        "nubia": {
            "semantic_relation": 3.33009,
            "contradiction": 0.17676,
            "irrelevancy": 99.68774,
            "logical_agreement": 0.13551,
            "grammar_ref": 4.40566,
            "grammar_hyp": 3.71576,
            "nubia_score": 0.52805
        },
        "bleurt": -0.19851
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.45454545454545453,
            "3": 1.0
        },
        "nist": 4.724361246816178,
        "rouge1": {
            "precision": 0.76667,
            "recall": 0.7,
            "fmeasure": 0.72778
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.46128,
            "fmeasure": 0.47037
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.63333,
            "fmeasure": 0.64848
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.63333,
            "fmeasure": 0.64848
        },
        "bleu": 54.91005,
        "meteor": 0.39658888089728345,
        "bertscore": {
            "precision": 0.95512,
            "recall": 0.94881,
            "f1": 0.95196
        },
        "nubia": {
            "semantic_relation": 3.7425,
            "contradiction": 15.37637,
            "irrelevancy": 36.03383,
            "logical_agreement": 48.5898,
            "grammar_ref": 4.72922,
            "grammar_hyp": 5.294,
            "nubia_score": 0.46123
        },
        "bleurt": 0.37962
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569693,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.14421971022094907,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.45454545454545453
        },
        "nist": 2.2221970596792264,
        "rouge1": {
            "precision": 0.36842,
            "recall": 0.47857,
            "fmeasure": 0.41622
        },
        "rouge2": {
            "precision": 0.13889,
            "recall": 0.18132,
            "fmeasure": 0.15726
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.34286,
            "fmeasure": 0.29768
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.34286,
            "fmeasure": 0.29768
        },
        "bleu": 16.19557,
        "meteor": 0.30257280602907694,
        "bertscore": {
            "precision": 0.84937,
            "recall": 0.87479,
            "f1": 0.8619
        },
        "nubia": {
            "semantic_relation": 3.87053,
            "contradiction": 11.3053,
            "irrelevancy": 76.59337,
            "logical_agreement": 12.10133,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.44663,
            "nubia_score": 0.63293
        },
        "bleurt": -0.16143
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.7272727272727273
        },
        "nist": 3.6074261652807755,
        "rouge1": {
            "precision": 0.72917,
            "recall": 0.74444,
            "fmeasure": 0.73656
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.37778,
            "fmeasure": 0.38788
        },
        "rougeL": {
            "precision": 0.60417,
            "recall": 0.53838,
            "fmeasure": 0.56845
        },
        "rougeLsum": {
            "precision": 0.60417,
            "recall": 0.53838,
            "fmeasure": 0.56845
        },
        "bleu": 31.32768,
        "meteor": 0.34397528287928436,
        "bertscore": {
            "precision": 0.88885,
            "recall": 0.88603,
            "f1": 0.8851
        },
        "nubia": {
            "semantic_relation": 4.26118,
            "contradiction": 0.08451,
            "irrelevancy": 0.53323,
            "logical_agreement": 99.38226,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.13049,
            "nubia_score": 0.92553
        },
        "bleurt": 0.29628
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.2727272727272727
        },
        "nist": 1.289797400827294,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.27619,
            "fmeasure": 0.30199
        },
        "rouge2": {
            "precision": 0.04545,
            "recall": 0.03846,
            "fmeasure": 0.04167
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.27619,
            "fmeasure": 0.30199
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.27619,
            "fmeasure": 0.30199
        },
        "bleu": 6.58199,
        "meteor": 0.19460615860168817,
        "bertscore": {
            "precision": 0.84134,
            "recall": 0.78849,
            "f1": 0.81406
        },
        "nubia": {
            "semantic_relation": 3.68723,
            "contradiction": 0.20292,
            "irrelevancy": 51.69562,
            "logical_agreement": 48.10146,
            "grammar_ref": 5.03823,
            "grammar_hyp": 3.43689,
            "nubia_score": 0.79292
        },
        "bleurt": 0.01855
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 3.8535769082186824,
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.84295,
            "fmeasure": 0.85833
        },
        "rougeL": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "rougeLsum": {
            "precision": 0.80769,
            "recall": 0.78022,
            "fmeasure": 0.79345
        },
        "bleu": 76.74162,
        "meteor": 0.5426177315437225,
        "bertscore": {
            "precision": 0.9822,
            "recall": 0.97494,
            "f1": 0.97856
        },
        "nubia": {
            "semantic_relation": 3.73103,
            "contradiction": 47.93643,
            "irrelevancy": 1.84919,
            "logical_agreement": 50.21438,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.4164,
            "nubia_score": 0.6985
        },
        "bleurt": 0.39021
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.25,
            "3": 0.6666666666666666
        },
        "nist": 3.8033997483448574,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.67407,
            "fmeasure": 0.67789
        },
        "rouge2": {
            "precision": 0.37037,
            "recall": 0.34524,
            "fmeasure": 0.35124
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.5037,
            "fmeasure": 0.51088
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.5037,
            "fmeasure": 0.51088
        },
        "bleu": 24.44615,
        "meteor": 0.3174718485843909,
        "bertscore": {
            "precision": 0.91928,
            "recall": 0.89085,
            "f1": 0.90484
        },
        "nubia": {
            "semantic_relation": 2.88922,
            "contradiction": 0.22715,
            "irrelevancy": 1.19259,
            "logical_agreement": 98.58026,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.42825,
            "nubia_score": 0.50424
        },
        "bleurt": 0.07076
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.494680368408909,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.680813428089397,
        "cond_entropy-2": 0.1977135987045114,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": 0.02247529290070043,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 27.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 27.0,
        "min_pred_length-nopunct": 27,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.43063240949075,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.2053555814454493,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": 0.023416471633632502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "nist": 3.7842536458962615,
        "rouge1": {
            "precision": 0.84,
            "recall": 0.77778,
            "fmeasure": 0.80769
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.61538,
            "fmeasure": 0.64
        },
        "rougeL": {
            "precision": 0.84,
            "recall": 0.77778,
            "fmeasure": 0.80769
        },
        "rougeLsum": {
            "precision": 0.84,
            "recall": 0.77778,
            "fmeasure": 0.80769
        },
        "bleu": 47.91102,
        "meteor": 0.43565881278054924,
        "bertscore": {
            "precision": 0.91788,
            "recall": 0.91639,
            "f1": 0.91713
        },
        "nubia": {
            "semantic_relation": 4.21223,
            "contradiction": 0.10241,
            "irrelevancy": 4.24083,
            "logical_agreement": 95.65676,
            "grammar_ref": 4.19464,
            "grammar_hyp": 3.62804,
            "nubia_score": 0.81152
        },
        "bleurt": 0.25132
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.6666666666666666
        },
        "nist": 2.596562362048614,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.63492,
            "fmeasure": 0.55728
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.45833,
            "fmeasure": 0.38431
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.57937,
            "fmeasure": 0.50464
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.57937,
            "fmeasure": 0.50464
        },
        "bleu": 42.7287,
        "meteor": 0.36301256549800204,
        "bertscore": {
            "precision": 0.89696,
            "recall": 0.92262,
            "f1": 0.90961
        },
        "nubia": {
            "semantic_relation": 3.39851,
            "contradiction": 0.12673,
            "irrelevancy": 53.26509,
            "logical_agreement": 46.60818,
            "grammar_ref": 4.8549,
            "grammar_hyp": 3.81343,
            "nubia_score": 0.67795
        },
        "bleurt": 0.44977
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 2.5708514565692293,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.57071,
            "fmeasure": 0.61472
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.21515,
            "fmeasure": 0.23509
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "bleu": 23.02104,
        "meteor": 0.2904516730189926,
        "bertscore": {
            "precision": 0.92577,
            "recall": 0.9082,
            "f1": 0.91649
        },
        "nubia": {
            "semantic_relation": 4.75868,
            "contradiction": 0.67843,
            "irrelevancy": 47.31477,
            "logical_agreement": 52.0068,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.55186,
            "nubia_score": 0.89352
        },
        "bleurt": 0.30229
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.38461538461538464
        },
        "nist": 0.4762470591647922,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.37778,
            "fmeasure": 0.48148
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.1369,
            "fmeasure": 0.17677
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.2963,
            "fmeasure": 0.37654
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.2963,
            "fmeasure": 0.37654
        },
        "bleu": 6.77869,
        "meteor": 0.22887808656375963,
        "bertscore": {
            "precision": 0.89358,
            "recall": 0.84319,
            "f1": 0.86571
        },
        "nubia": {
            "semantic_relation": 4.10534,
            "contradiction": 0.3817,
            "irrelevancy": 46.32713,
            "logical_agreement": 53.29118,
            "grammar_ref": 4.4151,
            "grammar_hyp": 7.09505,
            "nubia_score": 0.38496
        },
        "bleurt": -0.25247
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 4.766329012715601,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.83419,
            "fmeasure": 0.87546
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6627,
            "fmeasure": 0.70299
        },
        "rougeL": {
            "precision": 0.87179,
            "recall": 0.78291,
            "fmeasure": 0.82418
        },
        "rougeLsum": {
            "precision": 0.87179,
            "recall": 0.78291,
            "fmeasure": 0.82418
        },
        "bleu": 81.42442,
        "meteor": 0.4894845842304888,
        "bertscore": {
            "precision": 0.98573,
            "recall": 0.95537,
            "f1": 0.96627
        },
        "nubia": {
            "semantic_relation": 4.94744,
            "contradiction": 0.308,
            "irrelevancy": 0.49541,
            "logical_agreement": 99.1966,
            "grammar_ref": 4.20051,
            "grammar_hyp": 4.4586,
            "nubia_score": 0.95267
        },
        "bleurt": 0.59254
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "nist": 2.9422077838189056,
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.76667,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.62963,
            "fmeasure": 0.53968
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.76667,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.76667,
            "fmeasure": 0.66667
        },
        "bleu": 46.04629,
        "meteor": 0.4392315476523066,
        "bertscore": {
            "precision": 0.93659,
            "recall": 0.96101,
            "f1": 0.94864
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32197,
            "irrelevancy": 0.43441,
            "logical_agreement": 99.24362,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.40041,
            "nubia_score": 0.94248
        },
        "bleurt": 0.72347
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.456435556800404,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "bleu": 50.0,
        "meteor": 0.5277006683854432,
        "bertscore": {
            "precision": 0.986,
            "recall": 0.99497,
            "f1": 0.99047
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        },
        "bleurt": 0.93658
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nist": 4.507537764567106,
        "rouge1": {
            "precision": 0.89583,
            "recall": 0.82143,
            "fmeasure": 0.8536
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.73333,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.75794,
            "fmeasure": 0.78153
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.75794,
            "fmeasure": 0.78153
        },
        "bleu": 78.25423,
        "meteor": 0.5511445391114351,
        "bertscore": {
            "precision": 0.96642,
            "recall": 0.96589,
            "f1": 0.96615
        },
        "nubia": {
            "semantic_relation": 4.09191,
            "contradiction": 0.50894,
            "irrelevancy": 46.14429,
            "logical_agreement": 53.34677,
            "grammar_ref": 3.89472,
            "grammar_hyp": 3.99105,
            "nubia_score": 0.7335
        },
        "bleurt": 0.14151
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 0.5,
        "median_pred_length": 21.5,
        "min_pred_length": 21,
        "max_pred_length": 22,
        "distinct-1": 0.6976744186046512,
        "vocab_size-1": 30,
        "unique-1": 19,
        "entropy-1": 4.775101964004423,
        "distinct-2": 0.926829268292683,
        "vocab_size-2": 38,
        "unique-2": 35,
        "entropy-2": 5.211210541203447,
        "cond_entropy-2": 0.4190921279647663,
        "distinct-3": 0.9743589743589743,
        "vocab_size-3": 38,
        "unique-3": 37,
        "entropy-3": 5.234120167580196,
        "cond_entropy-3": 0.03041431680826746,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.500711588373536,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.8625759375402735,
        "cond_entropy-2-nopunct": 0.3999595872619716,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.889680181354619,
        "cond_entropy-3-nopunct": 0.03883444909293795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.5333333333333333
        },
        "nist": 3.249576974803004,
        "rouge1": {
            "precision": 0.64924,
            "recall": 0.57778,
            "fmeasure": 0.59722
        },
        "rouge2": {
            "precision": 0.36765,
            "recall": 0.31686,
            "fmeasure": 0.33544
        },
        "rougeL": {
            "precision": 0.42102,
            "recall": 0.37857,
            "fmeasure": 0.39552
        },
        "rougeLsum": {
            "precision": 0.42102,
            "recall": 0.37857,
            "fmeasure": 0.39552
        },
        "bleu": 14.62854,
        "meteor": 0.23944651356227403,
        "bertscore": {
            "precision": 0.87858,
            "recall": 0.82437,
            "f1": 0.84784
        },
        "nubia": {
            "semantic_relation": 3.44056,
            "contradiction": 8.43279,
            "irrelevancy": 84.73692,
            "logical_agreement": 6.83029,
            "grammar_ref": 4.16263,
            "grammar_hyp": 3.80049,
            "nubia_score": 0.52545
        },
        "bleurt": -0.31958
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nist": 3.7306421619051204,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.92308,
            "fmeasure": 0.91826
        },
        "rouge2": {
            "precision": 0.77273,
            "recall": 0.78333,
            "fmeasure": 0.7764
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.92308,
            "fmeasure": 0.91826
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.92308,
            "fmeasure": 0.91826
        },
        "bleu": 70.33686,
        "meteor": 0.5193190762351243,
        "bertscore": {
            "precision": 0.95474,
            "recall": 0.97415,
            "f1": 0.96434
        },
        "nubia": {
            "semantic_relation": 4.22652,
            "contradiction": 0.31193,
            "irrelevancy": 99.24408,
            "logical_agreement": 0.44399,
            "grammar_ref": 4.75081,
            "grammar_hyp": 4.0893,
            "nubia_score": 0.82534
        },
        "bleurt": 0.51084
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.5714285714285714
        },
        "nist": 2.792825988178902,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.61153,
            "fmeasure": 0.69281
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.37037,
            "fmeasure": 0.425
        },
        "rougeL": {
            "precision": 0.57778,
            "recall": 0.40829,
            "fmeasure": 0.47801
        },
        "rougeLsum": {
            "precision": 0.57778,
            "recall": 0.40829,
            "fmeasure": 0.47801
        },
        "bleu": 29.09162,
        "meteor": 0.36565187867834015,
        "bertscore": {
            "precision": 0.94188,
            "recall": 0.91814,
            "f1": 0.92986
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 7.20125,
            "irrelevancy": 10.51258,
            "logical_agreement": 82.28617,
            "grammar_ref": 3.4928,
            "grammar_hyp": 4.30964,
            "nubia_score": 0.92523
        },
        "bleurt": 0.51877
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 1.5,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 12,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 15,
        "unique-1": 9,
        "entropy-1": 3.8208888513501877,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548846,
        "cond_entropy-2": 0.27666272224377253,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.04281761336971672,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.614369445886757,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.33007499855768774,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "nist": 2.224002012581689,
        "rouge1": {
            "precision": 0.85,
            "recall": 0.60417,
            "fmeasure": 0.70155
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.40963,
            "fmeasure": 0.48077
        },
        "rougeL": {
            "precision": 0.85,
            "recall": 0.60417,
            "fmeasure": 0.70155
        },
        "rougeLsum": {
            "precision": 0.85,
            "recall": 0.60417,
            "fmeasure": 0.70155
        },
        "bleu": 25.70892,
        "meteor": 0.4244833059559144,
        "bertscore": {
            "precision": 0.94219,
            "recall": 0.89552,
            "f1": 0.91787
        },
        "nubia": {
            "semantic_relation": 4.23392,
            "contradiction": 0.66094,
            "irrelevancy": 1.4523,
            "logical_agreement": 97.88676,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.24666,
            "nubia_score": 0.79673
        },
        "bleurt": 0.46986
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548847,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.45454545454545453,
            "3": 0.5555555555555556
        },
        "nist": 2.620296866129636,
        "rouge1": {
            "precision": 0.68627,
            "recall": 0.47942,
            "fmeasure": 0.56429
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.19949,
            "fmeasure": 0.23684
        },
        "rougeL": {
            "precision": 0.45098,
            "recall": 0.31478,
            "fmeasure": 0.37063
        },
        "rougeLsum": {
            "precision": 0.45098,
            "recall": 0.31478,
            "fmeasure": 0.37063
        },
        "bleu": 15.42489,
        "meteor": 0.2837761114433518,
        "bertscore": {
            "precision": 0.90199,
            "recall": 0.86189,
            "f1": 0.88148
        },
        "nubia": {
            "semantic_relation": 3.05461,
            "contradiction": 31.99356,
            "irrelevancy": 48.30671,
            "logical_agreement": 19.69972,
            "grammar_ref": 3.96534,
            "grammar_hyp": 3.10206,
            "nubia_score": 0.46016
        },
        "bleurt": -0.18798
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 7.0,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.6388888888888888,
        "vocab_size-1": 23,
        "unique-1": 11,
        "entropy-1": 4.426733681937771,
        "distinct-2": 0.7647058823529411,
        "vocab_size-2": 26,
        "unique-2": 18,
        "entropy-2": 4.616874605956221,
        "cond_entropy-2": 0.17503453104812902,
        "distinct-3": 0.8125,
        "vocab_size-3": 26,
        "unique-3": 20,
        "entropy-3": 4.625,
        "cond_entropy-3": 0.03753715874966058,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6774193548387096,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.309035020064295,
        "distinct-2-nopunct": 0.7241379310344828,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.306256857196537,
        "cond_entropy-2-nopunct": -0.02724979801792366,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.310443057719026,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8181818181818182,
            "3": 0.9444444444444444
        },
        "nist": 3.966362748308545,
        "rouge1": {
            "precision": 0.78651,
            "recall": 0.80892,
            "fmeasure": 0.7953
        },
        "rouge2": {
            "precision": 0.56944,
            "recall": 0.6271,
            "fmeasure": 0.588
        },
        "rougeL": {
            "precision": 0.64365,
            "recall": 0.6481,
            "fmeasure": 0.64402
        },
        "rougeLsum": {
            "precision": 0.64365,
            "recall": 0.6481,
            "fmeasure": 0.64402
        },
        "bleu": 51.90069,
        "meteor": 0.4812534173213602,
        "bertscore": {
            "precision": 0.96406,
            "recall": 0.96026,
            "f1": 0.96094
        },
        "nubia": {
            "semantic_relation": 4.63671,
            "contradiction": 12.17036,
            "irrelevancy": 18.08244,
            "logical_agreement": 69.7472,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.58968,
            "nubia_score": 0.90296
        },
        "bleurt": 0.43163
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 4.0,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 15,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.095795255000932,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.16249647625006497,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.12577468433272804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.23529411764705882,
            "3": 0.4642857142857143
        },
        "nist": 0.3171509005382986,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.4451,
            "fmeasure": 0.5715
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.3555,
            "fmeasure": 0.45582
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.4451,
            "fmeasure": 0.5715
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.4451,
            "fmeasure": 0.5715
        },
        "bleu": 35.0289,
        "meteor": 0.2590427696184706,
        "bertscore": {
            "precision": 0.93696,
            "recall": 0.84139,
            "f1": 0.87715
        },
        "nubia": {
            "semantic_relation": 3.68516,
            "contradiction": 0.27349,
            "irrelevancy": 2.34616,
            "logical_agreement": 97.38034,
            "grammar_ref": 3.63495,
            "grammar_hyp": 4.75091,
            "nubia_score": 0.50031
        },
        "bleurt": -0.0138
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.1111111111111111,
            "3": 1.0
        },
        "nist": 2.439038707228168,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.83333,
            "fmeasure": 0.77143
        },
        "rouge2": {
            "precision": 0.57576,
            "recall": 0.68137,
            "fmeasure": 0.61028
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.81481,
            "fmeasure": 0.74921
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.81481,
            "fmeasure": 0.74921
        },
        "bleu": 59.23033,
        "meteor": 0.5492873737057178,
        "bertscore": {
            "precision": 0.92294,
            "recall": 0.97216,
            "f1": 0.94691
        },
        "nubia": {
            "semantic_relation": 4.2837,
            "contradiction": 0.05877,
            "irrelevancy": 64.63719,
            "logical_agreement": 35.30404,
            "grammar_ref": 4.62828,
            "grammar_hyp": 5.32464,
            "nubia_score": 0.70335
        },
        "bleurt": 0.41123
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.916126946588283,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.42961067210860193,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.821928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.4523152080299073,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "nist": 1.4789434453340473,
        "rouge1": {
            "precision": 0.28333,
            "recall": 0.3635,
            "fmeasure": 0.31723
        },
        "rouge2": {
            "precision": 0.05263,
            "recall": 0.07639,
            "fmeasure": 0.06206
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.31222,
            "fmeasure": 0.27682
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.31222,
            "fmeasure": 0.27682
        },
        "bleu": 5.23752,
        "meteor": 0.14516384509432115,
        "bertscore": {
            "precision": 0.65164,
            "recall": 0.66635,
            "f1": 0.65854
        },
        "nubia": {
            "semantic_relation": 1.29963,
            "contradiction": 22.78174,
            "irrelevancy": 75.0121,
            "logical_agreement": 2.20616,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.49215,
            "nubia_score": 0.14288
        },
        "bleurt": -0.73834
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.47368421052631576,
        "vocab_size-1": 9,
        "unique-1": 3,
        "entropy-1": 2.9847696187067436,
        "distinct-2": 0.5294117647058824,
        "vocab_size-2": 9,
        "unique-2": 3,
        "entropy-2": 3.0286393118385755,
        "cond_entropy-2": 0.0748294454538127,
        "distinct-3": 0.6,
        "vocab_size-3": 9,
        "unique-3": 3,
        "entropy-3": 3.106890595608519,
        "cond_entropy-3": 0.08609442102484582,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.47058823529411764,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 2.793345194191516,
        "distinct-2-nopunct": 0.5333333333333333,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 2.8402239289418523,
        "cond_entropy-2-nopunct": -0.0472389123084875,
        "distinct-3-nopunct": 0.6153846153846154,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 2.931208948910323,
        "cond_entropy-3-nopunct": -0.05260472362127268,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nist": 4.451815875634701,
        "rouge1": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rouge2": {
            "precision": 0.79464,
            "recall": 0.72685,
            "fmeasure": 0.75776
        },
        "rougeL": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rougeLsum": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "bleu": 69.05636,
        "meteor": 0.9489775258149422,
        "bertscore": {
            "precision": 0.98549,
            "recall": 0.97733,
            "f1": 0.98137
        },
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.40178,
            "irrelevancy": 0.5141,
            "logical_agreement": 99.08412,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.20195,
            "nubia_score": 0.97201
        },
        "bleurt": 0.78257
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.625
        },
        "nist": 2.5138039015607525,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.89167,
            "fmeasure": 0.85926
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.51323,
            "fmeasure": 0.49537
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.78333,
            "fmeasure": 0.75556
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.78333,
            "fmeasure": 0.75556
        },
        "bleu": 24.38418,
        "meteor": 0.4293370916987086,
        "bertscore": {
            "precision": 0.97051,
            "recall": 0.92756,
            "f1": 0.94855
        },
        "nubia": {
            "semantic_relation": 4.84068,
            "contradiction": 1.00439,
            "irrelevancy": 54.96337,
            "logical_agreement": 44.03224,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.79844,
            "nubia_score": 1.0
        },
        "bleurt": 0.47101
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3248629576173574,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.2588453731729854,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.051189449246730745,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.180832987205441,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.28076340776035313,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322734,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.375
        },
        "nist": 1.2119739722691256,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.40179,
            "fmeasure": 0.41429
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.14359,
            "fmeasure": 0.14835
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.33482,
            "fmeasure": 0.34524
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.33482,
            "fmeasure": 0.34524
        },
        "bleu": 6.95958,
        "meteor": 0.28636603727423415,
        "bertscore": {
            "precision": 0.8884,
            "recall": 0.87465,
            "f1": 0.88052
        },
        "nubia": {
            "semantic_relation": 3.84004,
            "contradiction": 0.13897,
            "irrelevancy": 1.84762,
            "logical_agreement": 98.01342,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.30476,
            "nubia_score": 0.79191
        },
        "bleurt": 0.09649
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 1.0,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 16,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.415061012203069,
        "distinct-2": 0.8928571428571429,
        "vocab_size-2": 25,
        "unique-2": 22,
        "entropy-2": 4.593069207771891,
        "cond_entropy-2": 0.14171030866920947,
        "distinct-3": 0.9230769230769231,
        "vocab_size-3": 24,
        "unique-3": 22,
        "entropy-3": 4.546593564294937,
        "cond_entropy-3": -0.02999212699343525,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.351823225551767,
        "distinct-2-nopunct": 0.8846153846153846,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.46967048737186,
        "cond_entropy-2-nopunct": 0.11442662308977508,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.418295834054489,
        "cond_entropy-3-nopunct": -0.03214388408660255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.782608695652174
        },
        "nist": 4.645094607841702,
        "rouge1": {
            "precision": 0.88718,
            "recall": 0.85294,
            "fmeasure": 0.86833
        },
        "rouge2": {
            "precision": 0.77183,
            "recall": 0.75,
            "fmeasure": 0.75942
        },
        "rougeL": {
            "precision": 0.85385,
            "recall": 0.82353,
            "fmeasure": 0.83708
        },
        "rougeLsum": {
            "precision": 0.85385,
            "recall": 0.82353,
            "fmeasure": 0.83708
        },
        "bleu": 69.23526,
        "meteor": 0.5008981217723252,
        "bertscore": {
            "precision": 0.97313,
            "recall": 0.95869,
            "f1": 0.9658
        },
        "nubia": {
            "semantic_relation": 4.41491,
            "contradiction": 0.22835,
            "irrelevancy": 32.85157,
            "logical_agreement": 66.92008,
            "grammar_ref": 4.08754,
            "grammar_hyp": 3.77833,
            "nubia_score": 0.88196
        },
        "bleurt": 0.44165
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.02961067210860201,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nist": 4.121175715581256,
        "rouge1": {
            "precision": 0.7451,
            "recall": 0.87464,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.54575,
            "fmeasure": 0.49495
        },
        "rougeL": {
            "precision": 0.72549,
            "recall": 0.76353,
            "fmeasure": 0.73968
        },
        "rougeLsum": {
            "precision": 0.72549,
            "recall": 0.76353,
            "fmeasure": 0.73968
        },
        "bleu": 49.80744,
        "meteor": 0.4545687963581247,
        "bertscore": {
            "precision": 0.94219,
            "recall": 0.96642,
            "f1": 0.95171
        },
        "nubia": {
            "semantic_relation": 3.77672,
            "contradiction": 0.58606,
            "irrelevancy": 95.82146,
            "logical_agreement": 3.59248,
            "grammar_ref": 5.3293,
            "grammar_hyp": 4.87277,
            "nubia_score": 0.58843
        },
        "bleurt": 0.0817
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.5714285714285714
        },
        "nist": 1.8934502576765253,
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.35714,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.15018,
            "fmeasure": 0.1715
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.28571,
            "fmeasure": 0.32
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.28571,
            "fmeasure": 0.32
        },
        "bleu": 8.57989,
        "meteor": 0.21332474102042903,
        "bertscore": {
            "precision": 0.77999,
            "recall": 0.78777,
            "f1": 0.78386
        },
        "nubia": {
            "semantic_relation": 3.10026,
            "contradiction": 0.21343,
            "irrelevancy": 99.66621,
            "logical_agreement": 0.12036,
            "grammar_ref": 3.90604,
            "grammar_hyp": 4.06323,
            "nubia_score": 0.41183
        },
        "bleurt": -0.25646
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 2.5035740619067566,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.58333,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.76923,
            "fmeasure": 0.68966
        },
        "bleu": 40.52128,
        "meteor": 0.41273120077558945,
        "bertscore": {
            "precision": 0.92246,
            "recall": 0.93303,
            "f1": 0.92772
        },
        "nubia": {
            "semantic_relation": 4.97386,
            "contradiction": 0.17938,
            "irrelevancy": 6.53839,
            "logical_agreement": 93.28223,
            "grammar_ref": 4.23153,
            "grammar_hyp": 4.12366,
            "nubia_score": 0.95564
        },
        "bleurt": 0.52247
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "nist": 1.259375898165659,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.56173,
            "fmeasure": 0.68372
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.38785,
            "fmeasure": 0.46394
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "bleu": 23.09472,
        "meteor": 0.32038272111982113,
        "bertscore": {
            "precision": 0.96471,
            "recall": 0.89731,
            "f1": 0.92814
        },
        "nubia": {
            "semantic_relation": 3.85327,
            "contradiction": 0.17167,
            "irrelevancy": 33.45547,
            "logical_agreement": 66.37286,
            "grammar_ref": 3.86337,
            "grammar_hyp": 3.58191,
            "nubia_score": 0.72381
        },
        "bleurt": 0.18008
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.6538461538461539,
        "vocab_size-1": 34,
        "unique-1": 22,
        "entropy-1": 4.89516466081557,
        "distinct-2": 0.8367346938775511,
        "vocab_size-2": 41,
        "unique-2": 33,
        "entropy-2": 5.288179231870311,
        "cond_entropy-2": 0.34527860513256026,
        "distinct-3": 0.8913043478260869,
        "vocab_size-3": 41,
        "unique-3": 36,
        "entropy-3": 5.306170651709184,
        "cond_entropy-3": 0.039286894550500245,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.265986323710904,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.81164134491358,
        "distinct-2-nopunct": 0.8222222222222222,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.136297540774117,
        "cond_entropy-2-nopunct": 0.32461253747243796,
        "distinct-3-nopunct": 0.8809523809523809,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.1542221846835234,
        "cond_entropy-3-nopunct": 0.019511945496704645,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.45,
            "2": 0.4444444444444444,
            "3": 0.7222222222222222
        },
        "nist": 3.63262413875133,
        "rouge1": {
            "precision": 0.64506,
            "recall": 0.66765,
            "fmeasure": 0.64779
        },
        "rouge2": {
            "precision": 0.44835,
            "recall": 0.42978,
            "fmeasure": 0.43458
        },
        "rougeL": {
            "precision": 0.57211,
            "recall": 0.5773,
            "fmeasure": 0.56767
        },
        "rougeLsum": {
            "precision": 0.57211,
            "recall": 0.5773,
            "fmeasure": 0.56767
        },
        "bleu": 35.8868,
        "meteor": 0.3810783830375084,
        "bertscore": {
            "precision": 0.90427,
            "recall": 0.89886,
            "f1": 0.89818
        },
        "nubia": {
            "semantic_relation": 3.95015,
            "contradiction": 2.43601,
            "irrelevancy": 76.4434,
            "logical_agreement": 21.1206,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.38286,
            "nubia_score": 0.64617
        },
        "bleurt": -0.18632
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.220175521464345,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.31924673803861625,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.061482186720775,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.3497852090063903,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 0.3
        },
        "nist": 3.0292480237011747,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.44572,
            "fmeasure": 0.51022
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.18095,
            "fmeasure": 0.20947
        },
        "rougeL": {
            "precision": 0.29333,
            "recall": 0.21481,
            "fmeasure": 0.24759
        },
        "rougeLsum": {
            "precision": 0.29333,
            "recall": 0.21481,
            "fmeasure": 0.24759
        },
        "bleu": 14.30625,
        "meteor": 0.21795315981515764,
        "bertscore": {
            "precision": 0.85956,
            "recall": 0.81454,
            "f1": 0.83561
        },
        "nubia": {
            "semantic_relation": 2.60317,
            "contradiction": 9.77085,
            "irrelevancy": 50.5073,
            "logical_agreement": 39.72186,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.89256,
            "nubia_score": 0.30484
        },
        "bleurt": -0.56556
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750188,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.08264309517020868,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.03462179117476821,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728205,
        "cond_entropy-2-nopunct": 0.09060036801448043,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.42105263157894735,
            "3": 0.8333333333333334
        },
        "nist": 3.242439727132991,
        "rouge1": {
            "precision": 0.61458,
            "recall": 0.54697,
            "fmeasure": 0.57602
        },
        "rouge2": {
            "precision": 0.44958,
            "recall": 0.39085,
            "fmeasure": 0.41544
        },
        "rougeL": {
            "precision": 0.58681,
            "recall": 0.51919,
            "fmeasure": 0.54825
        },
        "rougeLsum": {
            "precision": 0.58681,
            "recall": 0.51919,
            "fmeasure": 0.54825
        },
        "bleu": 35.52734,
        "meteor": 0.28171161595130073,
        "bertscore": {
            "precision": 0.89136,
            "recall": 0.87498,
            "f1": 0.88264
        },
        "nubia": {
            "semantic_relation": 4.04534,
            "contradiction": 23.44071,
            "irrelevancy": 24.4121,
            "logical_agreement": 52.14719,
            "grammar_ref": 5.11675,
            "grammar_hyp": 4.71717,
            "nubia_score": 0.61622
        },
        "bleurt": 0.01059
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.033108599109837954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "nist": 3.0961769012815985,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.67917,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "bleu": 60.54783,
        "meteor": 0.5158668426787606,
        "bertscore": {
            "precision": 0.90717,
            "recall": 0.95643,
            "f1": 0.93115
        },
        "nubia": {
            "semantic_relation": 2.9498,
            "contradiction": 0.88065,
            "irrelevancy": 98.13057,
            "logical_agreement": 0.98878,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.80836,
            "nubia_score": 0.37984
        },
        "bleurt": -0.33838
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 0.8514900221362205,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.39167,
            "fmeasure": 0.49333
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.20952,
            "fmeasure": 0.26877
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.38431,
            "fmeasure": 0.48718
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.38431,
            "fmeasure": 0.48718
        },
        "bleu": 8.56254,
        "meteor": 0.18367969290905986,
        "bertscore": {
            "precision": 0.86877,
            "recall": 0.78304,
            "f1": 0.82368
        },
        "nubia": {
            "semantic_relation": 2.99221,
            "contradiction": 5.39559,
            "irrelevancy": 94.25572,
            "logical_agreement": 0.3487,
            "grammar_ref": 4.68072,
            "grammar_hyp": 5.03882,
            "nubia_score": 0.25027
        },
        "bleurt": -0.3607
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 3.0881978509745025,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "bleu": 68.94026,
        "meteor": 0.81809314801268,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        },
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "bleurt": 0.64449
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.8
        },
        "nist": 3.0771726979738294,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.84416,
            "fmeasure": 0.91538
        },
        "rouge2": {
            "precision": 0.76471,
            "recall": 0.63968,
            "fmeasure": 0.69654
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.72381,
            "fmeasure": 0.68998
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.72381,
            "fmeasure": 0.68998
        },
        "bleu": 17.60928,
        "meteor": 0.40766503511701363,
        "bertscore": {
            "precision": 0.95419,
            "recall": 0.9717,
            "f1": 0.94901
        },
        "nubia": {
            "semantic_relation": 4.41687,
            "contradiction": 80.39199,
            "irrelevancy": 15.88546,
            "logical_agreement": 3.72255,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.32456,
            "nubia_score": 0.84263
        },
        "bleurt": 0.33386
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 2.3727213808108223,
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.63333,
            "fmeasure": 0.63333
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.2963,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.63333,
            "fmeasure": 0.63333
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.63333,
            "fmeasure": 0.63333
        },
        "bleu": 12.35622,
        "meteor": 0.41274018477617525,
        "bertscore": {
            "precision": 0.93579,
            "recall": 0.95587,
            "f1": 0.94573
        },
        "nubia": {
            "semantic_relation": 4.50776,
            "contradiction": 7.16066,
            "irrelevancy": 10.86459,
            "logical_agreement": 81.97476,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.02633,
            "nubia_score": 0.72182
        },
        "bleurt": -0.12997
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "nist": 3.353520501612051,
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.60644,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.37821,
            "fmeasure": 0.41905
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.54342,
            "fmeasure": 0.59753
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.54342,
            "fmeasure": 0.59753
        },
        "bleu": 35.84892,
        "meteor": 0.3424658391974671,
        "bertscore": {
            "precision": 0.916,
            "recall": 0.87322,
            "f1": 0.88581
        },
        "nubia": {
            "semantic_relation": 3.94575,
            "contradiction": 23.38666,
            "irrelevancy": 70.32109,
            "logical_agreement": 6.29225,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.3626,
            "nubia_score": 0.6368
        },
        "bleurt": -0.06378
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.96655480858378,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.5263157894736842,
        "vocab_size-1": 30,
        "unique-1": 19,
        "entropy-1": 4.600629821927414,
        "distinct-2": 0.7777777777777778,
        "vocab_size-2": 42,
        "unique-2": 35,
        "entropy-2": 5.222389585456738,
        "cond_entropy-2": 0.6021651908357745,
        "distinct-3": 0.8431372549019608,
        "vocab_size-3": 43,
        "unique-3": 37,
        "entropy-3": 5.319484165500912,
        "cond_entropy-3": 0.12841798690927142,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 4.96655480858378,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5370370370370371,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.542221882619692,
        "distinct-2-nopunct": 0.7647058823529411,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.108604018399667,
        "cond_entropy-2-nopunct": 0.6066377114252703,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.20996250072116,
        "cond_entropy-3-nopunct": 0.10357726294637558,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.7111111111111111
        },
        "nist": 3.8909581537636098,
        "rouge1": {
            "precision": 0.73521,
            "recall": 0.69271,
            "fmeasure": 0.70093
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.48655,
            "fmeasure": 0.49242
        },
        "rougeL": {
            "precision": 0.56926,
            "recall": 0.52648,
            "fmeasure": 0.53596
        },
        "rougeLsum": {
            "precision": 0.56926,
            "recall": 0.52648,
            "fmeasure": 0.53596
        },
        "bleu": 44.71921,
        "meteor": 0.3468475473712975,
        "bertscore": {
            "precision": 0.93335,
            "recall": 0.90825,
            "f1": 0.91974
        },
        "nubia": {
            "semantic_relation": 3.51658,
            "contradiction": 29.27958,
            "irrelevancy": 31.62682,
            "logical_agreement": 39.0936,
            "grammar_ref": 4.73012,
            "grammar_hyp": 4.4942,
            "nubia_score": 0.50798
        },
        "bleurt": 0.13612
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.42857142857142855
        },
        "nist": 1.2174315001944283,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.47059,
            "fmeasure": 0.55172
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.375,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.47059,
            "fmeasure": 0.55172
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.47059,
            "fmeasure": 0.55172
        },
        "bleu": 28.75684,
        "meteor": 0.2295725117242551,
        "bertscore": {
            "precision": 0.9508,
            "recall": 0.87145,
            "f1": 0.9094
        },
        "nubia": {
            "semantic_relation": 2.44736,
            "contradiction": 99.18879,
            "irrelevancy": 0.56686,
            "logical_agreement": 0.24435,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.68575,
            "nubia_score": 0.2397
        },
        "bleurt": -0.04844
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.033108599109837954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 3.046192803467789,
        "rouge1": {
            "precision": 0.8254,
            "recall": 0.72352,
            "fmeasure": 0.77047
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.39273,
            "fmeasure": 0.41905
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.54348,
            "fmeasure": 0.57834
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.54348,
            "fmeasure": 0.57834
        },
        "bleu": 28.34377,
        "meteor": 0.38380124057200804,
        "bertscore": {
            "precision": 0.9446,
            "recall": 0.91765,
            "f1": 0.93093
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.079,
            "irrelevancy": 0.55555,
            "logical_agreement": 99.36545,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.18394,
            "nubia_score": 0.99809
        },
        "bleurt": 0.51334
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.73215889136457,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.7777777777777778,
        "vocab_size-3": 14,
        "unique-3": 10,
        "entropy-3": 3.7254805569978675,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.490498678107601,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "bleurt": 0.92254
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "nist": 1.116118744365551,
        "rouge1": {
            "precision": 0.31818,
            "recall": 0.60985,
            "fmeasure": 0.418
        },
        "rouge2": {
            "precision": 0.19048,
            "recall": 0.38182,
            "fmeasure": 0.25403
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.52273,
            "fmeasure": 0.35829
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.52273,
            "fmeasure": 0.35829
        },
        "bleu": 12.43672,
        "meteor": 0.24921087290602761,
        "bertscore": {
            "precision": 0.81892,
            "recall": 0.88276,
            "f1": 0.84964
        },
        "nubia": {
            "semantic_relation": 4.46056,
            "contradiction": 0.15096,
            "irrelevancy": 95.86457,
            "logical_agreement": 3.98446,
            "grammar_ref": 5.10481,
            "grammar_hyp": 3.91582,
            "nubia_score": 0.54771
        },
        "bleurt": -0.06105
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.8
        },
        "nist": 1.6195489589943932,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.66667,
            "fmeasure": 0.56863
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.1,
            "fmeasure": 0.07692
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.45833,
            "fmeasure": 0.38431
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.45833,
            "fmeasure": 0.38431
        },
        "bleu": 5.30016,
        "meteor": 0.3096774193548387,
        "bertscore": {
            "precision": 0.80951,
            "recall": 0.84717,
            "f1": 0.82791
        },
        "nubia": {
            "semantic_relation": 3.72229,
            "contradiction": 1.54865,
            "irrelevancy": 97.82172,
            "logical_agreement": 0.62962,
            "grammar_ref": 7.18676,
            "grammar_hyp": 5.52764,
            "nubia_score": 0.72111
        },
        "bleurt": -0.28963
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "nist": 2.0348879367115016,
        "rouge1": {
            "precision": 0.54386,
            "recall": 0.43883,
            "fmeasure": 0.48462
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.23449,
            "fmeasure": 0.25427
        },
        "rougeL": {
            "precision": 0.31579,
            "recall": 0.26877,
            "fmeasure": 0.29036
        },
        "rougeLsum": {
            "precision": 0.31579,
            "recall": 0.26877,
            "fmeasure": 0.29036
        },
        "bleu": 13.93684,
        "meteor": 0.2596152824432974,
        "bertscore": {
            "precision": 0.87782,
            "recall": 0.85221,
            "f1": 0.86483
        },
        "nubia": {
            "semantic_relation": 2.99057,
            "contradiction": 4.17461,
            "irrelevancy": 95.48284,
            "logical_agreement": 0.34255,
            "grammar_ref": 3.13705,
            "grammar_hyp": 4.13315,
            "nubia_score": 0.32556
        },
        "bleurt": -0.15329
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 1.0,
        "vocab_size-1": 22,
        "unique-1": 22,
        "entropy-1": 4.459431618637295,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.06711419585853673,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.06711419585853673,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35294117647058826,
            "2": 0.8
        },
        "nist": 3.3373834188410645,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.70053,
            "fmeasure": 0.62142
        },
        "rouge2": {
            "precision": 0.36957,
            "recall": 0.47173,
            "fmeasure": 0.41259
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.53476,
            "fmeasure": 0.4666
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.53476,
            "fmeasure": 0.4666
        },
        "bleu": 25.85072,
        "meteor": 0.39490676375801437,
        "bertscore": {
            "precision": 0.84882,
            "recall": 0.89386,
            "f1": 0.87076
        },
        "nubia": {
            "semantic_relation": 3.52283,
            "contradiction": 0.20361,
            "irrelevancy": 66.99071,
            "logical_agreement": 32.80567,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.72447,
            "nubia_score": 0.6056
        },
        "bleurt": -0.65249
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 1.890824264926945,
        "rouge1": {
            "precision": 0.55556,
            "recall": 1.0,
            "fmeasure": 0.71345
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.8,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 1.0,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 1.0,
            "fmeasure": 0.66667
        },
        "bleu": 24.71244,
        "meteor": 0.43291883516976665,
        "bertscore": {
            "precision": 0.88062,
            "recall": 0.97808,
            "f1": 0.92471
        },
        "nubia": {
            "semantic_relation": 3.82816,
            "contradiction": 0.06109,
            "irrelevancy": 98.39158,
            "logical_agreement": 1.54732,
            "grammar_ref": 6.21263,
            "grammar_hyp": 4.8335,
            "nubia_score": 0.75297
        },
        "bleurt": 0.51479
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.5
        },
        "nist": 3.5945452408095178,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.63768,
            "fmeasure": 0.64449
        },
        "rouge2": {
            "precision": 0.35294,
            "recall": 0.35065,
            "fmeasure": 0.34739
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.39565,
            "fmeasure": 0.40133
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.39565,
            "fmeasure": 0.40133
        },
        "bleu": 33.30482,
        "meteor": 0.30419169888521747,
        "bertscore": {
            "precision": 0.87094,
            "recall": 0.87689,
            "f1": 0.8614
        },
        "nubia": {
            "semantic_relation": 3.68666,
            "contradiction": 3.82746,
            "irrelevancy": 94.06971,
            "logical_agreement": 2.10283,
            "grammar_ref": 5.51157,
            "grammar_hyp": 5.8645,
            "nubia_score": 0.44694
        },
        "bleurt": -0.43708
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.13652573434569687,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9333333333333333
        },
        "nist": 3.3529285851380135,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.88235,
            "fmeasure": 0.81081
        },
        "rouge2": {
            "precision": 0.52632,
            "recall": 0.625,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.88235,
            "fmeasure": 0.81081
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.88235,
            "fmeasure": 0.81081
        },
        "bleu": 47.05159,
        "meteor": 0.5487383858707926,
        "bertscore": {
            "precision": 0.95649,
            "recall": 0.97139,
            "f1": 0.96388
        },
        "nubia": {
            "semantic_relation": 4.36279,
            "contradiction": 0.47543,
            "irrelevancy": 10.51109,
            "logical_agreement": 89.01348,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.30508,
            "nubia_score": 0.67013
        },
        "bleurt": 0.59064
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 16.5,
        "std_pred_length": 5.852349955359813,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 51,
        "unique-1": 44,
        "entropy-1": 5.439604013890374,
        "distinct-2": 0.9838709677419355,
        "vocab_size-2": 61,
        "unique-2": 60,
        "entropy-2": 5.921938245870744,
        "cond_entropy-2": 0.4446612145563277,
        "distinct-3": 1.0,
        "vocab_size-3": 58,
        "unique-3": 58,
        "entropy-3": 5.85798099512757,
        "cond_entropy-3": -0.061732556638613253,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 4.085033659592048,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8727272727272727,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.499363804355075,
        "distinct-2-nopunct": 0.9803921568627451,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.63320965569699,
        "cond_entropy-2-nopunct": 0.15596317755128594,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.07528329880449634,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.6666666666666666,
            "3": 0.9130434782608695
        },
        "nist": 4.3990606096000615,
        "rouge1": {
            "precision": 0.67729,
            "recall": 0.80065,
            "fmeasure": 0.7048
        },
        "rouge2": {
            "precision": 0.3142,
            "recall": 0.40531,
            "fmeasure": 0.34001
        },
        "rougeL": {
            "precision": 0.55019,
            "recall": 0.68034,
            "fmeasure": 0.58299
        },
        "rougeLsum": {
            "precision": 0.55019,
            "recall": 0.68034,
            "fmeasure": 0.58299
        },
        "bleu": 35.44836,
        "meteor": 0.38591274800256636,
        "bertscore": {
            "precision": 0.90042,
            "recall": 0.93804,
            "f1": 0.9142
        },
        "nubia": {
            "semantic_relation": 4.30581,
            "contradiction": 0.59414,
            "irrelevancy": 25.35242,
            "logical_agreement": 74.05343,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.12401,
            "nubia_score": 0.70729
        },
        "bleurt": 0.22453
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.875
        },
        "nist": 3.311309621216697,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77273,
            "fmeasure": 0.85
        },
        "rouge2": {
            "precision": 0.80392,
            "recall": 0.65079,
            "fmeasure": 0.7193
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.72727,
            "fmeasure": 0.8
        },
        "bleu": 56.08898,
        "meteor": 0.45377256572687014,
        "bertscore": {
            "precision": 0.96401,
            "recall": 0.93587,
            "f1": 0.94973
        },
        "nubia": {
            "semantic_relation": 4.21849,
            "contradiction": 52.59568,
            "irrelevancy": 40.18515,
            "logical_agreement": 7.21917,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.50558,
            "nubia_score": 0.73773
        },
        "bleurt": 0.11713
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 3.9976702764876113,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.18615790478558605,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.807763576417195,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.20971762763487733,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8571428571428571
        },
        "nist": 1.9791848689144755,
        "rouge1": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.92593,
            "fmeasure": 0.62957
        },
        "rougeL": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "rougeLsum": {
            "precision": 0.54902,
            "recall": 1.0,
            "fmeasure": 0.70716
        },
        "bleu": 18.1072,
        "meteor": 0.49254427229214076,
        "bertscore": {
            "precision": 0.8679,
            "recall": 0.95093,
            "f1": 0.88993
        },
        "nubia": {
            "semantic_relation": 3.94217,
            "contradiction": 0.0797,
            "irrelevancy": 99.45168,
            "logical_agreement": 0.46862,
            "grammar_ref": 3.90726,
            "grammar_hyp": 2.42461,
            "nubia_score": 0.72909
        },
        "bleurt": 0.20489
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 1.0,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 10,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.19264507794239588,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.09306920777188989,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5882352941176471
        },
        "nist": 0.9041281752992886,
        "rouge1": {
            "precision": 0.87857,
            "recall": 0.65065,
            "fmeasure": 0.72857
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47607,
            "fmeasure": 0.53801
        },
        "rougeL": {
            "precision": 0.87857,
            "recall": 0.65065,
            "fmeasure": 0.72857
        },
        "rougeLsum": {
            "precision": 0.87857,
            "recall": 0.65065,
            "fmeasure": 0.72857
        },
        "bleu": 18.46931,
        "meteor": 0.36854898567502575,
        "bertscore": {
            "precision": 0.95224,
            "recall": 0.88005,
            "f1": 0.90807
        },
        "nubia": {
            "semantic_relation": 4.17759,
            "contradiction": 25.74464,
            "irrelevancy": 22.39003,
            "logical_agreement": 51.86533,
            "grammar_ref": 3.80999,
            "grammar_hyp": 4.16191,
            "nubia_score": 0.65675
        },
        "bleurt": 0.28537
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 24,
        "unique-1": 18,
        "entropy-1": 4.4375,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.37355726227518526,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.028107102122342936,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.3735572622751855,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.4004643264490856,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.02999212699343525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.0,
            "3": 0.20588235294117646
        },
        "nist": 0.15354793332912897,
        "rouge1": {
            "precision": 0.35556,
            "recall": 0.15612,
            "fmeasure": 0.21075
        },
        "rouge2": {
            "precision": 0.10714,
            "recall": 0.03458,
            "fmeasure": 0.05227
        },
        "rougeL": {
            "precision": 0.32222,
            "recall": 0.14013,
            "fmeasure": 0.18913
        },
        "rougeLsum": {
            "precision": 0.32222,
            "recall": 0.14013,
            "fmeasure": 0.18913
        },
        "bleu": 3.69954,
        "meteor": 0.07112013885696061,
        "bertscore": {
            "precision": 0.78984,
            "recall": 0.71789,
            "f1": 0.75071
        },
        "nubia": {
            "semantic_relation": 1.56439,
            "contradiction": 73.06157,
            "irrelevancy": 17.16289,
            "logical_agreement": 9.77554,
            "grammar_ref": 3.44707,
            "grammar_hyp": 4.51377,
            "nubia_score": 0.07838
        },
        "bleurt": -0.96856
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 2.0,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 20,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.683542362433229,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.3148841634647019,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.02496284125033942,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.453880987666651,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.3696389952347294,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.029019418890029344,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nist": 3.819249054616615,
        "rouge1": {
            "precision": 0.70238,
            "recall": 0.61186,
            "fmeasure": 0.62338
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.28,
            "fmeasure": 0.35
        },
        "rougeL": {
            "precision": 0.38839,
            "recall": 0.35363,
            "fmeasure": 0.34867
        },
        "rougeLsum": {
            "precision": 0.38839,
            "recall": 0.35363,
            "fmeasure": 0.34867
        },
        "bleu": 36.69387,
        "meteor": 0.3217785272424538,
        "bertscore": {
            "precision": 0.91256,
            "recall": 0.88856,
            "f1": 0.90012
        },
        "nubia": {
            "semantic_relation": 3.45535,
            "contradiction": 35.57276,
            "irrelevancy": 5.10324,
            "logical_agreement": 59.324,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.00931,
            "nubia_score": 0.57272
        },
        "bleurt": 0.15948
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622848,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8125
        },
        "nist": 3.6017702668137854,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.78947,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.73684,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.73684,
            "fmeasure": 0.8
        },
        "bleu": 48.81339,
        "meteor": 0.41468405035508926,
        "bertscore": {
            "precision": 0.96824,
            "recall": 0.90861,
            "f1": 0.93748
        },
        "nubia": {
            "semantic_relation": 3.8633,
            "contradiction": 38.57284,
            "irrelevancy": 22.41996,
            "logical_agreement": 39.0072,
            "grammar_ref": 4.21408,
            "grammar_hyp": 4.72901,
            "nubia_score": 0.51988
        },
        "bleurt": 0.37821
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.2222222222222222,
            "3": 0.5555555555555556
        },
        "nist": 2.2697085511895656,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.4697,
            "fmeasure": 0.51084
        },
        "rouge2": {
            "precision": 0.37778,
            "recall": 0.29464,
            "fmeasure": 0.32975
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.34641,
            "fmeasure": 0.36007
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.34641,
            "fmeasure": 0.36007
        },
        "bleu": 30.50639,
        "meteor": 0.228912893568558,
        "bertscore": {
            "precision": 0.87593,
            "recall": 0.88071,
            "f1": 0.87616
        },
        "nubia": {
            "semantic_relation": 2.9522,
            "contradiction": 2.5733,
            "irrelevancy": 96.78955,
            "logical_agreement": 0.63715,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.60784,
            "nubia_score": 0.29958
        },
        "bleurt": -0.62108
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094898,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.6666666666666666
        },
        "nist": 2.024645164285488,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.57143,
            "fmeasure": 0.53061
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.2849,
            "fmeasure": 0.2579
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.55357,
            "fmeasure": 0.5102
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.55357,
            "fmeasure": 0.5102
        },
        "bleu": 9.91772,
        "meteor": 0.34528604637752996,
        "bertscore": {
            "precision": 0.84544,
            "recall": 0.91082,
            "f1": 0.87691
        },
        "nubia": {
            "semantic_relation": 3.4383,
            "contradiction": 0.19702,
            "irrelevancy": 59.61916,
            "logical_agreement": 40.18382,
            "grammar_ref": 3.10421,
            "grammar_hyp": 2.63326,
            "nubia_score": 0.46356
        },
        "bleurt": 0.07323
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.354997429774719,
        "rouge1": {
            "precision": 0.9697,
            "recall": 1.0,
            "fmeasure": 0.98413
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.8963,
            "fmeasure": 0.8807
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "bleu": 71.70327,
        "meteor": 0.5423794259791352,
        "bertscore": {
            "precision": 0.97182,
            "recall": 0.98396,
            "f1": 0.97747
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23544,
            "irrelevancy": 0.46592,
            "logical_agreement": 99.29864,
            "grammar_ref": 5.07856,
            "grammar_hyp": 4.58636,
            "nubia_score": 1.0
        },
        "bleurt": 0.72235
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.375,
            "3": 0.5714285714285714
        },
        "nist": 1.6195899320022322,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.53333,
            "fmeasure": 0.45714
        },
        "rouge2": {
            "precision": 0.21053,
            "recall": 0.28571,
            "fmeasure": 0.24242
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.53333,
            "fmeasure": 0.45714
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.53333,
            "fmeasure": 0.45714
        },
        "bleu": 14.52868,
        "meteor": 0.22654933461512913,
        "bertscore": {
            "precision": 0.81693,
            "recall": 0.84862,
            "f1": 0.82687
        },
        "nubia": {
            "semantic_relation": 3.52183,
            "contradiction": 0.07903,
            "irrelevancy": 99.76646,
            "logical_agreement": 0.15451,
            "grammar_ref": 4.70243,
            "grammar_hyp": 5.20548,
            "nubia_score": 0.3934
        },
        "bleurt": -0.48785
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7692307692307693
        },
        "nist": 3.3720511100332526,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.80556,
            "fmeasure": 0.75672
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.54283,
            "fmeasure": 0.52021
        },
        "rougeL": {
            "precision": 0.69841,
            "recall": 0.75926,
            "fmeasure": 0.72712
        },
        "rougeLsum": {
            "precision": 0.69841,
            "recall": 0.75926,
            "fmeasure": 0.72712
        },
        "bleu": 42.97641,
        "meteor": 0.4082393286168766,
        "bertscore": {
            "precision": 0.93965,
            "recall": 0.93627,
            "f1": 0.93796
        },
        "nubia": {
            "semantic_relation": 4.11106,
            "contradiction": 5.24418,
            "irrelevancy": 91.8714,
            "logical_agreement": 2.88442,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.45627,
            "nubia_score": 0.66118
        },
        "bleurt": 0.31603
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 3.354990287206174,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "bleu": 69.97522,
        "meteor": 0.5740797318313066,
        "bertscore": {
            "precision": 0.95106,
            "recall": 0.98284,
            "f1": 0.96669
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37452,
            "irrelevancy": 0.52123,
            "logical_agreement": 99.10425,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.27977,
            "nubia_score": 1.0
        },
        "bleurt": 0.72733
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75509,
        "total_length": 6476,
        "mean_pred_length": 18.03899721448468,
        "std_pred_length": 5.862266391042509,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.36009882643607166,
        "vocab_size-1": 2332,
        "unique-1": 1711,
        "entropy-1": 8.994610891244227,
        "distinct-2": 0.8236063429785843,
        "vocab_size-2": 5038,
        "unique-2": 4652,
        "entropy-2": 11.936370465318006,
        "cond_entropy-2": 2.774016535022966,
        "distinct-3": 0.9565821465786731,
        "vocab_size-3": 5508,
        "unique-3": 5396,
        "entropy-3": 12.343502390376473,
        "cond_entropy-3": 0.43009999380784947,
        "total_length-nopunct": 5787,
        "mean_pred_length-nopunct": 16.119777158774372,
        "std_pred_length-nopunct": 5.377620390521064,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4010713668567479,
        "vocab_size-1-nopunct": 2321,
        "unique-1-nopunct": 1710,
        "entropy-1-nopunct": 9.277520166685044,
        "distinct-2-nopunct": 0.8516949152542372,
        "vocab_size-2-nopunct": 4623,
        "unique-2-nopunct": 4298,
        "entropy-2-nopunct": 11.896640591350042,
        "cond_entropy-2-nopunct": 2.7568827422506894,
        "distinct-3-nopunct": 0.9781021897810219,
        "vocab_size-3-nopunct": 4958,
        "unique-3-nopunct": 4873,
        "entropy-3-nopunct": 12.258466379361023,
        "cond_entropy-3-nopunct": 0.3844966388725018,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "local_recall": {
            "1": 0.06027164685908319,
            "2": 0.17879948914431673,
            "3": 0.2713347921225383,
            "4": 0.30427892234548337,
            "5": 0.37694704049844235,
            "6": 0.517512077294686,
            "7": 0.6762122947689958
        },
        "nist": 7.356810123672047,
        "rouge1": {
            "precision": 0.6736,
            "recall": 0.6077,
            "fmeasure": 0.62309
        },
        "rouge2": {
            "precision": 0.44392,
            "recall": 0.40001,
            "fmeasure": 0.40794
        },
        "rougeL": {
            "precision": 0.62228,
            "recall": 0.55829,
            "fmeasure": 0.57396
        },
        "rougeLsum": {
            "precision": 0.62228,
            "recall": 0.55829,
            "fmeasure": 0.57396
        },
        "bleu": 37.59152,
        "sari": 42.32215,
        "meteor": 0.3098273997963408,
        "bertscore": {
            "precision": 0.90123,
            "recall": 0.89136,
            "f1": 0.89308
        },
        "nubia": {
            "semantic_relation": 3.52266,
            "contradiction": 13.1013,
            "irrelevancy": 28.3948,
            "logical_agreement": 58.5039,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.06461,
            "nubia_score": 0.49576
        },
        "bleurt": -0.15929
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.30952380952380953,
        "vocab_size-1": 13,
        "unique-1": 0,
        "entropy-1": 3.6052067078749124,
        "distinct-2": 0.5128205128205128,
        "vocab_size-2": 20,
        "unique-2": 12,
        "entropy-2": 4.034274333747602,
        "cond_entropy-2": 0.4446174885021272,
        "distinct-3": 0.6666666666666666,
        "vocab_size-3": 24,
        "unique-3": 18,
        "entropy-3": 4.377443751081733,
        "cond_entropy-3": 0.31534986603359005,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.30303030303030304,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.2021520733138717,
        "distinct-2-nopunct": 0.5666666666666667,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.755913095175825,
        "cond_entropy-2-nopunct": 0.5794889763942963,
        "distinct-3-nopunct": 0.7037037037037037,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.0504597240651785,
        "cond_entropy-3-nopunct": 0.24632607330174533,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.7777777777777778
        },
        "nist": 4.402063778276956,
        "rouge1": {
            "precision": 0.9697,
            "recall": 0.82828,
            "fmeasure": 0.87738
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.76859,
            "fmeasure": 0.80163
        },
        "rougeL": {
            "precision": 0.9697,
            "recall": 0.82828,
            "fmeasure": 0.87738
        },
        "rougeLsum": {
            "precision": 0.9697,
            "recall": 0.82828,
            "fmeasure": 0.87738
        },
        "bleu": 76.20958,
        "meteor": 0.5295259054143824,
        "bertscore": {
            "precision": 0.98848,
            "recall": 0.95443,
            "f1": 0.9705
        },
        "nubia": {
            "semantic_relation": 4.52146,
            "contradiction": 0.43858,
            "irrelevancy": 0.59338,
            "logical_agreement": 98.96804,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.09336,
            "nubia_score": 0.84845
        },
        "bleurt": 0.73853
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 19,
        "unique-1": 14,
        "entropy-1": 4.16829583405449,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.373382064031509,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.011365041826378,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.329610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.9166666666666666
        },
        "nist": 4.043749058681353,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.77632,
            "fmeasure": 0.7439
        },
        "rouge2": {
            "precision": 0.48333,
            "recall": 0.53021,
            "fmeasure": 0.50562
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.72632,
            "fmeasure": 0.69512
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.72632,
            "fmeasure": 0.69512
        },
        "bleu": 45.51439,
        "meteor": 0.4070271048188923,
        "bertscore": {
            "precision": 0.93752,
            "recall": 0.94195,
            "f1": 0.93973
        },
        "nubia": {
            "semantic_relation": 3.9662,
            "contradiction": 0.49687,
            "irrelevancy": 92.1426,
            "logical_agreement": 7.36054,
            "grammar_ref": 5.26752,
            "grammar_hyp": 4.60715,
            "nubia_score": 0.68045
        },
        "bleurt": 0.22854
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 11.5,
        "std_pred_length": 5.024937810560445,
        "median_pred_length": 9.5,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.6956521739130435,
        "vocab_size-1": 32,
        "unique-1": 22,
        "entropy-1": 4.819985260913527,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 40,
        "unique-2": 38,
        "entropy-2": 5.297079327540667,
        "cond_entropy-2": 0.32296536188962444,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.039126751440438125,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 9.75,
        "std_pred_length-nopunct": 3.766629793329841,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.804507667524723,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.01499730265925,
        "cond_entropy-2-nopunct": 0.26544901243024566,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.04605444849357523,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.18518518518518517,
            "3": 0.41379310344827586
        },
        "nist": 1.125904978460547,
        "rouge1": {
            "precision": 0.53704,
            "recall": 0.41365,
            "fmeasure": 0.43766
        },
        "rouge2": {
            "precision": 0.30615,
            "recall": 0.21544,
            "fmeasure": 0.2314
        },
        "rougeL": {
            "precision": 0.42882,
            "recall": 0.30425,
            "fmeasure": 0.33126
        },
        "rougeLsum": {
            "precision": 0.42882,
            "recall": 0.30425,
            "fmeasure": 0.33126
        },
        "bleu": 16.30002,
        "meteor": 0.18839421977984314,
        "bertscore": {
            "precision": 0.86973,
            "recall": 0.8234,
            "f1": 0.83472
        },
        "nubia": {
            "semantic_relation": 3.90567,
            "contradiction": 1.04689,
            "irrelevancy": 49.22552,
            "logical_agreement": 49.72759,
            "grammar_ref": 5.44243,
            "grammar_hyp": 6.51231,
            "nubia_score": 0.48895
        },
        "bleurt": -0.291
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 28.0,
        "std_pred_length": 0.0,
        "median_pred_length": 28.0,
        "min_pred_length": 28,
        "max_pred_length": 28,
        "distinct-1": 0.75,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.182005814760214,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.6808134280893965,
        "cond_entropy-2": 0.44789461730315844,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": 0.022475292900700414,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.165894208390023,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.1673550472167754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.8571428571428571
        },
        "nist": 3.4946494932784535,
        "rouge1": {
            "precision": 0.69565,
            "recall": 0.81974,
            "fmeasure": 0.75249
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.59503,
            "fmeasure": 0.54329
        },
        "rougeL": {
            "precision": 0.6087,
            "recall": 0.71842,
            "fmeasure": 0.65891
        },
        "rougeLsum": {
            "precision": 0.6087,
            "recall": 0.71842,
            "fmeasure": 0.65891
        },
        "bleu": 42.39616,
        "meteor": 0.3962537379535929,
        "bertscore": {
            "precision": 0.89832,
            "recall": 0.915,
            "f1": 0.90658
        },
        "nubia": {
            "semantic_relation": 3.60598,
            "contradiction": 10.56964,
            "irrelevancy": 86.75914,
            "logical_agreement": 2.67122,
            "grammar_ref": 4.38153,
            "grammar_hyp": 4.27981,
            "nubia_score": 0.5358
        },
        "bleurt": -0.03412
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8
        },
        "nist": 2.749392935937563,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.81818,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "bleu": 29.42096,
        "meteor": 0.4294445532848442,
        "bertscore": {
            "precision": 0.93197,
            "recall": 0.95335,
            "f1": 0.94254
        },
        "nubia": {
            "semantic_relation": 4.72715,
            "contradiction": 0.1028,
            "irrelevancy": 1.26627,
            "logical_agreement": 98.63092,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.29938,
            "nubia_score": 0.95284
        },
        "bleurt": 0.55574
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8125
        },
        "nist": 3.185518112510882,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.85784,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.52222,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.67402,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.67402,
            "fmeasure": 0.68056
        },
        "bleu": 26.45629,
        "meteor": 0.36922254770089824,
        "bertscore": {
            "precision": 0.93211,
            "recall": 0.90939,
            "f1": 0.92061
        },
        "nubia": {
            "semantic_relation": 3.65128,
            "contradiction": 1.99492,
            "irrelevancy": 1.31365,
            "logical_agreement": 96.69143,
            "grammar_ref": 4.86284,
            "grammar_hyp": 5.56924,
            "nubia_score": 0.50086
        },
        "bleurt": 0.1795
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 1.0,
        "vocab_size-1": 26,
        "unique-1": 26,
        "entropy-1": 4.70043971814109,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.05658352836636749,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.06711419585853673,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5789473684210527
        },
        "nist": 2.934822133712506,
        "rouge1": {
            "precision": 0.62319,
            "recall": 0.59697,
            "fmeasure": 0.60926
        },
        "rouge2": {
            "precision": 0.25758,
            "recall": 0.24603,
            "fmeasure": 0.25143
        },
        "rougeL": {
            "precision": 0.43478,
            "recall": 0.43636,
            "fmeasure": 0.43519
        },
        "rougeLsum": {
            "precision": 0.43478,
            "recall": 0.43636,
            "fmeasure": 0.43519
        },
        "bleu": 9.72951,
        "meteor": 0.2847780182732616,
        "bertscore": {
            "precision": 0.8656,
            "recall": 0.85448,
            "f1": 0.86
        },
        "nubia": {
            "semantic_relation": 3.86709,
            "contradiction": 3.61417,
            "irrelevancy": 95.79795,
            "logical_agreement": 0.58788,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.45407,
            "nubia_score": 0.60769
        },
        "bleurt": -0.23557
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964168,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.7
        },
        "nist": 2.4400563760003515,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.73077,
            "fmeasure": 0.68376
        },
        "rouge2": {
            "precision": 0.17949,
            "recall": 0.1553,
            "fmeasure": 0.16571
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.37418,
            "fmeasure": 0.38627
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.37418,
            "fmeasure": 0.38627
        },
        "bleu": 7.65512,
        "meteor": 0.2775303246738564,
        "bertscore": {
            "precision": 0.89056,
            "recall": 0.88801,
            "f1": 0.88194
        },
        "nubia": {
            "semantic_relation": 3.56084,
            "contradiction": 23.5797,
            "irrelevancy": 70.56416,
            "logical_agreement": 5.85615,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.83259,
            "nubia_score": 0.4633
        },
        "bleurt": -0.03709
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.070656113151928,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.2673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9057645846554525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.2222222222222222
        },
        "nist": 2.4457301827671785,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.29032,
            "fmeasure": 0.36735
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.06667,
            "fmeasure": 0.08511
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.22581,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.22581,
            "fmeasure": 0.28571
        },
        "bleu": 8.67235,
        "meteor": 0.15934678489236104,
        "bertscore": {
            "precision": 0.88009,
            "recall": 0.81077,
            "f1": 0.84401
        },
        "nubia": {
            "semantic_relation": 1.45749,
            "contradiction": 70.31196,
            "irrelevancy": 27.24476,
            "logical_agreement": 2.44329,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.45232,
            "nubia_score": 0.11025
        },
        "bleurt": -0.44075
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.0,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.55079,
            "irrelevancy": 0.53693,
            "logical_agreement": 98.91228,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.38626,
            "nubia_score": 1.0
        },
        "bleurt": 1.00232
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.0323250490537745,
        "rouge1": {
            "precision": 0.9697,
            "recall": 0.94444,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.90909,
            "fmeasure": 0.92063
        },
        "rougeL": {
            "precision": 0.9697,
            "recall": 0.94444,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 0.9697,
            "recall": 0.94444,
            "fmeasure": 0.95652
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.94097,
            "contradiction": 0.61596,
            "irrelevancy": 0.67712,
            "logical_agreement": 98.70691,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.43131,
            "nubia_score": 0.9388
        },
        "bleurt": 0.66206
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.0,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.875,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.726409765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.13205351234730084,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.681727678869737,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.14171030866920947,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.7666666666666667
        },
        "nist": 3.4746708140503006,
        "rouge1": {
            "precision": 0.82804,
            "recall": 0.6911,
            "fmeasure": 0.75239
        },
        "rouge2": {
            "precision": 0.48643,
            "recall": 0.42484,
            "fmeasure": 0.45238
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.48684,
            "fmeasure": 0.52449
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.48684,
            "fmeasure": 0.52449
        },
        "bleu": 30.81665,
        "meteor": 0.35806685658357423,
        "bertscore": {
            "precision": 0.92014,
            "recall": 0.90007,
            "f1": 0.90818
        },
        "nubia": {
            "semantic_relation": 4.45616,
            "contradiction": 20.5622,
            "irrelevancy": 3.22409,
            "logical_agreement": 76.21372,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.82486,
            "nubia_score": 0.71458
        },
        "bleurt": 0.30435
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.5909090909090909,
        "vocab_size-1": 13,
        "unique-1": 6,
        "entropy-1": 3.550340709546388,
        "distinct-2": 0.85,
        "vocab_size-2": 17,
        "unique-2": 14,
        "entropy-2": 4.021928094887362,
        "cond_entropy-2": 0.46249647625006507,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 17,
        "unique-3": 16,
        "entropy-3": 4.058813890331201,
        "cond_entropy-3": -0.04089198233393865,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.4219280948873623,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.94770277922009,
        "cond_entropy-2-nopunct": 0.5146635732216167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.04492500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.25,
            "3": 0.8666666666666667
        },
        "nist": 3.5650926512979493,
        "rouge1": {
            "precision": 0.87179,
            "recall": 0.82114,
            "fmeasure": 0.83251
        },
        "rouge2": {
            "precision": 0.53056,
            "recall": 0.53962,
            "fmeasure": 0.51898
        },
        "rougeL": {
            "precision": 0.72378,
            "recall": 0.75082,
            "fmeasure": 0.71754
        },
        "rougeLsum": {
            "precision": 0.72378,
            "recall": 0.75082,
            "fmeasure": 0.71754
        },
        "bleu": 43.69676,
        "meteor": 0.4740504300575948,
        "bertscore": {
            "precision": 0.95146,
            "recall": 0.96012,
            "f1": 0.95112
        },
        "nubia": {
            "semantic_relation": 3.98205,
            "contradiction": 37.76497,
            "irrelevancy": 12.58366,
            "logical_agreement": 49.65137,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.59718,
            "nubia_score": 0.63857
        },
        "bleurt": 0.38305
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518523,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 2.819383617925176,
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.64706,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.3125,
            "fmeasure": 0.32258
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.47059,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.47059,
            "fmeasure": 0.48485
        },
        "bleu": 17.07706,
        "meteor": 0.2981550266311108,
        "bertscore": {
            "precision": 0.91956,
            "recall": 0.91442,
            "f1": 0.91698
        },
        "nubia": {
            "semantic_relation": 3.52838,
            "contradiction": 50.03464,
            "irrelevancy": 35.86719,
            "logical_agreement": 14.09817,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.36987,
            "nubia_score": 0.49373
        },
        "bleurt": 0.06834
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.42857142857142855
        },
        "nist": 1.3995848442429204,
        "rouge1": {
            "precision": 0.38095,
            "recall": 0.5303,
            "fmeasure": 0.44121
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.28571,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.4697,
            "fmeasure": 0.38788
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.4697,
            "fmeasure": 0.38788
        },
        "bleu": 7.76856,
        "meteor": 0.21935996157538779,
        "bertscore": {
            "precision": 0.79378,
            "recall": 0.78805,
            "f1": 0.7909
        },
        "nubia": {
            "semantic_relation": 2.612,
            "contradiction": 0.72259,
            "irrelevancy": 96.41141,
            "logical_agreement": 2.866,
            "grammar_ref": 5.51883,
            "grammar_hyp": 4.35742,
            "nubia_score": 0.32147
        },
        "bleurt": -0.33211
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.751629167387823,
        "distinct-2-nopunct": 0.5909090909090909,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.6412498004554794,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.521928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.2544789837508556,
        "rouge1": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "bleu": 82.65168,
        "meteor": 0.5690637876265101,
        "bertscore": {
            "precision": 0.94318,
            "recall": 0.98431,
            "f1": 0.9633
        },
        "nubia": {
            "semantic_relation": 4.37248,
            "contradiction": 0.31688,
            "irrelevancy": 96.54524,
            "logical_agreement": 3.13788,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.47724,
            "nubia_score": 0.89041
        },
        "bleurt": 0.56358
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.6875,
        "vocab_size-1": 11,
        "unique-1": 6,
        "entropy-1": 3.375,
        "distinct-2": 0.7333333333333333,
        "vocab_size-2": 11,
        "unique-2": 7,
        "entropy-2": 3.3735572622751846,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 0.7857142857142857,
        "vocab_size-3": 11,
        "unique-3": 8,
        "entropy-3": 3.3787834934861767,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.2402239289418517,
        "distinct-2-nopunct": 0.7142857142857143,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.2359263506290334,
        "cond_entropy-2-nopunct": 0.04332146930622848,
        "distinct-3-nopunct": 0.7692307692307693,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 3.238901256602631,
        "cond_entropy-3-nopunct": 0.04693094992964168,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.125,
            "3": 0.7777777777777778
        },
        "nist": 2.2998423428100763,
        "rouge1": {
            "precision": 0.43137,
            "recall": 0.65887,
            "fmeasure": 0.50712
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.30556,
            "fmeasure": 0.22549
        },
        "rougeL": {
            "precision": 0.37255,
            "recall": 0.56725,
            "fmeasure": 0.43732
        },
        "rougeLsum": {
            "precision": 0.37255,
            "recall": 0.56725,
            "fmeasure": 0.43732
        },
        "bleu": 10.32617,
        "meteor": 0.3688467430703021,
        "bertscore": {
            "precision": 0.8911,
            "recall": 0.93739,
            "f1": 0.91366
        },
        "nubia": {
            "semantic_relation": 4.55892,
            "contradiction": 0.18338,
            "irrelevancy": 10.59145,
            "logical_agreement": 89.22517,
            "grammar_ref": 3.44041,
            "grammar_hyp": 3.09297,
            "nubia_score": 0.86356
        },
        "bleurt": 0.31594
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5714285714285714
        },
        "nist": 2.9997292837160456,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.68182,
            "fmeasure": 0.65217
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.4,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "rougeLsum": {
            "precision": 0.54167,
            "recall": 0.59091,
            "fmeasure": 0.56522
        },
        "bleu": 50.08718,
        "meteor": 0.32475256955519033,
        "bertscore": {
            "precision": 0.88097,
            "recall": 0.89407,
            "f1": 0.88747
        },
        "nubia": {
            "semantic_relation": 3.22419,
            "contradiction": 0.08178,
            "irrelevancy": 99.56479,
            "logical_agreement": 0.35343,
            "grammar_ref": 4.25346,
            "grammar_hyp": 3.90368,
            "nubia_score": 0.53738
        },
        "bleurt": -0.17979
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "nist": 0.9313738634396848,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.19394,
            "fmeasure": 0.20702
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.35354,
            "fmeasure": 0.37518
        },
        "bleu": 8.29519,
        "meteor": 0.2331715255855191,
        "bertscore": {
            "precision": 0.79602,
            "recall": 0.78154,
            "f1": 0.78871
        },
        "nubia": {
            "semantic_relation": 2.78899,
            "contradiction": 0.29727,
            "irrelevancy": 97.22608,
            "logical_agreement": 2.47665,
            "grammar_ref": 4.79209,
            "grammar_hyp": 3.90146,
            "nubia_score": 0.40056
        },
        "bleurt": -0.53575
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 9.333333333333334,
        "std_pred_length": 0.9428090415820634,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 10,
        "distinct-1": 0.5714285714285714,
        "vocab_size-1": 16,
        "unique-1": 8,
        "entropy-1": 3.8423709931771084,
        "distinct-2": 0.72,
        "vocab_size-2": 18,
        "unique-2": 12,
        "entropy-2": 4.053660689688185,
        "cond_entropy-2": 0.13689226789019796,
        "distinct-3": 0.8181818181818182,
        "vocab_size-3": 18,
        "unique-3": 14,
        "entropy-3": 4.095795255000932,
        "cond_entropy-3": -0.09351548022833667,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 7.666666666666667,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.6086956521739131,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.6424896731661263,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": 0.17385488904669627,
        "distinct-3-nopunct": 0.8823529411764706,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.8521687236032816,
        "cond_entropy-3-nopunct": -0.11681819481349333,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.6296296296296297
        },
        "nist": 2.7546147694785046,
        "rouge1": {
            "precision": 0.87778,
            "recall": 0.75377,
            "fmeasure": 0.79926
        },
        "rouge2": {
            "precision": 0.72994,
            "recall": 0.65741,
            "fmeasure": 0.68251
        },
        "rougeL": {
            "precision": 0.87778,
            "recall": 0.75377,
            "fmeasure": 0.79926
        },
        "rougeLsum": {
            "precision": 0.87778,
            "recall": 0.75377,
            "fmeasure": 0.79926
        },
        "bleu": 52.16523,
        "meteor": 0.41637274185660517,
        "bertscore": {
            "precision": 0.96919,
            "recall": 0.92515,
            "f1": 0.94546
        },
        "nubia": {
            "semantic_relation": 3.98677,
            "contradiction": 27.90518,
            "irrelevancy": 17.86301,
            "logical_agreement": 54.23182,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.47886,
            "nubia_score": 0.66522
        },
        "bleurt": 0.51528
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 2.9991662387674958,
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "bleu": 54.45179,
        "meteor": 0.5777337135978416,
        "bertscore": {
            "precision": 0.97343,
            "recall": 0.97664,
            "f1": 0.97503
        },
        "nubia": {
            "semantic_relation": 4.31239,
            "contradiction": 11.29198,
            "irrelevancy": 84.38835,
            "logical_agreement": 4.31966,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.14735,
            "nubia_score": 0.58383
        },
        "bleurt": 0.49208
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7272727272727273
        },
        "nist": 2.6887218755408675,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.72727,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.5,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.54545,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.54545,
            "fmeasure": 0.57143
        },
        "bleu": 29.50234,
        "meteor": 0.44028590549202845,
        "bertscore": {
            "precision": 0.95645,
            "recall": 0.92862,
            "f1": 0.94233
        },
        "nubia": {
            "semantic_relation": 4.27907,
            "contradiction": 0.70305,
            "irrelevancy": 0.55666,
            "logical_agreement": 98.74029,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.47742,
            "nubia_score": 0.81775
        },
        "bleurt": 0.50925
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.6521739130434783,
        "vocab_size-1": 15,
        "unique-1": 7,
        "entropy-1": 3.8279097821439705,
        "distinct-2": 0.8095238095238095,
        "vocab_size-2": 17,
        "unique-2": 13,
        "entropy-2": 4.011365041826378,
        "cond_entropy-2": 0.15446975243603325,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 17,
        "unique-3": 15,
        "entropy-3": 4.03740119765411,
        "cond_entropy-3": -0.03912675144043809,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.8365916681089787,
        "cond_entropy-2-nopunct": 0.18133023988828356,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.75,
        "cond_entropy-3-nopunct": -0.04492500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.6666666666666666,
            "3": 0.8823529411764706
        },
        "nist": 3.861502021277094,
        "rouge1": {
            "precision": 0.86364,
            "recall": 0.89057,
            "fmeasure": 0.86404
        },
        "rouge2": {
            "precision": 0.6125,
            "recall": 0.67923,
            "fmeasure": 0.63508
        },
        "rougeL": {
            "precision": 0.80808,
            "recall": 0.84512,
            "fmeasure": 0.81404
        },
        "rougeLsum": {
            "precision": 0.80808,
            "recall": 0.84512,
            "fmeasure": 0.81404
        },
        "bleu": 54.90266,
        "meteor": 0.49790167127634993,
        "bertscore": {
            "precision": 0.9706,
            "recall": 0.96919,
            "f1": 0.9689
        },
        "nubia": {
            "semantic_relation": 4.64484,
            "contradiction": 0.30261,
            "irrelevancy": 51.90623,
            "logical_agreement": 47.79115,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.59432,
            "nubia_score": 0.88335
        },
        "bleurt": 0.7628
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 1.0
        },
        "nist": 3.5678241128574446,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.625,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.625,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.625,
            "fmeasure": 0.625
        },
        "bleu": 75.06239,
        "meteor": 0.9684210526315788,
        "bertscore": {
            "precision": 0.99025,
            "recall": 0.99025,
            "f1": 0.99025
        },
        "nubia": {
            "semantic_relation": 4.43146,
            "contradiction": 0.1958,
            "irrelevancy": 50.0387,
            "logical_agreement": 49.7655,
            "grammar_ref": 5.57872,
            "grammar_hyp": 5.5548,
            "nubia_score": 0.83499
        },
        "bleurt": 0.59026
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5294117647058824
        },
        "nist": 1.332484129241516,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.54684,
            "fmeasure": 0.67406
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.30637,
            "fmeasure": 0.37987
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.40414,
            "fmeasure": 0.49425
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.40414,
            "fmeasure": 0.49425
        },
        "bleu": 19.26116,
        "meteor": 0.34901729971764583,
        "bertscore": {
            "precision": 0.93267,
            "recall": 0.89736,
            "f1": 0.91467
        },
        "nubia": {
            "semantic_relation": 3.99577,
            "contradiction": 0.12117,
            "irrelevancy": 24.08054,
            "logical_agreement": 75.79828,
            "grammar_ref": 4.84215,
            "grammar_hyp": 5.50262,
            "nubia_score": 0.55276
        },
        "bleurt": 0.17565
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 3.5,
        "median_pred_length": 17.5,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.8285714285714286,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.729283016944964,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.2787474660498503,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015323,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.008968687611256042,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.8461538461538461
        },
        "nist": 4.320473364849076,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.8303,
            "fmeasure": 0.84762
        },
        "rouge2": {
            "precision": 0.46825,
            "recall": 0.45714,
            "fmeasure": 0.46241
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.51515,
            "fmeasure": 0.52381
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.51515,
            "fmeasure": 0.52381
        },
        "bleu": 46.87055,
        "meteor": 0.4619705312851165,
        "bertscore": {
            "precision": 0.93629,
            "recall": 0.94382,
            "f1": 0.94003
        },
        "nubia": {
            "semantic_relation": 4.90946,
            "contradiction": 0.1854,
            "irrelevancy": 49.63283,
            "logical_agreement": 50.18177,
            "grammar_ref": 3.76682,
            "grammar_hyp": 3.71595,
            "nubia_score": 0.99351
        },
        "bleurt": 0.45916
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 1.9768180677927414,
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.8,
            "fmeasure": 0.69565
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.66667,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.8,
            "fmeasure": 0.69565
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.8,
            "fmeasure": 0.69565
        },
        "bleu": 37.59664,
        "meteor": 0.38961328260486333,
        "bertscore": {
            "precision": 0.93253,
            "recall": 0.91583,
            "f1": 0.92368
        },
        "nubia": {
            "semantic_relation": 3.81686,
            "contradiction": 10.70782,
            "irrelevancy": 28.37112,
            "logical_agreement": 60.92106,
            "grammar_ref": 5.64952,
            "grammar_hyp": 4.7933,
            "nubia_score": 0.54866
        },
        "bleurt": 0.45923
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.513321309731279,
        "rouge1": {
            "precision": 0.96667,
            "recall": 1.0,
            "fmeasure": 0.98246
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98039
        },
        "rougeL": {
            "precision": 0.96667,
            "recall": 1.0,
            "fmeasure": 0.98246
        },
        "rougeLsum": {
            "precision": 0.96667,
            "recall": 1.0,
            "fmeasure": 0.98246
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34129,
            "irrelevancy": 0.58866,
            "logical_agreement": 99.07005,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.2408,
            "nubia_score": 1.0
        },
        "bleurt": 0.88359
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.867976246918685,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "bleurt": 0.73788
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.2857142857142857,
            "3": 0.7
        },
        "nist": 2.3877730929972563,
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.63333,
            "fmeasure": 0.62424
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.37473,
            "fmeasure": 0.3619
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.52963,
            "fmeasure": 0.51919
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.52963,
            "fmeasure": 0.51919
        },
        "bleu": 34.38931,
        "meteor": 0.3758083270637795,
        "bertscore": {
            "precision": 0.92814,
            "recall": 0.92182,
            "f1": 0.92497
        },
        "nubia": {
            "semantic_relation": 4.39918,
            "contradiction": 0.11846,
            "irrelevancy": 1.10775,
            "logical_agreement": 98.77379,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.37779,
            "nubia_score": 0.90494
        },
        "bleurt": 0.39103
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 1.0,
            "3": 0.7
        },
        "nist": 4.055701326616097,
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.72381,
            "fmeasure": 0.7422
        },
        "rouge2": {
            "precision": 0.51282,
            "recall": 0.49206,
            "fmeasure": 0.50173
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.49841,
            "fmeasure": 0.51067
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.49841,
            "fmeasure": 0.51067
        },
        "bleu": 51.49732,
        "meteor": 0.38991285684853666,
        "bertscore": {
            "precision": 0.9265,
            "recall": 0.88358,
            "f1": 0.90453
        },
        "nubia": {
            "semantic_relation": 3.48669,
            "contradiction": 1.09644,
            "irrelevancy": 75.1678,
            "logical_agreement": 23.73577,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.48254,
            "nubia_score": 0.63744
        },
        "bleurt": -0.19388
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.9161269465882835,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": 0.329610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": 0.031262576450960075,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.7216117239699003,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.94770277922009,
        "cond_entropy-2-nopunct": 0.25533082133206014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": 0.15283195745508585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3684210526315789
        },
        "nist": 1.5697866751120209,
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.34565,
            "fmeasure": 0.39796
        },
        "rouge2": {
            "precision": 0.19444,
            "recall": 0.13715,
            "fmeasure": 0.16011
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.30725,
            "fmeasure": 0.35374
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.30725,
            "fmeasure": 0.35374
        },
        "bleu": 9.41665,
        "meteor": 0.2004285277292584,
        "bertscore": {
            "precision": 0.85611,
            "recall": 0.80048,
            "f1": 0.82736
        },
        "nubia": {
            "semantic_relation": 3.77256,
            "contradiction": 3.57048,
            "irrelevancy": 9.15346,
            "logical_agreement": 87.27607,
            "grammar_ref": 4.294,
            "grammar_hyp": 3.74496,
            "nubia_score": 0.61035
        },
        "bleurt": -0.12807
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "nist": 3.665478841615569,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.92308,
            "fmeasure": 0.92308
        },
        "bleu": 80.03203,
        "meteor": 0.5412422363150462,
        "bertscore": {
            "precision": 0.98984,
            "recall": 0.98984,
            "f1": 0.98984
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.09029,
            "irrelevancy": 0.64534,
            "logical_agreement": 98.26437,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.93719,
            "nubia_score": 0.99638
        },
        "bleurt": 0.85769
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9166666666666666
        },
        "nist": 3.4401968890879853,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "bleu": 76.11606,
        "meteor": 0.9703703703703703,
        "bertscore": {
            "precision": 0.99818,
            "recall": 0.99818,
            "f1": 0.99818
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21499,
            "irrelevancy": 0.42919,
            "logical_agreement": 99.35582,
            "grammar_ref": 4.72684,
            "grammar_hyp": 5.12886,
            "nubia_score": 0.95534
        },
        "bleurt": 0.84801
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.75
        },
        "nist": 3.0824229688160574,
        "rouge1": {
            "precision": 0.85294,
            "recall": 0.725,
            "fmeasure": 0.78378
        },
        "rouge2": {
            "precision": 0.6875,
            "recall": 0.57895,
            "fmeasure": 0.62857
        },
        "rougeL": {
            "precision": 0.79412,
            "recall": 0.675,
            "fmeasure": 0.72973
        },
        "rougeLsum": {
            "precision": 0.79412,
            "recall": 0.675,
            "fmeasure": 0.72973
        },
        "bleu": 51.22072,
        "meteor": 0.40638042909497374,
        "bertscore": {
            "precision": 0.93446,
            "recall": 0.91157,
            "f1": 0.92288
        },
        "nubia": {
            "semantic_relation": 4.08852,
            "contradiction": 0.33001,
            "irrelevancy": 0.56936,
            "logical_agreement": 99.10063,
            "grammar_ref": 4.55046,
            "grammar_hyp": 4.78611,
            "nubia_score": 0.66805
        },
        "bleurt": 0.21615
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 1.2866252014276134,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.66138,
            "fmeasure": 0.79365
        },
        "rouge2": {
            "precision": 0.81481,
            "recall": 0.46757,
            "fmeasure": 0.59207
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.5037,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.5037,
            "fmeasure": 0.66667
        },
        "bleu": 53.41953,
        "meteor": 0.37628312161800387,
        "bertscore": {
            "precision": 0.9768,
            "recall": 0.89041,
            "f1": 0.9316
        },
        "nubia": {
            "semantic_relation": 3.33105,
            "contradiction": 91.39293,
            "irrelevancy": 2.01149,
            "logical_agreement": 6.59557,
            "grammar_ref": 3.09217,
            "grammar_hyp": 3.50014,
            "nubia_score": 0.48175
        },
        "bleurt": -0.19515
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "bleurt": 0.97683
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5
        },
        "nist": 1.8248488266296587,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "bleu": 22.07607,
        "meteor": 0.3500146727273663,
        "bertscore": {
            "precision": 0.94157,
            "recall": 0.92966,
            "f1": 0.93558
        },
        "nubia": {
            "semantic_relation": 4.26538,
            "contradiction": 0.20192,
            "irrelevancy": 20.65833,
            "logical_agreement": 79.13975,
            "grammar_ref": 3.76485,
            "grammar_hyp": 3.40933,
            "nubia_score": 0.91413
        },
        "bleurt": 0.55182
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5555555555555556
        },
        "nist": 0.998658318138759,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.54444,
            "fmeasure": 0.66957
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.39827,
            "fmeasure": 0.49735
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.52222,
            "fmeasure": 0.64058
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.52222,
            "fmeasure": 0.64058
        },
        "bleu": 21.7929,
        "meteor": 0.2985045194114117,
        "bertscore": {
            "precision": 0.91326,
            "recall": 0.82764,
            "f1": 0.86606
        },
        "nubia": {
            "semantic_relation": 3.83037,
            "contradiction": 0.33214,
            "irrelevancy": 0.80058,
            "logical_agreement": 98.86728,
            "grammar_ref": 4.47457,
            "grammar_hyp": 4.87991,
            "nubia_score": 0.65307
        },
        "bleurt": 0.05518
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "nist": 2.32249814589546,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "bleu": 41.10546,
        "meteor": 0.8569614896318238,
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        },
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "bleurt": 0.65075
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 2.232633837416351,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.375,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "bleu": 32.55964,
        "meteor": 0.33091500230441734,
        "bertscore": {
            "precision": 0.89174,
            "recall": 0.92597,
            "f1": 0.90853
        },
        "nubia": {
            "semantic_relation": 4.91098,
            "contradiction": 0.08146,
            "irrelevancy": 6.40087,
            "logical_agreement": 93.51767,
            "grammar_ref": 4.6877,
            "grammar_hyp": 4.56102,
            "nubia_score": 0.96666
        },
        "bleurt": 0.54945
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 14,
        "entropy-1": 4.23890125660263,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.1813302398882836,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5,
            "3": 0.6842105263157895
        },
        "nist": 3.3798339772471917,
        "rouge1": {
            "precision": 0.79437,
            "recall": 0.66128,
            "fmeasure": 0.70117
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.33771,
            "fmeasure": 0.34087
        },
        "rougeL": {
            "precision": 0.67532,
            "recall": 0.59689,
            "fmeasure": 0.61735
        },
        "rougeLsum": {
            "precision": 0.67532,
            "recall": 0.59689,
            "fmeasure": 0.61735
        },
        "bleu": 21.04851,
        "meteor": 0.33285947413340533,
        "bertscore": {
            "precision": 0.89278,
            "recall": 0.89804,
            "f1": 0.89112
        },
        "nubia": {
            "semantic_relation": 4.14603,
            "contradiction": 10.43948,
            "irrelevancy": 22.6785,
            "logical_agreement": 66.88202,
            "grammar_ref": 6.17452,
            "grammar_hyp": 6.15032,
            "nubia_score": 0.60575
        },
        "bleurt": 0.17898
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "nist": 1.0,
        "rouge1": {
            "precision": 0.26667,
            "recall": 0.26667,
            "fmeasure": 0.26667
        },
        "rouge2": {
            "precision": 0.07143,
            "recall": 0.07143,
            "fmeasure": 0.07143
        },
        "rougeL": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeLsum": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "bleu": 5.81664,
        "meteor": 0.11611197449693993,
        "bertscore": {
            "precision": 0.78903,
            "recall": 0.79034,
            "f1": 0.78964
        },
        "nubia": {
            "semantic_relation": 2.24515,
            "contradiction": 10.29014,
            "irrelevancy": 89.43458,
            "logical_agreement": 0.27528,
            "grammar_ref": 5.48676,
            "grammar_hyp": 3.98562,
            "nubia_score": 0.24994
        },
        "bleurt": -0.35023
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.1,
            "3": 0.6363636363636364
        },
        "nist": 1.0981975091179785,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.47619,
            "fmeasure": 0.58824
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.29286,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.47619,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.47619,
            "fmeasure": 0.58824
        },
        "bleu": 26.03338,
        "meteor": 0.35173481544534596,
        "bertscore": {
            "precision": 0.96612,
            "recall": 0.88009,
            "f1": 0.9211
        },
        "nubia": {
            "semantic_relation": 4.16208,
            "contradiction": 0.09927,
            "irrelevancy": 66.60413,
            "logical_agreement": 33.29661,
            "grammar_ref": 3.9898,
            "grammar_hyp": 5.65139,
            "nubia_score": 0.4993
        },
        "bleurt": 0.29084
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74288,
        "msttr-100_nopunct": 0.75354,
        "total_length": 10491,
        "mean_pred_length": 20.982,
        "std_pred_length": 3.325308406749666,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.2788104089219331,
        "vocab_size-1": 2925,
        "unique-1": 1850,
        "entropy-1": 9.114059815268007,
        "distinct-2": 0.7398658792913623,
        "vocab_size-2": 7392,
        "unique-2": 6460,
        "entropy-2": 12.363590296018927,
        "cond_entropy-2": 3.151237861327683,
        "distinct-3": 0.9260351912338004,
        "vocab_size-3": 8789,
        "unique-3": 8387,
        "entropy-3": 13.018121105716581,
        "cond_entropy-3": 0.6752842701162877,
        "total_length-nopunct": 9964,
        "mean_pred_length-nopunct": 19.928,
        "std_pred_length-nopunct": 3.447726207227018,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.2925531914893617,
        "vocab_size-1-nopunct": 2915,
        "unique-1-nopunct": 1849,
        "entropy-1-nopunct": 9.208243712445263,
        "distinct-2-nopunct": 0.7438715131022823,
        "vocab_size-2-nopunct": 7040,
        "unique-2-nopunct": 6174,
        "entropy-2-nopunct": 12.293727031826723,
        "cond_entropy-2-nopunct": 3.199886718258156,
        "distinct-3-nopunct": 0.9311691209281571,
        "vocab_size-3-nopunct": 8347,
        "unique-3-nopunct": 7988,
        "entropy-3-nopunct": 12.95166599607606,
        "cond_entropy-3-nopunct": 0.6766760503618064,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3502476498534317
        },
        "nist": 3.5686070081467696,
        "rouge1": {
            "precision": 0.39617,
            "recall": 0.3817,
            "fmeasure": 0.38187
        },
        "rouge2": {
            "precision": 0.14716,
            "recall": 0.14271,
            "fmeasure": 0.14232
        },
        "rougeL": {
            "precision": 0.30561,
            "recall": 0.29485,
            "fmeasure": 0.29481
        },
        "rougeLsum": {
            "precision": 0.30561,
            "recall": 0.29485,
            "fmeasure": 0.29481
        },
        "bleu": 9.75348,
        "meteor": 0.16311214935329388,
        "bertscore": {
            "precision": 0.82465,
            "recall": 0.81963,
            "f1": 0.8218
        },
        "nubia": {
            "semantic_relation": 2.80165,
            "contradiction": 23.02265,
            "irrelevancy": 65.77429,
            "logical_agreement": 11.20306,
            "grammar_ref": 3.78538,
            "grammar_hyp": 3.96658,
            "nubia_score": 0.38014
        },
        "bleurt": -0.41713
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.854285871987245,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "bleurt": 0.94692
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.831357016901516,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.79545,
            "fmeasure": 0.82895
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.60119,
            "fmeasure": 0.60952
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.76852,
            "fmeasure": 0.77941
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.76852,
            "fmeasure": 0.77941
        },
        "bleu": 51.69732,
        "meteor": 0.8999999999999999,
        "bertscore": {
            "precision": 0.9515,
            "recall": 0.9515,
            "f1": 0.9515
        },
        "nubia": {
            "semantic_relation": 3.88764,
            "contradiction": 1.48712,
            "irrelevancy": 3.02745,
            "logical_agreement": 95.48543,
            "grammar_ref": 3.66596,
            "grammar_hyp": 3.88296,
            "nubia_score": 0.68846
        },
        "bleurt": 0.30761
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 1.5993137571087497,
        "rouge1": {
            "precision": 0.42222,
            "recall": 0.76587,
            "fmeasure": 0.53648
        },
        "rouge2": {
            "precision": 0.19048,
            "recall": 0.31515,
            "fmeasure": 0.23018
        },
        "rougeL": {
            "precision": 0.35556,
            "recall": 0.64286,
            "fmeasure": 0.45118
        },
        "rougeLsum": {
            "precision": 0.35556,
            "recall": 0.64286,
            "fmeasure": 0.45118
        },
        "bleu": 8.54916,
        "meteor": 0.30416407043185206,
        "bertscore": {
            "precision": 0.84264,
            "recall": 0.89567,
            "f1": 0.84299
        },
        "nubia": {
            "semantic_relation": 3.31003,
            "contradiction": 3.66695,
            "irrelevancy": 95.4761,
            "logical_agreement": 0.85695,
            "grammar_ref": 6.44614,
            "grammar_hyp": 5.64913,
            "nubia_score": 0.3984
        },
        "bleurt": -0.98352
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 13,
        "unique-1": 10,
        "entropy-1": 3.530493056757482,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 16,
        "unique-2": 15,
        "entropy-2": 3.969815782426811,
        "cond_entropy-2": 0.4769363694743175,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": 0.03753715874966059,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.1395722619867223,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.5797339696152954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.7777777777777778
        },
        "nist": 2.1987741796570663,
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.63333,
            "fmeasure": 0.63333
        },
        "rouge2": {
            "precision": 0.17857,
            "recall": 0.17857,
            "fmeasure": 0.17857
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "bleu": 8.65711,
        "meteor": 0.3274018635813225,
        "bertscore": {
            "precision": 0.89624,
            "recall": 0.89268,
            "f1": 0.89446
        },
        "nubia": {
            "semantic_relation": 3.67076,
            "contradiction": 19.51022,
            "irrelevancy": 42.70365,
            "logical_agreement": 37.78612,
            "grammar_ref": 5.62728,
            "grammar_hyp": 4.94871,
            "nubia_score": 0.5624
        },
        "bleurt": -0.61952
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "nist": 3.557533649399047,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.625,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "rougeLsum": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "bleu": 61.28081,
        "meteor": 0.4907863019777329,
        "bertscore": {
            "precision": 0.98135,
            "recall": 0.98613,
            "f1": 0.98373
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31478,
            "irrelevancy": 0.53733,
            "logical_agreement": 99.14789,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.43696,
            "nubia_score": 0.88323
        },
        "bleurt": 0.67301
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.8,
        "vocab_size-1": 8,
        "unique-1": 6,
        "entropy-1": 2.9219280948873623,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 8,
        "unique-2": 7,
        "entropy-2": 2.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": 0.08007499855768763,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.75,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.47872969366552,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "bleurt": 0.9148
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.745,
        "msttr-100_nopunct": 0.75905,
        "total_length": 2232,
        "mean_pred_length": 21.056603773584907,
        "std_pred_length": 3.2789499834471436,
        "median_pred_length": 21.5,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.42383512544802865,
        "vocab_size-1": 946,
        "unique-1": 717,
        "entropy-1": 8.354935028933353,
        "distinct-2": 0.8405456255879586,
        "vocab_size-2": 1787,
        "unique-2": 1638,
        "entropy-2": 10.586095326972732,
        "cond_entropy-2": 2.126878670290585,
        "distinct-3": 0.9633663366336633,
        "vocab_size-3": 1946,
        "unique-3": 1900,
        "entropy-3": 10.890893077157024,
        "cond_entropy-3": 0.32166916789637723,
        "total_length-nopunct": 2104,
        "mean_pred_length-nopunct": 19.849056603773583,
        "std_pred_length-nopunct": 3.4416770068438325,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.44629277566539927,
        "vocab_size-1-nopunct": 939,
        "unique-1-nopunct": 716,
        "entropy-1-nopunct": 8.430914862439046,
        "distinct-2-nopunct": 0.8443443443443444,
        "vocab_size-2-nopunct": 1687,
        "unique-2-nopunct": 1552,
        "entropy-2-nopunct": 10.50269475766551,
        "cond_entropy-2-nopunct": 2.1707778090134773,
        "distinct-3-nopunct": 0.9661733615221987,
        "vocab_size-3-nopunct": 1828,
        "unique-3-nopunct": 1788,
        "entropy-3-nopunct": 10.803289712135486,
        "cond_entropy-3-nopunct": 0.31685157994839414,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3119815668202765
        },
        "nist": 2.8911593474951456,
        "rouge1": {
            "precision": 0.36293,
            "recall": 0.33952,
            "fmeasure": 0.34528
        },
        "rouge2": {
            "precision": 0.11754,
            "recall": 0.11069,
            "fmeasure": 0.11235
        },
        "rougeL": {
            "precision": 0.27561,
            "recall": 0.25793,
            "fmeasure": 0.26242
        },
        "rougeLsum": {
            "precision": 0.27561,
            "recall": 0.25793,
            "fmeasure": 0.26242
        },
        "bleu": 7.00716,
        "meteor": 0.14682265113862436,
        "bertscore": {
            "precision": 0.81706,
            "recall": 0.81194,
            "f1": 0.81426
        },
        "nubia": {
            "semantic_relation": 2.63335,
            "contradiction": 24.5535,
            "irrelevancy": 68.56495,
            "logical_agreement": 6.88155,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.8686,
            "nubia_score": 0.3454
        },
        "bleurt": -0.42175
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "nist": 2.5249790384034756,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.51754,
            "fmeasure": 0.5358
        },
        "rouge2": {
            "precision": 0.21569,
            "recall": 0.20078,
            "fmeasure": 0.20794
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.46579,
            "fmeasure": 0.48222
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.46579,
            "fmeasure": 0.48222
        },
        "bleu": 16.69107,
        "meteor": 0.2811002242758874,
        "bertscore": {
            "precision": 0.81253,
            "recall": 0.78171,
            "f1": 0.79682
        },
        "nubia": {
            "semantic_relation": 3.75448,
            "contradiction": 0.14744,
            "irrelevancy": 99.38746,
            "logical_agreement": 0.4651,
            "grammar_ref": 4.62058,
            "grammar_hyp": 5.02487,
            "nubia_score": 0.53058
        },
        "bleurt": -0.18422
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "nist": 3.0088906840841796,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "bleu": 58.33511,
        "meteor": 0.4630505936482093,
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        },
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "bleurt": 0.7528
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.6042028126043453,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "bleu": 15.6197,
        "meteor": 0.29493026749867945,
        "bertscore": {
            "precision": 0.89356,
            "recall": 0.89135,
            "f1": 0.89245
        },
        "nubia": {
            "semantic_relation": 4.74574,
            "contradiction": 0.29988,
            "irrelevancy": 0.49995,
            "logical_agreement": 99.20017,
            "grammar_ref": 5.72796,
            "grammar_hyp": 5.20023,
            "nubia_score": 0.96448
        },
        "bleurt": 0.62629
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5833333333333334
        },
        "nist": 1.758572044313509,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.58333,
            "fmeasure": 0.53846
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.36364,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.5,
            "fmeasure": 0.46154
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.5,
            "fmeasure": 0.46154
        },
        "bleu": 24.07844,
        "meteor": 0.27393242266513296,
        "bertscore": {
            "precision": 0.81523,
            "recall": 0.8879,
            "f1": 0.85002
        },
        "nubia": {
            "semantic_relation": 3.28979,
            "contradiction": 41.32265,
            "irrelevancy": 54.96127,
            "logical_agreement": 3.71607,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.73924,
            "nubia_score": 0.40016
        },
        "bleurt": -0.81336
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 1.0,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.8928571428571429,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.593069207771891,
        "distinct-2": 0.9615384615384616,
        "vocab_size-2": 25,
        "unique-2": 24,
        "entropy-2": 4.623516641218013,
        "cond_entropy-2": -0.02999212699343526,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.03214388408660254,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": -0.036006438040157185,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.03912675144043808,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.6666666666666666
        },
        "nist": 3.1793249234584042,
        "rouge1": {
            "precision": 0.59829,
            "recall": 0.62222,
            "fmeasure": 0.60287
        },
        "rouge2": {
            "precision": 0.36806,
            "recall": 0.31944,
            "fmeasure": 0.34174
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.59717,
            "fmeasure": 0.59782
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.59717,
            "fmeasure": 0.59782
        },
        "bleu": 26.51392,
        "meteor": 0.2926490082293192,
        "bertscore": {
            "precision": 0.89485,
            "recall": 0.87899,
            "f1": 0.88681
        },
        "nubia": {
            "semantic_relation": 4.12989,
            "contradiction": 45.52879,
            "irrelevancy": 47.26495,
            "logical_agreement": 7.20626,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.5527,
            "nubia_score": 0.64762
        },
        "bleurt": 0.29506
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 2.8045330046640538,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.375,
            "fmeasure": 0.42857
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.66667,
            "fmeasure": 0.75
        },
        "bleu": 34.66668,
        "meteor": 0.47818878613286225,
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.92279,
            "f1": 0.9389
        },
        "nubia": {
            "semantic_relation": 4.82331,
            "contradiction": 0.93144,
            "irrelevancy": 0.65741,
            "logical_agreement": 98.41114,
            "grammar_ref": 5.69157,
            "grammar_hyp": 6.14878,
            "nubia_score": 0.83549
        },
        "bleurt": 0.66772
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.462425934400558,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.21715,
            "contradiction": 0.42269,
            "irrelevancy": 0.62596,
            "logical_agreement": 98.95136,
            "grammar_ref": 6.37596,
            "grammar_hyp": 6.07415,
            "nubia_score": 0.84205
        },
        "bleurt": 0.45919
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673078,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "nist": 1.8591179305199363,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.92857,
            "fmeasure": 0.775
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.55,
            "fmeasure": 0.44505
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.70238,
            "fmeasure": 0.58333
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.70238,
            "fmeasure": 0.58333
        },
        "bleu": 14.69411,
        "meteor": 0.3991346130099254,
        "bertscore": {
            "precision": 0.87335,
            "recall": 0.90919,
            "f1": 0.89091
        },
        "nubia": {
            "semantic_relation": 4.33683,
            "contradiction": 0.82659,
            "irrelevancy": 98.56871,
            "logical_agreement": 0.60471,
            "grammar_ref": 7.77345,
            "grammar_hyp": 5.33661,
            "nubia_score": 1.0
        },
        "bleurt": 0.20769
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.23688579544383911,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.14257499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.12121650651382443,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.42857142857142855,
            "3": 1.0
        },
        "nist": 2.5952632418158172,
        "rouge1": {
            "precision": 0.7125,
            "recall": 0.72569,
            "fmeasure": 0.71345
        },
        "rouge2": {
            "precision": 0.45238,
            "recall": 0.47232,
            "fmeasure": 0.4593
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.60574,
            "fmeasure": 0.59064
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.60574,
            "fmeasure": 0.59064
        },
        "bleu": 13.61419,
        "meteor": 0.37010724418194707,
        "bertscore": {
            "precision": 0.83298,
            "recall": 0.87632,
            "f1": 0.85153
        },
        "nubia": {
            "semantic_relation": 4.10248,
            "contradiction": 12.32382,
            "irrelevancy": 44.97266,
            "logical_agreement": 42.70352,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.2718,
            "nubia_score": 0.70144
        },
        "bleurt": -0.18713
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "nist": 3.9427950465634054,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.875,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.49231,
            "fmeasure": 0.48361
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.34226,
            "fmeasure": 0.33741
        },
        "bleu": 29.61517,
        "meteor": 0.43170776462300553,
        "bertscore": {
            "precision": 0.94698,
            "recall": 0.91733,
            "f1": 0.93192
        },
        "nubia": {
            "semantic_relation": 4.7494,
            "contradiction": 0.24521,
            "irrelevancy": 33.5672,
            "logical_agreement": 66.18759,
            "grammar_ref": 4.41465,
            "grammar_hyp": 5.01939,
            "nubia_score": 0.82759
        },
        "bleurt": 0.3074
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.274328580297647,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "bleu": 90.3602,
        "meteor": 0.5538043848309318,
        "bertscore": {
            "precision": 0.97292,
            "recall": 0.98764,
            "f1": 0.98023
        },
        "nubia": {
            "semantic_relation": 4.36904,
            "contradiction": 26.33702,
            "irrelevancy": 55.43023,
            "logical_agreement": 18.23275,
            "grammar_ref": 5.78237,
            "grammar_hyp": 6.15853,
            "nubia_score": 0.59385
        },
        "bleurt": 0.54426
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.8465578035643277,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.69325,
            "irrelevancy": 0.54497,
            "logical_agreement": 98.76179,
            "grammar_ref": 7.00423,
            "grammar_hyp": 7.45225,
            "nubia_score": 0.93405
        },
        "bleurt": 0.87565
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "nist": 2.9898332363522426,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.71429,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "bleu": 61.0195,
        "meteor": 0.5230551846972475,
        "bertscore": {
            "precision": 0.99164,
            "recall": 0.97723,
            "f1": 0.98438
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51812,
            "irrelevancy": 0.46692,
            "logical_agreement": 99.01496,
            "grammar_ref": 5.85687,
            "grammar_hyp": 6.57356,
            "nubia_score": 0.90444
        },
        "bleurt": 0.84839
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 3.215258997148204,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.76852,
            "fmeasure": 0.71345
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.34524,
            "fmeasure": 0.31863
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.76852,
            "fmeasure": 0.71345
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.76852,
            "fmeasure": 0.71345
        },
        "bleu": 46.82569,
        "meteor": 0.43285228329802944,
        "bertscore": {
            "precision": 0.90994,
            "recall": 0.93093,
            "f1": 0.92031
        },
        "nubia": {
            "semantic_relation": 4.50443,
            "contradiction": 1.35294,
            "irrelevancy": 27.78692,
            "logical_agreement": 70.86014,
            "grammar_ref": 5.6187,
            "grammar_hyp": 5.91635,
            "nubia_score": 0.67315
        },
        "bleurt": 0.42469
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.8796640049025934,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 18,
        "unique-2": 15,
        "entropy-2": 4.106603137064474,
        "cond_entropy-2": 0.25454711376829514,
        "distinct-3": 0.9,
        "vocab_size-3": 18,
        "unique-3": 16,
        "entropy-3": 4.1219280948873624,
        "cond_entropy-3": 0.02961067210860201,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.6841837197791887,
        "distinct-2-nopunct": 0.8421052631578947,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.9321380397593733,
        "cond_entropy-2-nopunct": 0.28151981340693205,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": 0.03310859910983795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 3.025386574168449,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.52937,
            "fmeasure": 0.52652
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.275,
            "fmeasure": 0.27037
        },
        "rougeL": {
            "precision": 0.34921,
            "recall": 0.35238,
            "fmeasure": 0.35075
        },
        "rougeLsum": {
            "precision": 0.34921,
            "recall": 0.35238,
            "fmeasure": 0.35075
        },
        "bleu": 19.10722,
        "meteor": 0.2994513904607795,
        "bertscore": {
            "precision": 0.89124,
            "recall": 0.8702,
            "f1": 0.88059
        },
        "nubia": {
            "semantic_relation": 2.91423,
            "contradiction": 29.39685,
            "irrelevancy": 69.22567,
            "logical_agreement": 1.37748,
            "grammar_ref": 5.50536,
            "grammar_hyp": 4.10136,
            "nubia_score": 0.4355
        },
        "bleurt": -0.33214
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.5806451612903226,
        "vocab_size-1": 18,
        "unique-1": 7,
        "entropy-1": 4.050970503935262,
        "distinct-2": 0.7241379310344828,
        "vocab_size-2": 21,
        "unique-2": 13,
        "entropy-2": 4.306256857196538,
        "cond_entropy-2": 0.24861227094759358,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 22,
        "unique-3": 17,
        "entropy-3": 4.3845171317931,
        "cond_entropy-3": 0.04505465518404472,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6086956521739131,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.7409532604048397,
        "distinct-2-nopunct": 0.7619047619047619,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.916126946588283,
        "cond_entropy-2-nopunct": 0.15446975243603325,
        "distinct-3-nopunct": 0.8421052631578947,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.9321380397593733,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9130434782608695
        },
        "nist": 4.4163261036911825,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.95455,
            "fmeasure": 0.95455
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.9,
            "fmeasure": 0.9
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.95455,
            "fmeasure": 0.95455
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.95455,
            "fmeasure": 0.95455
        },
        "bleu": 79.60104,
        "meteor": 0.49838606005668157,
        "bertscore": {
            "precision": 0.98768,
            "recall": 0.9345,
            "f1": 0.95955
        },
        "nubia": {
            "semantic_relation": 4.54593,
            "contradiction": 45.5584,
            "irrelevancy": 11.71164,
            "logical_agreement": 42.72996,
            "grammar_ref": 4.1188,
            "grammar_hyp": 3.60981,
            "nubia_score": 0.89319
        },
        "bleurt": 0.51242
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5
        },
        "nist": 2.2031417285690287,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.45299,
            "fmeasure": 0.4714
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.125,
            "fmeasure": 0.14286
        },
        "rougeL": {
            "precision": 0.35,
            "recall": 0.32051,
            "fmeasure": 0.33181
        },
        "rougeLsum": {
            "precision": 0.35,
            "recall": 0.32051,
            "fmeasure": 0.33181
        },
        "bleu": 12.19209,
        "meteor": 0.2382234444404113,
        "bertscore": {
            "precision": 0.85637,
            "recall": 0.84768,
            "f1": 0.84534
        },
        "nubia": {
            "semantic_relation": 2.56367,
            "contradiction": 0.6162,
            "irrelevancy": 96.90027,
            "logical_agreement": 2.48353,
            "grammar_ref": 4.60771,
            "grammar_hyp": 4.99369,
            "nubia_score": 0.22953
        },
        "bleurt": -0.49317
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "nist": 1.5883314296664186,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.38182,
            "fmeasure": 0.39048
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.10556,
            "fmeasure": 0.10819
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.38182,
            "fmeasure": 0.39048
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.38182,
            "fmeasure": 0.39048
        },
        "bleu": 11.20847,
        "meteor": 0.3109179802026268,
        "bertscore": {
            "precision": 0.86481,
            "recall": 0.85451,
            "f1": 0.85963
        },
        "nubia": {
            "semantic_relation": 3.19966,
            "contradiction": 91.14662,
            "irrelevancy": 7.49734,
            "logical_agreement": 1.35603,
            "grammar_ref": 4.7527,
            "grammar_hyp": 4.95812,
            "nubia_score": 0.32234
        },
        "bleurt": 0.39304
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966054,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nist": 3.440608006668461,
        "rouge1": {
            "precision": 0.7619,
            "recall": 0.63971,
            "fmeasure": 0.69534
        },
        "rouge2": {
            "precision": 0.28205,
            "recall": 0.23333,
            "fmeasure": 0.25534
        },
        "rougeL": {
            "precision": 0.40476,
            "recall": 0.33946,
            "fmeasure": 0.36918
        },
        "rougeLsum": {
            "precision": 0.40476,
            "recall": 0.33946,
            "fmeasure": 0.36918
        },
        "bleu": 21.84182,
        "meteor": 0.3585815314681822,
        "bertscore": {
            "precision": 0.91252,
            "recall": 0.91144,
            "f1": 0.91198
        },
        "nubia": {
            "semantic_relation": 4.67916,
            "contradiction": 0.14947,
            "irrelevancy": 0.50608,
            "logical_agreement": 99.34445,
            "grammar_ref": 5.85115,
            "grammar_hyp": 5.2562,
            "nubia_score": 0.93279
        },
        "bleurt": 0.28957
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 3.0,
        "median_pred_length": 19.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.7105263157894737,
        "vocab_size-1": 27,
        "unique-1": 18,
        "entropy-1": 4.616348566075165,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.47755304355428246,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.506890595608518,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.22189289787765704,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.029992126993435266,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "nist": 3.3898904851433005,
        "rouge1": {
            "precision": 0.7265,
            "recall": 0.91502,
            "fmeasure": 0.79919
        },
        "rouge2": {
            "precision": 0.5098,
            "recall": 0.66364,
            "fmeasure": 0.57005
        },
        "rougeL": {
            "precision": 0.60684,
            "recall": 0.7803,
            "fmeasure": 0.67586
        },
        "rougeLsum": {
            "precision": 0.60684,
            "recall": 0.7803,
            "fmeasure": 0.67586
        },
        "bleu": 46.03318,
        "meteor": 0.4228536852220399,
        "bertscore": {
            "precision": 0.85857,
            "recall": 0.94815,
            "f1": 0.89751
        },
        "nubia": {
            "semantic_relation": 3.95115,
            "contradiction": 1.99199,
            "irrelevancy": 79.72719,
            "logical_agreement": 18.28082,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.29839,
            "nubia_score": 0.63096
        },
        "bleurt": -0.23817
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.75318,
        "msttr-100_nopunct": 0.76476,
        "total_length": 2219,
        "mean_pred_length": 20.933962264150942,
        "std_pred_length": 3.277334593280316,
        "median_pred_length": 21.5,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.4263181613339342,
        "vocab_size-1": 946,
        "unique-1": 720,
        "entropy-1": 8.393033760277469,
        "distinct-2": 0.8442972077614765,
        "vocab_size-2": 1784,
        "unique-2": 1626,
        "entropy-2": 10.60311402001353,
        "cond_entropy-2": 2.1108656123347074,
        "distinct-3": 0.9646238166417539,
        "vocab_size-3": 1936,
        "unique-3": 1883,
        "entropy-3": 10.89147344099087,
        "cond_entropy-3": 0.3001946695465963,
        "total_length-nopunct": 2111,
        "mean_pred_length-nopunct": 19.91509433962264,
        "std_pred_length-nopunct": 3.350916305346891,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4448128848886784,
        "vocab_size-1-nopunct": 939,
        "unique-1-nopunct": 717,
        "entropy-1-nopunct": 8.460717708511064,
        "distinct-2-nopunct": 0.8438902743142145,
        "vocab_size-2-nopunct": 1692,
        "unique-2-nopunct": 1547,
        "entropy-2-nopunct": 10.520706609150647,
        "cond_entropy-2-nopunct": 2.1558531201517437,
        "distinct-3-nopunct": 0.9647182727751448,
        "vocab_size-3-nopunct": 1832,
        "unique-3-nopunct": 1783,
        "entropy-3-nopunct": 10.81137259406411,
        "cond_entropy-3-nopunct": 0.30483043598966003,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.30422535211267604
        },
        "nist": 2.797902211710407,
        "rouge1": {
            "precision": 0.35539,
            "recall": 0.34362,
            "fmeasure": 0.3426
        },
        "rouge2": {
            "precision": 0.12115,
            "recall": 0.11601,
            "fmeasure": 0.11637
        },
        "rougeL": {
            "precision": 0.27348,
            "recall": 0.26367,
            "fmeasure": 0.26341
        },
        "rougeLsum": {
            "precision": 0.27348,
            "recall": 0.26367,
            "fmeasure": 0.26341
        },
        "bleu": 7.9875,
        "meteor": 0.14371025138897023,
        "bertscore": {
            "precision": 0.8173,
            "recall": 0.80861,
            "f1": 0.8126
        },
        "nubia": {
            "semantic_relation": 2.50672,
            "contradiction": 33.40774,
            "irrelevancy": 55.78683,
            "logical_agreement": 10.80543,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.95282,
            "nubia_score": 0.31372
        },
        "bleurt": -0.4351
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 3.0,
        "median_pred_length": 21.0,
        "min_pred_length": 18,
        "max_pred_length": 24,
        "distinct-1": 0.6904761904761905,
        "vocab_size-1": 29,
        "unique-1": 19,
        "entropy-1": 4.719349267862323,
        "distinct-2": 0.85,
        "vocab_size-2": 34,
        "unique-2": 28,
        "entropy-2": 5.021928094887363,
        "cond_entropy-2": 0.33622723477086214,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 34,
        "unique-3": 30,
        "entropy-3": 5.037401197654114,
        "cond_entropy-3": 0.03126257645096009,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.560667282798391,
        "distinct-2-nopunct": 0.8378378378378378,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.885129041304629,
        "cond_entropy-2-nopunct": 0.3636366199150905,
        "distinct-3-nopunct": 0.8857142857142857,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.900711588373535,
        "cond_entropy-3-nopunct": 0.03411536560173091,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.8857142857142857
        },
        "nist": 4.500806334674062,
        "rouge1": {
            "precision": 0.97727,
            "recall": 0.83627,
            "fmeasure": 0.89423
        },
        "rouge2": {
            "precision": 0.84127,
            "recall": 0.73668,
            "fmeasure": 0.77926
        },
        "rougeL": {
            "precision": 0.87121,
            "recall": 0.75,
            "fmeasure": 0.79853
        },
        "rougeLsum": {
            "precision": 0.87121,
            "recall": 0.75,
            "fmeasure": 0.79853
        },
        "bleu": 67.63582,
        "meteor": 0.4492861958806591,
        "bertscore": {
            "precision": 0.95806,
            "recall": 0.92822,
            "f1": 0.94251
        },
        "nubia": {
            "semantic_relation": 4.54991,
            "contradiction": 2.09069,
            "irrelevancy": 1.66356,
            "logical_agreement": 96.24575,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.66061,
            "nubia_score": 0.782
        },
        "bleurt": 0.16719
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 4.062184071066062,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.81818,
            "fmeasure": 0.80702
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.4875,
            "fmeasure": 0.4644
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.68182,
            "fmeasure": 0.66416
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.68182,
            "fmeasure": 0.66416
        },
        "bleu": 70.16879,
        "meteor": 0.5538043848309318,
        "bertscore": {
            "precision": 0.98252,
            "recall": 0.99278,
            "f1": 0.98762
        },
        "nubia": {
            "semantic_relation": 4.94839,
            "contradiction": 0.27723,
            "irrelevancy": 15.35454,
            "logical_agreement": 84.36823,
            "grammar_ref": 5.60099,
            "grammar_hyp": 5.26306,
            "nubia_score": 0.98151
        },
        "bleurt": 0.60355
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.7692307692307693
        },
        "nist": 3.8409079073408483,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.75,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.66667,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.75,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.75,
            "fmeasure": 0.85714
        },
        "bleu": 81.96501,
        "meteor": 0.4966624063624693,
        "bertscore": {
            "precision": 0.98659,
            "recall": 0.94382,
            "f1": 0.96473
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29112,
            "irrelevancy": 2.47078,
            "logical_agreement": 97.23811,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.685,
            "nubia_score": 0.96322
        },
        "bleurt": 0.60851
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 3.038485661251777,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.8963,
            "fmeasure": 0.79942
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.4213,
            "fmeasure": 0.37193
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "bleu": 27.62935,
        "meteor": 0.42856343508545097,
        "bertscore": {
            "precision": 0.90112,
            "recall": 0.91088,
            "f1": 0.90597
        },
        "nubia": {
            "semantic_relation": 4.34536,
            "contradiction": 0.38822,
            "irrelevancy": 93.49285,
            "logical_agreement": 6.11894,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.77914,
            "nubia_score": 0.56712
        },
        "bleurt": 0.22323
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.763324482612094,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.81667,
            "fmeasure": 0.79463
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.66138,
            "fmeasure": 0.64052
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.81667,
            "fmeasure": 0.79463
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.81667,
            "fmeasure": 0.79463
        },
        "bleu": 59.69492,
        "meteor": 0.875399822034102,
        "bertscore": {
            "precision": 0.9562,
            "recall": 0.96304,
            "f1": 0.95635
        },
        "nubia": {
            "semantic_relation": 4.7524,
            "contradiction": 0.47097,
            "irrelevancy": 34.77542,
            "logical_agreement": 64.7536,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.85489,
            "nubia_score": 0.9587
        },
        "bleurt": 0.67156
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 335,
        "msttr-100": 0.65524,
        "msttr-100_nopunct": 0.65267,
        "total_length": 8246,
        "mean_pred_length": 24.61492537313433,
        "std_pred_length": 3.1057603549679316,
        "median_pred_length": 25.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.11460101867572156,
        "vocab_size-1": 945,
        "unique-1": 465,
        "entropy-1": 7.536095572704574,
        "distinct-2": 0.31765895588421184,
        "vocab_size-2": 2513,
        "unique-2": 1534,
        "entropy-2": 10.05632168140645,
        "cond_entropy-2": 2.5059500018210445,
        "distinct-3": 0.5114836325237593,
        "vocab_size-3": 3875,
        "unique-3": 2814,
        "entropy-3": 11.176795788009542,
        "cond_entropy-3": 1.1391470786649176,
        "total_length-nopunct": 7588,
        "mean_pred_length-nopunct": 22.650746268656718,
        "std_pred_length-nopunct": 2.8797477674749783,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.12295730100158145,
        "vocab_size-1-nopunct": 933,
        "unique-1-nopunct": 463,
        "entropy-1-nopunct": 7.5640317038213025,
        "distinct-2-nopunct": 0.33282779539500895,
        "vocab_size-2-nopunct": 2414,
        "unique-2-nopunct": 1507,
        "entropy-2-nopunct": 10.008574099301399,
        "cond_entropy-2-nopunct": 2.5002685213499287,
        "distinct-3-nopunct": 0.5281873373807459,
        "vocab_size-3-nopunct": 3654,
        "unique-3-nopunct": 2706,
        "entropy-3-nopunct": 11.094628209651752,
        "cond_entropy-3-nopunct": 1.1169994508812358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6510828025477707
        },
        "nist": 6.7601777688756615,
        "rouge1": {
            "precision": 0.74652,
            "recall": 0.67266,
            "fmeasure": 0.70075
        },
        "rouge2": {
            "precision": 0.53263,
            "recall": 0.48129,
            "fmeasure": 0.50049
        },
        "rougeL": {
            "precision": 0.63605,
            "recall": 0.57371,
            "fmeasure": 0.59738
        },
        "rougeLsum": {
            "precision": 0.63605,
            "recall": 0.57371,
            "fmeasure": 0.59738
        },
        "bleu": 38.62569,
        "meteor": 0.3606213149986573,
        "bertscore": {
            "precision": 0.9084,
            "recall": 0.89022,
            "f1": 0.89895
        },
        "nubia": {
            "semantic_relation": 4.29862,
            "contradiction": 1.6649,
            "irrelevancy": 10.69005,
            "logical_agreement": 87.64505,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.48864,
            "nubia_score": 0.75574
        },
        "bleurt": -0.02781
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 1369,
        "msttr-100": 0.72313,
        "msttr-100_nopunct": 0.77224,
        "total_length": 24982,
        "mean_pred_length": 18.24835646457268,
        "std_pred_length": 4.522450999204789,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.25342246417420544,
        "vocab_size-1": 6331,
        "unique-1": 4516,
        "entropy-1": 9.50318682464044,
        "distinct-2": 0.6471858721890484,
        "vocab_size-2": 15282,
        "unique-2": 13164,
        "entropy-2": 13.0991778835124,
        "cond_entropy-2": 3.3388594210686806,
        "distinct-3": 0.8427890667146197,
        "vocab_size-3": 18747,
        "unique-3": 17375,
        "entropy-3": 13.935916514895206,
        "cond_entropy-3": 0.8415916092009321,
        "total_length-nopunct": 21945,
        "mean_pred_length-nopunct": 16.029948867786704,
        "std_pred_length-nopunct": 4.038689090090247,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.28781043517885624,
        "vocab_size-1-nopunct": 6316,
        "unique-1-nopunct": 4515,
        "entropy-1-nopunct": 9.929429510150758,
        "distinct-2-nopunct": 0.682396967340591,
        "vocab_size-2-nopunct": 14041,
        "unique-2-nopunct": 12330,
        "entropy-2-nopunct": 13.021082437379333,
        "cond_entropy-2-nopunct": 3.236594615479012,
        "distinct-3-nopunct": 0.8645285572968189,
        "vocab_size-3-nopunct": 16605,
        "unique-3-nopunct": 15518,
        "entropy-3-nopunct": 13.806221226698456,
        "cond_entropy-3-nopunct": 0.8386510203077845,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2322994652406417,
            "2": 0.4348888345956511,
            "3": 0.7760671375958461
        },
        "nist": 9.862718645631828,
        "rouge1": {
            "precision": 0.76157,
            "recall": 0.73663,
            "fmeasure": 0.73897
        },
        "rouge2": {
            "precision": 0.5284,
            "recall": 0.5132,
            "fmeasure": 0.51347
        },
        "rougeL": {
            "precision": 0.64384,
            "recall": 0.6278,
            "fmeasure": 0.62694
        },
        "rougeLsum": {
            "precision": 0.64384,
            "recall": 0.6278,
            "fmeasure": 0.62694
        },
        "bleu": 47.40799,
        "meteor": 0.3978561686751834,
        "bertscore": {
            "precision": 0.92917,
            "recall": 0.9247,
            "f1": 0.92527
        },
        "nubia": {
            "semantic_relation": 4.17794,
            "contradiction": 10.10189,
            "irrelevancy": 31.79331,
            "logical_agreement": 58.1048,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.41601,
            "nubia_score": 0.7308
        },
        "bleurt": 0.24662
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.762,
        "total_length": 2111,
        "mean_pred_length": 19.91509433962264,
        "std_pred_length": 3.9384843472285365,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.43391757460918995,
        "vocab_size-1": 916,
        "unique-1": 694,
        "entropy-1": 8.374425047484651,
        "distinct-2": 0.854862842892768,
        "vocab_size-2": 1714,
        "unique-2": 1581,
        "entropy-2": 10.533110221026078,
        "cond_entropy-2": 2.0414745128263725,
        "distinct-3": 0.9641916798314902,
        "vocab_size-3": 1831,
        "unique-3": 1783,
        "entropy-3": 10.808213036402183,
        "cond_entropy-3": 0.28572746821423006,
        "total_length-nopunct": 2010,
        "mean_pred_length-nopunct": 18.962264150943398,
        "std_pred_length-nopunct": 4.20450012352418,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4532338308457711,
        "vocab_size-1-nopunct": 911,
        "unique-1-nopunct": 692,
        "entropy-1-nopunct": 8.451789010002395,
        "distinct-2-nopunct": 0.8539915966386554,
        "vocab_size-2-nopunct": 1626,
        "unique-2-nopunct": 1501,
        "entropy-2-nopunct": 10.452000356974532,
        "cond_entropy-2-nopunct": 2.0857914676282934,
        "distinct-3-nopunct": 0.9649610678531702,
        "vocab_size-3-nopunct": 1735,
        "unique-3-nopunct": 1691,
        "entropy-3-nopunct": 10.730695940962537,
        "cond_entropy-3-nopunct": 0.29282372517592975,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2777237354085603
        },
        "nist": 2.504806638732296,
        "rouge1": {
            "precision": 0.32794,
            "recall": 0.3009,
            "fmeasure": 0.3057
        },
        "rouge2": {
            "precision": 0.10372,
            "recall": 0.09349,
            "fmeasure": 0.09631
        },
        "rougeL": {
            "precision": 0.25826,
            "recall": 0.23715,
            "fmeasure": 0.24102
        },
        "rougeLsum": {
            "precision": 0.25826,
            "recall": 0.23715,
            "fmeasure": 0.24102
        },
        "bleu": 6.61173,
        "meteor": 0.12802690647887005,
        "bertscore": {
            "precision": 0.80517,
            "recall": 0.79644,
            "f1": 0.80044
        },
        "nubia": {
            "semantic_relation": 2.37159,
            "contradiction": 24.84773,
            "irrelevancy": 68.54809,
            "logical_agreement": 6.60417,
            "grammar_ref": 3.93729,
            "grammar_hyp": 4.09328,
            "nubia_score": 0.29581
        },
        "bleurt": -0.55972
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74136,
        "msttr-100_nopunct": 0.75112,
        "total_length": 10394,
        "mean_pred_length": 20.788,
        "std_pred_length": 3.321303358622937,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.2819896093900327,
        "vocab_size-1": 2931,
        "unique-1": 1958,
        "entropy-1": 9.067001311010504,
        "distinct-2": 0.727107337780473,
        "vocab_size-2": 7194,
        "unique-2": 6261,
        "entropy-2": 12.290384538808448,
        "cond_entropy-2": 3.119201432748433,
        "distinct-3": 0.9187779433681073,
        "vocab_size-3": 8631,
        "unique-3": 8227,
        "entropy-3": 12.972797228972409,
        "cond_entropy-3": 0.7079958348667893,
        "total_length-nopunct": 9853,
        "mean_pred_length-nopunct": 19.706,
        "std_pred_length-nopunct": 3.499651982697708,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.29645793159443823,
        "vocab_size-1-nopunct": 2921,
        "unique-1-nopunct": 1956,
        "entropy-1-nopunct": 9.167751149495825,
        "distinct-2-nopunct": 0.7313161552443066,
        "vocab_size-2-nopunct": 6840,
        "unique-2-nopunct": 5972,
        "entropy-2-nopunct": 12.217954192493282,
        "cond_entropy-2-nopunct": 3.174914919825038,
        "distinct-3-nopunct": 0.9246583079182198,
        "vocab_size-3-nopunct": 8186,
        "unique-3-nopunct": 7830,
        "entropy-3-nopunct": 12.906414466489021,
        "cond_entropy-3-nopunct": 0.7121016956697508,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3430071315372425
        },
        "nist": 3.4971055753701847,
        "rouge1": {
            "precision": 0.39967,
            "recall": 0.37604,
            "fmeasure": 0.38129
        },
        "rouge2": {
            "precision": 0.14775,
            "recall": 0.13962,
            "fmeasure": 0.14119
        },
        "rougeL": {
            "precision": 0.30892,
            "recall": 0.29128,
            "fmeasure": 0.29504
        },
        "rougeLsum": {
            "precision": 0.30892,
            "recall": 0.29128,
            "fmeasure": 0.29504
        },
        "bleu": 8.84481,
        "meteor": 0.16097655587075482,
        "bertscore": {
            "precision": 0.82518,
            "recall": 0.81704,
            "f1": 0.8208
        },
        "nubia": {
            "semantic_relation": 2.72016,
            "contradiction": 26.00083,
            "irrelevancy": 64.19866,
            "logical_agreement": 9.80051,
            "grammar_ref": 3.74155,
            "grammar_hyp": 3.90321,
            "nubia_score": 0.36245
        },
        "bleurt": -0.42267
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 483,
        "msttr-100": 0.72616,
        "msttr-100_nopunct": 0.7692,
        "total_length": 9913,
        "mean_pred_length": 20.523809523809526,
        "std_pred_length": 4.116440851085924,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 37,
        "distinct-1": 0.31705840815091296,
        "vocab_size-1": 3143,
        "unique-1": 2331,
        "entropy-1": 9.17155611626843,
        "distinct-2": 0.7180275715800636,
        "vocab_size-2": 6771,
        "unique-2": 5872,
        "entropy-2": 12.21125954280812,
        "cond_entropy-2": 2.8735038449797385,
        "distinct-3": 0.8924779255616407,
        "vocab_size-3": 7985,
        "unique-3": 7475,
        "entropy-3": 12.840278266079121,
        "cond_entropy-3": 0.6370055029312043,
        "total_length-nopunct": 8823,
        "mean_pred_length-nopunct": 18.267080745341616,
        "std_pred_length-nopunct": 3.918038810925049,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.3548679587441913,
        "vocab_size-1-nopunct": 3131,
        "unique-1-nopunct": 2329,
        "entropy-1-nopunct": 9.494724854896857,
        "distinct-2-nopunct": 0.7432853717026379,
        "vocab_size-2-nopunct": 6199,
        "unique-2-nopunct": 5483,
        "entropy-2-nopunct": 12.094807305750837,
        "cond_entropy-2-nopunct": 2.706073425656947,
        "distinct-3-nopunct": 0.9037800687285223,
        "vocab_size-3-nopunct": 7101,
        "unique-3-nopunct": 6700,
        "entropy-3-nopunct": 12.6813481612067,
        "cond_entropy-3-nopunct": 0.6210509570929189,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22338568935427575,
            "2": 0.40064516129032257,
            "3": 0.7486865148861647
        },
        "nist": 8.735912558133787,
        "rouge1": {
            "precision": 0.74731,
            "recall": 0.71633,
            "fmeasure": 0.72205
        },
        "rouge2": {
            "precision": 0.49707,
            "recall": 0.47567,
            "fmeasure": 0.47983
        },
        "rougeL": {
            "precision": 0.60442,
            "recall": 0.58002,
            "fmeasure": 0.58397
        },
        "rougeLsum": {
            "precision": 0.60442,
            "recall": 0.58002,
            "fmeasure": 0.58397
        },
        "bleu": 41.24506,
        "meteor": 0.37902234131928136,
        "bertscore": {
            "precision": 0.92033,
            "recall": 0.91492,
            "f1": 0.916
        },
        "nubia": {
            "semantic_relation": 4.08272,
            "contradiction": 11.57856,
            "irrelevancy": 34.27078,
            "logical_agreement": 54.15065,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.27771,
            "nubia_score": 0.70107
        },
        "bleurt": 0.15417
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 379,
        "msttr-100": 0.70704,
        "msttr-100_nopunct": 0.74694,
        "total_length": 8198,
        "mean_pred_length": 21.630606860158313,
        "std_pred_length": 3.786618906779135,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 35,
        "distinct-1": 0.3375213466699195,
        "vocab_size-1": 2767,
        "unique-1": 2033,
        "entropy-1": 9.13589260901307,
        "distinct-2": 0.756490599820949,
        "vocab_size-2": 5915,
        "unique-2": 5185,
        "entropy-2": 12.098591014136797,
        "cond_entropy-2": 2.856751819300699,
        "distinct-3": 0.9220430107526881,
        "vocab_size-3": 6860,
        "unique-3": 6490,
        "entropy-3": 12.670934351146705,
        "cond_entropy-3": 0.5790128683773809,
        "total_length-nopunct": 7276,
        "mean_pred_length-nopunct": 19.19788918205805,
        "std_pred_length-nopunct": 3.6132847492291913,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.37850467289719625,
        "vocab_size-1-nopunct": 2754,
        "unique-1-nopunct": 2032,
        "entropy-1-nopunct": 9.438265378973671,
        "distinct-2-nopunct": 0.7841090329128607,
        "vocab_size-2-nopunct": 5408,
        "unique-2-nopunct": 4831,
        "entropy-2-nopunct": 11.999568858274166,
        "cond_entropy-2-nopunct": 2.6591300735136043,
        "distinct-3-nopunct": 0.9326480515495551,
        "vocab_size-3-nopunct": 6079,
        "unique-3-nopunct": 5803,
        "entropy-3-nopunct": 12.50482657801934,
        "cond_entropy-3-nopunct": 0.530572509435647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24404761904761904,
            "2": 0.4074333800841515,
            "3": 0.7282923299565847
        },
        "nist": 8.206064868386733,
        "rouge1": {
            "precision": 0.75045,
            "recall": 0.69345,
            "fmeasure": 0.71235
        },
        "rouge2": {
            "precision": 0.4873,
            "recall": 0.44848,
            "fmeasure": 0.46142
        },
        "rougeL": {
            "precision": 0.60316,
            "recall": 0.55918,
            "fmeasure": 0.57311
        },
        "rougeLsum": {
            "precision": 0.60316,
            "recall": 0.55918,
            "fmeasure": 0.57311
        },
        "bleu": 38.51064,
        "meteor": 0.3552717603100722,
        "bertscore": {
            "precision": 0.91862,
            "recall": 0.90698,
            "f1": 0.91124
        },
        "nubia": {
            "semantic_relation": 3.96711,
            "contradiction": 12.74391,
            "irrelevancy": 29.91962,
            "logical_agreement": 57.33647,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.27053,
            "nubia_score": 0.66712
        },
        "bleurt": 0.1094
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "msttr-100": 0.74349,
        "msttr-100_nopunct": 0.78304,
        "total_length": 6378,
        "mean_pred_length": 17.766016713091922,
        "std_pred_length": 6.048629625388265,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.38664158043273755,
        "vocab_size-1": 2466,
        "unique-1": 1880,
        "entropy-1": 9.160741375442807,
        "distinct-2": 0.8381790995181924,
        "vocab_size-2": 5045,
        "unique-2": 4705,
        "entropy-2": 11.961681313311333,
        "cond_entropy-2": 2.6087780674923544,
        "distinct-3": 0.9588339222614841,
        "vocab_size-3": 5427,
        "unique-3": 5339,
        "entropy-3": 12.308245849926317,
        "cond_entropy-3": 0.36782450137191625,
        "total_length-nopunct": 5674,
        "mean_pred_length-nopunct": 15.805013927576601,
        "std_pred_length-nopunct": 5.506732009386725,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.43267536129714484,
        "vocab_size-1-nopunct": 2455,
        "unique-1-nopunct": 1879,
        "entropy-1-nopunct": 9.476206587084707,
        "distinct-2-nopunct": 0.871307619943556,
        "vocab_size-2-nopunct": 4631,
        "unique-2-nopunct": 4354,
        "entropy-2-nopunct": 11.949243476556491,
        "cond_entropy-2-nopunct": 2.6031034010419156,
        "distinct-3-nopunct": 0.9828490718321227,
        "vocab_size-3-nopunct": 4871,
        "unique-3-nopunct": 4806,
        "entropy-3-nopunct": 12.236871659395746,
        "cond_entropy-3-nopunct": 0.3092189832078117,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "local_recall": {
            "1": 0.04584040747028863,
            "2": 0.1558109833971903,
            "3": 0.30196936542669583,
            "4": 0.4183835182250396,
            "5": 0.49117341640706125,
            "6": 0.6056763285024155,
            "7": 0.738831615120275
        },
        "nist": 8.453450618453354,
        "rouge1": {
            "precision": 0.76078,
            "recall": 0.67508,
            "fmeasure": 0.69995
        },
        "rouge2": {
            "precision": 0.57984,
            "recall": 0.50742,
            "fmeasure": 0.52781
        },
        "rougeL": {
            "precision": 0.73389,
            "recall": 0.64883,
            "fmeasure": 0.67386
        },
        "rougeLsum": {
            "precision": 0.73389,
            "recall": 0.64883,
            "fmeasure": 0.67386
        },
        "bleu": 50.28956,
        "sari": 45.34907,
        "meteor": 0.35468684385039617,
        "bertscore": {
            "precision": 0.90965,
            "recall": 0.90877,
            "f1": 0.90575
        },
        "nubia": {
            "semantic_relation": 3.87719,
            "contradiction": 8.04995,
            "irrelevancy": 20.3949,
            "logical_agreement": 71.55516,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.56888,
            "nubia_score": 0.52685
        },
        "bleurt": -0.29756
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 256,
        "msttr-100": 0.63823,
        "msttr-100_nopunct": 0.64,
        "total_length": 6294,
        "mean_pred_length": 24.5859375,
        "std_pred_length": 3.253669427906552,
        "median_pred_length": 25.0,
        "min_pred_length": 14,
        "max_pred_length": 32,
        "distinct-1": 0.09183349221480776,
        "vocab_size-1": 578,
        "unique-1": 238,
        "entropy-1": 7.172759519137589,
        "distinct-2": 0.2866843325604505,
        "vocab_size-2": 1731,
        "unique-2": 956,
        "entropy-2": 9.608955599600762,
        "cond_entropy-2": 2.45746723624884,
        "distinct-3": 0.4975786924939467,
        "vocab_size-3": 2877,
        "unique-3": 2015,
        "entropy-3": 10.789317384040363,
        "cond_entropy-3": 1.228436289087742,
        "total_length-nopunct": 5852,
        "mean_pred_length-nopunct": 22.859375,
        "std_pred_length-nopunct": 3.0419832526453856,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.09723171565276828,
        "vocab_size-1-nopunct": 569,
        "unique-1-nopunct": 235,
        "entropy-1-nopunct": 7.168247602210172,
        "distinct-2-nopunct": 0.2952108649035025,
        "vocab_size-2-nopunct": 1652,
        "unique-2-nopunct": 922,
        "entropy-2-nopunct": 9.548946277308444,
        "cond_entropy-2-nopunct": 2.4602507787605123,
        "distinct-3-nopunct": 0.5041198501872659,
        "vocab_size-3-nopunct": 2692,
        "unique-3-nopunct": 1909,
        "entropy-3-nopunct": 10.689340535044725,
        "cond_entropy-3-nopunct": 1.2060192805776928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5611094630673391
        },
        "nist": 4.866677554452594,
        "rouge1": {
            "precision": 0.71276,
            "recall": 0.56748,
            "fmeasure": 0.62342
        },
        "rouge2": {
            "precision": 0.46368,
            "recall": 0.3699,
            "fmeasure": 0.40565
        },
        "rougeL": {
            "precision": 0.59721,
            "recall": 0.47701,
            "fmeasure": 0.52312
        },
        "rougeLsum": {
            "precision": 0.59721,
            "recall": 0.47701,
            "fmeasure": 0.52312
        },
        "bleu": 28.24902,
        "meteor": 0.3021399568248691,
        "bertscore": {
            "precision": 0.89653,
            "recall": 0.86679,
            "f1": 0.88109
        },
        "nubia": {
            "semantic_relation": 3.75044,
            "contradiction": 3.39649,
            "irrelevancy": 14.30249,
            "logical_agreement": 82.30102,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.32292,
            "nubia_score": 0.58094
        },
        "bleurt": -0.16157
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 46,
        "msttr-100": 0.56273,
        "msttr-100_nopunct": 0.562,
        "total_length": 1123,
        "mean_pred_length": 24.41304347826087,
        "std_pred_length": 3.5051272194025427,
        "median_pred_length": 25.0,
        "min_pred_length": 16,
        "max_pred_length": 33,
        "distinct-1": 0.163846838824577,
        "vocab_size-1": 184,
        "unique-1": 73,
        "entropy-1": 6.376473636797292,
        "distinct-2": 0.4373259052924791,
        "vocab_size-2": 471,
        "unique-2": 265,
        "entropy-2": 8.296002874246394,
        "cond_entropy-2": 1.9282757515361286,
        "distinct-3": 0.6556741028128031,
        "vocab_size-3": 676,
        "unique-3": 489,
        "entropy-3": 9.132411031867218,
        "cond_entropy-3": 0.8700776598825775,
        "total_length-nopunct": 1069,
        "mean_pred_length-nopunct": 23.23913043478261,
        "std_pred_length-nopunct": 3.258332346253056,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.16838166510757718,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.324524978862968,
        "distinct-2-nopunct": 0.4389051808406647,
        "vocab_size-2-nopunct": 449,
        "unique-2-nopunct": 257,
        "entropy-2-nopunct": 8.21621075898962,
        "cond_entropy-2-nopunct": 1.9167016333628788,
        "distinct-3-nopunct": 0.654042988741044,
        "vocab_size-3-nopunct": 639,
        "unique-3-nopunct": 468,
        "entropy-3-nopunct": 9.040999402816425,
        "cond_entropy-3-nopunct": 0.8585645738766022,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.573905862923204
        },
        "nist": 4.346187048832349,
        "rouge1": {
            "precision": 0.70058,
            "recall": 0.60058,
            "fmeasure": 0.63114
        },
        "rouge2": {
            "precision": 0.44712,
            "recall": 0.3904,
            "fmeasure": 0.40664
        },
        "rougeL": {
            "precision": 0.56864,
            "recall": 0.48728,
            "fmeasure": 0.51222
        },
        "rougeLsum": {
            "precision": 0.56864,
            "recall": 0.48728,
            "fmeasure": 0.51222
        },
        "bleu": 29.67243,
        "meteor": 0.2912901664274396,
        "bertscore": {
            "precision": 0.89718,
            "recall": 0.87332,
            "f1": 0.88453
        },
        "nubia": {
            "semantic_relation": 3.77752,
            "contradiction": 44.05442,
            "irrelevancy": 10.17816,
            "logical_agreement": 45.76742,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.70776,
            "nubia_score": 0.54584
        },
        "bleurt": -0.22133
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 1187,
        "msttr-100": 0.28541,
        "msttr-100_nopunct": 0.2796,
        "total_length": 26648,
        "mean_pred_length": 22.44987363100253,
        "std_pred_length": 2.966787153815446,
        "median_pred_length": 23.0,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.010544881416991895,
        "vocab_size-1": 281,
        "unique-1": 50,
        "entropy-1": 5.924326556292038,
        "distinct-2": 0.040414751973606694,
        "vocab_size-2": 1029,
        "unique-2": 289,
        "entropy-2": 7.767927756601391,
        "cond_entropy-2": 1.8804025337383743,
        "distinct-3": 0.07934415423910357,
        "vocab_size-3": 1926,
        "unique-3": 633,
        "entropy-3": 8.918171268870397,
        "cond_entropy-3": 1.2238845016979727,
        "total_length-nopunct": 25036,
        "mean_pred_length-nopunct": 21.091828138163436,
        "std_pred_length-nopunct": 2.9632672166468104,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.01106406774245087,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.926392206318894,
        "distinct-2-nopunct": 0.0411757306386012,
        "vocab_size-2-nopunct": 982,
        "unique-2-nopunct": 277,
        "entropy-2-nopunct": 7.727073665949549,
        "cond_entropy-2-nopunct": 1.9053905962039037,
        "distinct-3-nopunct": 0.08141382049245433,
        "vocab_size-3-nopunct": 1845,
        "unique-3-nopunct": 594,
        "entropy-3-nopunct": 8.92477947476717,
        "cond_entropy-3-nopunct": 1.2475548503619478,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6880869162420516
        },
        "nist": 4.811895769944817,
        "rouge1": {
            "precision": 0.72591,
            "recall": 0.70111,
            "fmeasure": 0.70337
        },
        "rouge2": {
            "precision": 0.41506,
            "recall": 0.4003,
            "fmeasure": 0.40158
        },
        "rougeL": {
            "precision": 0.50727,
            "recall": 0.4903,
            "fmeasure": 0.4917
        },
        "rougeLsum": {
            "precision": 0.50727,
            "recall": 0.4903,
            "fmeasure": 0.4917
        },
        "bleu": 27.74703,
        "meteor": 0.3466526693777804,
        "bertscore": {
            "precision": 0.90908,
            "recall": 0.90078,
            "f1": 0.90458
        },
        "nubia": {
            "semantic_relation": 4.16285,
            "contradiction": 2.44611,
            "irrelevancy": 28.43098,
            "logical_agreement": 69.12291,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.75927,
            "nubia_score": 0.72126
        },
        "bleurt": 0.05321
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.73846,
        "msttr-100_nopunct": 0.7497,
        "total_length": 10446,
        "mean_pred_length": 20.892,
        "std_pred_length": 3.2906437060247042,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.2822132873827302,
        "vocab_size-1": 2948,
        "unique-1": 1975,
        "entropy-1": 9.087257576254178,
        "distinct-2": 0.7280313693947316,
        "vocab_size-2": 7241,
        "unique-2": 6297,
        "entropy-2": 12.299677065243346,
        "cond_entropy-2": 3.1023293836952774,
        "distinct-3": 0.9178488248994283,
        "vocab_size-3": 8670,
        "unique-3": 8244,
        "entropy-3": 12.982635678586902,
        "cond_entropy-3": 0.7042167066338554,
        "total_length-nopunct": 9912,
        "mean_pred_length-nopunct": 19.824,
        "std_pred_length-nopunct": 3.4183364375087484,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.29640839386602097,
        "vocab_size-1-nopunct": 2938,
        "unique-1-nopunct": 1974,
        "entropy-1-nopunct": 9.185600013859226,
        "distinct-2-nopunct": 0.7321504462388441,
        "vocab_size-2-nopunct": 6891,
        "unique-2-nopunct": 6017,
        "entropy-2-nopunct": 12.226778977225374,
        "cond_entropy-2-nopunct": 3.161091161951068,
        "distinct-3-nopunct": 0.9222396768402155,
        "vocab_size-3-nopunct": 8219,
        "unique-3-nopunct": 7838,
        "entropy-3-nopunct": 12.911272330034333,
        "cond_entropy-3-nopunct": 0.7105024965577978,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.34109916367980886
        },
        "nist": 3.5074263880976364,
        "rouge1": {
            "precision": 0.39285,
            "recall": 0.37162,
            "fmeasure": 0.37537
        },
        "rouge2": {
            "precision": 0.14488,
            "recall": 0.13712,
            "fmeasure": 0.13845
        },
        "rougeL": {
            "precision": 0.30484,
            "recall": 0.28788,
            "fmeasure": 0.29105
        },
        "rougeLsum": {
            "precision": 0.30484,
            "recall": 0.28788,
            "fmeasure": 0.29105
        },
        "bleu": 9.0633,
        "meteor": 0.16227243060260402,
        "bertscore": {
            "precision": 0.82562,
            "recall": 0.81795,
            "f1": 0.82143
        },
        "nubia": {
            "semantic_relation": 2.76189,
            "contradiction": 25.59537,
            "irrelevancy": 63.30262,
            "logical_agreement": 11.10201,
            "grammar_ref": 3.79385,
            "grammar_hyp": 3.93729,
            "nubia_score": 0.37204
        },
        "bleurt": -0.42206
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.74788,
        "msttr-100_nopunct": 0.75707,
        "total_length": 10478,
        "mean_pred_length": 20.956,
        "std_pred_length": 3.4470369884873584,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.2776293185722466,
        "vocab_size-1": 2909,
        "unique-1": 1894,
        "entropy-1": 9.111305799987694,
        "distinct-2": 0.7329124072960513,
        "vocab_size-2": 7313,
        "unique-2": 6359,
        "entropy-2": 12.34146695986379,
        "cond_entropy-2": 3.12918417454368,
        "distinct-3": 0.9240346064570585,
        "vocab_size-3": 8758,
        "unique-3": 8350,
        "entropy-3": 13.00976066945469,
        "cond_entropy-3": 0.6876188573627392,
        "total_length-nopunct": 9968,
        "mean_pred_length-nopunct": 19.936,
        "std_pred_length-nopunct": 3.6463548922177065,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.2909309791332263,
        "vocab_size-1-nopunct": 2900,
        "unique-1-nopunct": 1893,
        "entropy-1-nopunct": 9.206592237118201,
        "distinct-2-nopunct": 0.7374313476975074,
        "vocab_size-2-nopunct": 6982,
        "unique-2-nopunct": 6093,
        "entropy-2-nopunct": 12.277495994432815,
        "cond_entropy-2-nopunct": 3.1853793248944067,
        "distinct-3-nopunct": 0.9287466547725245,
        "vocab_size-3-nopunct": 8329,
        "unique-3-nopunct": 7961,
        "entropy-3-nopunct": 12.944440194915861,
        "cond_entropy-3-nopunct": 0.6879070000409491,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3455202892728003
        },
        "nist": 3.5220253671288613,
        "rouge1": {
            "precision": 0.39402,
            "recall": 0.37726,
            "fmeasure": 0.37829
        },
        "rouge2": {
            "precision": 0.14862,
            "recall": 0.142,
            "fmeasure": 0.14247
        },
        "rougeL": {
            "precision": 0.30828,
            "recall": 0.29395,
            "fmeasure": 0.29544
        },
        "rougeLsum": {
            "precision": 0.30828,
            "recall": 0.29395,
            "fmeasure": 0.29544
        },
        "bleu": 9.27044,
        "meteor": 0.16205608842218513,
        "bertscore": {
            "precision": 0.82512,
            "recall": 0.81787,
            "f1": 0.82117
        },
        "nubia": {
            "semantic_relation": 2.73603,
            "contradiction": 23.83695,
            "irrelevancy": 65.93993,
            "logical_agreement": 10.22312,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.98356,
            "nubia_score": 0.3632
        },
        "bleurt": -0.42872
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.77462,
        "msttr-100_nopunct": 0.83682,
        "total_length": 2664,
        "mean_pred_length": 12.448598130841122,
        "std_pred_length": 2.4788211128536917,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.3791291291291291,
        "vocab_size-1": 1010,
        "unique-1": 659,
        "entropy-1": 8.552669053539338,
        "distinct-2": 0.7097959183673469,
        "vocab_size-2": 1739,
        "unique-2": 1394,
        "entropy-2": 10.45989916829354,
        "cond_entropy-2": 2.0639811013916343,
        "distinct-3": 0.8573345259391771,
        "vocab_size-3": 1917,
        "unique-3": 1683,
        "entropy-3": 10.80655946363992,
        "cond_entropy-3": 0.40428739170104655,
        "total_length-nopunct": 2290,
        "mean_pred_length-nopunct": 10.700934579439252,
        "std_pred_length-nopunct": 2.0311359248590084,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.43799126637554586,
        "vocab_size-1-nopunct": 1003,
        "unique-1-nopunct": 657,
        "entropy-1-nopunct": 8.955965722426143,
        "distinct-2-nopunct": 0.75626204238921,
        "vocab_size-2-nopunct": 1570,
        "unique-2-nopunct": 1300,
        "entropy-2-nopunct": 10.380043534884013,
        "cond_entropy-2-nopunct": 1.5679100556205057,
        "distinct-3-nopunct": 0.8754027926960258,
        "vocab_size-3-nopunct": 1630,
        "unique-3-nopunct": 1460,
        "entropy-3-nopunct": 10.5822771518388,
        "cond_entropy-3-nopunct": 0.25895561416480084,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13554555680539931,
            "2": 0.29867256637168144,
            "3": 0.4197802197802198
        },
        "nist": 0.4975751826911632,
        "rouge1": {
            "precision": 0.25903,
            "recall": 0.18016,
            "fmeasure": 0.20162
        },
        "rouge2": {
            "precision": 0.09566,
            "recall": 0.06425,
            "fmeasure": 0.07176
        },
        "rougeL": {
            "precision": 0.24486,
            "recall": 0.16874,
            "fmeasure": 0.18918
        },
        "rougeLsum": {
            "precision": 0.24486,
            "recall": 0.16874,
            "fmeasure": 0.18918
        },
        "bleu": 13.68172,
        "meteor": 0.30855460015345115,
        "bertscore": {
            "precision": 0.94046,
            "recall": 0.88467,
            "f1": 0.91104
        },
        "nubia": {
            "semantic_relation": 3.33599,
            "contradiction": 22.74519,
            "irrelevancy": 22.80472,
            "logical_agreement": 54.4501,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.64501,
            "nubia_score": 0.62088
        },
        "bleurt": -0.04245
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.78462,
        "msttr-100_nopunct": 0.83864,
        "total_length": 2649,
        "mean_pred_length": 12.378504672897197,
        "std_pred_length": 2.541562108411428,
        "median_pred_length": 12.5,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.38995847489618723,
        "vocab_size-1": 1033,
        "unique-1": 665,
        "entropy-1": 8.620994703749616,
        "distinct-2": 0.7248459958932238,
        "vocab_size-2": 1765,
        "unique-2": 1400,
        "entropy-2": 10.515534429737187,
        "cond_entropy-2": 2.016561704002577,
        "distinct-3": 0.8779828905898244,
        "vocab_size-3": 1950,
        "unique-3": 1733,
        "entropy-3": 10.851113025567761,
        "cond_entropy-3": 0.3816223163260992,
        "total_length-nopunct": 2297,
        "mean_pred_length-nopunct": 10.733644859813085,
        "std_pred_length-nopunct": 2.187280303530368,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.44710491946016545,
        "vocab_size-1-nopunct": 1027,
        "unique-1-nopunct": 664,
        "entropy-1-nopunct": 9.012267844375515,
        "distinct-2-nopunct": 0.7681228996639462,
        "vocab_size-2-nopunct": 1600,
        "unique-2-nopunct": 1321,
        "entropy-2-nopunct": 10.43023879590118,
        "cond_entropy-2-nopunct": 1.5358514728336055,
        "distinct-3-nopunct": 0.898876404494382,
        "vocab_size-3-nopunct": 1680,
        "unique-3-nopunct": 1532,
        "entropy-3-nopunct": 10.645880326441148,
        "cond_entropy-3-nopunct": 0.2640126887635718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.157369782046546,
            "2": 0.38968915845337376,
            "3": 0.5618374558303887,
            "4": 0.3181818181818182
        },
        "nist": 2.744964554016702,
        "rouge1": {
            "precision": 0.27603,
            "recall": 0.2202,
            "fmeasure": 0.23719
        },
        "rouge2": {
            "precision": 0.11604,
            "recall": 0.0809,
            "fmeasure": 0.09348
        },
        "rougeL": {
            "precision": 0.27393,
            "recall": 0.21857,
            "fmeasure": 0.23536
        },
        "rougeLsum": {
            "precision": 0.27393,
            "recall": 0.21857,
            "fmeasure": 0.23536
        },
        "bleu": 24.67575,
        "meteor": 0.4107634809912822,
        "bertscore": {
            "precision": 0.9456,
            "recall": 0.9076,
            "f1": 0.92547
        },
        "nubia": {
            "semantic_relation": 3.46627,
            "contradiction": 23.57399,
            "irrelevancy": 23.5383,
            "logical_agreement": 52.8877,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.66644,
            "nubia_score": 0.67405
        },
        "bleurt": -0.00134
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "msttr-100": 0.75677,
        "msttr-100_nopunct": 0.79411,
        "total_length": 6294,
        "mean_pred_length": 17.532033426183844,
        "std_pred_length": 6.136647668857653,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.42357801080394025,
        "vocab_size-1": 2666,
        "unique-1": 2147,
        "entropy-1": 9.31374697332768,
        "distinct-2": 0.858972198820556,
        "vocab_size-2": 5098,
        "unique-2": 4814,
        "entropy-2": 12.025868069116147,
        "cond_entropy-2": 2.521197089628982,
        "distinct-3": 0.9695121951219512,
        "vocab_size-3": 5406,
        "unique-3": 5336,
        "entropy-3": 12.332478182478413,
        "cond_entropy-3": 0.32076026876529357,
        "total_length-nopunct": 5600,
        "mean_pred_length-nopunct": 15.598885793871867,
        "std_pred_length-nopunct": 5.617382382477457,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4739285714285714,
        "vocab_size-1-nopunct": 2654,
        "unique-1-nopunct": 2145,
        "entropy-1-nopunct": 9.644731126584361,
        "distinct-2-nopunct": 0.8889524899828277,
        "vocab_size-2-nopunct": 4659,
        "unique-2-nopunct": 4433,
        "entropy-2-nopunct": 11.978754476301583,
        "cond_entropy-2-nopunct": 2.4653721826544577,
        "distinct-3-nopunct": 0.9881196231052847,
        "vocab_size-3-nopunct": 4824,
        "unique-3-nopunct": 4774,
        "entropy-3-nopunct": 12.227882900350009,
        "cond_entropy-3-nopunct": 0.26761506235520527,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "local_recall": {
            "1": 0.03968590831918506,
            "2": 0.13537675606641125,
            "3": 0.2844638949671772,
            "4": 0.40729001584786056,
            "5": 0.43613707165109034,
            "6": 0.5446859903381642,
            "7": 0.6914852997327224
        },
        "nist": 7.63686017126765,
        "rouge1": {
            "precision": 0.71646,
            "recall": 0.63057,
            "fmeasure": 0.65543
        },
        "rouge2": {
            "precision": 0.5131,
            "recall": 0.44835,
            "fmeasure": 0.46613
        },
        "rougeL": {
            "precision": 0.69115,
            "recall": 0.60784,
            "fmeasure": 0.63135
        },
        "rougeLsum": {
            "precision": 0.69115,
            "recall": 0.60784,
            "fmeasure": 0.63135
        },
        "bleu": 43.78966,
        "sari": 46.62182,
        "meteor": 0.31975666460496704,
        "bertscore": {
            "precision": 0.88235,
            "recall": 0.89299,
            "f1": 0.88457
        },
        "nubia": {
            "semantic_relation": 3.71956,
            "contradiction": 9.7875,
            "irrelevancy": 20.3961,
            "logical_agreement": 69.8164,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.10095,
            "nubia_score": 0.44837
        },
        "bleurt": -0.59916
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "msttr-100": 0.7354,
        "msttr-100_nopunct": 0.77179,
        "total_length": 6339,
        "mean_pred_length": 17.657381615598887,
        "std_pred_length": 6.291626379831737,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.3647262975232686,
        "vocab_size-1": 2312,
        "unique-1": 1694,
        "entropy-1": 9.060958196522957,
        "distinct-2": 0.822742474916388,
        "vocab_size-2": 4920,
        "unique-2": 4563,
        "entropy-2": 11.879305327483854,
        "cond_entropy-2": 2.6449646691065314,
        "distinct-3": 0.9487635652019214,
        "vocab_size-3": 5333,
        "unique-3": 5229,
        "entropy-3": 12.252080782873199,
        "cond_entropy-3": 0.3976839926477428,
        "total_length-nopunct": 5625,
        "mean_pred_length-nopunct": 15.668523676880223,
        "std_pred_length-nopunct": 5.631080265045888,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4090666666666667,
        "vocab_size-1-nopunct": 2301,
        "unique-1-nopunct": 1693,
        "entropy-1-nopunct": 9.366983315518093,
        "distinct-2-nopunct": 0.8571971135586783,
        "vocab_size-2-nopunct": 4514,
        "unique-2-nopunct": 4208,
        "entropy-2-nopunct": 11.89004168996225,
        "cond_entropy-2-nopunct": 2.6626034193343036,
        "distinct-3-nopunct": 0.9761565111065824,
        "vocab_size-3-nopunct": 4790,
        "unique-3-nopunct": 4706,
        "entropy-3-nopunct": 12.205824838428692,
        "cond_entropy-3-nopunct": 0.33699149405036855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "local_recall": {
            "1": 0.0432937181663837,
            "2": 0.1583652618135377,
            "3": 0.33260393873085337,
            "4": 0.42630744849445323,
            "5": 0.5160955347871236,
            "6": 0.6467391304347826,
            "7": 0.803741886216113
        },
        "nist": 9.266448171622997,
        "rouge1": {
            "precision": 0.82416,
            "recall": 0.72399,
            "fmeasure": 0.75745
        },
        "rouge2": {
            "precision": 0.66979,
            "recall": 0.58772,
            "fmeasure": 0.6136
        },
        "rougeL": {
            "precision": 0.79545,
            "recall": 0.70048,
            "fmeasure": 0.73168
        },
        "rougeLsum": {
            "precision": 0.79545,
            "recall": 0.70048,
            "fmeasure": 0.73168
        },
        "bleu": 60.07373,
        "sari": 44.25402,
        "meteor": 0.40113618603440737,
        "bertscore": {
            "precision": 0.94151,
            "recall": 0.92592,
            "f1": 0.93049
        },
        "nubia": {
            "semantic_relation": 4.05183,
            "contradiction": 5.58465,
            "irrelevancy": 19.01702,
            "logical_agreement": 75.39832,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.00482,
            "nubia_score": 0.62896
        },
        "bleurt": 0.05384
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 1397,
        "msttr-100": 0.64044,
        "msttr-100_nopunct": 0.64004,
        "total_length": 27191,
        "mean_pred_length": 19.4638511095204,
        "std_pred_length": 5.273848209110212,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.0656099444669192,
        "vocab_size-1": 1784,
        "unique-1": 847,
        "entropy-1": 7.549572114447174,
        "distinct-2": 0.2187330386911685,
        "vocab_size-2": 5642,
        "unique-2": 3417,
        "entropy-2": 10.375122133665087,
        "cond_entropy-2": 2.7558125795309394,
        "distinct-3": 0.4005820387752593,
        "vocab_size-3": 9773,
        "unique-3": 7062,
        "entropy-3": 11.859156204977307,
        "cond_entropy-3": 1.5194815886822648,
        "total_length-nopunct": 24733,
        "mean_pred_length-nopunct": 17.70436649964209,
        "std_pred_length-nopunct": 5.104414651705341,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.07156430679658755,
        "vocab_size-1-nopunct": 1770,
        "unique-1-nopunct": 844,
        "entropy-1-nopunct": 7.599868489241989,
        "distinct-2-nopunct": 0.23178779568049365,
        "vocab_size-2-nopunct": 5409,
        "unique-2-nopunct": 3336,
        "entropy-2-nopunct": 10.329254508934431,
        "cond_entropy-2-nopunct": 2.813247632214094,
        "distinct-3-nopunct": 0.4194812890286704,
        "vocab_size-3-nopunct": 9203,
        "unique-3-nopunct": 6754,
        "entropy-3-nopunct": 11.807916172791495,
        "cond_entropy-3-nopunct": 1.5240625057680393,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6287921919479463
        },
        "nist": 6.742454719310356,
        "rouge1": {
            "precision": 0.66634,
            "recall": 0.64273,
            "fmeasure": 0.64216
        },
        "rouge2": {
            "precision": 0.44987,
            "recall": 0.43483,
            "fmeasure": 0.43375
        },
        "rougeL": {
            "precision": 0.57661,
            "recall": 0.55803,
            "fmeasure": 0.55668
        },
        "rougeLsum": {
            "precision": 0.57661,
            "recall": 0.55803,
            "fmeasure": 0.55668
        },
        "bleu": 35.29721,
        "meteor": 0.337696159679253,
        "bertscore": {
            "precision": 0.88355,
            "recall": 0.8792,
            "f1": 0.88093
        },
        "nubia": {
            "semantic_relation": 4.08629,
            "contradiction": 4.92063,
            "irrelevancy": 20.23727,
            "logical_agreement": 74.84209,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.90775,
            "nubia_score": 0.68949
        },
        "bleurt": -0.06819
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 1406,
        "msttr-100": 0.3064,
        "msttr-100_nopunct": 0.29748,
        "total_length": 33689,
        "mean_pred_length": 23.960881934566146,
        "std_pred_length": 2.241603347256244,
        "median_pred_length": 24.0,
        "min_pred_length": 17,
        "max_pred_length": 31,
        "distinct-1": 0.009142450057882395,
        "vocab_size-1": 308,
        "unique-1": 36,
        "entropy-1": 5.952870225219081,
        "distinct-2": 0.037233218721927946,
        "vocab_size-2": 1202,
        "unique-2": 213,
        "entropy-2": 8.018068045057115,
        "cond_entropy-2": 2.1503833042829967,
        "distinct-3": 0.07860219580917835,
        "vocab_size-3": 2427,
        "unique-3": 547,
        "entropy-3": 9.350968186611434,
        "cond_entropy-3": 1.433555633782677,
        "total_length-nopunct": 31790,
        "mean_pred_length-nopunct": 22.610241820768138,
        "std_pred_length-nopunct": 2.257343401054692,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.009594212016357346,
        "vocab_size-1-nopunct": 305,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.939315486239108,
        "distinct-2-nopunct": 0.03919826224328594,
        "vocab_size-2-nopunct": 1191,
        "unique-2-nopunct": 215,
        "entropy-2-nopunct": 8.011736130145065,
        "cond_entropy-2-nopunct": 2.1907992954051405,
        "distinct-3-nopunct": 0.08220028987507765,
        "vocab_size-3-nopunct": 2382,
        "unique-3-nopunct": 547,
        "entropy-3-nopunct": 9.373021301626117,
        "cond_entropy-3-nopunct": 1.4528663405299498,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6396002308697105
        },
        "nist": 4.417387105625663,
        "rouge1": {
            "precision": 0.76241,
            "recall": 0.65678,
            "fmeasure": 0.69894
        },
        "rouge2": {
            "precision": 0.44104,
            "recall": 0.37905,
            "fmeasure": 0.40364
        },
        "rougeL": {
            "precision": 0.51926,
            "recall": 0.44833,
            "fmeasure": 0.4766
        },
        "rougeLsum": {
            "precision": 0.51926,
            "recall": 0.44833,
            "fmeasure": 0.4766
        },
        "bleu": 25.18564,
        "meteor": 0.3274201346157444,
        "bertscore": {
            "precision": 0.91272,
            "recall": 0.88967,
            "f1": 0.90084
        },
        "nubia": {
            "semantic_relation": 4.16477,
            "contradiction": 2.79425,
            "irrelevancy": 11.80697,
            "logical_agreement": 85.39877,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.7609,
            "nubia_score": 0.69765
        },
        "bleurt": 0.00913
    },
    "cs_restaurants_validation": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_validation",
        "N": 781,
        "msttr-100": 0.62222,
        "msttr-100_nopunct": 0.65929,
        "total_length": 8122,
        "mean_pred_length": 10.399487836107554,
        "std_pred_length": 4.145151247784516,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 22,
        "distinct-1": 0.060453090371829596,
        "vocab_size-1": 491,
        "unique-1": 145,
        "entropy-1": 7.026065756137629,
        "distinct-2": 0.21264132951913908,
        "vocab_size-2": 1561,
        "unique-2": 730,
        "entropy-2": 9.39477934918171,
        "cond_entropy-2": 2.0638491138755835,
        "distinct-3": 0.36051829268292684,
        "vocab_size-3": 2365,
        "unique-3": 1381,
        "entropy-3": 10.285797126765079,
        "cond_entropy-3": 0.8085757223770365,
        "total_length-nopunct": 7017,
        "mean_pred_length-nopunct": 8.984635083226632,
        "std_pred_length-nopunct": 3.73580379416193,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.06940287872310104,
        "vocab_size-1-nopunct": 487,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 7.240774084587025,
        "distinct-2-nopunct": 0.22883258499037845,
        "vocab_size-2-nopunct": 1427,
        "unique-2-nopunct": 698,
        "entropy-2-nopunct": 9.303070050367895,
        "cond_entropy-2-nopunct": 2.0722330695430093,
        "distinct-3-nopunct": 0.3869844179651696,
        "vocab_size-3-nopunct": 2111,
        "unique-3-nopunct": 1280,
        "entropy-3-nopunct": 10.180977150666845,
        "cond_entropy-3-nopunct": 0.8158542893634336,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_validation.json",
        "local_recall": {
            "1": 0.3946745562130177
        },
        "nist": 3.3348136512929836,
        "rouge1": {
            "precision": 0.42355,
            "recall": 0.44516,
            "fmeasure": 0.41816
        },
        "rouge2": {
            "precision": 0.23645,
            "recall": 0.25622,
            "fmeasure": 0.23516
        },
        "rougeL": {
            "precision": 0.38006,
            "recall": 0.40252,
            "fmeasure": 0.37652
        },
        "rougeLsum": {
            "precision": 0.38006,
            "recall": 0.40252,
            "fmeasure": 0.37652
        },
        "bleu": 13.28659,
        "meteor": 0.2021392199817205,
        "bertscore": {
            "precision": 0.88584,
            "recall": 0.88429,
            "f1": 0.88482
        },
        "nubia": {
            "semantic_relation": 2.96245,
            "contradiction": 23.70006,
            "irrelevancy": 33.37396,
            "logical_agreement": 42.92598,
            "grammar_ref": 6.54085,
            "grammar_hyp": 6.44514,
            "nubia_score": 0.39141
        },
        "bleurt": -0.24513
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 983,
        "msttr-100": 0.25109,
        "msttr-100_nopunct": 0.25227,
        "total_length": 5543,
        "mean_pred_length": 5.638860630722279,
        "std_pred_length": 1.7343385885348297,
        "median_pred_length": 5.0,
        "min_pred_length": 2,
        "max_pred_length": 16,
        "distinct-1": 0.021829334295507846,
        "vocab_size-1": 121,
        "unique-1": 34,
        "entropy-1": 4.237887718238058,
        "distinct-2": 0.06162280701754386,
        "vocab_size-2": 281,
        "unique-2": 124,
        "entropy-2": 5.264145292265693,
        "cond_entropy-2": 0.878021664606088,
        "distinct-3": 0.10455689124965055,
        "vocab_size-3": 374,
        "unique-3": 186,
        "entropy-3": 6.167826579820528,
        "cond_entropy-3": 0.7787567002890724,
        "total_length-nopunct": 4466,
        "mean_pred_length-nopunct": 4.54323499491353,
        "std_pred_length-nopunct": 1.4263586490227802,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.025974025974025976,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.062813099996431,
        "distinct-2-nopunct": 0.06373815676141258,
        "vocab_size-2-nopunct": 222,
        "unique-2-nopunct": 100,
        "entropy-2-nopunct": 4.929341643548797,
        "cond_entropy-2-nopunct": 0.7543815390996017,
        "distinct-3-nopunct": 0.10315873650539784,
        "vocab_size-3-nopunct": 258,
        "unique-3-nopunct": 137,
        "entropy-3-nopunct": 5.44751741503343,
        "cond_entropy-3-nopunct": 0.7302340684795933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4876900021408692
        },
        "nist": 2.754360141468099,
        "rouge1": {
            "precision": 0.52271,
            "recall": 0.50438,
            "fmeasure": 0.50509
        },
        "rouge2": {
            "precision": 0.35365,
            "recall": 0.33811,
            "fmeasure": 0.3395
        },
        "rougeL": {
            "precision": 0.52205,
            "recall": 0.50367,
            "fmeasure": 0.50442
        },
        "rougeLsum": {
            "precision": 0.52205,
            "recall": 0.50367,
            "fmeasure": 0.50442
        },
        "bleu": 29.10803,
        "meteor": 0.26786318007454313,
        "bertscore": {
            "precision": 0.85399,
            "recall": 0.85155,
            "f1": 0.85232
        },
        "nubia": {
            "semantic_relation": 3.07399,
            "contradiction": 3.33602,
            "irrelevancy": 25.25698,
            "logical_agreement": 71.407,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.57836,
            "nubia_score": 0.58233
        },
        "bleurt": 0.10613
    },
    "cs_restaurants_test": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_test",
        "N": 842,
        "msttr-100": 0.5877,
        "msttr-100_nopunct": 0.61437,
        "total_length": 10076,
        "mean_pred_length": 11.966745843230404,
        "std_pred_length": 3.626746263573584,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.06877729257641921,
        "vocab_size-1": 693,
        "unique-1": 231,
        "entropy-1": 6.993306870412135,
        "distinct-2": 0.22211392679228936,
        "vocab_size-2": 2051,
        "unique-2": 1087,
        "entropy-2": 9.14566536892515,
        "cond_entropy-2": 1.931924676122677,
        "distinct-3": 0.3593898951382269,
        "vocab_size-3": 3016,
        "unique-3": 2056,
        "entropy-3": 9.869225477014817,
        "cond_entropy-3": 0.7916342714279991,
        "total_length-nopunct": 8749,
        "mean_pred_length-nopunct": 10.390736342042755,
        "std_pred_length-nopunct": 3.3167049555000214,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.0787518573551263,
        "vocab_size-1-nopunct": 689,
        "unique-1-nopunct": 231,
        "entropy-1-nopunct": 7.172468983787323,
        "distinct-2-nopunct": 0.23030226381687113,
        "vocab_size-2-nopunct": 1821,
        "unique-2-nopunct": 1008,
        "entropy-2-nopunct": 8.960304618354924,
        "cond_entropy-2-nopunct": 1.955074280759693,
        "distinct-3-nopunct": 0.3740976645435244,
        "vocab_size-3-nopunct": 2643,
        "unique-3-nopunct": 1843,
        "entropy-3-nopunct": 9.696118722479476,
        "cond_entropy-3-nopunct": 0.8492194222037286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.46106954835134384
        },
        "nist": 3.4877976060606883,
        "rouge1": {
            "precision": 0.43888,
            "recall": 0.50734,
            "fmeasure": 0.45211
        },
        "rouge2": {
            "precision": 0.23099,
            "recall": 0.26922,
            "fmeasure": 0.23805
        },
        "rougeL": {
            "precision": 0.38239,
            "recall": 0.44218,
            "fmeasure": 0.39416
        },
        "rougeLsum": {
            "precision": 0.38239,
            "recall": 0.44218,
            "fmeasure": 0.39416
        },
        "bleu": 13.90716,
        "meteor": 0.22749384545203058,
        "bertscore": {
            "precision": 0.88672,
            "recall": 0.89868,
            "f1": 0.89238
        },
        "nubia": {
            "semantic_relation": 3.13533,
            "contradiction": 18.04382,
            "irrelevancy": 35.4008,
            "logical_agreement": 46.55538,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.52006,
            "nubia_score": 0.45348
        },
        "bleurt": -0.20097
    },
    "cs_restaurants_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_challenge_train_sample",
        "N": 500
    },
    "cs_restaurants_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_challenge_validation_sample",
        "N": 500
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 774,
        "msttr-100": 0.31672,
        "msttr-100_nopunct": 0.30484,
        "total_length": 19521,
        "mean_pred_length": 25.22093023255814,
        "std_pred_length": 1.8653722429991355,
        "median_pred_length": 25.0,
        "min_pred_length": 21,
        "max_pred_length": 31,
        "distinct-1": 0.01260181343168895,
        "vocab_size-1": 246,
        "unique-1": 23,
        "entropy-1": 6.057045994445723,
        "distinct-2": 0.04640742518803009,
        "vocab_size-2": 870,
        "unique-2": 127,
        "entropy-2": 8.011714340472649,
        "cond_entropy-2": 2.074543624639619,
        "distinct-3": 0.09330662660657653,
        "vocab_size-3": 1677,
        "unique-3": 288,
        "entropy-3": 9.26911994800713,
        "cond_entropy-3": 1.3569387529267718,
        "total_length-nopunct": 18472,
        "mean_pred_length-nopunct": 23.8656330749354,
        "std_pred_length-nopunct": 1.6018504479551328,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.013209181463837158,
        "vocab_size-1-nopunct": 244,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 6.039007323144424,
        "distinct-2-nopunct": 0.04887557916148717,
        "vocab_size-2-nopunct": 865,
        "unique-2-nopunct": 134,
        "entropy-2-nopunct": 8.029060877656072,
        "cond_entropy-2-nopunct": 2.1180299289271005,
        "distinct-3-nopunct": 0.09719924367761758,
        "vocab_size-3-nopunct": 1645,
        "unique-3-nopunct": 292,
        "entropy-3-nopunct": 9.315809244749378,
        "cond_entropy-3-nopunct": 1.3875192523446513,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.570962783548372
        },
        "nist": 3.5345593685850654,
        "rouge1": {
            "precision": 0.76971,
            "recall": 0.58163,
            "fmeasure": 0.65852
        },
        "rouge2": {
            "precision": 0.44246,
            "recall": 0.33114,
            "fmeasure": 0.37634
        },
        "rougeL": {
            "precision": 0.52326,
            "recall": 0.39673,
            "fmeasure": 0.44855
        },
        "rougeLsum": {
            "precision": 0.52326,
            "recall": 0.39673,
            "fmeasure": 0.44855
        },
        "bleu": 22.11981,
        "meteor": 0.29233585595732997,
        "bertscore": {
            "precision": 0.90957,
            "recall": 0.8682,
            "f1": 0.88823
        },
        "nubia": {
            "semantic_relation": 3.68196,
            "contradiction": 4.24406,
            "irrelevancy": 12.15909,
            "logical_agreement": 83.59685,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.71038,
            "nubia_score": 0.54808
        },
        "bleurt": -0.14052
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "ByT5-large (Baseline)/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.59644,
        "msttr-100_nopunct": 0.62333,
        "total_length": 5910,
        "mean_pred_length": 11.82,
        "std_pred_length": 3.3916957410711235,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.09187817258883249,
        "vocab_size-1": 543,
        "unique-1": 200,
        "entropy-1": 6.957139778302849,
        "distinct-2": 0.27800369685767096,
        "vocab_size-2": 1504,
        "unique-2": 890,
        "entropy-2": 9.00017865386415,
        "cond_entropy-2": 1.806553611874976,
        "distinct-3": 0.42668024439918534,
        "vocab_size-3": 2095,
        "unique-3": 1525,
        "entropy-3": 9.65822670008424,
        "cond_entropy-3": 0.7031275232453842,
        "total_length-nopunct": 5112,
        "mean_pred_length-nopunct": 10.224,
        "std_pred_length-nopunct": 3.103840202072265,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.10543818466353677,
        "vocab_size-1-nopunct": 539,
        "unique-1-nopunct": 200,
        "entropy-1-nopunct": 7.144647888579006,
        "distinct-2-nopunct": 0.28902862098872506,
        "vocab_size-2-nopunct": 1333,
        "unique-2-nopunct": 812,
        "entropy-2-nopunct": 8.828713070514823,
        "cond_entropy-2-nopunct": 1.8182076448400082,
        "distinct-3-nopunct": 0.4489299610894942,
        "vocab_size-3-nopunct": 1846,
        "unique-3-nopunct": 1390,
        "entropy-3-nopunct": 9.496542606266464,
        "cond_entropy-3-nopunct": 0.7572385780205121,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.4581877474959236
        },
        "nist": 3.435563340088082,
        "rouge1": {
            "precision": 0.43827,
            "recall": 0.50255,
            "fmeasure": 0.44922
        },
        "rouge2": {
            "precision": 0.23017,
            "recall": 0.26925,
            "fmeasure": 0.23708
        },
        "rougeL": {
            "precision": 0.37816,
            "recall": 0.43484,
            "fmeasure": 0.38826
        },
        "rougeLsum": {
            "precision": 0.37816,
            "recall": 0.43484,
            "fmeasure": 0.38826
        },
        "bleu": 14.15639,
        "meteor": 0.22644946751542838,
        "bertscore": {
            "precision": 0.88712,
            "recall": 0.89781,
            "f1": 0.89216
        },
        "nubia": {
            "semantic_relation": 3.12667,
            "contradiction": 18.36398,
            "irrelevancy": 34.78853,
            "logical_agreement": 46.84749,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.56209,
            "nubia_score": 0.44431
        },
        "bleurt": -0.22511
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 73,
        "msttr-100": 0.39222,
        "msttr-100_nopunct": 0.40176,
        "total_length": 1829,
        "mean_pred_length": 25.054794520547944,
        "std_pred_length": 2.033220072173149,
        "median_pred_length": 25.0,
        "min_pred_length": 21,
        "max_pred_length": 31,
        "distinct-1": 0.07271733187534171,
        "vocab_size-1": 133,
        "unique-1": 30,
        "entropy-1": 5.8398461115320215,
        "distinct-2": 0.2072892938496583,
        "vocab_size-2": 364,
        "unique-2": 122,
        "entropy-2": 7.585420711966117,
        "cond_entropy-2": 1.8337359593889446,
        "distinct-3": 0.36066547831253715,
        "vocab_size-3": 607,
        "unique-3": 278,
        "entropy-3": 8.585000383283658,
        "cond_entropy-3": 1.0735881074205194,
        "total_length-nopunct": 1734,
        "mean_pred_length-nopunct": 23.753424657534246,
        "std_pred_length-nopunct": 1.8415361508828558,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07554786620530565,
        "vocab_size-1-nopunct": 131,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.813231913393475,
        "distinct-2-nopunct": 0.21312462372065022,
        "vocab_size-2-nopunct": 354,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 7.604012788642967,
        "cond_entropy-2-nopunct": 1.8843382915642737,
        "distinct-3-nopunct": 0.37531486146095716,
        "vocab_size-3-nopunct": 596,
        "unique-3-nopunct": 269,
        "entropy-3-nopunct": 8.638590654645093,
        "cond_entropy-3-nopunct": 1.1040912184761336,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6138211382113821
        },
        "nist": 3.9713213713106184,
        "rouge1": {
            "precision": 0.78639,
            "recall": 0.61365,
            "fmeasure": 0.6855
        },
        "rouge2": {
            "precision": 0.49526,
            "recall": 0.38179,
            "fmeasure": 0.42854
        },
        "rougeL": {
            "precision": 0.57561,
            "recall": 0.45003,
            "fmeasure": 0.50241
        },
        "rougeLsum": {
            "precision": 0.57561,
            "recall": 0.45003,
            "fmeasure": 0.50241
        },
        "bleu": 27.86318,
        "meteor": 0.31436233942755964,
        "bertscore": {
            "precision": 0.91599,
            "recall": 0.87933,
            "f1": 0.89707
        },
        "nubia": {
            "semantic_relation": 3.77318,
            "contradiction": 4.56092,
            "irrelevancy": 10.35663,
            "logical_agreement": 85.08245,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.73663,
            "nubia_score": 0.58594
        },
        "bleurt": -0.08357
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.46153846153846156,
        "vocab_size-1": 24,
        "unique-1": 0,
        "entropy-1": 4.546593564294937,
        "distinct-2": 0.5,
        "vocab_size-2": 25,
        "unique-2": 0,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.10341647163363238,
        "distinct-3": 0.5,
        "vocab_size-3": 24,
        "unique-3": 0,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.46,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 0.5,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.1077729776130983,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.061400544664143256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6428571428571429
        },
        "nist": 2.142603282278024,
        "rouge1": {
            "precision": 0.98,
            "recall": 0.61466,
            "fmeasure": 0.75503
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.51945,
            "fmeasure": 0.6396
        },
        "rougeL": {
            "precision": 0.86,
            "recall": 0.54323,
            "fmeasure": 0.66548
        },
        "rougeLsum": {
            "precision": 0.86,
            "recall": 0.54323,
            "fmeasure": 0.66548
        },
        "bleu": 43.41299,
        "meteor": 0.3474533266129814,
        "bertscore": {
            "precision": 0.96415,
            "recall": 0.88509,
            "f1": 0.92293
        },
        "nubia": {
            "semantic_relation": 3.54838,
            "contradiction": 0.818,
            "irrelevancy": 0.91752,
            "logical_agreement": 98.26448,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.89053,
            "nubia_score": 0.45208
        },
        "bleurt": -0.03258
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 1027,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.66413,
        "total_length": 10720,
        "mean_pred_length": 10.438169425511198,
        "std_pred_length": 4.407970977532983,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 29,
        "distinct-1": 0.11259328358208955,
        "vocab_size-1": 1207,
        "unique-1": 640,
        "entropy-1": 7.424308812673277,
        "distinct-2": 0.3260084597131951,
        "vocab_size-2": 3160,
        "unique-2": 1961,
        "entropy-2": 10.359564672964654,
        "cond_entropy-2": 2.571635708177474,
        "distinct-3": 0.5309254558042926,
        "vocab_size-3": 4601,
        "unique-3": 3320,
        "entropy-3": 11.477754688255528,
        "cond_entropy-3": 1.1587845498728604,
        "total_length-nopunct": 9272,
        "mean_pred_length-nopunct": 9.02823758519961,
        "std_pred_length-nopunct": 4.134093777748904,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.12920621225194132,
        "vocab_size-1-nopunct": 1198,
        "unique-1-nopunct": 639,
        "entropy-1-nopunct": 7.713650716456889,
        "distinct-2-nopunct": 0.3417828987265009,
        "vocab_size-2-nopunct": 2818,
        "unique-2-nopunct": 1775,
        "entropy-2-nopunct": 10.218566916263251,
        "cond_entropy-2-nopunct": 2.754408741184177,
        "distinct-3-nopunct": 0.5490929234178091,
        "vocab_size-3-nopunct": 3965,
        "unique-3-nopunct": 2920,
        "entropy-3-nopunct": 11.275704017845698,
        "cond_entropy-3-nopunct": 1.1892161839804027,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6239240785698521
        },
        "nist": 7.204238024196098,
        "rouge1": {
            "precision": 0.66577,
            "recall": 0.6505,
            "fmeasure": 0.64678
        },
        "rouge2": {
            "precision": 0.45753,
            "recall": 0.44714,
            "fmeasure": 0.44266
        },
        "rougeL": {
            "precision": 0.60155,
            "recall": 0.58768,
            "fmeasure": 0.58394
        },
        "rougeLsum": {
            "precision": 0.60155,
            "recall": 0.58768,
            "fmeasure": 0.58394
        },
        "bleu": 43.81838,
        "meteor": 0.37297194160585045,
        "bertscore": {
            "precision": 0.90079,
            "recall": 0.89726,
            "f1": 0.89863
        },
        "nubia": {
            "semantic_relation": 4.12521,
            "contradiction": 3.76137,
            "irrelevancy": 17.62218,
            "logical_agreement": 78.61645,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.83392,
            "nubia_score": 0.75802
        },
        "bleurt": 0.18426
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 5049,
        "msttr-100": 0.57985,
        "msttr-100_nopunct": 0.60567,
        "total_length": 39346,
        "mean_pred_length": 7.792830263418499,
        "std_pred_length": 2.86962705739121,
        "median_pred_length": 7.0,
        "min_pred_length": 2,
        "max_pred_length": 29,
        "distinct-1": 0.032735220861078634,
        "vocab_size-1": 1288,
        "unique-1": 526,
        "entropy-1": 6.955544356572769,
        "distinct-2": 0.14114937166516023,
        "vocab_size-2": 4841,
        "unique-2": 2492,
        "entropy-2": 9.818271847423013,
        "cond_entropy-2": 2.500748280616068,
        "distinct-3": 0.2631632932166302,
        "vocab_size-3": 7697,
        "unique-3": 4787,
        "entropy-3": 10.939366538731518,
        "cond_entropy-3": 1.146412859192031,
        "total_length-nopunct": 33539,
        "mean_pred_length-nopunct": 6.642701525054466,
        "std_pred_length-nopunct": 2.6471894740547937,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.03801544470616298,
        "vocab_size-1-nopunct": 1275,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 7.1351478705758025,
        "distinct-2-nopunct": 0.14791154791154792,
        "vocab_size-2-nopunct": 4214,
        "unique-2-nopunct": 2259,
        "entropy-2-nopunct": 9.537382617356492,
        "cond_entropy-2-nopunct": 2.6115564827650264,
        "distinct-3-nopunct": 0.2693308312364055,
        "vocab_size-3-nopunct": 6315,
        "unique-3-nopunct": 4049,
        "entropy-3-nopunct": 10.557202155655723,
        "cond_entropy-3-nopunct": 1.178971320351265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4555542542601159
        },
        "nist": 4.484132413123376,
        "rouge1": {
            "precision": 0.48919,
            "recall": 0.47659,
            "fmeasure": 0.47013
        },
        "rouge2": {
            "precision": 0.28406,
            "recall": 0.27499,
            "fmeasure": 0.27116
        },
        "rougeL": {
            "precision": 0.46464,
            "recall": 0.45101,
            "fmeasure": 0.44585
        },
        "rougeLsum": {
            "precision": 0.46464,
            "recall": 0.45101,
            "fmeasure": 0.44585
        },
        "bleu": 24.76574,
        "meteor": 0.2566952796057293,
        "bertscore": {
            "precision": 0.84955,
            "recall": 0.84809,
            "f1": 0.84816
        },
        "nubia": {
            "semantic_relation": 3.12076,
            "contradiction": 7.65081,
            "irrelevancy": 29.31402,
            "logical_agreement": 63.03517,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.58646,
            "nubia_score": 0.56154
        },
        "bleurt": -0.14471
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 958,
        "msttr-100": 0.6661,
        "msttr-100_nopunct": 0.69135,
        "total_length": 20098,
        "mean_pred_length": 20.97912317327766,
        "std_pred_length": 4.824215023003083,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.08478455567718181,
        "vocab_size-1": 1704,
        "unique-1": 790,
        "entropy-1": 7.75905084146546,
        "distinct-2": 0.26927899686520373,
        "vocab_size-2": 5154,
        "unique-2": 3098,
        "entropy-2": 10.678613629716848,
        "cond_entropy-2": 2.8181807140619703,
        "distinct-3": 0.46271037289627104,
        "vocab_size-3": 8413,
        "unique-3": 5978,
        "entropy-3": 12.0597959181169,
        "cond_entropy-3": 1.4607124255618293,
        "total_length-nopunct": 17864,
        "mean_pred_length-nopunct": 18.647181628392484,
        "std_pred_length-nopunct": 4.532272053738478,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.09460367218987908,
        "vocab_size-1-nopunct": 1690,
        "unique-1-nopunct": 789,
        "entropy-1-nopunct": 7.956696613334683,
        "distinct-2-nopunct": 0.28960132497338226,
        "vocab_size-2-nopunct": 4896,
        "unique-2-nopunct": 3042,
        "entropy-2-nopunct": 10.67691887077783,
        "cond_entropy-2-nopunct": 2.868261835250935,
        "distinct-3-nopunct": 0.4949836970152997,
        "vocab_size-3-nopunct": 7894,
        "unique-3-nopunct": 5742,
        "entropy-3-nopunct": 12.091990302030649,
        "cond_entropy-3-nopunct": 1.5028189841386215,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.596202890337206
        },
        "nist": 6.449349976074245,
        "rouge1": {
            "precision": 0.63661,
            "recall": 0.61399,
            "fmeasure": 0.61468
        },
        "rouge2": {
            "precision": 0.39492,
            "recall": 0.38193,
            "fmeasure": 0.38142
        },
        "rougeL": {
            "precision": 0.55096,
            "recall": 0.5309,
            "fmeasure": 0.53188
        },
        "rougeLsum": {
            "precision": 0.55096,
            "recall": 0.5309,
            "fmeasure": 0.53188
        },
        "bleu": 30.70658,
        "meteor": 0.32736510316695455,
        "bertscore": {
            "precision": 0.88362,
            "recall": 0.87614,
            "f1": 0.87945
        },
        "nubia": {
            "semantic_relation": 4.28718,
            "contradiction": 3.82606,
            "irrelevancy": 18.89556,
            "logical_agreement": 77.27838,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.76955,
            "nubia_score": 0.74347
        },
        "bleurt": -0.06576
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 72,
        "msttr-100": 0.62722,
        "msttr-100_nopunct": 0.6475,
        "total_length": 1842,
        "mean_pred_length": 25.583333333333332,
        "std_pred_length": 3.77031534195454,
        "median_pred_length": 26.0,
        "min_pred_length": 14,
        "max_pred_length": 32,
        "distinct-1": 0.20575461454940283,
        "vocab_size-1": 379,
        "unique-1": 215,
        "entropy-1": 7.012691418737974,
        "distinct-2": 0.47966101694915253,
        "vocab_size-2": 849,
        "unique-2": 596,
        "entropy-2": 8.998711860594758,
        "cond_entropy-2": 2.0015990280679157,
        "distinct-3": 0.6613663133097762,
        "vocab_size-3": 1123,
        "unique-3": 906,
        "entropy-3": 9.713975336708783,
        "cond_entropy-3": 0.7541658078153354,
        "total_length-nopunct": 1658,
        "mean_pred_length-nopunct": 23.02777777777778,
        "std_pred_length-nopunct": 3.689219362707081,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.22376357056694812,
        "vocab_size-1-nopunct": 371,
        "unique-1-nopunct": 212,
        "entropy-1-nopunct": 7.077559034761056,
        "distinct-2-nopunct": 0.5063051702395964,
        "vocab_size-2-nopunct": 803,
        "unique-2-nopunct": 576,
        "entropy-2-nopunct": 8.964582591757258,
        "cond_entropy-2-nopunct": 1.9375000028290672,
        "distinct-3-nopunct": 0.6869220607661823,
        "vocab_size-3-nopunct": 1040,
        "unique-3-nopunct": 849,
        "entropy-3-nopunct": 9.643121250585049,
        "cond_entropy-3-nopunct": 0.7190700544160671,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5087108013937283
        },
        "nist": 3.875117207356501,
        "rouge1": {
            "precision": 0.66623,
            "recall": 0.51343,
            "fmeasure": 0.5715
        },
        "rouge2": {
            "precision": 0.40611,
            "recall": 0.31688,
            "fmeasure": 0.35038
        },
        "rougeL": {
            "precision": 0.53059,
            "recall": 0.41143,
            "fmeasure": 0.45657
        },
        "rougeLsum": {
            "precision": 0.53059,
            "recall": 0.41143,
            "fmeasure": 0.45657
        },
        "bleu": 25.33139,
        "meteor": 0.2732606788277258,
        "bertscore": {
            "precision": 0.89058,
            "recall": 0.84737,
            "f1": 0.86809
        },
        "nubia": {
            "semantic_relation": 3.60246,
            "contradiction": 6.85873,
            "irrelevancy": 13.88012,
            "logical_agreement": 79.26114,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.40796,
            "nubia_score": 0.52126
        },
        "bleurt": -0.30212
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 1024,
        "msttr-100": 0.52,
        "msttr-100_nopunct": 0.5425,
        "total_length": 10879,
        "mean_pred_length": 10.6240234375,
        "std_pred_length": 5.397504579613683,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 28,
        "distinct-1": 0.07390385145693538,
        "vocab_size-1": 804,
        "unique-1": 436,
        "entropy-1": 6.5312895608977035,
        "distinct-2": 0.22029426686960935,
        "vocab_size-2": 2171,
        "unique-2": 1302,
        "entropy-2": 9.248880425269059,
        "cond_entropy-2": 2.471007536530042,
        "distinct-3": 0.378326350356698,
        "vocab_size-3": 3341,
        "unique-3": 2286,
        "entropy-3": 10.407638573721668,
        "cond_entropy-3": 1.1639385799819268,
        "total_length-nopunct": 9218,
        "mean_pred_length-nopunct": 9.001953125,
        "std_pred_length-nopunct": 4.8363851361634485,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.08624430462139293,
        "vocab_size-1-nopunct": 795,
        "unique-1-nopunct": 435,
        "entropy-1-nopunct": 6.737538947998895,
        "distinct-2-nopunct": 0.24664388577007568,
        "vocab_size-2-nopunct": 2021,
        "unique-2-nopunct": 1263,
        "entropy-2-nopunct": 9.191213483963487,
        "cond_entropy-2-nopunct": 2.633848474827822,
        "distinct-3-nopunct": 0.42044345279598383,
        "vocab_size-3-nopunct": 3015,
        "unique-3-nopunct": 2158,
        "entropy-3-nopunct": 10.30216924842013,
        "cond_entropy-3-nopunct": 1.158371867852426,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4133318715053174
        },
        "nist": 4.077680492553165,
        "rouge1": {
            "precision": 0.39915,
            "recall": 0.39265,
            "fmeasure": 0.38378
        },
        "rouge2": {
            "precision": 0.18496,
            "recall": 0.17864,
            "fmeasure": 0.17679
        },
        "rougeL": {
            "precision": 0.35303,
            "recall": 0.34591,
            "fmeasure": 0.33845
        },
        "rougeLsum": {
            "precision": 0.35303,
            "recall": 0.34591,
            "fmeasure": 0.33845
        },
        "bleu": 22.3227,
        "meteor": 0.23544153221811695,
        "bertscore": {
            "precision": 0.82715,
            "recall": 0.83357,
            "f1": 0.82967
        },
        "nubia": {
            "semantic_relation": 2.4906,
            "contradiction": 11.68851,
            "irrelevancy": 36.94498,
            "logical_agreement": 51.36651,
            "grammar_ref": 5.2128,
            "grammar_hyp": 4.97232,
            "nubia_score": 0.41008
        },
        "bleurt": -0.56383
    },
    "e2e_nlg_validation": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_validation",
        "N": 4299,
        "msttr-100": 0.31217,
        "msttr-100_nopunct": 0.30438,
        "total_length": 96238,
        "mean_pred_length": 22.386136310769945,
        "std_pred_length": 3.974477007911926,
        "median_pred_length": 23.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.006120243562833808,
        "vocab_size-1": 589,
        "unique-1": 93,
        "entropy-1": 6.2558101099311925,
        "distinct-2": 0.028421018283862128,
        "vocab_size-2": 2613,
        "unique-2": 638,
        "entropy-2": 8.506954591589581,
        "cond_entropy-2": 2.277373754442752,
        "distinct-3": 0.05968735737106344,
        "vocab_size-3": 5231,
        "unique-3": 1471,
        "entropy-3": 10.002664863124766,
        "cond_entropy-3": 1.5828048272972133,
        "total_length-nopunct": 89466,
        "mean_pred_length-nopunct": 20.81088625261689,
        "std_pred_length-nopunct": 3.9032629756437487,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.006549974291909776,
        "vocab_size-1-nopunct": 586,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.279253483694944,
        "distinct-2-nopunct": 0.030833538811981167,
        "vocab_size-2-nopunct": 2626,
        "unique-2-nopunct": 668,
        "entropy-2-nopunct": 8.468636150036165,
        "cond_entropy-2-nopunct": 2.3014972567257233,
        "distinct-3-nopunct": 0.06325122421724291,
        "vocab_size-3-nopunct": 5115,
        "unique-3-nopunct": 1457,
        "entropy-3-nopunct": 9.993772274717793,
        "cond_entropy-3-nopunct": 1.6044738604529272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_validation.json",
        "local_recall": {
            "1": 0.6264290401685491
        },
        "nist": 4.6400122219112925,
        "rouge1": {
            "precision": 0.68276,
            "recall": 0.64878,
            "fmeasure": 0.65447
        },
        "rouge2": {
            "precision": 0.39123,
            "recall": 0.36853,
            "fmeasure": 0.37332
        },
        "rougeL": {
            "precision": 0.49226,
            "recall": 0.46911,
            "fmeasure": 0.47254
        },
        "rougeLsum": {
            "precision": 0.49226,
            "recall": 0.46911,
            "fmeasure": 0.47254
        },
        "bleu": 25.30603,
        "meteor": 0.323970136097675,
        "bertscore": {
            "precision": 0.89694,
            "recall": 0.88694,
            "f1": 0.89157
        },
        "nubia": {
            "semantic_relation": 4.01137,
            "contradiction": 4.28973,
            "irrelevancy": 26.15592,
            "logical_agreement": 69.55436,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.74236,
            "nubia_score": 0.6674
        },
        "bleurt": 0.0024
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 2517,
        "msttr-100": 0.6945,
        "msttr-100_nopunct": 0.72112,
        "total_length": 37369,
        "mean_pred_length": 14.846642828764402,
        "std_pred_length": 4.279786090877937,
        "median_pred_length": 14.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.0688271026786909,
        "vocab_size-1": 2572,
        "unique-1": 1202,
        "entropy-1": 8.14410601657026,
        "distinct-2": 0.26632617927235164,
        "vocab_size-2": 9282,
        "unique-2": 5525,
        "entropy-2": 11.621714974937145,
        "cond_entropy-2": 3.2544298896091597,
        "distinct-3": 0.4774083810112881,
        "vocab_size-3": 15437,
        "unique-3": 11041,
        "entropy-3": 13.000598688836291,
        "cond_entropy-3": 1.4275858108095962,
        "total_length-nopunct": 33079,
        "mean_pred_length-nopunct": 13.142232816845452,
        "std_pred_length-nopunct": 3.8709353014347907,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.07733002811451374,
        "vocab_size-1-nopunct": 2558,
        "unique-1-nopunct": 1200,
        "entropy-1-nopunct": 8.346439155196286,
        "distinct-2-nopunct": 0.283489300438453,
        "vocab_size-2-nopunct": 8664,
        "unique-2-nopunct": 5348,
        "entropy-2-nopunct": 11.501722519800927,
        "cond_entropy-2-nopunct": 3.3206135139287936,
        "distinct-3-nopunct": 0.4957213149825287,
        "vocab_size-3-nopunct": 13903,
        "unique-3-nopunct": 10201,
        "entropy-3-nopunct": 12.848364830784863,
        "cond_entropy-3-nopunct": 1.4249046616745467,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5880808775274228
        },
        "nist": 6.778775567179422,
        "rouge1": {
            "precision": 0.62714,
            "recall": 0.61291,
            "fmeasure": 0.6082
        },
        "rouge2": {
            "precision": 0.39408,
            "recall": 0.3858,
            "fmeasure": 0.38189
        },
        "rougeL": {
            "precision": 0.53871,
            "recall": 0.52762,
            "fmeasure": 0.5229
        },
        "rougeLsum": {
            "precision": 0.53871,
            "recall": 0.52762,
            "fmeasure": 0.5229
        },
        "bleu": 32.56677,
        "meteor": 0.32745027270686217,
        "bertscore": {
            "precision": 0.88208,
            "recall": 0.87762,
            "f1": 0.87941
        },
        "nubia": {
            "semantic_relation": 4.04937,
            "contradiction": 4.72183,
            "irrelevancy": 21.95685,
            "logical_agreement": 73.32133,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.66673,
            "nubia_score": 0.71023
        },
        "bleurt": -0.05054
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 1246,
        "msttr-100": 0.67685,
        "msttr-100_nopunct": 0.69964,
        "total_length": 18461,
        "mean_pred_length": 14.81621187800963,
        "std_pred_length": 4.630046378855886,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.10405720166838199,
        "vocab_size-1": 1921,
        "unique-1": 914,
        "entropy-1": 8.023436450875518,
        "distinct-2": 0.31298286378158585,
        "vocab_size-2": 5388,
        "unique-2": 3321,
        "entropy-2": 10.898313079817736,
        "cond_entropy-2": 2.6596728790037703,
        "distinct-3": 0.5121172271275597,
        "vocab_size-3": 8178,
        "unique-3": 5957,
        "entropy-3": 12.147553884309149,
        "cond_entropy-3": 1.2975013509936209,
        "total_length-nopunct": 16558,
        "mean_pred_length-nopunct": 13.28892455858748,
        "std_pred_length-nopunct": 4.252464789842607,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.11511052059427467,
        "vocab_size-1-nopunct": 1906,
        "unique-1-nopunct": 912,
        "entropy-1-nopunct": 8.18702704669932,
        "distinct-2-nopunct": 0.3218390804597701,
        "vocab_size-2-nopunct": 4928,
        "unique-2-nopunct": 3127,
        "entropy-2-nopunct": 10.742544125199945,
        "cond_entropy-2-nopunct": 2.7014310788903195,
        "distinct-3-nopunct": 0.5221100526091284,
        "vocab_size-3-nopunct": 7344,
        "unique-3-nopunct": 5425,
        "entropy-3-nopunct": 11.992654556489903,
        "cond_entropy-3-nopunct": 1.325461781890234,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6329793580718291
        },
        "nist": 7.2715792534114,
        "rouge1": {
            "precision": 0.69606,
            "recall": 0.6601,
            "fmeasure": 0.66644
        },
        "rouge2": {
            "precision": 0.48537,
            "recall": 0.45972,
            "fmeasure": 0.46361
        },
        "rougeL": {
            "precision": 0.60037,
            "recall": 0.56994,
            "fmeasure": 0.57516
        },
        "rougeLsum": {
            "precision": 0.60037,
            "recall": 0.56994,
            "fmeasure": 0.57516
        },
        "bleu": 37.95722,
        "meteor": 0.3665112200938876,
        "bertscore": {
            "precision": 0.8994,
            "recall": 0.88847,
            "f1": 0.89345
        },
        "nubia": {
            "semantic_relation": 4.34456,
            "contradiction": 3.48281,
            "irrelevancy": 19.04923,
            "logical_agreement": 77.46796,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.84662,
            "nubia_score": 0.77907
        },
        "bleurt": -0.01144
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.35698,
        "msttr-100_nopunct": 0.36132,
        "total_length": 4302,
        "mean_pred_length": 8.604,
        "std_pred_length": 1.8174663683270729,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.03277545327754533,
        "vocab_size-1": 141,
        "unique-1": 43,
        "entropy-1": 5.115800222878574,
        "distinct-2": 0.11809573908469227,
        "vocab_size-2": 449,
        "unique-2": 203,
        "entropy-2": 6.94115763953815,
        "cond_entropy-2": 1.5936349233392562,
        "distinct-3": 0.22077528770442156,
        "vocab_size-3": 729,
        "unique-3": 383,
        "entropy-3": 7.906610147481668,
        "cond_entropy-3": 1.0310387890971187,
        "total_length-nopunct": 3807,
        "mean_pred_length-nopunct": 7.614,
        "std_pred_length-nopunct": 1.7991675853016027,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.03598634095087996,
        "vocab_size-1-nopunct": 137,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.170218841022317,
        "distinct-2-nopunct": 0.11974599334744482,
        "vocab_size-2-nopunct": 396,
        "unique-2-nopunct": 182,
        "entropy-2-nopunct": 6.672724224039505,
        "cond_entropy-2-nopunct": 1.6757457513445486,
        "distinct-3-nopunct": 0.21980762379764873,
        "vocab_size-3-nopunct": 617,
        "unique-3-nopunct": 333,
        "entropy-3-nopunct": 7.555313395386102,
        "cond_entropy-3-nopunct": 1.107252789541442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5038492168834616
        },
        "nist": 3.294968062295489,
        "rouge1": {
            "precision": 0.52745,
            "recall": 0.52127,
            "fmeasure": 0.51383
        },
        "rouge2": {
            "precision": 0.29359,
            "recall": 0.2911,
            "fmeasure": 0.28544
        },
        "rougeL": {
            "precision": 0.50283,
            "recall": 0.49703,
            "fmeasure": 0.48996
        },
        "rougeLsum": {
            "precision": 0.50283,
            "recall": 0.49703,
            "fmeasure": 0.48996
        },
        "bleu": 23.49547,
        "meteor": 0.2709558201045205,
        "bertscore": {
            "precision": 0.87822,
            "recall": 0.87781,
            "f1": 0.87764
        },
        "nubia": {
            "semantic_relation": 3.54767,
            "contradiction": 6.32893,
            "irrelevancy": 28.81257,
            "logical_agreement": 64.8585,
            "grammar_ref": 4.43492,
            "grammar_hyp": 4.21484,
            "nubia_score": 0.65193
        },
        "bleurt": -0.01503
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 1328,
        "msttr-100": 0.69751,
        "msttr-100_nopunct": 0.72289,
        "total_length": 25321,
        "mean_pred_length": 19.067018072289155,
        "std_pred_length": 4.770724872270702,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.08265866277003278,
        "vocab_size-1": 2093,
        "unique-1": 1022,
        "entropy-1": 8.082193821602887,
        "distinct-2": 0.28820906097611804,
        "vocab_size-2": 6915,
        "unique-2": 4243,
        "entropy-2": 11.294366493259268,
        "cond_entropy-2": 3.0568576741431412,
        "distinct-3": 0.49631590558129274,
        "vocab_size-3": 11249,
        "unique-3": 8200,
        "entropy-3": 12.629584703891304,
        "cond_entropy-3": 1.3851152213375995,
        "total_length-nopunct": 22531,
        "mean_pred_length-nopunct": 16.966114457831324,
        "std_pred_length-nopunct": 4.279000554561257,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.0922728684922995,
        "vocab_size-1-nopunct": 2079,
        "unique-1-nopunct": 1019,
        "entropy-1-nopunct": 8.281506269273306,
        "distinct-2-nopunct": 0.3090600386737726,
        "vocab_size-2-nopunct": 6553,
        "unique-2-nopunct": 4168,
        "entropy-2-nopunct": 11.239892867882096,
        "cond_entropy-2-nopunct": 3.092101675678685,
        "distinct-3-nopunct": 0.5217106918238994,
        "vocab_size-3-nopunct": 10369,
        "unique-3-nopunct": 7750,
        "entropy-3-nopunct": 12.556870615428876,
        "cond_entropy-3-nopunct": 1.381333539058343,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5974197665937272
        },
        "nist": 6.662031653494001,
        "rouge1": {
            "precision": 0.64005,
            "recall": 0.6188,
            "fmeasure": 0.6184
        },
        "rouge2": {
            "precision": 0.40254,
            "recall": 0.39157,
            "fmeasure": 0.39004
        },
        "rougeL": {
            "precision": 0.53532,
            "recall": 0.51858,
            "fmeasure": 0.51799
        },
        "rougeLsum": {
            "precision": 0.53532,
            "recall": 0.51858,
            "fmeasure": 0.51799
        },
        "bleu": 30.96548,
        "meteor": 0.325775740692861,
        "bertscore": {
            "precision": 0.88712,
            "recall": 0.87954,
            "f1": 0.88291
        },
        "nubia": {
            "semantic_relation": 4.20087,
            "contradiction": 4.03391,
            "irrelevancy": 18.70839,
            "logical_agreement": 77.2577,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.70034,
            "nubia_score": 0.7296
        },
        "bleurt": -0.04843
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 469,
        "msttr-100": 0.69969,
        "msttr-100_nopunct": 0.72034,
        "total_length": 9857,
        "mean_pred_length": 21.017057569296377,
        "std_pred_length": 4.387388288069474,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.12224814852389165,
        "vocab_size-1": 1205,
        "unique-1": 592,
        "entropy-1": 7.893199722747329,
        "distinct-2": 0.3575841499786962,
        "vocab_size-2": 3357,
        "unique-2": 2156,
        "entropy-2": 10.565767031508381,
        "cond_entropy-2": 2.564286944779093,
        "distinct-3": 0.5641888104047539,
        "vocab_size-3": 5032,
        "unique-3": 3785,
        "entropy-3": 11.683995902855443,
        "cond_entropy-3": 1.158960486529049,
        "total_length-nopunct": 8927,
        "mean_pred_length-nopunct": 19.03411513859275,
        "std_pred_length-nopunct": 4.016345642417458,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.13386355998655763,
        "vocab_size-1-nopunct": 1195,
        "unique-1-nopunct": 590,
        "entropy-1-nopunct": 8.02434840773128,
        "distinct-2-nopunct": 0.3740837077323244,
        "vocab_size-2-nopunct": 3164,
        "unique-2-nopunct": 2085,
        "entropy-2-nopunct": 10.495083737588862,
        "cond_entropy-2-nopunct": 2.5628175524145407,
        "distinct-3-nopunct": 0.5855551383151834,
        "vocab_size-3-nopunct": 4678,
        "unique-3-nopunct": 3573,
        "entropy-3-nopunct": 11.620446350088212,
        "cond_entropy-3-nopunct": 1.1489981607750908,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6389114070642733
        },
        "nist": 6.676716520793968,
        "rouge1": {
            "precision": 0.66837,
            "recall": 0.65586,
            "fmeasure": 0.65183
        },
        "rouge2": {
            "precision": 0.44538,
            "recall": 0.43606,
            "fmeasure": 0.43369
        },
        "rougeL": {
            "precision": 0.57286,
            "recall": 0.56121,
            "fmeasure": 0.55842
        },
        "rougeLsum": {
            "precision": 0.57286,
            "recall": 0.56121,
            "fmeasure": 0.55842
        },
        "bleu": 34.74755,
        "meteor": 0.34592761992843296,
        "bertscore": {
            "precision": 0.89186,
            "recall": 0.886,
            "f1": 0.88853
        },
        "nubia": {
            "semantic_relation": 4.28451,
            "contradiction": 2.78921,
            "irrelevancy": 18.69023,
            "logical_agreement": 78.52056,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.77081,
            "nubia_score": 0.75263
        },
        "bleurt": -0.02156
    },
    "e2e_nlg_test": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_test",
        "N": 4693,
        "msttr-100": 0.30732,
        "msttr-100_nopunct": 0.29958,
        "total_length": 105366,
        "mean_pred_length": 22.451736629021948,
        "std_pred_length": 3.85366013422344,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.0052578630677827766,
        "vocab_size-1": 554,
        "unique-1": 74,
        "entropy-1": 6.149860255435954,
        "distinct-2": 0.02399849016121502,
        "vocab_size-2": 2416,
        "unique-2": 476,
        "entropy-2": 8.322415166389447,
        "cond_entropy-2": 2.228560588229963,
        "distinct-3": 0.053667430714732234,
        "vocab_size-3": 5151,
        "unique-3": 1246,
        "entropy-3": 9.786718520307566,
        "cond_entropy-3": 1.5663714180713606,
        "total_length-nopunct": 98949,
        "mean_pred_length-nopunct": 21.08438099296825,
        "std_pred_length-nopunct": 3.783468733126526,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.0055483127671830945,
        "vocab_size-1-nopunct": 549,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.159646169589099,
        "distinct-2-nopunct": 0.025568664063826175,
        "vocab_size-2-nopunct": 2410,
        "unique-2-nopunct": 488,
        "entropy-2-nopunct": 8.309379204604905,
        "cond_entropy-2-nopunct": 2.2756816910376525,
        "distinct-3-nopunct": 0.056206245882786415,
        "vocab_size-3-nopunct": 5034,
        "unique-3-nopunct": 1227,
        "entropy-3-nopunct": 9.81933088802509,
        "cond_entropy-3-nopunct": 1.596491572011251,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6397589884638978
        },
        "nist": 4.7441042216554745,
        "rouge1": {
            "precision": 0.73674,
            "recall": 0.66008,
            "fmeasure": 0.68578
        },
        "rouge2": {
            "precision": 0.43079,
            "recall": 0.38494,
            "fmeasure": 0.40006
        },
        "rougeL": {
            "precision": 0.5215,
            "recall": 0.46883,
            "fmeasure": 0.48623
        },
        "rougeLsum": {
            "precision": 0.5215,
            "recall": 0.46883,
            "fmeasure": 0.48623
        },
        "bleu": 26.02833,
        "meteor": 0.32743555905059235,
        "bertscore": {
            "precision": 0.91002,
            "recall": 0.89143,
            "f1": 0.90028
        },
        "nubia": {
            "semantic_relation": 4.0701,
            "contradiction": 3.35462,
            "irrelevancy": 21.62764,
            "logical_agreement": 75.01773,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.7701,
            "nubia_score": 0.6836
        },
        "bleurt": 0.01787
    },
    "e2e_nlg_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_challenge_train_sample",
        "N": 500
    },
    "e2e_nlg_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 2078,
        "msttr-100": 0.51639,
        "msttr-100_nopunct": 0.53807,
        "total_length": 21977,
        "mean_pred_length": 10.576034648700674,
        "std_pred_length": 5.337208743622966,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 33,
        "distinct-1": 0.026027210265277337,
        "vocab_size-1": 572,
        "unique-1": 189,
        "entropy-1": 6.353102348289967,
        "distinct-2": 0.1362380019096437,
        "vocab_size-2": 2711,
        "unique-2": 1321,
        "entropy-2": 9.277650570185735,
        "cond_entropy-2": 2.63635038272639,
        "distinct-3": 0.28786263397115763,
        "vocab_size-3": 5130,
        "unique-3": 3163,
        "entropy-3": 10.690626781502303,
        "cond_entropy-3": 1.4695161277182138,
        "total_length-nopunct": 19276,
        "mean_pred_length-nopunct": 9.276227141482195,
        "std_pred_length-nopunct": 4.891185803699198,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.029362938368956214,
        "vocab_size-1-nopunct": 566,
        "unique-1-nopunct": 188,
        "entropy-1-nopunct": 6.517704515641185,
        "distinct-2-nopunct": 0.145482032794511,
        "vocab_size-2-nopunct": 2502,
        "unique-2-nopunct": 1297,
        "entropy-2-nopunct": 9.028928859189506,
        "cond_entropy-2-nopunct": 2.6976348701999537,
        "distinct-3-nopunct": 0.2979764581404576,
        "vocab_size-3-nopunct": 4506,
        "unique-3-nopunct": 2912,
        "entropy-3-nopunct": 10.408314380179903,
        "cond_entropy-3-nopunct": 1.503428019205921,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4330729031924251
        },
        "nist": 3.5981069816477915,
        "rouge1": {
            "precision": 0.46616,
            "recall": 0.43777,
            "fmeasure": 0.43692
        },
        "rouge2": {
            "precision": 0.23226,
            "recall": 0.21844,
            "fmeasure": 0.21649
        },
        "rougeL": {
            "precision": 0.42385,
            "recall": 0.39855,
            "fmeasure": 0.39771
        },
        "rougeLsum": {
            "precision": 0.42385,
            "recall": 0.39855,
            "fmeasure": 0.39771
        },
        "bleu": 17.03595,
        "meteor": 0.23204561121826095,
        "bertscore": {
            "precision": 0.84482,
            "recall": 0.83647,
            "f1": 0.8399
        },
        "nubia": {
            "semantic_relation": 3.11784,
            "contradiction": 10.46036,
            "irrelevancy": 27.75574,
            "logical_agreement": 61.7839,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.38901,
            "nubia_score": 0.52264
        },
        "bleurt": -0.28657
    },
    "schema_guided_dialog_validation": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_validation",
        "N": 10000,
        "msttr-100": 0.7001,
        "msttr-100_nopunct": 0.72694,
        "total_length": 124134,
        "mean_pred_length": 12.4134,
        "std_pred_length": 6.677956307134691,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 33,
        "distinct-1": 0.03566307377511399,
        "vocab_size-1": 4427,
        "unique-1": 1922,
        "entropy-1": 8.16793233187938,
        "distinct-2": 0.15698214379588904,
        "vocab_size-2": 17917,
        "unique-2": 9752,
        "entropy-2": 11.827326007762808,
        "cond_entropy-2": 3.4295829477132505,
        "distinct-3": 0.3302956682063052,
        "vocab_size-3": 34396,
        "unique-3": 22824,
        "entropy-3": 13.502431274497077,
        "cond_entropy-3": 1.7075622104061492,
        "total_length-nopunct": 109514,
        "mean_pred_length-nopunct": 10.9514,
        "std_pred_length-nopunct": 6.219842284174093,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.04026882407728692,
        "vocab_size-1-nopunct": 4410,
        "unique-1-nopunct": 1919,
        "entropy-1-nopunct": 8.383362488754479,
        "distinct-2-nopunct": 0.1727998070623229,
        "vocab_size-2-nopunct": 17196,
        "unique-2-nopunct": 9780,
        "entropy-2-nopunct": 11.735034518721266,
        "cond_entropy-2-nopunct": 3.5094791526973563,
        "distinct-3-nopunct": 0.35351673759340546,
        "vocab_size-3-nopunct": 31650,
        "unique-3-nopunct": 21669,
        "entropy-3-nopunct": 13.391839215278896,
        "cond_entropy-3-nopunct": 1.713890911704484,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_validation.json",
        "local_recall": {
            "1": 0.5986959595207977
        },
        "nist": 7.234305907256092,
        "rouge1": {
            "precision": 0.59977,
            "recall": 0.59804,
            "fmeasure": 0.58538
        },
        "rouge2": {
            "precision": 0.38666,
            "recall": 0.38655,
            "fmeasure": 0.37719
        },
        "rougeL": {
            "precision": 0.54219,
            "recall": 0.54099,
            "fmeasure": 0.52938
        },
        "rougeLsum": {
            "precision": 0.54219,
            "recall": 0.54099,
            "fmeasure": 0.52938
        },
        "bleu": 34.13887,
        "meteor": 0.33229486035865013,
        "bertscore": {
            "precision": 0.87675,
            "recall": 0.87548,
            "f1": 0.87553
        },
        "nubia": {
            "semantic_relation": 3.78555,
            "contradiction": 3.80727,
            "irrelevancy": 21.88705,
            "logical_agreement": 74.30568,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.69503,
            "nubia_score": 0.68422
        },
        "bleurt": -0.0142
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "ByT5-large (Baseline)/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.51196,
        "msttr-100_nopunct": 0.52,
        "total_length": 11210,
        "mean_pred_length": 22.42,
        "std_pred_length": 3.9511517308248236,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.028902765388046387,
        "vocab_size-1": 324,
        "unique-1": 102,
        "entropy-1": 6.167031819296375,
        "distinct-2": 0.11783380018674136,
        "vocab_size-2": 1262,
        "unique-2": 594,
        "entropy-2": 8.352292354916182,
        "cond_entropy-2": 2.232386494048614,
        "distinct-3": 0.23506366307541626,
        "vocab_size-3": 2400,
        "unique-3": 1365,
        "entropy-3": 9.708346826030526,
        "cond_entropy-3": 1.4468393307620446,
        "total_length-nopunct": 10502,
        "mean_pred_length-nopunct": 21.004,
        "std_pred_length-nopunct": 3.886384438009189,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.030565606551133117,
        "vocab_size-1-nopunct": 321,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.178177619762699,
        "distinct-2-nopunct": 0.1226754649070186,
        "vocab_size-2-nopunct": 1227,
        "unique-2-nopunct": 582,
        "entropy-2-nopunct": 8.33764741697472,
        "cond_entropy-2-nopunct": 2.277988017603728,
        "distinct-3-nopunct": 0.2448958114081246,
        "vocab_size-3-nopunct": 2327,
        "unique-3-nopunct": 1317,
        "entropy-3-nopunct": 9.73420909610151,
        "cond_entropy-3-nopunct": 1.4758855290987594,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.6255928578071236
        },
        "nist": 4.613975766581238,
        "rouge1": {
            "precision": 0.72299,
            "recall": 0.64368,
            "fmeasure": 0.67126
        },
        "rouge2": {
            "precision": 0.41641,
            "recall": 0.36835,
            "fmeasure": 0.38503
        },
        "rougeL": {
            "precision": 0.5081,
            "recall": 0.45247,
            "fmeasure": 0.4717
        },
        "rougeLsum": {
            "precision": 0.5081,
            "recall": 0.45247,
            "fmeasure": 0.4717
        },
        "bleu": 25.22756,
        "meteor": 0.32106887435264736,
        "bertscore": {
            "precision": 0.90622,
            "recall": 0.88719,
            "f1": 0.89626
        },
        "nubia": {
            "semantic_relation": 4.01167,
            "contradiction": 3.31831,
            "irrelevancy": 23.2126,
            "logical_agreement": 73.46909,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.76804,
            "nubia_score": 0.67078
        },
        "bleurt": -0.01807
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 715,
        "msttr-100": 0.27769,
        "msttr-100_nopunct": 0.26965,
        "total_length": 6543,
        "mean_pred_length": 9.151048951048951,
        "std_pred_length": 3.3247717652960915,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 25,
        "distinct-1": 0.02277242854959499,
        "vocab_size-1": 149,
        "unique-1": 53,
        "entropy-1": 4.665139029985578,
        "distinct-2": 0.07755662319835278,
        "vocab_size-2": 452,
        "unique-2": 233,
        "entropy-2": 6.070850939151227,
        "cond_entropy-2": 1.2371084569529902,
        "distinct-3": 0.12595345198513594,
        "vocab_size-3": 644,
        "unique-3": 365,
        "entropy-3": 6.694830470673485,
        "cond_entropy-3": 0.6223380928550803,
        "total_length-nopunct": 5733,
        "mean_pred_length-nopunct": 8.018181818181818,
        "std_pred_length-nopunct": 2.9971463435582164,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.025466596895168322,
        "vocab_size-1-nopunct": 146,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 4.606287994986363,
        "distinct-2-nopunct": 0.08110801115982463,
        "vocab_size-2-nopunct": 407,
        "unique-2-nopunct": 220,
        "entropy-2-nopunct": 5.789217069199326,
        "cond_entropy-2-nopunct": 1.1715113023796142,
        "distinct-3-nopunct": 0.1308389495700674,
        "vocab_size-3-nopunct": 563,
        "unique-3-nopunct": 333,
        "entropy-3-nopunct": 6.373175030057006,
        "cond_entropy-3-nopunct": 0.5756702694803071,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5390274537950834
        },
        "nist": 2.9541315315841836,
        "rouge1": {
            "precision": 0.53421,
            "recall": 0.55221,
            "fmeasure": 0.52974
        },
        "rouge2": {
            "precision": 0.29392,
            "recall": 0.30064,
            "fmeasure": 0.2877
        },
        "rougeL": {
            "precision": 0.46066,
            "recall": 0.47029,
            "fmeasure": 0.45365
        },
        "rougeLsum": {
            "precision": 0.46066,
            "recall": 0.47029,
            "fmeasure": 0.45365
        },
        "bleu": 25.05259,
        "meteor": 0.28267681439224546,
        "bertscore": {
            "precision": 0.85208,
            "recall": 0.85313,
            "f1": 0.85193
        },
        "nubia": {
            "semantic_relation": 3.58225,
            "contradiction": 1.74467,
            "irrelevancy": 28.87418,
            "logical_agreement": 69.38116,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.69742,
            "nubia_score": 0.70656
        },
        "bleurt": 0.12298
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73955,
        "msttr-100_nopunct": 0.75095,
        "total_length": 2242,
        "mean_pred_length": 21.150943396226417,
        "std_pred_length": 3.18247694215717,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.423728813559322,
        "vocab_size-1": 950,
        "unique-1": 721,
        "entropy-1": 8.380143443503517,
        "distinct-2": 0.848314606741573,
        "vocab_size-2": 1812,
        "unique-2": 1670,
        "entropy-2": 10.62157938718731,
        "cond_entropy-2": 2.1462435683010126,
        "distinct-3": 0.970935960591133,
        "vocab_size-3": 1971,
        "unique-3": 1930,
        "entropy-3": 10.920813838185579,
        "cond_entropy-3": 0.3152034513439052,
        "total_length-nopunct": 2117,
        "mean_pred_length-nopunct": 19.971698113207548,
        "std_pred_length-nopunct": 3.2634555917662498,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4444969296173831,
        "vocab_size-1-nopunct": 941,
        "unique-1-nopunct": 719,
        "entropy-1-nopunct": 8.439856125817062,
        "distinct-2-nopunct": 0.8508204873197415,
        "vocab_size-2-nopunct": 1711,
        "unique-2-nopunct": 1581,
        "entropy-2-nopunct": 10.540174753890373,
        "cond_entropy-2-nopunct": 2.1861230449456457,
        "distinct-3-nopunct": 0.973753280839895,
        "vocab_size-3-nopunct": 1855,
        "unique-3-nopunct": 1819,
        "entropy-3-nopunct": 10.836313417293885,
        "cond_entropy-3-nopunct": 0.30591527314323197,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.4419665484034465
        },
        "nist": 4.083493080032244,
        "rouge1": {
            "precision": 0.45966,
            "recall": 0.47543,
            "fmeasure": 0.45869
        },
        "rouge2": {
            "precision": 0.22548,
            "recall": 0.23384,
            "fmeasure": 0.22555
        },
        "rougeL": {
            "precision": 0.37334,
            "recall": 0.3872,
            "fmeasure": 0.37314
        },
        "rougeLsum": {
            "precision": 0.37334,
            "recall": 0.3872,
            "fmeasure": 0.37314
        },
        "bleu": 16.73817,
        "meteor": 0.2161851219753507,
        "bertscore": {
            "precision": 0.84576,
            "recall": 0.8465,
            "f1": 0.84572
        },
        "nubia": {
            "semantic_relation": 3.16655,
            "contradiction": 21.34434,
            "irrelevancy": 68.45478,
            "logical_agreement": 10.20088,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.86761,
            "nubia_score": 0.46373
        },
        "bleurt": -0.2727
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73864,
        "msttr-100_nopunct": 0.74619,
        "total_length": 2243,
        "mean_pred_length": 21.160377358490567,
        "std_pred_length": 3.256739869038008,
        "median_pred_length": 21.5,
        "min_pred_length": 14,
        "max_pred_length": 29,
        "distinct-1": 0.42978154257690593,
        "vocab_size-1": 964,
        "unique-1": 747,
        "entropy-1": 8.33587249682264,
        "distinct-2": 0.8656995788488535,
        "vocab_size-2": 1850,
        "unique-2": 1728,
        "entropy-2": 10.650882089489944,
        "cond_entropy-2": 2.2100532654683973,
        "distinct-3": 0.9763663220088626,
        "vocab_size-3": 1983,
        "unique-3": 1946,
        "entropy-3": 10.934730326616643,
        "cond_entropy-3": 0.29599820463860466,
        "total_length-nopunct": 2127,
        "mean_pred_length-nopunct": 20.066037735849058,
        "std_pred_length-nopunct": 3.3145444717456694,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.44945933239304187,
        "vocab_size-1-nopunct": 956,
        "unique-1-nopunct": 745,
        "entropy-1-nopunct": 8.393819216524651,
        "distinct-2-nopunct": 0.867887184562098,
        "vocab_size-2-nopunct": 1754,
        "unique-2-nopunct": 1643,
        "entropy-2-nopunct": 10.571674709315614,
        "cond_entropy-2-nopunct": 2.2591189996746013,
        "distinct-3-nopunct": 0.9801566579634464,
        "vocab_size-3-nopunct": 1877,
        "unique-3-nopunct": 1846,
        "entropy-3-nopunct": 10.85998027447093,
        "cond_entropy-3-nopunct": 0.2982997993482527,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3855992420653719
        },
        "nist": 3.6202931345540077,
        "rouge1": {
            "precision": 0.437,
            "recall": 0.41913,
            "fmeasure": 0.42113
        },
        "rouge2": {
            "precision": 0.18912,
            "recall": 0.18001,
            "fmeasure": 0.18103
        },
        "rougeL": {
            "precision": 0.34302,
            "recall": 0.32872,
            "fmeasure": 0.33032
        },
        "rougeLsum": {
            "precision": 0.34302,
            "recall": 0.32872,
            "fmeasure": 0.33032
        },
        "bleu": 12.46611,
        "meteor": 0.1824451016218764,
        "bertscore": {
            "precision": 0.83702,
            "recall": 0.83018,
            "f1": 0.83327
        },
        "nubia": {
            "semantic_relation": 2.9465,
            "contradiction": 22.03107,
            "irrelevancy": 63.62051,
            "logical_agreement": 14.34842,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.88035,
            "nubia_score": 0.41828
        },
        "bleurt": -0.35966
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.75409,
        "msttr-100_nopunct": 0.75905,
        "total_length": 2236,
        "mean_pred_length": 21.09433962264151,
        "std_pred_length": 3.088408950725375,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.4387298747763864,
        "vocab_size-1": 981,
        "unique-1": 758,
        "entropy-1": 8.427054211844867,
        "distinct-2": 0.8582159624413146,
        "vocab_size-2": 1828,
        "unique-2": 1699,
        "entropy-2": 10.630438438173734,
        "cond_entropy-2": 2.134639792792322,
        "distinct-3": 0.9787549407114624,
        "vocab_size-3": 1981,
        "unique-3": 1947,
        "entropy-3": 10.936240022084489,
        "cond_entropy-3": 0.31575980985516705,
        "total_length-nopunct": 2130,
        "mean_pred_length-nopunct": 20.09433962264151,
        "std_pred_length-nopunct": 3.269436227111186,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4572769953051643,
        "vocab_size-1-nopunct": 974,
        "unique-1-nopunct": 754,
        "entropy-1-nopunct": 8.491642799548512,
        "distinct-2-nopunct": 0.8631422924901185,
        "vocab_size-2-nopunct": 1747,
        "unique-2-nopunct": 1625,
        "entropy-2-nopunct": 10.572292427245717,
        "cond_entropy-2-nopunct": 2.171389796864309,
        "distinct-3-nopunct": 0.9833159541188738,
        "vocab_size-3-nopunct": 1886,
        "unique-3-nopunct": 1858,
        "entropy-3-nopunct": 10.870188999281096,
        "cond_entropy-3-nopunct": 0.3068071991576627,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3617511520737327
        },
        "nist": 3.336849287598163,
        "rouge1": {
            "precision": 0.40827,
            "recall": 0.39015,
            "fmeasure": 0.39303
        },
        "rouge2": {
            "precision": 0.14897,
            "recall": 0.14185,
            "fmeasure": 0.14339
        },
        "rougeL": {
            "precision": 0.3159,
            "recall": 0.29947,
            "fmeasure": 0.30331
        },
        "rougeLsum": {
            "precision": 0.3159,
            "recall": 0.29947,
            "fmeasure": 0.30331
        },
        "bleu": 8.79879,
        "meteor": 0.1730744264170908,
        "bertscore": {
            "precision": 0.82825,
            "recall": 0.82346,
            "f1": 0.82551
        },
        "nubia": {
            "semantic_relation": 2.88521,
            "contradiction": 22.67205,
            "irrelevancy": 61.65583,
            "logical_agreement": 15.67212,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.99572,
            "nubia_score": 0.38656
        },
        "bleurt": -0.42007
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74571,
        "msttr-100_nopunct": 0.764,
        "total_length": 2191,
        "mean_pred_length": 20.669811320754718,
        "std_pred_length": 3.15547352578774,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.42902784116841625,
        "vocab_size-1": 940,
        "unique-1": 716,
        "entropy-1": 8.403503029815049,
        "distinct-2": 0.8484412470023981,
        "vocab_size-2": 1769,
        "unique-2": 1616,
        "entropy-2": 10.604776497403117,
        "cond_entropy-2": 2.0910967716974236,
        "distinct-3": 0.9656392117230924,
        "vocab_size-3": 1911,
        "unique-3": 1860,
        "entropy-3": 10.87367920908033,
        "cond_entropy-3": 0.27465809605734137,
        "total_length-nopunct": 2077,
        "mean_pred_length-nopunct": 19.59433962264151,
        "std_pred_length-nopunct": 3.296019045004719,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4492055849783341,
        "vocab_size-1-nopunct": 933,
        "unique-1-nopunct": 712,
        "entropy-1-nopunct": 8.481902457685017,
        "distinct-2-nopunct": 0.8533739218670725,
        "vocab_size-2-nopunct": 1682,
        "unique-2-nopunct": 1540,
        "entropy-2-nopunct": 10.536556754385785,
        "cond_entropy-2-nopunct": 2.13195889549807,
        "distinct-3-nopunct": 0.9705093833780161,
        "vocab_size-3-nopunct": 1810,
        "unique-3-nopunct": 1767,
        "entropy-3-nopunct": 10.80033293122159,
        "cond_entropy-3-nopunct": 0.264493438017567,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.34988290398126465
        },
        "nist": 3.252531642234832,
        "rouge1": {
            "precision": 0.40813,
            "recall": 0.37903,
            "fmeasure": 0.38591
        },
        "rouge2": {
            "precision": 0.15773,
            "recall": 0.14656,
            "fmeasure": 0.14808
        },
        "rougeL": {
            "precision": 0.30858,
            "recall": 0.28516,
            "fmeasure": 0.29076
        },
        "rougeLsum": {
            "precision": 0.30858,
            "recall": 0.28516,
            "fmeasure": 0.29076
        },
        "bleu": 9.52639,
        "meteor": 0.1677213921886271,
        "bertscore": {
            "precision": 0.82613,
            "recall": 0.81543,
            "f1": 0.82042
        },
        "nubia": {
            "semantic_relation": 2.87723,
            "contradiction": 17.27627,
            "irrelevancy": 68.27207,
            "logical_agreement": 14.45166,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.92299,
            "nubia_score": 0.39473
        },
        "bleurt": -0.42051
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74714,
        "msttr-100_nopunct": 0.7545,
        "total_length": 2196,
        "mean_pred_length": 20.71698113207547,
        "std_pred_length": 3.061491549731595,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.4412568306010929,
        "vocab_size-1": 969,
        "unique-1": 740,
        "entropy-1": 8.42180736157559,
        "distinct-2": 0.8593301435406698,
        "vocab_size-2": 1796,
        "unique-2": 1660,
        "entropy-2": 10.61567234502463,
        "cond_entropy-2": 2.0885639077505647,
        "distinct-3": 0.9747983870967742,
        "vocab_size-3": 1934,
        "unique-3": 1896,
        "entropy-3": 10.896799988320215,
        "cond_entropy-3": 0.2927498926098985,
        "total_length-nopunct": 2086,
        "mean_pred_length-nopunct": 19.67924528301887,
        "std_pred_length-nopunct": 3.2288416341355,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.46021093000958774,
        "vocab_size-1-nopunct": 960,
        "unique-1-nopunct": 739,
        "entropy-1-nopunct": 8.476258534638268,
        "distinct-2-nopunct": 0.8590909090909091,
        "vocab_size-2-nopunct": 1701,
        "unique-2-nopunct": 1574,
        "entropy-2-nopunct": 10.533387970899344,
        "cond_entropy-2-nopunct": 2.1543011218278365,
        "distinct-3-nopunct": 0.9770544290288153,
        "vocab_size-3-nopunct": 1831,
        "unique-3-nopunct": 1796,
        "entropy-3-nopunct": 10.82155063361631,
        "cond_entropy-3-nopunct": 0.29698610994281655,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.341518872214643
        },
        "nist": 3.161542633853981,
        "rouge1": {
            "precision": 0.4128,
            "recall": 0.37205,
            "fmeasure": 0.38694
        },
        "rouge2": {
            "precision": 0.14909,
            "recall": 0.13095,
            "fmeasure": 0.13772
        },
        "rougeL": {
            "precision": 0.31982,
            "recall": 0.28693,
            "fmeasure": 0.2991
        },
        "rougeLsum": {
            "precision": 0.31982,
            "recall": 0.28693,
            "fmeasure": 0.2991
        },
        "bleu": 9.12594,
        "meteor": 0.16267913460794578,
        "bertscore": {
            "precision": 0.8278,
            "recall": 0.81721,
            "f1": 0.82224
        },
        "nubia": {
            "semantic_relation": 2.76623,
            "contradiction": 23.00889,
            "irrelevancy": 64.29255,
            "logical_agreement": 12.69857,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.9583,
            "nubia_score": 0.36771
        },
        "bleurt": -0.4159
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74545,
        "msttr-100_nopunct": 0.75048,
        "total_length": 2253,
        "mean_pred_length": 21.254716981132077,
        "std_pred_length": 3.296829010378595,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 28,
        "distinct-1": 0.43142476697736354,
        "vocab_size-1": 972,
        "unique-1": 732,
        "entropy-1": 8.42986230907651,
        "distinct-2": 0.8579413134606427,
        "vocab_size-2": 1842,
        "unique-2": 1698,
        "entropy-2": 10.651391531538945,
        "cond_entropy-2": 2.145448210170053,
        "distinct-3": 0.9720725134737873,
        "vocab_size-3": 1984,
        "unique-3": 1938,
        "entropy-3": 10.934656639244896,
        "cond_entropy-3": 0.3007010810507999,
        "total_length-nopunct": 2140,
        "mean_pred_length-nopunct": 20.18867924528302,
        "std_pred_length-nopunct": 3.4644099052300428,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4504672897196262,
        "vocab_size-1-nopunct": 964,
        "unique-1-nopunct": 730,
        "entropy-1-nopunct": 8.483988348958132,
        "distinct-2-nopunct": 0.859882005899705,
        "vocab_size-2-nopunct": 1749,
        "unique-2-nopunct": 1614,
        "entropy-2-nopunct": 10.576374501715783,
        "cond_entropy-2-nopunct": 2.17535359389026,
        "distinct-3-nopunct": 0.9740663900414938,
        "vocab_size-3-nopunct": 1878,
        "unique-3-nopunct": 1837,
        "entropy-3-nopunct": 10.856989731712304,
        "cond_entropy-3-nopunct": 0.2975682372498286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.33501374885426216
        },
        "nist": 3.134622364229084,
        "rouge1": {
            "precision": 0.39282,
            "recall": 0.36701,
            "fmeasure": 0.3745
        },
        "rouge2": {
            "precision": 0.15187,
            "recall": 0.14487,
            "fmeasure": 0.14619
        },
        "rougeL": {
            "precision": 0.3139,
            "recall": 0.29281,
            "fmeasure": 0.29892
        },
        "rougeLsum": {
            "precision": 0.3139,
            "recall": 0.29281,
            "fmeasure": 0.29892
        },
        "bleu": 8.9013,
        "meteor": 0.15857882662762723,
        "bertscore": {
            "precision": 0.83106,
            "recall": 0.82285,
            "f1": 0.82665
        },
        "nubia": {
            "semantic_relation": 2.80431,
            "contradiction": 27.17875,
            "irrelevancy": 60.28088,
            "logical_agreement": 12.54037,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.94061,
            "nubia_score": 0.37681
        },
        "bleurt": -0.42476
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73286,
        "msttr-100_nopunct": 0.7355,
        "total_length": 2199,
        "mean_pred_length": 20.745283018867923,
        "std_pred_length": 3.542361755480766,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.41109595270577537,
        "vocab_size-1": 904,
        "unique-1": 692,
        "entropy-1": 8.220127484318285,
        "distinct-2": 0.8256091734352604,
        "vocab_size-2": 1728,
        "unique-2": 1561,
        "entropy-2": 10.513165749015979,
        "cond_entropy-2": 2.218275988669568,
        "distinct-3": 0.9582284851534978,
        "vocab_size-3": 1904,
        "unique-3": 1844,
        "entropy-3": 10.858538397816769,
        "cond_entropy-3": 0.3645841950034196,
        "total_length-nopunct": 2097,
        "mean_pred_length-nopunct": 19.78301886792453,
        "std_pred_length-nopunct": 3.696006812511926,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.42727706247019553,
        "vocab_size-1-nopunct": 896,
        "unique-1-nopunct": 690,
        "entropy-1-nopunct": 8.26306545679385,
        "distinct-2-nopunct": 0.8272225012556504,
        "vocab_size-2-nopunct": 1647,
        "unique-2-nopunct": 1494,
        "entropy-2-nopunct": 10.438780880523526,
        "cond_entropy-2-nopunct": 2.2839381468066295,
        "distinct-3-nopunct": 0.9596816976127321,
        "vocab_size-3-nopunct": 1809,
        "unique-3-nopunct": 1755,
        "entropy-3-nopunct": 10.785044436542465,
        "cond_entropy-3-nopunct": 0.3663340028449387,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3632993512511585
        },
        "nist": 3.299003175922099,
        "rouge1": {
            "precision": 0.42988,
            "recall": 0.39358,
            "fmeasure": 0.40346
        },
        "rouge2": {
            "precision": 0.15669,
            "recall": 0.14151,
            "fmeasure": 0.146
        },
        "rougeL": {
            "precision": 0.33557,
            "recall": 0.30955,
            "fmeasure": 0.31623
        },
        "rougeLsum": {
            "precision": 0.33557,
            "recall": 0.30955,
            "fmeasure": 0.31623
        },
        "bleu": 9.20615,
        "meteor": 0.16607580261539776,
        "bertscore": {
            "precision": 0.83097,
            "recall": 0.82191,
            "f1": 0.826
        },
        "nubia": {
            "semantic_relation": 2.71707,
            "contradiction": 33.52134,
            "irrelevancy": 56.25388,
            "logical_agreement": 10.22478,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.90296,
            "nubia_score": 0.35478
        },
        "bleurt": -0.43431
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74714,
        "msttr-100_nopunct": 0.757,
        "total_length": 2166,
        "mean_pred_length": 20.433962264150942,
        "std_pred_length": 3.5951195112906604,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.4441366574330563,
        "vocab_size-1": 962,
        "unique-1": 727,
        "entropy-1": 8.439809895406265,
        "distinct-2": 0.8737864077669902,
        "vocab_size-2": 1800,
        "unique-2": 1672,
        "entropy-2": 10.647271385212054,
        "cond_entropy-2": 2.1085683801333754,
        "distinct-3": 0.9769703172978506,
        "vocab_size-3": 1909,
        "unique-3": 1874,
        "entropy-3": 10.880227132252235,
        "cond_entropy-3": 0.2343499599655608,
        "total_length-nopunct": 2048,
        "mean_pred_length-nopunct": 19.32075471698113,
        "std_pred_length-nopunct": 3.7806537565120526,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.466796875,
        "vocab_size-1-nopunct": 956,
        "unique-1-nopunct": 725,
        "entropy-1-nopunct": 8.523640274553912,
        "distinct-2-nopunct": 0.8779608650875386,
        "vocab_size-2-nopunct": 1705,
        "unique-2-nopunct": 1591,
        "entropy-2-nopunct": 10.570099938819538,
        "cond_entropy-2-nopunct": 2.1270334439333047,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 1800,
        "unique-3-nopunct": 1768,
        "entropy-3-nopunct": 10.80075746325228,
        "cond_entropy-3-nopunct": 0.2355313310483905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3056462902473168
        },
        "nist": 2.757630782402079,
        "rouge1": {
            "precision": 0.36681,
            "recall": 0.33311,
            "fmeasure": 0.34406
        },
        "rouge2": {
            "precision": 0.11454,
            "recall": 0.10384,
            "fmeasure": 0.107
        },
        "rougeL": {
            "precision": 0.27354,
            "recall": 0.24877,
            "fmeasure": 0.25663
        },
        "rougeLsum": {
            "precision": 0.27354,
            "recall": 0.24877,
            "fmeasure": 0.25663
        },
        "bleu": 5.41007,
        "meteor": 0.14021501530595853,
        "bertscore": {
            "precision": 0.81648,
            "recall": 0.80477,
            "f1": 0.81036
        },
        "nubia": {
            "semantic_relation": 2.5524,
            "contradiction": 30.03087,
            "irrelevancy": 63.23077,
            "logical_agreement": 6.73837,
            "grammar_ref": 3.75874,
            "grammar_hyp": 4.10307,
            "nubia_score": 0.31174
        },
        "bleurt": -0.45839
    },
    "common_gen_validation": {
        "predictions_file": "ByT5-large (Baseline)/common_gen_validation",
        "N": 993,
        "msttr-100": 0.6161,
        "msttr-100_nopunct": 0.64027,
        "total_length": 11887,
        "mean_pred_length": 11.97079556898288,
        "std_pred_length": 3.226924911146173,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.14393875662488434,
        "vocab_size-1": 1711,
        "unique-1": 884,
        "entropy-1": 7.6252451981820055,
        "distinct-2": 0.5189094914631908,
        "vocab_size-2": 5653,
        "unique-2": 4296,
        "entropy-2": 11.448567446717119,
        "cond_entropy-2": 3.5994938223661475,
        "distinct-3": 0.7973942026057974,
        "vocab_size-3": 7895,
        "unique-3": 6987,
        "entropy-3": 12.669481517769245,
        "cond_entropy-3": 1.2896320136711739,
        "total_length-nopunct": 11037,
        "mean_pred_length-nopunct": 11.114803625377643,
        "std_pred_length-nopunct": 3.085703052793167,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.15484280148591104,
        "vocab_size-1-nopunct": 1709,
        "unique-1-nopunct": 884,
        "entropy-1-nopunct": 7.7932866034513015,
        "distinct-2-nopunct": 0.5153325368379131,
        "vocab_size-2-nopunct": 5176,
        "unique-2-nopunct": 3971,
        "entropy-2-nopunct": 11.27484330043308,
        "cond_entropy-2-nopunct": 3.777238593617575,
        "distinct-3-nopunct": 0.7995801568887416,
        "vocab_size-3-nopunct": 7237,
        "unique-3-nopunct": 6441,
        "entropy-3-nopunct": 12.53627472379981,
        "cond_entropy-3-nopunct": 1.3483897613194509,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_validation.json",
        "local_recall": {
            "1": 0.10279965004374453,
            "2": 0.31117021276595747,
            "3": 0.49212775528565,
            "4": 0.7578998541565386,
            "5": 0.7832618025751072,
            "6": 0.8095238095238095,
            "7": 0.8333333333333334,
            "8": 0.8
        },
        "nist": 6.01179782897781,
        "rouge1": {
            "precision": 0.57226,
            "recall": 0.60978,
            "fmeasure": 0.57817
        },
        "rouge2": {
            "precision": 0.23612,
            "recall": 0.25027,
            "fmeasure": 0.23655
        },
        "rougeL": {
            "precision": 0.46688,
            "recall": 0.49664,
            "fmeasure": 0.47129
        },
        "rougeLsum": {
            "precision": 0.46688,
            "recall": 0.49664,
            "fmeasure": 0.47129
        },
        "bleu": 17.35264,
        "meteor": 0.24119580096874346,
        "bertscore": {
            "precision": 0.8616,
            "recall": 0.87138,
            "f1": 0.86485
        },
        "nubia": {
            "semantic_relation": 2.94283,
            "contradiction": 30.91688,
            "irrelevancy": 40.9354,
            "logical_agreement": 28.14772,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.98521,
            "nubia_score": 0.36313
        },
        "bleurt": -0.63991
    },
    "common_gen_test": {
        "predictions_file": "ByT5-large (Baseline)/common_gen_test",
        "N": 1497
    },
    "common_gen_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/common_gen_challenge_train_sample",
        "N": 500
    },
    "common_gen_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/common_gen_challenge_validation_sample",
        "N": 500
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "ByT5-large (Baseline)/common_gen_challenge_test_scramble",
        "N": 500
    },
    "mlsum_de_validation": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_de_validation",
        "N": 11392,
        "msttr-100": 0.7574,
        "msttr-100_nopunct": 0.78887,
        "total_length": 227149,
        "mean_pred_length": 19.939343398876403,
        "std_pred_length": 2.61972929734102,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.13651391817705558,
        "vocab_size-1": 31009,
        "unique-1": 19484,
        "entropy-1": 10.390446720730967,
        "distinct-2": 0.5288078718187591,
        "vocab_size-2": 114094,
        "unique-2": 93197,
        "entropy-2": 15.394878599781816,
        "cond_entropy-2": 5.0853643161582065,
        "distinct-3": 0.8193379492574561,
        "vocab_size-3": 167444,
        "unique-3": 153453,
        "entropy-3": 16.99904967051852,
        "cond_entropy-3": 1.666997030852782,
        "total_length-nopunct": 207896,
        "mean_pred_length-nopunct": 18.24929775280899,
        "std_pred_length-nopunct": 2.397183403683128,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.14909858775541618,
        "vocab_size-1-nopunct": 30997,
        "unique-1-nopunct": 19483,
        "entropy-1-nopunct": 10.753169681744945,
        "distinct-2-nopunct": 0.5803087977852868,
        "vocab_size-2-nopunct": 114033,
        "unique-2-nopunct": 94662,
        "entropy-2-nopunct": 15.727876894338614,
        "cond_entropy-2-nopunct": 5.1382204444450466,
        "distinct-3-nopunct": 0.8598578158088076,
        "vocab_size-3-nopunct": 159170,
        "unique-3-nopunct": 148219,
        "entropy-3-nopunct": 17.035445289955785,
        "cond_entropy-3-nopunct": 1.3769962896323729,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_validation.json",
        "local_recall": {
            "1": 0.35688312730775407
        },
        "nist": 5.276444799401546,
        "rouge1": {
            "precision": 0.46094,
            "recall": 0.35868,
            "fmeasure": 0.39733
        },
        "rouge2": {
            "precision": 0.33778,
            "recall": 0.25204,
            "fmeasure": 0.28478
        },
        "rougeL": {
            "precision": 0.42158,
            "recall": 0.32626,
            "fmeasure": 0.3624
        },
        "rougeLsum": {
            "precision": 0.42158,
            "recall": 0.32626,
            "fmeasure": 0.3624
        },
        "bleu": 25.61408,
        "meteor": 0.3090045308818097,
        "bertscore": {
            "precision": 0.89322,
            "recall": 0.87307,
            "f1": 0.88284
        },
        "nubia": {
            "semantic_relation": 2.38191,
            "contradiction": 24.88597,
            "irrelevancy": 42.44562,
            "logical_agreement": 32.66841,
            "grammar_ref": 5.04919,
            "grammar_hyp": 5.10008,
            "nubia_score": 0.28126
        },
        "bleurt": -0.44924
    },
    "schema_guided_dialog_test": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_test",
        "N": 10000,
        "msttr-100": 0.69053,
        "msttr-100_nopunct": 0.71644,
        "total_length": 127556,
        "mean_pred_length": 12.7556,
        "std_pred_length": 6.655093435857982,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 33,
        "distinct-1": 0.034737683840822854,
        "vocab_size-1": 4431,
        "unique-1": 1933,
        "entropy-1": 8.1237111210327,
        "distinct-2": 0.1579077205757256,
        "vocab_size-2": 18563,
        "unique-2": 10228,
        "entropy-2": 11.82895278891184,
        "cond_entropy-2": 3.4707518697624935,
        "distinct-3": 0.3339655621257763,
        "vocab_size-3": 35920,
        "unique-3": 23987,
        "entropy-3": 13.536893459534857,
        "cond_entropy-3": 1.7373067271466578,
        "total_length-nopunct": 112585,
        "mean_pred_length-nopunct": 11.2585,
        "std_pred_length-nopunct": 6.190854363494589,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.03918816893902385,
        "vocab_size-1-nopunct": 4412,
        "unique-1-nopunct": 1929,
        "entropy-1-nopunct": 8.330421531270215,
        "distinct-2-nopunct": 0.17383633084758982,
        "vocab_size-2-nopunct": 17833,
        "unique-2-nopunct": 10266,
        "entropy-2-nopunct": 11.741606551900063,
        "cond_entropy-2-nopunct": 3.564021032690462,
        "distinct-3-nopunct": 0.3583030931397961,
        "vocab_size-3-nopunct": 33176,
        "unique-3-nopunct": 22921,
        "entropy-3-nopunct": 13.42986307286542,
        "cond_entropy-3-nopunct": 1.7532181153914137,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5562042887484782
        },
        "nist": 6.733946644879905,
        "rouge1": {
            "precision": 0.56767,
            "recall": 0.54766,
            "fmeasure": 0.54548
        },
        "rouge2": {
            "precision": 0.34873,
            "recall": 0.33579,
            "fmeasure": 0.33419
        },
        "rougeL": {
            "precision": 0.50736,
            "recall": 0.48938,
            "fmeasure": 0.48746
        },
        "rougeLsum": {
            "precision": 0.50736,
            "recall": 0.48938,
            "fmeasure": 0.48746
        },
        "bleu": 30.64736,
        "meteor": 0.30818682501510575,
        "bertscore": {
            "precision": 0.86811,
            "recall": 0.86348,
            "f1": 0.86525
        },
        "nubia": {
            "semantic_relation": 3.61111,
            "contradiction": 6.06327,
            "irrelevancy": 24.45931,
            "logical_agreement": 69.47742,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.62097,
            "nubia_score": 0.63718
        },
        "bleurt": -0.09931
    },
    "schema_guided_dialog_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_challenge_train_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.68125,
        "msttr-100_nopunct": 0.715,
        "total_length": 6414,
        "mean_pred_length": 12.828,
        "std_pred_length": 6.689575173357423,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.15887121920798253,
        "vocab_size-1": 1019,
        "unique-1": 582,
        "entropy-1": 7.806922255509911,
        "distinct-2": 0.49222184646601286,
        "vocab_size-2": 2911,
        "unique-2": 2050,
        "entropy-2": 10.720662846635452,
        "cond_entropy-2": 2.682427307378014,
        "distinct-3": 0.7137052087181381,
        "vocab_size-3": 3864,
        "unique-3": 3210,
        "entropy-3": 11.532829107663348,
        "cond_entropy-3": 0.8375616389212549,
        "total_length-nopunct": 5645,
        "mean_pred_length-nopunct": 11.29,
        "std_pred_length-nopunct": 6.212398892537406,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.17821080602302922,
        "vocab_size-1-nopunct": 1006,
        "unique-1-nopunct": 579,
        "entropy-1-nopunct": 7.983708611715745,
        "distinct-2-nopunct": 0.5105928085519922,
        "vocab_size-2-nopunct": 2627,
        "unique-2-nopunct": 1904,
        "entropy-2-nopunct": 10.5637981018717,
        "cond_entropy-2-nopunct": 2.718952823147117,
        "distinct-3-nopunct": 0.7259418729817008,
        "vocab_size-3-nopunct": 3372,
        "unique-3-nopunct": 2849,
        "entropy-3-nopunct": 11.329204612171965,
        "cond_entropy-3-nopunct": 0.8156726362124461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.5548961424332344
        },
        "nist": 5.71324806449662,
        "rouge1": {
            "precision": 0.54892,
            "recall": 0.54877,
            "fmeasure": 0.5364
        },
        "rouge2": {
            "precision": 0.33109,
            "recall": 0.33173,
            "fmeasure": 0.32307
        },
        "rougeL": {
            "precision": 0.48791,
            "recall": 0.48787,
            "fmeasure": 0.47675
        },
        "rougeLsum": {
            "precision": 0.48791,
            "recall": 0.48787,
            "fmeasure": 0.47675
        },
        "bleu": 30.01831,
        "meteor": 0.308807116859604,
        "bertscore": {
            "precision": 0.8657,
            "recall": 0.86462,
            "f1": 0.86464
        },
        "nubia": {
            "semantic_relation": 3.6099,
            "contradiction": 6.01407,
            "irrelevancy": 25.56404,
            "logical_agreement": 68.42189,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.48553,
            "nubia_score": 0.64514
        },
        "bleurt": -0.09793
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "msttr-100": 0.6973,
        "msttr-100_nopunct": 0.72107,
        "total_length": 6346,
        "mean_pred_length": 12.692,
        "std_pred_length": 6.804787726299771,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.15616136148755122,
        "vocab_size-1": 991,
        "unique-1": 541,
        "entropy-1": 7.859643829686605,
        "distinct-2": 0.4827232295586726,
        "vocab_size-2": 2822,
        "unique-2": 1952,
        "entropy-2": 10.704114442572681,
        "cond_entropy-2": 2.6345470341522934,
        "distinct-3": 0.7003367003367004,
        "vocab_size-3": 3744,
        "unique-3": 3052,
        "entropy-3": 11.507485331552985,
        "cond_entropy-3": 0.8268362345548494,
        "total_length-nopunct": 5620,
        "mean_pred_length-nopunct": 11.24,
        "std_pred_length-nopunct": 6.372315120896015,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.17384341637010675,
        "vocab_size-1-nopunct": 977,
        "unique-1-nopunct": 537,
        "entropy-1-nopunct": 8.016567885025848,
        "distinct-2-nopunct": 0.4986328125,
        "vocab_size-2-nopunct": 2553,
        "unique-2-nopunct": 1806,
        "entropy-2-nopunct": 10.554135413835708,
        "cond_entropy-2-nopunct": 2.669632135367492,
        "distinct-3-nopunct": 0.7149967539493616,
        "vocab_size-3-nopunct": 3304,
        "unique-3-nopunct": 2740,
        "entropy-3-nopunct": 11.32751417508083,
        "cond_entropy-3-nopunct": 0.816629792576474,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "local_recall": {
            "1": 0.5574341990587415
        },
        "nist": 6.1146099513289345,
        "rouge1": {
            "precision": 0.57533,
            "recall": 0.54075,
            "fmeasure": 0.54658
        },
        "rouge2": {
            "precision": 0.36391,
            "recall": 0.33944,
            "fmeasure": 0.34376
        },
        "rougeL": {
            "precision": 0.51684,
            "recall": 0.48496,
            "fmeasure": 0.49073
        },
        "rougeLsum": {
            "precision": 0.51684,
            "recall": 0.48496,
            "fmeasure": 0.49073
        },
        "bleu": 31.35649,
        "meteor": 0.31196434437147036,
        "bertscore": {
            "precision": 0.87051,
            "recall": 0.86023,
            "f1": 0.86487
        },
        "nubia": {
            "semantic_relation": 3.59225,
            "contradiction": 6.21708,
            "irrelevancy": 22.41852,
            "logical_agreement": 71.3644,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.70179,
            "nubia_score": 0.63194
        },
        "bleurt": -0.11075
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "msttr-100": 0.69656,
        "msttr-100_nopunct": 0.71963,
        "total_length": 6133,
        "mean_pred_length": 12.266,
        "std_pred_length": 6.378968882194049,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 29,
        "distinct-1": 0.1632153921408772,
        "vocab_size-1": 1001,
        "unique-1": 565,
        "entropy-1": 7.825422971890117,
        "distinct-2": 0.4931652760518374,
        "vocab_size-2": 2778,
        "unique-2": 1972,
        "entropy-2": 10.646228813356283,
        "cond_entropy-2": 2.5844657171294383,
        "distinct-3": 0.7106954997077732,
        "vocab_size-3": 3648,
        "unique-3": 3039,
        "entropy-3": 11.432202170554957,
        "cond_entropy-3": 0.8074712553966581,
        "total_length-nopunct": 5419,
        "mean_pred_length-nopunct": 10.838,
        "std_pred_length-nopunct": 5.9548094847778295,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.1825059974164975,
        "vocab_size-1-nopunct": 989,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 7.998884258000625,
        "distinct-2-nopunct": 0.5078267940638341,
        "vocab_size-2-nopunct": 2498,
        "unique-2-nopunct": 1815,
        "entropy-2-nopunct": 10.474921631975857,
        "cond_entropy-2-nopunct": 2.6005819240491057,
        "distinct-3-nopunct": 0.7218827789092555,
        "vocab_size-3-nopunct": 3190,
        "unique-3-nopunct": 2703,
        "entropy-3-nopunct": 11.233171272749054,
        "cond_entropy-3-nopunct": 0.8019019014490167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "local_recall": {
            "1": 0.5608281421766215
        },
        "nist": 5.997748067598152,
        "rouge1": {
            "precision": 0.57305,
            "recall": 0.54876,
            "fmeasure": 0.54948
        },
        "rouge2": {
            "precision": 0.35609,
            "recall": 0.33929,
            "fmeasure": 0.33986
        },
        "rougeL": {
            "precision": 0.51541,
            "recall": 0.49215,
            "fmeasure": 0.49345
        },
        "rougeLsum": {
            "precision": 0.51541,
            "recall": 0.49215,
            "fmeasure": 0.49345
        },
        "bleu": 31.57311,
        "meteor": 0.3116141725329493,
        "bertscore": {
            "precision": 0.86625,
            "recall": 0.86206,
            "f1": 0.86365
        },
        "nubia": {
            "semantic_relation": 3.58847,
            "contradiction": 6.20419,
            "irrelevancy": 25.14734,
            "logical_agreement": 68.64847,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.66991,
            "nubia_score": 0.63246
        },
        "bleurt": -0.12476
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.72855,
        "total_length": 6142,
        "mean_pred_length": 12.284,
        "std_pred_length": 6.265089305029897,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.1729078476066428,
        "vocab_size-1": 1062,
        "unique-1": 600,
        "entropy-1": 8.050892173104163,
        "distinct-2": 0.5136476426799007,
        "vocab_size-2": 2898,
        "unique-2": 2088,
        "entropy-2": 10.761904276517596,
        "cond_entropy-2": 2.674143226143754,
        "distinct-3": 0.7269544924154026,
        "vocab_size-3": 3738,
        "unique-3": 3111,
        "entropy-3": 11.529588439541731,
        "cond_entropy-3": 0.8083506067796516,
        "total_length-nopunct": 5582,
        "mean_pred_length-nopunct": 11.164,
        "std_pred_length-nopunct": 5.861834525129484,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.18774632748118955,
        "vocab_size-1-nopunct": 1048,
        "unique-1-nopunct": 596,
        "entropy-1-nopunct": 8.128106301014078,
        "distinct-2-nopunct": 0.5304998032270759,
        "vocab_size-2-nopunct": 2696,
        "unique-2-nopunct": 1983,
        "entropy-2-nopunct": 10.650675982715457,
        "cond_entropy-2-nopunct": 2.6433292469632437,
        "distinct-3-nopunct": 0.7446529899607158,
        "vocab_size-3-nopunct": 3412,
        "unique-3-nopunct": 2886,
        "entropy-3-nopunct": 11.411467343623205,
        "cond_entropy-3-nopunct": 0.7906346073348205,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.5268107573007754
        },
        "nist": 5.64703723792168,
        "rouge1": {
            "precision": 0.57074,
            "recall": 0.51538,
            "fmeasure": 0.52898
        },
        "rouge2": {
            "precision": 0.35033,
            "recall": 0.31597,
            "fmeasure": 0.32425
        },
        "rougeL": {
            "precision": 0.50389,
            "recall": 0.45613,
            "fmeasure": 0.46768
        },
        "rougeLsum": {
            "precision": 0.50389,
            "recall": 0.45613,
            "fmeasure": 0.46768
        },
        "bleu": 27.77637,
        "meteor": 0.2926604828167876,
        "bertscore": {
            "precision": 0.86272,
            "recall": 0.84656,
            "f1": 0.85405
        },
        "nubia": {
            "semantic_relation": 3.56795,
            "contradiction": 6.858,
            "irrelevancy": 22.12677,
            "logical_agreement": 71.01523,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.92681,
            "nubia_score": 0.59717
        },
        "bleurt": -0.17083
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "ByT5-large (Baseline)/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.68719,
        "msttr-100_nopunct": 0.71439,
        "total_length": 6464,
        "mean_pred_length": 12.928,
        "std_pred_length": 6.590509540240421,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 32,
        "distinct-1": 0.15717821782178218,
        "vocab_size-1": 1016,
        "unique-1": 562,
        "entropy-1": 7.853443676053598,
        "distinct-2": 0.48876592890677395,
        "vocab_size-2": 2915,
        "unique-2": 2031,
        "entropy-2": 10.746667986098066,
        "cond_entropy-2": 2.679495564147151,
        "distinct-3": 0.7154099560761347,
        "vocab_size-3": 3909,
        "unique-3": 3219,
        "entropy-3": 11.583933744777346,
        "cond_entropy-3": 0.8743920106985678,
        "total_length-nopunct": 5708,
        "mean_pred_length-nopunct": 11.416,
        "std_pred_length-nopunct": 6.123964728833764,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.1760686755430974,
        "vocab_size-1-nopunct": 1005,
        "unique-1-nopunct": 559,
        "entropy-1-nopunct": 8.032005878902801,
        "distinct-2-nopunct": 0.5053763440860215,
        "vocab_size-2-nopunct": 2632,
        "unique-2-nopunct": 1880,
        "entropy-2-nopunct": 10.583691327404225,
        "cond_entropy-2-nopunct": 2.6917268147453743,
        "distinct-3-nopunct": 0.7262688468889361,
        "vocab_size-3-nopunct": 3420,
        "unique-3-nopunct": 2861,
        "entropy-3-nopunct": 11.381875518310965,
        "cond_entropy-3-nopunct": 0.8541644086880299,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.5487867836861126
        },
        "nist": 5.91709063982142,
        "rouge1": {
            "precision": 0.57065,
            "recall": 0.54224,
            "fmeasure": 0.54346
        },
        "rouge2": {
            "precision": 0.34735,
            "recall": 0.32576,
            "fmeasure": 0.32743
        },
        "rougeL": {
            "precision": 0.50304,
            "recall": 0.47781,
            "fmeasure": 0.47877
        },
        "rougeLsum": {
            "precision": 0.50304,
            "recall": 0.47781,
            "fmeasure": 0.47877
        },
        "bleu": 29.6439,
        "meteor": 0.30255125331563687,
        "bertscore": {
            "precision": 0.86501,
            "recall": 0.858,
            "f1": 0.86097
        },
        "nubia": {
            "semantic_relation": 3.55404,
            "contradiction": 5.98171,
            "irrelevancy": 23.96611,
            "logical_agreement": 70.05218,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.62478,
            "nubia_score": 0.62274
        },
        "bleurt": -0.13791
    },
    "totto_validation": {
        "predictions_file": "ByT5-large (Baseline)/totto_validation",
        "N": 7700,
        "msttr-100": 0.72136,
        "msttr-100_nopunct": 0.77082,
        "total_length": 124455,
        "mean_pred_length": 16.162987012987013,
        "std_pred_length": 5.40935278672596,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 42,
        "distinct-1": 0.17353260214535374,
        "vocab_size-1": 21597,
        "unique-1": 14858,
        "entropy-1": 10.041123070457415,
        "distinct-2": 0.5356430131471885,
        "vocab_size-2": 62539,
        "unique-2": 52469,
        "entropy-2": 14.466904647886317,
        "cond_entropy-2": 4.087488376086612,
        "distinct-3": 0.7584980055935079,
        "vocab_size-3": 82718,
        "unique-3": 75216,
        "entropy-3": 15.754372874583083,
        "cond_entropy-3": 1.2969225031082832,
        "total_length-nopunct": 108810,
        "mean_pred_length-nopunct": 14.13116883116883,
        "std_pred_length-nopunct": 4.817035779270148,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.19830897895414024,
        "vocab_size-1-nopunct": 21578,
        "unique-1-nopunct": 14855,
        "entropy-1-nopunct": 10.566056222697108,
        "distinct-2-nopunct": 0.5761151221441994,
        "vocab_size-2-nopunct": 58251,
        "unique-2-nopunct": 49952,
        "entropy-2-nopunct": 14.444687877346569,
        "cond_entropy-2-nopunct": 4.072705235659785,
        "distinct-3-nopunct": 0.7833422545765978,
        "vocab_size-3-nopunct": 73172,
        "unique-3-nopunct": 67316,
        "entropy-3-nopunct": 15.638414548406704,
        "cond_entropy-3-nopunct": 1.2929320927755747,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_validation.json",
        "local_recall": {
            "1": 0.2269031781226903,
            "2": 0.4538710373086047,
            "3": 0.7620634781410152
        },
        "nist": 10.701046817825205,
        "rouge1": {
            "precision": 0.7519,
            "recall": 0.73005,
            "fmeasure": 0.72943
        },
        "rouge2": {
            "precision": 0.53156,
            "recall": 0.51657,
            "fmeasure": 0.51568
        },
        "rougeL": {
            "precision": 0.65455,
            "recall": 0.63924,
            "fmeasure": 0.63668
        },
        "rougeLsum": {
            "precision": 0.65455,
            "recall": 0.63924,
            "fmeasure": 0.63668
        },
        "bleu": 46.27825,
        "meteor": 0.3892618916697249,
        "bertscore": {
            "precision": 0.92701,
            "recall": 0.92373,
            "f1": 0.92374
        },
        "nubia": {
            "semantic_relation": 4.14876,
            "contradiction": 9.56314,
            "irrelevancy": 31.15273,
            "logical_agreement": 59.28413,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.56964,
            "nubia_score": 0.72376
        },
        "bleurt": 0.26137
    },
    "xsum_validation": {
        "predictions_file": "ByT5-large (Baseline)/xsum_validation",
        "N": 1117,
        "msttr-100": 0.74043,
        "msttr-100_nopunct": 0.7514,
        "total_length": 23483,
        "mean_pred_length": 21.023276633840645,
        "std_pred_length": 3.332296963147185,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.20380700932589532,
        "vocab_size-1": 4786,
        "unique-1": 2821,
        "entropy-1": 9.317780061290074,
        "distinct-2": 0.6505857104533668,
        "vocab_size-2": 14551,
        "unique-2": 12135,
        "entropy-2": 13.103687644745802,
        "cond_entropy-2": 3.67641761146671,
        "distinct-3": 0.8818767942020801,
        "vocab_size-3": 18739,
        "unique-3": 17507,
        "entropy-3": 14.03400888577898,
        "cond_entropy-3": 0.9529400750097222,
        "total_length-nopunct": 22260,
        "mean_pred_length-nopunct": 19.928379588182633,
        "std_pred_length-nopunct": 3.409433220559721,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.21455525606469003,
        "vocab_size-1-nopunct": 4776,
        "unique-1-nopunct": 2821,
        "entropy-1-nopunct": 9.429091123291258,
        "distinct-2-nopunct": 0.6563874568415078,
        "vocab_size-2-nopunct": 13878,
        "unique-2-nopunct": 11632,
        "entropy-2-nopunct": 13.039562185222868,
        "cond_entropy-2-nopunct": 3.738358944395286,
        "distinct-3-nopunct": 0.8886447618096475,
        "vocab_size-3-nopunct": 17796,
        "unique-3-nopunct": 16685,
        "entropy-3-nopunct": 13.97191365197885,
        "cond_entropy-3-nopunct": 0.9582338869475876,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_validation.json",
        "local_recall": {
            "1": 0.34355800505963136
        },
        "nist": 3.6392854032955446,
        "rouge1": {
            "precision": 0.3893,
            "recall": 0.37033,
            "fmeasure": 0.37327
        },
        "rouge2": {
            "precision": 0.14675,
            "recall": 0.13878,
            "fmeasure": 0.14016
        },
        "rougeL": {
            "precision": 0.30204,
            "recall": 0.28762,
            "fmeasure": 0.28973
        },
        "rougeLsum": {
            "precision": 0.30204,
            "recall": 0.28762,
            "fmeasure": 0.28973
        },
        "bleu": 9.09438,
        "meteor": 0.1624581101670463,
        "bertscore": {
            "precision": 0.8253,
            "recall": 0.81806,
            "f1": 0.82139
        },
        "nubia": {
            "semantic_relation": 2.75508,
            "contradiction": 22.83223,
            "irrelevancy": 65.37337,
            "logical_agreement": 11.79441,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.95081,
            "nubia_score": 0.37077
        },
        "bleurt": -0.42348
    },
    "xsum_test": {
        "predictions_file": "ByT5-large (Baseline)/xsum_test",
        "N": 1166,
        "msttr-100": 0.74231,
        "msttr-100_nopunct": 0.75413,
        "total_length": 24288,
        "mean_pred_length": 20.830188679245282,
        "std_pred_length": 3.3644261154294974,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.2054512516469038,
        "vocab_size-1": 4990,
        "unique-1": 2983,
        "entropy-1": 9.351469652534345,
        "distinct-2": 0.6509385001297465,
        "vocab_size-2": 15051,
        "unique-2": 12560,
        "entropy-2": 13.138869704992711,
        "cond_entropy-2": 3.6749346007316164,
        "distinct-3": 0.8808526143195482,
        "vocab_size-3": 19340,
        "unique-3": 18063,
        "entropy-3": 14.076207122515834,
        "cond_entropy-3": 0.9615797818237871,
        "total_length-nopunct": 23047,
        "mean_pred_length-nopunct": 19.765866209262434,
        "std_pred_length-nopunct": 3.5116910201304794,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.2159934047815334,
        "vocab_size-1-nopunct": 4978,
        "unique-1-nopunct": 2980,
        "entropy-1-nopunct": 9.465347297620958,
        "distinct-2-nopunct": 0.6571454686714501,
        "vocab_size-2-nopunct": 14379,
        "unique-2-nopunct": 12059,
        "entropy-2-nopunct": 13.078540635836422,
        "cond_entropy-2-nopunct": 3.7418721860093167,
        "distinct-3-nopunct": 0.8880521361332367,
        "vocab_size-3-nopunct": 18396,
        "unique-3-nopunct": 17250,
        "entropy-3-nopunct": 14.017258915328421,
        "cond_entropy-3-nopunct": 0.9660953318947062,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.34298032185085586
        },
        "nist": 3.6788240292838834,
        "rouge1": {
            "precision": 0.39651,
            "recall": 0.37396,
            "fmeasure": 0.3783
        },
        "rouge2": {
            "precision": 0.14872,
            "recall": 0.14033,
            "fmeasure": 0.14182
        },
        "rougeL": {
            "precision": 0.30827,
            "recall": 0.29067,
            "fmeasure": 0.29412
        },
        "rougeLsum": {
            "precision": 0.30827,
            "recall": 0.29067,
            "fmeasure": 0.29412
        },
        "bleu": 9.29644,
        "meteor": 0.1618434364757871,
        "bertscore": {
            "precision": 0.82573,
            "recall": 0.81812,
            "f1": 0.82159
        },
        "nubia": {
            "semantic_relation": 2.74792,
            "contradiction": 25.44296,
            "irrelevancy": 63.54192,
            "logical_agreement": 11.01512,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.9533,
            "nubia_score": 0.3663
        },
        "bleurt": -0.42026
    },
    "xsum_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/xsum_challenge_train_sample",
        "N": 500
    },
    "xsum_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/xsum_challenge_validation_sample",
        "N": 500
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "ByT5-large (Baseline)/xsum_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.73755,
        "msttr-100_nopunct": 0.74584,
        "total_length": 10611,
        "mean_pred_length": 21.222,
        "std_pred_length": 3.150351726395007,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.28008670247856,
        "vocab_size-1": 2972,
        "unique-1": 1940,
        "entropy-1": 9.088558793313423,
        "distinct-2": 0.7361289684502027,
        "vocab_size-2": 7443,
        "unique-2": 6514,
        "entropy-2": 12.359858584245304,
        "cond_entropy-2": 3.2114148911312035,
        "distinct-3": 0.929039642076787,
        "vocab_size-3": 8929,
        "unique-3": 8537,
        "entropy-3": 13.04256507148915,
        "cond_entropy-3": 0.7048821186512905,
        "total_length-nopunct": 10116,
        "mean_pred_length-nopunct": 20.232,
        "std_pred_length-nopunct": 3.307291338845128,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.2929023329379201,
        "vocab_size-1-nopunct": 2963,
        "unique-1-nopunct": 1940,
        "entropy-1-nopunct": 9.161359305736472,
        "distinct-2-nopunct": 0.7407445923460898,
        "vocab_size-2-nopunct": 7123,
        "unique-2-nopunct": 6263,
        "entropy-2-nopunct": 12.296930162930833,
        "cond_entropy-2-nopunct": 3.256434290650122,
        "distinct-3-nopunct": 0.9329749890302764,
        "vocab_size-3-nopunct": 8505,
        "unique-3-nopunct": 8144,
        "entropy-3-nopunct": 12.981730584403376,
        "cond_entropy-3-nopunct": 0.7087502449393679,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.3038512079247953
        },
        "nist": 2.9173857304334527,
        "rouge1": {
            "precision": 0.34186,
            "recall": 0.33034,
            "fmeasure": 0.3297
        },
        "rouge2": {
            "precision": 0.10473,
            "recall": 0.10147,
            "fmeasure": 0.101
        },
        "rougeL": {
            "precision": 0.2615,
            "recall": 0.25403,
            "fmeasure": 0.25277
        },
        "rougeLsum": {
            "precision": 0.2615,
            "recall": 0.25403,
            "fmeasure": 0.25277
        },
        "bleu": 6.25841,
        "meteor": 0.13846102146569472,
        "bertscore": {
            "precision": 0.80674,
            "recall": 0.80249,
            "f1": 0.8043
        },
        "nubia": {
            "semantic_relation": 2.38667,
            "contradiction": 26.4434,
            "irrelevancy": 65.17833,
            "logical_agreement": 8.37828,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.15016,
            "nubia_score": 0.28721
        },
        "bleurt": -0.54698
    },
    "totto_test": {
        "predictions_file": "ByT5-large (Baseline)/totto_test",
        "N": 7700,
        "msttr-100": 0.72424,
        "msttr-100_nopunct": 0.77371,
        "total_length": 123487,
        "mean_pred_length": 16.03727272727273,
        "std_pred_length": 5.337326325253423,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 37,
        "distinct-1": 0.1737186910363034,
        "vocab_size-1": 21452,
        "unique-1": 14811,
        "entropy-1": 10.038088314177347,
        "distinct-2": 0.5358287199771995,
        "vocab_size-2": 62042,
        "unique-2": 52029,
        "entropy-2": 14.458090701400948,
        "cond_entropy-2": 4.081473692880585,
        "distinct-3": 0.7573528731484822,
        "vocab_size-3": 81860,
        "unique-3": 74219,
        "entropy-3": 15.746982054775282,
        "cond_entropy-3": 1.2934041107494323,
        "total_length-nopunct": 108143,
        "mean_pred_length-nopunct": 14.044545454545455,
        "std_pred_length-nopunct": 4.789703796241067,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.19820053077869118,
        "vocab_size-1-nopunct": 21434,
        "unique-1-nopunct": 14810,
        "entropy-1-nopunct": 10.557042471677637,
        "distinct-2-nopunct": 0.5757792977111397,
        "vocab_size-2-nopunct": 57833,
        "unique-2-nopunct": 49505,
        "entropy-2-nopunct": 14.44122795863442,
        "cond_entropy-2-nopunct": 4.07762163975135,
        "distinct-3-nopunct": 0.7819997196553918,
        "vocab_size-3-nopunct": 72525,
        "unique-3-nopunct": 66491,
        "entropy-3-nopunct": 15.636585521413393,
        "cond_entropy-3-nopunct": 1.2933885107659109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2266407231748348,
            "2": 0.45588874402433727,
            "3": 0.7626152261824027
        },
        "nist": 10.688761966400081,
        "rouge1": {
            "precision": 0.75437,
            "recall": 0.72908,
            "fmeasure": 0.72977
        },
        "rouge2": {
            "precision": 0.53169,
            "recall": 0.51499,
            "fmeasure": 0.51452
        },
        "rougeL": {
            "precision": 0.65629,
            "recall": 0.63837,
            "fmeasure": 0.63663
        },
        "rougeLsum": {
            "precision": 0.65629,
            "recall": 0.63837,
            "fmeasure": 0.63663
        },
        "bleu": 46.11117,
        "meteor": 0.389225495687798,
        "bertscore": {
            "precision": 0.92765,
            "recall": 0.92372,
            "f1": 0.924
        },
        "nubia": {
            "semantic_relation": 4.14819,
            "contradiction": 9.77193,
            "irrelevancy": 30.67716,
            "logical_agreement": 59.55092,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.59059,
            "nubia_score": 0.72139
        },
        "bleurt": 0.26261
    },
    "totto_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/totto_challenge_train_sample",
        "N": 500
    },
    "totto_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/totto_challenge_validation_sample",
        "N": 500
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "ByT5-large (Baseline)/totto_challenge_test_scramble",
        "N": 378
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "ByT5-large (Baseline)/xsum_challenge_test_bfp_02",
        "N": 500,
        "msttr-100": 0.73562,
        "msttr-100_nopunct": 0.74879,
        "total_length": 10534,
        "mean_pred_length": 21.068,
        "std_pred_length": 3.5041940585532645,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.2775773685209797,
        "vocab_size-1": 2924,
        "unique-1": 1932,
        "entropy-1": 9.0281868019011,
        "distinct-2": 0.7152680884991031,
        "vocab_size-2": 7177,
        "unique-2": 6179,
        "entropy-2": 12.268666030051476,
        "cond_entropy-2": 3.1351994522278908,
        "distinct-3": 0.9124187119781834,
        "vocab_size-3": 8699,
        "unique-3": 8225,
        "entropy-3": 12.986283434799487,
        "cond_entropy-3": 0.739677814057267,
        "total_length-nopunct": 9994,
        "mean_pred_length-nopunct": 19.988,
        "std_pred_length-nopunct": 3.6155021781213192,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.29157494496698017,
        "vocab_size-1-nopunct": 2914,
        "unique-1-nopunct": 1931,
        "entropy-1-nopunct": 9.123762102499576,
        "distinct-2-nopunct": 0.7194017274067832,
        "vocab_size-2-nopunct": 6830,
        "unique-2-nopunct": 5903,
        "entropy-2-nopunct": 12.19675724933724,
        "cond_entropy-2-nopunct": 3.1906586795175444,
        "distinct-3-nopunct": 0.916833444518568,
        "vocab_size-3-nopunct": 8246,
        "unique-3-nopunct": 7822,
        "entropy-3-nopunct": 12.91628262906568,
        "cond_entropy-3-nopunct": 0.7447350913962631,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "local_recall": {
            "1": 0.33409270998415214
        },
        "nist": 3.38609607343216,
        "rouge1": {
            "precision": 0.38678,
            "recall": 0.36746,
            "fmeasure": 0.37068
        },
        "rouge2": {
            "precision": 0.13819,
            "recall": 0.131,
            "fmeasure": 0.1322
        },
        "rougeL": {
            "precision": 0.30205,
            "recall": 0.28807,
            "fmeasure": 0.29008
        },
        "rougeLsum": {
            "precision": 0.30205,
            "recall": 0.28807,
            "fmeasure": 0.29008
        },
        "bleu": 8.583,
        "meteor": 0.15641817900047597,
        "bertscore": {
            "precision": 0.82085,
            "recall": 0.81414,
            "f1": 0.8172
        },
        "nubia": {
            "semantic_relation": 2.70462,
            "contradiction": 24.08986,
            "irrelevancy": 64.62231,
            "logical_agreement": 11.28784,
            "grammar_ref": 3.74155,
            "grammar_hyp": 4.02771,
            "nubia_score": 0.3499
        },
        "bleurt": -0.46928
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "ByT5-large (Baseline)/xsum_challenge_test_bfp_05",
        "N": 500,
        "msttr-100": 0.72981,
        "msttr-100_nopunct": 0.74253,
        "total_length": 10473,
        "mean_pred_length": 20.946,
        "std_pred_length": 3.4904274809828095,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.2735605843597823,
        "vocab_size-1": 2865,
        "unique-1": 1897,
        "entropy-1": 8.98490563927237,
        "distinct-2": 0.7202446605835756,
        "vocab_size-2": 7183,
        "unique-2": 6232,
        "entropy-2": 12.268879938215251,
        "cond_entropy-2": 3.1655225043328166,
        "distinct-3": 0.9172384672226327,
        "vocab_size-3": 8689,
        "unique-3": 8235,
        "entropy-3": 12.991252557817301,
        "cond_entropy-3": 0.7435144750622602,
        "total_length-nopunct": 9932,
        "mean_pred_length-nopunct": 19.864,
        "std_pred_length-nopunct": 3.582946273669199,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.2874546919049537,
        "vocab_size-1-nopunct": 2855,
        "unique-1-nopunct": 1896,
        "entropy-1-nopunct": 9.083555449075918,
        "distinct-2-nopunct": 0.7238125530110263,
        "vocab_size-2-nopunct": 6827,
        "unique-2-nopunct": 5941,
        "entropy-2-nopunct": 12.194186748704638,
        "cond_entropy-2-nopunct": 3.2400633847870894,
        "distinct-3-nopunct": 0.921294223018361,
        "vocab_size-3-nopunct": 8229,
        "unique-3-nopunct": 7816,
        "entropy-3-nopunct": 12.920336124975773,
        "cond_entropy-3-nopunct": 0.7505186215865055,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "local_recall": {
            "1": 0.32277976901632816
        },
        "nist": 3.2693782698218565,
        "rouge1": {
            "precision": 0.37256,
            "recall": 0.35108,
            "fmeasure": 0.35594
        },
        "rouge2": {
            "precision": 0.1303,
            "recall": 0.12283,
            "fmeasure": 0.12436
        },
        "rougeL": {
            "precision": 0.29057,
            "recall": 0.2738,
            "fmeasure": 0.27749
        },
        "rougeLsum": {
            "precision": 0.29057,
            "recall": 0.2738,
            "fmeasure": 0.27749
        },
        "bleu": 7.68134,
        "meteor": 0.15124697013334404,
        "bertscore": {
            "precision": 0.81643,
            "recall": 0.80955,
            "f1": 0.81268
        },
        "nubia": {
            "semantic_relation": 2.58784,
            "contradiction": 27.93766,
            "irrelevancy": 61.66207,
            "logical_agreement": 10.40027,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.13386,
            "nubia_score": 0.32404
        },
        "bleurt": -0.53
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "ByT5-large (Baseline)/xsum_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.74048,
        "msttr-100_nopunct": 0.7499,
        "total_length": 10590,
        "mean_pred_length": 21.18,
        "std_pred_length": 3.44261528492511,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.2747875354107649,
        "vocab_size-1": 2910,
        "unique-1": 1889,
        "entropy-1": 9.083621410448375,
        "distinct-2": 0.7279484638255699,
        "vocab_size-2": 7345,
        "unique-2": 6370,
        "entropy-2": 12.342187338631211,
        "cond_entropy-2": 3.1612425525838197,
        "distinct-3": 0.924191866527633,
        "vocab_size-3": 8863,
        "unique-3": 8455,
        "entropy-3": 13.026760558813908,
        "cond_entropy-3": 0.7057521236491472,
        "total_length-nopunct": 10077,
        "mean_pred_length-nopunct": 20.154,
        "std_pred_length-nopunct": 3.629088590817259,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.28788329860077405,
        "vocab_size-1-nopunct": 2901,
        "unique-1-nopunct": 1888,
        "entropy-1-nopunct": 9.174990624352278,
        "distinct-2-nopunct": 0.7323796596011277,
        "vocab_size-2-nopunct": 7014,
        "unique-2-nopunct": 6101,
        "entropy-2-nopunct": 12.279352524181967,
        "cond_entropy-2-nopunct": 3.22058772891778,
        "distinct-3-nopunct": 0.9285006059270684,
        "vocab_size-3-nopunct": 8428,
        "unique-3-nopunct": 8054,
        "entropy-3-nopunct": 12.961808138977908,
        "cond_entropy-3-nopunct": 0.7047286683916387,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.34773001205303333
        },
        "nist": 3.5359267927807925,
        "rouge1": {
            "precision": 0.39548,
            "recall": 0.38079,
            "fmeasure": 0.38087
        },
        "rouge2": {
            "precision": 0.15097,
            "recall": 0.14482,
            "fmeasure": 0.14508
        },
        "rougeL": {
            "precision": 0.30895,
            "recall": 0.29668,
            "fmeasure": 0.2971
        },
        "rougeLsum": {
            "precision": 0.30895,
            "recall": 0.29668,
            "fmeasure": 0.2971
        },
        "bleu": 9.42532,
        "meteor": 0.16375655294297725,
        "bertscore": {
            "precision": 0.82501,
            "recall": 0.81774,
            "f1": 0.82105
        },
        "nubia": {
            "semantic_relation": 2.73306,
            "contradiction": 24.83381,
            "irrelevancy": 64.2871,
            "logical_agreement": 10.8791,
            "grammar_ref": 3.78318,
            "grammar_hyp": 3.9506,
            "nubia_score": 0.36424
        },
        "bleurt": -0.42654
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "ByT5-large (Baseline)/xsum_challenge_test_covid",
        "N": 401,
        "msttr-100": 0.72218,
        "msttr-100_nopunct": 0.725,
        "total_length": 8716,
        "mean_pred_length": 21.7356608478803,
        "std_pred_length": 3.2555266839198223,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.22636530518586506,
        "vocab_size-1": 1973,
        "unique-1": 1229,
        "entropy-1": 8.507757848657343,
        "distinct-2": 0.638965724594107,
        "vocab_size-2": 5313,
        "unique-2": 4386,
        "entropy-2": 11.717724550200732,
        "cond_entropy-2": 3.1708471917640817,
        "distinct-3": 0.8626484710639373,
        "vocab_size-3": 6827,
        "unique-3": 6314,
        "entropy-3": 12.553799198621462,
        "cond_entropy-3": 0.845089590023321,
        "total_length-nopunct": 8256,
        "mean_pred_length-nopunct": 20.58852867830424,
        "std_pred_length-nopunct": 3.2910015726860333,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.23776647286821706,
        "vocab_size-1-nopunct": 1963,
        "unique-1-nopunct": 1229,
        "entropy-1-nopunct": 8.569297693763394,
        "distinct-2-nopunct": 0.6501591343093571,
        "vocab_size-2-nopunct": 5107,
        "unique-2-nopunct": 4255,
        "entropy-2-nopunct": 11.672798909508524,
        "cond_entropy-2-nopunct": 3.1855403879742323,
        "distinct-3-nopunct": 0.870136839280923,
        "vocab_size-3-nopunct": 6486,
        "unique-3-nopunct": 6025,
        "entropy-3-nopunct": 12.489384526716742,
        "cond_entropy-3-nopunct": 0.8282020405616213,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "local_recall": {
            "1": 0.27967323402210476
        },
        "nist": 2.5423508206981764,
        "rouge1": {
            "precision": 0.32216,
            "recall": 0.30279,
            "fmeasure": 0.30519
        },
        "rouge2": {
            "precision": 0.09773,
            "recall": 0.09233,
            "fmeasure": 0.09295
        },
        "rougeL": {
            "precision": 0.24505,
            "recall": 0.23273,
            "fmeasure": 0.23321
        },
        "rougeLsum": {
            "precision": 0.24505,
            "recall": 0.23273,
            "fmeasure": 0.23321
        },
        "bleu": 6.06309,
        "meteor": 0.1261551986013607,
        "bertscore": {
            "precision": 0.7928,
            "recall": 0.78688,
            "f1": 0.78957
        },
        "nubia": {
            "semantic_relation": 2.21631,
            "contradiction": 23.25456,
            "irrelevancy": 68.36111,
            "logical_agreement": 8.38432,
            "grammar_ref": 4.04957,
            "grammar_hyp": 4.30148,
            "nubia_score": 0.2609
        },
        "bleurt": -0.64484
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 500,
        "msttr-100": 0.67804,
        "msttr-100_nopunct": 0.73213,
        "total_length": 5613,
        "mean_pred_length": 11.226,
        "std_pred_length": 3.0441622821393737,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.2955638695884554,
        "vocab_size-1": 1659,
        "unique-1": 989,
        "entropy-1": 8.919969695434864,
        "distinct-2": 0.6195971054175631,
        "vocab_size-2": 3168,
        "unique-2": 2366,
        "entropy-2": 11.184832185356907,
        "cond_entropy-2": 2.294528267944113,
        "distinct-3": 0.7973119445046607,
        "vocab_size-3": 3678,
        "unique-3": 3105,
        "entropy-3": 11.679184318995842,
        "cond_entropy-3": 0.5721795498385749,
        "total_length-nopunct": 4773,
        "mean_pred_length-nopunct": 9.546,
        "std_pred_length-nopunct": 2.690703253798159,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.346113555415881,
        "vocab_size-1-nopunct": 1652,
        "unique-1-nopunct": 989,
        "entropy-1-nopunct": 9.421357839741837,
        "distinct-2-nopunct": 0.6613620407208051,
        "vocab_size-2-nopunct": 2826,
        "unique-2-nopunct": 2200,
        "entropy-2-nopunct": 11.074971562107976,
        "cond_entropy-2-nopunct": 1.8406162626176894,
        "distinct-3-nopunct": 0.8173866949377153,
        "vocab_size-3-nopunct": 3084,
        "unique-3-nopunct": 2670,
        "entropy-3-nopunct": 11.433582328630798,
        "cond_entropy-3-nopunct": 0.4487144008753447,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1748696219035202,
            "2": 0.3384848484848485,
            "3": 0.4911242603550296,
            "4": 0.5777777777777777,
            "5": 0.6,
            "6": 1.0
        },
        "nist": 1.5595399195829498,
        "rouge1": {
            "precision": 0.29117,
            "recall": 0.23791,
            "fmeasure": 0.25207
        },
        "rouge2": {
            "precision": 0.13581,
            "recall": 0.1093,
            "fmeasure": 0.11641
        },
        "rougeL": {
            "precision": 0.28524,
            "recall": 0.2334,
            "fmeasure": 0.24702
        },
        "rougeLsum": {
            "precision": 0.28524,
            "recall": 0.2334,
            "fmeasure": 0.24702
        },
        "bleu": 21.13138,
        "meteor": 0.39190586475947276,
        "bertscore": {
            "precision": 0.95029,
            "recall": 0.91337,
            "f1": 0.93063
        },
        "nubia": {
            "semantic_relation": 3.60155,
            "contradiction": 22.13555,
            "irrelevancy": 22.45331,
            "logical_agreement": 55.41114,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.7405,
            "nubia_score": 0.69931
        },
        "bleurt": 0.10273
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.52351,
        "msttr-100_nopunct": 0.52624,
        "total_length": 9405,
        "mean_pred_length": 18.81,
        "std_pred_length": 6.50245338314701,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.1343965975544923,
        "vocab_size-1": 1264,
        "unique-1": 513,
        "entropy-1": 7.9953509272281575,
        "distinct-2": 0.3849522740033689,
        "vocab_size-2": 3428,
        "unique-2": 2052,
        "entropy-2": 10.856613408802827,
        "cond_entropy-2": 2.786656144023819,
        "distinct-3": 0.5828673408685306,
        "vocab_size-3": 4899,
        "unique-3": 3528,
        "entropy-3": 11.774944676009957,
        "cond_entropy-3": 0.9947456208350959,
        "total_length-nopunct": 8531,
        "mean_pred_length-nopunct": 17.062,
        "std_pred_length-nopunct": 6.2008189781673195,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.147227757589966,
        "vocab_size-1-nopunct": 1256,
        "unique-1-nopunct": 512,
        "entropy-1-nopunct": 8.165777670005006,
        "distinct-2-nopunct": 0.3906113808990163,
        "vocab_size-2-nopunct": 3137,
        "unique-2-nopunct": 1910,
        "entropy-2-nopunct": 10.73870561683689,
        "cond_entropy-2-nopunct": 2.7244538206199285,
        "distinct-3-nopunct": 0.5878369406453327,
        "vocab_size-3-nopunct": 4427,
        "unique-3-nopunct": 3241,
        "entropy-3-nopunct": 11.619766798543765,
        "cond_entropy-3-nopunct": 0.9527071188751859,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1844237991697964,
            "2": 0.501187648456057,
            "3": 0.7471952131637996,
            "4": 0.2,
            "5": 0.3333333333333333
        },
        "nist": 6.715162727443547,
        "rouge1": {
            "precision": 0.78165,
            "recall": 0.67945,
            "fmeasure": 0.7141
        },
        "rouge2": {
            "precision": 0.51901,
            "recall": 0.44872,
            "fmeasure": 0.47166
        },
        "rougeL": {
            "precision": 0.64137,
            "recall": 0.55865,
            "fmeasure": 0.58625
        },
        "rougeLsum": {
            "precision": 0.64137,
            "recall": 0.55865,
            "fmeasure": 0.58625
        },
        "bleu": 39.12431,
        "meteor": 0.3252769080543448,
        "bertscore": {
            "precision": 0.92115,
            "recall": 0.90071,
            "f1": 0.90923
        },
        "nubia": {
            "semantic_relation": 4.15723,
            "contradiction": 7.25224,
            "irrelevancy": 10.18157,
            "logical_agreement": 82.56619,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.8186,
            "nubia_score": 0.67869
        },
        "bleurt": 0.05963
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.66758,
        "msttr-100_nopunct": 0.68698,
        "total_length": 9591,
        "mean_pred_length": 19.182,
        "std_pred_length": 6.335367076973519,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.13314565738713377,
        "vocab_size-1": 1277,
        "unique-1": 515,
        "entropy-1": 8.027336274890654,
        "distinct-2": 0.38147618523814764,
        "vocab_size-2": 3468,
        "unique-2": 2068,
        "entropy-2": 10.860623430042047,
        "cond_entropy-2": 2.767399972403693,
        "distinct-3": 0.5810732161564428,
        "vocab_size-3": 4992,
        "unique-3": 3640,
        "entropy-3": 11.78466728748178,
        "cond_entropy-3": 1.0032653916666856,
        "total_length-nopunct": 8677,
        "mean_pred_length-nopunct": 17.354,
        "std_pred_length-nopunct": 6.0203558034388625,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.1461334562636856,
        "vocab_size-1-nopunct": 1268,
        "unique-1-nopunct": 514,
        "entropy-1-nopunct": 8.196658880906025,
        "distinct-2-nopunct": 0.3870612694142106,
        "vocab_size-2-nopunct": 3165,
        "unique-2-nopunct": 1934,
        "entropy-2-nopunct": 10.730610793480759,
        "cond_entropy-2-nopunct": 2.6990176372206753,
        "distinct-3-nopunct": 0.5874690634362381,
        "vocab_size-3-nopunct": 4510,
        "unique-3-nopunct": 3339,
        "entropy-3-nopunct": 11.632636168270233,
        "cond_entropy-3-nopunct": 0.9804313368989415,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19151160359606942,
            "2": 0.5135878912968697,
            "3": 0.7463703172611579,
            "4": 0.7777777777777778,
            "5": 0.5454545454545454
        },
        "nist": 6.702550437674809,
        "rouge1": {
            "precision": 0.78924,
            "recall": 0.68377,
            "fmeasure": 0.71936
        },
        "rouge2": {
            "precision": 0.52795,
            "recall": 0.45341,
            "fmeasure": 0.47749
        },
        "rougeL": {
            "precision": 0.64335,
            "recall": 0.5569,
            "fmeasure": 0.58547
        },
        "rougeLsum": {
            "precision": 0.64335,
            "recall": 0.5569,
            "fmeasure": 0.58547
        },
        "bleu": 40.04587,
        "meteor": 0.33139978487630123,
        "bertscore": {
            "precision": 0.92338,
            "recall": 0.90272,
            "f1": 0.91133
        },
        "nubia": {
            "semantic_relation": 4.16649,
            "contradiction": 7.92518,
            "irrelevancy": 9.61036,
            "logical_agreement": 82.46446,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.76524,
            "nubia_score": 0.68177
        },
        "bleurt": 0.06437
    },
    "mlsum_de_test": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_de_test",
        "N": 10695,
        "msttr-100": 0.75969,
        "msttr-100_nopunct": 0.79006,
        "total_length": 213796,
        "mean_pred_length": 19.990275829827024,
        "std_pred_length": 2.6317191427312387,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.14182678815319277,
        "vocab_size-1": 30322,
        "unique-1": 19077,
        "entropy-1": 10.39868504712155,
        "distinct-2": 0.5399382573202496,
        "vocab_size-2": 109662,
        "unique-2": 89953,
        "entropy-2": 15.3776916781058,
        "cond_entropy-2": 5.060463007061305,
        "distinct-3": 0.8295271457231064,
        "vocab_size-3": 159606,
        "unique-3": 147018,
        "entropy-3": 16.95248048779892,
        "cond_entropy-3": 1.636228512799354,
        "total_length-nopunct": 195757,
        "mean_pred_length-nopunct": 18.303599812996726,
        "std_pred_length-nopunct": 2.4033483617719167,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.15482460397329342,
        "vocab_size-1-nopunct": 30308,
        "unique-1-nopunct": 19076,
        "entropy-1-nopunct": 10.757994970689571,
        "distinct-2-nopunct": 0.5912667106159017,
        "vocab_size-2-nopunct": 109421,
        "unique-2-nopunct": 91129,
        "entropy-2-nopunct": 15.706586308804443,
        "cond_entropy-2-nopunct": 5.107861607955381,
        "distinct-3-nopunct": 0.8693502784357132,
        "vocab_size-3-nopunct": 151586,
        "unique-3-nopunct": 141789,
        "entropy-3-nopunct": 16.983812847408522,
        "cond_entropy-3-nopunct": 1.3428825931787118,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "local_recall": {
            "1": 0.36513577276751114
        },
        "nist": 5.373149127276475,
        "rouge1": {
            "precision": 0.4743,
            "recall": 0.36662,
            "fmeasure": 0.40757
        },
        "rouge2": {
            "precision": 0.35455,
            "recall": 0.26345,
            "fmeasure": 0.29838
        },
        "rougeL": {
            "precision": 0.43643,
            "recall": 0.33546,
            "fmeasure": 0.374
        },
        "rougeLsum": {
            "precision": 0.43643,
            "recall": 0.33546,
            "fmeasure": 0.374
        },
        "bleu": 26.66131,
        "meteor": 0.3179584831489641,
        "bertscore": {
            "precision": 0.89536,
            "recall": 0.87427,
            "f1": 0.88451
        },
        "nubia": {
            "semantic_relation": 2.39889,
            "contradiction": 24.63763,
            "irrelevancy": 41.51397,
            "logical_agreement": 33.8484,
            "grammar_ref": 5.03454,
            "grammar_hyp": 5.09657,
            "nubia_score": 0.28561
        },
        "bleurt": -0.44026
    },
    "mlsum_de_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_de_challenge_train_sample",
        "N": 500
    },
    "mlsum_de_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_de_challenge_validation_sample",
        "N": 500
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_de_challenge_test_covid",
        "N": 5058,
        "msttr-100": 0.71116,
        "msttr-100_nopunct": 0.73938,
        "total_length": 102257,
        "mean_pred_length": 20.216884143930407,
        "std_pred_length": 2.9478490088512737,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.12576156155568813,
        "vocab_size-1": 12860,
        "unique-1": 8319,
        "entropy-1": 9.294239477710137,
        "distinct-2": 0.44996347699050404,
        "vocab_size-2": 43736,
        "unique-2": 36475,
        "entropy-2": 12.968648048886665,
        "cond_entropy-2": 3.746215825465463,
        "distinct-3": 0.650220857164563,
        "vocab_size-3": 59912,
        "unique-3": 55863,
        "entropy-3": 13.927362254501814,
        "cond_entropy-3": 1.0166791773250168,
        "total_length-nopunct": 92654,
        "mean_pred_length-nopunct": 18.31830763147489,
        "std_pred_length-nopunct": 2.4095961407159883,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.13866643641936668,
        "vocab_size-1-nopunct": 12848,
        "unique-1-nopunct": 8317,
        "entropy-1-nopunct": 9.602770885887406,
        "distinct-2-nopunct": 0.49309329193113843,
        "vocab_size-2-nopunct": 43193,
        "unique-2-nopunct": 36705,
        "entropy-2-nopunct": 13.15516628955041,
        "cond_entropy-2-nopunct": 3.6944710882102005,
        "distinct-3-nopunct": 0.6791417286583149,
        "vocab_size-3-nopunct": 56055,
        "unique-3-nopunct": 52938,
        "entropy-3-nopunct": 13.91054441195145,
        "cond_entropy-3-nopunct": 0.8159661539919464,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "local_recall": {
            "1": 0.30930498449902155
        },
        "nist": 4.402576274296508,
        "rouge1": {
            "precision": 0.33323,
            "recall": 0.31292,
            "fmeasure": 0.31624
        },
        "rouge2": {
            "precision": 0.22959,
            "recall": 0.20693,
            "fmeasure": 0.21369
        },
        "rougeL": {
            "precision": 0.3061,
            "recall": 0.28645,
            "fmeasure": 0.29
        },
        "rougeLsum": {
            "precision": 0.3061,
            "recall": 0.28645,
            "fmeasure": 0.29
        },
        "bleu": 20.76433,
        "meteor": 0.26173041790953405,
        "bertscore": {
            "precision": 0.87356,
            "recall": 0.865,
            "f1": 0.86909
        },
        "nubia": {
            "semantic_relation": 1.97559,
            "contradiction": 25.43796,
            "irrelevancy": 57.0147,
            "logical_agreement": 17.54734,
            "grammar_ref": 5.17449,
            "grammar_hyp": 5.11775,
            "nubia_score": 0.24584
        },
        "bleurt": -0.52922
    },
    "mlsum_es_validation": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_es_validation",
        "N": 9977,
        "msttr-100": 0.69858,
        "msttr-100_nopunct": 0.69857,
        "total_length": 176029,
        "mean_pred_length": 17.64348000400922,
        "std_pred_length": 4.38937341942571,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 36,
        "distinct-1": 0.13006379630629045,
        "vocab_size-1": 22895,
        "unique-1": 13232,
        "entropy-1": 9.902691215108783,
        "distinct-2": 0.5033302820803122,
        "vocab_size-2": 83579,
        "unique-2": 66140,
        "entropy-2": 14.946341822851938,
        "cond_entropy-2": 5.2664245111942805,
        "distinct-3": 0.8178439852634951,
        "vocab_size-3": 127645,
        "unique-3": 116007,
        "entropy-3": 16.668100311420098,
        "cond_entropy-3": 1.7815285480701704,
        "total_length-nopunct": 171802,
        "mean_pred_length-nopunct": 17.219805552771373,
        "std_pred_length-nopunct": 4.085914149794151,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.13317656371869943,
        "vocab_size-1-nopunct": 22880,
        "unique-1-nopunct": 13232,
        "entropy-1-nopunct": 9.925828766644557,
        "distinct-2-nopunct": 0.5085369998455121,
        "vocab_size-2-nopunct": 82294,
        "unique-2-nopunct": 65379,
        "entropy-2-nopunct": 14.935341182337588,
        "cond_entropy-2-nopunct": 5.247036404318873,
        "distinct-3-nopunct": 0.8206166693008798,
        "vocab_size-3-nopunct": 124609,
        "unique-3-nopunct": 113506,
        "entropy-3-nopunct": 16.636566214641654,
        "cond_entropy-3-nopunct": 1.7617057655131207,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_validation.json",
        "local_recall": {
            "1": 0.25400305627533054
        },
        "nist": 2.530196262355131,
        "rouge1": {
            "precision": 0.34037,
            "recall": 0.27156,
            "fmeasure": 0.29241
        },
        "rouge2": {
            "precision": 0.13262,
            "recall": 0.1057,
            "fmeasure": 0.1138
        },
        "rougeL": {
            "precision": 0.27599,
            "recall": 0.22126,
            "fmeasure": 0.23772
        },
        "rougeLsum": {
            "precision": 0.27599,
            "recall": 0.22126,
            "fmeasure": 0.23772
        },
        "bleu": 7.42821,
        "meteor": 0.2056058451145329,
        "bertscore": {
            "precision": 0.84569,
            "recall": 0.83243,
            "f1": 0.83881
        },
        "nubia": {
            "semantic_relation": 1.69908,
            "contradiction": 28.17224,
            "irrelevancy": 59.22626,
            "logical_agreement": 12.60151,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.35289,
            "nubia_score": 0.17643
        },
        "bleurt": -0.45411
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_validation",
        "N": 20000,
        "msttr-100": 0.23975,
        "msttr-100_nopunct": 0.22583,
        "total_length": 365900,
        "mean_pred_length": 18.295,
        "std_pred_length": 5.939189759554749,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.02258267286143755,
        "vocab_size-1": 8263,
        "unique-1": 0,
        "entropy-1": 9.71104043366003,
        "distinct-2": 0.06954900260190806,
        "vocab_size-2": 24057,
        "unique-2": 0,
        "entropy-2": 13.756193394706541,
        "cond_entropy-2": 3.875179176452762,
        "distinct-3": 0.09040810064436944,
        "vocab_size-3": 29464,
        "unique-3": 0,
        "entropy-3": 14.631543251317112,
        "cond_entropy-3": 0.9130504922699618,
        "total_length-nopunct": 323820,
        "mean_pred_length-nopunct": 16.191,
        "std_pred_length-nopunct": 5.323017847048796,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.02546476437527021,
        "vocab_size-1-nopunct": 8246,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.096732587224645,
        "distinct-2-nopunct": 0.07323086037785531,
        "vocab_size-2-nopunct": 22249,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 13.809869505407875,
        "cond_entropy-2-nopunct": 3.891415442251949,
        "distinct-3-nopunct": 0.09315763512085125,
        "vocab_size-3-nopunct": 26440,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.609246670347746,
        "cond_entropy-3-nopunct": 0.8509285103230323,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_validation.json",
        "local_recall": {
            "1": 0.6661269271155337
        },
        "nist": 9.266182530793563,
        "rouge1": {
            "precision": 0.71309,
            "recall": 0.69611,
            "fmeasure": 0.68404
        },
        "rouge2": {
            "precision": 0.52667,
            "recall": 0.50994,
            "fmeasure": 0.50179
        },
        "rougeL": {
            "precision": 0.668,
            "recall": 0.65106,
            "fmeasure": 0.64046
        },
        "rougeLsum": {
            "precision": 0.668,
            "recall": 0.65106,
            "fmeasure": 0.64046
        },
        "bleu": 41.36215,
        "sari": 43.17992,
        "meteor": 0.3580420544969433,
        "bertscore": {
            "precision": 0.9114,
            "recall": 0.91132,
            "f1": 0.91042
        },
        "nubia": {
            "semantic_relation": 4.14557,
            "contradiction": 3.59793,
            "irrelevancy": 30.03993,
            "logical_agreement": 66.36215,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.79469,
            "nubia_score": 0.65079
        },
        "bleurt": 0.15895
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "ByT5-large (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.72925,
        "msttr-100_nopunct": 0.762,
        "total_length": 6758,
        "mean_pred_length": 18.824512534818943,
        "std_pred_length": 5.890822920340777,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3709677419354839,
        "vocab_size-1": 2507,
        "unique-1": 1859,
        "entropy-1": 9.13529021808793,
        "distinct-2": 0.8223159868729489,
        "vocab_size-2": 5262,
        "unique-2": 4859,
        "entropy-2": 11.99041361863729,
        "cond_entropy-2": 2.7286039137986697,
        "distinct-3": 0.9548013245033112,
        "vocab_size-3": 5767,
        "unique-3": 5644,
        "entropy-3": 12.398848657134623,
        "cond_entropy-3": 0.4322075231108565,
        "total_length-nopunct": 6009,
        "mean_pred_length-nopunct": 16.738161559888578,
        "std_pred_length-nopunct": 5.312356748618713,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.41521051755699784,
        "vocab_size-1-nopunct": 2495,
        "unique-1-nopunct": 1857,
        "entropy-1-nopunct": 9.42737677718133,
        "distinct-2-nopunct": 0.8543362831858408,
        "vocab_size-2-nopunct": 4827,
        "unique-2-nopunct": 4488,
        "entropy-2-nopunct": 11.97557207338415,
        "cond_entropy-2-nopunct": 2.6784103275196585,
        "distinct-3-nopunct": 0.9775089775089775,
        "vocab_size-3-nopunct": 5172,
        "unique-3-nopunct": 5076,
        "entropy-3-nopunct": 12.320505242471597,
        "cond_entropy-3-nopunct": 0.36939251540770074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.03362734288864388,
            "2": 0.1421832884097035,
            "3": 0.2963855421686747,
            "4": 0.5107033639143731,
            "5": 0.6191198786039454,
            "6": 0.6873239436619718,
            "7": 0.7199453551912568,
            "8": 0.7901085645355851,
            "9": 0.8306878306878307,
            "10": 0.9232558139534883
        },
        "nist": 12.655379487862204,
        "rouge1": {
            "precision": 0.85647,
            "recall": 0.83521,
            "fmeasure": 0.83391
        },
        "rouge2": {
            "precision": 0.75947,
            "recall": 0.7337,
            "fmeasure": 0.73247
        },
        "rougeL": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "rougeLsum": {
            "precision": 0.84143,
            "recall": 0.82169,
            "fmeasure": 0.81998
        },
        "bleu": 79.81079,
        "sari": 43.51483,
        "meteor": 0.4813906927942626,
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.95853,
            "f1": 0.95294
        },
        "nubia": {
            "semantic_relation": 4.06468,
            "contradiction": 4.01064,
            "irrelevancy": 34.75851,
            "logical_agreement": 61.23085,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.80536,
            "nubia_score": 0.61895
        },
        "bleurt": 0.11216
    },
    "mlsum_es_test": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_es_test",
        "N": 13366,
        "msttr-100": 0.70218,
        "msttr-100_nopunct": 0.70135,
        "total_length": 233550,
        "mean_pred_length": 17.47344007182403,
        "std_pred_length": 4.301398072688922,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 41,
        "distinct-1": 0.11648469278527082,
        "vocab_size-1": 27205,
        "unique-1": 15253,
        "entropy-1": 9.976626197640114,
        "distinct-2": 0.47558405697053374,
        "vocab_size-2": 104716,
        "unique-2": 82050,
        "entropy-2": 15.138976140656675,
        "cond_entropy-2": 5.387860750295776,
        "distinct-3": 0.7961105899873319,
        "vocab_size-3": 164650,
        "unique-3": 148478,
        "entropy-3": 16.982448263951447,
        "cond_entropy-3": 1.9060995928586246,
        "total_length-nopunct": 228396,
        "mean_pred_length-nopunct": 17.087834804728416,
        "std_pred_length-nopunct": 4.010860629356593,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.11904324068722745,
        "vocab_size-1-nopunct": 27189,
        "unique-1-nopunct": 15252,
        "entropy-1-nopunct": 9.996263317095606,
        "distinct-2-nopunct": 0.480198111891364,
        "vocab_size-2-nopunct": 103257,
        "unique-2-nopunct": 81227,
        "entropy-2-nopunct": 15.128952715879366,
        "cond_entropy-2-nopunct": 5.372257547974341,
        "distinct-3-nopunct": 0.7990122183433831,
        "vocab_size-3-nopunct": 161132,
        "unique-3-nopunct": 145615,
        "entropy-3-nopunct": 16.955238580484924,
        "cond_entropy-3-nopunct": 1.8892113624450946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "local_recall": {
            "1": 0.24955221850225592
        },
        "nist": 2.4239917892869105,
        "rouge1": {
            "precision": 0.34076,
            "recall": 0.2674,
            "fmeasure": 0.28994
        },
        "rouge2": {
            "precision": 0.13039,
            "recall": 0.10101,
            "fmeasure": 0.11002
        },
        "rougeL": {
            "precision": 0.27491,
            "recall": 0.21651,
            "fmeasure": 0.23439
        },
        "rougeLsum": {
            "precision": 0.27491,
            "recall": 0.21651,
            "fmeasure": 0.23439
        },
        "bleu": 6.95693,
        "meteor": 0.20228270866133996,
        "bertscore": {
            "precision": 0.8457,
            "recall": 0.83139,
            "f1": 0.83828
        },
        "nubia": {
            "semantic_relation": 1.68144,
            "contradiction": 29.08985,
            "irrelevancy": 58.67775,
            "logical_agreement": 12.2324,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.37508,
            "nubia_score": 0.17209
        },
        "bleurt": -0.46477
    },
    "mlsum_es_challenge_train_sample": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_es_challenge_train_sample",
        "N": 500
    },
    "mlsum_es_challenge_validation_sample": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_es_challenge_validation_sample",
        "N": 500
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "ByT5-large (Baseline)/mlsum_es_challenge_test_covid",
        "N": 1938,
        "msttr-100": 0.67789,
        "msttr-100_nopunct": 0.6766,
        "total_length": 33168,
        "mean_pred_length": 17.11455108359133,
        "std_pred_length": 3.8457466929234214,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.1928666184273999,
        "vocab_size-1": 6397,
        "unique-1": 4017,
        "entropy-1": 9.028339463431733,
        "distinct-2": 0.5639449247518412,
        "vocab_size-2": 17612,
        "unique-2": 14323,
        "entropy-2": 13.030548134716774,
        "cond_entropy-2": 4.1889790038894,
        "distinct-3": 0.8286904274204561,
        "vocab_size-3": 24274,
        "unique-3": 22156,
        "entropy-3": 14.312137527129828,
        "cond_entropy-3": 1.30480320303669,
        "total_length-nopunct": 32684,
        "mean_pred_length-nopunct": 16.864809081527348,
        "std_pred_length-nopunct": 3.6904599054041136,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.19535552563945663,
        "vocab_size-1-nopunct": 6385,
        "unique-1-nopunct": 4016,
        "entropy-1-nopunct": 9.0172363217294,
        "distinct-2-nopunct": 0.5672607818903272,
        "vocab_size-2-nopunct": 17441,
        "unique-2-nopunct": 14207,
        "entropy-2-nopunct": 13.024008549371391,
        "cond_entropy-2-nopunct": 4.200246285960459,
        "distinct-3-nopunct": 0.831609275201333,
        "vocab_size-3-nopunct": 23957,
        "unique-3-nopunct": 21911,
        "entropy-3-nopunct": 14.296090430576774,
        "cond_entropy-3-nopunct": 1.2953093079164444,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "local_recall": {
            "1": 0.2337925055389654
        },
        "nist": 1.6113953999626731,
        "rouge1": {
            "precision": 0.35492,
            "recall": 0.25221,
            "fmeasure": 0.28519
        },
        "rouge2": {
            "precision": 0.12712,
            "recall": 0.08903,
            "fmeasure": 0.10115
        },
        "rougeL": {
            "precision": 0.2813,
            "recall": 0.20135,
            "fmeasure": 0.22691
        },
        "rougeLsum": {
            "precision": 0.2813,
            "recall": 0.20135,
            "fmeasure": 0.22691
        },
        "bleu": 5.42968,
        "meteor": 0.1923588768193167,
        "bertscore": {
            "precision": 0.84837,
            "recall": 0.82849,
            "f1": 0.83812
        },
        "nubia": {
            "semantic_relation": 1.61311,
            "contradiction": 27.35674,
            "irrelevancy": 62.16086,
            "logical_agreement": 10.48241,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.37509,
            "nubia_score": 0.15701
        },
        "bleurt": -0.50504
    },
    "wiki_lingua_spanish_es_validation": {
        "predictions_file": "ByT5-large (Baseline)/wiki_lingua_spanish_es_validation",
        "N": 11316,
        "msttr-100": 0.55048,
        "msttr-100_nopunct": 0.6193,
        "total_length": 277362,
        "mean_pred_length": 24.510604453870627,
        "std_pred_length": 5.657070822305201,
        "median_pred_length": 26.0,
        "min_pred_length": 3,
        "max_pred_length": 48,
        "distinct-1": 0.04184062705056929,
        "vocab_size-1": 11605,
        "unique-1": 4610,
        "entropy-1": 8.710835893668527,
        "distinct-2": 0.2350383016470836,
        "vocab_size-2": 62531,
        "unique-2": 39782,
        "entropy-2": 13.567072626810942,
        "cond_entropy-2": 4.869143668472772,
        "distinct-3": 0.5372590586110784,
        "vocab_size-3": 136856,
        "unique-3": 107009,
        "entropy-3": 15.943989721996614,
        "cond_entropy-3": 2.438400979111607,
        "total_length-nopunct": 235804,
        "mean_pred_length-nopunct": 20.838105337575115,
        "std_pred_length-nopunct": 5.172265825852351,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 43,
        "distinct-1-nopunct": 0.049129785754270495,
        "vocab_size-1-nopunct": 11585,
        "unique-1-nopunct": 4609,
        "entropy-1-nopunct": 9.483559947480988,
        "distinct-2-nopunct": 0.3534977370728057,
        "vocab_size-2-nopunct": 79356,
        "unique-2-nopunct": 56522,
        "entropy-2-nopunct": 14.33974966404842,
        "cond_entropy-2-nopunct": 4.998172593018687,
        "distinct-3-nopunct": 0.67169234233389,
        "vocab_size-3-nopunct": 143186,
        "unique-3-nopunct": 119306,
        "entropy-3-nopunct": 16.49416859519202,
        "cond_entropy-3-nopunct": 2.2311366354276547,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_validation.json",
        "local_recall": {
            "1": 0.24573323036033592
        },
        "nist": 1.840939725068848,
        "rouge1": {
            "precision": 0.43258,
            "recall": 0.2996,
            "fmeasure": 0.33286
        },
        "rouge2": {
            "precision": 0.1568,
            "recall": 0.10829,
            "fmeasure": 0.1201
        },
        "rougeL": {
            "precision": 0.35969,
            "recall": 0.25322,
            "fmeasure": 0.27919
        },
        "rougeLsum": {
            "precision": 0.35969,
            "recall": 0.25322,
            "fmeasure": 0.27919
        },
        "bleu": 7.18715,
        "sari": 67.14893,
        "meteor": 0.13562302763398157,
        "bertscore": {
            "precision": 0.85536,
            "recall": 0.82267,
            "f1": 0.83811
        },
        "nubia": {
            "semantic_relation": 2.8339,
            "contradiction": 17.83141,
            "irrelevancy": 38.5363,
            "logical_agreement": 43.63229,
            "grammar_ref": 3.95671,
            "grammar_hyp": 3.80661,
            "nubia_score": 0.37826
        },
        "bleurt": -0.48867
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "ByT5-large (Baseline)/wiki_lingua_spanish_es_test",
        "N": 22632,
        "msttr-100": 0.55065,
        "msttr-100_nopunct": 0.61862,
        "total_length": 551285,
        "mean_pred_length": 24.358651466949453,
        "std_pred_length": 5.6958130596531005,
        "median_pred_length": 26.0,
        "min_pred_length": 2,
        "max_pred_length": 44,
        "distinct-1": 0.028981379867037922,
        "vocab_size-1": 15977,
        "unique-1": 6208,
        "entropy-1": 8.751752720291726,
        "distinct-2": 0.189581823994189,
        "vocab_size-2": 100223,
        "unique-2": 62327,
        "entropy-2": 13.788902223182648,
        "cond_entropy-2": 5.050093012415835,
        "distinct-3": 0.4761600803128724,
        "vocab_size-3": 240947,
        "unique-3": 182754,
        "entropy-3": 16.469488586204815,
        "cond_entropy-3": 2.7494577099088944,
        "total_length-nopunct": 469034,
        "mean_pred_length-nopunct": 20.724372569812655,
        "std_pred_length-nopunct": 5.198943509314899,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.034008195567911924,
        "vocab_size-1-nopunct": 15951,
        "unique-1-nopunct": 6207,
        "entropy-1-nopunct": 9.52625511336061,
        "distinct-2-nopunct": 0.2978772496538994,
        "vocab_size-2-nopunct": 132973,
        "unique-2-nopunct": 91723,
        "entropy-2-nopunct": 14.664921387262188,
        "cond_entropy-2-nopunct": 5.287638527408638,
        "distinct-3-nopunct": 0.6142185284033121,
        "vocab_size-3-nopunct": 260288,
        "unique-3-nopunct": 211447,
        "entropy-3-nopunct": 17.154970220170263,
        "cond_entropy-3-nopunct": 2.5783913114603645,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "local_recall": {
            "1": 0.24339361183776292
        },
        "nist": 1.7595719503413483,
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.2973,
            "fmeasure": 0.33154
        },
        "rouge2": {
            "precision": 0.15571,
            "recall": 0.10631,
            "fmeasure": 0.11835
        },
        "rougeL": {
            "precision": 0.35962,
            "recall": 0.25068,
            "fmeasure": 0.27741
        },
        "rougeLsum": {
            "precision": 0.35962,
            "recall": 0.25068,
            "fmeasure": 0.27741
        },
        "bleu": 6.96683,
        "sari": 67.09179,
        "meteor": 0.13410739495018706,
        "bertscore": {
            "precision": 0.85497,
            "recall": 0.8215,
            "f1": 0.83731
        },
        "nubia": {
            "semantic_relation": 2.8242,
            "contradiction": 17.70684,
            "irrelevancy": 38.9891,
            "logical_agreement": 43.30407,
            "grammar_ref": 3.9494,
            "grammar_hyp": 3.80132,
            "nubia_score": 0.37618
        },
        "bleurt": -0.49646
    },
    "wiki_lingua_turkish_tr_validation": {
        "predictions_file": "ByT5-large (Baseline)/wiki_lingua_turkish_tr_validation",
        "N": 449,
        "msttr-100": 0.61697,
        "msttr-100_nopunct": 0.69,
        "total_length": 10993,
        "mean_pred_length": 24.48329621380846,
        "std_pred_length": 5.427005950735406,
        "median_pred_length": 26.0,
        "min_pred_length": 3,
        "max_pred_length": 36,
        "distinct-1": 0.1877558446283999,
        "vocab_size-1": 2064,
        "unique-1": 1048,
        "entropy-1": 8.30499445173565,
        "distinct-2": 0.5530159332321699,
        "vocab_size-2": 5831,
        "unique-2": 4320,
        "entropy-2": 11.741552378004236,
        "cond_entropy-2": 3.4649386841597622,
        "distinct-3": 0.8032689450222883,
        "vocab_size-3": 8109,
        "unique-3": 7059,
        "entropy-3": 12.745088838018559,
        "cond_entropy-3": 1.0344589637533577,
        "total_length-nopunct": 9407,
        "mean_pred_length-nopunct": 20.951002227171493,
        "std_pred_length-nopunct": 4.960629416427112,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.21834803869458913,
        "vocab_size-1-nopunct": 2054,
        "unique-1-nopunct": 1045,
        "entropy-1-nopunct": 8.937960678910398,
        "distinct-2-nopunct": 0.6563965170797053,
        "vocab_size-2-nopunct": 5880,
        "unique-2-nopunct": 4666,
        "entropy-2-nopunct": 12.031629496997363,
        "cond_entropy-2-nopunct": 3.197776029164134,
        "distinct-3-nopunct": 0.8825948995181573,
        "vocab_size-3-nopunct": 7510,
        "unique-3-nopunct": 6842,
        "entropy-3-nopunct": 12.762161047772606,
        "cond_entropy-3-nopunct": 0.7619245508872343,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_validation.json",
        "local_recall": {
            "1": 0.2601911976911977
        },
        "nist": 1.4976063614886674,
        "rouge1": {
            "precision": 0.4159,
            "recall": 0.28611,
            "fmeasure": 0.32018
        },
        "rouge2": {
            "precision": 0.16726,
            "recall": 0.11348,
            "fmeasure": 0.12733
        },
        "rougeL": {
            "precision": 0.34438,
            "recall": 0.23996,
            "fmeasure": 0.2666
        },
        "rougeLsum": {
            "precision": 0.34438,
            "recall": 0.23996,
            "fmeasure": 0.2666
        },
        "bleu": 9.4922,
        "sari": 67.68321,
        "meteor": 0.1315894258461327,
        "bertscore": {
            "precision": 0.84397,
            "recall": 0.82401,
            "f1": 0.83338
        },
        "nubia": {
            "semantic_relation": 2.51617,
            "contradiction": 25.09124,
            "irrelevancy": 45.54005,
            "logical_agreement": 29.36871,
            "grammar_ref": 3.85457,
            "grammar_hyp": 4.249,
            "nubia_score": 0.2752
        },
        "bleurt": -0.5863
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "ByT5-large (Baseline)/wiki_lingua_turkish_tr_test",
        "N": 900,
        "msttr-100": 0.61493,
        "msttr-100_nopunct": 0.68031,
        "total_length": 22338,
        "mean_pred_length": 24.82,
        "std_pred_length": 5.184468257315412,
        "median_pred_length": 26.0,
        "min_pred_length": 3,
        "max_pred_length": 36,
        "distinct-1": 0.13729966872593785,
        "vocab_size-1": 3067,
        "unique-1": 1471,
        "entropy-1": 8.416952635933155,
        "distinct-2": 0.4721522530086762,
        "vocab_size-2": 10122,
        "unique-2": 7184,
        "entropy-2": 12.217970316643251,
        "cond_entropy-2": 3.8376646947342894,
        "distinct-3": 0.7406758204304217,
        "vocab_size-3": 15212,
        "unique-3": 12891,
        "entropy-3": 13.506719235683516,
        "cond_entropy-3": 1.3342931017946842,
        "total_length-nopunct": 19183,
        "mean_pred_length-nopunct": 21.314444444444444,
        "std_pred_length-nopunct": 4.713575220363487,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.1592555908877652,
        "vocab_size-1-nopunct": 3055,
        "unique-1-nopunct": 1468,
        "entropy-1-nopunct": 9.044302047470918,
        "distinct-2-nopunct": 0.5769293879560248,
        "vocab_size-2-nopunct": 10548,
        "unique-2-nopunct": 8068,
        "entropy-2-nopunct": 12.626195157783059,
        "cond_entropy-2-nopunct": 3.6935933009923096,
        "distinct-3-nopunct": 0.8304090203071967,
        "vocab_size-3-nopunct": 14435,
        "unique-3-nopunct": 12807,
        "entropy-3-nopunct": 13.621659036716794,
        "cond_entropy-3-nopunct": 1.0414993845083884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "local_recall": {
            "1": 0.2617404249560157
        },
        "nist": 1.624095753606579,
        "rouge1": {
            "precision": 0.41356,
            "recall": 0.29024,
            "fmeasure": 0.31903
        },
        "rouge2": {
            "precision": 0.16168,
            "recall": 0.10839,
            "fmeasure": 0.12165
        },
        "rougeL": {
            "precision": 0.33543,
            "recall": 0.23803,
            "fmeasure": 0.25993
        },
        "rougeLsum": {
            "precision": 0.33543,
            "recall": 0.23803,
            "fmeasure": 0.25993
        },
        "bleu": 9.05654,
        "sari": 66.65835,
        "meteor": 0.1322403024830761,
        "bertscore": {
            "precision": 0.84308,
            "recall": 0.82367,
            "f1": 0.83273
        },
        "nubia": {
            "semantic_relation": 2.49982,
            "contradiction": 24.69024,
            "irrelevancy": 47.4372,
            "logical_agreement": 27.87256,
            "grammar_ref": 3.87672,
            "grammar_hyp": 4.19871,
            "nubia_score": 0.27252
        },
        "bleurt": -0.59606
    },
    "wiki_lingua_vietnamese_vi_validation": {
        "predictions_file": "ByT5-large (Baseline)/wiki_lingua_vietnamese_vi_validation",
        "N": 1957,
        "msttr-100": 0.6313,
        "msttr-100_nopunct": 0.70351,
        "total_length": 47731,
        "mean_pred_length": 24.389882473173223,
        "std_pred_length": 4.791488774591963,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 36,
        "distinct-1": 0.10502608367727473,
        "vocab_size-1": 5013,
        "unique-1": 2381,
        "entropy-1": 8.714961979220737,
        "distinct-2": 0.42010748459824354,
        "vocab_size-2": 19230,
        "unique-2": 13538,
        "entropy-2": 13.00391794246244,
        "cond_entropy-2": 4.312529103772691,
        "distinct-3": 0.7353995024762079,
        "vocab_size-3": 32223,
        "unique-3": 27617,
        "entropy-3": 14.567296424937876,
        "cond_entropy-3": 1.6118534607793917,
        "total_length-nopunct": 41028,
        "mean_pred_length-nopunct": 20.964741951967298,
        "std_pred_length-nopunct": 4.530629715407421,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.12191673978746222,
        "vocab_size-1-nopunct": 5002,
        "unique-1-nopunct": 2380,
        "entropy-1-nopunct": 9.411651992469583,
        "distinct-2-nopunct": 0.5452893450385197,
        "vocab_size-2-nopunct": 21305,
        "unique-2-nopunct": 16590,
        "entropy-2-nopunct": 13.464044229028277,
        "cond_entropy-2-nopunct": 4.176249962356592,
        "distinct-3-nopunct": 0.8385784340141187,
        "vocab_size-3-nopunct": 31123,
        "unique-3-nopunct": 28142,
        "entropy-3-nopunct": 14.715923753701398,
        "cond_entropy-3-nopunct": 1.3037531631317039,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_validation.json",
        "local_recall": {
            "1": 0.22777253518237395
        },
        "nist": 1.639433464521061,
        "rouge1": {
            "precision": 0.36312,
            "recall": 0.26176,
            "fmeasure": 0.2871
        },
        "rouge2": {
            "precision": 0.11679,
            "recall": 0.08379,
            "fmeasure": 0.09192
        },
        "rougeL": {
            "precision": 0.29037,
            "recall": 0.21282,
            "fmeasure": 0.23143
        },
        "rougeLsum": {
            "precision": 0.29037,
            "recall": 0.21282,
            "fmeasure": 0.23143
        },
        "bleu": 6.30202,
        "sari": 65.96856,
        "meteor": 0.12099421552843068,
        "bertscore": {
            "precision": 0.83546,
            "recall": 0.8168,
            "f1": 0.82557
        },
        "nubia": {
            "semantic_relation": 2.38236,
            "contradiction": 20.4415,
            "irrelevancy": 49.14472,
            "logical_agreement": 30.41378,
            "grammar_ref": 3.90718,
            "grammar_hyp": 4.09266,
            "nubia_score": 0.2674
        },
        "bleurt": -0.552
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "ByT5-large (Baseline)/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "msttr-100": 0.62751,
        "msttr-100_nopunct": 0.7,
        "total_length": 95435,
        "mean_pred_length": 24.364309420474854,
        "std_pred_length": 4.844720048198132,
        "median_pred_length": 25.0,
        "min_pred_length": 4,
        "max_pred_length": 36,
        "distinct-1": 0.07302352386441033,
        "vocab_size-1": 6969,
        "unique-1": 2989,
        "entropy-1": 8.813255997537528,
        "distinct-2": 0.3482375051902358,
        "vocab_size-2": 31870,
        "unique-2": 21440,
        "entropy-2": 13.38456281782061,
        "cond_entropy-2": 4.592967498344985,
        "distinct-3": 0.6700722594490931,
        "vocab_size-3": 58699,
        "unique-3": 48638,
        "entropy-3": 15.257813024121731,
        "cond_entropy-3": 1.9278545709263244,
        "total_length-nopunct": 81943,
        "mean_pred_length-nopunct": 20.919836609650243,
        "std_pred_length-nopunct": 4.580286222259736,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.08486386878683963,
        "vocab_size-1-nopunct": 6954,
        "unique-1-nopunct": 2987,
        "entropy-1-nopunct": 9.526727582759458,
        "distinct-2-nopunct": 0.47079178735293364,
        "vocab_size-2-nopunct": 36734,
        "unique-2-nopunct": 27379,
        "entropy-2-nopunct": 13.9680440768752,
        "cond_entropy-2-nopunct": 4.572977907725524,
        "distinct-3-nopunct": 0.7875156863538841,
        "vocab_size-3-nopunct": 58362,
        "unique-3-nopunct": 51307,
        "entropy-3-nopunct": 15.524128378547472,
        "cond_entropy-3-nopunct": 1.6176238266289236,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "local_recall": {
            "1": 0.23388470339912854
        },
        "nist": 1.7519728534042323,
        "rouge1": {
            "precision": 0.36533,
            "recall": 0.26758,
            "fmeasure": 0.29086
        },
        "rouge2": {
            "precision": 0.12143,
            "recall": 0.08723,
            "fmeasure": 0.09522
        },
        "rougeL": {
            "precision": 0.29282,
            "recall": 0.21806,
            "fmeasure": 0.23504
        },
        "rougeLsum": {
            "precision": 0.29282,
            "recall": 0.21806,
            "fmeasure": 0.23504
        },
        "bleu": 6.76049,
        "sari": 65.83492,
        "meteor": 0.12319711024205535,
        "bertscore": {
            "precision": 0.83675,
            "recall": 0.81794,
            "f1": 0.82675
        },
        "nubia": {
            "semantic_relation": 2.40026,
            "contradiction": 20.28453,
            "irrelevancy": 49.35774,
            "logical_agreement": 30.35773,
            "grammar_ref": 3.92068,
            "grammar_hyp": 4.09793,
            "nubia_score": 0.26979
        },
        "bleurt": -0.55401
    },
    "wiki_lingua_russian_ru_validation": {
        "predictions_file": "ByT5-large (Baseline)/wiki_lingua_russian_ru_validation",
        "N": 5288,
        "msttr-100": 0.61468,
        "msttr-100_nopunct": 0.69003,
        "total_length": 123918,
        "mean_pred_length": 23.433812405446293,
        "std_pred_length": 5.73759324430749,
        "median_pred_length": 25.0,
        "min_pred_length": 2,
        "max_pred_length": 40,
        "distinct-1": 0.06783518132958892,
        "vocab_size-1": 8406,
        "unique-1": 3567,
        "entropy-1": 8.858366004802505,
        "distinct-2": 0.3368709432689876,
        "vocab_size-2": 39963,
        "unique-2": 26950,
        "entropy-2": 13.641192053834528,
        "cond_entropy-2": 4.753716839441952,
        "distinct-3": 0.6711545587690353,
        "vocab_size-3": 76070,
        "unique-3": 63294,
        "entropy-3": 15.62572883568713,
        "cond_entropy-3": 2.032560251149054,
        "total_length-nopunct": 105551,
        "mean_pred_length-nopunct": 19.960476550680788,
        "std_pred_length-nopunct": 5.36290312040033,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 37,
        "distinct-1-nopunct": 0.07947816695246847,
        "vocab_size-1-nopunct": 8389,
        "unique-1-nopunct": 3566,
        "entropy-1-nopunct": 9.62946114903556,
        "distinct-2-nopunct": 0.4677697655166911,
        "vocab_size-2-nopunct": 46900,
        "unique-2-nopunct": 35333,
        "entropy-2-nopunct": 14.257584940655715,
        "cond_entropy-2-nopunct": 4.767024130408863,
        "distinct-3-nopunct": 0.7949692553908356,
        "vocab_size-3-nopunct": 75503,
        "unique-3-nopunct": 66840,
        "entropy-3-nopunct": 15.903296175625327,
        "cond_entropy-3-nopunct": 1.7065484955723926,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_validation.json",
        "local_recall": {
            "1": 0.2157643725477107
        },
        "nist": 1.2288552943295357,
        "rouge1": {
            "precision": 0.3787,
            "recall": 0.25596,
            "fmeasure": 0.28473
        },
        "rouge2": {
            "precision": 0.12425,
            "recall": 0.08358,
            "fmeasure": 0.09323
        },
        "rougeL": {
            "precision": 0.30841,
            "recall": 0.21158,
            "fmeasure": 0.23363
        },
        "rougeLsum": {
            "precision": 0.30841,
            "recall": 0.21158,
            "fmeasure": 0.23363
        },
        "bleu": 5.57775,
        "sari": 67.41281,
        "meteor": 0.11522494787915114,
        "bertscore": {
            "precision": 0.8392,
            "recall": 0.81322,
            "f1": 0.82545
        },
        "nubia": {
            "semantic_relation": 2.46489,
            "contradiction": 20.14325,
            "irrelevancy": 48.7985,
            "logical_agreement": 31.05825,
            "grammar_ref": 3.95099,
            "grammar_hyp": 4.07129,
            "nubia_score": 0.29662
        },
        "bleurt": -0.56642
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "ByT5-large (Baseline)/wiki_lingua_russian_ru_test",
        "N": 10580,
        "msttr-100": 0.6143,
        "msttr-100_nopunct": 0.68984,
        "total_length": 245815,
        "mean_pred_length": 23.233931947069944,
        "std_pred_length": 5.860766500440406,
        "median_pred_length": 25.0,
        "min_pred_length": 2,
        "max_pred_length": 42,
        "distinct-1": 0.04740556922889164,
        "vocab_size-1": 11653,
        "unique-1": 4688,
        "entropy-1": 8.915796756053382,
        "distinct-2": 0.2771993963483325,
        "vocab_size-2": 65207,
        "unique-2": 43221,
        "entropy-2": 13.932862295437003,
        "cond_entropy-2": 4.984778781187396,
        "distinct-3": 0.605595246043934,
        "vocab_size-3": 136050,
        "unique-3": 110879,
        "entropy-3": 16.231688678419744,
        "cond_entropy-3": 2.353632149734133,
        "total_length-nopunct": 209526,
        "mean_pred_length-nopunct": 19.80396975425331,
        "std_pred_length-nopunct": 5.469380598169194,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 40,
        "distinct-1-nopunct": 0.05550623788933116,
        "vocab_size-1-nopunct": 11630,
        "unique-1-nopunct": 4687,
        "entropy-1-nopunct": 9.69391277233277,
        "distinct-2-nopunct": 0.400832386677792,
        "vocab_size-2-nopunct": 79744,
        "unique-2-nopunct": 58633,
        "entropy-2-nopunct": 14.659847043518969,
        "cond_entropy-2-nopunct": 5.116120803094185,
        "distinct-3-nopunct": 0.7399505223817209,
        "vocab_size-3-nopunct": 139383,
        "unique-3-nopunct": 121039,
        "entropy-3-nopunct": 16.64416787953843,
        "cond_entropy-3-nopunct": 2.058726232688152,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "local_recall": {
            "1": 0.21827687411332877
        },
        "nist": 1.2985327770937902,
        "rouge1": {
            "precision": 0.38078,
            "recall": 0.25678,
            "fmeasure": 0.28622
        },
        "rouge2": {
            "precision": 0.12509,
            "recall": 0.08262,
            "fmeasure": 0.09278
        },
        "rougeL": {
            "precision": 0.31025,
            "recall": 0.21161,
            "fmeasure": 0.23445
        },
        "rougeLsum": {
            "precision": 0.31025,
            "recall": 0.21161,
            "fmeasure": 0.23445
        },
        "bleu": 5.70078,
        "sari": 67.3095,
        "meteor": 0.11622914524043544,
        "bertscore": {
            "precision": 0.83979,
            "recall": 0.81362,
            "f1": 0.82594
        },
        "nubia": {
            "semantic_relation": 2.46108,
            "contradiction": 20.8064,
            "irrelevancy": 48.64279,
            "logical_agreement": 30.5508,
            "grammar_ref": 3.95647,
            "grammar_hyp": 4.07797,
            "nubia_score": 0.29663
        },
        "bleurt": -0.56952
    },
    "dart_validation": {
        "predictions_file": "ByT5-large (Baseline)/dart_validation",
        "N": 2768,
        "msttr-100": 0.46865,
        "msttr-100_nopunct": 0.47467,
        "total_length": 54847,
        "mean_pred_length": 19.814667630057805,
        "std_pred_length": 6.081631721684628,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.06800736594526592,
        "vocab_size-1": 3730,
        "unique-1": 1750,
        "entropy-1": 7.817748046751714,
        "distinct-2": 0.2242362564565372,
        "vocab_size-2": 11678,
        "unique-2": 7542,
        "entropy-2": 10.835325600887101,
        "cond_entropy-2": 2.9677704794918136,
        "distinct-3": 0.3598791344730385,
        "vocab_size-3": 17746,
        "unique-3": 13036,
        "entropy-3": 12.222387440222626,
        "cond_entropy-3": 1.4935179245082375,
        "total_length-nopunct": 50107,
        "mean_pred_length-nopunct": 18.102239884393065,
        "std_pred_length-nopunct": 5.830272369947513,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.07410142295487657,
        "vocab_size-1-nopunct": 3713,
        "unique-1-nopunct": 1748,
        "entropy-1-nopunct": 7.96327386756102,
        "distinct-2-nopunct": 0.2297471429476753,
        "vocab_size-2-nopunct": 10876,
        "unique-2-nopunct": 7145,
        "entropy-2-nopunct": 10.727088546184701,
        "cond_entropy-2-nopunct": 2.9390951261274694,
        "distinct-3-nopunct": 0.3638464472414799,
        "vocab_size-3-nopunct": 16217,
        "unique-3-nopunct": 12028,
        "entropy-3-nopunct": 12.117016723022449,
        "cond_entropy-3-nopunct": 1.498301759267039,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/dart_validation.json",
        "local_recall": {
            "1": 0.02182576175587027,
            "2": 0.014825202844836221,
            "3": 0.01471004243281471,
            "4": 0.02784950202877167,
            "5": 0.04876448720752241,
            "6": 0.06397583745194947,
            "7": 0.087248322147651,
            "8": 0.09556451612903226,
            "9": 0.10259301014656144,
            "10": 0.11380323054331865,
            "11": 0.11745334796926454,
            "12": 0.11544461778471139,
            "13": 0.09190371991247265,
            "14": 0.07246376811594203,
            "15": 0.05660377358490566,
            "16": 0.09027777777777778,
            "17": 0.05128205128205128,
            "18": 0.06666666666666667,
            "19": 0.041666666666666664,
            "20": 0.058823529411764705,
            "21": 0.13043478260869565,
            "22": 0.0625,
            "23": 0.06666666666666667,
            "24": 0.0,
            "25": 0.16666666666666666,
            "26": 0.0,
            "27": 0,
            "28": 0.0,
            "29": 0.0,
            "30": 0.0,
            "31": 0.0,
            "32": 0,
            "33": 0,
            "34": 0,
            "35": 0,
            "36": 0,
            "37": 0.0,
            "38": 0,
            "39": 0,
            "40": 0,
            "41": 0,
            "42": 0,
            "43": 0,
            "44": 0,
            "45": 0,
            "46": 0,
            "47": 0,
            "48": 0,
            "49": 0,
            "50": 0,
            "51": 0,
            "52": 0,
            "53": 0,
            "54": 0,
            "55": 0,
            "56": 0,
            "57": 0,
            "58": 0,
            "59": 0,
            "60": 0,
            "61": 0,
            "62": 0,
            "63": 0,
            "64": 0,
            "65": 0,
            "66": 0,
            "67": 0,
            "68": 0,
            "69": 0,
            "70": 0,
            "71": 0,
            "72": 0
        },
        "nist": 0.6152068214816708,
        "rouge1": {
            "precision": 0.04082,
            "recall": 0.7384,
            "fmeasure": 0.07678
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.04082,
            "recall": 0.7384,
            "fmeasure": 0.07678
        },
        "rougeLsum": {
            "precision": 0.04082,
            "recall": 0.7384,
            "fmeasure": 0.07678
        },
        "bleu": 0.006,
        "meteor": 0.08328067494891667,
        "bertscore": {
            "precision": 0.90328,
            "recall": 0.88971,
            "f1": 0.89608
        },
        "nubia": {
            "semantic_relation": 4.07473,
            "contradiction": 6.2562,
            "irrelevancy": 19.75549,
            "logical_agreement": 73.98831,
            "grammar_ref": 4.89251,
            "grammar_hyp": 4.84348,
            "nubia_score": 0.68059
        },
        "bleurt": 0.05591
    },
    "web_nlg_ru_validation": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_validation",
        "N": 790,
        "msttr-100": 0.53149,
        "msttr-100_nopunct": 0.56608,
        "total_length": 8712,
        "mean_pred_length": 11.027848101265823,
        "std_pred_length": 3.0342741174727026,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.17527548209366392,
        "vocab_size-1": 1527,
        "unique-1": 756,
        "entropy-1": 8.572509449473124,
        "distinct-2": 0.40431709164352436,
        "vocab_size-2": 3203,
        "unique-2": 2028,
        "entropy-2": 10.743086271467309,
        "cond_entropy-2": 2.2314753788767496,
        "distinct-3": 0.5501962983735278,
        "vocab_size-3": 3924,
        "unique-3": 2777,
        "entropy-3": 11.366249730701469,
        "cond_entropy-3": 0.7630265234908175,
        "total_length-nopunct": 7453,
        "mean_pred_length-nopunct": 9.434177215189873,
        "std_pred_length-nopunct": 2.6519821140331503,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.2038105460888233,
        "vocab_size-1-nopunct": 1519,
        "unique-1-nopunct": 754,
        "entropy-1-nopunct": 8.98605915685419,
        "distinct-2-nopunct": 0.4365901245685127,
        "vocab_size-2-nopunct": 2909,
        "unique-2-nopunct": 1919,
        "entropy-2-nopunct": 10.678346458537469,
        "cond_entropy-2-nopunct": 1.9015524522387321,
        "distinct-3-nopunct": 0.5734718201941086,
        "vocab_size-3-nopunct": 3368,
        "unique-3-nopunct": 2436,
        "entropy-3-nopunct": 11.174424638343478,
        "cond_entropy-3-nopunct": 0.6565830647753571,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_validation.json",
        "local_recall": {
            "1": 0.14480354879594423,
            "2": 0.3698657583650571,
            "3": 0.5110995037868895,
            "4": 0.7878787878787878,
            "5": 0.6538461538461539,
            "6": 0.9,
            "7": 0.75,
            "8": 0,
            "9": 1.0
        },
        "nist": 1.852841065486399,
        "rouge1": {
            "precision": 0.21333,
            "recall": 0.16357,
            "fmeasure": 0.17671
        },
        "rouge2": {
            "precision": 0.09058,
            "recall": 0.05948,
            "fmeasure": 0.06761
        },
        "rougeL": {
            "precision": 0.20526,
            "recall": 0.15772,
            "fmeasure": 0.17012
        },
        "rougeLsum": {
            "precision": 0.20526,
            "recall": 0.15772,
            "fmeasure": 0.17012
        },
        "bleu": 22.09502,
        "meteor": 0.38920918825954576,
        "bertscore": {
            "precision": 0.94744,
            "recall": 0.91434,
            "f1": 0.92968
        },
        "nubia": {
            "semantic_relation": 3.60468,
            "contradiction": 23.03419,
            "irrelevancy": 22.07458,
            "logical_agreement": 54.89124,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.70128,
            "nubia_score": 0.69602
        },
        "bleurt": 0.07597
    },
    "web_nlg_ru_test": {
        "predictions_file": "ByT5-large (Baseline)/web_nlg_ru_test",
        "N": 1102,
        "msttr-100": 0.77589,
        "msttr-100_nopunct": 0.84781,
        "total_length": 12438,
        "mean_pred_length": 11.286751361161524,
        "std_pred_length": 2.928579149473418,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.20887602508441871,
        "vocab_size-1": 2598,
        "unique-1": 1357,
        "entropy-1": 9.166551868923264,
        "distinct-2": 0.5018525052928723,
        "vocab_size-2": 5689,
        "unique-2": 3923,
        "entropy-2": 11.773120600378537,
        "cond_entropy-2": 2.6698947743975268,
        "distinct-3": 0.7008989642368575,
        "vocab_size-3": 7173,
        "unique-3": 5744,
        "entropy-3": 12.498294749534715,
        "cond_entropy-3": 0.8405908095418169,
        "total_length-nopunct": 10585,
        "mean_pred_length-nopunct": 9.605263157894736,
        "std_pred_length-nopunct": 2.5985633113001185,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.2446858762399622,
        "vocab_size-1-nopunct": 2590,
        "unique-1-nopunct": 1356,
        "entropy-1-nopunct": 9.70156456554306,
        "distinct-2-nopunct": 0.550985974902457,
        "vocab_size-2-nopunct": 5225,
        "unique-2-nopunct": 3802,
        "entropy-2-nopunct": 11.728057128112315,
        "cond_entropy-2-nopunct": 2.2511345179257356,
        "distinct-3-nopunct": 0.7340412838563417,
        "vocab_size-3-nopunct": 6152,
        "unique-3-nopunct": 5086,
        "entropy-3-nopunct": 12.299930060573717,
        "cond_entropy-3-nopunct": 0.7032714706405314,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1615873242452359,
            "2": 0.3500756846016238,
            "3": 0.48423213286060834,
            "4": 0.6363636363636364,
            "5": 0.6216216216216216,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "nist": 1.6441853776449913,
        "rouge1": {
            "precision": 0.2815,
            "recall": 0.23046,
            "fmeasure": 0.24383
        },
        "rouge2": {
            "precision": 0.12946,
            "recall": 0.10392,
            "fmeasure": 0.11083
        },
        "rougeL": {
            "precision": 0.2755,
            "recall": 0.22541,
            "fmeasure": 0.2384
        },
        "rougeLsum": {
            "precision": 0.2755,
            "recall": 0.22541,
            "fmeasure": 0.2384
        },
        "bleu": 21.27264,
        "meteor": 0.39086094147752687,
        "bertscore": {
            "precision": 0.94952,
            "recall": 0.91243,
            "f1": 0.92974
        },
        "nubia": {
            "semantic_relation": 3.58648,
            "contradiction": 22.12065,
            "irrelevancy": 22.73304,
            "logical_agreement": 55.14631,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.73164,
            "nubia_score": 0.69368
        },
        "bleurt": 0.09072
    }
}
