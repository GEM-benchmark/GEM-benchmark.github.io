{
    "submission_name": "ByT5-small (Baseline)",
    "param_count": 0,
    "web_nlg_ru_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_challenge_train_sample",
        "N": 501
    },
    "web_nlg_ru_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.16829583405449,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.3733820640315089,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.031262576450960096,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "nist": 0.5803717267906512,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.33815,
            "fmeasure": 0.44828
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.22362,
            "fmeasure": 0.29829
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.2401,
            "fmeasure": 0.31897
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.2401,
            "fmeasure": 0.31897
        },
        "bleu": 22.08417,
        "nubia": {
            "semantic_relation": 2.15687,
            "contradiction": 33.23524,
            "irrelevancy": 43.87644,
            "logical_agreement": 22.88832,
            "grammar_ref": 4.14314,
            "grammar_hyp": 4.63942,
            "nubia_score": 0.11245
        },
        "bleurt": -1.08021,
        "meteor": 0.2108447979203352,
        "bertscore": {
            "precision": 0.90719,
            "recall": 0.83107,
            "f1": 0.86746
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 4.027681991198191,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.7105263157894737,
        "vocab_size-1": 27,
        "unique-1": 19,
        "entropy-1": 4.6093837632727865,
        "distinct-2": 0.9428571428571428,
        "vocab_size-2": 33,
        "unique-2": 31,
        "entropy-2": 5.014997302659249,
        "cond_entropy-2": 0.40320300368682105,
        "distinct-3": 0.96875,
        "vocab_size-3": 31,
        "unique-3": 30,
        "entropy-3": 4.9375,
        "cond_entropy-3": -0.06678301694496643,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.453880987666651,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.24333048679950664,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.08349873228287957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.25,
            "3": 0.5
        },
        "nist": 1.0859680592932952,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "bleu": 14.0385,
        "nubia": {
            "semantic_relation": 3.63462,
            "contradiction": 18.12701,
            "irrelevancy": 16.23435,
            "logical_agreement": 65.63863,
            "grammar_ref": 2.52713,
            "grammar_hyp": 2.81563,
            "nubia_score": 0.69123
        },
        "bleurt": -0.02335,
        "meteor": 0.35828942206621,
        "bertscore": {
            "precision": 0.94666,
            "recall": 0.90412,
            "f1": 0.92454
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.2417888922404337,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.9321380397593733,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.25533082133206014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.23529411764705882
        },
        "nist": 0.9193534437607584,
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.24324,
            "fmeasure": 0.32143
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.13889,
            "fmeasure": 0.18519
        },
        "rougeL": {
            "precision": 0.31579,
            "recall": 0.23587,
            "fmeasure": 0.26655
        },
        "rougeLsum": {
            "precision": 0.31579,
            "recall": 0.23587,
            "fmeasure": 0.26655
        },
        "bleu": 9.77892,
        "nubia": {
            "semantic_relation": 2.95786,
            "contradiction": 0.16485,
            "irrelevancy": 99.53732,
            "logical_agreement": 0.29783,
            "grammar_ref": 4.39709,
            "grammar_hyp": 4.80148,
            "nubia_score": 0.25696
        },
        "bleurt": -0.53765,
        "meteor": 0.1417968854397355,
        "bertscore": {
            "precision": 0.85868,
            "recall": 0.78568,
            "f1": 0.82056
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.8219280948873626,
        "distinct-2": 0.8421052631578947,
        "vocab_size-2": 16,
        "unique-2": 13,
        "entropy-2": 3.9321380397593733,
        "cond_entropy-2": 0.13652573434569693,
        "distinct-3": 0.8888888888888888,
        "vocab_size-3": 16,
        "unique-3": 14,
        "entropy-3": 3.94770277922009,
        "cond_entropy-3": 0.03310859910983795,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.506890595608518,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.521640636343319,
        "cond_entropy-2-nopunct": 0.04332146930622848,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.5465935642949384,
        "cond_entropy-3-nopunct": 0.046930949929641676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.47619047619047616
        },
        "nist": 2.5254597197748554,
        "rouge1": {
            "precision": 0.71111,
            "recall": 0.50472,
            "fmeasure": 0.58728
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.26852,
            "fmeasure": 0.30637
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.40769,
            "fmeasure": 0.46187
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.40769,
            "fmeasure": 0.46187
        },
        "bleu": 25.12712,
        "nubia": {
            "semantic_relation": 3.50662,
            "contradiction": 1.55056,
            "irrelevancy": 13.8495,
            "logical_agreement": 84.59994,
            "grammar_ref": 4.75948,
            "grammar_hyp": 5.00575,
            "nubia_score": 0.45745
        },
        "bleurt": -0.24717,
        "meteor": 0.24705932586472767,
        "bertscore": {
            "precision": 0.91893,
            "recall": 0.85668,
            "f1": 0.88672
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 29,
        "unique-1": 23,
        "entropy-1": 4.736216203349846,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.4201089371539294,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.6578823768686535,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.28899211045304996,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.3409090909090909
        },
        "nist": 1.5747515979580649,
        "rouge1": {
            "precision": 0.64744,
            "recall": 0.43796,
            "fmeasure": 0.52113
        },
        "rouge2": {
            "precision": 0.24,
            "recall": 0.15936,
            "fmeasure": 0.19107
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.39649,
            "fmeasure": 0.45536
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.39649,
            "fmeasure": 0.45536
        },
        "bleu": 14.72184,
        "nubia": {
            "semantic_relation": 2.9999,
            "contradiction": 48.52153,
            "irrelevancy": 50.08443,
            "logical_agreement": 1.39405,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.51727,
            "nubia_score": 0.29068
        },
        "bleurt": -0.15308,
        "meteor": 0.21720254634698327,
        "bertscore": {
            "precision": 0.87442,
            "recall": 0.83518,
            "f1": 0.85421
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666
        },
        "nist": 0.7054392373313632,
        "rouge1": {
            "precision": 0.16667,
            "recall": 0.13333,
            "fmeasure": 0.14815
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.08333,
            "recall": 0.06667,
            "fmeasure": 0.07407
        },
        "rougeLsum": {
            "precision": 0.08333,
            "recall": 0.06667,
            "fmeasure": 0.07407
        },
        "bleu": 3.1935,
        "nubia": {
            "semantic_relation": 1.7099,
            "contradiction": 1.44669,
            "irrelevancy": 97.99002,
            "logical_agreement": 0.56328,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.99597,
            "nubia_score": 0.11341
        },
        "bleurt": -0.6843,
        "meteor": 0.07766990291262137,
        "bertscore": {
            "precision": 0.77193,
            "recall": 0.75004,
            "f1": 0.76016
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.38461538461538464
        },
        "nist": 1.7226471781503148,
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.4,
            "fmeasure": 0.42857
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.26667,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.26667,
            "fmeasure": 0.28571
        },
        "bleu": 4.0043,
        "nubia": {
            "semantic_relation": 2.75884,
            "contradiction": 58.37207,
            "irrelevancy": 40.32453,
            "logical_agreement": 1.30339,
            "grammar_ref": 5.57252,
            "grammar_hyp": 5.25966,
            "nubia_score": 0.2522
        },
        "bleurt": -0.81535,
        "meteor": 0.14814814814814814,
        "bertscore": {
            "precision": 0.77788,
            "recall": 0.79189,
            "f1": 0.78482
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nist": 2.0298972812678846,
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.68718,
            "fmeasure": 0.56277
        },
        "rouge2": {
            "precision": 0.29167,
            "recall": 0.41667,
            "fmeasure": 0.32222
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.68718,
            "fmeasure": 0.56277
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.68718,
            "fmeasure": 0.56277
        },
        "bleu": 12.2562,
        "nubia": {
            "semantic_relation": 3.18872,
            "contradiction": 60.9561,
            "irrelevancy": 26.75656,
            "logical_agreement": 12.28733,
            "grammar_ref": 6.66832,
            "grammar_hyp": 6.00806,
            "nubia_score": 0.35304
        },
        "bleurt": 0.36534,
        "meteor": 0.3494153946457485,
        "bertscore": {
            "precision": 0.95416,
            "recall": 0.96968,
            "f1": 0.9204
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.02677875348937537,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.02961067210860197,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.25,
            "3": 0.5
        },
        "nist": 2.4019505215766874,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.38333,
            "fmeasure": 0.40368
        },
        "rouge2": {
            "precision": 0.21667,
            "recall": 0.21032,
            "fmeasure": 0.21034
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.25333,
            "fmeasure": 0.26794
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.25333,
            "fmeasure": 0.26794
        },
        "bleu": 15.1151,
        "nubia": {
            "semantic_relation": 2.31296,
            "contradiction": 1.02337,
            "irrelevancy": 90.56751,
            "logical_agreement": 8.40912,
            "grammar_ref": 4.19943,
            "grammar_hyp": 4.69434,
            "nubia_score": 0.23379
        },
        "bleurt": -0.61515,
        "meteor": 0.22018091199042092,
        "bertscore": {
            "precision": 0.84438,
            "recall": 0.823,
            "f1": 0.83355
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910023,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2186000898557489,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064474,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.22961067210860203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.35714285714285715
        },
        "nist": 0.1703900932726753,
        "rouge1": {
            "precision": 0.65909,
            "recall": 0.38095,
            "fmeasure": 0.48191
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.16141,
            "fmeasure": 0.20587
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.20952,
            "fmeasure": 0.26535
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.20952,
            "fmeasure": 0.26535
        },
        "bleu": 10.48792,
        "nubia": {
            "semantic_relation": 2.98122,
            "contradiction": 39.5197,
            "irrelevancy": 2.6155,
            "logical_agreement": 57.86481,
            "grammar_ref": 3.72412,
            "grammar_hyp": 4.45402,
            "nubia_score": 0.25741
        },
        "bleurt": -0.57217,
        "meteor": 0.14495469617086912,
        "bertscore": {
            "precision": 0.83541,
            "recall": 0.72199,
            "f1": 0.77428
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.5526315789473685,
        "vocab_size-1": 21,
        "unique-1": 8,
        "entropy-1": 4.247927513443584,
        "distinct-2": 0.7222222222222222,
        "vocab_size-2": 26,
        "unique-2": 16,
        "entropy-2": 4.614369445886756,
        "cond_entropy-2": 0.36644193244317125,
        "distinct-3": 0.7352941176470589,
        "vocab_size-3": 25,
        "unique-3": 16,
        "entropy-3": 4.558051076544457,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.59375,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 4.125,
        "distinct-2-nopunct": 0.7,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.306890595608518,
        "cond_entropy-2-nopunct": 0.24022392894185188,
        "distinct-3-nopunct": 0.7142857142857143,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 4.235926350629033,
        "cond_entropy-3-nopunct": -0.02810710212234293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.8666666666666667
        },
        "nist": 4.83659519269576,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.83115,
            "fmeasure": 0.87794
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.58673,
            "fmeasure": 0.61246
        },
        "rougeL": {
            "precision": 0.6875,
            "recall": 0.60161,
            "fmeasure": 0.63967
        },
        "rougeLsum": {
            "precision": 0.6875,
            "recall": 0.60161,
            "fmeasure": 0.63967
        },
        "bleu": 60.06502,
        "nubia": {
            "semantic_relation": 4.19012,
            "contradiction": 0.17109,
            "irrelevancy": 44.29111,
            "logical_agreement": 55.53781,
            "grammar_ref": 4.80653,
            "grammar_hyp": 5.13583,
            "nubia_score": 0.6641
        },
        "bleurt": 0.32297,
        "meteor": 0.4631576290861218,
        "bertscore": {
            "precision": 0.95569,
            "recall": 0.9368,
            "f1": 0.93759
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185189,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.02810710212234293,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666
        },
        "nist": 2.644760024053843,
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.5625,
            "fmeasure": 0.59531
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.25098,
            "fmeasure": 0.26696
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.47222,
            "fmeasure": 0.50049
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.47222,
            "fmeasure": 0.50049
        },
        "bleu": 14.88055,
        "nubia": {
            "semantic_relation": 3.64839,
            "contradiction": 3.91587,
            "irrelevancy": 92.90575,
            "logical_agreement": 3.17838,
            "grammar_ref": 4.60656,
            "grammar_hyp": 4.9954,
            "nubia_score": 0.47299
        },
        "bleurt": 0.26055,
        "meteor": 0.33321505959683195,
        "bertscore": {
            "precision": 0.93203,
            "recall": 0.92139,
            "f1": 0.92668
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.0994705707972505,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.5081746640479654,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.031262576450960075,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.14285714285714285
        },
        "nist": 1.5367254930584515,
        "rouge1": {
            "precision": 0.20455,
            "recall": 0.275,
            "fmeasure": 0.22917
        },
        "rouge2": {
            "precision": 0.04762,
            "recall": 0.05263,
            "fmeasure": 0.05
        },
        "rougeL": {
            "precision": 0.13636,
            "recall": 0.2,
            "fmeasure": 0.15774
        },
        "rougeLsum": {
            "precision": 0.13636,
            "recall": 0.2,
            "fmeasure": 0.15774
        },
        "bleu": 6.30358,
        "nubia": {
            "semantic_relation": 2.372,
            "contradiction": 39.9148,
            "irrelevancy": 53.83716,
            "logical_agreement": 6.24804,
            "grammar_ref": 5.69136,
            "grammar_hyp": 4.63989,
            "nubia_score": 0.29249
        },
        "bleurt": -0.65804,
        "meteor": 0.11387739034001544,
        "bertscore": {
            "precision": 0.76585,
            "recall": 0.7526,
            "f1": 0.75917
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.175735869100492,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 20,
        "unique-2": 18,
        "entropy-2": 4.277613436819114,
        "cond_entropy-2": 0.0722332989439208,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 20,
        "unique-3": 19,
        "entropy-3": 4.297079327540665,
        "cond_entropy-3": -0.019495148239489106,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.095795255000933,
        "distinct-2-nopunct": 0.9047619047619048,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.20184123230257,
        "cond_entropy-2-nopunct": 0.07574294699860612,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.221928094887362,
        "cond_entropy-3-nopunct": -0.020389327891398006,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.5
        },
        "nist": 0.9979724757517527,
        "rouge1": {
            "precision": 0.67308,
            "recall": 0.42424,
            "fmeasure": 0.50926
        },
        "rouge2": {
            "precision": 0.32,
            "recall": 0.18806,
            "fmeasure": 0.23183
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.31212,
            "fmeasure": 0.3761
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.31212,
            "fmeasure": 0.3761
        },
        "bleu": 21.52817,
        "nubia": {
            "semantic_relation": 2.67978,
            "contradiction": 36.36558,
            "irrelevancy": 10.9939,
            "logical_agreement": 52.64052,
            "grammar_ref": 4.34131,
            "grammar_hyp": 5.29243,
            "nubia_score": 0.18575
        },
        "bleurt": -0.00557,
        "meteor": 0.20615794744610214,
        "bertscore": {
            "precision": 0.92971,
            "recall": 0.88037,
            "f1": 0.89235
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 166,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.755,
        "total_length": 2499,
        "mean_pred_length": 15.05421686746988,
        "std_pred_length": 5.88059502777392,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.45818327330932374,
        "vocab_size-1": 1145,
        "unique-1": 924,
        "entropy-1": 8.449685125724871,
        "distinct-2": 0.8718388341191599,
        "vocab_size-2": 2034,
        "unique-2": 1908,
        "entropy-2": 10.784075478531184,
        "cond_entropy-2": 2.0921437020087534,
        "distinct-3": 0.9769266266728196,
        "vocab_size-3": 2117,
        "unique-3": 2079,
        "entropy-3": 11.030251527614631,
        "cond_entropy-3": 0.26834798670777205,
        "total_length-nopunct": 2203,
        "mean_pred_length-nopunct": 13.271084337349398,
        "std_pred_length-nopunct": 5.180362133698831,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5152065365410804,
        "vocab_size-1-nopunct": 1135,
        "unique-1-nopunct": 922,
        "entropy-1-nopunct": 8.729641659858475,
        "distinct-2-nopunct": 0.8807069219440353,
        "vocab_size-2-nopunct": 1794,
        "unique-2-nopunct": 1696,
        "entropy-2-nopunct": 10.60301613252665,
        "cond_entropy-2-nopunct": 2.0329394286905957,
        "distinct-3-nopunct": 0.982896846606093,
        "vocab_size-3-nopunct": 1839,
        "unique-3-nopunct": 1813,
        "entropy-3-nopunct": 10.83270471977269,
        "cond_entropy-3-nopunct": 0.2556691035395269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.029078363725973385,
            "2": 0.13440860215053763,
            "3": 0.3167259786476868,
            "4": 0.4678111587982833,
            "5": 0.5529953917050692,
            "6": 0.6818181818181818,
            "7": 0.6830985915492958,
            "8": 0.7395498392282959,
            "9": 0.8434343434343434,
            "10": 0.9075907590759076
        },
        "nist": 11.663116821488472,
        "rouge1": {
            "precision": 0.87951,
            "recall": 0.84362,
            "fmeasure": 0.85058
        },
        "rouge2": {
            "precision": 0.77039,
            "recall": 0.73679,
            "fmeasure": 0.74034
        },
        "rougeL": {
            "precision": 0.85947,
            "recall": 0.82836,
            "fmeasure": 0.83443
        },
        "rougeLsum": {
            "precision": 0.85947,
            "recall": 0.82836,
            "fmeasure": 0.83443
        },
        "bleu": 82.57338,
        "nubia": {
            "semantic_relation": 4.13136,
            "contradiction": 3.51548,
            "irrelevancy": 27.65341,
            "logical_agreement": 68.83112,
            "grammar_ref": 4.62208,
            "grammar_hyp": 4.92616,
            "nubia_score": 0.65521
        },
        "bleurt": 0.22734,
        "meteor": 0.48795978169269705,
        "bertscore": {
            "precision": 0.96849,
            "recall": 0.95952,
            "f1": 0.96033
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level1": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json"
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "nist": 1.5306625155282125,
        "rouge1": {
            "precision": 0.23077,
            "recall": 0.23077,
            "fmeasure": 0.23077
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.08333,
            "fmeasure": 0.08333
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.23077,
            "fmeasure": 0.23077
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.23077,
            "fmeasure": 0.23077
        },
        "bleu": 8.4931,
        "nubia": {
            "semantic_relation": 1.46451,
            "contradiction": 4.39456,
            "irrelevancy": 85.38399,
            "logical_agreement": 10.22145,
            "grammar_ref": 4.12033,
            "grammar_hyp": 4.96045,
            "nubia_score": 0.09994
        },
        "bleurt": -0.83706,
        "meteor": 0.09423415101120709,
        "bertscore": {
            "precision": 0.74073,
            "recall": 0.69739,
            "f1": 0.7184
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.7
        },
        "nist": 3.465089104049031,
        "rouge1": {
            "precision": 0.69048,
            "recall": 0.70696,
            "fmeasure": 0.69841
        },
        "rouge2": {
            "precision": 0.5641,
            "recall": 0.57692,
            "fmeasure": 0.57026
        },
        "rougeL": {
            "precision": 0.69048,
            "recall": 0.70696,
            "fmeasure": 0.69841
        },
        "rougeLsum": {
            "precision": 0.69048,
            "recall": 0.70696,
            "fmeasure": 0.69841
        },
        "bleu": 64.75445,
        "nubia": {
            "semantic_relation": 2.91043,
            "contradiction": 51.04697,
            "irrelevancy": 41.52355,
            "logical_agreement": 7.42948,
            "grammar_ref": 4.48671,
            "grammar_hyp": 4.8018,
            "nubia_score": 0.3226
        },
        "bleurt": -0.00196,
        "meteor": 0.44550313106843964,
        "bertscore": {
            "precision": 0.91265,
            "recall": 0.92998,
            "f1": 0.92123
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "nist": 0.31592321743697377,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.41176,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.25,
            "fmeasure": 0.34783
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.35294,
            "fmeasure": 0.48
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.35294,
            "fmeasure": 0.48
        },
        "bleu": 15.98205,
        "nubia": {
            "semantic_relation": 2.69293,
            "contradiction": 61.91548,
            "irrelevancy": 8.5993,
            "logical_agreement": 29.48523,
            "grammar_ref": 4.28272,
            "grammar_hyp": 5.32215,
            "nubia_score": 0.17607
        },
        "bleurt": 0.02689,
        "meteor": 0.22923407173743382,
        "bertscore": {
            "precision": 0.94721,
            "recall": 0.82881,
            "f1": 0.88407
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 183,
        "msttr-100": 0.19429,
        "msttr-100_nopunct": 0.20286,
        "total_length": 2100,
        "mean_pred_length": 11.475409836065573,
        "std_pred_length": 1.3380504214696305,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 13,
        "distinct-1": 0.02666666666666667,
        "vocab_size-1": 56,
        "unique-1": 18,
        "entropy-1": 3.8549486184676662,
        "distinct-2": 0.04225352112676056,
        "vocab_size-2": 81,
        "unique-2": 32,
        "entropy-2": 4.332112347908552,
        "cond_entropy-2": 0.44523420597281715,
        "distinct-3": 0.04440599769319493,
        "vocab_size-3": 77,
        "unique-3": 31,
        "entropy-3": 4.197392108730996,
        "cond_entropy-3": -0.11522636285722866,
        "total_length-nopunct": 1441,
        "mean_pred_length-nopunct": 7.8743169398907105,
        "std_pred_length-nopunct": 0.6533197679706599,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.03747397640527411,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 3.9201508298627052,
        "distinct-2-nopunct": 0.051669316375198726,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 3.8660971250210614,
        "cond_entropy-2-nopunct": -0.030053909230551217,
        "distinct-3-nopunct": 0.053023255813953486,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 3.6388575526827167,
        "cond_entropy-3-nopunct": -0.20105847241844674,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.15952143569292124
        },
        "nist": 0.8468193981817773,
        "rouge1": {
            "precision": 0.22789,
            "recall": 0.39304,
            "fmeasure": 0.27544
        },
        "rouge2": {
            "precision": 0.08506,
            "recall": 0.14483,
            "fmeasure": 0.09915
        },
        "rougeL": {
            "precision": 0.21604,
            "recall": 0.37133,
            "fmeasure": 0.26074
        },
        "rougeLsum": {
            "precision": 0.21604,
            "recall": 0.37133,
            "fmeasure": 0.26074
        },
        "bleu": 4.36722,
        "nubia": {
            "semantic_relation": 2.32041,
            "contradiction": 46.11324,
            "irrelevancy": 41.39415,
            "logical_agreement": 12.49261,
            "grammar_ref": 6.72681,
            "grammar_hyp": 6.23747,
            "nubia_score": 0.22591
        },
        "bleurt": -0.92746,
        "meteor": 0.08940620866612657,
        "bertscore": {
            "precision": 0.81234,
            "recall": 0.86702,
            "f1": 0.83843
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 58,
        "msttr-100": 0.72222,
        "msttr-100_nopunct": 0.74875,
        "total_length": 989,
        "mean_pred_length": 17.051724137931036,
        "std_pred_length": 5.703666134353937,
        "median_pred_length": 16.5,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.5247724974721941,
        "vocab_size-1": 519,
        "unique-1": 422,
        "entropy-1": 7.934877277196197,
        "distinct-2": 0.9301825993555317,
        "vocab_size-2": 866,
        "unique-2": 829,
        "entropy-2": 9.68965999898526,
        "cond_entropy-2": 1.5934484773810629,
        "distinct-3": 0.9885452462772051,
        "vocab_size-3": 863,
        "unique-3": 859,
        "entropy-3": 9.738658827651383,
        "cond_entropy-3": 0.06049102431005302,
        "total_length-nopunct": 897,
        "mean_pred_length-nopunct": 15.46551724137931,
        "std_pred_length-nopunct": 5.531151645504289,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.568561872909699,
        "vocab_size-1-nopunct": 510,
        "unique-1-nopunct": 419,
        "entropy-1-nopunct": 8.060654817269858,
        "distinct-2-nopunct": 0.9439809296781884,
        "vocab_size-2-nopunct": 792,
        "unique-2-nopunct": 761,
        "entropy-2-nopunct": 9.580699397419368,
        "cond_entropy-2-nopunct": 1.59857625368691,
        "distinct-3-nopunct": 0.9974391805377721,
        "vocab_size-3-nopunct": 779,
        "unique-3-nopunct": 777,
        "entropy-3-nopunct": 9.60405709921738,
        "cond_entropy-3-nopunct": 0.030586896388619056,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02553191489361702,
            "2": 0.12403100775193798,
            "3": 0.2119205298013245,
            "4": 0.45454545454545453,
            "5": 0.5333333333333333,
            "6": 0.5961538461538461,
            "7": 0.7105263157894737,
            "8": 0.7482993197278912,
            "9": 0.738562091503268,
            "10": 0.8685446009389671
        },
        "nist": 9.879456901558582,
        "rouge1": {
            "precision": 0.88255,
            "recall": 0.75998,
            "fmeasure": 0.79492
        },
        "rouge2": {
            "precision": 0.78575,
            "recall": 0.66218,
            "fmeasure": 0.69642
        },
        "rougeL": {
            "precision": 0.86772,
            "recall": 0.7419,
            "fmeasure": 0.77907
        },
        "rougeLsum": {
            "precision": 0.86772,
            "recall": 0.7419,
            "fmeasure": 0.77907
        },
        "bleu": 79.78032,
        "nubia": {
            "semantic_relation": 3.89925,
            "contradiction": 4.00204,
            "irrelevancy": 30.0121,
            "logical_agreement": 65.98587,
            "grammar_ref": 4.50862,
            "grammar_hyp": 4.99959,
            "nubia_score": 0.57658
        },
        "bleurt": 0.08179,
        "meteor": 0.4327550698421438,
        "bertscore": {
            "precision": 0.95761,
            "recall": 0.93317,
            "f1": 0.9416
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 124,
        "msttr-100": 0.70321,
        "msttr-100_nopunct": 0.742,
        "total_length": 2844,
        "mean_pred_length": 22.93548387096774,
        "std_pred_length": 4.053556653121112,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 35,
        "distinct-1": 0.4240506329113924,
        "vocab_size-1": 1206,
        "unique-1": 915,
        "entropy-1": 8.549845234396235,
        "distinct-2": 0.8301470588235295,
        "vocab_size-2": 2258,
        "unique-2": 2043,
        "entropy-2": 10.887433822358771,
        "cond_entropy-2": 2.28128503660763,
        "distinct-3": 0.9649460708782742,
        "vocab_size-3": 2505,
        "unique-3": 2427,
        "entropy-3": 11.267808879277856,
        "cond_entropy-3": 0.38690432808177433,
        "total_length-nopunct": 2524,
        "mean_pred_length-nopunct": 20.35483870967742,
        "std_pred_length-nopunct": 3.8962213878343324,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.47385103011093505,
        "vocab_size-1-nopunct": 1196,
        "unique-1-nopunct": 912,
        "entropy-1-nopunct": 8.790476960037868,
        "distinct-2-nopunct": 0.8545833333333334,
        "vocab_size-2-nopunct": 2051,
        "unique-2-nopunct": 1891,
        "entropy-2-nopunct": 10.771819743985,
        "cond_entropy-2-nopunct": 2.0441807997091397,
        "distinct-3-nopunct": 0.9727592267135325,
        "vocab_size-3-nopunct": 2214,
        "unique-3-nopunct": 2163,
        "entropy-3-nopunct": 11.093724116245149,
        "cond_entropy-3-nopunct": 0.3311960752303819,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2236024844720497,
            "2": 0.37020316027088035,
            "3": 0.6761133603238867
        },
        "nist": 6.777413172180754,
        "rouge1": {
            "precision": 0.71625,
            "recall": 0.64724,
            "fmeasure": 0.67009
        },
        "rouge2": {
            "precision": 0.45032,
            "recall": 0.41903,
            "fmeasure": 0.42542
        },
        "rougeL": {
            "precision": 0.58107,
            "recall": 0.53294,
            "fmeasure": 0.54622
        },
        "rougeLsum": {
            "precision": 0.58107,
            "recall": 0.53294,
            "fmeasure": 0.54622
        },
        "bleu": 33.06389,
        "nubia": {
            "semantic_relation": 3.77567,
            "contradiction": 12.97664,
            "irrelevancy": 35.3719,
            "logical_agreement": 51.65145,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.44652,
            "nubia_score": 0.58875
        },
        "bleurt": -0.01878,
        "meteor": 0.3230828602834198,
        "bertscore": {
            "precision": 0.91036,
            "recall": 0.89835,
            "f1": 0.9022
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.6896551724137931,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.073329701949522,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 24,
        "unique-2": 22,
        "entropy-2": 4.450212064914748,
        "cond_entropy-2": 0.4049056234358702,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.6808134280893965,
        "cond_entropy-3": 0.24382887640216078,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9238561897747233,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.16829583405449,
        "cond_entropy-2-nopunct": 0.23277297761309837,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.436605434317882,
        "cond_entropy-3-nopunct": 0.24294728142281322,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.4444444444444444
        },
        "nist": 4.02055520564225,
        "rouge1": {
            "precision": 0.76,
            "recall": 0.6129,
            "fmeasure": 0.67857
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.46667,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.76,
            "recall": 0.6129,
            "fmeasure": 0.67857
        },
        "rougeLsum": {
            "precision": 0.76,
            "recall": 0.6129,
            "fmeasure": 0.67857
        },
        "bleu": 37.50618,
        "nubia": {
            "semantic_relation": 2.69315,
            "contradiction": 88.22961,
            "irrelevancy": 5.58621,
            "logical_agreement": 6.18418,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.89347,
            "nubia_score": 0.27858
        },
        "bleurt": -0.23734,
        "meteor": 0.3018269986761726,
        "bertscore": {
            "precision": 0.97161,
            "recall": 0.94842,
            "f1": 0.95987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 71,
        "msttr-100": 0.67625,
        "msttr-100_nopunct": 0.70857,
        "total_length": 858,
        "mean_pred_length": 12.084507042253522,
        "std_pred_length": 4.938342308608493,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.44405594405594406,
        "vocab_size-1": 381,
        "unique-1": 302,
        "entropy-1": 7.215293914301361,
        "distinct-2": 0.8055908513341804,
        "vocab_size-2": 634,
        "unique-2": 569,
        "entropy-2": 9.035535478682455,
        "cond_entropy-2": 1.5128834284592023,
        "distinct-3": 0.909217877094972,
        "vocab_size-3": 651,
        "unique-3": 613,
        "entropy-3": 9.248015375676498,
        "cond_entropy-3": 0.2285589313859467,
        "total_length-nopunct": 758,
        "mean_pred_length-nopunct": 10.67605633802817,
        "std_pred_length-nopunct": 4.369467198922522,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.4947229551451187,
        "vocab_size-1-nopunct": 375,
        "unique-1-nopunct": 300,
        "entropy-1-nopunct": 7.388018762783947,
        "distinct-2-nopunct": 0.8020378457059679,
        "vocab_size-2-nopunct": 551,
        "unique-2-nopunct": 492,
        "entropy-2-nopunct": 8.827540497777797,
        "cond_entropy-2-nopunct": 1.593712241530636,
        "distinct-3-nopunct": 0.9042207792207793,
        "vocab_size-3-nopunct": 557,
        "unique-3-nopunct": 521,
        "entropy-3-nopunct": 9.021131812557757,
        "cond_entropy-3-nopunct": 0.2523421364723957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2737430167597765,
            "2": 0.6210526315789474,
            "3": 0.8012048192771084
        },
        "nist": 7.068867128583985,
        "rouge1": {
            "precision": 0.75988,
            "recall": 0.76705,
            "fmeasure": 0.74927
        },
        "rouge2": {
            "precision": 0.56491,
            "recall": 0.58305,
            "fmeasure": 0.56186
        },
        "rougeL": {
            "precision": 0.72289,
            "recall": 0.73209,
            "fmeasure": 0.71451
        },
        "rougeLsum": {
            "precision": 0.72289,
            "recall": 0.73209,
            "fmeasure": 0.71451
        },
        "bleu": 52.10294,
        "nubia": {
            "semantic_relation": 4.07651,
            "contradiction": 8.12613,
            "irrelevancy": 39.72634,
            "logical_agreement": 52.14753,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.36919,
            "nubia_score": 0.67439
        },
        "bleurt": 0.37294,
        "meteor": 0.42473535598969725,
        "bertscore": {
            "precision": 0.9448,
            "recall": 0.94823,
            "f1": 0.94495
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 32,
        "msttr-100": 0.71833,
        "msttr-100_nopunct": 0.75,
        "total_length": 603,
        "mean_pred_length": 18.84375,
        "std_pred_length": 4.975624175668817,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.5538971807628524,
        "vocab_size-1": 334,
        "unique-1": 270,
        "entropy-1": 7.521096643463316,
        "distinct-2": 0.9089316987740805,
        "vocab_size-2": 519,
        "unique-2": 494,
        "entropy-2": 8.919580528370098,
        "cond_entropy-2": 1.2943780897836845,
        "distinct-3": 0.9777365491651205,
        "vocab_size-3": 527,
        "unique-3": 522,
        "entropy-3": 9.014820185477811,
        "cond_entropy-3": 0.100849235072593,
        "total_length-nopunct": 542,
        "mean_pred_length-nopunct": 16.9375,
        "std_pred_length-nopunct": 4.44365769946336,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6014760147601476,
        "vocab_size-1-nopunct": 326,
        "unique-1-nopunct": 268,
        "entropy-1-nopunct": 7.581796514986238,
        "distinct-2-nopunct": 0.9274509803921569,
        "vocab_size-2-nopunct": 473,
        "unique-2-nopunct": 453,
        "entropy-2-nopunct": 8.809685183001132,
        "cond_entropy-2-nopunct": 1.2894379714081534,
        "distinct-3-nopunct": 0.99581589958159,
        "vocab_size-3-nopunct": 476,
        "unique-3-nopunct": 474,
        "entropy-3-nopunct": 8.892498607143999,
        "cond_entropy-3-nopunct": 0.0876762308847846,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02053388090349076,
            "2": 0.16822429906542055,
            "3": 0.30985915492957744,
            "4": 0.59375,
            "5": 0.6909090909090909,
            "6": 0.6323529411764706,
            "7": 0.7575757575757576,
            "8": 0.7142857142857143,
            "9": 0.8333333333333334,
            "10": 0.9354838709677419
        },
        "nist": 9.982909150877719,
        "rouge1": {
            "precision": 0.84663,
            "recall": 0.85971,
            "fmeasure": 0.84553
        },
        "rouge2": {
            "precision": 0.73259,
            "recall": 0.74077,
            "fmeasure": 0.72594
        },
        "rougeL": {
            "precision": 0.83621,
            "recall": 0.83172,
            "fmeasure": 0.82598
        },
        "rougeLsum": {
            "precision": 0.83621,
            "recall": 0.83172,
            "fmeasure": 0.82598
        },
        "bleu": 81.22164,
        "nubia": {
            "semantic_relation": 4.30124,
            "contradiction": 4.18414,
            "irrelevancy": 30.44608,
            "logical_agreement": 65.36978,
            "grammar_ref": 4.51508,
            "grammar_hyp": 4.7043,
            "nubia_score": 0.68446
        },
        "bleurt": 0.16959,
        "meteor": 0.47227239591465964,
        "bertscore": {
            "precision": 0.95676,
            "recall": 0.96336,
            "f1": 0.95662
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 75,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.732863826479693,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.7866666666666666,
        "vocab_size-1": 59,
        "unique-1": 50,
        "entropy-1": 5.6958297778153915,
        "distinct-2": 1.0,
        "vocab_size-2": 70,
        "unique-2": 70,
        "entropy-2": 6.129283016944973,
        "cond_entropy-2": 0.3056718689719467,
        "distinct-3": 1.0,
        "vocab_size-3": 65,
        "unique-3": 65,
        "entropy-3": 6.022367813028458,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.732863826479693,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8285714285714286,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.72407547442211,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 65,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.022367813028458,
        "cond_entropy-2-nopunct": 0.3140775341850306,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": -0.11547721741993579,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.09523809523809523,
            "3": 0.25,
            "4": 0.4,
            "5": 0.42857142857142855,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0,
            "9": 0.875,
            "10": 0.9047619047619048
        },
        "nist": 7.4526155517687425,
        "rouge1": {
            "precision": 0.96696,
            "recall": 0.91324,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.92726,
            "recall": 0.86527,
            "fmeasure": 0.88767
        },
        "rougeL": {
            "precision": 0.9653,
            "recall": 0.9149,
            "fmeasure": 0.93318
        },
        "rougeLsum": {
            "precision": 0.9653,
            "recall": 0.9149,
            "fmeasure": 0.93318
        },
        "bleu": 96.11122,
        "nubia": {
            "semantic_relation": 4.36718,
            "contradiction": 0.25043,
            "irrelevancy": 25.37302,
            "logical_agreement": 74.37655,
            "grammar_ref": 5.04038,
            "grammar_hyp": 5.36444,
            "nubia_score": 0.72591
        },
        "bleurt": 0.41285,
        "meteor": 0.61550127480956,
        "bertscore": {
            "precision": 0.99202,
            "recall": 0.97812,
            "f1": 0.98314
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 200,
        "msttr-100": 0.77913,
        "msttr-100_nopunct": 0.84263,
        "total_length": 2343,
        "mean_pred_length": 11.715,
        "std_pred_length": 2.4091025299891244,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.4058898847631242,
        "vocab_size-1": 951,
        "unique-1": 636,
        "entropy-1": 8.529280308699015,
        "distinct-2": 0.7391507232851143,
        "vocab_size-2": 1584,
        "unique-2": 1271,
        "entropy-2": 10.36574826060749,
        "cond_entropy-2": 1.8232493370520206,
        "distinct-3": 0.8847143592382913,
        "vocab_size-3": 1719,
        "unique-3": 1528,
        "entropy-3": 10.678976430813163,
        "cond_entropy-3": 0.3602333388464193,
        "total_length-nopunct": 1993,
        "mean_pred_length-nopunct": 9.965,
        "std_pred_length-nopunct": 2.035626439207351,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.47415955845459107,
        "vocab_size-1-nopunct": 945,
        "unique-1-nopunct": 635,
        "entropy-1-nopunct": 8.960351645438083,
        "distinct-2-nopunct": 0.7769102063580591,
        "vocab_size-2-nopunct": 1393,
        "unique-2-nopunct": 1153,
        "entropy-2-nopunct": 10.238028190314077,
        "cond_entropy-2-nopunct": 1.4126827006688978,
        "distinct-3-nopunct": 0.90646578782172,
        "vocab_size-3-nopunct": 1444,
        "unique-3-nopunct": 1317,
        "entropy-3-nopunct": 10.438269297286284,
        "cond_entropy-3-nopunct": 0.2489360155035493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.21652003910068426,
            "2": 0.4637096774193548,
            "3": 0.6866059817945384,
            "4": 0.75,
            "5": 0.7692307692307693,
            "6": 0.6666666666666666,
            "7": 1.0
        },
        "nist": 6.040292380847819,
        "rouge1": {
            "precision": 0.29475,
            "recall": 0.27251,
            "fmeasure": 0.27866
        },
        "rouge2": {
            "precision": 0.13594,
            "recall": 0.12332,
            "fmeasure": 0.12707
        },
        "rougeL": {
            "precision": 0.28456,
            "recall": 0.26316,
            "fmeasure": 0.26887
        },
        "rougeLsum": {
            "precision": 0.28456,
            "recall": 0.26316,
            "fmeasure": 0.26887
        },
        "bleu": 38.41393,
        "nubia": {
            "semantic_relation": 3.71272,
            "contradiction": 21.00282,
            "irrelevancy": 24.31244,
            "logical_agreement": 54.68473,
            "grammar_ref": 2.7039,
            "grammar_hyp": 2.71938,
            "nubia_score": 0.73985
        },
        "bleurt": 0.13469,
        "meteor": 0.5369195912244834,
        "bertscore": {
            "precision": 0.95649,
            "recall": 0.93496,
            "f1": 0.94471
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 32,
        "msttr-100": 0.67667,
        "msttr-100_nopunct": 0.65333,
        "total_length": 380,
        "mean_pred_length": 11.875,
        "std_pred_length": 2.394655507583502,
        "median_pred_length": 12.5,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.4763157894736842,
        "vocab_size-1": 181,
        "unique-1": 109,
        "entropy-1": 6.828434280110581,
        "distinct-2": 0.735632183908046,
        "vocab_size-2": 256,
        "unique-2": 194,
        "entropy-2": 7.815254838216815,
        "cond_entropy-2": 1.0790744270423505,
        "distinct-3": 0.8449367088607594,
        "vocab_size-3": 267,
        "unique-3": 224,
        "entropy-3": 7.979320858895542,
        "cond_entropy-3": 0.20292260967292114,
        "total_length-nopunct": 338,
        "mean_pred_length-nopunct": 10.5625,
        "std_pred_length-nopunct": 2.0757152381769517,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5207100591715976,
        "vocab_size-1-nopunct": 176,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.90241279794619,
        "distinct-2-nopunct": 0.7483660130718954,
        "vocab_size-2-nopunct": 229,
        "unique-2-nopunct": 174,
        "entropy-2-nopunct": 7.678386117440793,
        "cond_entropy-2-nopunct": 0.8761423535088217,
        "distinct-3-nopunct": 0.8576642335766423,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 200,
        "entropy-3-nopunct": 7.80234029460774,
        "cond_entropy-3-nopunct": 0.16389247171933455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.09482758620689655,
            "2": 0.19910514541387025,
            "3": 0.3610223642172524
        },
        "nist": 0.016029478632952295,
        "rouge1": {
            "precision": 0.42188,
            "recall": 0.22834,
            "fmeasure": 0.28328
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.11528,
            "fmeasure": 0.13403
        },
        "rougeL": {
            "precision": 0.42188,
            "recall": 0.22834,
            "fmeasure": 0.28328
        },
        "rougeLsum": {
            "precision": 0.42188,
            "recall": 0.22834,
            "fmeasure": 0.28328
        },
        "bleu": 5.94806,
        "nubia": {
            "semantic_relation": 3.13863,
            "contradiction": 22.70761,
            "irrelevancy": 24.48556,
            "logical_agreement": 52.80682,
            "grammar_ref": 2.45871,
            "grammar_hyp": 2.6747,
            "nubia_score": 0.59367
        },
        "bleurt": 0.00457,
        "meteor": 0.26318760477958947,
        "bertscore": {
            "precision": 0.9408,
            "recall": 0.85826,
            "f1": 0.89702
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 28,
        "msttr-100": 0.746,
        "msttr-100_nopunct": 0.7775,
        "total_length": 548,
        "mean_pred_length": 19.571428571428573,
        "std_pred_length": 5.924697529522206,
        "median_pred_length": 20.5,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5784671532846716,
        "vocab_size-1": 317,
        "unique-1": 251,
        "entropy-1": 7.584494258393235,
        "distinct-2": 0.9346153846153846,
        "vocab_size-2": 486,
        "unique-2": 462,
        "entropy-2": 8.871349880311298,
        "cond_entropy-2": 1.2059422143316243,
        "distinct-3": 0.9898373983739838,
        "vocab_size-3": 487,
        "unique-3": 484,
        "entropy-3": 8.919120653704327,
        "cond_entropy-3": 0.0563652898893502,
        "total_length-nopunct": 495,
        "mean_pred_length-nopunct": 17.678571428571427,
        "std_pred_length-nopunct": 5.398766866004624,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6262626262626263,
        "vocab_size-1-nopunct": 310,
        "unique-1-nopunct": 251,
        "entropy-1-nopunct": 7.6278845017220025,
        "distinct-2-nopunct": 0.9443254817987152,
        "vocab_size-2-nopunct": 441,
        "unique-2-nopunct": 422,
        "entropy-2-nopunct": 8.73823235318621,
        "cond_entropy-2-nopunct": 1.170059373882591,
        "distinct-3-nopunct": 0.9977220956719818,
        "vocab_size-3-nopunct": 438,
        "unique-3-nopunct": 437,
        "entropy-3-nopunct": 8.773521320879254,
        "cond_entropy-3-nopunct": 0.04351971671975191,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.023121387283236993,
            "2": 0.08552631578947369,
            "3": 0.2631578947368421,
            "4": 0.4838709677419355,
            "5": 0.5483870967741935,
            "6": 0.5714285714285714,
            "7": 0.6049382716049383,
            "8": 0.7580645161290323,
            "9": 0.8636363636363636,
            "10": 0.9534883720930233
        },
        "nist": 9.497502668256185,
        "rouge1": {
            "precision": 0.86444,
            "recall": 0.78747,
            "fmeasure": 0.81354
        },
        "rouge2": {
            "precision": 0.75978,
            "recall": 0.6835,
            "fmeasure": 0.7069
        },
        "rougeL": {
            "precision": 0.85967,
            "recall": 0.76657,
            "fmeasure": 0.80012
        },
        "rougeLsum": {
            "precision": 0.85967,
            "recall": 0.76657,
            "fmeasure": 0.80012
        },
        "bleu": 81.17859,
        "nubia": {
            "semantic_relation": 4.00271,
            "contradiction": 4.92502,
            "irrelevancy": 28.38861,
            "logical_agreement": 66.68637,
            "grammar_ref": 4.66117,
            "grammar_hyp": 4.97258,
            "nubia_score": 0.6005
        },
        "bleurt": 0.03658,
        "meteor": 0.46411937318040375,
        "bertscore": {
            "precision": 0.96504,
            "recall": 0.95289,
            "f1": 0.95168
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 7,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.78,
        "total_length": 148,
        "mean_pred_length": 21.142857142857142,
        "std_pred_length": 2.695423180587601,
        "median_pred_length": 22.0,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 112,
        "unique-1": 99,
        "entropy-1": 6.458606971409433,
        "distinct-2": 0.9645390070921985,
        "vocab_size-2": 136,
        "unique-2": 134,
        "entropy-2": 7.0430290795304265,
        "cond_entropy-2": 0.5649605815929027,
        "distinct-3": 1.0,
        "vocab_size-3": 134,
        "unique-3": 134,
        "entropy-3": 7.06608919045778,
        "cond_entropy-3": 0.028102319211492297,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 2.7255405754769875,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7714285714285715,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.406959685912918,
        "distinct-2-nopunct": 0.9624060150375939,
        "vocab_size-2-nopunct": 128,
        "unique-2-nopunct": 126,
        "entropy-2-nopunct": 6.952954311633253,
        "cond_entropy-2-nopunct": 0.5840116431430745,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 126,
        "unique-3-nopunct": 126,
        "entropy-3-nopunct": 6.977279923499926,
        "cond_entropy-3-nopunct": 0.030010507637114294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.023529411764705882,
            "2": 0.18181818181818182,
            "3": 0.5333333333333333,
            "4": 0.75,
            "5": 0.6875,
            "6": 0.5833333333333334,
            "7": 0.8,
            "8": 0.88,
            "9": 1.0,
            "10": 0.9583333333333334
        },
        "nist": 8.261284231965584,
        "rouge1": {
            "precision": 0.89276,
            "recall": 0.85013,
            "fmeasure": 0.86791
        },
        "rouge2": {
            "precision": 0.81867,
            "recall": 0.79703,
            "fmeasure": 0.80381
        },
        "rougeL": {
            "precision": 0.8819,
            "recall": 0.85032,
            "fmeasure": 0.86309
        },
        "rougeLsum": {
            "precision": 0.8819,
            "recall": 0.85032,
            "fmeasure": 0.86309
        },
        "bleu": 83.68019,
        "nubia": {
            "semantic_relation": 4.23851,
            "contradiction": 2.57018,
            "irrelevancy": 44.08435,
            "logical_agreement": 53.34547,
            "grammar_ref": 4.66733,
            "grammar_hyp": 4.78078,
            "nubia_score": 0.67954
        },
        "bleurt": 0.18649,
        "meteor": 0.5125303208786836,
        "bertscore": {
            "precision": 0.96577,
            "recall": 0.96897,
            "f1": 0.96044
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 52,
        "msttr-100": 0.65143,
        "msttr-100_nopunct": 0.69833,
        "total_length": 772,
        "mean_pred_length": 14.846153846153847,
        "std_pred_length": 4.360595475323099,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.4326424870466321,
        "vocab_size-1": 334,
        "unique-1": 252,
        "entropy-1": 7.146988904161593,
        "distinct-2": 0.7777777777777778,
        "vocab_size-2": 560,
        "unique-2": 492,
        "entropy-2": 8.848188549565181,
        "cond_entropy-2": 1.4838983618242967,
        "distinct-3": 0.8847305389221557,
        "vocab_size-3": 591,
        "unique-3": 553,
        "entropy-3": 9.079349012083313,
        "cond_entropy-3": 0.23934991825434185,
        "total_length-nopunct": 669,
        "mean_pred_length-nopunct": 12.865384615384615,
        "std_pred_length-nopunct": 3.726355438236,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.49327354260089684,
        "vocab_size-1-nopunct": 330,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.32014839693036,
        "distinct-2-nopunct": 0.7957860615883307,
        "vocab_size-2-nopunct": 491,
        "unique-2-nopunct": 436,
        "entropy-2-nopunct": 8.67865818937354,
        "cond_entropy-2-nopunct": 1.4432793883577295,
        "distinct-3-nopunct": 0.8955752212389381,
        "vocab_size-3-nopunct": 506,
        "unique-3-nopunct": 475,
        "entropy-3-nopunct": 8.871659110622168,
        "cond_entropy-3-nopunct": 0.224336074290073,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28289473684210525,
            "2": 0.5783783783783784,
            "3": 0.7994858611825193
        },
        "nist": 6.854971575295264,
        "rouge1": {
            "precision": 0.72419,
            "recall": 0.76379,
            "fmeasure": 0.72667
        },
        "rouge2": {
            "precision": 0.54103,
            "recall": 0.54832,
            "fmeasure": 0.53231
        },
        "rougeL": {
            "precision": 0.66836,
            "recall": 0.7077,
            "fmeasure": 0.6718
        },
        "rougeLsum": {
            "precision": 0.66836,
            "recall": 0.7077,
            "fmeasure": 0.6718
        },
        "bleu": 51.3046,
        "nubia": {
            "semantic_relation": 4.04761,
            "contradiction": 11.58248,
            "irrelevancy": 31.83673,
            "logical_agreement": 56.58079,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.90452,
            "nubia_score": 0.68359
        },
        "bleurt": 0.33283,
        "meteor": 0.4219933571690571,
        "bertscore": {
            "precision": 0.93077,
            "recall": 0.9344,
            "f1": 0.93032
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.70233,
        "msttr-100_nopunct": 0.74885,
        "total_length": 3073,
        "mean_pred_length": 24.0078125,
        "std_pred_length": 3.9240765110843276,
        "median_pred_length": 25.0,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.41848356654734786,
        "vocab_size-1": 1286,
        "unique-1": 1016,
        "entropy-1": 8.52907496484726,
        "distinct-2": 0.7921901528013582,
        "vocab_size-2": 2333,
        "unique-2": 2134,
        "entropy-2": 10.797707205022846,
        "cond_entropy-2": 2.2641569193486295,
        "distinct-3": 0.9130280440184594,
        "vocab_size-3": 2572,
        "unique-3": 2488,
        "entropy-3": 11.17195090442509,
        "cond_entropy-3": 0.3896277720694857,
        "total_length-nopunct": 2671,
        "mean_pred_length-nopunct": 20.8671875,
        "std_pred_length-nopunct": 3.5824465578489444,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4780980906027705,
        "vocab_size-1-nopunct": 1277,
        "unique-1-nopunct": 1015,
        "entropy-1-nopunct": 8.849708655179565,
        "distinct-2-nopunct": 0.8230436492331892,
        "vocab_size-2-nopunct": 2093,
        "unique-2-nopunct": 1938,
        "entropy-2-nopunct": 10.69969361283493,
        "cond_entropy-2-nopunct": 1.9263750803813056,
        "distinct-3-nopunct": 0.9300207039337474,
        "vocab_size-3-nopunct": 2246,
        "unique-3-nopunct": 2187,
        "entropy-3-nopunct": 11.005613960690024,
        "cond_entropy-3-nopunct": 0.32745943251025356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21315192743764172,
            "2": 0.39728682170542634,
            "3": 0.6444444444444445
        },
        "nist": 5.911519384635619,
        "rouge1": {
            "precision": 0.7177,
            "recall": 0.59986,
            "fmeasure": 0.64132
        },
        "rouge2": {
            "precision": 0.47842,
            "recall": 0.3859,
            "fmeasure": 0.41799
        },
        "rougeL": {
            "precision": 0.58754,
            "recall": 0.48595,
            "fmeasure": 0.51948
        },
        "rougeLsum": {
            "precision": 0.58754,
            "recall": 0.48595,
            "fmeasure": 0.51948
        },
        "bleu": 34.83775,
        "nubia": {
            "semantic_relation": 3.61572,
            "contradiction": 16.50578,
            "irrelevancy": 28.95948,
            "logical_agreement": 54.53474,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.45525,
            "nubia_score": 0.5141
        },
        "bleurt": -0.11306,
        "meteor": 0.31032660208721075,
        "bertscore": {
            "precision": 0.90685,
            "recall": 0.8888,
            "f1": 0.89634
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.698,
        "msttr-100_nopunct": 0.735,
        "total_length": 537,
        "mean_pred_length": 14.916666666666666,
        "std_pred_length": 5.230121094837735,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5325884543761639,
        "vocab_size-1": 286,
        "unique-1": 230,
        "entropy-1": 7.251359740803904,
        "distinct-2": 0.8363273453093812,
        "vocab_size-2": 419,
        "unique-2": 382,
        "entropy-2": 8.523171215708636,
        "cond_entropy-2": 1.0309128068142448,
        "distinct-3": 0.9096774193548387,
        "vocab_size-3": 423,
        "unique-3": 399,
        "entropy-3": 8.642002383455699,
        "cond_entropy-3": 0.10675881577955393,
        "total_length-nopunct": 469,
        "mean_pred_length-nopunct": 13.027777777777779,
        "std_pred_length-nopunct": 4.212983312934164,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5906183368869936,
        "vocab_size-1-nopunct": 277,
        "unique-1-nopunct": 226,
        "entropy-1-nopunct": 7.364435903136748,
        "distinct-2-nopunct": 0.8337182448036952,
        "vocab_size-2-nopunct": 361,
        "unique-2-nopunct": 329,
        "entropy-2-nopunct": 8.306625524504254,
        "cond_entropy-2-nopunct": 1.008408584608232,
        "distinct-3-nopunct": 0.9118387909319899,
        "vocab_size-3-nopunct": 362,
        "unique-3-nopunct": 342,
        "entropy-3-nopunct": 8.418588609035258,
        "cond_entropy-3-nopunct": 0.10567247834924752,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22772277227722773,
            "2": 0.49206349206349204,
            "3": 0.7155425219941349
        },
        "nist": 6.206386522091532,
        "rouge1": {
            "precision": 0.74502,
            "recall": 0.69734,
            "fmeasure": 0.7029
        },
        "rouge2": {
            "precision": 0.5237,
            "recall": 0.48862,
            "fmeasure": 0.49186
        },
        "rougeL": {
            "precision": 0.66808,
            "recall": 0.62305,
            "fmeasure": 0.62943
        },
        "rougeLsum": {
            "precision": 0.66808,
            "recall": 0.62305,
            "fmeasure": 0.62943
        },
        "bleu": 42.5649,
        "nubia": {
            "semantic_relation": 3.99449,
            "contradiction": 13.95803,
            "irrelevancy": 25.03316,
            "logical_agreement": 61.0088,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.69037,
            "nubia_score": 0.66902
        },
        "bleurt": 0.21952,
        "meteor": 0.3644019610295328,
        "bertscore": {
            "precision": 0.92919,
            "recall": 0.91681,
            "f1": 0.9203
        }
    },
    "wiki_auto_asset_turk_test_asset_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 63,
        "msttr-100": 0.76231,
        "msttr-100_nopunct": 0.78,
        "total_length": 1333,
        "mean_pred_length": 21.158730158730158,
        "std_pred_length": 5.15846153146751,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.5003750937734434,
        "vocab_size-1": 667,
        "unique-1": 550,
        "entropy-1": 8.197587284948227,
        "distinct-2": 0.9007874015748032,
        "vocab_size-2": 1144,
        "unique-2": 1093,
        "entropy-2": 9.99603626215222,
        "cond_entropy-2": 1.773538145202284,
        "distinct-3": 0.9676884838442419,
        "vocab_size-3": 1168,
        "unique-3": 1160,
        "entropy-3": 10.109845732001999,
        "cond_entropy-3": 0.12601399171231367,
        "total_length-nopunct": 1204,
        "mean_pred_length-nopunct": 19.11111111111111,
        "std_pred_length-nopunct": 4.731223913303307,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5465116279069767,
        "vocab_size-1-nopunct": 658,
        "unique-1-nopunct": 547,
        "entropy-1-nopunct": 8.334670973654971,
        "distinct-2-nopunct": 0.9430324276950044,
        "vocab_size-2-nopunct": 1076,
        "unique-2-nopunct": 1035,
        "entropy-2-nopunct": 10.017005909861126,
        "cond_entropy-2-nopunct": 1.7547114192939586,
        "distinct-3-nopunct": 0.9972170686456401,
        "vocab_size-3-nopunct": 1075,
        "unique-3-nopunct": 1072,
        "entropy-3-nopunct": 10.068575600043836,
        "cond_entropy-3-nopunct": 0.05876993274773962,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.027755102040816326,
            "2": 0.1366120218579235,
            "3": 0.31140350877192985,
            "4": 0.49693251533742333,
            "5": 0.5508982035928144,
            "6": 0.6075268817204301,
            "7": 0.6987951807228916,
            "8": 0.7441860465116279,
            "9": 0.7183908045977011,
            "10": 0.8796296296296297
        },
        "nist": 10.827482066942949,
        "rouge1": {
            "precision": 0.8472,
            "recall": 0.77089,
            "fmeasure": 0.79744
        },
        "rouge2": {
            "precision": 0.75056,
            "recall": 0.66642,
            "fmeasure": 0.69535
        },
        "rougeL": {
            "precision": 0.83674,
            "recall": 0.76058,
            "fmeasure": 0.78671
        },
        "rougeLsum": {
            "precision": 0.83674,
            "recall": 0.76058,
            "fmeasure": 0.78671
        },
        "bleu": 80.94486,
        "nubia": {
            "semantic_relation": 3.88834,
            "contradiction": 4.10606,
            "irrelevancy": 36.21451,
            "logical_agreement": 59.67943,
            "grammar_ref": 4.4268,
            "grammar_hyp": 4.81819,
            "nubia_score": 0.56535
        },
        "bleurt": -0.08142,
        "meteor": 0.44758404175878036,
        "bertscore": {
            "precision": 0.94881,
            "recall": 0.93817,
            "f1": 0.93932
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 41,
        "msttr-100": 0.622,
        "msttr-100_nopunct": 0.6775,
        "total_length": 520,
        "mean_pred_length": 12.682926829268293,
        "std_pred_length": 4.677079682932471,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.46923076923076923,
        "vocab_size-1": 244,
        "unique-1": 197,
        "entropy-1": 6.876816911224207,
        "distinct-2": 0.7974947807933194,
        "vocab_size-2": 382,
        "unique-2": 346,
        "entropy-2": 8.327237097658095,
        "cond_entropy-2": 1.186673854052461,
        "distinct-3": 0.8858447488584474,
        "vocab_size-3": 388,
        "unique-3": 368,
        "entropy-3": 8.453583756190094,
        "cond_entropy-3": 0.1263259969264718,
        "total_length-nopunct": 442,
        "mean_pred_length-nopunct": 10.78048780487805,
        "std_pred_length-nopunct": 3.910662068093699,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5384615384615384,
        "vocab_size-1-nopunct": 238,
        "unique-1-nopunct": 196,
        "entropy-1-nopunct": 7.033089529833952,
        "distinct-2-nopunct": 0.8154613466334164,
        "vocab_size-2-nopunct": 327,
        "unique-2-nopunct": 299,
        "entropy-2-nopunct": 8.11828929453867,
        "cond_entropy-2-nopunct": 1.1762539958866312,
        "distinct-3-nopunct": 0.9027777777777778,
        "vocab_size-3-nopunct": 325,
        "unique-3-nopunct": 310,
        "entropy-3-nopunct": 8.219863799216062,
        "cond_entropy-3-nopunct": 0.10072987803445928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.4214876033057851,
            "3": 0.7454545454545455
        },
        "nist": 6.28334823420713,
        "rouge1": {
            "precision": 0.78296,
            "recall": 0.71868,
            "fmeasure": 0.74014
        },
        "rouge2": {
            "precision": 0.57853,
            "recall": 0.53745,
            "fmeasure": 0.54896
        },
        "rougeL": {
            "precision": 0.68268,
            "recall": 0.6371,
            "fmeasure": 0.65027
        },
        "rougeLsum": {
            "precision": 0.68268,
            "recall": 0.6371,
            "fmeasure": 0.65027
        },
        "bleu": 45.98918,
        "nubia": {
            "semantic_relation": 3.91068,
            "contradiction": 11.13788,
            "irrelevancy": 27.11125,
            "logical_agreement": 61.75087,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.54545,
            "nubia_score": 0.69079
        },
        "bleurt": 0.30745,
        "meteor": 0.3986262039482155,
        "bertscore": {
            "precision": 0.93326,
            "recall": 0.92592,
            "f1": 0.92809
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level0": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 174,
        "msttr-100": 0.7268,
        "msttr-100_nopunct": 0.76818,
        "total_length": 2531,
        "mean_pred_length": 14.545977011494253,
        "std_pred_length": 5.450473028036795,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.4583168708020545,
        "vocab_size-1": 1160,
        "unique-1": 931,
        "entropy-1": 8.49478191342695,
        "distinct-2": 0.879507848960543,
        "vocab_size-2": 2073,
        "unique-2": 1951,
        "entropy-2": 10.832803879719956,
        "cond_entropy-2": 2.059723310956396,
        "distinct-3": 0.9816765918460834,
        "vocab_size-3": 2143,
        "unique-3": 2112,
        "entropy-3": 11.051888243890632,
        "cond_entropy-3": 0.23682341147539537,
        "total_length-nopunct": 2253,
        "mean_pred_length-nopunct": 12.948275862068966,
        "std_pred_length-nopunct": 4.942505346108785,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5108743897026188,
        "vocab_size-1-nopunct": 1151,
        "unique-1-nopunct": 929,
        "entropy-1-nopunct": 8.778052455703305,
        "distinct-2-nopunct": 0.8864838864838864,
        "vocab_size-2-nopunct": 1843,
        "unique-2-nopunct": 1744,
        "entropy-2-nopunct": 10.662417406493608,
        "cond_entropy-2-nopunct": 2.040852842089147,
        "distinct-3-nopunct": 0.9858267716535433,
        "vocab_size-3-nopunct": 1878,
        "unique-3-nopunct": 1855,
        "entropy-3-nopunct": 10.86538642411029,
        "cond_entropy-3-nopunct": 0.22411433837119524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.039349422875131164,
            "2": 0.14521452145214522,
            "3": 0.328042328042328,
            "4": 0.4596774193548387,
            "5": 0.5510835913312694,
            "6": 0.6671641791044776,
            "7": 0.8059071729957806
        },
        "nist": 8.4909766749357,
        "rouge1": {
            "precision": 0.85487,
            "recall": 0.74673,
            "fmeasure": 0.78184
        },
        "rouge2": {
            "precision": 0.6947,
            "recall": 0.59971,
            "fmeasure": 0.62952
        },
        "rougeL": {
            "precision": 0.82322,
            "recall": 0.71218,
            "fmeasure": 0.74863
        },
        "rougeLsum": {
            "precision": 0.82322,
            "recall": 0.71218,
            "fmeasure": 0.74863
        },
        "bleu": 63.36552,
        "nubia": {
            "semantic_relation": 4.12199,
            "contradiction": 5.05025,
            "irrelevancy": 15.79274,
            "logical_agreement": 79.15701,
            "grammar_ref": 4.58509,
            "grammar_hyp": 5.13557,
            "nubia_score": 0.64807
        },
        "bleurt": 0.16725,
        "meteor": 0.4191239499169813,
        "bertscore": {
            "precision": 0.95421,
            "recall": 0.92711,
            "f1": 0.93768
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level2": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 58,
        "msttr-100": 0.73111,
        "msttr-100_nopunct": 0.75625,
        "total_length": 978,
        "mean_pred_length": 16.862068965517242,
        "std_pred_length": 5.8085794923872465,
        "median_pred_length": 16.5,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.5296523517382413,
        "vocab_size-1": 518,
        "unique-1": 422,
        "entropy-1": 7.911634558539159,
        "distinct-2": 0.941304347826087,
        "vocab_size-2": 866,
        "unique-2": 830,
        "entropy-2": 9.70756194986872,
        "cond_entropy-2": 1.6426479405292451,
        "distinct-3": 0.9953596287703016,
        "vocab_size-3": 858,
        "unique-3": 854,
        "entropy-3": 9.742263316629735,
        "cond_entropy-3": 0.041661726230083976,
        "total_length-nopunct": 896,
        "mean_pred_length-nopunct": 15.448275862068966,
        "std_pred_length-nopunct": 5.754076257669213,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5703125,
        "vocab_size-1-nopunct": 511,
        "unique-1-nopunct": 419,
        "entropy-1-nopunct": 8.046306653703136,
        "distinct-2-nopunct": 0.9486873508353222,
        "vocab_size-2-nopunct": 795,
        "unique-2-nopunct": 766,
        "entropy-2-nopunct": 9.589823047082032,
        "cond_entropy-2-nopunct": 1.640928117197906,
        "distinct-3-nopunct": 0.9974358974358974,
        "vocab_size-3-nopunct": 778,
        "unique-3-nopunct": 776,
        "entropy-3-nopunct": 9.602202108621388,
        "cond_entropy-3-nopunct": 0.01806120759453202,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.032825322391559206,
            "2": 0.176056338028169,
            "3": 0.3116883116883117,
            "4": 0.375,
            "5": 0.46368715083798884,
            "6": 0.6559139784946236,
            "7": 0.744131455399061
        },
        "nist": 6.627632253755813,
        "rouge1": {
            "precision": 0.81774,
            "recall": 0.67596,
            "fmeasure": 0.72328
        },
        "rouge2": {
            "precision": 0.66314,
            "recall": 0.55031,
            "fmeasure": 0.5866
        },
        "rougeL": {
            "precision": 0.79495,
            "recall": 0.66205,
            "fmeasure": 0.70548
        },
        "rougeLsum": {
            "precision": 0.79495,
            "recall": 0.66205,
            "fmeasure": 0.70548
        },
        "bleu": 59.06226,
        "nubia": {
            "semantic_relation": 3.98251,
            "contradiction": 6.94876,
            "irrelevancy": 16.28642,
            "logical_agreement": 76.76482,
            "grammar_ref": 4.54049,
            "grammar_hyp": 4.92586,
            "nubia_score": 0.62047
        },
        "bleurt": 0.01356,
        "meteor": 0.38427026873501074,
        "bertscore": {
            "precision": 0.9441,
            "recall": 0.91177,
            "f1": 0.9248
        }
    },
    "e2e_nlg_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 500,
        "msttr-100": 0.51625,
        "msttr-100_nopunct": 0.51781,
        "total_length": 11255,
        "mean_pred_length": 22.51,
        "std_pred_length": 3.8933147830608306,
        "median_pred_length": 24.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.027809862283429587,
        "vocab_size-1": 313,
        "unique-1": 89,
        "entropy-1": 6.172243264203616,
        "distinct-2": 0.1096234309623431,
        "vocab_size-2": 1179,
        "unique-2": 510,
        "entropy-2": 8.318350298159576,
        "cond_entropy-2": 2.186218744758074,
        "distinct-3": 0.21803998049731838,
        "vocab_size-3": 2236,
        "unique-3": 1145,
        "entropy-3": 9.653727558102098,
        "cond_entropy-3": 1.4214306915383381,
        "total_length-nopunct": 10529,
        "mean_pred_length-nopunct": 21.058,
        "std_pred_length-nopunct": 3.8223861657346974,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.029442492164498055,
        "vocab_size-1-nopunct": 310,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.1776145563066684,
        "distinct-2-nopunct": 0.11377006680626184,
        "vocab_size-2-nopunct": 1141,
        "unique-2-nopunct": 500,
        "entropy-2-nopunct": 8.284215598477076,
        "cond_entropy-2-nopunct": 2.2156293204087616,
        "distinct-3-nopunct": 0.22531220484835765,
        "vocab_size-3-nopunct": 2147,
        "unique-3-nopunct": 1097,
        "entropy-3-nopunct": 9.655090174220641,
        "cond_entropy-3-nopunct": 1.4418301242266072,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6368455314795871
        },
        "nist": 4.734143798012,
        "rouge1": {
            "precision": 0.73137,
            "recall": 0.65425,
            "fmeasure": 0.6804
        },
        "rouge2": {
            "precision": 0.42541,
            "recall": 0.38022,
            "fmeasure": 0.39526
        },
        "rougeL": {
            "precision": 0.51,
            "recall": 0.45793,
            "fmeasure": 0.47531
        },
        "rougeLsum": {
            "precision": 0.51,
            "recall": 0.45793,
            "fmeasure": 0.47531
        },
        "bleu": 25.56848,
        "nubia": {
            "semantic_relation": 4.05039,
            "contradiction": 3.47444,
            "irrelevancy": 23.77637,
            "logical_agreement": 72.74919,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.78626,
            "nubia_score": 0.67813
        },
        "bleurt": -0.01328,
        "meteor": 0.32645206857648273,
        "bertscore": {
            "precision": 0.90727,
            "recall": 0.89037,
            "f1": 0.89841
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level3": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 22,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76333,
        "total_length": 407,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.458521278281743,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5798525798525799,
        "vocab_size-1": 236,
        "unique-1": 192,
        "entropy-1": 7.205803937241801,
        "distinct-2": 0.9168831168831169,
        "vocab_size-2": 353,
        "unique-2": 333,
        "entropy-2": 8.391210479693198,
        "cond_entropy-2": 1.0764481471734335,
        "distinct-3": 0.9834710743801653,
        "vocab_size-3": 357,
        "unique-3": 353,
        "entropy-3": 8.46660872696457,
        "cond_entropy-3": 0.0774922663591063,
        "total_length-nopunct": 363,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 5.024937810560445,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6336088154269972,
        "vocab_size-1-nopunct": 230,
        "unique-1-nopunct": 192,
        "entropy-1-nopunct": 7.260850970573767,
        "distinct-2-nopunct": 0.9325513196480938,
        "vocab_size-2-nopunct": 318,
        "unique-2-nopunct": 304,
        "entropy-2-nopunct": 8.250066528699206,
        "cond_entropy-2-nopunct": 1.0390853378333673,
        "distinct-3-nopunct": 0.9968652037617555,
        "vocab_size-3-nopunct": 318,
        "unique-3-nopunct": 317,
        "entropy-3-nopunct": 8.311143021288444,
        "cond_entropy-3-nopunct": 0.06425325844005884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05333333333333334,
            "2": 0.11864406779661017,
            "3": 0.3125,
            "4": 0.22448979591836735,
            "5": 0.4594594594594595,
            "6": 0.5959595959595959,
            "7": 0.7619047619047619
        },
        "nist": 5.974612230226326,
        "rouge1": {
            "precision": 0.7703,
            "recall": 0.65633,
            "fmeasure": 0.69171
        },
        "rouge2": {
            "precision": 0.58989,
            "recall": 0.5174,
            "fmeasure": 0.53796
        },
        "rougeL": {
            "precision": 0.72297,
            "recall": 0.64361,
            "fmeasure": 0.66257
        },
        "rougeLsum": {
            "precision": 0.72297,
            "recall": 0.64361,
            "fmeasure": 0.66257
        },
        "bleu": 52.42044,
        "nubia": {
            "semantic_relation": 4.02698,
            "contradiction": 7.99575,
            "irrelevancy": 16.15097,
            "logical_agreement": 75.85327,
            "grammar_ref": 4.50363,
            "grammar_hyp": 4.91166,
            "nubia_score": 0.63023
        },
        "bleurt": 0.06073,
        "meteor": 0.3528833135364812,
        "bertscore": {
            "precision": 0.9341,
            "recall": 0.90867,
            "f1": 0.91813
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation_parent": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.73574,
        "msttr-100_nopunct": 0.77073,
        "total_length": 6195,
        "mean_pred_length": 17.25626740947075,
        "std_pred_length": 6.102746858210674,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3861178369652946,
        "vocab_size-1": 2392,
        "unique-1": 1804,
        "entropy-1": 9.128919406069475,
        "distinct-2": 0.8415010281014393,
        "vocab_size-2": 4911,
        "unique-2": 4579,
        "entropy-2": 11.951184855882673,
        "cond_entropy-2": 2.645463000586634,
        "distinct-3": 0.9667701296330108,
        "vocab_size-3": 5295,
        "unique-3": 5209,
        "entropy-3": 12.306699863458707,
        "cond_entropy-3": 0.38003923522366023,
        "total_length-nopunct": 5551,
        "mean_pred_length-nopunct": 15.462395543175488,
        "std_pred_length-nopunct": 5.597761774116267,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.42857142857142855,
        "vocab_size-1-nopunct": 2379,
        "unique-1-nopunct": 1801,
        "entropy-1-nopunct": 9.397022590121578,
        "distinct-2-nopunct": 0.863251155624037,
        "vocab_size-2-nopunct": 4482,
        "unique-2-nopunct": 4202,
        "entropy-2-nopunct": 11.879929657724336,
        "cond_entropy-2-nopunct": 2.629561991939067,
        "distinct-3-nopunct": 0.9836540451065591,
        "vocab_size-3-nopunct": 4754,
        "unique-3-nopunct": 4692,
        "entropy-3-nopunct": 12.20277347589048,
        "cond_entropy-3-nopunct": 0.3485169726431887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02627710400588019,
            "2": 0.1307277628032345,
            "3": 0.29397590361445786,
            "4": 0.4908256880733945,
            "5": 0.5614567526555387,
            "6": 0.6394366197183099,
            "7": 0.6939890710382514,
            "8": 0.7478890229191797,
            "9": 0.8084656084656084,
            "10": 0.9031007751937985
        },
        "nist": 12.671020892791919,
        "rouge1": {
            "precision": 0.8717,
            "recall": 0.81549,
            "fmeasure": 0.83041
        },
        "rouge2": {
            "precision": 0.76832,
            "recall": 0.71155,
            "fmeasure": 0.72475
        },
        "rougeL": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "rougeLsum": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "bleu": 81.93645,
        "nubia": {
            "semantic_relation": 4.06169,
            "contradiction": 3.80336,
            "irrelevancy": 30.13173,
            "logical_agreement": 66.06491,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.90619,
            "nubia_score": 0.62654
        },
        "bleurt": 0.1314,
        "meteor": 0.4679813155989895,
        "bertscore": {
            "precision": 0.96224,
            "recall": 0.95179,
            "f1": 0.95293
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 61,
        "msttr-100": 0.70385,
        "msttr-100_nopunct": 0.76455,
        "total_length": 1360,
        "mean_pred_length": 22.295081967213115,
        "std_pred_length": 5.384690691742692,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5088235294117647,
        "vocab_size-1": 692,
        "unique-1": 580,
        "entropy-1": 8.057962497416577,
        "distinct-2": 0.8868360277136259,
        "vocab_size-2": 1152,
        "unique-2": 1084,
        "entropy-2": 10.010413151008354,
        "cond_entropy-2": 1.9240189241107315,
        "distinct-3": 0.9822294022617124,
        "vocab_size-3": 1216,
        "unique-3": 1198,
        "entropy-3": 10.235419367385518,
        "cond_entropy-3": 0.221420216971639,
        "total_length-nopunct": 1159,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 4.6764144875124565,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5918895599654875,
        "vocab_size-1-nopunct": 686,
        "unique-1-nopunct": 579,
        "entropy-1-nopunct": 8.404440765741745,
        "distinct-2-nopunct": 0.9262295081967213,
        "vocab_size-2-nopunct": 1017,
        "unique-2-nopunct": 973,
        "entropy-2-nopunct": 9.898344343740602,
        "cond_entropy-2-nopunct": 1.5508133049097246,
        "distinct-3-nopunct": 0.9922854387656702,
        "vocab_size-3-nopunct": 1029,
        "unique-3-nopunct": 1022,
        "entropy-3-nopunct": 10.002043103111845,
        "cond_entropy-3-nopunct": 0.10990368426578151,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15053763440860216,
            "2": 0.3755656108597285,
            "3": 0.6304801670146137
        },
        "nist": 5.519894394906074,
        "rouge1": {
            "precision": 0.69055,
            "recall": 0.59043,
            "fmeasure": 0.62741
        },
        "rouge2": {
            "precision": 0.40113,
            "recall": 0.34902,
            "fmeasure": 0.36693
        },
        "rougeL": {
            "precision": 0.56002,
            "recall": 0.48287,
            "fmeasure": 0.50975
        },
        "rougeLsum": {
            "precision": 0.56002,
            "recall": 0.48287,
            "fmeasure": 0.50975
        },
        "bleu": 31.30441,
        "nubia": {
            "semantic_relation": 3.60836,
            "contradiction": 12.15718,
            "irrelevancy": 31.55271,
            "logical_agreement": 56.29011,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.58244,
            "nubia_score": 0.52891
        },
        "bleurt": -0.07061,
        "meteor": 0.3014833926266292,
        "bertscore": {
            "precision": 0.90062,
            "recall": 0.88799,
            "f1": 0.89313
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02_parent": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.73574,
        "msttr-100_nopunct": 0.77073,
        "total_length": 6195,
        "mean_pred_length": 17.25626740947075,
        "std_pred_length": 6.102746858210674,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3861178369652946,
        "vocab_size-1": 2392,
        "unique-1": 1804,
        "entropy-1": 9.128919406069475,
        "distinct-2": 0.8415010281014393,
        "vocab_size-2": 4911,
        "unique-2": 4579,
        "entropy-2": 11.951184855882673,
        "cond_entropy-2": 2.645463000586634,
        "distinct-3": 0.9667701296330108,
        "vocab_size-3": 5295,
        "unique-3": 5209,
        "entropy-3": 12.306699863458707,
        "cond_entropy-3": 0.38003923522366023,
        "total_length-nopunct": 5551,
        "mean_pred_length-nopunct": 15.462395543175488,
        "std_pred_length-nopunct": 5.597761774116267,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.42857142857142855,
        "vocab_size-1-nopunct": 2379,
        "unique-1-nopunct": 1801,
        "entropy-1-nopunct": 9.397022590121578,
        "distinct-2-nopunct": 0.863251155624037,
        "vocab_size-2-nopunct": 4482,
        "unique-2-nopunct": 4202,
        "entropy-2-nopunct": 11.879929657724336,
        "cond_entropy-2-nopunct": 2.629561991939067,
        "distinct-3-nopunct": 0.9836540451065591,
        "vocab_size-3-nopunct": 4754,
        "unique-3-nopunct": 4692,
        "entropy-3-nopunct": 12.20277347589048,
        "cond_entropy-3-nopunct": 0.3485169726431887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02627710400588019,
            "2": 0.1307277628032345,
            "3": 0.29397590361445786,
            "4": 0.4908256880733945,
            "5": 0.5614567526555387,
            "6": 0.6394366197183099,
            "7": 0.6939890710382514,
            "8": 0.7478890229191797,
            "9": 0.8084656084656084,
            "10": 0.9031007751937985
        },
        "nist": 12.671020892791919,
        "rouge1": {
            "precision": 0.8717,
            "recall": 0.81549,
            "fmeasure": 0.83041
        },
        "rouge2": {
            "precision": 0.76832,
            "recall": 0.71155,
            "fmeasure": 0.72475
        },
        "rougeL": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "rougeLsum": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "bleu": 81.93645,
        "nubia": {
            "semantic_relation": 4.06169,
            "contradiction": 3.80336,
            "irrelevancy": 30.13173,
            "logical_agreement": 66.06491,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.90619,
            "nubia_score": 0.62654
        },
        "bleurt": 0.1314,
        "meteor": 0.4679813155989895,
        "bertscore": {
            "precision": 0.96224,
            "recall": 0.95179,
            "f1": 0.95293
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level4": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.875,
        "vocab_size-1": 42,
        "unique-1": 37,
        "entropy-1": 5.319235677759421,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.08466837338629611,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.09324233720029841,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.06666666666666667,
            "3": 0.25,
            "4": 0.7142857142857143,
            "5": 0.6666666666666666,
            "6": 0.5714285714285714,
            "7": 0.8571428571428571
        },
        "nist": 4.717366214607595,
        "rouge1": {
            "precision": 0.8836,
            "recall": 0.76484,
            "fmeasure": 0.81201
        },
        "rouge2": {
            "precision": 0.7451,
            "recall": 0.61323,
            "fmeasure": 0.66227
        },
        "rougeL": {
            "precision": 0.85582,
            "recall": 0.73489,
            "fmeasure": 0.7832
        },
        "rougeLsum": {
            "precision": 0.85582,
            "recall": 0.73489,
            "fmeasure": 0.7832
        },
        "bleu": 58.4262,
        "nubia": {
            "semantic_relation": 4.37734,
            "contradiction": 0.37907,
            "irrelevancy": 18.93183,
            "logical_agreement": 80.6891,
            "grammar_ref": 4.54431,
            "grammar_hyp": 5.0171,
            "nubia_score": 0.72844
        },
        "bleurt": 0.3195,
        "meteor": 0.4126035487740927,
        "bertscore": {
            "precision": 0.96414,
            "recall": 0.94609,
            "f1": 0.95245
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05_parent": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.73574,
        "msttr-100_nopunct": 0.77073,
        "total_length": 6195,
        "mean_pred_length": 17.25626740947075,
        "std_pred_length": 6.102746858210674,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3861178369652946,
        "vocab_size-1": 2392,
        "unique-1": 1804,
        "entropy-1": 9.128919406069475,
        "distinct-2": 0.8415010281014393,
        "vocab_size-2": 4911,
        "unique-2": 4579,
        "entropy-2": 11.951184855882673,
        "cond_entropy-2": 2.645463000586634,
        "distinct-3": 0.9667701296330108,
        "vocab_size-3": 5295,
        "unique-3": 5209,
        "entropy-3": 12.306699863458707,
        "cond_entropy-3": 0.38003923522366023,
        "total_length-nopunct": 5551,
        "mean_pred_length-nopunct": 15.462395543175488,
        "std_pred_length-nopunct": 5.597761774116267,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.42857142857142855,
        "vocab_size-1-nopunct": 2379,
        "unique-1-nopunct": 1801,
        "entropy-1-nopunct": 9.397022590121578,
        "distinct-2-nopunct": 0.863251155624037,
        "vocab_size-2-nopunct": 4482,
        "unique-2-nopunct": 4202,
        "entropy-2-nopunct": 11.879929657724336,
        "cond_entropy-2-nopunct": 2.629561991939067,
        "distinct-3-nopunct": 0.9836540451065591,
        "vocab_size-3-nopunct": 4754,
        "unique-3-nopunct": 4692,
        "entropy-3-nopunct": 12.20277347589048,
        "cond_entropy-3-nopunct": 0.3485169726431887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02627710400588019,
            "2": 0.1307277628032345,
            "3": 0.29397590361445786,
            "4": 0.4908256880733945,
            "5": 0.5614567526555387,
            "6": 0.6394366197183099,
            "7": 0.6939890710382514,
            "8": 0.7478890229191797,
            "9": 0.8084656084656084,
            "10": 0.9031007751937985
        },
        "nist": 12.671020892791919,
        "rouge1": {
            "precision": 0.8717,
            "recall": 0.81549,
            "fmeasure": 0.83041
        },
        "rouge2": {
            "precision": 0.76832,
            "recall": 0.71155,
            "fmeasure": 0.72475
        },
        "rougeL": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "rougeLsum": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "bleu": 81.93645,
        "nubia": {
            "semantic_relation": 4.06169,
            "contradiction": 3.80336,
            "irrelevancy": 30.13173,
            "logical_agreement": 66.06491,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.90619,
            "nubia_score": 0.62654
        },
        "bleurt": 0.1314,
        "meteor": 0.4679813155989895,
        "bertscore": {
            "precision": 0.96224,
            "recall": 0.95179,
            "f1": 0.95293
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 414,
        "msttr-100": 0.52105,
        "msttr-100_nopunct": 0.53029,
        "total_length": 7662,
        "mean_pred_length": 18.507246376811594,
        "std_pred_length": 4.87958338011075,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.14526233359436178,
        "vocab_size-1": 1113,
        "unique-1": 426,
        "entropy-1": 7.962895573331881,
        "distinct-2": 0.4068708609271523,
        "vocab_size-2": 2949,
        "unique-2": 1783,
        "entropy-2": 10.730739471390356,
        "cond_entropy-2": 2.6262384397744,
        "distinct-3": 0.6033069944395669,
        "vocab_size-3": 4123,
        "unique-3": 3011,
        "entropy-3": 11.574351588051162,
        "cond_entropy-3": 0.9142213002857912,
        "total_length-nopunct": 6827,
        "mean_pred_length-nopunct": 16.49033816425121,
        "std_pred_length-nopunct": 4.532614327214277,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.16185733118500073,
        "vocab_size-1-nopunct": 1105,
        "unique-1-nopunct": 425,
        "entropy-1-nopunct": 8.189323498945392,
        "distinct-2-nopunct": 0.4121316076719164,
        "vocab_size-2-nopunct": 2643,
        "unique-2-nopunct": 1624,
        "entropy-2-nopunct": 10.571814242935186,
        "cond_entropy-2-nopunct": 2.5478752117970673,
        "distinct-3-nopunct": 0.6072678779796633,
        "vocab_size-3-nopunct": 3643,
        "unique-3-nopunct": 2714,
        "entropy-3-nopunct": 11.380611463927766,
        "cond_entropy-3-nopunct": 0.8765880201849648,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21085535663540778,
            "2": 0.5740833751883475,
            "3": 0.8486624203821655,
            "4": 0.7272727272727273,
            "5": 0.5
        },
        "nist": 8.769999646854515,
        "rouge1": {
            "precision": 0.77582,
            "recall": 0.74063,
            "fmeasure": 0.75011
        },
        "rouge2": {
            "precision": 0.52641,
            "recall": 0.50457,
            "fmeasure": 0.50929
        },
        "rougeL": {
            "precision": 0.64418,
            "recall": 0.61793,
            "fmeasure": 0.624
        },
        "rougeLsum": {
            "precision": 0.64418,
            "recall": 0.61793,
            "fmeasure": 0.624
        },
        "bleu": 48.36936,
        "nubia": {
            "semantic_relation": 4.43102,
            "contradiction": 8.12668,
            "irrelevancy": 7.99812,
            "logical_agreement": 83.8752,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.73426,
            "nubia_score": 0.76926
        },
        "bleurt": 0.17375,
        "meteor": 0.3871724611177925,
        "bertscore": {
            "precision": 0.92811,
            "recall": 0.92166,
            "f1": 0.92353
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.71444,
        "msttr-100_nopunct": 0.74625,
        "total_length": 911,
        "mean_pred_length": 22.775,
        "std_pred_length": 5.081768884945478,
        "median_pred_length": 23.5,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.5137211855104281,
        "vocab_size-1": 468,
        "unique-1": 372,
        "entropy-1": 7.811370789184004,
        "distinct-2": 0.8714121699196326,
        "vocab_size-2": 759,
        "unique-2": 709,
        "entropy-2": 9.403937649266519,
        "cond_entropy-2": 1.5890220026474524,
        "distinct-3": 0.9651022864019254,
        "vocab_size-3": 802,
        "unique-3": 783,
        "entropy-3": 9.616436883405122,
        "cond_entropy-3": 0.2287491142507935,
        "total_length-nopunct": 806,
        "mean_pred_length-nopunct": 20.15,
        "std_pred_length-nopunct": 4.222262426709168,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5694789081885856,
        "vocab_size-1-nopunct": 459,
        "unique-1-nopunct": 369,
        "entropy-1-nopunct": 7.957778691480577,
        "distinct-2-nopunct": 0.8981723237597912,
        "vocab_size-2-nopunct": 688,
        "unique-2-nopunct": 651,
        "entropy-2-nopunct": 9.306699130414733,
        "cond_entropy-2-nopunct": 1.4108059506449804,
        "distinct-3-nopunct": 0.9765840220385675,
        "vocab_size-3-nopunct": 709,
        "unique-3-nopunct": 698,
        "entropy-3-nopunct": 9.448227214611977,
        "cond_entropy-3-nopunct": 0.155274720644178,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2465753424657534,
            "2": 0.3727810650887574,
            "3": 0.6909937888198758
        },
        "nist": 5.881972305067308,
        "rouge1": {
            "precision": 0.7442,
            "recall": 0.6383,
            "fmeasure": 0.67622
        },
        "rouge2": {
            "precision": 0.51155,
            "recall": 0.4331,
            "fmeasure": 0.46201
        },
        "rougeL": {
            "precision": 0.60882,
            "recall": 0.52227,
            "fmeasure": 0.55311
        },
        "rougeLsum": {
            "precision": 0.60882,
            "recall": 0.52227,
            "fmeasure": 0.55311
        },
        "bleu": 37.31576,
        "nubia": {
            "semantic_relation": 3.70738,
            "contradiction": 18.17203,
            "irrelevancy": 30.42513,
            "logical_agreement": 51.40284,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.45952,
            "nubia_score": 0.56722
        },
        "bleurt": -0.06237,
        "meteor": 0.33262325474516513,
        "bertscore": {
            "precision": 0.91534,
            "recall": 0.89914,
            "f1": 0.90597
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level5": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 30,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.7575,
        "total_length": 551,
        "mean_pred_length": 18.366666666666667,
        "std_pred_length": 6.139942091655986,
        "median_pred_length": 19.5,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.5517241379310345,
        "vocab_size-1": 304,
        "unique-1": 239,
        "entropy-1": 7.494451857489044,
        "distinct-2": 0.9232245681381958,
        "vocab_size-2": 481,
        "unique-2": 453,
        "entropy-2": 8.849496999890135,
        "cond_entropy-2": 1.2263833024838124,
        "distinct-3": 0.9857433808553971,
        "vocab_size-3": 484,
        "unique-3": 481,
        "entropy-3": 8.902919336514344,
        "cond_entropy-3": 0.06415406141363277,
        "total_length-nopunct": 494,
        "mean_pred_length-nopunct": 16.466666666666665,
        "std_pred_length-nopunct": 5.542161632030913,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6012145748987854,
        "vocab_size-1-nopunct": 297,
        "unique-1-nopunct": 239,
        "entropy-1-nopunct": 7.564646440153883,
        "distinct-2-nopunct": 0.9418103448275862,
        "vocab_size-2-nopunct": 437,
        "unique-2-nopunct": 416,
        "entropy-2-nopunct": 8.729727169687314,
        "cond_entropy-2-nopunct": 1.240353706348353,
        "distinct-3-nopunct": 0.9976958525345622,
        "vocab_size-3-nopunct": 433,
        "unique-3-nopunct": 432,
        "entropy-3-nopunct": 8.756942937513553,
        "cond_entropy-3-nopunct": 0.03608123963102468,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.049773755656108594,
            "2": 0.13580246913580246,
            "3": 0.3389830508474576,
            "4": 0.36231884057971014,
            "5": 0.40217391304347827,
            "6": 0.538961038961039,
            "7": 0.7899543378995434
        },
        "nist": 5.719949950419487,
        "rouge1": {
            "precision": 0.7779,
            "recall": 0.65745,
            "fmeasure": 0.69285
        },
        "rouge2": {
            "precision": 0.62765,
            "recall": 0.50558,
            "fmeasure": 0.54
        },
        "rougeL": {
            "precision": 0.74349,
            "recall": 0.62203,
            "fmeasure": 0.65549
        },
        "rougeLsum": {
            "precision": 0.74349,
            "recall": 0.62203,
            "fmeasure": 0.65549
        },
        "bleu": 54.41252,
        "nubia": {
            "semantic_relation": 3.85671,
            "contradiction": 3.44682,
            "irrelevancy": 20.58622,
            "logical_agreement": 75.96696,
            "grammar_ref": 4.65355,
            "grammar_hyp": 5.14258,
            "nubia_score": 0.55915
        },
        "bleurt": -0.09038,
        "meteor": 0.37275954290243696,
        "bertscore": {
            "precision": 0.93651,
            "recall": 0.91128,
            "f1": 0.91782
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.78667,
        "total_length": 447,
        "mean_pred_length": 22.35,
        "std_pred_length": 6.436419812286951,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.5861297539149888,
        "vocab_size-1": 262,
        "unique-1": 223,
        "entropy-1": 7.203810433406763,
        "distinct-2": 0.9203747072599532,
        "vocab_size-2": 393,
        "unique-2": 371,
        "entropy-2": 8.544249402634158,
        "cond_entropy-2": 1.3577864978480776,
        "distinct-3": 0.9877149877149877,
        "vocab_size-3": 402,
        "unique-3": 397,
        "entropy-3": 8.644314959696214,
        "cond_entropy-3": 0.10959100457982773,
        "total_length-nopunct": 378,
        "mean_pred_length-nopunct": 18.9,
        "std_pred_length-nopunct": 5.42125446737192,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6746031746031746,
        "vocab_size-1-nopunct": 255,
        "unique-1-nopunct": 221,
        "entropy-1-nopunct": 7.415293741750847,
        "distinct-2-nopunct": 0.952513966480447,
        "vocab_size-2-nopunct": 341,
        "unique-2-nopunct": 328,
        "entropy-2-nopunct": 8.37903986943094,
        "cond_entropy-2-nopunct": 1.000573183957333,
        "distinct-3-nopunct": 0.9970414201183432,
        "vocab_size-3-nopunct": 337,
        "unique-3-nopunct": 336,
        "entropy-3-nopunct": 8.394962276518834,
        "cond_entropy-3-nopunct": 0.022122164947889336,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13793103448275862,
            "2": 0.32967032967032966,
            "3": 0.641566265060241
        },
        "nist": 3.796372841025421,
        "rouge1": {
            "precision": 0.71465,
            "recall": 0.58457,
            "fmeasure": 0.62061
        },
        "rouge2": {
            "precision": 0.47159,
            "recall": 0.38124,
            "fmeasure": 0.40824
        },
        "rougeL": {
            "precision": 0.57464,
            "recall": 0.47697,
            "fmeasure": 0.50208
        },
        "rougeLsum": {
            "precision": 0.57464,
            "recall": 0.47697,
            "fmeasure": 0.50208
        },
        "bleu": 30.91537,
        "nubia": {
            "semantic_relation": 3.49787,
            "contradiction": 14.05469,
            "irrelevancy": 26.4102,
            "logical_agreement": 59.53511,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.76698,
            "nubia_score": 0.47667
        },
        "bleurt": -0.11448,
        "meteor": 0.2914528019773797,
        "bertscore": {
            "precision": 0.91618,
            "recall": 0.892,
            "f1": 0.89916
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level6": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 9,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.82,
        "total_length": 166,
        "mean_pred_length": 18.444444444444443,
        "std_pred_length": 4.323350324076381,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.7469879518072289,
        "vocab_size-1": 124,
        "unique-1": 109,
        "entropy-1": 6.586878152497307,
        "distinct-2": 0.9681528662420382,
        "vocab_size-2": 152,
        "unique-2": 151,
        "entropy-2": 7.195832373067884,
        "cond_entropy-2": 0.5203774785937967,
        "distinct-3": 1.0,
        "vocab_size-3": 148,
        "unique-3": 148,
        "entropy-3": 7.209453365628947,
        "cond_entropy-3": 0.019628393793586035,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.78,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.543253541902303,
        "distinct-2-nopunct": 0.9645390070921985,
        "vocab_size-2-nopunct": 136,
        "unique-2-nopunct": 135,
        "entropy-2-nopunct": 7.029552948112767,
        "cond_entropy-2-nopunct": 0.5300588837802722,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 132,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.044394119358443,
        "cond_entropy-3-nopunct": 0.02234106244698484,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.05185185185185185,
            "2": 0.18181818181818182,
            "3": 0.5,
            "4": 0.75,
            "5": 0.5,
            "6": 0.62,
            "7": 0.7301587301587301
        },
        "nist": 5.748352087811841,
        "rouge1": {
            "precision": 0.81994,
            "recall": 0.68935,
            "fmeasure": 0.74526
        },
        "rouge2": {
            "precision": 0.6396,
            "recall": 0.53458,
            "fmeasure": 0.57914
        },
        "rougeL": {
            "precision": 0.76675,
            "recall": 0.63589,
            "fmeasure": 0.69181
        },
        "rougeLsum": {
            "precision": 0.76675,
            "recall": 0.63589,
            "fmeasure": 0.69181
        },
        "bleu": 56.88159,
        "nubia": {
            "semantic_relation": 3.82086,
            "contradiction": 7.26224,
            "irrelevancy": 30.25728,
            "logical_agreement": 62.48047,
            "grammar_ref": 4.59683,
            "grammar_hyp": 5.34751,
            "nubia_score": 0.52043
        },
        "bleurt": -0.01095,
        "meteor": 0.3622995597758784,
        "bertscore": {
            "precision": 0.93639,
            "recall": 0.90236,
            "f1": 0.91662
        }
    },
    "wiki_auto_asset_turk_test_turk_contrast_challenge_syncomp_simpl-Level7": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 63,
        "msttr-100": 0.755,
        "msttr-100_nopunct": 0.78273,
        "total_length": 1260,
        "mean_pred_length": 20.0,
        "std_pred_length": 6.007931265855003,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.49444444444444446,
        "vocab_size-1": 623,
        "unique-1": 494,
        "entropy-1": 8.1587757550477,
        "distinct-2": 0.9055973266499582,
        "vocab_size-2": 1084,
        "unique-2": 1034,
        "entropy-2": 9.923496783812425,
        "cond_entropy-2": 1.7085621097061872,
        "distinct-3": 0.9647266313932981,
        "vocab_size-3": 1094,
        "unique-3": 1085,
        "entropy-3": 10.009878095925936,
        "cond_entropy-3": 0.10314301506500034,
        "total_length-nopunct": 1144,
        "mean_pred_length-nopunct": 18.158730158730158,
        "std_pred_length-nopunct": 5.677039104205444,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5367132867132867,
        "vocab_size-1-nopunct": 614,
        "unique-1-nopunct": 489,
        "entropy-1-nopunct": 8.282035501965249,
        "distinct-2-nopunct": 0.9435707678075855,
        "vocab_size-2-nopunct": 1020,
        "unique-2-nopunct": 977,
        "entropy-2-nopunct": 9.944305250940712,
        "cond_entropy-2-nopunct": 1.7351636906600312,
        "distinct-3-nopunct": 0.9950884086444007,
        "vocab_size-3-nopunct": 1013,
        "unique-3-nopunct": 1008,
        "entropy-3-nopunct": 9.98169866336457,
        "cond_entropy-3-nopunct": 0.04215501122251761,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04339440694310511,
            "2": 0.13664596273291926,
            "3": 0.2553191489361702,
            "4": 0.4253731343283582,
            "5": 0.48627450980392156,
            "6": 0.5969773299748111,
            "7": 0.7037735849056603
        },
        "nist": 6.196275092857114,
        "rouge1": {
            "precision": 0.79188,
            "recall": 0.63789,
            "fmeasure": 0.6871
        },
        "rouge2": {
            "precision": 0.63788,
            "recall": 0.51532,
            "fmeasure": 0.55401
        },
        "rougeL": {
            "precision": 0.75732,
            "recall": 0.61796,
            "fmeasure": 0.66225
        },
        "rougeLsum": {
            "precision": 0.75732,
            "recall": 0.61796,
            "fmeasure": 0.66225
        },
        "bleu": 55.30261,
        "nubia": {
            "semantic_relation": 3.76951,
            "contradiction": 6.01471,
            "irrelevancy": 22.33012,
            "logical_agreement": 71.65517,
            "grammar_ref": 4.43738,
            "grammar_hyp": 5.14748,
            "nubia_score": 0.5318
        },
        "bleurt": -0.19808,
        "meteor": 0.35786046383718173,
        "bertscore": {
            "precision": 0.92453,
            "recall": 0.90133,
            "f1": 0.90821
        }
    },
    "web_nlg_ru_challenge_test_scramble": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.66891,
        "msttr-100_nopunct": 0.72085,
        "total_length": 5578,
        "mean_pred_length": 11.156,
        "std_pred_length": 3.046910566459081,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.28988884904983864,
        "vocab_size-1": 1617,
        "unique-1": 936,
        "entropy-1": 8.887609009190903,
        "distinct-2": 0.6051595116187476,
        "vocab_size-2": 3073,
        "unique-2": 2239,
        "entropy-2": 11.133367673433694,
        "cond_entropy-2": 2.251393759007711,
        "distinct-3": 0.7848405417212757,
        "vocab_size-3": 3593,
        "unique-3": 2987,
        "entropy-3": 11.64477609519515,
        "cond_entropy-3": 0.5916862134786166,
        "total_length-nopunct": 4736,
        "mean_pred_length-nopunct": 9.472,
        "std_pred_length-nopunct": 2.6842533412478042,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.34016047297297297,
        "vocab_size-1-nopunct": 1611,
        "unique-1-nopunct": 936,
        "entropy-1-nopunct": 9.38828349918708,
        "distinct-2-nopunct": 0.642823418319169,
        "vocab_size-2-nopunct": 2723,
        "unique-2-nopunct": 2049,
        "entropy-2-nopunct": 11.020138839369437,
        "cond_entropy-2-nopunct": 1.8049249720169938,
        "distinct-3-nopunct": 0.8016595289079229,
        "vocab_size-3-nopunct": 2995,
        "unique-3-nopunct": 2531,
        "entropy-3-nopunct": 11.392373069328418,
        "cond_entropy-3-nopunct": 0.46427661400945575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.18269230769230768,
            "2": 0.3596969696969697,
            "3": 0.489010989010989,
            "4": 0.6444444444444445,
            "5": 0.4,
            "6": 1.0
        },
        "nist": 1.6108757009407126,
        "rouge1": {
            "precision": 0.27069,
            "recall": 0.21879,
            "fmeasure": 0.2339
        },
        "rouge2": {
            "precision": 0.12752,
            "recall": 0.09807,
            "fmeasure": 0.10553
        },
        "rougeL": {
            "precision": 0.26382,
            "recall": 0.21364,
            "fmeasure": 0.22809
        },
        "rougeLsum": {
            "precision": 0.26382,
            "recall": 0.21364,
            "fmeasure": 0.22809
        },
        "bleu": 22.54313,
        "nubia": {
            "semantic_relation": 3.63463,
            "contradiction": 21.40688,
            "irrelevancy": 22.12617,
            "logical_agreement": 56.46695,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.75186,
            "nubia_score": 0.7098
        },
        "bleurt": 0.13084,
        "meteor": 0.40407464669531323,
        "bertscore": {
            "precision": 0.95318,
            "recall": 0.91567,
            "f1": 0.93318
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 149,
        "msttr-100": 0.1,
        "msttr-100_nopunct": 0.08,
        "total_length": 1788,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.005592841163310962,
        "vocab_size-1": 10,
        "unique-1": 0,
        "entropy-1": 3.188721875540867,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 11,
        "unique-2": 0,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.30673161811281985,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 10,
        "unique-3": 0,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 1192,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.006711409395973154,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.09785522788203753
        },
        "nist": 0.4722844955395275,
        "rouge1": {
            "precision": 0.17833,
            "recall": 0.38229,
            "fmeasure": 0.23855
        },
        "rouge2": {
            "precision": 0.03975,
            "recall": 0.11333,
            "fmeasure": 0.0579
        },
        "rougeL": {
            "precision": 0.16635,
            "recall": 0.35865,
            "fmeasure": 0.22326
        },
        "rougeLsum": {
            "precision": 0.16635,
            "recall": 0.35865,
            "fmeasure": 0.22326
        },
        "bleu": 0.696,
        "nubia": {
            "semantic_relation": 2.21147,
            "contradiction": 50.78054,
            "irrelevancy": 43.97333,
            "logical_agreement": 5.24613,
            "grammar_ref": 6.81129,
            "grammar_hyp": 6.2034,
            "nubia_score": 0.20101
        },
        "bleurt": -1.10101,
        "meteor": 0.05941689963779256,
        "bertscore": {
            "precision": 0.79134,
            "recall": 0.85869,
            "f1": 0.82349
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 144,
        "msttr-100": 0.71524,
        "msttr-100_nopunct": 0.76389,
        "total_length": 2143,
        "mean_pred_length": 14.881944444444445,
        "std_pred_length": 6.200914502198868,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 30,
        "distinct-1": 0.3775081661222585,
        "vocab_size-1": 809,
        "unique-1": 584,
        "entropy-1": 8.100614563834476,
        "distinct-2": 0.7538769384692346,
        "vocab_size-2": 1507,
        "unique-2": 1290,
        "entropy-2": 10.241865383817839,
        "cond_entropy-2": 1.867600662340402,
        "distinct-3": 0.8878706199460916,
        "vocab_size-3": 1647,
        "unique-3": 1533,
        "entropy-3": 10.568977500203543,
        "cond_entropy-3": 0.3245390806461007,
        "total_length-nopunct": 1863,
        "mean_pred_length-nopunct": 12.9375,
        "std_pred_length-nopunct": 5.5517999458634035,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.428341384863124,
        "vocab_size-1-nopunct": 798,
        "unique-1-nopunct": 579,
        "entropy-1-nopunct": 8.38942999267128,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 1337,
        "unique-2-nopunct": 1165,
        "entropy-2-nopunct": 10.086325876468228,
        "cond_entropy-2-nopunct": 1.7832161982519596,
        "distinct-3-nopunct": 0.8965079365079365,
        "vocab_size-3-nopunct": 1412,
        "unique-3-nopunct": 1320,
        "entropy-3-nopunct": 10.354939867970426,
        "cond_entropy-3-nopunct": 0.2836424778912501,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22957198443579765,
            "2": 0.47902869757174393,
            "3": 0.7626459143968871
        },
        "nist": 7.5888164903847555,
        "rouge1": {
            "precision": 0.74982,
            "recall": 0.71041,
            "fmeasure": 0.71365
        },
        "rouge2": {
            "precision": 0.52119,
            "recall": 0.49757,
            "fmeasure": 0.49778
        },
        "rougeL": {
            "precision": 0.65674,
            "recall": 0.63211,
            "fmeasure": 0.62916
        },
        "rougeLsum": {
            "precision": 0.65674,
            "recall": 0.63211,
            "fmeasure": 0.62916
        },
        "bleu": 46.72317,
        "nubia": {
            "semantic_relation": 4.06705,
            "contradiction": 5.22283,
            "irrelevancy": 34.11156,
            "logical_agreement": 60.66561,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.83764,
            "nubia_score": 0.68962
        },
        "bleurt": 0.21415,
        "meteor": 0.4014871601874577,
        "bertscore": {
            "precision": 0.9227,
            "recall": 0.91902,
            "f1": 0.91857
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.714,
        "total_length": 653,
        "mean_pred_length": 25.115384615384617,
        "std_pred_length": 5.576923076923077,
        "median_pred_length": 24.5,
        "min_pred_length": 13,
        "max_pred_length": 35,
        "distinct-1": 0.49770290964777947,
        "vocab_size-1": 325,
        "unique-1": 240,
        "entropy-1": 7.375473132943955,
        "distinct-2": 0.835725677830941,
        "vocab_size-2": 524,
        "unique-2": 459,
        "entropy-2": 8.889094729422844,
        "cond_entropy-2": 1.5013688953297277,
        "distinct-3": 0.9334442595673876,
        "vocab_size-3": 561,
        "unique-3": 529,
        "entropy-3": 9.08582338040301,
        "cond_entropy-3": 0.2022427516231628,
        "total_length-nopunct": 562,
        "mean_pred_length-nopunct": 21.615384615384617,
        "std_pred_length-nopunct": 4.464190193399048,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5676156583629893,
        "vocab_size-1-nopunct": 319,
        "unique-1-nopunct": 239,
        "entropy-1-nopunct": 7.56094111807029,
        "distinct-2-nopunct": 0.8675373134328358,
        "vocab_size-2-nopunct": 465,
        "unique-2-nopunct": 420,
        "entropy-2-nopunct": 8.740450023515033,
        "cond_entropy-2-nopunct": 1.2119842590229577,
        "distinct-3-nopunct": 0.9490196078431372,
        "vocab_size-3-nopunct": 484,
        "unique-3-nopunct": 465,
        "entropy-3-nopunct": 8.879394239833077,
        "cond_entropy-3-nopunct": 0.14067295325895612,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19166666666666668,
            "2": 0.29411764705882354,
            "3": 0.6365638766519823
        },
        "nist": 4.392725500615976,
        "rouge1": {
            "precision": 0.7266,
            "recall": 0.57026,
            "fmeasure": 0.62643
        },
        "rouge2": {
            "precision": 0.45795,
            "recall": 0.36309,
            "fmeasure": 0.39709
        },
        "rougeL": {
            "precision": 0.57027,
            "recall": 0.44654,
            "fmeasure": 0.49074
        },
        "rougeLsum": {
            "precision": 0.57027,
            "recall": 0.44654,
            "fmeasure": 0.49074
        },
        "bleu": 29.70427,
        "nubia": {
            "semantic_relation": 3.37085,
            "contradiction": 25.21238,
            "irrelevancy": 19.66307,
            "logical_agreement": 55.12455,
            "grammar_ref": 4.04917,
            "grammar_hyp": 4.31705,
            "nubia_score": 0.46328
        },
        "bleurt": -0.15671,
        "meteor": 0.28280443655424364,
        "bertscore": {
            "precision": 0.90321,
            "recall": 0.88041,
            "f1": 0.88978
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 267,
        "msttr-100": 0.51435,
        "msttr-100_nopunct": 0.545,
        "total_length": 2347,
        "mean_pred_length": 8.790262172284644,
        "std_pred_length": 2.5821736058051226,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 19,
        "distinct-1": 0.1469961653174265,
        "vocab_size-1": 345,
        "unique-1": 162,
        "entropy-1": 6.330761787544552,
        "distinct-2": 0.35336538461538464,
        "vocab_size-2": 735,
        "unique-2": 425,
        "entropy-2": 8.355822652170515,
        "cond_entropy-2": 1.8106401121788047,
        "distinct-3": 0.4958632101489244,
        "vocab_size-3": 899,
        "unique-3": 621,
        "entropy-3": 9.02816457634605,
        "cond_entropy-3": 0.9520004881652763,
        "total_length-nopunct": 2078,
        "mean_pred_length-nopunct": 7.782771535580524,
        "std_pred_length-nopunct": 2.418252029956406,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.1645813282001925,
        "vocab_size-1-nopunct": 342,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 6.47134955025707,
        "distinct-2-nopunct": 0.3169519602429597,
        "vocab_size-2-nopunct": 574,
        "unique-2-nopunct": 319,
        "entropy-2-nopunct": 7.923873852839942,
        "cond_entropy-2-nopunct": 1.9644124123024116,
        "distinct-3-nopunct": 0.4630829015544041,
        "vocab_size-3-nopunct": 715,
        "unique-3-nopunct": 488,
        "entropy-3-nopunct": 8.622339329683772,
        "cond_entropy-3-nopunct": 1.0932796773671423,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.5687250996015937
        },
        "nist": 4.505038914167523,
        "rouge1": {
            "precision": 0.604,
            "recall": 0.60616,
            "fmeasure": 0.5934
        },
        "rouge2": {
            "precision": 0.35165,
            "recall": 0.35248,
            "fmeasure": 0.34441
        },
        "rougeL": {
            "precision": 0.55751,
            "recall": 0.5591,
            "fmeasure": 0.54779
        },
        "rougeLsum": {
            "precision": 0.55751,
            "recall": 0.5591,
            "fmeasure": 0.54779
        },
        "bleu": 22.41193,
        "nubia": {
            "semantic_relation": 3.72652,
            "contradiction": 15.61327,
            "irrelevancy": 30.67837,
            "logical_agreement": 53.70836,
            "grammar_ref": 7.44295,
            "grammar_hyp": 7.3425,
            "nubia_score": 0.58666
        },
        "bleurt": 0.00314,
        "meteor": 0.2865105552613299,
        "bertscore": {
            "precision": 0.91072,
            "recall": 0.91162,
            "f1": 0.91093
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 254,
        "msttr-100": 0.74762,
        "msttr-100_nopunct": 0.87294,
        "total_length": 2139,
        "mean_pred_length": 8.421259842519685,
        "std_pred_length": 2.2726767984294773,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 15,
        "distinct-1": 0.4216923796166433,
        "vocab_size-1": 902,
        "unique-1": 609,
        "entropy-1": 8.376309558773015,
        "distinct-2": 0.7660477453580902,
        "vocab_size-2": 1444,
        "unique-2": 1184,
        "entropy-2": 10.273458998389483,
        "cond_entropy-2": 1.3129118046018542,
        "distinct-3": 0.8933169834457388,
        "vocab_size-3": 1457,
        "unique-3": 1317,
        "entropy-3": 10.436833981495283,
        "cond_entropy-3": 0.1548819932408241,
        "total_length-nopunct": 1730,
        "mean_pred_length-nopunct": 6.811023622047244,
        "std_pred_length-nopunct": 2.041815941270093,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.5184971098265896,
        "vocab_size-1-nopunct": 897,
        "unique-1-nopunct": 609,
        "entropy-1-nopunct": 9.046882483103442,
        "distinct-2-nopunct": 0.7913279132791328,
        "vocab_size-2-nopunct": 1168,
        "unique-2-nopunct": 983,
        "entropy-2-nopunct": 9.987164922922227,
        "cond_entropy-2-nopunct": 1.0690700808430453,
        "distinct-3-nopunct": 0.9018003273322422,
        "vocab_size-3-nopunct": 1102,
        "unique-3-nopunct": 1010,
        "entropy-3-nopunct": 10.035353669645927,
        "cond_entropy-3-nopunct": 0.11230591463222948,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.38790760869565216,
            "2": 0.7059639389736477,
            "3": 0.7849829351535836,
            "4": 0.7714285714285715,
            "5": 0.36363636363636365,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 8.447843582379233,
        "rouge1": {
            "precision": 0.28406,
            "recall": 0.2873,
            "fmeasure": 0.28379
        },
        "rouge2": {
            "precision": 0.16932,
            "recall": 0.16732,
            "fmeasure": 0.16697
        },
        "rougeL": {
            "precision": 0.28241,
            "recall": 0.28583,
            "fmeasure": 0.28224
        },
        "rougeLsum": {
            "precision": 0.28241,
            "recall": 0.28583,
            "fmeasure": 0.28224
        },
        "bleu": 58.79104,
        "nubia": {
            "semantic_relation": 4.18338,
            "contradiction": 19.5828,
            "irrelevancy": 20.09613,
            "logical_agreement": 60.32107,
            "grammar_ref": 2.90382,
            "grammar_hyp": 2.92031,
            "nubia_score": 0.84077
        },
        "bleurt": 0.4051,
        "meteor": 0.7369501684804334,
        "bertscore": {
            "precision": 0.97079,
            "recall": 0.9661,
            "f1": 0.96799
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc_parent": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.73574,
        "msttr-100_nopunct": 0.77073,
        "total_length": 6195,
        "mean_pred_length": 17.25626740947075,
        "std_pred_length": 6.102746858210674,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3861178369652946,
        "vocab_size-1": 2392,
        "unique-1": 1804,
        "entropy-1": 9.128919406069475,
        "distinct-2": 0.8415010281014393,
        "vocab_size-2": 4911,
        "unique-2": 4579,
        "entropy-2": 11.951184855882673,
        "cond_entropy-2": 2.645463000586634,
        "distinct-3": 0.9667701296330108,
        "vocab_size-3": 5295,
        "unique-3": 5209,
        "entropy-3": 12.306699863458707,
        "cond_entropy-3": 0.38003923522366023,
        "total_length-nopunct": 5551,
        "mean_pred_length-nopunct": 15.462395543175488,
        "std_pred_length-nopunct": 5.597761774116267,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.42857142857142855,
        "vocab_size-1-nopunct": 2379,
        "unique-1-nopunct": 1801,
        "entropy-1-nopunct": 9.397022590121578,
        "distinct-2-nopunct": 0.863251155624037,
        "vocab_size-2-nopunct": 4482,
        "unique-2-nopunct": 4202,
        "entropy-2-nopunct": 11.879929657724336,
        "cond_entropy-2-nopunct": 2.629561991939067,
        "distinct-3-nopunct": 0.9836540451065591,
        "vocab_size-3-nopunct": 4754,
        "unique-3-nopunct": 4692,
        "entropy-3-nopunct": 12.20277347589048,
        "cond_entropy-3-nopunct": 0.3485169726431887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02627710400588019,
            "2": 0.1307277628032345,
            "3": 0.29397590361445786,
            "4": 0.4908256880733945,
            "5": 0.5614567526555387,
            "6": 0.6394366197183099,
            "7": 0.6939890710382514,
            "8": 0.7478890229191797,
            "9": 0.8084656084656084,
            "10": 0.9031007751937985
        },
        "nist": 12.671020892791919,
        "rouge1": {
            "precision": 0.8717,
            "recall": 0.81549,
            "fmeasure": 0.83041
        },
        "rouge2": {
            "precision": 0.76832,
            "recall": 0.71155,
            "fmeasure": 0.72475
        },
        "rougeL": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "rougeLsum": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "bleu": 81.93645,
        "nubia": {
            "semantic_relation": 4.06169,
            "contradiction": 3.80336,
            "irrelevancy": 30.13173,
            "logical_agreement": 66.06491,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.90619,
            "nubia_score": 0.62654
        },
        "bleurt": 0.1314,
        "meteor": 0.4679813155989895,
        "bertscore": {
            "precision": 0.96224,
            "recall": 0.95179,
            "f1": 0.95293
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.735,
        "total_length": 253,
        "mean_pred_length": 25.3,
        "std_pred_length": 5.000999900019995,
        "median_pred_length": 26.5,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.6047430830039525,
        "vocab_size-1": 153,
        "unique-1": 117,
        "entropy-1": 6.7028878456299195,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 216,
        "unique-2": 196,
        "entropy-2": 7.678827164055076,
        "cond_entropy-2": 1.0203881138598996,
        "distinct-3": 0.9613733905579399,
        "vocab_size-3": 224,
        "unique-3": 216,
        "entropy-3": 7.783693065245888,
        "cond_entropy-3": 0.11542321190109153,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 22.4,
        "std_pred_length-nopunct": 4.673328578219169,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6651785714285714,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.784316528293491,
        "distinct-2-nopunct": 0.9345794392523364,
        "vocab_size-2-nopunct": 200,
        "unique-2-nopunct": 188,
        "entropy-2-nopunct": 7.603570841521083,
        "cond_entropy-2-nopunct": 0.8670598456464826,
        "distinct-3-nopunct": 0.9803921568627451,
        "vocab_size-3-nopunct": 200,
        "unique-3-nopunct": 196,
        "entropy-3-nopunct": 7.633209655696986,
        "cond_entropy-3-nopunct": 0.03639842912097074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.136986301369863,
            "2": 0.3559322033898305,
            "3": 0.6095890410958904
        },
        "nist": 4.244689387905875,
        "rouge1": {
            "precision": 0.64726,
            "recall": 0.57249,
            "fmeasure": 0.59629
        },
        "rouge2": {
            "precision": 0.41565,
            "recall": 0.36851,
            "fmeasure": 0.38294
        },
        "rougeL": {
            "precision": 0.52256,
            "recall": 0.44042,
            "fmeasure": 0.47109
        },
        "rougeLsum": {
            "precision": 0.52256,
            "recall": 0.44042,
            "fmeasure": 0.47109
        },
        "bleu": 36.526,
        "nubia": {
            "semantic_relation": 3.22066,
            "contradiction": 16.47681,
            "irrelevancy": 46.55415,
            "logical_agreement": 36.96904,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.85507,
            "nubia_score": 0.43735
        },
        "bleurt": -0.38544,
        "meteor": 0.2706716357240329,
        "bertscore": {
            "precision": 0.88035,
            "recall": 0.86663,
            "f1": 0.87199
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.76,
        "total_length": 311,
        "mean_pred_length": 22.214285714285715,
        "std_pred_length": 4.474987173622024,
        "median_pred_length": 24.5,
        "min_pred_length": 14,
        "max_pred_length": 28,
        "distinct-1": 0.6270096463022508,
        "vocab_size-1": 195,
        "unique-1": 164,
        "entropy-1": 6.912643844680149,
        "distinct-2": 0.9225589225589226,
        "vocab_size-2": 274,
        "unique-2": 259,
        "entropy-2": 8.026049265713613,
        "cond_entropy-2": 1.099371242115661,
        "distinct-3": 0.9787985865724381,
        "vocab_size-3": 277,
        "unique-3": 271,
        "entropy-3": 8.102255415976737,
        "cond_entropy-3": 0.08551985334169418,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 19.857142857142858,
        "std_pred_length-nopunct": 3.582838915424129,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6798561151079137,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 163,
        "entropy-1-nopunct": 6.966319404417245,
        "distinct-2-nopunct": 0.9204545454545454,
        "vocab_size-2-nopunct": 243,
        "unique-2-nopunct": 230,
        "entropy-2-nopunct": 7.847742047536895,
        "cond_entropy-2-nopunct": 0.9223877009279468,
        "distinct-3-nopunct": 0.98,
        "vocab_size-3-nopunct": 245,
        "unique-3-nopunct": 240,
        "entropy-3-nopunct": 7.9257842846621,
        "cond_entropy-3-nopunct": 0.08905475314720786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3142857142857143,
            "2": 0.4492753623188406,
            "3": 0.5805084745762712
        },
        "nist": 4.057140543791558,
        "rouge1": {
            "precision": 0.69157,
            "recall": 0.56758,
            "fmeasure": 0.60449
        },
        "rouge2": {
            "precision": 0.42798,
            "recall": 0.3414,
            "fmeasure": 0.36901
        },
        "rougeL": {
            "precision": 0.55964,
            "recall": 0.4639,
            "fmeasure": 0.49307
        },
        "rougeLsum": {
            "precision": 0.55964,
            "recall": 0.4639,
            "fmeasure": 0.49307
        },
        "bleu": 29.85973,
        "nubia": {
            "semantic_relation": 3.40255,
            "contradiction": 26.688,
            "irrelevancy": 20.57727,
            "logical_agreement": 52.73473,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.34791,
            "nubia_score": 0.44253
        },
        "bleurt": -0.06676,
        "meteor": 0.2856136337368012,
        "bertscore": {
            "precision": 0.90323,
            "recall": 0.86907,
            "f1": 0.88502
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.68143,
        "msttr-100_nopunct": 0.73667,
        "total_length": 737,
        "mean_pred_length": 15.680851063829786,
        "std_pred_length": 5.481521698101193,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.4559023066485753,
        "vocab_size-1": 336,
        "unique-1": 246,
        "entropy-1": 7.2963733824883805,
        "distinct-2": 0.8101449275362319,
        "vocab_size-2": 559,
        "unique-2": 501,
        "entropy-2": 8.88477608509688,
        "cond_entropy-2": 1.3985684554332503,
        "distinct-3": 0.8895800933125972,
        "vocab_size-3": 572,
        "unique-3": 541,
        "entropy-3": 9.0261203495964,
        "cond_entropy-3": 0.17500957387553898,
        "total_length-nopunct": 628,
        "mean_pred_length-nopunct": 13.361702127659575,
        "std_pred_length-nopunct": 4.879071815787558,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5254777070063694,
        "vocab_size-1-nopunct": 330,
        "unique-1-nopunct": 246,
        "entropy-1-nopunct": 7.488787463453913,
        "distinct-2-nopunct": 0.8175559380378657,
        "vocab_size-2-nopunct": 475,
        "unique-2-nopunct": 431,
        "entropy-2-nopunct": 8.646426459336325,
        "cond_entropy-2-nopunct": 1.272155888159093,
        "distinct-3-nopunct": 0.8932584269662921,
        "vocab_size-3-nopunct": 477,
        "unique-3-nopunct": 451,
        "entropy-3-nopunct": 8.771785948588631,
        "cond_entropy-3-nopunct": 0.16020130296100824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.41007194244604317,
            "3": 0.6731182795698925
        },
        "nist": 5.949700213531574,
        "rouge1": {
            "precision": 0.66646,
            "recall": 0.66069,
            "fmeasure": 0.65369
        },
        "rouge2": {
            "precision": 0.43398,
            "recall": 0.43349,
            "fmeasure": 0.42757
        },
        "rougeL": {
            "precision": 0.58634,
            "recall": 0.57309,
            "fmeasure": 0.57084
        },
        "rougeLsum": {
            "precision": 0.58634,
            "recall": 0.57309,
            "fmeasure": 0.57084
        },
        "bleu": 40.27108,
        "nubia": {
            "semantic_relation": 3.89157,
            "contradiction": 14.50728,
            "irrelevancy": 32.11405,
            "logical_agreement": 53.37867,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.5136,
            "nubia_score": 0.64421
        },
        "bleurt": 0.18222,
        "meteor": 0.34801000437558977,
        "bertscore": {
            "precision": 0.90992,
            "recall": 0.9035,
            "f1": 0.90459
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.765,
        "total_length": 313,
        "mean_pred_length": 22.357142857142858,
        "std_pred_length": 5.911334667485881,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.610223642172524,
        "vocab_size-1": 191,
        "unique-1": 155,
        "entropy-1": 6.958768387221517,
        "distinct-2": 0.9364548494983278,
        "vocab_size-2": 280,
        "unique-2": 266,
        "entropy-2": 8.08100873940822,
        "cond_entropy-2": 1.1173666696813964,
        "distinct-3": 0.9859649122807017,
        "vocab_size-3": 281,
        "unique-3": 277,
        "entropy-3": 8.126747933613524,
        "cond_entropy-3": 0.04574586468615182,
        "total_length-nopunct": 262,
        "mean_pred_length-nopunct": 18.714285714285715,
        "std_pred_length-nopunct": 4.430874976934521,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7022900763358778,
        "vocab_size-1-nopunct": 184,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 7.114620914089501,
        "distinct-2-nopunct": 0.9717741935483871,
        "vocab_size-2-nopunct": 241,
        "unique-2-nopunct": 234,
        "entropy-2-nopunct": 7.897744697483673,
        "cond_entropy-2-nopunct": 0.8141451713894512,
        "distinct-3-nopunct": 0.9957264957264957,
        "vocab_size-3-nopunct": 233,
        "unique-3-nopunct": 232,
        "entropy-3-nopunct": 7.861817711036382,
        "cond_entropy-3-nopunct": -0.03682304379492388,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2619047619047619,
            "2": 0.23529411764705882,
            "3": 0.532319391634981
        },
        "nist": 3.203261724561732,
        "rouge1": {
            "precision": 0.69463,
            "recall": 0.55281,
            "fmeasure": 0.59225
        },
        "rouge2": {
            "precision": 0.36857,
            "recall": 0.30655,
            "fmeasure": 0.3206
        },
        "rougeL": {
            "precision": 0.52311,
            "recall": 0.43043,
            "fmeasure": 0.45403
        },
        "rougeLsum": {
            "precision": 0.52311,
            "recall": 0.43043,
            "fmeasure": 0.45403
        },
        "bleu": 20.27994,
        "nubia": {
            "semantic_relation": 3.31229,
            "contradiction": 39.89451,
            "irrelevancy": 27.20918,
            "logical_agreement": 32.8963,
            "grammar_ref": 3.91022,
            "grammar_hyp": 4.59006,
            "nubia_score": 0.40179
        },
        "bleurt": -0.27853,
        "meteor": 0.25285507138845636,
        "bertscore": {
            "precision": 0.89171,
            "recall": 0.86773,
            "f1": 0.87798
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation_parent": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73983,
        "msttr-100_nopunct": 0.77415,
        "total_length": 5941,
        "mean_pred_length": 16.54874651810585,
        "std_pred_length": 6.029384160853018,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.38023901700050494,
        "vocab_size-1": 2259,
        "unique-1": 1690,
        "entropy-1": 9.076608864809497,
        "distinct-2": 0.8453959154424937,
        "vocab_size-2": 4719,
        "unique-2": 4395,
        "entropy-2": 11.91588152640679,
        "cond_entropy-2": 2.6249027906690263,
        "distinct-3": 0.9689833429063757,
        "vocab_size-3": 5061,
        "unique-3": 4986,
        "entropy-3": 12.247669214831733,
        "cond_entropy-3": 0.3551319058023003,
        "total_length-nopunct": 5344,
        "mean_pred_length-nopunct": 14.885793871866296,
        "std_pred_length-nopunct": 5.624339651427024,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.42047155688622756,
        "vocab_size-1-nopunct": 2247,
        "unique-1-nopunct": 1687,
        "entropy-1-nopunct": 9.34693880826332,
        "distinct-2-nopunct": 0.8647943831494483,
        "vocab_size-2-nopunct": 4311,
        "unique-2-nopunct": 4032,
        "entropy-2-nopunct": 11.838746836403581,
        "cond_entropy-2-nopunct": 2.64631598324386,
        "distinct-3-nopunct": 0.9827064418504107,
        "vocab_size-3-nopunct": 4546,
        "unique-3-nopunct": 4484,
        "entropy-3-nopunct": 12.136984131701494,
        "cond_entropy-3-nopunct": 0.32221182220254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04095925297113752,
            "2": 0.14559386973180077,
            "3": 0.31072210065645517,
            "4": 0.4215530903328051,
            "5": 0.4953271028037383,
            "6": 0.6304347826086957,
            "7": 0.7697594501718213
        },
        "nist": 8.317675435042805,
        "rouge1": {
            "precision": 0.82557,
            "recall": 0.70191,
            "fmeasure": 0.74213
        },
        "rouge2": {
            "precision": 0.66664,
            "recall": 0.56249,
            "fmeasure": 0.59525
        },
        "rougeL": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "rougeLsum": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "bleu": 59.09788,
        "nubia": {
            "semantic_relation": 4.00419,
            "contradiction": 5.58916,
            "irrelevancy": 17.8311,
            "logical_agreement": 76.57974,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.09497,
            "nubia_score": 0.61215
        },
        "bleurt": 0.04706,
        "meteor": 0.389663287826127,
        "bertscore": {
            "precision": 0.94429,
            "recall": 0.91719,
            "f1": 0.92716
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02_parent": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73983,
        "msttr-100_nopunct": 0.77415,
        "total_length": 5941,
        "mean_pred_length": 16.54874651810585,
        "std_pred_length": 6.029384160853018,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.38023901700050494,
        "vocab_size-1": 2259,
        "unique-1": 1690,
        "entropy-1": 9.076608864809497,
        "distinct-2": 0.8453959154424937,
        "vocab_size-2": 4719,
        "unique-2": 4395,
        "entropy-2": 11.91588152640679,
        "cond_entropy-2": 2.6249027906690263,
        "distinct-3": 0.9689833429063757,
        "vocab_size-3": 5061,
        "unique-3": 4986,
        "entropy-3": 12.247669214831733,
        "cond_entropy-3": 0.3551319058023003,
        "total_length-nopunct": 5344,
        "mean_pred_length-nopunct": 14.885793871866296,
        "std_pred_length-nopunct": 5.624339651427024,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.42047155688622756,
        "vocab_size-1-nopunct": 2247,
        "unique-1-nopunct": 1687,
        "entropy-1-nopunct": 9.34693880826332,
        "distinct-2-nopunct": 0.8647943831494483,
        "vocab_size-2-nopunct": 4311,
        "unique-2-nopunct": 4032,
        "entropy-2-nopunct": 11.838746836403581,
        "cond_entropy-2-nopunct": 2.64631598324386,
        "distinct-3-nopunct": 0.9827064418504107,
        "vocab_size-3-nopunct": 4546,
        "unique-3-nopunct": 4484,
        "entropy-3-nopunct": 12.136984131701494,
        "cond_entropy-3-nopunct": 0.32221182220254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04095925297113752,
            "2": 0.14559386973180077,
            "3": 0.31072210065645517,
            "4": 0.4215530903328051,
            "5": 0.4953271028037383,
            "6": 0.6304347826086957,
            "7": 0.7697594501718213
        },
        "nist": 8.317675435042805,
        "rouge1": {
            "precision": 0.82557,
            "recall": 0.70191,
            "fmeasure": 0.74213
        },
        "rouge2": {
            "precision": 0.66664,
            "recall": 0.56249,
            "fmeasure": 0.59525
        },
        "rougeL": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "rougeLsum": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "bleu": 59.09788,
        "nubia": {
            "semantic_relation": 4.00419,
            "contradiction": 5.58916,
            "irrelevancy": 17.8311,
            "logical_agreement": 76.57974,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.09497,
            "nubia_score": 0.61215
        },
        "bleurt": 0.04706,
        "meteor": 0.389663287826127,
        "bertscore": {
            "precision": 0.94429,
            "recall": 0.91719,
            "f1": 0.92716
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 169,
        "mean_pred_length": 24.142857142857142,
        "std_pred_length": 2.695423180587601,
        "median_pred_length": 25.0,
        "min_pred_length": 20,
        "max_pred_length": 28,
        "distinct-1": 0.6272189349112426,
        "vocab_size-1": 106,
        "unique-1": 84,
        "entropy-1": 6.162416087433112,
        "distinct-2": 0.9320987654320988,
        "vocab_size-2": 151,
        "unique-2": 142,
        "entropy-2": 7.194727934956662,
        "cond_entropy-2": 1.0455567949673088,
        "distinct-3": 0.9870967741935484,
        "vocab_size-3": 153,
        "unique-3": 152,
        "entropy-3": 7.245447711711913,
        "cond_entropy-3": 0.057273676597118996,
        "total_length-nopunct": 141,
        "mean_pred_length-nopunct": 20.142857142857142,
        "std_pred_length-nopunct": 3.313546715640915,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.723404255319149,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 83,
        "entropy-1-nopunct": 6.421406806539336,
        "distinct-2-nopunct": 0.9477611940298507,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 6.95034460087325,
        "cond_entropy-2-nopunct": 0.5515274347892354,
        "distinct-3-nopunct": 0.984251968503937,
        "vocab_size-3-nopunct": 125,
        "unique-3-nopunct": 124,
        "entropy-3-nopunct": 6.951244627699994,
        "cond_entropy-3-nopunct": 0.007279649874735769,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.48333333333333334,
            "3": 0.6956521739130435
        },
        "nist": 4.101583825166183,
        "rouge1": {
            "precision": 0.73615,
            "recall": 0.57317,
            "fmeasure": 0.63294
        },
        "rouge2": {
            "precision": 0.45348,
            "recall": 0.3824,
            "fmeasure": 0.40682
        },
        "rougeL": {
            "precision": 0.62426,
            "recall": 0.50165,
            "fmeasure": 0.54429
        },
        "rougeLsum": {
            "precision": 0.62426,
            "recall": 0.50165,
            "fmeasure": 0.54429
        },
        "bleu": 34.24823,
        "nubia": {
            "semantic_relation": 3.11972,
            "contradiction": 17.60565,
            "irrelevancy": 62.06891,
            "logical_agreement": 20.32545,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.80272,
            "nubia_score": 0.39452
        },
        "bleurt": -0.14638,
        "meteor": 0.307897675575275,
        "bertscore": {
            "precision": 0.90946,
            "recall": 0.88431,
            "f1": 0.89462
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05_parent": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73983,
        "msttr-100_nopunct": 0.77415,
        "total_length": 5941,
        "mean_pred_length": 16.54874651810585,
        "std_pred_length": 6.029384160853018,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.38023901700050494,
        "vocab_size-1": 2259,
        "unique-1": 1690,
        "entropy-1": 9.076608864809497,
        "distinct-2": 0.8453959154424937,
        "vocab_size-2": 4719,
        "unique-2": 4395,
        "entropy-2": 11.91588152640679,
        "cond_entropy-2": 2.6249027906690263,
        "distinct-3": 0.9689833429063757,
        "vocab_size-3": 5061,
        "unique-3": 4986,
        "entropy-3": 12.247669214831733,
        "cond_entropy-3": 0.3551319058023003,
        "total_length-nopunct": 5344,
        "mean_pred_length-nopunct": 14.885793871866296,
        "std_pred_length-nopunct": 5.624339651427024,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.42047155688622756,
        "vocab_size-1-nopunct": 2247,
        "unique-1-nopunct": 1687,
        "entropy-1-nopunct": 9.34693880826332,
        "distinct-2-nopunct": 0.8647943831494483,
        "vocab_size-2-nopunct": 4311,
        "unique-2-nopunct": 4032,
        "entropy-2-nopunct": 11.838746836403581,
        "cond_entropy-2-nopunct": 2.64631598324386,
        "distinct-3-nopunct": 0.9827064418504107,
        "vocab_size-3-nopunct": 4546,
        "unique-3-nopunct": 4484,
        "entropy-3-nopunct": 12.136984131701494,
        "cond_entropy-3-nopunct": 0.32221182220254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04095925297113752,
            "2": 0.14559386973180077,
            "3": 0.31072210065645517,
            "4": 0.4215530903328051,
            "5": 0.4953271028037383,
            "6": 0.6304347826086957,
            "7": 0.7697594501718213
        },
        "nist": 8.317675435042805,
        "rouge1": {
            "precision": 0.82557,
            "recall": 0.70191,
            "fmeasure": 0.74213
        },
        "rouge2": {
            "precision": 0.66664,
            "recall": 0.56249,
            "fmeasure": 0.59525
        },
        "rougeL": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "rougeLsum": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "bleu": 59.09788,
        "nubia": {
            "semantic_relation": 4.00419,
            "contradiction": 5.58916,
            "irrelevancy": 17.8311,
            "logical_agreement": 76.57974,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.09497,
            "nubia_score": 0.61215
        },
        "bleurt": 0.04706,
        "meteor": 0.389663287826127,
        "bertscore": {
            "precision": 0.94429,
            "recall": 0.91719,
            "f1": 0.92716
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 59,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.7425,
        "total_length": 949,
        "mean_pred_length": 16.084745762711865,
        "std_pred_length": 5.016204708853708,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.48261327713382507,
        "vocab_size-1": 458,
        "unique-1": 374,
        "entropy-1": 7.659504717169878,
        "distinct-2": 0.8258426966292135,
        "vocab_size-2": 735,
        "unique-2": 665,
        "entropy-2": 9.313797603770558,
        "cond_entropy-2": 1.449818334061437,
        "distinct-3": 0.914560770156438,
        "vocab_size-3": 760,
        "unique-3": 715,
        "entropy-3": 9.499200808793123,
        "cond_entropy-3": 0.19296434689537842,
        "total_length-nopunct": 833,
        "mean_pred_length-nopunct": 14.11864406779661,
        "std_pred_length-nopunct": 4.694333929622369,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5402160864345739,
        "vocab_size-1-nopunct": 450,
        "unique-1-nopunct": 372,
        "entropy-1-nopunct": 7.845064263127555,
        "distinct-2-nopunct": 0.8307493540051679,
        "vocab_size-2-nopunct": 643,
        "unique-2-nopunct": 590,
        "entropy-2-nopunct": 9.10928477792324,
        "cond_entropy-2-nopunct": 1.343558217058718,
        "distinct-3-nopunct": 0.9174825174825175,
        "vocab_size-3-nopunct": 656,
        "unique-3-nopunct": 619,
        "entropy-3-nopunct": 9.288403724008758,
        "cond_entropy-3-nopunct": 0.19627944445474446,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.518796992481203,
            "3": 0.7965571205007824
        },
        "nist": 7.344425439284365,
        "rouge1": {
            "precision": 0.77679,
            "recall": 0.74588,
            "fmeasure": 0.75476
        },
        "rouge2": {
            "precision": 0.55476,
            "recall": 0.53243,
            "fmeasure": 0.53825
        },
        "rougeL": {
            "precision": 0.69504,
            "recall": 0.67423,
            "fmeasure": 0.67777
        },
        "rougeLsum": {
            "precision": 0.69504,
            "recall": 0.67423,
            "fmeasure": 0.67777
        },
        "bleu": 49.70841,
        "nubia": {
            "semantic_relation": 4.32572,
            "contradiction": 4.95487,
            "irrelevancy": 25.95213,
            "logical_agreement": 69.093,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.60225,
            "nubia_score": 0.77487
        },
        "bleurt": 0.35407,
        "meteor": 0.40729887173543955,
        "bertscore": {
            "precision": 0.94029,
            "recall": 0.93662,
            "f1": 0.93686
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 159,
        "msttr-100": 0.77889,
        "msttr-100_nopunct": 0.85625,
        "total_length": 1892,
        "mean_pred_length": 11.89937106918239,
        "std_pred_length": 2.260391708007357,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 18,
        "distinct-1": 0.41966173361522197,
        "vocab_size-1": 794,
        "unique-1": 524,
        "entropy-1": 8.358152900795892,
        "distinct-2": 0.7386035776110791,
        "vocab_size-2": 1280,
        "unique-2": 1025,
        "entropy-2": 10.080156508736502,
        "cond_entropy-2": 1.848333275933239,
        "distinct-3": 0.8729351969504447,
        "vocab_size-3": 1374,
        "unique-3": 1219,
        "entropy-3": 10.341473643465156,
        "cond_entropy-3": 0.30794409807867,
        "total_length-nopunct": 1606,
        "mean_pred_length-nopunct": 10.10062893081761,
        "std_pred_length-nopunct": 1.7309428432096208,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.4900373599003736,
        "vocab_size-1-nopunct": 787,
        "unique-1-nopunct": 522,
        "entropy-1-nopunct": 8.798300314009621,
        "distinct-2-nopunct": 0.7712508638562543,
        "vocab_size-2-nopunct": 1116,
        "unique-2-nopunct": 915,
        "entropy-2-nopunct": 9.931137391854,
        "cond_entropy-2-nopunct": 1.2510943458931878,
        "distinct-3-nopunct": 0.8819875776397516,
        "vocab_size-3-nopunct": 1136,
        "unique-3-nopunct": 1017,
        "entropy-3-nopunct": 10.07222307725016,
        "cond_entropy-3-nopunct": 0.19583047656973662,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1046133853151397,
            "2": 0.2379421221864952,
            "3": 0.37085514834205935
        },
        "nist": 0.1392960974052622,
        "rouge1": {
            "precision": 0.21426,
            "recall": 0.1325,
            "fmeasure": 0.155
        },
        "rouge2": {
            "precision": 0.07201,
            "recall": 0.04535,
            "fmeasure": 0.0528
        },
        "rougeL": {
            "precision": 0.213,
            "recall": 0.13189,
            "fmeasure": 0.15418
        },
        "rougeLsum": {
            "precision": 0.213,
            "recall": 0.13189,
            "fmeasure": 0.15418
        },
        "bleu": 9.54976,
        "nubia": {
            "semantic_relation": 3.24342,
            "contradiction": 22.44889,
            "irrelevancy": 21.27198,
            "logical_agreement": 56.27913,
            "grammar_ref": 2.45758,
            "grammar_hyp": 2.65074,
            "nubia_score": 0.57673
        },
        "bleurt": -0.05308,
        "meteor": 0.27202846340054715,
        "bertscore": {
            "precision": 0.93706,
            "recall": 0.87112,
            "f1": 0.90201
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "total_length": 156,
        "mean_pred_length": 26.0,
        "std_pred_length": 5.033222956847166,
        "median_pred_length": 26.0,
        "min_pred_length": 20,
        "max_pred_length": 34,
        "distinct-1": 0.6794871794871795,
        "vocab_size-1": 106,
        "unique-1": 86,
        "entropy-1": 6.375746271151145,
        "distinct-2": 0.9266666666666666,
        "vocab_size-2": 139,
        "unique-2": 129,
        "entropy-2": 7.077119440481442,
        "cond_entropy-2": 0.7050468032680479,
        "distinct-3": 0.9652777777777778,
        "vocab_size-3": 139,
        "unique-3": 134,
        "entropy-3": 7.100480556997886,
        "cond_entropy-3": 0.02968191860034468,
        "total_length-nopunct": 136,
        "mean_pred_length-nopunct": 22.666666666666668,
        "std_pred_length-nopunct": 3.5433819375782165,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.7426470588235294,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.405940437617536,
        "distinct-2-nopunct": 0.9538461538461539,
        "vocab_size-2-nopunct": 124,
        "unique-2-nopunct": 118,
        "entropy-2-nopunct": 6.930060120720763,
        "cond_entropy-2-nopunct": 0.5433825440345722,
        "distinct-3-nopunct": 0.9838709677419355,
        "vocab_size-3-nopunct": 122,
        "unique-3-nopunct": 120,
        "entropy-3-nopunct": 6.921938245870733,
        "cond_entropy-3-nopunct": -0.0036553736093211785,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12121212121212122,
            "2": 0.2777777777777778,
            "3": 0.6017699115044248
        },
        "nist": 3.829688775906167,
        "rouge1": {
            "precision": 0.69203,
            "recall": 0.53181,
            "fmeasure": 0.59263
        },
        "rouge2": {
            "precision": 0.5177,
            "recall": 0.38491,
            "fmeasure": 0.43579
        },
        "rougeL": {
            "precision": 0.64,
            "recall": 0.4981,
            "fmeasure": 0.55256
        },
        "rougeLsum": {
            "precision": 0.64,
            "recall": 0.4981,
            "fmeasure": 0.55256
        },
        "bleu": 38.82912,
        "nubia": {
            "semantic_relation": 3.30285,
            "contradiction": 20.40534,
            "irrelevancy": 9.27845,
            "logical_agreement": 70.31621,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.79632,
            "nubia_score": 0.48415
        },
        "bleurt": 0.02774,
        "meteor": 0.3008275327535654,
        "bertscore": {
            "precision": 0.90308,
            "recall": 0.88521,
            "f1": 0.89155
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.7,
        "total_length": 117,
        "mean_pred_length": 23.4,
        "std_pred_length": 6.053098380168623,
        "median_pred_length": 24.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.6410256410256411,
        "vocab_size-1": 75,
        "unique-1": 54,
        "entropy-1": 5.948225271618178,
        "distinct-2": 0.9107142857142857,
        "vocab_size-2": 102,
        "unique-2": 93,
        "entropy-2": 6.6220434265025645,
        "cond_entropy-2": 0.69712795166855,
        "distinct-3": 0.9532710280373832,
        "vocab_size-3": 102,
        "unique-3": 97,
        "entropy-3": 6.6480090424759055,
        "cond_entropy-3": 0.034625031653482005,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 20.2,
        "std_pred_length-nopunct": 4.707440918375928,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7029702970297029,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.930647686164024,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.410432422573624,
        "cond_entropy-2-nopunct": 0.5011686580993552,
        "distinct-3-nopunct": 0.9560439560439561,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.419882552286616,
        "cond_entropy-3-nopunct": 0.019039694446369066,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.5238095238095238,
            "3": 0.52
        },
        "nist": 2.747647668379798,
        "rouge1": {
            "precision": 0.63515,
            "recall": 0.55206,
            "fmeasure": 0.57468
        },
        "rouge2": {
            "precision": 0.41158,
            "recall": 0.3783,
            "fmeasure": 0.38608
        },
        "rougeL": {
            "precision": 0.56715,
            "recall": 0.497,
            "fmeasure": 0.51724
        },
        "rougeLsum": {
            "precision": 0.56715,
            "recall": 0.497,
            "fmeasure": 0.51724
        },
        "bleu": 22.29302,
        "nubia": {
            "semantic_relation": 3.48954,
            "contradiction": 34.992,
            "irrelevancy": 15.57424,
            "logical_agreement": 49.43376,
            "grammar_ref": 3.87874,
            "grammar_hyp": 4.21875,
            "nubia_score": 0.54438
        },
        "bleurt": -0.09137,
        "meteor": 0.23796125059470674,
        "bertscore": {
            "precision": 0.89015,
            "recall": 0.87695,
            "f1": 0.88303
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 110,
        "mean_pred_length": 22.0,
        "std_pred_length": 6.418722614352485,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 80,
        "unique-1": 62,
        "entropy-1": 6.095669513840841,
        "distinct-2": 0.9904761904761905,
        "vocab_size-2": 104,
        "unique-2": 103,
        "entropy-2": 6.695197898618494,
        "cond_entropy-2": 0.5863959664573006,
        "distinct-3": 1.0,
        "vocab_size-3": 100,
        "unique-3": 100,
        "entropy-3": 6.6438561897747395,
        "cond_entropy-3": -0.05038932789139774,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 19.4,
        "std_pred_length-nopunct": 5.986651818838307,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7835051546391752,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 6.0867743111477814,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.523561956057027,
        "cond_entropy-2-nopunct": 0.46467560855268286,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 87,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.442943495848723,
        "cond_entropy-3-nopunct": -0.0806184602082847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2619047619047619,
            "2": 0.42424242424242425,
            "3": 0.6571428571428571
        },
        "nist": 3.816539276938623,
        "rouge1": {
            "precision": 0.53564,
            "recall": 0.56217,
            "fmeasure": 0.54484
        },
        "rouge2": {
            "precision": 0.28517,
            "recall": 0.28912,
            "fmeasure": 0.28462
        },
        "rougeL": {
            "precision": 0.47268,
            "recall": 0.49713,
            "fmeasure": 0.48108
        },
        "rougeLsum": {
            "precision": 0.47268,
            "recall": 0.49713,
            "fmeasure": 0.48108
        },
        "bleu": 22.69029,
        "nubia": {
            "semantic_relation": 3.00957,
            "contradiction": 57.07186,
            "irrelevancy": 39.27323,
            "logical_agreement": 3.65491,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.77515,
            "nubia_score": 0.4105
        },
        "bleurt": -0.00767,
        "meteor": 0.28089082305935625,
        "bertscore": {
            "precision": 0.89323,
            "recall": 0.89001,
            "f1": 0.89013
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78,
        "total_length": 116,
        "mean_pred_length": 23.2,
        "std_pred_length": 3.54400902933387,
        "median_pred_length": 24.0,
        "min_pred_length": 17,
        "max_pred_length": 28,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 84,
        "unique-1": 66,
        "entropy-1": 6.167988753599047,
        "distinct-2": 0.954954954954955,
        "vocab_size-2": 106,
        "unique-2": 101,
        "entropy-2": 6.70432577626003,
        "cond_entropy-2": 0.5493997362433252,
        "distinct-3": 0.9905660377358491,
        "vocab_size-3": 105,
        "unique-3": 104,
        "entropy-3": 6.709052530034882,
        "cond_entropy-3": 0.008976286326300945,
        "total_length-nopunct": 102,
        "mean_pred_length-nopunct": 20.4,
        "std_pred_length-nopunct": 3.3823069050575527,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7745098039215687,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.125617131081133,
        "distinct-2-nopunct": 0.9690721649484536,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.538057172084048,
        "cond_entropy-2-nopunct": 0.43031675290447075,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.523561956057027,
        "cond_entropy-3-nopunct": -0.02200306004315831,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.375,
            "3": 0.5061728395061729
        },
        "nist": 1.931424806567663,
        "rouge1": {
            "precision": 0.59939,
            "recall": 0.48036,
            "fmeasure": 0.52196
        },
        "rouge2": {
            "precision": 0.31637,
            "recall": 0.23643,
            "fmeasure": 0.2637
        },
        "rougeL": {
            "precision": 0.45069,
            "recall": 0.36664,
            "fmeasure": 0.39332
        },
        "rougeLsum": {
            "precision": 0.45069,
            "recall": 0.36664,
            "fmeasure": 0.39332
        },
        "bleu": 18.78515,
        "nubia": {
            "semantic_relation": 3.09573,
            "contradiction": 14.95768,
            "irrelevancy": 52.91584,
            "logical_agreement": 32.12649,
            "grammar_ref": 4.13756,
            "grammar_hyp": 4.43746,
            "nubia_score": 0.35111
        },
        "bleurt": -0.21469,
        "meteor": 0.2206296413520453,
        "bertscore": {
            "precision": 0.89307,
            "recall": 0.86991,
            "f1": 0.88011
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 82,
        "mean_pred_length": 20.5,
        "std_pred_length": 5.220153254455275,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7804878048780488,
        "vocab_size-1": 64,
        "unique-1": 54,
        "entropy-1": 5.798109285338486,
        "distinct-2": 0.9743589743589743,
        "vocab_size-2": 76,
        "unique-2": 74,
        "entropy-2": 6.234120167580205,
        "cond_entropy-2": 0.4647002524611806,
        "distinct-3": 1.0,
        "vocab_size-3": 74,
        "unique-3": 74,
        "entropy-3": 6.2094533656289554,
        "cond_entropy-3": -0.02189479917924466,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 18.75,
        "std_pred_length-nopunct": 5.717298313014636,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.707226484112371,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 71,
        "entropy-2-nopunct": 6.149747119504677,
        "cond_entropy-2-nopunct": 0.47190611180829106,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.08365792904690947,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.6666666666666666,
            "3": 0.4642857142857143
        },
        "nist": 0.9424065527373796,
        "rouge1": {
            "precision": 0.64515,
            "recall": 0.4888,
            "fmeasure": 0.53593
        },
        "rouge2": {
            "precision": 0.42652,
            "recall": 0.31279,
            "fmeasure": 0.34548
        },
        "rougeL": {
            "precision": 0.52862,
            "recall": 0.39262,
            "fmeasure": 0.43089
        },
        "rougeLsum": {
            "precision": 0.52862,
            "recall": 0.39262,
            "fmeasure": 0.43089
        },
        "bleu": 12.01113,
        "nubia": {
            "semantic_relation": 3.00598,
            "contradiction": 25.90151,
            "irrelevancy": 44.10889,
            "logical_agreement": 29.9896,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.90604,
            "nubia_score": 0.3161
        },
        "bleurt": -0.20864,
        "meteor": 0.19671550345655384,
        "bertscore": {
            "precision": 0.87293,
            "recall": 0.83985,
            "f1": 0.85561
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 29,
        "msttr-100": 0.67667,
        "msttr-100_nopunct": 0.79,
        "total_length": 340,
        "mean_pred_length": 11.724137931034482,
        "std_pred_length": 2.347361713809312,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.48823529411764705,
        "vocab_size-1": 166,
        "unique-1": 111,
        "entropy-1": 6.580924092670571,
        "distinct-2": 0.7363344051446945,
        "vocab_size-2": 229,
        "unique-2": 176,
        "entropy-2": 7.649061817060265,
        "cond_entropy-2": 1.185609381509337,
        "distinct-3": 0.8368794326241135,
        "vocab_size-3": 236,
        "unique-3": 198,
        "entropy-3": 7.7866798098302805,
        "cond_entropy-3": 0.18839657305028687,
        "total_length-nopunct": 288,
        "mean_pred_length-nopunct": 9.931034482758621,
        "std_pred_length-nopunct": 1.92856985573925,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.5659722222222222,
        "vocab_size-1-nopunct": 163,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 6.858181761946916,
        "distinct-2-nopunct": 0.752895752895753,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 152,
        "entropy-2-nopunct": 7.4355521585591795,
        "cond_entropy-2-nopunct": 0.6721530253730347,
        "distinct-3-nopunct": 0.8608695652173913,
        "vocab_size-3-nopunct": 198,
        "unique-3-nopunct": 172,
        "entropy-3-nopunct": 7.543273637882079,
        "cond_entropy-3-nopunct": 0.15927116516937487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.07167832167832168,
            "2": 0.17176470588235293,
            "3": 0.2932551319648094
        },
        "nist": 0.003735894997407137,
        "rouge1": {
            "precision": 0.34483,
            "recall": 0.1681,
            "fmeasure": 0.21133
        },
        "rouge2": {
            "precision": 0.24138,
            "recall": 0.11281,
            "fmeasure": 0.13822
        },
        "rougeL": {
            "precision": 0.34483,
            "recall": 0.1681,
            "fmeasure": 0.21133
        },
        "rougeLsum": {
            "precision": 0.34483,
            "recall": 0.1681,
            "fmeasure": 0.21133
        },
        "bleu": 3.98411,
        "nubia": {
            "semantic_relation": 3.00473,
            "contradiction": 25.92161,
            "irrelevancy": 23.29759,
            "logical_agreement": 50.78081,
            "grammar_ref": 2.50557,
            "grammar_hyp": 2.70799,
            "nubia_score": 0.6613
        },
        "bleurt": -0.01782,
        "meteor": 0.2399446069731511,
        "bertscore": {
            "precision": 0.93448,
            "recall": 0.84935,
            "f1": 0.88948
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 253,
        "msttr-100": 0.74762,
        "msttr-100_nopunct": 0.87118,
        "total_length": 2130,
        "mean_pred_length": 8.41897233201581,
        "std_pred_length": 2.2768719725693045,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 15,
        "distinct-1": 0.42065727699530514,
        "vocab_size-1": 896,
        "unique-1": 604,
        "entropy-1": 8.367727971146723,
        "distinct-2": 0.7650506126798082,
        "vocab_size-2": 1436,
        "unique-2": 1176,
        "entropy-2": 10.264736487622732,
        "cond_entropy-2": 1.3141161572709459,
        "distinct-3": 0.8928571428571429,
        "vocab_size-3": 1450,
        "unique-3": 1310,
        "entropy-3": 10.429617163497868,
        "cond_entropy-3": 0.1563803452060148,
        "total_length-nopunct": 1723,
        "mean_pred_length-nopunct": 6.810276679841897,
        "std_pred_length-nopunct": 2.045812536696843,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.5171213000580384,
        "vocab_size-1-nopunct": 891,
        "unique-1-nopunct": 604,
        "entropy-1-nopunct": 9.035248052854307,
        "distinct-2-nopunct": 0.7904761904761904,
        "vocab_size-2-nopunct": 1162,
        "unique-2-nopunct": 977,
        "entropy-2-nopunct": 9.979083001144362,
        "cond_entropy-2-nopunct": 1.0729808755564245,
        "distinct-3-nopunct": 0.9013968775677896,
        "vocab_size-3-nopunct": 1097,
        "unique-3-nopunct": 1005,
        "entropy-3-nopunct": 10.028536026246147,
        "cond_entropy-3-nopunct": 0.11384811304579699,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.38839590443686006,
            "2": 0.704323570432357,
            "3": 0.7849829351535836,
            "4": 0.7714285714285715,
            "5": 0.36363636363636365,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 8.437395777726598,
        "rouge1": {
            "precision": 0.28518,
            "recall": 0.28844,
            "fmeasure": 0.28491
        },
        "rouge2": {
            "precision": 0.16999,
            "recall": 0.16798,
            "fmeasure": 0.16763
        },
        "rougeL": {
            "precision": 0.28353,
            "recall": 0.28696,
            "fmeasure": 0.28336
        },
        "rougeLsum": {
            "precision": 0.28353,
            "recall": 0.28696,
            "fmeasure": 0.28336
        },
        "bleu": 58.8357,
        "nubia": {
            "semantic_relation": 4.18279,
            "contradiction": 19.54245,
            "irrelevancy": 20.10463,
            "logical_agreement": 60.35293,
            "grammar_ref": 2.90527,
            "grammar_hyp": 2.92163,
            "nubia_score": 0.84076
        },
        "bleurt": 0.40509,
        "meteor": 0.7369228448697515,
        "bertscore": {
            "precision": 0.97074,
            "recall": 0.96606,
            "f1": 0.96795
        }
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 3.5439015885836427,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "bleu": 44.63236,
        "nubia": {
            "semantic_relation": 4.33153,
            "contradiction": 29.79225,
            "irrelevancy": 17.94546,
            "logical_agreement": 52.26229,
            "grammar_ref": 2.53664,
            "grammar_hyp": 2.58855,
            "nubia_score": 0.84247
        },
        "bleurt": 0.40776,
        "meteor": 0.7312768843948173,
        "bertscore": {
            "precision": 0.98204,
            "recall": 0.97628,
            "f1": 0.97915
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc_parent": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73983,
        "msttr-100_nopunct": 0.77415,
        "total_length": 5941,
        "mean_pred_length": 16.54874651810585,
        "std_pred_length": 6.029384160853018,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.38023901700050494,
        "vocab_size-1": 2259,
        "unique-1": 1690,
        "entropy-1": 9.076608864809497,
        "distinct-2": 0.8453959154424937,
        "vocab_size-2": 4719,
        "unique-2": 4395,
        "entropy-2": 11.91588152640679,
        "cond_entropy-2": 2.6249027906690263,
        "distinct-3": 0.9689833429063757,
        "vocab_size-3": 5061,
        "unique-3": 4986,
        "entropy-3": 12.247669214831733,
        "cond_entropy-3": 0.3551319058023003,
        "total_length-nopunct": 5344,
        "mean_pred_length-nopunct": 14.885793871866296,
        "std_pred_length-nopunct": 5.624339651427024,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.42047155688622756,
        "vocab_size-1-nopunct": 2247,
        "unique-1-nopunct": 1687,
        "entropy-1-nopunct": 9.34693880826332,
        "distinct-2-nopunct": 0.8647943831494483,
        "vocab_size-2-nopunct": 4311,
        "unique-2-nopunct": 4032,
        "entropy-2-nopunct": 11.838746836403581,
        "cond_entropy-2-nopunct": 2.64631598324386,
        "distinct-3-nopunct": 0.9827064418504107,
        "vocab_size-3-nopunct": 4546,
        "unique-3-nopunct": 4484,
        "entropy-3-nopunct": 12.136984131701494,
        "cond_entropy-3-nopunct": 0.32221182220254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04095925297113752,
            "2": 0.14559386973180077,
            "3": 0.31072210065645517,
            "4": 0.4215530903328051,
            "5": 0.4953271028037383,
            "6": 0.6304347826086957,
            "7": 0.7697594501718213
        },
        "nist": 8.317675435042805,
        "rouge1": {
            "precision": 0.82557,
            "recall": 0.70191,
            "fmeasure": 0.74213
        },
        "rouge2": {
            "precision": 0.66664,
            "recall": 0.56249,
            "fmeasure": 0.59525
        },
        "rougeL": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "rougeLsum": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "bleu": 59.09788,
        "nubia": {
            "semantic_relation": 4.00419,
            "contradiction": 5.58916,
            "irrelevancy": 17.8311,
            "logical_agreement": 76.57974,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.09497,
            "nubia_score": 0.61215
        },
        "bleurt": 0.04706,
        "meteor": 0.389663287826127,
        "bertscore": {
            "precision": 0.94429,
            "recall": 0.91719,
            "f1": 0.92716
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.6666666666666666
        },
        "nist": 1.4807818128667825,
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.51429,
            "fmeasure": 0.55668
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.20648,
            "fmeasure": 0.22452
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.51429,
            "fmeasure": 0.55668
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.51429,
            "fmeasure": 0.55668
        },
        "bleu": 20.24206,
        "nubia": {
            "semantic_relation": 4.26939,
            "contradiction": 0.07286,
            "irrelevancy": 0.54756,
            "logical_agreement": 99.37958,
            "grammar_ref": 4.03834,
            "grammar_hyp": 3.74698,
            "nubia_score": 0.81465
        },
        "bleurt": 0.36585,
        "meteor": 0.27997032211313777,
        "bertscore": {
            "precision": 0.94449,
            "recall": 0.94408,
            "f1": 0.94429
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.7037037037037037,
        "vocab_size-1": 38,
        "unique-1": 31,
        "entropy-1": 4.893233335256418,
        "distinct-2": 1.0,
        "vocab_size-2": 52,
        "unique-2": 52,
        "entropy-2": 5.700439718141095,
        "cond_entropy-2": 0.8403469277657161,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.05658352836636756,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 22.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 22.5,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8222222222222222,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.091853096329676,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.3530163095352142,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.06871275008401433,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.19047619047619047,
            "3": 0.47368421052631576
        },
        "nist": 2.1671096105705843,
        "rouge1": {
            "precision": 0.34127,
            "recall": 0.31981,
            "fmeasure": 0.32688
        },
        "rouge2": {
            "precision": 0.04674,
            "recall": 0.04749,
            "fmeasure": 0.04701
        },
        "rougeL": {
            "precision": 0.1994,
            "recall": 0.20081,
            "fmeasure": 0.19967
        },
        "rougeLsum": {
            "precision": 0.1994,
            "recall": 0.20081,
            "fmeasure": 0.19967
        },
        "bleu": 7.64328,
        "nubia": {
            "semantic_relation": 1.99356,
            "contradiction": 48.55162,
            "irrelevancy": 38.16337,
            "logical_agreement": 13.28501,
            "grammar_ref": 4.17,
            "grammar_hyp": 3.82538,
            "nubia_score": 0.19431
        },
        "bleurt": -0.43702,
        "meteor": 0.16689801503269244,
        "bertscore": {
            "precision": 0.83511,
            "recall": 0.83091,
            "f1": 0.82975
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 95,
        "mean_pred_length": 23.75,
        "std_pred_length": 6.179603547154137,
        "median_pred_length": 25.0,
        "min_pred_length": 14,
        "max_pred_length": 31,
        "distinct-1": 0.7157894736842105,
        "vocab_size-1": 68,
        "unique-1": 56,
        "entropy-1": 5.802794919875401,
        "distinct-2": 0.9120879120879121,
        "vocab_size-2": 83,
        "unique-2": 77,
        "entropy-2": 6.3099924423965,
        "cond_entropy-2": 0.5189364538817799,
        "distinct-3": 0.9655172413793104,
        "vocab_size-3": 84,
        "unique-3": 81,
        "entropy-3": 6.373977978607345,
        "cond_entropy-3": 0.07307989013279068,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 19.25,
        "std_pred_length-nopunct": 4.14578098794425,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.809393281618623,
        "distinct-2-nopunct": 0.9315068493150684,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 6.05283825751016,
        "cond_entropy-2-nopunct": 0.25480899008749464,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.021567935039033,
        "cond_entropy-3-nopunct": -0.037821841232283056,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.5263157894736842
        },
        "nist": 2.1860004547043053,
        "rouge1": {
            "precision": 0.65335,
            "recall": 0.50371,
            "fmeasure": 0.56346
        },
        "rouge2": {
            "precision": 0.46428,
            "recall": 0.35393,
            "fmeasure": 0.39731
        },
        "rougeL": {
            "precision": 0.5534,
            "recall": 0.42622,
            "fmeasure": 0.47668
        },
        "rougeLsum": {
            "precision": 0.5534,
            "recall": 0.42622,
            "fmeasure": 0.47668
        },
        "bleu": 33.76029,
        "nubia": {
            "semantic_relation": 3.45196,
            "contradiction": 16.50119,
            "irrelevancy": 4.44376,
            "logical_agreement": 79.05505,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.93616,
            "nubia_score": 0.45089
        },
        "bleurt": -0.32288,
        "meteor": 0.2727434408728582,
        "bertscore": {
            "precision": 0.90184,
            "recall": 0.86958,
            "f1": 0.88531
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.031262576450960075,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.8888888888888888
        },
        "nist": 2.574965103363526,
        "rouge1": {
            "precision": 0.55,
            "recall": 0.6875,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.26316,
            "recall": 0.33333,
            "fmeasure": 0.29412
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.5625,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.5625,
            "fmeasure": 0.5
        },
        "bleu": 11.66445,
        "nubia": {
            "semantic_relation": 3.98569,
            "contradiction": 0.22042,
            "irrelevancy": 78.61366,
            "logical_agreement": 21.16592,
            "grammar_ref": 3.92881,
            "grammar_hyp": 3.81069,
            "nubia_score": 0.73152
        },
        "bleurt": -0.02256,
        "meteor": 0.29917738643981495,
        "bertscore": {
            "precision": 0.86079,
            "recall": 0.91083,
            "f1": 0.8851
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.0,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.05118944924673078,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.05628729973432273,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.3333333333333333,
            "3": 0.7777777777777778
        },
        "nist": 3.370344639312103,
        "rouge1": {
            "precision": 0.64881,
            "recall": 0.72546,
            "fmeasure": 0.68414
        },
        "rouge2": {
            "precision": 0.39277,
            "recall": 0.39583,
            "fmeasure": 0.39092
        },
        "rougeL": {
            "precision": 0.47421,
            "recall": 0.49751,
            "fmeasure": 0.48219
        },
        "rougeLsum": {
            "precision": 0.47421,
            "recall": 0.49751,
            "fmeasure": 0.48219
        },
        "bleu": 28.54939,
        "nubia": {
            "semantic_relation": 4.47877,
            "contradiction": 0.49096,
            "irrelevancy": 56.40077,
            "logical_agreement": 43.10827,
            "grammar_ref": 5.41182,
            "grammar_hyp": 5.40757,
            "nubia_score": 0.75411
        },
        "bleurt": 0.36543,
        "meteor": 0.3683824322073614,
        "bertscore": {
            "precision": 0.91227,
            "recall": 0.92126,
            "f1": 0.91465
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 382,
        "msttr-100": 0.50821,
        "msttr-100_nopunct": 0.50632,
        "total_length": 8427,
        "mean_pred_length": 22.06020942408377,
        "std_pred_length": 3.7506073446208354,
        "median_pred_length": 22.5,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.12839681974605435,
        "vocab_size-1": 1082,
        "unique-1": 372,
        "entropy-1": 7.982086479542039,
        "distinct-2": 0.36594157862026105,
        "vocab_size-2": 2944,
        "unique-2": 1627,
        "entropy-2": 10.682129031937533,
        "cond_entropy-2": 2.679159133385047,
        "distinct-3": 0.5590499804254209,
        "vocab_size-3": 4284,
        "unique-3": 2965,
        "entropy-3": 11.588949120324376,
        "cond_entropy-3": 0.9736900703431893,
        "total_length-nopunct": 7641,
        "mean_pred_length-nopunct": 20.00261780104712,
        "std_pred_length-nopunct": 3.73430305748317,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.1406883915717838,
        "vocab_size-1-nopunct": 1075,
        "unique-1-nopunct": 372,
        "entropy-1-nopunct": 8.14376192614502,
        "distinct-2-nopunct": 0.37374293979887035,
        "vocab_size-2-nopunct": 2713,
        "unique-2-nopunct": 1549,
        "entropy-2-nopunct": 10.56360213449229,
        "cond_entropy-2-nopunct": 2.557678449894876,
        "distinct-3-nopunct": 0.5615820852115748,
        "vocab_size-3-nopunct": 3862,
        "unique-3-nopunct": 2711,
        "entropy-3-nopunct": 11.42748062771326,
        "cond_entropy-3-nopunct": 0.9279534615539139,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2081571748321313,
            "2": 0.4926215277777778,
            "3": 0.7704422869471413,
            "4": 0.8333333333333334,
            "5": 0.7619047619047619
        },
        "nist": 7.480513777548623,
        "rouge1": {
            "precision": 0.74279,
            "recall": 0.67192,
            "fmeasure": 0.69612
        },
        "rouge2": {
            "precision": 0.47709,
            "recall": 0.42585,
            "fmeasure": 0.44305
        },
        "rougeL": {
            "precision": 0.58704,
            "recall": 0.53108,
            "fmeasure": 0.54976
        },
        "rougeLsum": {
            "precision": 0.58704,
            "recall": 0.53108,
            "fmeasure": 0.54976
        },
        "bleu": 39.77155,
        "nubia": {
            "semantic_relation": 4.11058,
            "contradiction": 7.5464,
            "irrelevancy": 11.2354,
            "logical_agreement": 81.2182,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.64697,
            "nubia_score": 0.66663
        },
        "bleurt": -0.01362,
        "meteor": 0.3376697174135273,
        "bertscore": {
            "precision": 0.91036,
            "recall": 0.89397,
            "f1": 0.90043
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.0,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.8529411764705882,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.7711426205984715,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.248627393192269,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8484848484848485,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.718488437474714,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.2567340459369209,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.5
        },
        "nist": 2.1633216103882944,
        "rouge1": {
            "precision": 0.43889,
            "recall": 0.38333,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.11466,
            "recall": 0.11786,
            "fmeasure": 0.10874
        },
        "rougeL": {
            "precision": 0.30833,
            "recall": 0.32778,
            "fmeasure": 0.3116
        },
        "rougeLsum": {
            "precision": 0.30833,
            "recall": 0.32778,
            "fmeasure": 0.3116
        },
        "bleu": 6.8386,
        "nubia": {
            "semantic_relation": 3.23293,
            "contradiction": 0.30872,
            "irrelevancy": 99.50212,
            "logical_agreement": 0.18916,
            "grammar_ref": 5.71002,
            "grammar_hyp": 5.57569,
            "nubia_score": 0.36484
        },
        "bleurt": -0.33462,
        "meteor": 0.19379464590363016,
        "bertscore": {
            "precision": 0.83695,
            "recall": 0.86499,
            "f1": 0.84048
        }
    },
    "wiki_auto_asset_turk_test_turk": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_turk",
        "N": 359,
        "msttr-100": 0.73983,
        "msttr-100_nopunct": 0.77415,
        "total_length": 5941,
        "mean_pred_length": 16.54874651810585,
        "std_pred_length": 6.029384160853018,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.38023901700050494,
        "vocab_size-1": 2259,
        "unique-1": 1690,
        "entropy-1": 9.076608864809497,
        "distinct-2": 0.8453959154424937,
        "vocab_size-2": 4719,
        "unique-2": 4395,
        "entropy-2": 11.91588152640679,
        "cond_entropy-2": 2.6249027906690263,
        "distinct-3": 0.9689833429063757,
        "vocab_size-3": 5061,
        "unique-3": 4986,
        "entropy-3": 12.247669214831733,
        "cond_entropy-3": 0.3551319058023003,
        "total_length-nopunct": 5344,
        "mean_pred_length-nopunct": 14.885793871866296,
        "std_pred_length-nopunct": 5.624339651427024,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.42047155688622756,
        "vocab_size-1-nopunct": 2247,
        "unique-1-nopunct": 1687,
        "entropy-1-nopunct": 9.34693880826332,
        "distinct-2-nopunct": 0.8647943831494483,
        "vocab_size-2-nopunct": 4311,
        "unique-2-nopunct": 4032,
        "entropy-2-nopunct": 11.838746836403581,
        "cond_entropy-2-nopunct": 2.64631598324386,
        "distinct-3-nopunct": 0.9827064418504107,
        "vocab_size-3-nopunct": 4546,
        "unique-3-nopunct": 4484,
        "entropy-3-nopunct": 12.136984131701494,
        "cond_entropy-3-nopunct": 0.32221182220254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_turk.json",
        "local_recall": {
            "1": 0.04095925297113752,
            "2": 0.14559386973180077,
            "3": 0.31072210065645517,
            "4": 0.4215530903328051,
            "5": 0.4953271028037383,
            "6": 0.6304347826086957,
            "7": 0.7697594501718213
        },
        "nist": 8.317675435042805,
        "rouge1": {
            "precision": 0.82557,
            "recall": 0.70191,
            "fmeasure": 0.74213
        },
        "rouge2": {
            "precision": 0.66664,
            "recall": 0.56249,
            "fmeasure": 0.59525
        },
        "rougeL": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "rougeLsum": {
            "precision": 0.79314,
            "recall": 0.67409,
            "fmeasure": 0.71231
        },
        "bleu": 59.09788,
        "sari": 42.14859,
        "nubia": {
            "semantic_relation": 4.00419,
            "contradiction": 5.58916,
            "irrelevancy": 17.8311,
            "logical_agreement": 76.57974,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.09497,
            "nubia_score": 0.61215
        },
        "bleurt": 0.04706,
        "meteor": 0.389663287826127,
        "bertscore": {
            "precision": 0.94429,
            "recall": 0.91719,
            "f1": 0.92716
        }
    },
    "wiki_auto_asset_turk_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_train_sample",
        "N": 500
    },
    "wiki_auto_asset_turk_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_validation_sample",
        "N": 500
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75385,
        "total_length": 1551,
        "mean_pred_length": 14.771428571428572,
        "std_pred_length": 6.108942926028151,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.41715022566086396,
        "vocab_size-1": 647,
        "unique-1": 495,
        "entropy-1": 7.917449567321653,
        "distinct-2": 0.8084370677731674,
        "vocab_size-2": 1169,
        "unique-2": 1045,
        "entropy-2": 9.953989421851086,
        "cond_entropy-2": 1.767579018617603,
        "distinct-3": 0.918717375093214,
        "vocab_size-3": 1232,
        "unique-3": 1167,
        "entropy-3": 10.190100904478845,
        "cond_entropy-3": 0.24461730184556318,
        "total_length-nopunct": 1335,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 5.245795206347535,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4794007490636704,
        "vocab_size-1-nopunct": 640,
        "unique-1-nopunct": 495,
        "entropy-1-nopunct": 8.182615948807054,
        "distinct-2-nopunct": 0.8300813008130081,
        "vocab_size-2-nopunct": 1021,
        "unique-2-nopunct": 921,
        "entropy-2-nopunct": 9.789733431225454,
        "cond_entropy-2-nopunct": 1.7177762582051492,
        "distinct-3-nopunct": 0.9324444444444444,
        "vocab_size-3-nopunct": 1049,
        "unique-3-nopunct": 1001,
        "entropy-3-nopunct": 9.974989286148341,
        "cond_entropy-3-nopunct": 0.1992075257846632,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25722543352601157,
            "2": 0.39009287925696595,
            "3": 0.710752688172043
        },
        "nist": 6.688004384376426,
        "rouge1": {
            "precision": 0.65501,
            "recall": 0.63327,
            "fmeasure": 0.62873
        },
        "rouge2": {
            "precision": 0.40526,
            "recall": 0.40767,
            "fmeasure": 0.3962
        },
        "rougeL": {
            "precision": 0.54523,
            "recall": 0.53292,
            "fmeasure": 0.52596
        },
        "rougeLsum": {
            "precision": 0.54523,
            "recall": 0.53292,
            "fmeasure": 0.52596
        },
        "bleu": 36.38581,
        "nubia": {
            "semantic_relation": 3.53311,
            "contradiction": 22.5361,
            "irrelevancy": 31.00974,
            "logical_agreement": 46.45416,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.8792,
            "nubia_score": 0.59155
        },
        "bleurt": 0.10806,
        "meteor": 0.34766003596905065,
        "bertscore": {
            "precision": 0.89746,
            "recall": 0.89305,
            "f1": 0.89366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.646,
        "msttr-100_nopunct": 0.678,
        "total_length": 590,
        "mean_pred_length": 14.75,
        "std_pred_length": 5.611372381155968,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.4491525423728814,
        "vocab_size-1": 265,
        "unique-1": 218,
        "entropy-1": 6.844598705171556,
        "distinct-2": 0.7945454545454546,
        "vocab_size-2": 437,
        "unique-2": 396,
        "entropy-2": 8.495051389501574,
        "cond_entropy-2": 1.4669329762103505,
        "distinct-3": 0.8725490196078431,
        "vocab_size-3": 445,
        "unique-3": 417,
        "entropy-3": 8.643181377950386,
        "cond_entropy-3": 0.18651149679051363,
        "total_length-nopunct": 509,
        "mean_pred_length-nopunct": 12.725,
        "std_pred_length-nopunct": 4.974874370273083,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5088408644400786,
        "vocab_size-1-nopunct": 259,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 7.005174915917374,
        "distinct-2-nopunct": 0.7910447761194029,
        "vocab_size-2-nopunct": 371,
        "unique-2-nopunct": 335,
        "entropy-2-nopunct": 8.24839943785559,
        "cond_entropy-2-nopunct": 1.3574306614272396,
        "distinct-3-nopunct": 0.8764568764568764,
        "vocab_size-3-nopunct": 376,
        "unique-3-nopunct": 353,
        "entropy-3-nopunct": 8.40142285257545,
        "cond_entropy-3-nopunct": 0.18623297062714894,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18803418803418803,
            "2": 0.4307692307692308,
            "3": 0.7399527186761229
        },
        "nist": 6.4881963262935685,
        "rouge1": {
            "precision": 0.77678,
            "recall": 0.71923,
            "fmeasure": 0.73007
        },
        "rouge2": {
            "precision": 0.56369,
            "recall": 0.52929,
            "fmeasure": 0.53287
        },
        "rougeL": {
            "precision": 0.71187,
            "recall": 0.66406,
            "fmeasure": 0.66971
        },
        "rougeLsum": {
            "precision": 0.71187,
            "recall": 0.66406,
            "fmeasure": 0.66971
        },
        "bleu": 48.48387,
        "nubia": {
            "semantic_relation": 4.08921,
            "contradiction": 8.38893,
            "irrelevancy": 30.25591,
            "logical_agreement": 61.35516,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.49577,
            "nubia_score": 0.69944
        },
        "bleurt": 0.31749,
        "meteor": 0.37980720200868173,
        "bertscore": {
            "precision": 0.93383,
            "recall": 0.92211,
            "f1": 0.92579
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 494,
        "msttr-100": 0.77333,
        "msttr-100_nopunct": 0.84314,
        "total_length": 6045,
        "mean_pred_length": 12.236842105263158,
        "std_pred_length": 2.610043461286822,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.27030603804797354,
        "vocab_size-1": 1634,
        "unique-1": 940,
        "entropy-1": 8.808501172861964,
        "distinct-2": 0.5768330030625113,
        "vocab_size-2": 3202,
        "unique-2": 2324,
        "entropy-2": 11.121117387274552,
        "cond_entropy-2": 2.456835739807282,
        "distinct-3": 0.7654736009491794,
        "vocab_size-3": 3871,
        "unique-3": 3188,
        "entropy-3": 11.7219747884435,
        "cond_entropy-3": 0.6955438375963993,
        "total_length-nopunct": 5129,
        "mean_pred_length-nopunct": 10.382591093117409,
        "std_pred_length-nopunct": 2.101999377593259,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3170208617664262,
        "vocab_size-1-nopunct": 1626,
        "unique-1-nopunct": 939,
        "entropy-1-nopunct": 9.315485186694277,
        "distinct-2-nopunct": 0.6325782092772384,
        "vocab_size-2-nopunct": 2932,
        "unique-2-nopunct": 2233,
        "entropy-2-nopunct": 11.08764668055579,
        "cond_entropy-2-nopunct": 1.9686632264123207,
        "distinct-3-nopunct": 0.8007727602028496,
        "vocab_size-3-nopunct": 3316,
        "unique-3-nopunct": 2834,
        "entropy-3-nopunct": 11.51867275390106,
        "cond_entropy-3-nopunct": 0.5264917548377647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1488359201773836,
            "2": 0.3281615925058548,
            "3": 0.500184706316956,
            "4": 0.8,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 1.5705605535904439,
        "rouge1": {
            "precision": 0.24936,
            "recall": 0.19071,
            "fmeasure": 0.20753
        },
        "rouge2": {
            "precision": 0.10163,
            "recall": 0.07078,
            "fmeasure": 0.07943
        },
        "rougeL": {
            "precision": 0.24194,
            "recall": 0.18479,
            "fmeasure": 0.20096
        },
        "rougeLsum": {
            "precision": 0.24194,
            "recall": 0.18479,
            "fmeasure": 0.20096
        },
        "bleu": 20.30292,
        "nubia": {
            "semantic_relation": 3.45126,
            "contradiction": 21.84229,
            "irrelevancy": 23.11758,
            "logical_agreement": 55.04013,
            "grammar_ref": 2.60025,
            "grammar_hyp": 2.67374,
            "nubia_score": 0.66463
        },
        "bleurt": 0.01187,
        "meteor": 0.37470042878413923,
        "bertscore": {
            "precision": 0.94499,
            "recall": 0.90357,
            "f1": 0.92291
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 297,
        "msttr-100": 0.6,
        "msttr-100_nopunct": 0.637,
        "total_length": 3478,
        "mean_pred_length": 11.710437710437711,
        "std_pred_length": 3.45782557698729,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 19,
        "distinct-1": 0.1144335825186889,
        "vocab_size-1": 398,
        "unique-1": 171,
        "entropy-1": 6.842902278975689,
        "distinct-2": 0.30336372209996854,
        "vocab_size-2": 965,
        "unique-2": 540,
        "entropy-2": 8.733043477119184,
        "cond_entropy-2": 1.6041000165392068,
        "distinct-3": 0.4549237170596394,
        "vocab_size-3": 1312,
        "unique-3": 896,
        "entropy-3": 9.3435932586247,
        "cond_entropy-3": 0.615713093159518,
        "total_length-nopunct": 3032,
        "mean_pred_length-nopunct": 10.20875420875421,
        "std_pred_length-nopunct": 3.187231068238951,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.13027704485488126,
        "vocab_size-1-nopunct": 395,
        "unique-1-nopunct": 171,
        "entropy-1-nopunct": 7.058021247787697,
        "distinct-2-nopunct": 0.31078610603290674,
        "vocab_size-2-nopunct": 850,
        "unique-2-nopunct": 470,
        "entropy-2-nopunct": 8.60530964198288,
        "cond_entropy-2-nopunct": 1.6455394502974712,
        "distinct-3-nopunct": 0.46554552912223135,
        "vocab_size-3-nopunct": 1135,
        "unique-3-nopunct": 779,
        "entropy-3-nopunct": 9.157294744490896,
        "cond_entropy-3-nopunct": 0.6484679499011212,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.46717446499818643
        },
        "nist": 3.6405014376650118,
        "rouge1": {
            "precision": 0.50929,
            "recall": 0.51325,
            "fmeasure": 0.49683
        },
        "rouge2": {
            "precision": 0.28431,
            "recall": 0.29003,
            "fmeasure": 0.27934
        },
        "rougeL": {
            "precision": 0.45411,
            "recall": 0.45927,
            "fmeasure": 0.44439
        },
        "rougeLsum": {
            "precision": 0.45411,
            "recall": 0.45927,
            "fmeasure": 0.44439
        },
        "bleu": 17.75214,
        "nubia": {
            "semantic_relation": 3.4704,
            "contradiction": 18.19884,
            "irrelevancy": 38.38179,
            "logical_agreement": 43.41937,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.61569,
            "nubia_score": 0.51534
        },
        "bleurt": -0.1781,
        "meteor": 0.23538456281945172,
        "bertscore": {
            "precision": 0.89556,
            "recall": 0.89281,
            "f1": 0.89396
        }
    },
    "cs_restaurants_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 500,
        "msttr-100": 0.59821,
        "msttr-100_nopunct": 0.64766,
        "total_length": 5665,
        "mean_pred_length": 11.33,
        "std_pred_length": 3.6492601989992437,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.0969108561341571,
        "vocab_size-1": 549,
        "unique-1": 220,
        "entropy-1": 6.95738363451989,
        "distinct-2": 0.2787996127783156,
        "vocab_size-2": 1440,
        "unique-2": 810,
        "entropy-2": 8.963866828600356,
        "cond_entropy-2": 1.8132167801046797,
        "distinct-3": 0.427438370846731,
        "vocab_size-3": 1994,
        "unique-3": 1425,
        "entropy-3": 9.569440366819132,
        "cond_entropy-3": 0.6709945458941201,
        "total_length-nopunct": 4738,
        "mean_pred_length-nopunct": 9.476,
        "std_pred_length-nopunct": 3.376599472842463,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.11502743773744196,
        "vocab_size-1-nopunct": 545,
        "unique-1-nopunct": 220,
        "entropy-1-nopunct": 7.249399784688476,
        "distinct-2-nopunct": 0.2940066068900425,
        "vocab_size-2-nopunct": 1246,
        "unique-2-nopunct": 703,
        "entropy-2-nopunct": 8.85625537085517,
        "cond_entropy-2-nopunct": 1.7780720923753652,
        "distinct-3-nopunct": 0.46013911182450506,
        "vocab_size-3-nopunct": 1720,
        "unique-3-nopunct": 1251,
        "entropy-3-nopunct": 9.509176664359241,
        "cond_entropy-3-nopunct": 0.7518371295901208,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4612159329140461
        },
        "nist": 3.7200235788236005,
        "rouge1": {
            "precision": 0.48462,
            "recall": 0.52323,
            "fmeasure": 0.48594
        },
        "rouge2": {
            "precision": 0.27055,
            "recall": 0.28721,
            "fmeasure": 0.26934
        },
        "rougeL": {
            "precision": 0.43636,
            "recall": 0.47262,
            "fmeasure": 0.4385
        },
        "rougeLsum": {
            "precision": 0.43636,
            "recall": 0.47262,
            "fmeasure": 0.4385
        },
        "bleu": 16.30587,
        "nubia": {
            "semantic_relation": 3.29654,
            "contradiction": 23.8051,
            "irrelevancy": 33.8264,
            "logical_agreement": 42.36849,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.70634,
            "nubia_score": 0.48206
        },
        "bleurt": -0.27399,
        "meteor": 0.23214700603438382,
        "bertscore": {
            "precision": 0.88531,
            "recall": 0.89626,
            "f1": 0.89031
        }
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 354,
        "msttr-100": 0.75452,
        "msttr-100_nopunct": 0.8225,
        "total_length": 4275,
        "mean_pred_length": 12.076271186440678,
        "std_pred_length": 2.2530209963677064,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.2895906432748538,
        "vocab_size-1": 1238,
        "unique-1": 740,
        "entropy-1": 8.523466673789065,
        "distinct-2": 0.5643968375414435,
        "vocab_size-2": 2213,
        "unique-2": 1585,
        "entropy-2": 10.554576860420466,
        "cond_entropy-2": 2.178581832173846,
        "distinct-3": 0.7151668068404822,
        "vocab_size-3": 2551,
        "unique-3": 2034,
        "entropy-3": 11.039386802956654,
        "cond_entropy-3": 0.5812802275285435,
        "total_length-nopunct": 3655,
        "mean_pred_length-nopunct": 10.324858757062147,
        "std_pred_length-nopunct": 1.9380528137447626,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.33707250341997264,
        "vocab_size-1-nopunct": 1232,
        "unique-1-nopunct": 739,
        "entropy-1-nopunct": 8.971025428347117,
        "distinct-2-nopunct": 0.6049681914571342,
        "vocab_size-2-nopunct": 1997,
        "unique-2-nopunct": 1491,
        "entropy-2-nopunct": 10.469098958646837,
        "cond_entropy-2-nopunct": 1.6717016425514077,
        "distinct-3-nopunct": 0.7407533084492705,
        "vocab_size-3-nopunct": 2183,
        "unique-3-nopunct": 1805,
        "entropy-3-nopunct": 10.819598070073098,
        "cond_entropy-3-nopunct": 0.4599167272476068,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1284989667480744,
            "2": 0.30255591054313097,
            "3": 0.42729970326409494,
            "4": 0.5135135135135135,
            "5": 0.7272727272727273,
            "6": 0.0,
            "7": 1.0
        },
        "nist": 0.4922957541141473,
        "rouge1": {
            "precision": 0.30439,
            "recall": 0.22973,
            "fmeasure": 0.25027
        },
        "rouge2": {
            "precision": 0.13136,
            "recall": 0.09199,
            "fmeasure": 0.10008
        },
        "rougeL": {
            "precision": 0.29881,
            "recall": 0.2246,
            "fmeasure": 0.24498
        },
        "rougeLsum": {
            "precision": 0.29881,
            "recall": 0.2246,
            "fmeasure": 0.24498
        },
        "bleu": 15.35732,
        "nubia": {
            "semantic_relation": 3.38365,
            "contradiction": 22.56367,
            "irrelevancy": 22.94494,
            "logical_agreement": 54.49139,
            "grammar_ref": 2.54394,
            "grammar_hyp": 2.67789,
            "nubia_score": 0.64327
        },
        "bleurt": 0.00991,
        "meteor": 0.33584666411647357,
        "bertscore": {
            "precision": 0.94503,
            "recall": 0.88976,
            "f1": 0.91579
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 86,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.65833,
        "total_length": 1377,
        "mean_pred_length": 16.011627906976745,
        "std_pred_length": 3.715129926822841,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.20406681190994916,
        "vocab_size-1": 281,
        "unique-1": 128,
        "entropy-1": 6.822180140827891,
        "distinct-2": 0.5151045701006971,
        "vocab_size-2": 665,
        "unique-2": 444,
        "entropy-2": 8.787862733761516,
        "cond_entropy-2": 1.812471152419023,
        "distinct-3": 0.7053941908713693,
        "vocab_size-3": 850,
        "unique-3": 694,
        "entropy-3": 9.371960355181235,
        "cond_entropy-3": 0.5628774341220495,
        "total_length-nopunct": 1216,
        "mean_pred_length-nopunct": 14.13953488372093,
        "std_pred_length-nopunct": 3.3451206767180133,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.22861842105263158,
        "vocab_size-1-nopunct": 278,
        "unique-1-nopunct": 128,
        "entropy-1-nopunct": 6.99453063873021,
        "distinct-2-nopunct": 0.5424778761061947,
        "vocab_size-2-nopunct": 613,
        "unique-2-nopunct": 417,
        "entropy-2-nopunct": 8.713016574963097,
        "cond_entropy-2-nopunct": 1.7683275298980936,
        "distinct-3-nopunct": 0.7442528735632183,
        "vocab_size-3-nopunct": 777,
        "unique-3-nopunct": 648,
        "entropy-3-nopunct": 9.301925909653528,
        "cond_entropy-3-nopunct": 0.5589424316358388,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4509505703422053
        },
        "nist": 3.7797642106703027,
        "rouge1": {
            "precision": 0.56102,
            "recall": 0.50967,
            "fmeasure": 0.52557
        },
        "rouge2": {
            "precision": 0.31015,
            "recall": 0.27989,
            "fmeasure": 0.28949
        },
        "rougeL": {
            "precision": 0.45533,
            "recall": 0.41132,
            "fmeasure": 0.42548
        },
        "rougeLsum": {
            "precision": 0.45533,
            "recall": 0.41132,
            "fmeasure": 0.42548
        },
        "bleu": 15.76585,
        "nubia": {
            "semantic_relation": 3.28407,
            "contradiction": 15.88853,
            "irrelevancy": 22.97224,
            "logical_agreement": 61.13923,
            "grammar_ref": 6.22337,
            "grammar_hyp": 6.26081,
            "nubia_score": 0.51584
        },
        "bleurt": -0.10016,
        "meteor": 0.22438897738518926,
        "bertscore": {
            "precision": 0.91562,
            "recall": 0.90735,
            "f1": 0.91135
        }
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 9,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.61,
        "total_length": 150,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 3.6514837167011076,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.52,
        "vocab_size-1": 78,
        "unique-1": 52,
        "entropy-1": 5.785834979289481,
        "distinct-2": 0.7801418439716312,
        "vocab_size-2": 110,
        "unique-2": 90,
        "entropy-2": 6.623559242454356,
        "cond_entropy-2": 0.749975705642323,
        "distinct-3": 0.8712121212121212,
        "vocab_size-3": 115,
        "unique-3": 103,
        "entropy-3": 6.750796486766295,
        "cond_entropy-3": 0.10181246392935657,
        "total_length-nopunct": 131,
        "mean_pred_length-nopunct": 14.555555555555555,
        "std_pred_length-nopunct": 3.402976184691901,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5801526717557252,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.85251498078093,
        "distinct-2-nopunct": 0.8032786885245902,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.471720944120277,
        "cond_entropy-2-nopunct": 0.6301933388086733,
        "distinct-3-nopunct": 0.8938053097345132,
        "vocab_size-3-nopunct": 101,
        "unique-3-nopunct": 92,
        "entropy-3-nopunct": 6.583410046466856,
        "cond_entropy-3-nopunct": 0.07745146996589933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.45925925925925926
        },
        "nist": 2.9573939407185756,
        "rouge1": {
            "precision": 0.56766,
            "recall": 0.50701,
            "fmeasure": 0.52485
        },
        "rouge2": {
            "precision": 0.28337,
            "recall": 0.27092,
            "fmeasure": 0.2726
        },
        "rougeL": {
            "precision": 0.43236,
            "recall": 0.39056,
            "fmeasure": 0.40256
        },
        "rougeLsum": {
            "precision": 0.43236,
            "recall": 0.39056,
            "fmeasure": 0.40256
        },
        "bleu": 16.63002,
        "nubia": {
            "semantic_relation": 3.31881,
            "contradiction": 17.87528,
            "irrelevancy": 21.88908,
            "logical_agreement": 60.23564,
            "grammar_ref": 6.01604,
            "grammar_hyp": 6.31406,
            "nubia_score": 0.49207
        },
        "bleurt": -0.07845,
        "meteor": 0.2348150622786438,
        "bertscore": {
            "precision": 0.91779,
            "recall": 0.90888,
            "f1": 0.91321
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 609,
        "msttr-100": 0.59985,
        "msttr-100_nopunct": 0.63458,
        "total_length": 6719,
        "mean_pred_length": 11.032840722495894,
        "std_pred_length": 3.914384064387463,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.09435927965471053,
        "vocab_size-1": 634,
        "unique-1": 232,
        "entropy-1": 7.026950816159151,
        "distinct-2": 0.2818330605564648,
        "vocab_size-2": 1722,
        "unique-2": 912,
        "entropy-2": 9.39556535723846,
        "cond_entropy-2": 2.109071268163129,
        "distinct-3": 0.4562806762406835,
        "vocab_size-3": 2510,
        "unique-3": 1742,
        "entropy-3": 10.27622641192216,
        "cond_entropy-3": 0.988601122896874,
        "total_length-nopunct": 5908,
        "mean_pred_length-nopunct": 9.701149425287356,
        "std_pred_length-nopunct": 3.563085966075729,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.10680433310765064,
        "vocab_size-1-nopunct": 631,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 7.2486850063782775,
        "distinct-2-nopunct": 0.28118512926967354,
        "vocab_size-2-nopunct": 1490,
        "unique-2-nopunct": 810,
        "entropy-2-nopunct": 9.171791350266602,
        "cond_entropy-2-nopunct": 2.2025087177528175,
        "distinct-3-nopunct": 0.4616204690831556,
        "vocab_size-3-nopunct": 2165,
        "unique-3-nopunct": 1531,
        "entropy-3-nopunct": 10.065098706997317,
        "cond_entropy-3-nopunct": 1.0839416661246772,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.5061246227587431
        },
        "nist": 4.34457819959623,
        "rouge1": {
            "precision": 0.55672,
            "recall": 0.55434,
            "fmeasure": 0.54274
        },
        "rouge2": {
            "precision": 0.31576,
            "recall": 0.31605,
            "fmeasure": 0.3084
        },
        "rougeL": {
            "precision": 0.49894,
            "recall": 0.49754,
            "fmeasure": 0.48718
        },
        "rougeLsum": {
            "precision": 0.49894,
            "recall": 0.49754,
            "fmeasure": 0.48718
        },
        "bleu": 19.46771,
        "nubia": {
            "semantic_relation": 3.56823,
            "contradiction": 16.5898,
            "irrelevancy": 33.9213,
            "logical_agreement": 49.4889,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.90176,
            "nubia_score": 0.54942
        },
        "bleurt": -0.09081,
        "meteor": 0.2532221380429701,
        "bertscore": {
            "precision": 0.90406,
            "recall": 0.90223,
            "f1": 0.90292
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 251,
        "msttr-100": 0.49407,
        "msttr-100_nopunct": 0.49167,
        "total_length": 5937,
        "mean_pred_length": 23.653386454183266,
        "std_pred_length": 3.3843114852417497,
        "median_pred_length": 24.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.15091797203975071,
        "vocab_size-1": 896,
        "unique-1": 331,
        "entropy-1": 7.849220434861389,
        "distinct-2": 0.38515652479774887,
        "vocab_size-2": 2190,
        "unique-2": 1244,
        "entropy-2": 10.292710742536057,
        "cond_entropy-2": 2.49593871447752,
        "distinct-3": 0.5545538178472861,
        "vocab_size-3": 3014,
        "unique-3": 2105,
        "entropy-3": 11.053904373561153,
        "cond_entropy-3": 0.8210625711384724,
        "total_length-nopunct": 5455,
        "mean_pred_length-nopunct": 21.733067729083665,
        "std_pred_length-nopunct": 3.299834317854951,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.1633363886342805,
        "vocab_size-1-nopunct": 891,
        "unique-1-nopunct": 331,
        "entropy-1-nopunct": 7.964166626467927,
        "distinct-2-nopunct": 0.39815526518063027,
        "vocab_size-2-nopunct": 2072,
        "unique-2-nopunct": 1211,
        "entropy-2-nopunct": 10.243503974215338,
        "cond_entropy-2-nopunct": 2.3832866626341405,
        "distinct-3-nopunct": 0.5626892792247123,
        "vocab_size-3-nopunct": 2787,
        "unique-3-nopunct": 1987,
        "entropy-3-nopunct": 10.939831083251663,
        "cond_entropy-3-nopunct": 0.7602224826136852,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.17937074278300358,
            "2": 0.45734597156398105,
            "3": 0.6864406779661016
        },
        "nist": 4.791805606730675,
        "rouge1": {
            "precision": 0.75001,
            "recall": 0.57848,
            "fmeasure": 0.63678
        },
        "rouge2": {
            "precision": 0.48252,
            "recall": 0.35972,
            "fmeasure": 0.40026
        },
        "rougeL": {
            "precision": 0.59588,
            "recall": 0.45571,
            "fmeasure": 0.50306
        },
        "rougeLsum": {
            "precision": 0.59588,
            "recall": 0.45571,
            "fmeasure": 0.50306
        },
        "bleu": 32.78672,
        "nubia": {
            "semantic_relation": 3.6392,
            "contradiction": 10.93291,
            "irrelevancy": 12.31777,
            "logical_agreement": 76.74932,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.60962,
            "nubia_score": 0.51349
        },
        "bleurt": -0.20962,
        "meteor": 0.2847610730669586,
        "bertscore": {
            "precision": 0.9042,
            "recall": 0.86549,
            "f1": 0.88266
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 986,
        "msttr-100": 0.66355,
        "msttr-100_nopunct": 0.71554,
        "total_length": 11022,
        "mean_pred_length": 11.178498985801218,
        "std_pred_length": 2.9244344087453453,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.2149337688259844,
        "vocab_size-1": 2369,
        "unique-1": 1214,
        "entropy-1": 9.086987914303625,
        "distinct-2": 0.5051813471502591,
        "vocab_size-2": 5070,
        "unique-2": 3444,
        "entropy-2": 11.647479170200329,
        "cond_entropy-2": 2.593718812465599,
        "distinct-3": 0.6986740331491713,
        "vocab_size-3": 6323,
        "unique-3": 4982,
        "entropy-3": 12.33066779025107,
        "cond_entropy-3": 0.7912075139651107,
        "total_length-nopunct": 9281,
        "mean_pred_length-nopunct": 9.412778904665315,
        "std_pred_length-nopunct": 2.54154107188579,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.25439069065833425,
        "vocab_size-1-nopunct": 2361,
        "unique-1-nopunct": 1213,
        "entropy-1-nopunct": 9.661917051071299,
        "distinct-2-nopunct": 0.5564798071127185,
        "vocab_size-2-nopunct": 4616,
        "unique-2-nopunct": 3317,
        "entropy-2-nopunct": 11.590521545389128,
        "cond_entropy-2-nopunct": 2.137029982786912,
        "distinct-3-nopunct": 0.7336160897523601,
        "vocab_size-3-nopunct": 5362,
        "unique-3-nopunct": 4385,
        "entropy-3-nopunct": 12.1144618581692,
        "cond_entropy-3-nopunct": 0.6492692008069219,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16943195749897835,
            "2": 0.3578439009191463,
            "3": 0.4774166314900802,
            "4": 0.6493506493506493,
            "5": 0.6486486486486487,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "nist": 1.7584804503718061,
        "rouge1": {
            "precision": 0.29928,
            "recall": 0.24494,
            "fmeasure": 0.2595
        },
        "rouge2": {
            "precision": 0.13967,
            "recall": 0.10957,
            "fmeasure": 0.11671
        },
        "rougeL": {
            "precision": 0.29313,
            "recall": 0.23975,
            "fmeasure": 0.25391
        },
        "rougeLsum": {
            "precision": 0.29313,
            "recall": 0.23975,
            "fmeasure": 0.25391
        },
        "bleu": 22.69679,
        "nubia": {
            "semantic_relation": 3.60467,
            "contradiction": 21.4672,
            "irrelevancy": 22.48933,
            "logical_agreement": 56.04347,
            "grammar_ref": 2.66553,
            "grammar_hyp": 2.74299,
            "nubia_score": 0.70055
        },
        "bleurt": 0.11354,
        "meteor": 0.4055246054390626,
        "bertscore": {
            "precision": 0.9516,
            "recall": 0.91512,
            "f1": 0.93214
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 22,
        "msttr-100": 0.21,
        "msttr-100_nopunct": 0.19,
        "total_length": 218,
        "mean_pred_length": 9.909090909090908,
        "std_pred_length": 0.949118773537323,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.0963302752293578,
        "vocab_size-1": 21,
        "unique-1": 0,
        "entropy-1": 4.033565094030991,
        "distinct-2": 0.12755102040816327,
        "vocab_size-2": 25,
        "unique-2": 0,
        "entropy-2": 4.2773598146813265,
        "cond_entropy-2": 0.16243822813191608,
        "distinct-3": 0.13793103448275862,
        "vocab_size-3": 24,
        "unique-3": 0,
        "entropy-3": 4.2474658512566545,
        "cond_entropy-3": 0.05135596837073987,
        "total_length-nopunct": 172,
        "mean_pred_length-nopunct": 7.818181818181818,
        "std_pred_length-nopunct": 0.7767276132106847,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.11046511627906977,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.9030066344969487,
        "distinct-2-nopunct": 0.12666666666666668,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.930626039536706,
        "cond_entropy-2-nopunct": 0.14913584590221687,
        "distinct-3-nopunct": 0.1328125,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.768496961967316,
        "cond_entropy-3-nopunct": -0.058410125960347316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.37142857142857144
        },
        "nist": 2.361931323295827,
        "rouge1": {
            "precision": 0.48005,
            "recall": 0.4684,
            "fmeasure": 0.47062
        },
        "rouge2": {
            "precision": 0.32524,
            "recall": 0.30858,
            "fmeasure": 0.31473
        },
        "rougeL": {
            "precision": 0.46263,
            "recall": 0.44794,
            "fmeasure": 0.45184
        },
        "rougeLsum": {
            "precision": 0.46263,
            "recall": 0.44794,
            "fmeasure": 0.45184
        },
        "bleu": 25.83372,
        "nubia": {
            "semantic_relation": 2.81146,
            "contradiction": 26.21371,
            "irrelevancy": 25.3975,
            "logical_agreement": 48.38879,
            "grammar_ref": 6.09546,
            "grammar_hyp": 5.88603,
            "nubia_score": 0.36569
        },
        "bleurt": -0.14944,
        "meteor": 0.20574540471910596,
        "bertscore": {
            "precision": 0.90977,
            "recall": 0.90815,
            "f1": 0.90889
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 116,
        "msttr-100": 0.64214,
        "msttr-100_nopunct": 0.69333,
        "total_length": 1437,
        "mean_pred_length": 12.387931034482758,
        "std_pred_length": 2.3517108655707992,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.3736951983298539,
        "vocab_size-1": 537,
        "unique-1": 327,
        "entropy-1": 7.914269889993167,
        "distinct-2": 0.6707040121120363,
        "vocab_size-2": 886,
        "unique-2": 657,
        "entropy-2": 9.50099965415712,
        "cond_entropy-2": 1.6981027706316925,
        "distinct-3": 0.8049792531120332,
        "vocab_size-3": 970,
        "unique-3": 805,
        "entropy-3": 9.787952693432057,
        "cond_entropy-3": 0.35321227011713763,
        "total_length-nopunct": 1233,
        "mean_pred_length-nopunct": 10.629310344827585,
        "std_pred_length-nopunct": 2.094863061995622,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.43146796431467965,
        "vocab_size-1-nopunct": 532,
        "unique-1-nopunct": 327,
        "entropy-1-nopunct": 8.27084875053343,
        "distinct-2-nopunct": 0.7072515666965085,
        "vocab_size-2-nopunct": 790,
        "unique-2-nopunct": 602,
        "entropy-2-nopunct": 9.388010998057391,
        "cond_entropy-2-nopunct": 1.2585130475968043,
        "distinct-3-nopunct": 0.8201798201798202,
        "vocab_size-3-nopunct": 821,
        "unique-3-nopunct": 693,
        "entropy-3-nopunct": 9.555079799383096,
        "cond_entropy-3-nopunct": 0.23220250442104393,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.14414414414414414,
            "2": 0.330188679245283,
            "3": 0.5314009661835749
        },
        "nist": 1.1428147566510238,
        "rouge1": {
            "precision": 0.06897,
            "recall": 0.06034,
            "fmeasure": 0.06322
        },
        "rouge2": {
            "precision": 0.01724,
            "recall": 0.01724,
            "fmeasure": 0.01724
        },
        "rougeL": {
            "precision": 0.06897,
            "recall": 0.06034,
            "fmeasure": 0.06322
        },
        "rougeLsum": {
            "precision": 0.06897,
            "recall": 0.06034,
            "fmeasure": 0.06322
        },
        "bleu": 19.41539,
        "nubia": {
            "semantic_relation": 3.54407,
            "contradiction": 22.28452,
            "irrelevancy": 21.31489,
            "logical_agreement": 56.40059,
            "grammar_ref": 2.53819,
            "grammar_hyp": 2.63767,
            "nubia_score": 0.67978
        },
        "bleurt": 0.00279,
        "meteor": 0.35519918946896667,
        "bertscore": {
            "precision": 0.9454,
            "recall": 0.90018,
            "f1": 0.92146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 77,
        "msttr-100": 0.7075,
        "msttr-100_nopunct": 0.756,
        "total_length": 1234,
        "mean_pred_length": 16.025974025974026,
        "std_pred_length": 5.164750722474355,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.4821717990275527,
        "vocab_size-1": 595,
        "unique-1": 483,
        "entropy-1": 7.886910354402207,
        "distinct-2": 0.8582541054451167,
        "vocab_size-2": 993,
        "unique-2": 915,
        "entropy-2": 9.77365396099904,
        "cond_entropy-2": 1.641166552581849,
        "distinct-3": 0.9398148148148148,
        "vocab_size-3": 1015,
        "unique-3": 980,
        "entropy-3": 9.921095166027964,
        "cond_entropy-3": 0.14339439901769724,
        "total_length-nopunct": 1071,
        "mean_pred_length-nopunct": 13.909090909090908,
        "std_pred_length-nopunct": 4.838111196817876,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5452847805788982,
        "vocab_size-1-nopunct": 584,
        "unique-1-nopunct": 477,
        "entropy-1-nopunct": 8.119914556232748,
        "distinct-2-nopunct": 0.8752515090543259,
        "vocab_size-2-nopunct": 870,
        "unique-2-nopunct": 814,
        "entropy-2-nopunct": 9.593710485045714,
        "cond_entropy-2-nopunct": 1.5665844787599112,
        "distinct-3-nopunct": 0.9531079607415486,
        "vocab_size-3-nopunct": 874,
        "unique-3-nopunct": 849,
        "entropy-3-nopunct": 9.7251409552011,
        "cond_entropy-3-nopunct": 0.1405866177575096,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1867704280155642,
            "2": 0.43023255813953487,
            "3": 0.7932379713914174
        },
        "nist": 7.319931463994365,
        "rouge1": {
            "precision": 0.77089,
            "recall": 0.73447,
            "fmeasure": 0.73985
        },
        "rouge2": {
            "precision": 0.53615,
            "recall": 0.50811,
            "fmeasure": 0.51346
        },
        "rougeL": {
            "precision": 0.68008,
            "recall": 0.65102,
            "fmeasure": 0.65404
        },
        "rougeLsum": {
            "precision": 0.68008,
            "recall": 0.65102,
            "fmeasure": 0.65404
        },
        "bleu": 48.3243,
        "nubia": {
            "semantic_relation": 4.12344,
            "contradiction": 10.13451,
            "irrelevancy": 22.96478,
            "logical_agreement": 66.90072,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.73758,
            "nubia_score": 0.69549
        },
        "bleurt": 0.25937,
        "meteor": 0.39466960467444945,
        "bertscore": {
            "precision": 0.93225,
            "recall": 0.92728,
            "f1": 0.92812
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 16,
        "msttr-100": 0.495,
        "msttr-100_nopunct": 0.525,
        "total_length": 275,
        "mean_pred_length": 17.1875,
        "std_pred_length": 3.5216961467452017,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.3018181818181818,
        "vocab_size-1": 83,
        "unique-1": 33,
        "entropy-1": 5.633127357503799,
        "distinct-2": 0.5598455598455598,
        "vocab_size-2": 145,
        "unique-2": 89,
        "entropy-2": 6.8348810206119275,
        "cond_entropy-2": 1.148547478960355,
        "distinct-3": 0.7078189300411523,
        "vocab_size-3": 172,
        "unique-3": 123,
        "entropy-3": 7.235512273620721,
        "cond_entropy-3": 0.4290709084540324,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 14.625,
        "std_pred_length-nopunct": 3.4437443284889775,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.3418803418803419,
        "vocab_size-1-nopunct": 80,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.717459922919788,
        "distinct-2-nopunct": 0.5825688073394495,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.66698567449547,
        "cond_entropy-2-nopunct": 1.0062878136009659,
        "distinct-3-nopunct": 0.7425742574257426,
        "vocab_size-3-nopunct": 150,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 7.064902218237099,
        "cond_entropy-3-nopunct": 0.38661335651806794,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.3967611336032389
        },
        "nist": 2.8092739644508122,
        "rouge1": {
            "precision": 0.50034,
            "recall": 0.48933,
            "fmeasure": 0.48445
        },
        "rouge2": {
            "precision": 0.27672,
            "recall": 0.27441,
            "fmeasure": 0.26943
        },
        "rougeL": {
            "precision": 0.37531,
            "recall": 0.37415,
            "fmeasure": 0.36704
        },
        "rougeLsum": {
            "precision": 0.37531,
            "recall": 0.37415,
            "fmeasure": 0.36704
        },
        "bleu": 14.60768,
        "nubia": {
            "semantic_relation": 3.3342,
            "contradiction": 25.15099,
            "irrelevancy": 23.78185,
            "logical_agreement": 51.06716,
            "grammar_ref": 5.92126,
            "grammar_hyp": 6.0104,
            "nubia_score": 0.50625
        },
        "bleurt": -0.16264,
        "meteor": 0.2073888456274836,
        "bertscore": {
            "precision": 0.89814,
            "recall": 0.89429,
            "f1": 0.89605
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 34,
        "msttr-100": 0.54667,
        "msttr-100_nopunct": 0.56667,
        "total_length": 358,
        "mean_pred_length": 10.529411764705882,
        "std_pred_length": 3.3888684049021354,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.3016759776536313,
        "vocab_size-1": 108,
        "unique-1": 48,
        "entropy-1": 5.991670918979525,
        "distinct-2": 0.5740740740740741,
        "vocab_size-2": 186,
        "unique-2": 115,
        "entropy-2": 7.224327251910508,
        "cond_entropy-2": 0.9755049648511618,
        "distinct-3": 0.7,
        "vocab_size-3": 203,
        "unique-3": 144,
        "entropy-3": 7.485914672890178,
        "cond_entropy-3": 0.16601829898456305,
        "total_length-nopunct": 315,
        "mean_pred_length-nopunct": 9.264705882352942,
        "std_pred_length-nopunct": 2.9436754089904023,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.33650793650793653,
        "vocab_size-1-nopunct": 106,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 6.100783979091299,
        "distinct-2-nopunct": 0.597864768683274,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 106,
        "entropy-2-nopunct": 7.138832461038722,
        "cond_entropy-2-nopunct": 0.9867723314292504,
        "distinct-3-nopunct": 0.7125506072874493,
        "vocab_size-3-nopunct": 176,
        "unique-3-nopunct": 127,
        "entropy-3-nopunct": 7.288877948226072,
        "cond_entropy-3-nopunct": 0.14658724116591068,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4059701492537313
        },
        "nist": 2.9442991407323076,
        "rouge1": {
            "precision": 0.55393,
            "recall": 0.50745,
            "fmeasure": 0.51877
        },
        "rouge2": {
            "precision": 0.31855,
            "recall": 0.29089,
            "fmeasure": 0.29842
        },
        "rougeL": {
            "precision": 0.49757,
            "recall": 0.45836,
            "fmeasure": 0.46751
        },
        "rougeLsum": {
            "precision": 0.49757,
            "recall": 0.45836,
            "fmeasure": 0.46751
        },
        "bleu": 14.98552,
        "nubia": {
            "semantic_relation": 3.28208,
            "contradiction": 17.51418,
            "irrelevancy": 21.31031,
            "logical_agreement": 61.17551,
            "grammar_ref": 6.46033,
            "grammar_hyp": 6.50659,
            "nubia_score": 0.46442
        },
        "bleurt": -0.10221,
        "meteor": 0.21657799124197952,
        "bertscore": {
            "precision": 0.91786,
            "recall": 0.91211,
            "f1": 0.91478
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 102,
        "mean_pred_length": 14.571428571428571,
        "std_pred_length": 7.687785169756405,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.696078431372549,
        "vocab_size-1": 71,
        "unique-1": 58,
        "entropy-1": 5.821730244587508,
        "distinct-2": 0.968421052631579,
        "vocab_size-2": 92,
        "unique-2": 90,
        "entropy-2": 6.498751529360806,
        "cond_entropy-2": 0.5623974547663778,
        "distinct-3": 0.9886363636363636,
        "vocab_size-3": 87,
        "unique-3": 86,
        "entropy-3": 6.436704345910033,
        "cond_entropy-3": -0.05639117716906579,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 7.264675505766355,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7528089887640449,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.797480307633818,
        "distinct-2-nopunct": 0.9634146341463414,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.275175327762435,
        "cond_entropy-2-nopunct": 0.5233995550472572,
        "distinct-3-nopunct": 0.9866666666666667,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.202152023829225,
        "cond_entropy-3-nopunct": -0.07866814742668995,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.3448275862068966,
            "3": 0.7627118644067796
        },
        "nist": 4.031198180537613,
        "rouge1": {
            "precision": 0.79441,
            "recall": 0.70814,
            "fmeasure": 0.72607
        },
        "rouge2": {
            "precision": 0.61869,
            "recall": 0.54901,
            "fmeasure": 0.56198
        },
        "rougeL": {
            "precision": 0.72297,
            "recall": 0.65021,
            "fmeasure": 0.66416
        },
        "rougeLsum": {
            "precision": 0.72297,
            "recall": 0.65021,
            "fmeasure": 0.66416
        },
        "bleu": 42.562,
        "nubia": {
            "semantic_relation": 4.35396,
            "contradiction": 2.05823,
            "irrelevancy": 13.80184,
            "logical_agreement": 84.13992,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.39914,
            "nubia_score": 0.81303
        },
        "bleurt": 0.26946,
        "meteor": 0.34647853319356336,
        "bertscore": {
            "precision": 0.92748,
            "recall": 0.9083,
            "f1": 0.91662
        }
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 12,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 94,
        "mean_pred_length": 7.833333333333333,
        "std_pred_length": 2.1147629234082532,
        "median_pred_length": 7.5,
        "min_pred_length": 5,
        "max_pred_length": 13,
        "distinct-1": 0.39361702127659576,
        "vocab_size-1": 37,
        "unique-1": 19,
        "entropy-1": 4.773320868341835,
        "distinct-2": 0.5975609756097561,
        "vocab_size-2": 49,
        "unique-2": 34,
        "entropy-2": 5.3630535287444925,
        "cond_entropy-2": 0.3257773651755297,
        "distinct-3": 0.6142857142857143,
        "vocab_size-3": 43,
        "unique-3": 31,
        "entropy-3": 5.175083195238235,
        "cond_entropy-3": -0.19969755910168846,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 6.416666666666667,
        "std_pred_length-nopunct": 1.7539637649874324,
        "median_pred_length-nopunct": 6.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.45454545454545453,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.801721606273151,
        "distinct-2-nopunct": 0.6153846153846154,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 5.087075697344285,
        "cond_entropy-2-nopunct": 0.3442139635464766,
        "distinct-3-nopunct": 0.6415094339622641,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.859258190085694,
        "cond_entropy-3-nopunct": -0.2755794339369534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.2682926829268293
        },
        "nist": 1.851757418460142,
        "rouge1": {
            "precision": 0.38095,
            "recall": 0.38834,
            "fmeasure": 0.37569
        },
        "rouge2": {
            "precision": 0.20724,
            "recall": 0.23574,
            "fmeasure": 0.21621
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.38834,
            "fmeasure": 0.37569
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.38834,
            "fmeasure": 0.37569
        },
        "bleu": 8.94996,
        "nubia": {
            "semantic_relation": 2.77282,
            "contradiction": 24.64336,
            "irrelevancy": 38.69657,
            "logical_agreement": 36.66007,
            "grammar_ref": 6.83527,
            "grammar_hyp": 7.30479,
            "nubia_score": 0.27888
        },
        "bleurt": -0.19891,
        "meteor": 0.142864097916631,
        "bertscore": {
            "precision": 0.89446,
            "recall": 0.89499,
            "f1": 0.89462
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 642,
        "msttr-100": 0.66507,
        "msttr-100_nopunct": 0.71466,
        "total_length": 6952,
        "mean_pred_length": 10.828660436137072,
        "std_pred_length": 3.1427988815592425,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.2643843498273878,
        "vocab_size-1": 1838,
        "unique-1": 1009,
        "entropy-1": 8.987899782949665,
        "distinct-2": 0.5824088748019017,
        "vocab_size-2": 3675,
        "unique-2": 2610,
        "entropy-2": 11.379369268217921,
        "cond_entropy-2": 2.3255504482601927,
        "distinct-3": 0.7692307692307693,
        "vocab_size-3": 4360,
        "unique-3": 3586,
        "entropy-3": 11.893290114583888,
        "cond_entropy-3": 0.5890514390518238,
        "total_length-nopunct": 5846,
        "mean_pred_length-nopunct": 9.105919003115265,
        "std_pred_length-nopunct": 2.765721841011984,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.31303455354088267,
        "vocab_size-1-nopunct": 1830,
        "unique-1-nopunct": 1008,
        "entropy-1-nopunct": 9.539022533162472,
        "distinct-2-nopunct": 0.6247117601844735,
        "vocab_size-2-nopunct": 3251,
        "unique-2-nopunct": 2424,
        "entropy-2-nopunct": 11.246295707774967,
        "cond_entropy-2-nopunct": 1.886525326449888,
        "distinct-3-nopunct": 0.7963612450679527,
        "vocab_size-3-nopunct": 3633,
        "unique-3-nopunct": 3079,
        "entropy-3-nopunct": 11.645830514628177,
        "cond_entropy-3-nopunct": 0.496372460621982,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.19733176953525877,
            "2": 0.38228882833787464,
            "3": 0.49545136459062283,
            "4": 0.6447368421052632,
            "5": 0.6060606060606061,
            "6": 0.9090909090909091,
            "7": 1.0
        },
        "nist": 2.634343650945393,
        "rouge1": {
            "precision": 0.3288,
            "recall": 0.26505,
            "fmeasure": 0.28199
        },
        "rouge2": {
            "precision": 0.18128,
            "recall": 0.14363,
            "fmeasure": 0.15265
        },
        "rougeL": {
            "precision": 0.32014,
            "recall": 0.25786,
            "fmeasure": 0.27418
        },
        "rougeLsum": {
            "precision": 0.32014,
            "recall": 0.25786,
            "fmeasure": 0.27418
        },
        "bleu": 26.37214,
        "nubia": {
            "semantic_relation": 3.67001,
            "contradiction": 21.3355,
            "irrelevancy": 22.45337,
            "logical_agreement": 56.21113,
            "grammar_ref": 2.74601,
            "grammar_hyp": 2.79102,
            "nubia_score": 0.71919
        },
        "bleurt": 0.16677,
        "meteor": 0.43950373525574954,
        "bertscore": {
            "precision": 0.95519,
            "recall": 0.92523,
            "f1": 0.93917
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 162,
        "msttr-100": 0.70167,
        "msttr-100_nopunct": 0.759,
        "total_length": 2404,
        "mean_pred_length": 14.839506172839506,
        "std_pred_length": 5.285565692942085,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.3527454242928453,
        "vocab_size-1": 848,
        "unique-1": 620,
        "entropy-1": 8.045553618013225,
        "distinct-2": 0.7591436217662801,
        "vocab_size-2": 1702,
        "unique-2": 1471,
        "entropy-2": 10.425162694711839,
        "cond_entropy-2": 2.108514797303632,
        "distinct-3": 0.9134615384615384,
        "vocab_size-3": 1900,
        "unique-3": 1808,
        "entropy-3": 10.793688875604206,
        "cond_entropy-3": 0.3800550165108668,
        "total_length-nopunct": 2092,
        "mean_pred_length-nopunct": 12.91358024691358,
        "std_pred_length-nopunct": 4.714562495874993,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.40152963671128106,
        "vocab_size-1-nopunct": 840,
        "unique-1-nopunct": 618,
        "entropy-1-nopunct": 8.375944124736424,
        "distinct-2-nopunct": 0.783419689119171,
        "vocab_size-2-nopunct": 1512,
        "unique-2-nopunct": 1332,
        "entropy-2-nopunct": 10.275005035900657,
        "cond_entropy-2-nopunct": 2.0153242725148255,
        "distinct-3-nopunct": 0.9213800904977375,
        "vocab_size-3-nopunct": 1629,
        "unique-3-nopunct": 1562,
        "entropy-3-nopunct": 10.576489727456698,
        "cond_entropy-3-nopunct": 0.3313581666264702,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22629969418960244,
            "2": 0.3665158371040724,
            "3": 0.7457088366179275
        },
        "nist": 7.545594388463951,
        "rouge1": {
            "precision": 0.72704,
            "recall": 0.70898,
            "fmeasure": 0.70499
        },
        "rouge2": {
            "precision": 0.48056,
            "recall": 0.46802,
            "fmeasure": 0.46421
        },
        "rougeL": {
            "precision": 0.62339,
            "recall": 0.6078,
            "fmeasure": 0.60295
        },
        "rougeLsum": {
            "precision": 0.62339,
            "recall": 0.6078,
            "fmeasure": 0.60295
        },
        "bleu": 42.39739,
        "nubia": {
            "semantic_relation": 4.12881,
            "contradiction": 8.98069,
            "irrelevancy": 32.63501,
            "logical_agreement": 58.3843,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.50626,
            "nubia_score": 0.72692
        },
        "bleurt": 0.25387,
        "meteor": 0.3791711610213412,
        "bertscore": {
            "precision": 0.92705,
            "recall": 0.92193,
            "f1": 0.92234
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 1075,
        "msttr-100": 0.7738,
        "msttr-100_nopunct": 0.85069,
        "total_length": 12175,
        "mean_pred_length": 11.325581395348838,
        "std_pred_length": 2.876698125254006,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.20788501026694045,
        "vocab_size-1": 2531,
        "unique-1": 1299,
        "entropy-1": 9.132780378775912,
        "distinct-2": 0.4936936936936937,
        "vocab_size-2": 5480,
        "unique-2": 3701,
        "entropy-2": 11.733741460915036,
        "cond_entropy-2": 2.6589256150207157,
        "distinct-3": 0.6879800498753117,
        "vocab_size-3": 6897,
        "unique-3": 5392,
        "entropy-3": 12.44855482387211,
        "cond_entropy-3": 0.8281015755823302,
        "total_length-nopunct": 10281,
        "mean_pred_length-nopunct": 9.563720930232558,
        "std_pred_length-nopunct": 2.5099587907817114,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.24540414356580098,
        "vocab_size-1-nopunct": 2523,
        "unique-1-nopunct": 1298,
        "entropy-1-nopunct": 9.710366406051246,
        "distinct-2-nopunct": 0.5456224201607647,
        "vocab_size-2-nopunct": 5023,
        "unique-2-nopunct": 3591,
        "entropy-2-nopunct": 11.696099548171828,
        "cond_entropy-2-nopunct": 2.1994324918616703,
        "distinct-3-nopunct": 0.7225433526011561,
        "vocab_size-3-nopunct": 5875,
        "unique-3-nopunct": 4765,
        "entropy-3-nopunct": 12.238482783302647,
        "cond_entropy-3-nopunct": 0.6720085935745015,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16515689542720488,
            "2": 0.35185444366689994,
            "3": 0.4830022918258212,
            "4": 0.6493506493506493,
            "5": 0.6486486486486487,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "nist": 1.6694002963802619,
        "rouge1": {
            "precision": 0.27415,
            "recall": 0.2254,
            "fmeasure": 0.2384
        },
        "rouge2": {
            "precision": 0.12411,
            "recall": 0.09833,
            "fmeasure": 0.10443
        },
        "rougeL": {
            "precision": 0.26897,
            "recall": 0.22097,
            "fmeasure": 0.23366
        },
        "rougeLsum": {
            "precision": 0.26897,
            "recall": 0.22097,
            "fmeasure": 0.23366
        },
        "bleu": 22.11876,
        "nubia": {
            "semantic_relation": 3.59233,
            "contradiction": 21.49269,
            "irrelevancy": 22.38009,
            "logical_agreement": 56.12723,
            "grammar_ref": 2.64396,
            "grammar_hyp": 2.72335,
            "nubia_score": 0.69749
        },
        "bleurt": 0.09971,
        "meteor": 0.3975006144078117,
        "bertscore": {
            "precision": 0.95084,
            "recall": 0.91305,
            "f1": 0.93072
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 7.0,
        "std_pred_length": 1.8708286933869707,
        "median_pred_length": 6.5,
        "min_pred_length": 5,
        "max_pred_length": 10,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.450212064914748,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": -0.13905908800311473,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 1.8708286933869707,
        "median_pred_length-nopunct": 5.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.16303440583379408,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.5333333333333333,
            "2": 0.23076923076923078,
            "3": 1.0
        },
        "nist": 3.392254709523683,
        "rouge1": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.125,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.16667,
            "fmeasure": 0.2
        },
        "bleu": 51.49418,
        "nubia": {
            "semantic_relation": 4.13841,
            "contradiction": 32.70655,
            "irrelevancy": 18.05905,
            "logical_agreement": 49.2344,
            "grammar_ref": 3.0388,
            "grammar_hyp": 3.13635,
            "nubia_score": 0.81156
        },
        "bleurt": 0.37073,
        "meteor": 0.652763012943509,
        "bertscore": {
            "precision": 0.95752,
            "recall": 0.9498,
            "f1": 0.94997
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.63667,
        "msttr-100_nopunct": 0.686,
        "total_length": 605,
        "mean_pred_length": 16.805555555555557,
        "std_pred_length": 5.5967224756222995,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.43636363636363634,
        "vocab_size-1": 264,
        "unique-1": 205,
        "entropy-1": 6.948124429018626,
        "distinct-2": 0.7855887521968365,
        "vocab_size-2": 447,
        "unique-2": 381,
        "entropy-2": 8.56931710136576,
        "cond_entropy-2": 1.4665064504368026,
        "distinct-3": 0.9193245778611632,
        "vocab_size-3": 490,
        "unique-3": 455,
        "entropy-3": 8.881867326922505,
        "cond_entropy-3": 0.32799478685463007,
        "total_length-nopunct": 506,
        "mean_pred_length-nopunct": 14.055555555555555,
        "std_pred_length-nopunct": 4.570098737350847,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5098814229249012,
        "vocab_size-1-nopunct": 258,
        "unique-1-nopunct": 204,
        "entropy-1-nopunct": 7.102556916774108,
        "distinct-2-nopunct": 0.8382978723404255,
        "vocab_size-2-nopunct": 394,
        "unique-2-nopunct": 341,
        "entropy-2-nopunct": 8.506275949823841,
        "cond_entropy-2-nopunct": 1.5004310025173626,
        "distinct-3-nopunct": 0.9447004608294931,
        "vocab_size-3-nopunct": 410,
        "unique-3-nopunct": 387,
        "entropy-3-nopunct": 8.649212781978623,
        "cond_entropy-3-nopunct": 0.1575190346494824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2982456140350877,
            "2": 0.5283018867924528,
            "3": 0.7683284457478006
        },
        "nist": 6.7000132787307765,
        "rouge1": {
            "precision": 0.76376,
            "recall": 0.743,
            "fmeasure": 0.74413
        },
        "rouge2": {
            "precision": 0.55982,
            "recall": 0.55289,
            "fmeasure": 0.54965
        },
        "rougeL": {
            "precision": 0.69013,
            "recall": 0.68078,
            "fmeasure": 0.67671
        },
        "rougeLsum": {
            "precision": 0.69013,
            "recall": 0.68078,
            "fmeasure": 0.67671
        },
        "bleu": 50.47637,
        "nubia": {
            "semantic_relation": 4.0474,
            "contradiction": 5.21139,
            "irrelevancy": 30.50734,
            "logical_agreement": 64.28127,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.92643,
            "nubia_score": 0.7508
        },
        "bleurt": 0.37408,
        "meteor": 0.41797059278112,
        "bertscore": {
            "precision": 0.94191,
            "recall": 0.93854,
            "f1": 0.93831
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72,
        "total_length": 209,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.3245498310218435,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 16,
        "distinct-1": 0.5598086124401914,
        "vocab_size-1": 117,
        "unique-1": 82,
        "entropy-1": 6.433059073561732,
        "distinct-2": 0.868421052631579,
        "vocab_size-2": 165,
        "unique-2": 147,
        "entropy-2": 7.276305937221391,
        "cond_entropy-2": 0.7166072823251941,
        "distinct-3": 0.9415204678362573,
        "vocab_size-3": 161,
        "unique-3": 152,
        "entropy-3": 7.296478903762128,
        "cond_entropy-3": 0.035245737014914194,
        "total_length-nopunct": 172,
        "mean_pred_length-nopunct": 9.052631578947368,
        "std_pred_length-nopunct": 3.1030322048386685,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6511627906976745,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.5345539473340875,
        "distinct-2-nopunct": 0.9084967320261438,
        "vocab_size-2-nopunct": 139,
        "unique-2-nopunct": 129,
        "entropy-2-nopunct": 7.051441600834286,
        "cond_entropy-2-nopunct": 0.5628720635942095,
        "distinct-3-nopunct": 0.9776119402985075,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 128,
        "entropy-3-nopunct": 7.021313071054795,
        "cond_entropy-3-nopunct": -0.008389883545872168,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.19631901840490798,
            "2": 0.5520833333333334,
            "3": 0.532608695652174
        },
        "nist": 3.195066339983084,
        "rouge1": {
            "precision": 0.30263,
            "recall": 0.2183,
            "fmeasure": 0.24649
        },
        "rouge2": {
            "precision": 0.23392,
            "recall": 0.15652,
            "fmeasure": 0.17544
        },
        "rougeL": {
            "precision": 0.28684,
            "recall": 0.20482,
            "fmeasure": 0.23158
        },
        "rougeLsum": {
            "precision": 0.28684,
            "recall": 0.20482,
            "fmeasure": 0.23158
        },
        "bleu": 33.60555,
        "nubia": {
            "semantic_relation": 3.79995,
            "contradiction": 24.01434,
            "irrelevancy": 20.93302,
            "logical_agreement": 55.05263,
            "grammar_ref": 2.97301,
            "grammar_hyp": 3.03009,
            "nubia_score": 0.73407
        },
        "bleurt": 0.1555,
        "meteor": 0.526552394512347,
        "bertscore": {
            "precision": 0.95635,
            "recall": 0.93176,
            "f1": 0.94248
        }
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 11.75,
        "std_pred_length": 2.680951323690902,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.6808510638297872,
        "vocab_size-1": 32,
        "unique-1": 20,
        "entropy-1": 4.857676351631607,
        "distinct-2": 0.813953488372093,
        "vocab_size-2": 35,
        "unique-2": 27,
        "entropy-2": 5.054171731446284,
        "cond_entropy-2": 0.2613244495864016,
        "distinct-3": 0.8974358974358975,
        "vocab_size-3": 35,
        "unique-3": 31,
        "entropy-3": 5.080274013734042,
        "cond_entropy-3": 0.06426566928835543,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 9.25,
        "std_pred_length-nopunct": 1.299038105676658,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7297297297297297,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.668912825088411,
        "distinct-2-nopunct": 0.8484848484848485,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.7413638163281515,
        "cond_entropy-2-nopunct": 0.13797105675980686,
        "distinct-3-nopunct": 0.9310344827586207,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.720049960644813,
        "cond_entropy-3-nopunct": 0.02048342749325653,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.5384615384615384,
            "3": 0.34615384615384615
        },
        "nist": 2.189171213017005,
        "rouge1": {
            "precision": 0.40833,
            "recall": 0.34697,
            "fmeasure": 0.35783
        },
        "rouge2": {
            "precision": 0.2125,
            "recall": 0.21435,
            "fmeasure": 0.20421
        },
        "rougeL": {
            "precision": 0.35833,
            "recall": 0.32273,
            "fmeasure": 0.32519
        },
        "rougeLsum": {
            "precision": 0.35833,
            "recall": 0.32273,
            "fmeasure": 0.32519
        },
        "bleu": 16.02037,
        "nubia": {
            "semantic_relation": 3.70125,
            "contradiction": 14.98126,
            "irrelevancy": 29.61277,
            "logical_agreement": 55.40597,
            "grammar_ref": 2.93748,
            "grammar_hyp": 3.21071,
            "nubia_score": 0.65066
        },
        "bleurt": 0.16105,
        "meteor": 0.3741529332796084,
        "bertscore": {
            "precision": 0.94841,
            "recall": 0.92441,
            "f1": 0.93538
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 339,
        "msttr-100": 0.672,
        "msttr-100_nopunct": 0.7356,
        "total_length": 3081,
        "mean_pred_length": 9.08849557522124,
        "std_pred_length": 2.567866516131765,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 17,
        "distinct-1": 0.36806231742940604,
        "vocab_size-1": 1134,
        "unique-1": 719,
        "entropy-1": 8.578562213246856,
        "distinct-2": 0.7162654996353027,
        "vocab_size-2": 1964,
        "unique-2": 1562,
        "entropy-2": 10.637875346770011,
        "cond_entropy-2": 1.6554139187689625,
        "distinct-3": 0.8680815647107782,
        "vocab_size-3": 2086,
        "unique-3": 1848,
        "entropy-3": 10.933321206347438,
        "cond_entropy-3": 0.31791894471371396,
        "total_length-nopunct": 2522,
        "mean_pred_length-nopunct": 7.43952802359882,
        "std_pred_length-nopunct": 2.331969886823045,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.4476605868358446,
        "vocab_size-1-nopunct": 1129,
        "unique-1-nopunct": 719,
        "entropy-1-nopunct": 9.201715405193504,
        "distinct-2-nopunct": 0.7434722858451672,
        "vocab_size-2-nopunct": 1623,
        "unique-2-nopunct": 1322,
        "entropy-2-nopunct": 10.391209767279763,
        "cond_entropy-2-nopunct": 1.3499369714815497,
        "distinct-3-nopunct": 0.8790672451193059,
        "vocab_size-3-nopunct": 1621,
        "unique-3-nopunct": 1458,
        "entropy-3-nopunct": 10.573184898133286,
        "cond_entropy-3-nopunct": 0.26166500650699387,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.32454624027657736,
            "2": 0.6337262012692656,
            "3": 0.7495769881556683,
            "4": 0.7777777777777778,
            "5": 0.5333333333333333,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 8.25266576739453,
        "rouge1": {
            "precision": 0.24823,
            "recall": 0.25066,
            "fmeasure": 0.24803
        },
        "rouge2": {
            "precision": 0.12687,
            "recall": 0.12537,
            "fmeasure": 0.1251
        },
        "rougeL": {
            "precision": 0.247,
            "recall": 0.24956,
            "fmeasure": 0.24687
        },
        "rougeLsum": {
            "precision": 0.247,
            "recall": 0.24956,
            "fmeasure": 0.24687
        },
        "bleu": 52.73373,
        "nubia": {
            "semantic_relation": 4.09697,
            "contradiction": 19.74932,
            "irrelevancy": 20.90146,
            "logical_agreement": 59.34922,
            "grammar_ref": 2.83259,
            "grammar_hyp": 2.85366,
            "nubia_score": 0.82643
        },
        "bleurt": 0.34275,
        "meteor": 0.6809731472082726,
        "bertscore": {
            "precision": 0.96759,
            "recall": 0.95908,
            "f1": 0.96268
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 122,
        "msttr-100": 0.74579,
        "msttr-100_nopunct": 0.79176,
        "total_length": 1987,
        "mean_pred_length": 16.28688524590164,
        "std_pred_length": 5.237756227461039,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.46552591847005537,
        "vocab_size-1": 925,
        "unique-1": 741,
        "entropy-1": 8.393128211026767,
        "distinct-2": 0.8718498659517426,
        "vocab_size-2": 1626,
        "unique-2": 1501,
        "entropy-2": 10.524667828536959,
        "cond_entropy-2": 1.8924038499225784,
        "distinct-3": 0.9661503155479059,
        "vocab_size-3": 1684,
        "unique-3": 1641,
        "entropy-3": 10.691393785856127,
        "cond_entropy-3": 0.15447198806220677,
        "total_length-nopunct": 1757,
        "mean_pred_length-nopunct": 14.401639344262295,
        "std_pred_length-nopunct": 4.76094052573644,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5213431986340353,
        "vocab_size-1-nopunct": 916,
        "unique-1-nopunct": 739,
        "entropy-1-nopunct": 8.651630751481147,
        "distinct-2-nopunct": 0.8892966360856269,
        "vocab_size-2-nopunct": 1454,
        "unique-2-nopunct": 1365,
        "entropy-2-nopunct": 10.372386152459818,
        "cond_entropy-2-nopunct": 1.8019211740688508,
        "distinct-3-nopunct": 0.9722405816259088,
        "vocab_size-3-nopunct": 1471,
        "unique-3-nopunct": 1441,
        "entropy-3-nopunct": 10.5004772682577,
        "cond_entropy-3-nopunct": 0.14103769853679834,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20674157303370785,
            "2": 0.4540059347181009,
            "3": 0.7453737971872687
        },
        "nist": 7.387757708886675,
        "rouge1": {
            "precision": 0.74594,
            "recall": 0.72248,
            "fmeasure": 0.72411
        },
        "rouge2": {
            "precision": 0.50566,
            "recall": 0.48844,
            "fmeasure": 0.49009
        },
        "rougeL": {
            "precision": 0.6346,
            "recall": 0.61557,
            "fmeasure": 0.6166
        },
        "rougeLsum": {
            "precision": 0.6346,
            "recall": 0.61557,
            "fmeasure": 0.6166
        },
        "bleu": 42.36703,
        "nubia": {
            "semantic_relation": 4.16925,
            "contradiction": 7.42832,
            "irrelevancy": 30.68275,
            "logical_agreement": 61.88893,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.80115,
            "nubia_score": 0.70332
        },
        "bleurt": 0.20955,
        "meteor": 0.3778156032443885,
        "bertscore": {
            "precision": 0.92366,
            "recall": 0.91782,
            "f1": 0.9189
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.774917217635375,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 51,
        "unique-1": 45,
        "entropy-1": 5.428800324160117,
        "distinct-2": 0.9838709677419355,
        "vocab_size-2": 61,
        "unique-2": 60,
        "entropy-2": 5.921938245870745,
        "cond_entropy-2": 0.4561619165272476,
        "distinct-3": 1.0,
        "vocab_size-3": 58,
        "unique-3": 58,
        "entropy-3": 5.85798099512757,
        "cond_entropy-3": -0.0617325566386132,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.598076211353316,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8448275862068966,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.439624745015668,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.7548875021634665,
        "cond_entropy-2-nopunct": 0.34625210900794134,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.11103131238874385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8181818181818182,
            "3": 0.7111111111111111
        },
        "nist": 5.068008528063287,
        "rouge1": {
            "precision": 0.79196,
            "recall": 0.86688,
            "fmeasure": 0.80332
        },
        "rouge2": {
            "precision": 0.64813,
            "recall": 0.69001,
            "fmeasure": 0.64565
        },
        "rougeL": {
            "precision": 0.69196,
            "recall": 0.75949,
            "fmeasure": 0.7001
        },
        "rougeLsum": {
            "precision": 0.69196,
            "recall": 0.75949,
            "fmeasure": 0.7001
        },
        "bleu": 56.48842,
        "nubia": {
            "semantic_relation": 4.06521,
            "contradiction": 1.76304,
            "irrelevancy": 45.29256,
            "logical_agreement": 52.94439,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.25628,
            "nubia_score": 0.68767
        },
        "bleurt": 0.41176,
        "meteor": 0.4475544131445289,
        "bertscore": {
            "precision": 0.94684,
            "recall": 0.95288,
            "f1": 0.9491
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 460,
        "msttr-100": 0.63782,
        "msttr-100_nopunct": 0.68348,
        "total_length": 5507,
        "mean_pred_length": 11.971739130434782,
        "std_pred_length": 2.347354018564053,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.25694570546577084,
        "vocab_size-1": 1415,
        "unique-1": 761,
        "entropy-1": 8.639761739117764,
        "distinct-2": 0.5306122448979592,
        "vocab_size-2": 2678,
        "unique-2": 1814,
        "entropy-2": 10.814269133933644,
        "cond_entropy-2": 2.324979235492535,
        "distinct-3": 0.7015478526269893,
        "vocab_size-3": 3218,
        "unique-3": 2473,
        "entropy-3": 11.40929996507924,
        "cond_entropy-3": 0.696679301190762,
        "total_length-nopunct": 4668,
        "mean_pred_length-nopunct": 10.147826086956522,
        "std_pred_length-nopunct": 1.9945293800832122,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3018423307626392,
        "vocab_size-1-nopunct": 1409,
        "unique-1-nopunct": 760,
        "entropy-1-nopunct": 9.143565716270704,
        "distinct-2-nopunct": 0.5834125475285171,
        "vocab_size-2-nopunct": 2455,
        "unique-2-nopunct": 1750,
        "entropy-2-nopunct": 10.799653274429659,
        "cond_entropy-2-nopunct": 1.8471964753187402,
        "distinct-3-nopunct": 0.7323906083244397,
        "vocab_size-3-nopunct": 2745,
        "unique-3-nopunct": 2176,
        "entropy-3-nopunct": 11.203633154859078,
        "cond_entropy-3-nopunct": 0.5159160778402162,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13671766342141864,
            "2": 0.3263830970252989,
            "3": 0.47021191523390643,
            "4": 1.0,
            "5": 1.0,
            "6": 1.0,
            "7": 1.0
        },
        "nist": 0.8726231599839679,
        "rouge1": {
            "precision": 0.2,
            "recall": 0.17032,
            "fmeasure": 0.17861
        },
        "rouge2": {
            "precision": 0.05072,
            "recall": 0.03874,
            "fmeasure": 0.04147
        },
        "rougeL": {
            "precision": 0.19891,
            "recall": 0.16923,
            "fmeasure": 0.17752
        },
        "rougeLsum": {
            "precision": 0.19891,
            "recall": 0.16923,
            "fmeasure": 0.17752
        },
        "bleu": 18.01104,
        "nubia": {
            "semantic_relation": 3.49819,
            "contradiction": 21.85711,
            "irrelevancy": 22.24336,
            "logical_agreement": 55.89953,
            "grammar_ref": 2.52111,
            "grammar_hyp": 2.64941,
            "nubia_score": 0.6693
        },
        "bleurt": 0.01131,
        "meteor": 0.35671242872486036,
        "bertscore": {
            "precision": 0.94503,
            "recall": 0.89724,
            "f1": 0.91963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.77125,
        "total_length": 1893,
        "mean_pred_length": 16.605263157894736,
        "std_pred_length": 4.860543650649661,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.45905969360802956,
        "vocab_size-1": 869,
        "unique-1": 677,
        "entropy-1": 8.300518218036986,
        "distinct-2": 0.8684654300168634,
        "vocab_size-2": 1545,
        "unique-2": 1410,
        "entropy-2": 10.45059008905792,
        "cond_entropy-2": 1.922441638508742,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 1620,
        "unique-3": 1581,
        "entropy-3": 10.644237663154872,
        "cond_entropy-3": 0.1940075846231806,
        "total_length-nopunct": 1662,
        "mean_pred_length-nopunct": 14.578947368421053,
        "std_pred_length-nopunct": 4.39875328597935,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5180505415162455,
        "vocab_size-1-nopunct": 861,
        "unique-1-nopunct": 676,
        "entropy-1-nopunct": 8.574841835202406,
        "distinct-2-nopunct": 0.8837209302325582,
        "vocab_size-2-nopunct": 1368,
        "unique-2-nopunct": 1271,
        "entropy-2-nopunct": 10.277963839890942,
        "cond_entropy-2-nopunct": 1.8052980114966422,
        "distinct-3-nopunct": 0.9755927475592747,
        "vocab_size-3-nopunct": 1399,
        "unique-3-nopunct": 1370,
        "entropy-3-nopunct": 10.433514420271763,
        "cond_entropy-3-nopunct": 0.17555950084987396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22139303482587064,
            "2": 0.4847715736040609,
            "3": 0.7374890254609306
        },
        "nist": 7.018980513870672,
        "rouge1": {
            "precision": 0.70864,
            "recall": 0.68991,
            "fmeasure": 0.68936
        },
        "rouge2": {
            "precision": 0.44544,
            "recall": 0.43824,
            "fmeasure": 0.43479
        },
        "rougeL": {
            "precision": 0.58829,
            "recall": 0.58384,
            "fmeasure": 0.57761
        },
        "rougeLsum": {
            "precision": 0.58829,
            "recall": 0.58384,
            "fmeasure": 0.57761
        },
        "bleu": 35.89587,
        "nubia": {
            "semantic_relation": 4.13203,
            "contradiction": 8.17951,
            "irrelevancy": 34.3992,
            "logical_agreement": 57.42129,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.65519,
            "nubia_score": 0.71001
        },
        "bleurt": 0.1629,
        "meteor": 0.3587668623932434,
        "bertscore": {
            "precision": 0.91469,
            "recall": 0.91606,
            "f1": 0.91397
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 158,
        "msttr-100": 0.51842,
        "msttr-100_nopunct": 0.51714,
        "total_length": 3843,
        "mean_pred_length": 24.32278481012658,
        "std_pred_length": 2.9258104737622466,
        "median_pred_length": 24.0,
        "min_pred_length": 16,
        "max_pred_length": 32,
        "distinct-1": 0.18761384335154827,
        "vocab_size-1": 721,
        "unique-1": 307,
        "entropy-1": 7.6957565773543095,
        "distinct-2": 0.44097693351424694,
        "vocab_size-2": 1625,
        "unique-2": 998,
        "entropy-2": 9.985988315485603,
        "cond_entropy-2": 2.3643269546916454,
        "distinct-3": 0.6112843776580663,
        "vocab_size-3": 2156,
        "unique-3": 1598,
        "entropy-3": 10.650741749848795,
        "cond_entropy-3": 0.7159950860163737,
        "total_length-nopunct": 3513,
        "mean_pred_length-nopunct": 22.234177215189874,
        "std_pred_length-nopunct": 3.042250419371225,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.20324508966695132,
        "vocab_size-1-nopunct": 714,
        "unique-1-nopunct": 305,
        "entropy-1-nopunct": 7.822308992786211,
        "distinct-2-nopunct": 0.4581222056631893,
        "vocab_size-2-nopunct": 1537,
        "unique-2-nopunct": 967,
        "entropy-2-nopunct": 9.936980609527602,
        "cond_entropy-2-nopunct": 2.217198849636139,
        "distinct-3-nopunct": 0.6230841413825461,
        "vocab_size-3-nopunct": 1992,
        "unique-3-nopunct": 1516,
        "entropy-3-nopunct": 10.529580394726809,
        "cond_entropy-3-nopunct": 0.6507405455736194,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.14016172506738545,
            "2": 0.36192109777015435,
            "3": 0.6067495559502665
        },
        "nist": 2.9225094846113318,
        "rouge1": {
            "precision": 0.75688,
            "recall": 0.51181,
            "fmeasure": 0.59733
        },
        "rouge2": {
            "precision": 0.48092,
            "recall": 0.3082,
            "fmeasure": 0.36591
        },
        "rougeL": {
            "precision": 0.59329,
            "recall": 0.39597,
            "fmeasure": 0.46316
        },
        "rougeLsum": {
            "precision": 0.59329,
            "recall": 0.39597,
            "fmeasure": 0.46316
        },
        "bleu": 28.51983,
        "nubia": {
            "semantic_relation": 3.41136,
            "contradiction": 7.87214,
            "irrelevancy": 13.38229,
            "logical_agreement": 78.74557,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.56675,
            "nubia_score": 0.45859
        },
        "bleurt": -0.35081,
        "meteor": 0.25100338308872305,
        "bertscore": {
            "precision": 0.89866,
            "recall": 0.8445,
            "f1": 0.86923
        }
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.72208,
        "msttr-100_nopunct": 0.77929,
        "total_length": 4800,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.130951828527205,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.37916666666666665,
        "vocab_size-1": 1820,
        "unique-1": 1409,
        "entropy-1": 8.78255511209814,
        "distinct-2": 0.786,
        "vocab_size-2": 3537,
        "unique-2": 3162,
        "entropy-2": 11.448240928822257,
        "cond_entropy-2": 2.3786154944988454,
        "distinct-3": 0.9319047619047619,
        "vocab_size-3": 3914,
        "unique-3": 3759,
        "entropy-3": 11.86036374961495,
        "cond_entropy-3": 0.4130380390384732,
        "total_length-nopunct": 4224,
        "mean_pred_length-nopunct": 14.08,
        "std_pred_length-nopunct": 4.769374522233846,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4287405303030303,
        "vocab_size-1-nopunct": 1811,
        "unique-1-nopunct": 1408,
        "entropy-1-nopunct": 9.152892254624057,
        "distinct-2-nopunct": 0.8068297655453619,
        "vocab_size-2-nopunct": 3166,
        "unique-2-nopunct": 2882,
        "entropy-2-nopunct": 11.29243839847701,
        "cond_entropy-2-nopunct": 2.247147589037313,
        "distinct-3-nopunct": 0.9445364238410596,
        "vocab_size-3-nopunct": 3423,
        "unique-3-nopunct": 3306,
        "entropy-3-nopunct": 11.68378146994218,
        "cond_entropy-3-nopunct": 0.4138248599862628,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20070011668611434,
            "2": 0.43661971830985913,
            "3": 0.8100609756097561
        },
        "nist": 8.768358858378239,
        "rouge1": {
            "precision": 0.79304,
            "recall": 0.76953,
            "fmeasure": 0.77225
        },
        "rouge2": {
            "precision": 0.56039,
            "recall": 0.54443,
            "fmeasure": 0.54595
        },
        "rougeL": {
            "precision": 0.68021,
            "recall": 0.66837,
            "fmeasure": 0.66632
        },
        "rougeLsum": {
            "precision": 0.68021,
            "recall": 0.66837,
            "fmeasure": 0.66632
        },
        "bleu": 47.57338,
        "nubia": {
            "semantic_relation": 4.39574,
            "contradiction": 4.45044,
            "irrelevancy": 23.96836,
            "logical_agreement": 71.5812,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.84004,
            "nubia_score": 0.78559
        },
        "bleurt": 0.36205,
        "meteor": 0.4099514818649728,
        "bertscore": {
            "precision": 0.94154,
            "recall": 0.93685,
            "f1": 0.93781
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 213,
        "msttr-100": 0.64385,
        "msttr-100_nopunct": 0.66404,
        "total_length": 5211,
        "mean_pred_length": 24.464788732394368,
        "std_pred_length": 2.8159388026628926,
        "median_pred_length": 25.0,
        "min_pred_length": 16,
        "max_pred_length": 32,
        "distinct-1": 0.17309537516791404,
        "vocab_size-1": 902,
        "unique-1": 379,
        "entropy-1": 7.860473079887749,
        "distinct-2": 0.4223689475790316,
        "vocab_size-2": 2111,
        "unique-2": 1267,
        "entropy-2": 10.300549821039366,
        "cond_entropy-2": 2.518819175350309,
        "distinct-3": 0.6020898641588297,
        "vocab_size-3": 2881,
        "unique-3": 2080,
        "entropy-3": 11.074095933705774,
        "cond_entropy-3": 0.8276115050620192,
        "total_length-nopunct": 4785,
        "mean_pred_length-nopunct": 22.464788732394368,
        "std_pred_length-nopunct": 2.8655194086216897,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.18725182863113898,
        "vocab_size-1-nopunct": 896,
        "unique-1-nopunct": 378,
        "entropy-1-nopunct": 7.990201159183994,
        "distinct-2-nopunct": 0.44006999125109364,
        "vocab_size-2-nopunct": 2012,
        "unique-2-nopunct": 1244,
        "entropy-2-nopunct": 10.264029256121184,
        "cond_entropy-2-nopunct": 2.3772558193759132,
        "distinct-3-nopunct": 0.6139022711631108,
        "vocab_size-3-nopunct": 2676,
        "unique-3-nopunct": 1984,
        "entropy-3-nopunct": 10.961773296550057,
        "cond_entropy-3-nopunct": 0.7601844074329999,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.15979202772963605,
            "2": 0.38946723821187995,
            "3": 0.637071202075526
        },
        "nist": 4.110702262014174,
        "rouge1": {
            "precision": 0.73771,
            "recall": 0.5244,
            "fmeasure": 0.60393
        },
        "rouge2": {
            "precision": 0.45333,
            "recall": 0.30697,
            "fmeasure": 0.35973
        },
        "rougeL": {
            "precision": 0.56828,
            "recall": 0.4036,
            "fmeasure": 0.46419
        },
        "rougeLsum": {
            "precision": 0.56828,
            "recall": 0.4036,
            "fmeasure": 0.46419
        },
        "bleu": 30.67948,
        "nubia": {
            "semantic_relation": 3.46826,
            "contradiction": 8.14779,
            "irrelevancy": 13.82208,
            "logical_agreement": 78.03014,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.54325,
            "nubia_score": 0.46233
        },
        "bleurt": -0.31754,
        "meteor": 0.26242469946413893,
        "bertscore": {
            "precision": 0.89784,
            "recall": 0.85023,
            "f1": 0.87203
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 316,
        "msttr-100": 0.66947,
        "msttr-100_nopunct": 0.73344,
        "total_length": 3845,
        "mean_pred_length": 12.167721518987342,
        "std_pred_length": 2.293435016653597,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 18,
        "distinct-1": 0.3401820546163849,
        "vocab_size-1": 1308,
        "unique-1": 800,
        "entropy-1": 8.736567539611123,
        "distinct-2": 0.6531595352791159,
        "vocab_size-2": 2305,
        "unique-2": 1724,
        "entropy-2": 10.779422998333805,
        "cond_entropy-2": 2.1480711797468675,
        "distinct-3": 0.8188608776844071,
        "vocab_size-3": 2631,
        "unique-3": 2220,
        "entropy-3": 11.23588213118215,
        "cond_entropy-3": 0.525309587435692,
        "total_length-nopunct": 3263,
        "mean_pred_length-nopunct": 10.325949367088608,
        "std_pred_length-nopunct": 1.8838312825817964,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.39901930738584124,
        "vocab_size-1-nopunct": 1302,
        "unique-1-nopunct": 799,
        "entropy-1-nopunct": 9.2346925064316,
        "distinct-2-nopunct": 0.7088564642008822,
        "vocab_size-2-nopunct": 2089,
        "unique-2-nopunct": 1641,
        "entropy-2-nopunct": 10.734745233297703,
        "cond_entropy-2-nopunct": 1.659085868788226,
        "distinct-3-nopunct": 0.8449258836944128,
        "vocab_size-3-nopunct": 2223,
        "unique-3-nopunct": 1932,
        "entropy-3-nopunct": 11.007688738247028,
        "cond_entropy-3-nopunct": 0.3434417397362358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.16166822867853795,
            "2": 0.391702846116739,
            "3": 0.5640845070422535,
            "4": 0.7368421052631579,
            "5": 0.7272727272727273,
            "6": 0.0,
            "7": 1.0
        },
        "nist": 2.431236041242172,
        "rouge1": {
            "precision": 0.27911,
            "recall": 0.2508,
            "fmeasure": 0.25863
        },
        "rouge2": {
            "precision": 0.1161,
            "recall": 0.10178,
            "fmeasure": 0.106
        },
        "rougeL": {
            "precision": 0.27266,
            "recall": 0.24488,
            "fmeasure": 0.25243
        },
        "rougeLsum": {
            "precision": 0.27266,
            "recall": 0.24488,
            "fmeasure": 0.25243
        },
        "bleu": 25.25157,
        "nubia": {
            "semantic_relation": 3.55163,
            "contradiction": 21.48022,
            "irrelevancy": 23.14461,
            "logical_agreement": 55.37516,
            "grammar_ref": 2.6064,
            "grammar_hyp": 2.68119,
            "nubia_score": 0.68826
        },
        "bleurt": 0.03308,
        "meteor": 0.41563884960241637,
        "bertscore": {
            "precision": 0.94862,
            "recall": 0.91142,
            "f1": 0.92883
        }
    },
    "schema_guided_dialog_challenge_test_backtranslation_parent": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69065,
        "msttr-100_nopunct": 0.71741,
        "total_length": 6278,
        "mean_pred_length": 12.556,
        "std_pred_length": 6.581098996368312,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.15864925135393437,
        "vocab_size-1": 996,
        "unique-1": 559,
        "entropy-1": 7.817427213610869,
        "distinct-2": 0.4974039460020768,
        "vocab_size-2": 2874,
        "unique-2": 2046,
        "entropy-2": 10.727132124034016,
        "cond_entropy-2": 2.660889654767666,
        "distinct-3": 0.7161803713527851,
        "vocab_size-3": 3780,
        "unique-3": 3151,
        "entropy-3": 11.502386731210933,
        "cond_entropy-3": 0.7978132484074494,
        "total_length-nopunct": 5488,
        "mean_pred_length-nopunct": 10.976,
        "std_pred_length-nopunct": 6.045446550917475,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.17911807580174927,
        "vocab_size-1-nopunct": 983,
        "unique-1-nopunct": 555,
        "entropy-1-nopunct": 8.0139514745028,
        "distinct-2-nopunct": 0.5182437850842021,
        "vocab_size-2-nopunct": 2585,
        "unique-2-nopunct": 1892,
        "entropy-2-nopunct": 10.568347696142535,
        "cond_entropy-2-nopunct": 2.6845989714043235,
        "distinct-3-nopunct": 0.7342984409799554,
        "vocab_size-3-nopunct": 3297,
        "unique-3-nopunct": 2823,
        "entropy-3-nopunct": 11.295369707729732,
        "cond_entropy-3-nopunct": 0.7648117855125833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.571772997032641
        },
        "nist": 6.120824735686664,
        "rouge1": {
            "precision": 0.56188,
            "recall": 0.54895,
            "fmeasure": 0.54432
        },
        "rouge2": {
            "precision": 0.34945,
            "recall": 0.34263,
            "fmeasure": 0.33858
        },
        "rougeL": {
            "precision": 0.51139,
            "recall": 0.4991,
            "fmeasure": 0.49526
        },
        "rougeLsum": {
            "precision": 0.51139,
            "recall": 0.4991,
            "fmeasure": 0.49526
        },
        "bleu": 32.84909,
        "nubia": {
            "semantic_relation": 3.61154,
            "contradiction": 5.48544,
            "irrelevancy": 22.547,
            "logical_agreement": 71.96757,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.59662,
            "nubia_score": 0.64563
        },
        "bleurt": -0.0616,
        "meteor": 0.31881897845488744,
        "bertscore": {
            "precision": 0.8698,
            "recall": 0.86726,
            "f1": 0.86802
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.785,
        "total_length": 306,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.9907335852038095,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.6241830065359477,
        "vocab_size-1": 191,
        "unique-1": 157,
        "entropy-1": 6.951790821532993,
        "distinct-2": 0.9513888888888888,
        "vocab_size-2": 274,
        "unique-2": 262,
        "entropy-2": 8.067460504899481,
        "cond_entropy-2": 0.9701882282306693,
        "distinct-3": 0.9925925925925926,
        "vocab_size-3": 268,
        "unique-3": 266,
        "entropy-3": 8.062000782236028,
        "cond_entropy-3": 0.001371243772692083,
        "total_length-nopunct": 268,
        "mean_pred_length-nopunct": 14.88888888888889,
        "std_pred_length-nopunct": 5.2269482161507,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6828358208955224,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 7.001549025456237,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 240,
        "unique-2-nopunct": 232,
        "entropy-2-nopunct": 7.879745184644792,
        "cond_entropy-2-nopunct": 0.9428430510686318,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 232,
        "unique-3-nopunct": 232,
        "entropy-3-nopunct": 7.857980995127551,
        "cond_entropy-3-nopunct": -0.019399086929657222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2912621359223301,
            "2": 0.45454545454545453,
            "3": 0.6938775510204082
        },
        "nist": 6.192033711472404,
        "rouge1": {
            "precision": 0.74338,
            "recall": 0.66465,
            "fmeasure": 0.68153
        },
        "rouge2": {
            "precision": 0.49496,
            "recall": 0.43957,
            "fmeasure": 0.45086
        },
        "rougeL": {
            "precision": 0.6326,
            "recall": 0.57224,
            "fmeasure": 0.58372
        },
        "rougeLsum": {
            "precision": 0.6326,
            "recall": 0.57224,
            "fmeasure": 0.58372
        },
        "bleu": 40.4376,
        "nubia": {
            "semantic_relation": 3.94863,
            "contradiction": 10.88197,
            "irrelevancy": 34.38651,
            "logical_agreement": 54.73152,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.89967,
            "nubia_score": 0.63658
        },
        "bleurt": 0.01903,
        "meteor": 0.3678370784717913,
        "bertscore": {
            "precision": 0.91984,
            "recall": 0.91225,
            "f1": 0.91442
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 217,
        "msttr-100": 0.67885,
        "msttr-100_nopunct": 0.73182,
        "total_length": 2697,
        "mean_pred_length": 12.428571428571429,
        "std_pred_length": 2.4841830126401043,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.38264738598442716,
        "vocab_size-1": 1032,
        "unique-1": 669,
        "entropy-1": 8.565141416224822,
        "distinct-2": 0.7125,
        "vocab_size-2": 1767,
        "unique-2": 1377,
        "entropy-2": 10.515650054182556,
        "cond_entropy-2": 2.0674470243836254,
        "distinct-3": 0.8555015466195316,
        "vocab_size-3": 1936,
        "unique-3": 1686,
        "entropy-3": 10.823961052405913,
        "cond_entropy-3": 0.366800240861172,
        "total_length-nopunct": 2296,
        "mean_pred_length-nopunct": 10.580645161290322,
        "std_pred_length-nopunct": 2.0306847834554955,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.44642857142857145,
        "vocab_size-1-nopunct": 1025,
        "unique-1-nopunct": 668,
        "entropy-1-nopunct": 9.030438024719963,
        "distinct-2-nopunct": 0.759018759018759,
        "vocab_size-2-nopunct": 1578,
        "unique-2-nopunct": 1287,
        "entropy-2-nopunct": 10.410836581783933,
        "cond_entropy-2-nopunct": 1.499079627549929,
        "distinct-3-nopunct": 0.8748657357679914,
        "vocab_size-3-nopunct": 1629,
        "unique-3-nopunct": 1453,
        "entropy-3-nopunct": 10.584304239653415,
        "cond_entropy-3-nopunct": 0.22689134930678426,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13282208588957056,
            "2": 0.31382636655948554,
            "3": 0.4783565663976522,
            "4": 0.36363636363636365
        },
        "nist": 1.2317870186565392,
        "rouge1": {
            "precision": 0.28248,
            "recall": 0.21412,
            "fmeasure": 0.23455
        },
        "rouge2": {
            "precision": 0.11514,
            "recall": 0.08042,
            "fmeasure": 0.08918
        },
        "rougeL": {
            "precision": 0.27436,
            "recall": 0.20756,
            "fmeasure": 0.22737
        },
        "rougeLsum": {
            "precision": 0.27436,
            "recall": 0.20756,
            "fmeasure": 0.22737
        },
        "bleu": 19.0585,
        "nubia": {
            "semantic_relation": 3.37515,
            "contradiction": 22.22241,
            "irrelevancy": 22.74063,
            "logical_agreement": 55.03695,
            "grammar_ref": 2.56565,
            "grammar_hyp": 2.65223,
            "nubia_score": 0.63018
        },
        "bleurt": -0.02463,
        "meteor": 0.3533696973167681,
        "bertscore": {
            "precision": 0.94278,
            "recall": 0.89453,
            "f1": 0.91737
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 143,
        "msttr-100": 0.65611,
        "msttr-100_nopunct": 0.71133,
        "total_length": 1831,
        "mean_pred_length": 12.804195804195805,
        "std_pred_length": 2.509447160744734,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.3965046422719825,
        "vocab_size-1": 726,
        "unique-1": 481,
        "entropy-1": 8.22976989346448,
        "distinct-2": 0.7227488151658767,
        "vocab_size-2": 1220,
        "unique-2": 969,
        "entropy-2": 10.012494485472017,
        "cond_entropy-2": 1.9115778080700119,
        "distinct-3": 0.858252427184466,
        "vocab_size-3": 1326,
        "unique-3": 1171,
        "entropy-3": 10.27188907814073,
        "cond_entropy-3": 0.29967207343940166,
        "total_length-nopunct": 1558,
        "mean_pred_length-nopunct": 10.895104895104895,
        "std_pred_length-nopunct": 2.016412679461256,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.4614890885750963,
        "vocab_size-1-nopunct": 719,
        "unique-1-nopunct": 480,
        "entropy-1-nopunct": 8.624784701768734,
        "distinct-2-nopunct": 0.7625441696113074,
        "vocab_size-2-nopunct": 1079,
        "unique-2-nopunct": 887,
        "entropy-2-nopunct": 9.882882818112487,
        "cond_entropy-2-nopunct": 1.3789424439628934,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 1113,
        "unique-3-nopunct": 998,
        "entropy-3-nopunct": 10.03090059760439,
        "cond_entropy-3-nopunct": 0.1962272121797285,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.12010848508330105,
            "2": 0.26380368098159507,
            "3": 0.3657844990548204
        },
        "nist": 0.19385508343737398,
        "rouge1": {
            "precision": 0.24504,
            "recall": 0.14708,
            "fmeasure": 0.1756
        },
        "rouge2": {
            "precision": 0.1183,
            "recall": 0.06261,
            "fmeasure": 0.07569
        },
        "rougeL": {
            "precision": 0.23356,
            "recall": 0.13766,
            "fmeasure": 0.16531
        },
        "rougeLsum": {
            "precision": 0.23356,
            "recall": 0.13766,
            "fmeasure": 0.16531
        },
        "bleu": 10.29245,
        "nubia": {
            "semantic_relation": 3.21781,
            "contradiction": 24.08345,
            "irrelevancy": 22.80771,
            "logical_agreement": 53.10883,
            "grammar_ref": 2.5384,
            "grammar_hyp": 2.71436,
            "nubia_score": 0.57495
        },
        "bleurt": -0.04221,
        "meteor": 0.283708707584938,
        "bertscore": {
            "precision": 0.93592,
            "recall": 0.87171,
            "f1": 0.90204
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 56,
        "msttr-100": 0.68667,
        "msttr-100_nopunct": 0.78,
        "total_length": 654,
        "mean_pred_length": 11.678571428571429,
        "std_pred_length": 2.7717139028376785,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.5657492354740061,
        "vocab_size-1": 370,
        "unique-1": 275,
        "entropy-1": 7.7660332792461615,
        "distinct-2": 0.8712374581939799,
        "vocab_size-2": 521,
        "unique-2": 466,
        "entropy-2": 8.932081231003517,
        "cond_entropy-2": 1.2680754805910788,
        "distinct-3": 0.9501845018450185,
        "vocab_size-3": 515,
        "unique-3": 490,
        "entropy-3": 8.979732482305346,
        "cond_entropy-3": 0.06935343270048969,
        "total_length-nopunct": 567,
        "mean_pred_length-nopunct": 10.125,
        "std_pred_length-nopunct": 2.1469455046647083,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6419753086419753,
        "vocab_size-1-nopunct": 364,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 8.032905342757283,
        "distinct-2-nopunct": 0.8884540117416829,
        "vocab_size-2-nopunct": 454,
        "unique-2-nopunct": 410,
        "entropy-2-nopunct": 8.752004896759258,
        "cond_entropy-2-nopunct": 0.7978379492522314,
        "distinct-3-nopunct": 0.9494505494505494,
        "vocab_size-3-nopunct": 432,
        "unique-3-nopunct": 410,
        "entropy-3-nopunct": 8.726964740575815,
        "cond_entropy-3-nopunct": 0.000739572858285127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.08999081726354453,
            "2": 0.18282988871224165,
            "3": 0.3474426807760141
        },
        "nist": 0.03886853083407084,
        "rouge1": {
            "precision": 0.37321,
            "recall": 0.19883,
            "fmeasure": 0.24497
        },
        "rouge2": {
            "precision": 0.15685,
            "recall": 0.10422,
            "fmeasure": 0.11836
        },
        "rougeL": {
            "precision": 0.36964,
            "recall": 0.1971,
            "fmeasure": 0.24264
        },
        "rougeLsum": {
            "precision": 0.36964,
            "recall": 0.1971,
            "fmeasure": 0.24264
        },
        "bleu": 6.83783,
        "nubia": {
            "semantic_relation": 3.04666,
            "contradiction": 21.03414,
            "irrelevancy": 23.32446,
            "logical_agreement": 55.64139,
            "grammar_ref": 2.50981,
            "grammar_hyp": 2.64719,
            "nubia_score": 0.61065
        },
        "bleurt": -0.05443,
        "meteor": 0.2535542906484708,
        "bertscore": {
            "precision": 0.9392,
            "recall": 0.86347,
            "f1": 0.89888
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.57,
        "msttr-100_nopunct": 0.54,
        "total_length": 211,
        "mean_pred_length": 11.105263157894736,
        "std_pred_length": 2.1495345112275936,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.5023696682464455,
        "vocab_size-1": 106,
        "unique-1": 70,
        "entropy-1": 6.136648675950235,
        "distinct-2": 0.6770833333333334,
        "vocab_size-2": 130,
        "unique-2": 98,
        "entropy-2": 6.773117172695505,
        "cond_entropy-2": 0.7238780365759718,
        "distinct-3": 0.7398843930635838,
        "vocab_size-3": 128,
        "unique-3": 105,
        "entropy-3": 6.787229383706092,
        "cond_entropy-3": 0.0570316401001188,
        "total_length-nopunct": 191,
        "mean_pred_length-nopunct": 10.052631578947368,
        "std_pred_length-nopunct": 1.9323747105985072,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.5287958115183246,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.1310351014349695,
        "distinct-2-nopunct": 0.6802325581395349,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.617430943779033,
        "cond_entropy-2-nopunct": 0.5687188232192422,
        "distinct-3-nopunct": 0.738562091503268,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.603793071450808,
        "cond_entropy-3-nopunct": 0.0345179604007744,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.10847457627118644,
            "2": 0.18421052631578946,
            "3": 0.33663366336633666
        },
        "nist": 0.006005325138696626,
        "rouge1": {
            "precision": 0.44737,
            "recall": 0.21564,
            "fmeasure": 0.28162
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.12554,
            "fmeasure": 0.1674
        },
        "rougeL": {
            "precision": 0.44737,
            "recall": 0.21564,
            "fmeasure": 0.28162
        },
        "rougeLsum": {
            "precision": 0.44737,
            "recall": 0.21564,
            "fmeasure": 0.28162
        },
        "bleu": 4.62626,
        "nubia": {
            "semantic_relation": 2.9883,
            "contradiction": 25.67274,
            "irrelevancy": 23.09093,
            "logical_agreement": 51.23633,
            "grammar_ref": 2.51721,
            "grammar_hyp": 2.68333,
            "nubia_score": 0.5831
        },
        "bleurt": 0.01813,
        "meteor": 0.26235889056545764,
        "bertscore": {
            "precision": 0.94562,
            "recall": 0.85841,
            "f1": 0.89899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 49,
        "msttr-100": 0.70125,
        "msttr-100_nopunct": 0.75429,
        "total_length": 889,
        "mean_pred_length": 18.142857142857142,
        "std_pred_length": 5.329930887479323,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.5376827896512936,
        "vocab_size-1": 478,
        "unique-1": 393,
        "entropy-1": 7.825396540439114,
        "distinct-2": 0.905952380952381,
        "vocab_size-2": 761,
        "unique-2": 715,
        "entropy-2": 9.454897139635827,
        "cond_entropy-2": 1.4720747977794417,
        "distinct-3": 0.9696586599241467,
        "vocab_size-3": 767,
        "unique-3": 748,
        "entropy-3": 9.561459722012046,
        "cond_entropy-3": 0.11757152109104282,
        "total_length-nopunct": 774,
        "mean_pred_length-nopunct": 15.795918367346939,
        "std_pred_length-nopunct": 4.5623999763673195,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6072351421188631,
        "vocab_size-1-nopunct": 470,
        "unique-1-nopunct": 391,
        "entropy-1-nopunct": 8.028996585109129,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 667,
        "unique-2-nopunct": 636,
        "entropy-2-nopunct": 9.269640133121351,
        "cond_entropy-2-nopunct": 1.3229234294307386,
        "distinct-3-nopunct": 0.9792899408284024,
        "vocab_size-3-nopunct": 662,
        "unique-3-nopunct": 651,
        "entropy-3-nopunct": 9.356109225473869,
        "cond_entropy-3-nopunct": 0.10034136385712783,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2422680412371134,
            "2": 0.4682080924855491,
            "3": 0.7874762808349146
        },
        "nist": 7.2300831874569464,
        "rouge1": {
            "precision": 0.75952,
            "recall": 0.72524,
            "fmeasure": 0.72971
        },
        "rouge2": {
            "precision": 0.5423,
            "recall": 0.50795,
            "fmeasure": 0.51536
        },
        "rougeL": {
            "precision": 0.65951,
            "recall": 0.6301,
            "fmeasure": 0.63377
        },
        "rougeLsum": {
            "precision": 0.65951,
            "recall": 0.6301,
            "fmeasure": 0.63377
        },
        "bleu": 48.23716,
        "nubia": {
            "semantic_relation": 4.25607,
            "contradiction": 8.24393,
            "irrelevancy": 23.28346,
            "logical_agreement": 68.47262,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.78417,
            "nubia_score": 0.73566
        },
        "bleurt": 0.22953,
        "meteor": 0.3823500276983553,
        "bertscore": {
            "precision": 0.9338,
            "recall": 0.9231,
            "f1": 0.92626
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 12,
        "msttr-100": 0.59,
        "msttr-100_nopunct": 0.67,
        "total_length": 140,
        "mean_pred_length": 11.666666666666666,
        "std_pred_length": 2.3213980461973533,
        "median_pred_length": 11.5,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.6,
        "vocab_size-1": 84,
        "unique-1": 60,
        "entropy-1": 5.893777218683402,
        "distinct-2": 0.875,
        "vocab_size-2": 112,
        "unique-2": 98,
        "entropy-2": 6.734375,
        "cond_entropy-2": 0.8907280832150497,
        "distinct-3": 0.9568965517241379,
        "vocab_size-3": 111,
        "unique-3": 106,
        "entropy-3": 6.7717740985758335,
        "cond_entropy-3": 0.06487754685171006,
        "total_length-nopunct": 117,
        "mean_pred_length-nopunct": 9.75,
        "std_pred_length-nopunct": 2.0052015692526606,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.071356655862335,
        "distinct-2-nopunct": 0.8857142857142857,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.466626470047067,
        "cond_entropy-2-nopunct": 0.4263761824682105,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 90,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.47464268207578,
        "cond_entropy-3-nopunct": 0.029214368710726107,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.07352941176470588,
            "2": 0.15517241379310345,
            "3": 0.27848101265822783
        },
        "nist": 0.002992373944062246,
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.12917,
            "fmeasure": 0.19246
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.06181,
            "fmeasure": 0.09861
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.12917,
            "fmeasure": 0.19246
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.12917,
            "fmeasure": 0.19246
        },
        "bleu": 3.50436,
        "nubia": {
            "semantic_relation": 2.84807,
            "contradiction": 28.08344,
            "irrelevancy": 25.54963,
            "logical_agreement": 46.36693,
            "grammar_ref": 2.55511,
            "grammar_hyp": 2.74995,
            "nubia_score": 0.64241
        },
        "bleurt": -0.02452,
        "meteor": 0.23214097888419957,
        "bertscore": {
            "precision": 0.93243,
            "recall": 0.84628,
            "f1": 0.88663
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 158,
        "msttr-100": 0.7156,
        "msttr-100_nopunct": 0.775,
        "total_length": 2598,
        "mean_pred_length": 16.443037974683545,
        "std_pred_length": 5.6696992428952555,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.4172440338722094,
        "vocab_size-1": 1084,
        "unique-1": 840,
        "entropy-1": 8.405331071833432,
        "distinct-2": 0.8057377049180328,
        "vocab_size-2": 1966,
        "unique-2": 1765,
        "entropy-2": 10.6713010965698,
        "cond_entropy-2": 2.0298626691188715,
        "distinct-3": 0.9193689745836985,
        "vocab_size-3": 2098,
        "unique-3": 2014,
        "entropy-3": 10.938062224499939,
        "cond_entropy-3": 0.27956847875646285,
        "total_length-nopunct": 2255,
        "mean_pred_length-nopunct": 14.272151898734178,
        "std_pred_length-nopunct": 4.981800719349031,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4753880266075388,
        "vocab_size-1-nopunct": 1072,
        "unique-1-nopunct": 839,
        "entropy-1-nopunct": 8.715826330221173,
        "distinct-2-nopunct": 0.8235574630424416,
        "vocab_size-2-nopunct": 1727,
        "unique-2-nopunct": 1570,
        "entropy-2-nopunct": 10.494119025389642,
        "cond_entropy-2-nopunct": 1.8972045037218017,
        "distinct-3-nopunct": 0.9236719958741619,
        "vocab_size-3-nopunct": 1791,
        "unique-3-nopunct": 1728,
        "entropy-3-nopunct": 10.709965258146456,
        "cond_entropy-3-nopunct": 0.24162184135341233,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28975265017667845,
            "2": 0.44664031620553357,
            "3": 0.730745147150908
        },
        "nist": 7.642932049456073,
        "rouge1": {
            "precision": 0.72889,
            "recall": 0.70379,
            "fmeasure": 0.70407
        },
        "rouge2": {
            "precision": 0.48429,
            "recall": 0.47201,
            "fmeasure": 0.47
        },
        "rougeL": {
            "precision": 0.62063,
            "recall": 0.60411,
            "fmeasure": 0.60224
        },
        "rougeLsum": {
            "precision": 0.62063,
            "recall": 0.60411,
            "fmeasure": 0.60224
        },
        "bleu": 41.93353,
        "nubia": {
            "semantic_relation": 4.11378,
            "contradiction": 8.16315,
            "irrelevancy": 32.3242,
            "logical_agreement": 59.51264,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.6726,
            "nubia_score": 0.70756
        },
        "bleurt": 0.19412,
        "meteor": 0.37774809163369744,
        "bertscore": {
            "precision": 0.92028,
            "recall": 0.9167,
            "f1": 0.91707
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 80,
        "msttr-100": 0.53,
        "msttr-100_nopunct": 0.52556,
        "total_length": 2026,
        "mean_pred_length": 25.325,
        "std_pred_length": 2.691537664607352,
        "median_pred_length": 26.0,
        "min_pred_length": 17,
        "max_pred_length": 31,
        "distinct-1": 0.24876604146100692,
        "vocab_size-1": 504,
        "unique-1": 264,
        "entropy-1": 7.42553704656969,
        "distinct-2": 0.5282631038026722,
        "vocab_size-2": 1028,
        "unique-2": 707,
        "entropy-2": 9.46759962988879,
        "cond_entropy-2": 2.1039578656758504,
        "distinct-3": 0.6918542336548767,
        "vocab_size-3": 1291,
        "unique-3": 1028,
        "entropy-3": 10.002304308467105,
        "cond_entropy-3": 0.5715721291671176,
        "total_length-nopunct": 1856,
        "mean_pred_length-nopunct": 23.2,
        "std_pred_length-nopunct": 2.585536694769579,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.26885775862068967,
        "vocab_size-1-nopunct": 499,
        "unique-1-nopunct": 263,
        "entropy-1-nopunct": 7.5230196288306885,
        "distinct-2-nopunct": 0.5467342342342343,
        "vocab_size-2-nopunct": 971,
        "unique-2-nopunct": 688,
        "entropy-2-nopunct": 9.40496747829264,
        "cond_entropy-2-nopunct": 1.957352126754201,
        "distinct-3-nopunct": 0.6975235849056604,
        "vocab_size-3-nopunct": 1183,
        "unique-3-nopunct": 959,
        "entropy-3-nopunct": 9.863626798105322,
        "cond_entropy-3-nopunct": 0.49845405085507066,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1449165402124431,
            "2": 0.3632707774798928,
            "3": 0.5870445344129555
        },
        "nist": 2.0837977494361644,
        "rouge1": {
            "precision": 0.74801,
            "recall": 0.46085,
            "fmeasure": 0.56293
        },
        "rouge2": {
            "precision": 0.4373,
            "recall": 0.25544,
            "fmeasure": 0.31775
        },
        "rougeL": {
            "precision": 0.56154,
            "recall": 0.34614,
            "fmeasure": 0.42221
        },
        "rougeLsum": {
            "precision": 0.56154,
            "recall": 0.34614,
            "fmeasure": 0.42221
        },
        "bleu": 24.69502,
        "nubia": {
            "semantic_relation": 3.2393,
            "contradiction": 8.76343,
            "irrelevancy": 15.30504,
            "logical_agreement": 75.93153,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.6955,
            "nubia_score": 0.36542
        },
        "bleurt": -0.45522,
        "meteor": 0.2239052607814069,
        "bertscore": {
            "precision": 0.88705,
            "recall": 0.82626,
            "f1": 0.85426
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 349,
        "msttr-100": 0.66228,
        "msttr-100_nopunct": 0.6926,
        "total_length": 5755,
        "mean_pred_length": 16.48997134670487,
        "std_pred_length": 3.9113437624213354,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.16698523023457862,
        "vocab_size-1": 961,
        "unique-1": 396,
        "entropy-1": 7.8374558781052786,
        "distinct-2": 0.4345172031076582,
        "vocab_size-2": 2349,
        "unique-2": 1440,
        "entropy-2": 10.48534826422913,
        "cond_entropy-2": 2.425321639228216,
        "distinct-3": 0.6191417836662053,
        "vocab_size-3": 3131,
        "unique-3": 2306,
        "entropy-3": 11.211124914955143,
        "cond_entropy-3": 0.8065507747449547,
        "total_length-nopunct": 5091,
        "mean_pred_length-nopunct": 14.587392550143267,
        "std_pred_length-nopunct": 3.6543276253207404,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.1871930858377529,
        "vocab_size-1-nopunct": 953,
        "unique-1-nopunct": 395,
        "entropy-1-nopunct": 8.08539637829807,
        "distinct-2-nopunct": 0.43315056938000845,
        "vocab_size-2-nopunct": 2054,
        "unique-2-nopunct": 1278,
        "entropy-2-nopunct": 10.278188656799669,
        "cond_entropy-2-nopunct": 2.379855905105529,
        "distinct-3-nopunct": 0.6184839517414068,
        "vocab_size-3-nopunct": 2717,
        "unique-3-nopunct": 2024,
        "entropy-3-nopunct": 10.989777182551562,
        "cond_entropy-3-nopunct": 0.7867929922447787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23018717642373557,
            "2": 0.5822102425876011,
            "3": 0.885850991114149,
            "4": 1.0
        },
        "nist": 9.078019570351678,
        "rouge1": {
            "precision": 0.78697,
            "recall": 0.77625,
            "fmeasure": 0.77513
        },
        "rouge2": {
            "precision": 0.55015,
            "recall": 0.54437,
            "fmeasure": 0.54176
        },
        "rougeL": {
            "precision": 0.66877,
            "recall": 0.65901,
            "fmeasure": 0.65765
        },
        "rougeLsum": {
            "precision": 0.66877,
            "recall": 0.65901,
            "fmeasure": 0.65765
        },
        "bleu": 53.26769,
        "nubia": {
            "semantic_relation": 4.62072,
            "contradiction": 5.59928,
            "irrelevancy": 5.90512,
            "logical_agreement": 88.4956,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.80057,
            "nubia_score": 0.83163
        },
        "bleurt": 0.27703,
        "meteor": 0.42284709399898085,
        "bertscore": {
            "precision": 0.93521,
            "recall": 0.93271,
            "f1": 0.93233
        }
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 1099,
        "msttr-100": 0.66637,
        "msttr-100_nopunct": 0.71625,
        "total_length": 12421,
        "mean_pred_length": 11.302092811646952,
        "std_pred_length": 2.888858013937168,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.2061025682312213,
        "vocab_size-1": 2560,
        "unique-1": 1299,
        "entropy-1": 9.145385691087604,
        "distinct-2": 0.49187422716834484,
        "vocab_size-2": 5569,
        "unique-2": 3745,
        "entropy-2": 11.753597165811744,
        "cond_entropy-2": 2.6612745685656813,
        "distinct-3": 0.6868825198082754,
        "vocab_size-3": 7022,
        "unique-3": 5475,
        "entropy-3": 12.473524910387303,
        "cond_entropy-3": 0.8334213081296274,
        "total_length-nopunct": 10483,
        "mean_pred_length-nopunct": 9.53867151956324,
        "std_pred_length-nopunct": 2.523971778757103,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.24344176285414482,
        "vocab_size-1-nopunct": 2552,
        "unique-1-nopunct": 1298,
        "entropy-1-nopunct": 9.725227208954847,
        "distinct-2-nopunct": 0.5437979539641944,
        "vocab_size-2-nopunct": 5103,
        "unique-2-nopunct": 3634,
        "entropy-2-nopunct": 11.715282254620329,
        "cond_entropy-2-nopunct": 2.205140515130596,
        "distinct-3-nopunct": 0.7217863608931805,
        "vocab_size-3-nopunct": 5980,
        "unique-3-nopunct": 4843,
        "entropy-3-nopunct": 12.26325943509831,
        "cond_entropy-3-nopunct": 0.678632371535186,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1663088593101474,
            "2": 0.35478980013783595,
            "3": 0.4835865691239917,
            "4": 0.6493506493506493,
            "5": 0.6486486486486487,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "nist": 1.7156875604776753,
        "rouge1": {
            "precision": 0.27579,
            "recall": 0.22612,
            "fmeasure": 0.23949
        },
        "rouge2": {
            "precision": 0.12713,
            "recall": 0.10012,
            "fmeasure": 0.10653
        },
        "rougeL": {
            "precision": 0.27027,
            "recall": 0.22147,
            "fmeasure": 0.23447
        },
        "rougeLsum": {
            "precision": 0.27027,
            "recall": 0.22147,
            "fmeasure": 0.23447
        },
        "bleu": 22.32948,
        "nubia": {
            "semantic_relation": 3.59819,
            "contradiction": 21.56259,
            "irrelevancy": 22.38244,
            "logical_agreement": 56.05497,
            "grammar_ref": 2.65247,
            "grammar_hyp": 2.73168,
            "nubia_score": 0.69839
        },
        "bleurt": 0.10222,
        "meteor": 0.39974292035324627,
        "bertscore": {
            "precision": 0.95096,
            "recall": 0.91357,
            "f1": 0.93103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.229871195093384,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.24291000358771483,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.1523912776298655,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.254547113768295,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7647058823529411
        },
        "nist": 3.2045944164345155,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.84211,
            "fmeasure": 0.82051
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.38889,
            "fmeasure": 0.37838
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.57895,
            "fmeasure": 0.5641
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.57895,
            "fmeasure": 0.5641
        },
        "bleu": 15.38285,
        "nubia": {
            "semantic_relation": 4.59365,
            "contradiction": 0.51287,
            "irrelevancy": 18.17297,
            "logical_agreement": 81.31416,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.67546,
            "nubia_score": 0.8138
        },
        "bleurt": 0.3208,
        "meteor": 0.3888778706320149,
        "bertscore": {
            "precision": 0.92406,
            "recall": 0.92179,
            "f1": 0.92176
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 2.0252978015663303,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.67407,
            "fmeasure": 0.71296
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.53571,
            "fmeasure": 0.56818
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.67407,
            "fmeasure": 0.71296
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.67407,
            "fmeasure": 0.71296
        },
        "bleu": 35.0844,
        "nubia": {
            "semantic_relation": 4.16312,
            "contradiction": 0.06604,
            "irrelevancy": 34.04572,
            "logical_agreement": 65.88824,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.69339,
            "nubia_score": 0.65985
        },
        "bleurt": 0.41052,
        "meteor": 0.44290451502953765,
        "bertscore": {
            "precision": 0.94095,
            "recall": 0.9582,
            "f1": 0.9495
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 41,
        "msttr-100": 0.543,
        "msttr-100_nopunct": 0.58111,
        "total_length": 1040,
        "mean_pred_length": 25.365853658536587,
        "std_pred_length": 2.4169734910902427,
        "median_pred_length": 25.0,
        "min_pred_length": 21,
        "max_pred_length": 31,
        "distinct-1": 0.3326923076923077,
        "vocab_size-1": 346,
        "unique-1": 197,
        "entropy-1": 7.215584634150079,
        "distinct-2": 0.6336336336336337,
        "vocab_size-2": 633,
        "unique-2": 456,
        "entropy-2": 8.980232649048178,
        "cond_entropy-2": 1.8125509371157449,
        "distinct-3": 0.7734864300626305,
        "vocab_size-3": 741,
        "unique-3": 613,
        "entropy-3": 9.342072881192049,
        "cond_entropy-3": 0.38753571183369456,
        "total_length-nopunct": 952,
        "mean_pred_length-nopunct": 23.21951219512195,
        "std_pred_length-nopunct": 2.0542899209020065,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.3581932773109244,
        "vocab_size-1-nopunct": 341,
        "unique-1-nopunct": 196,
        "entropy-1-nopunct": 7.279446977872047,
        "distinct-2-nopunct": 0.6575192096597146,
        "vocab_size-2-nopunct": 599,
        "unique-2-nopunct": 443,
        "entropy-2-nopunct": 8.929039850795085,
        "cond_entropy-2-nopunct": 1.7039602841237154,
        "distinct-3-nopunct": 0.7862068965517242,
        "vocab_size-3-nopunct": 684,
        "unique-3-nopunct": 573,
        "entropy-3-nopunct": 9.235831761849765,
        "cond_entropy-3-nopunct": 0.33305140322516924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1404833836858006,
            "2": 0.28316326530612246,
            "3": 0.5492170022371364
        },
        "nist": 1.4546190915531971,
        "rouge1": {
            "precision": 0.7588,
            "recall": 0.43442,
            "fmeasure": 0.54793
        },
        "rouge2": {
            "precision": 0.42681,
            "recall": 0.23605,
            "fmeasure": 0.30126
        },
        "rougeL": {
            "precision": 0.5903,
            "recall": 0.33329,
            "fmeasure": 0.42188
        },
        "rougeLsum": {
            "precision": 0.5903,
            "recall": 0.33329,
            "fmeasure": 0.42188
        },
        "bleu": 21.84008,
        "nubia": {
            "semantic_relation": 3.12703,
            "contradiction": 9.16613,
            "irrelevancy": 8.74529,
            "logical_agreement": 82.08858,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.42384,
            "nubia_score": 0.32786
        },
        "bleurt": -0.45248,
        "meteor": 0.21293610556533896,
        "bertscore": {
            "precision": 0.89138,
            "recall": 0.81548,
            "f1": 0.85018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.59,
        "msttr-100_nopunct": 0.61,
        "total_length": 548,
        "mean_pred_length": 15.657142857142857,
        "std_pred_length": 4.881117302672512,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.35036496350364965,
        "vocab_size-1": 192,
        "unique-1": 144,
        "entropy-1": 6.41668161699665,
        "distinct-2": 0.6705653021442495,
        "vocab_size-2": 344,
        "unique-2": 283,
        "entropy-2": 8.030993269133935,
        "cond_entropy-2": 1.457206350863297,
        "distinct-3": 0.799163179916318,
        "vocab_size-3": 382,
        "unique-3": 346,
        "entropy-3": 8.3108984575599,
        "cond_entropy-3": 0.30693243449596397,
        "total_length-nopunct": 466,
        "mean_pred_length-nopunct": 13.314285714285715,
        "std_pred_length-nopunct": 4.294657335882929,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4012875536480687,
        "vocab_size-1-nopunct": 187,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 6.490592743467071,
        "distinct-2-nopunct": 0.6937354988399071,
        "vocab_size-2-nopunct": 299,
        "unique-2-nopunct": 249,
        "entropy-2-nopunct": 7.8572794430710955,
        "cond_entropy-2-nopunct": 1.4411448916733272,
        "distinct-3-nopunct": 0.8005050505050505,
        "vocab_size-3-nopunct": 317,
        "unique-3-nopunct": 287,
        "entropy-3-nopunct": 8.048634974918345,
        "cond_entropy-3-nopunct": 0.25333627441906253,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21839080459770116,
            "2": 0.46153846153846156,
            "3": 0.7867435158501441
        },
        "nist": 6.685395062056192,
        "rouge1": {
            "precision": 0.79069,
            "recall": 0.76965,
            "fmeasure": 0.77381
        },
        "rouge2": {
            "precision": 0.55236,
            "recall": 0.54441,
            "fmeasure": 0.54386
        },
        "rougeL": {
            "precision": 0.68752,
            "recall": 0.66744,
            "fmeasure": 0.67172
        },
        "rougeLsum": {
            "precision": 0.68752,
            "recall": 0.66744,
            "fmeasure": 0.67172
        },
        "bleu": 53.37432,
        "nubia": {
            "semantic_relation": 4.23106,
            "contradiction": 7.90609,
            "irrelevancy": 24.31217,
            "logical_agreement": 67.78173,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.11914,
            "nubia_score": 0.78913
        },
        "bleurt": 0.4327,
        "meteor": 0.41353744801515707,
        "bertscore": {
            "precision": 0.94261,
            "recall": 0.93423,
            "f1": 0.9371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 55,
        "msttr-100": 0.7275,
        "msttr-100_nopunct": 0.78571,
        "total_length": 899,
        "mean_pred_length": 16.345454545454544,
        "std_pred_length": 5.081940151406679,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5183537263626251,
        "vocab_size-1": 466,
        "unique-1": 373,
        "entropy-1": 7.82563859483206,
        "distinct-2": 0.909952606635071,
        "vocab_size-2": 768,
        "unique-2": 720,
        "entropy-2": 9.50271082975605,
        "cond_entropy-2": 1.4553148459951741,
        "distinct-3": 0.982256020278834,
        "vocab_size-3": 775,
        "unique-3": 764,
        "entropy-3": 9.585523235885924,
        "cond_entropy-3": 0.05854130382792298,
        "total_length-nopunct": 769,
        "mean_pred_length-nopunct": 13.981818181818182,
        "std_pred_length-nopunct": 4.308515496679101,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5968790637191157,
        "vocab_size-1-nopunct": 459,
        "unique-1-nopunct": 372,
        "entropy-1-nopunct": 8.083576890485533,
        "distinct-2-nopunct": 0.9243697478991597,
        "vocab_size-2-nopunct": 660,
        "unique-2-nopunct": 627,
        "entropy-2-nopunct": 9.296084864174757,
        "cond_entropy-2-nopunct": 1.2890050851337063,
        "distinct-3-nopunct": 0.9833080424886191,
        "vocab_size-3-nopunct": 648,
        "unique-3-nopunct": 640,
        "entropy-3-nopunct": 9.327314226318272,
        "cond_entropy-3-nopunct": 0.04200818914220075,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28921568627450983,
            "2": 0.4262295081967213,
            "3": 0.7397769516728625
        },
        "nist": 7.042771484631228,
        "rouge1": {
            "precision": 0.73402,
            "recall": 0.71752,
            "fmeasure": 0.71468
        },
        "rouge2": {
            "precision": 0.50852,
            "recall": 0.49773,
            "fmeasure": 0.4948
        },
        "rougeL": {
            "precision": 0.63005,
            "recall": 0.62345,
            "fmeasure": 0.61697
        },
        "rougeLsum": {
            "precision": 0.63005,
            "recall": 0.62345,
            "fmeasure": 0.61697
        },
        "bleu": 47.67177,
        "nubia": {
            "semantic_relation": 4.14213,
            "contradiction": 7.14326,
            "irrelevancy": 35.78582,
            "logical_agreement": 57.07092,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.86598,
            "nubia_score": 0.7074
        },
        "bleurt": 0.1948,
        "meteor": 0.3901396700342415,
        "bertscore": {
            "precision": 0.92168,
            "recall": 0.9231,
            "f1": 0.92147
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.8,
        "total_length": 168,
        "mean_pred_length": 15.272727272727273,
        "std_pred_length": 4.672762645780508,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6726190476190477,
        "vocab_size-1": 113,
        "unique-1": 96,
        "entropy-1": 6.309057604584304,
        "distinct-2": 0.9490445859872612,
        "vocab_size-2": 149,
        "unique-2": 144,
        "entropy-2": 7.169718580264637,
        "cond_entropy-2": 0.6941776011270394,
        "distinct-3": 1.0,
        "vocab_size-3": 146,
        "unique-3": 146,
        "entropy-3": 7.18982455888002,
        "cond_entropy-3": 0.029516415977683685,
        "total_length-nopunct": 147,
        "mean_pred_length-nopunct": 13.363636363636363,
        "std_pred_length-nopunct": 3.891079010733218,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7346938775510204,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.339644272405509,
        "distinct-2-nopunct": 0.9558823529411765,
        "vocab_size-2-nopunct": 130,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 6.972686073055939,
        "cond_entropy-2-nopunct": 0.7026028947441082,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 125,
        "unique-3-nopunct": 125,
        "entropy-3-nopunct": 6.965784284662096,
        "cond_entropy-3-nopunct": 0.003198567207242006,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2037037037037037,
            "2": 0.5483870967741935,
            "3": 0.8478260869565217
        },
        "nist": 5.800677442637419,
        "rouge1": {
            "precision": 0.7675,
            "recall": 0.76364,
            "fmeasure": 0.7541
        },
        "rouge2": {
            "precision": 0.55363,
            "recall": 0.55256,
            "fmeasure": 0.54352
        },
        "rougeL": {
            "precision": 0.66369,
            "recall": 0.67302,
            "fmeasure": 0.65662
        },
        "rougeLsum": {
            "precision": 0.66369,
            "recall": 0.67302,
            "fmeasure": 0.65662
        },
        "bleu": 48.33243,
        "nubia": {
            "semantic_relation": 4.0236,
            "contradiction": 11.0717,
            "irrelevancy": 42.56795,
            "logical_agreement": 46.36035,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.54249,
            "nubia_score": 0.6835
        },
        "bleurt": 0.22877,
        "meteor": 0.4434447083334443,
        "bertscore": {
            "precision": 0.94124,
            "recall": 0.94835,
            "f1": 0.94342
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.71714,
        "msttr-100_nopunct": 0.76833,
        "total_length": 747,
        "mean_pred_length": 16.977272727272727,
        "std_pred_length": 6.039599009731284,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.5100401606425703,
        "vocab_size-1": 381,
        "unique-1": 293,
        "entropy-1": 7.605346794043947,
        "distinct-2": 0.8904694167852063,
        "vocab_size-2": 626,
        "unique-2": 568,
        "entropy-2": 9.20752491820237,
        "cond_entropy-2": 1.44158288728817,
        "distinct-3": 0.9696509863429439,
        "vocab_size-3": 639,
        "unique-3": 619,
        "entropy-3": 9.303436627693833,
        "cond_entropy-3": 0.10348934572571948,
        "total_length-nopunct": 646,
        "mean_pred_length-nopunct": 14.681818181818182,
        "std_pred_length-nopunct": 5.5052566915330505,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5804953560371517,
        "vocab_size-1-nopunct": 375,
        "unique-1-nopunct": 293,
        "entropy-1-nopunct": 7.813253856085387,
        "distinct-2-nopunct": 0.9036544850498339,
        "vocab_size-2-nopunct": 544,
        "unique-2-nopunct": 505,
        "entropy-2-nopunct": 9.004967283916292,
        "cond_entropy-2-nopunct": 1.2644749773934145,
        "distinct-3-nopunct": 0.9767025089605734,
        "vocab_size-3-nopunct": 545,
        "unique-3-nopunct": 532,
        "entropy-3-nopunct": 9.077526329750421,
        "cond_entropy-3-nopunct": 0.07848345046299861,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2079207920792079,
            "2": 0.488,
            "3": 0.7818574514038877
        },
        "nist": 6.791415268924577,
        "rouge1": {
            "precision": 0.75787,
            "recall": 0.75919,
            "fmeasure": 0.74822
        },
        "rouge2": {
            "precision": 0.55892,
            "recall": 0.56768,
            "fmeasure": 0.5557
        },
        "rougeL": {
            "precision": 0.69649,
            "recall": 0.70078,
            "fmeasure": 0.68926
        },
        "rougeLsum": {
            "precision": 0.69649,
            "recall": 0.70078,
            "fmeasure": 0.68926
        },
        "bleu": 50.43538,
        "nubia": {
            "semantic_relation": 4.22414,
            "contradiction": 9.13385,
            "irrelevancy": 23.80922,
            "logical_agreement": 67.05694,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.55211,
            "nubia_score": 0.75871
        },
        "bleurt": 0.32237,
        "meteor": 0.40812114511124187,
        "bertscore": {
            "precision": 0.92466,
            "recall": 0.93038,
            "f1": 0.92608
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.71333,
        "msttr-100_nopunct": 0.745,
        "total_length": 315,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.163977794943222,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5873015873015873,
        "vocab_size-1": 185,
        "unique-1": 151,
        "entropy-1": 6.847448036291013,
        "distinct-2": 0.8945578231292517,
        "vocab_size-2": 263,
        "unique-2": 250,
        "entropy-2": 7.911084134447496,
        "cond_entropy-2": 0.8733245257968957,
        "distinct-3": 0.9597069597069597,
        "vocab_size-3": 262,
        "unique-3": 257,
        "entropy-3": 7.985726807773761,
        "cond_entropy-3": 0.05431561084906901,
        "total_length-nopunct": 280,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 5.055250296034367,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6428571428571429,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 149,
        "entropy-1-nopunct": 6.931939474130218,
        "distinct-2-nopunct": 0.8996138996138996,
        "vocab_size-2-nopunct": 233,
        "unique-2-nopunct": 222,
        "entropy-2-nopunct": 7.741768544907074,
        "cond_entropy-2-nopunct": 0.8582251090960986,
        "distinct-3-nopunct": 0.9747899159663865,
        "vocab_size-3-nopunct": 232,
        "unique-3-nopunct": 229,
        "entropy-3-nopunct": 7.829231038625481,
        "cond_entropy-3-nopunct": 0.06295070432308567,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2028985507246377,
            "2": 0.3584905660377358,
            "3": 0.7606382978723404
        },
        "nist": 5.2603608440912,
        "rouge1": {
            "precision": 0.70505,
            "recall": 0.71978,
            "fmeasure": 0.70063
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.46786,
            "fmeasure": 0.45988
        },
        "rougeL": {
            "precision": 0.59298,
            "recall": 0.62213,
            "fmeasure": 0.59682
        },
        "rougeLsum": {
            "precision": 0.59298,
            "recall": 0.62213,
            "fmeasure": 0.59682
        },
        "bleu": 36.11915,
        "nubia": {
            "semantic_relation": 3.82384,
            "contradiction": 7.4989,
            "irrelevancy": 49.20334,
            "logical_agreement": 43.29776,
            "grammar_ref": 4.80447,
            "grammar_hyp": 5.00759,
            "nubia_score": 0.60252
        },
        "bleurt": 0.09631,
        "meteor": 0.35121374962923374,
        "bertscore": {
            "precision": 0.91221,
            "recall": 0.91067,
            "f1": 0.90935
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.72,
        "total_length": 122,
        "mean_pred_length": 17.428571428571427,
        "std_pred_length": 5.0950155714648595,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.6639344262295082,
        "vocab_size-1": 81,
        "unique-1": 63,
        "entropy-1": 6.041021456874498,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 110,
        "unique-2": 105,
        "entropy-2": 6.758533529205258,
        "cond_entropy-2": 0.6230187998070211,
        "distinct-3": 0.9907407407407407,
        "vocab_size-3": 107,
        "unique-3": 106,
        "entropy-3": 6.736368983644939,
        "cond_entropy-3": -0.016528474706832406,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 15.285714285714286,
        "std_pred_length-nopunct": 4.266624149448022,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7102803738317757,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.991180304742318,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 96,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.5638561897747385,
        "cond_entropy-2-nopunct": 0.599346327741305,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 93,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.539158811108037,
        "cond_entropy-3-nopunct": -0.018675873290349414,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3448275862068966,
            "2": 0.7391304347826086,
            "3": 0.5263157894736842
        },
        "nist": 3.5836631808367865,
        "rouge1": {
            "precision": 0.58319,
            "recall": 0.66692,
            "fmeasure": 0.59733
        },
        "rouge2": {
            "precision": 0.26986,
            "recall": 0.32219,
            "fmeasure": 0.28113
        },
        "rougeL": {
            "precision": 0.43501,
            "recall": 0.51465,
            "fmeasure": 0.45241
        },
        "rougeLsum": {
            "precision": 0.43501,
            "recall": 0.51465,
            "fmeasure": 0.45241
        },
        "bleu": 15.93642,
        "nubia": {
            "semantic_relation": 3.73149,
            "contradiction": 14.52016,
            "irrelevancy": 24.43016,
            "logical_agreement": 61.04968,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.25203,
            "nubia_score": 0.62088
        },
        "bleurt": 0.11109,
        "meteor": 0.28807193736273506,
        "bertscore": {
            "precision": 0.89226,
            "recall": 0.9111,
            "f1": 0.89996
        }
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.69635,
        "msttr-100_nopunct": 0.74089,
        "total_length": 5215,
        "mean_pred_length": 17.383333333333333,
        "std_pred_length": 5.021592266292525,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.35627996164908915,
        "vocab_size-1": 1858,
        "unique-1": 1479,
        "entropy-1": 8.509299838402251,
        "distinct-2": 0.7257375381485249,
        "vocab_size-2": 3567,
        "unique-2": 3166,
        "entropy-2": 11.256532824051783,
        "cond_entropy-2": 2.538191695729119,
        "distinct-3": 0.8923076923076924,
        "vocab_size-3": 4118,
        "unique-3": 3899,
        "entropy-3": 11.863000750058221,
        "cond_entropy-3": 0.6311267221688497,
        "total_length-nopunct": 4589,
        "mean_pred_length-nopunct": 15.296666666666667,
        "std_pred_length-nopunct": 4.717554686723008,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4024842013510569,
        "vocab_size-1-nopunct": 1847,
        "unique-1-nopunct": 1475,
        "entropy-1-nopunct": 8.817267753910068,
        "distinct-2-nopunct": 0.7418978782933084,
        "vocab_size-2-nopunct": 3182,
        "unique-2-nopunct": 2868,
        "entropy-2-nopunct": 11.084120995117978,
        "cond_entropy-2-nopunct": 2.419001234433415,
        "distinct-3-nopunct": 0.9072449235397343,
        "vocab_size-3-nopunct": 3619,
        "unique-3-nopunct": 3447,
        "entropy-3-nopunct": 11.697474525811925,
        "cond_entropy-3-nopunct": 0.6709484018754401,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22020431328036322,
            "2": 0.3686440677966102,
            "3": 0.7754604550379198
        },
        "nist": 8.448160689158957,
        "rouge1": {
            "precision": 0.78816,
            "recall": 0.75285,
            "fmeasure": 0.76177
        },
        "rouge2": {
            "precision": 0.53929,
            "recall": 0.51757,
            "fmeasure": 0.52198
        },
        "rougeL": {
            "precision": 0.66728,
            "recall": 0.63963,
            "fmeasure": 0.64559
        },
        "rougeLsum": {
            "precision": 0.66728,
            "recall": 0.63963,
            "fmeasure": 0.64559
        },
        "bleu": 43.8951,
        "nubia": {
            "semantic_relation": 4.37633,
            "contradiction": 4.71369,
            "irrelevancy": 26.15269,
            "logical_agreement": 69.13363,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.92853,
            "nubia_score": 0.7624
        },
        "bleurt": 0.29461,
        "meteor": 0.38920563568658423,
        "bertscore": {
            "precision": 0.93668,
            "recall": 0.93117,
            "f1": 0.93268
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.72833,
        "msttr-100_nopunct": 0.76333,
        "total_length": 690,
        "mean_pred_length": 16.046511627906977,
        "std_pred_length": 5.356819120249824,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.5231884057971015,
        "vocab_size-1": 361,
        "unique-1": 287,
        "entropy-1": 7.504199191412917,
        "distinct-2": 0.8995363214837713,
        "vocab_size-2": 582,
        "unique-2": 537,
        "entropy-2": 9.098567357169566,
        "cond_entropy-2": 1.3976037197942826,
        "distinct-3": 0.9652317880794702,
        "vocab_size-3": 583,
        "unique-3": 566,
        "entropy-3": 9.163057429715224,
        "cond_entropy-3": 0.059985677557854944,
        "total_length-nopunct": 606,
        "mean_pred_length-nopunct": 14.093023255813954,
        "std_pred_length-nopunct": 4.74862992964934,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5825082508250825,
        "vocab_size-1-nopunct": 353,
        "unique-1-nopunct": 285,
        "entropy-1-nopunct": 7.656411837859994,
        "distinct-2-nopunct": 0.9147424511545293,
        "vocab_size-2-nopunct": 515,
        "unique-2-nopunct": 484,
        "entropy-2-nopunct": 8.927553451337335,
        "cond_entropy-2-nopunct": 1.343832799931778,
        "distinct-3-nopunct": 0.9769230769230769,
        "vocab_size-3-nopunct": 508,
        "unique-3-nopunct": 498,
        "entropy-3-nopunct": 8.973310553404868,
        "cond_entropy-3-nopunct": 0.041368846360453106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.44360902255639095,
            "3": 0.8018867924528302
        },
        "nist": 6.692353790214471,
        "rouge1": {
            "precision": 0.76994,
            "recall": 0.77384,
            "fmeasure": 0.76414
        },
        "rouge2": {
            "precision": 0.57194,
            "recall": 0.57744,
            "fmeasure": 0.56755
        },
        "rougeL": {
            "precision": 0.69783,
            "recall": 0.69695,
            "fmeasure": 0.69106
        },
        "rougeLsum": {
            "precision": 0.69783,
            "recall": 0.69695,
            "fmeasure": 0.69106
        },
        "bleu": 47.74851,
        "nubia": {
            "semantic_relation": 4.20815,
            "contradiction": 5.69804,
            "irrelevancy": 29.57569,
            "logical_agreement": 64.72627,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.51815,
            "nubia_score": 0.74262
        },
        "bleurt": 0.28726,
        "meteor": 0.39609972741878036,
        "bertscore": {
            "precision": 0.92951,
            "recall": 0.93326,
            "f1": 0.92905
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 33,
        "msttr-100": 0.716,
        "msttr-100_nopunct": 0.755,
        "total_length": 557,
        "mean_pred_length": 16.87878787878788,
        "std_pred_length": 4.212230214416945,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.5493716337522442,
        "vocab_size-1": 306,
        "unique-1": 266,
        "entropy-1": 7.232271299751064,
        "distinct-2": 0.9083969465648855,
        "vocab_size-2": 476,
        "unique-2": 445,
        "entropy-2": 8.810152546461728,
        "cond_entropy-2": 1.4037697344175526,
        "distinct-3": 0.9775967413441955,
        "vocab_size-3": 480,
        "unique-3": 470,
        "entropy-3": 8.893235247915232,
        "cond_entropy-3": 0.08840457012014331,
        "total_length-nopunct": 481,
        "mean_pred_length-nopunct": 14.575757575757576,
        "std_pred_length-nopunct": 3.9545164285478354,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6237006237006237,
        "vocab_size-1-nopunct": 300,
        "unique-1-nopunct": 265,
        "entropy-1-nopunct": 7.388624985126721,
        "distinct-2-nopunct": 0.9084821428571429,
        "vocab_size-2-nopunct": 407,
        "unique-2-nopunct": 382,
        "entropy-2-nopunct": 8.579143245813098,
        "cond_entropy-2-nopunct": 1.2888038014314518,
        "distinct-3-nopunct": 0.980722891566265,
        "vocab_size-3-nopunct": 407,
        "unique-3-nopunct": 400,
        "entropy-3-nopunct": 8.656594303337545,
        "cond_entropy-3-nopunct": 0.09559801009322325,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1625,
            "2": 0.2537313432835821,
            "3": 0.8097560975609757
        },
        "nist": 7.222873639167556,
        "rouge1": {
            "precision": 0.80959,
            "recall": 0.79029,
            "fmeasure": 0.78974
        },
        "rouge2": {
            "precision": 0.60011,
            "recall": 0.58879,
            "fmeasure": 0.58713
        },
        "rougeL": {
            "precision": 0.68665,
            "recall": 0.67018,
            "fmeasure": 0.6701
        },
        "rougeLsum": {
            "precision": 0.68665,
            "recall": 0.67018,
            "fmeasure": 0.6701
        },
        "bleu": 54.07013,
        "nubia": {
            "semantic_relation": 4.53167,
            "contradiction": 2.90351,
            "irrelevancy": 20.03489,
            "logical_agreement": 77.0616,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.89483,
            "nubia_score": 0.81501
        },
        "bleurt": 0.38026,
        "meteor": 0.4156924520238333,
        "bertscore": {
            "precision": 0.94373,
            "recall": 0.93371,
            "f1": 0.9372
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.72846,
        "msttr-100_nopunct": 0.75455,
        "total_length": 1345,
        "mean_pred_length": 17.025316455696203,
        "std_pred_length": 5.580197091805996,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.441635687732342,
        "vocab_size-1": 594,
        "unique-1": 458,
        "entropy-1": 7.880052946496223,
        "distinct-2": 0.7898894154818326,
        "vocab_size-2": 1000,
        "unique-2": 909,
        "entropy-2": 9.647216827026062,
        "cond_entropy-2": 1.6029619736056886,
        "distinct-3": 0.8946925021061499,
        "vocab_size-3": 1062,
        "unique-3": 1020,
        "entropy-3": 9.884405217989434,
        "cond_entropy-3": 0.25913341550397617,
        "total_length-nopunct": 1184,
        "mean_pred_length-nopunct": 14.987341772151899,
        "std_pred_length-nopunct": 5.120061488174283,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.49493243243243246,
        "vocab_size-1-nopunct": 586,
        "unique-1-nopunct": 458,
        "entropy-1-nopunct": 8.069761028964948,
        "distinct-2-nopunct": 0.8009049773755657,
        "vocab_size-2-nopunct": 885,
        "unique-2-nopunct": 809,
        "entropy-2-nopunct": 9.47973708137883,
        "cond_entropy-2-nopunct": 1.5146437479979775,
        "distinct-3-nopunct": 0.8957115009746589,
        "vocab_size-3-nopunct": 919,
        "unique-3-nopunct": 882,
        "entropy-3-nopunct": 9.679119141185588,
        "cond_entropy-3-nopunct": 0.2337734235130318,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17813765182186234,
            "2": 0.48188405797101447,
            "3": 0.7554038680318543
        },
        "nist": 7.071722912347127,
        "rouge1": {
            "precision": 0.75206,
            "recall": 0.71468,
            "fmeasure": 0.72408
        },
        "rouge2": {
            "precision": 0.54287,
            "recall": 0.51206,
            "fmeasure": 0.52077
        },
        "rougeL": {
            "precision": 0.64978,
            "recall": 0.62058,
            "fmeasure": 0.62707
        },
        "rougeLsum": {
            "precision": 0.64978,
            "recall": 0.62058,
            "fmeasure": 0.62707
        },
        "bleu": 48.41643,
        "nubia": {
            "semantic_relation": 4.09181,
            "contradiction": 11.42777,
            "irrelevancy": 28.40777,
            "logical_agreement": 60.16446,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.47315,
            "nubia_score": 0.70182
        },
        "bleurt": 0.21793,
        "meteor": 0.37796559323054585,
        "bertscore": {
            "precision": 0.92359,
            "recall": 0.92166,
            "f1": 0.92101
        }
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.706,
        "msttr-100_nopunct": 0.75235,
        "total_length": 2050,
        "mean_pred_length": 16.015625,
        "std_pred_length": 5.45719761960065,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.3858536585365854,
        "vocab_size-1": 791,
        "unique-1": 612,
        "entropy-1": 7.9349252039639735,
        "distinct-2": 0.7663891779396462,
        "vocab_size-2": 1473,
        "unique-2": 1305,
        "entropy-2": 10.14767059272129,
        "cond_entropy-2": 1.9837616355795402,
        "distinct-3": 0.9297658862876255,
        "vocab_size-3": 1668,
        "unique-3": 1594,
        "entropy-3": 10.621598894828736,
        "cond_entropy-3": 0.3972012935936381,
        "total_length-nopunct": 1793,
        "mean_pred_length-nopunct": 14.0078125,
        "std_pred_length-nopunct": 5.082900398871077,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.43558282208588955,
        "vocab_size-1-nopunct": 781,
        "unique-1-nopunct": 609,
        "entropy-1-nopunct": 8.206673197974979,
        "distinct-2-nopunct": 0.7981981981981981,
        "vocab_size-2-nopunct": 1329,
        "unique-2-nopunct": 1200,
        "entropy-2-nopunct": 10.048877970971665,
        "cond_entropy-2-nopunct": 1.8384791276472374,
        "distinct-3-nopunct": 0.9440468445022772,
        "vocab_size-3-nopunct": 1451,
        "unique-3-nopunct": 1395,
        "entropy-3-nopunct": 10.449554743475657,
        "cond_entropy-3-nopunct": 0.3792272158067848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1696969696969697,
            "2": 0.3388704318936877,
            "3": 0.7664184157075152
        },
        "nist": 7.428513462996571,
        "rouge1": {
            "precision": 0.77952,
            "recall": 0.74987,
            "fmeasure": 0.75549
        },
        "rouge2": {
            "precision": 0.51947,
            "recall": 0.51177,
            "fmeasure": 0.50942
        },
        "rougeL": {
            "precision": 0.66782,
            "recall": 0.64766,
            "fmeasure": 0.64993
        },
        "rougeLsum": {
            "precision": 0.66782,
            "recall": 0.64766,
            "fmeasure": 0.64993
        },
        "bleu": 43.99951,
        "nubia": {
            "semantic_relation": 4.38966,
            "contradiction": 4.86134,
            "irrelevancy": 27.09226,
            "logical_agreement": 68.0464,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.24214,
            "nubia_score": 0.81106
        },
        "bleurt": 0.34594,
        "meteor": 0.39257294889248906,
        "bertscore": {
            "precision": 0.93312,
            "recall": 0.93128,
            "f1": 0.93051
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 30,
        "msttr-100": 0.694,
        "msttr-100_nopunct": 0.7475,
        "total_length": 511,
        "mean_pred_length": 17.033333333333335,
        "std_pred_length": 5.369564435056369,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5714285714285714,
        "vocab_size-1": 292,
        "unique-1": 233,
        "entropy-1": 7.325829583783838,
        "distinct-2": 0.9085239085239085,
        "vocab_size-2": 437,
        "unique-2": 410,
        "entropy-2": 8.677359879129773,
        "cond_entropy-2": 1.176935671487676,
        "distinct-3": 0.975609756097561,
        "vocab_size-3": 440,
        "unique-3": 430,
        "entropy-3": 8.766529327241644,
        "cond_entropy-3": 0.1011229595054707,
        "total_length-nopunct": 454,
        "mean_pred_length-nopunct": 15.133333333333333,
        "std_pred_length-nopunct": 4.745055906473132,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6277533039647577,
        "vocab_size-1-nopunct": 285,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 7.449862809471008,
        "distinct-2-nopunct": 0.9056603773584906,
        "vocab_size-2-nopunct": 384,
        "unique-2-nopunct": 361,
        "entropy-2-nopunct": 8.482994814393525,
        "cond_entropy-2-nopunct": 1.0936008545375784,
        "distinct-3-nopunct": 0.9771573604060914,
        "vocab_size-3-nopunct": 385,
        "unique-3-nopunct": 377,
        "entropy-3-nopunct": 8.574450582141287,
        "cond_entropy-3-nopunct": 0.10354410963703357,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19387755102040816,
            "2": 0.35514018691588783,
            "3": 0.8059701492537313
        },
        "nist": 6.441423400902337,
        "rouge1": {
            "precision": 0.74303,
            "recall": 0.7286,
            "fmeasure": 0.72687
        },
        "rouge2": {
            "precision": 0.53397,
            "recall": 0.52103,
            "fmeasure": 0.52108
        },
        "rougeL": {
            "precision": 0.63041,
            "recall": 0.61954,
            "fmeasure": 0.61727
        },
        "rougeLsum": {
            "precision": 0.63041,
            "recall": 0.61954,
            "fmeasure": 0.61727
        },
        "bleu": 48.30826,
        "nubia": {
            "semantic_relation": 4.03117,
            "contradiction": 16.30281,
            "irrelevancy": 29.91852,
            "logical_agreement": 53.77867,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.87867,
            "nubia_score": 0.65404
        },
        "bleurt": 0.17366,
        "meteor": 0.4005028902961963,
        "bertscore": {
            "precision": 0.9299,
            "recall": 0.92509,
            "f1": 0.92501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.71923,
        "msttr-100_nopunct": 0.76091,
        "total_length": 1367,
        "mean_pred_length": 17.0875,
        "std_pred_length": 5.64843728388658,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.46964155084125825,
        "vocab_size-1": 642,
        "unique-1": 497,
        "entropy-1": 8.006025185004153,
        "distinct-2": 0.8578088578088578,
        "vocab_size-2": 1104,
        "unique-2": 1008,
        "entropy-2": 9.939481681615534,
        "cond_entropy-2": 1.7505650532454848,
        "distinct-3": 0.9627174813587407,
        "vocab_size-3": 1162,
        "unique-3": 1129,
        "entropy-3": 10.1487155581756,
        "cond_entropy-3": 0.22453651535599156,
        "total_length-nopunct": 1199,
        "mean_pred_length-nopunct": 14.9875,
        "std_pred_length-nopunct": 4.781458328794678,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5287739783152627,
        "vocab_size-1-nopunct": 634,
        "unique-1-nopunct": 495,
        "entropy-1-nopunct": 8.232658861154146,
        "distinct-2-nopunct": 0.870420017873101,
        "vocab_size-2-nopunct": 974,
        "unique-2-nopunct": 901,
        "entropy-2-nopunct": 9.758431340161808,
        "cond_entropy-2-nopunct": 1.6309023973570984,
        "distinct-3-nopunct": 0.9643888354186718,
        "vocab_size-3-nopunct": 1002,
        "unique-3-nopunct": 976,
        "entropy-3-nopunct": 9.934302502512553,
        "cond_entropy-3-nopunct": 0.2008760477833502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.211864406779661,
            "2": 0.4502923976608187,
            "3": 0.7283311772315654
        },
        "nist": 6.9208092020560725,
        "rouge1": {
            "precision": 0.70083,
            "recall": 0.68337,
            "fmeasure": 0.68011
        },
        "rouge2": {
            "precision": 0.45417,
            "recall": 0.45848,
            "fmeasure": 0.44585
        },
        "rougeL": {
            "precision": 0.61311,
            "recall": 0.61454,
            "fmeasure": 0.60162
        },
        "rougeLsum": {
            "precision": 0.61311,
            "recall": 0.61454,
            "fmeasure": 0.60162
        },
        "bleu": 41.1669,
        "nubia": {
            "semantic_relation": 3.99822,
            "contradiction": 10.1832,
            "irrelevancy": 35.40467,
            "logical_agreement": 54.41213,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.5522,
            "nubia_score": 0.66141
        },
        "bleurt": 0.15304,
        "meteor": 0.35292853713046657,
        "bertscore": {
            "precision": 0.91589,
            "recall": 0.91208,
            "f1": 0.91169
        }
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.6945,
        "msttr-100_nopunct": 0.74278,
        "total_length": 2074,
        "mean_pred_length": 16.203125,
        "std_pred_length": 5.397278502576553,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.42430086788813887,
        "vocab_size-1": 880,
        "unique-1": 700,
        "entropy-1": 8.18500476399708,
        "distinct-2": 0.8340184994861254,
        "vocab_size-2": 1623,
        "unique-2": 1481,
        "entropy-2": 10.430352626795056,
        "cond_entropy-2": 2.0216896978755874,
        "distinct-3": 0.9559955995599559,
        "vocab_size-3": 1738,
        "unique-3": 1692,
        "entropy-3": 10.717301934181092,
        "cond_entropy-3": 0.26759997199331415,
        "total_length-nopunct": 1818,
        "mean_pred_length-nopunct": 14.203125,
        "std_pred_length-nopunct": 5.03946824916826,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4812981298129813,
        "vocab_size-1-nopunct": 875,
        "unique-1-nopunct": 700,
        "entropy-1-nopunct": 8.503374555504054,
        "distinct-2-nopunct": 0.855621301775148,
        "vocab_size-2-nopunct": 1446,
        "unique-2-nopunct": 1344,
        "entropy-2-nopunct": 10.27339099534324,
        "cond_entropy-2-nopunct": 1.8456155577509046,
        "distinct-3-nopunct": 0.969270166453265,
        "vocab_size-3-nopunct": 1514,
        "unique-3-nopunct": 1486,
        "entropy-3-nopunct": 10.533795507692318,
        "cond_entropy-3-nopunct": 0.262914630196039,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1887905604719764,
            "2": 0.32653061224489793,
            "3": 0.8063427800269906
        },
        "nist": 7.86705597308283,
        "rouge1": {
            "precision": 0.78716,
            "recall": 0.77623,
            "fmeasure": 0.77304
        },
        "rouge2": {
            "precision": 0.55014,
            "recall": 0.54268,
            "fmeasure": 0.54045
        },
        "rougeL": {
            "precision": 0.67213,
            "recall": 0.66345,
            "fmeasure": 0.6604
        },
        "rougeLsum": {
            "precision": 0.67213,
            "recall": 0.66345,
            "fmeasure": 0.6604
        },
        "bleu": 46.43616,
        "nubia": {
            "semantic_relation": 4.45154,
            "contradiction": 5.14609,
            "irrelevancy": 23.74379,
            "logical_agreement": 71.11012,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.59136,
            "nubia_score": 0.8086
        },
        "bleurt": 0.34372,
        "meteor": 0.40587424619135837,
        "bertscore": {
            "precision": 0.93242,
            "recall": 0.93349,
            "f1": 0.93157
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 103,
        "msttr-100": 0.71471,
        "msttr-100_nopunct": 0.74933,
        "total_length": 1754,
        "mean_pred_length": 17.02912621359223,
        "std_pred_length": 5.550223140235014,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.4412770809578107,
        "vocab_size-1": 774,
        "unique-1": 619,
        "entropy-1": 8.067386104563129,
        "distinct-2": 0.8201090248334343,
        "vocab_size-2": 1354,
        "unique-2": 1248,
        "entropy-2": 10.113824767006658,
        "cond_entropy-2": 1.827250622468164,
        "distinct-3": 0.915374677002584,
        "vocab_size-3": 1417,
        "unique-3": 1367,
        "entropy-3": 10.341523466517604,
        "cond_entropy-3": 0.22560074682360207,
        "total_length-nopunct": 1541,
        "mean_pred_length-nopunct": 14.96116504854369,
        "std_pred_length-nopunct": 5.378710875432592,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4970798182998053,
        "vocab_size-1-nopunct": 766,
        "unique-1-nopunct": 616,
        "entropy-1-nopunct": 8.301523643116848,
        "distinct-2-nopunct": 0.8261474269819193,
        "vocab_size-2-nopunct": 1188,
        "unique-2-nopunct": 1107,
        "entropy-2-nopunct": 9.915515354907797,
        "cond_entropy-2-nopunct": 1.7276938132169426,
        "distinct-3-nopunct": 0.9123595505617977,
        "vocab_size-3-nopunct": 1218,
        "unique-3-nopunct": 1178,
        "entropy-3-nopunct": 10.112426542426412,
        "cond_entropy-3-nopunct": 0.23404324434947069,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17378048780487804,
            "2": 0.4107744107744108,
            "3": 0.8069395017793595
        },
        "nist": 7.7519556202453535,
        "rouge1": {
            "precision": 0.75349,
            "recall": 0.74356,
            "fmeasure": 0.74001
        },
        "rouge2": {
            "precision": 0.53998,
            "recall": 0.53307,
            "fmeasure": 0.53012
        },
        "rougeL": {
            "precision": 0.66439,
            "recall": 0.65583,
            "fmeasure": 0.65193
        },
        "rougeLsum": {
            "precision": 0.66439,
            "recall": 0.65583,
            "fmeasure": 0.65193
        },
        "bleu": 51.23004,
        "nubia": {
            "semantic_relation": 4.18054,
            "contradiction": 11.44341,
            "irrelevancy": 23.4835,
            "logical_agreement": 65.07309,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.61864,
            "nubia_score": 0.72206
        },
        "bleurt": 0.25545,
        "meteor": 0.40524110670274593,
        "bertscore": {
            "precision": 0.93182,
            "recall": 0.92806,
            "f1": 0.92876
        }
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 45,
        "msttr-100": 0.67429,
        "msttr-100_nopunct": 0.70833,
        "total_length": 730,
        "mean_pred_length": 16.22222222222222,
        "std_pred_length": 4.525919864213677,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.4575342465753425,
        "vocab_size-1": 334,
        "unique-1": 257,
        "entropy-1": 7.235324026202714,
        "distinct-2": 0.8,
        "vocab_size-2": 548,
        "unique-2": 476,
        "entropy-2": 8.85720430411202,
        "cond_entropy-2": 1.4423937605318555,
        "distinct-3": 0.93125,
        "vocab_size-3": 596,
        "unique-3": 561,
        "entropy-3": 9.169155536276712,
        "cond_entropy-3": 0.3161880428336734,
        "total_length-nopunct": 656,
        "mean_pred_length-nopunct": 14.577777777777778,
        "std_pred_length-nopunct": 4.509194995359242,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5015243902439024,
        "vocab_size-1-nopunct": 329,
        "unique-1-nopunct": 254,
        "entropy-1-nopunct": 7.383578608178095,
        "distinct-2-nopunct": 0.8019639934533551,
        "vocab_size-2-nopunct": 490,
        "unique-2-nopunct": 428,
        "entropy-2-nopunct": 8.686905418374364,
        "cond_entropy-2-nopunct": 1.3743925751380326,
        "distinct-3-nopunct": 0.9328621908127208,
        "vocab_size-3-nopunct": 528,
        "unique-3-nopunct": 498,
        "entropy-3-nopunct": 8.99444702373535,
        "cond_entropy-3-nopunct": 0.3315040202009427,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18,
            "2": 0.4921875,
            "3": 0.7793522267206477
        },
        "nist": 7.015199314399804,
        "rouge1": {
            "precision": 0.77749,
            "recall": 0.74664,
            "fmeasure": 0.75142
        },
        "rouge2": {
            "precision": 0.53703,
            "recall": 0.52377,
            "fmeasure": 0.52253
        },
        "rougeL": {
            "precision": 0.65047,
            "recall": 0.62437,
            "fmeasure": 0.628
        },
        "rougeLsum": {
            "precision": 0.65047,
            "recall": 0.62437,
            "fmeasure": 0.628
        },
        "bleu": 43.71079,
        "nubia": {
            "semantic_relation": 4.36243,
            "contradiction": 3.38786,
            "irrelevancy": 26.87583,
            "logical_agreement": 69.73632,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.89043,
            "nubia_score": 0.76998
        },
        "bleurt": 0.34336,
        "meteor": 0.40100190368309496,
        "bertscore": {
            "precision": 0.93781,
            "recall": 0.93336,
            "f1": 0.93494
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_backtranslation": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_test_asset_backtranslation",
        "N": 359,
        "msttr-100": 0.72673,
        "msttr-100_nopunct": 0.76367,
        "total_length": 5548,
        "mean_pred_length": 15.454038997214484,
        "std_pred_length": 6.278803632174206,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.38590483056957464,
        "vocab_size-1": 2141,
        "unique-1": 1617,
        "entropy-1": 8.957731437004814,
        "distinct-2": 0.8398535363268452,
        "vocab_size-2": 4358,
        "unique-2": 4053,
        "entropy-2": 11.77129673600684,
        "cond_entropy-2": 2.5617687873015464,
        "distinct-3": 0.9604554865424431,
        "vocab_size-3": 4639,
        "unique-3": 4569,
        "entropy-3": 12.081635751661247,
        "cond_entropy-3": 0.34098566901794064,
        "total_length-nopunct": 4928,
        "mean_pred_length-nopunct": 13.727019498607243,
        "std_pred_length-nopunct": 5.637925671720287,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.43262987012987014,
        "vocab_size-1-nopunct": 2132,
        "unique-1-nopunct": 1617,
        "entropy-1-nopunct": 9.279497482088193,
        "distinct-2-nopunct": 0.8664915736485007,
        "vocab_size-2-nopunct": 3959,
        "unique-2-nopunct": 3701,
        "entropy-2-nopunct": 11.731756607562719,
        "cond_entropy-2-nopunct": 2.6228010987022183,
        "distinct-3-nopunct": 0.9838479809976247,
        "vocab_size-3-nopunct": 4142,
        "unique-3-nopunct": 4086,
        "entropy-3-nopunct": 12.00503233861334,
        "cond_entropy-3-nopunct": 0.30302899445426446,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_backtranslation.json",
        "local_recall": {
            "1": 0.04657004830917874,
            "2": 0.11469780219780219,
            "3": 0.19460726846424384,
            "4": 0.273371104815864,
            "5": 0.3293492695883134,
            "6": 0.39655172413793105,
            "7": 0.4554794520547945,
            "8": 0.5694444444444444,
            "9": 0.7143884892086331
        },
        "nist": 7.487268053605685,
        "rouge1": {
            "precision": 0.68104,
            "recall": 0.59568,
            "fmeasure": 0.62142
        },
        "rouge2": {
            "precision": 0.44546,
            "recall": 0.38661,
            "fmeasure": 0.40031
        },
        "rougeL": {
            "precision": 0.62364,
            "recall": 0.55099,
            "fmeasure": 0.57188
        },
        "rougeLsum": {
            "precision": 0.62364,
            "recall": 0.55099,
            "fmeasure": 0.57188
        },
        "bleu": 38.75474,
        "sari": 42.18746,
        "nubia": {
            "semantic_relation": 3.32699,
            "contradiction": 13.21324,
            "irrelevancy": 31.80673,
            "logical_agreement": 54.98003,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.37192,
            "nubia_score": 0.428
        },
        "bleurt": -0.25271,
        "meteor": 0.3051683200335298,
        "bertscore": {
            "precision": 0.90188,
            "recall": 0.89047,
            "f1": 0.89153
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 66,
        "msttr-100": 0.742,
        "msttr-100_nopunct": 0.80111,
        "total_length": 1035,
        "mean_pred_length": 15.681818181818182,
        "std_pred_length": 6.108015327393131,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.5043478260869565,
        "vocab_size-1": 522,
        "unique-1": 430,
        "entropy-1": 7.8738705785786856,
        "distinct-2": 0.8833849329205367,
        "vocab_size-2": 856,
        "unique-2": 798,
        "entropy-2": 9.60069711033382,
        "cond_entropy-2": 1.5085298476449582,
        "distinct-3": 0.9700996677740864,
        "vocab_size-3": 876,
        "unique-3": 861,
        "entropy-3": 9.735737620108612,
        "cond_entropy-3": 0.10851064418274418,
        "total_length-nopunct": 906,
        "mean_pred_length-nopunct": 13.727272727272727,
        "std_pred_length-nopunct": 5.389511291009868,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5673289183222958,
        "vocab_size-1-nopunct": 514,
        "unique-1-nopunct": 426,
        "entropy-1-nopunct": 8.111028659536759,
        "distinct-2-nopunct": 0.905952380952381,
        "vocab_size-2-nopunct": 761,
        "unique-2-nopunct": 718,
        "entropy-2-nopunct": 9.463731774511396,
        "cond_entropy-2-nopunct": 1.3950570935322097,
        "distinct-3-nopunct": 0.9832041343669251,
        "vocab_size-3-nopunct": 761,
        "unique-3-nopunct": 751,
        "entropy-3-nopunct": 9.559038738699801,
        "cond_entropy-3-nopunct": 0.05975161437335409,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20398009950248755,
            "2": 0.45408163265306123,
            "3": 0.7456896551724138
        },
        "nist": 6.670231134433339,
        "rouge1": {
            "precision": 0.7565,
            "recall": 0.71418,
            "fmeasure": 0.72473
        },
        "rouge2": {
            "precision": 0.53319,
            "recall": 0.50745,
            "fmeasure": 0.51244
        },
        "rougeL": {
            "precision": 0.66591,
            "recall": 0.63193,
            "fmeasure": 0.63915
        },
        "rougeLsum": {
            "precision": 0.66591,
            "recall": 0.63193,
            "fmeasure": 0.63915
        },
        "bleu": 42.01057,
        "nubia": {
            "semantic_relation": 4.16742,
            "contradiction": 6.94609,
            "irrelevancy": 34.3258,
            "logical_agreement": 58.72811,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.5355,
            "nubia_score": 0.72108
        },
        "bleurt": 0.19715,
        "meteor": 0.37899519807209664,
        "bertscore": {
            "precision": 0.92314,
            "recall": 0.91843,
            "f1": 0.91932
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 73,
        "msttr-100": 0.71917,
        "msttr-100_nopunct": 0.762,
        "total_length": 1226,
        "mean_pred_length": 16.794520547945204,
        "std_pred_length": 5.702580295830976,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.47471451876019577,
        "vocab_size-1": 582,
        "unique-1": 446,
        "entropy-1": 7.93285348546032,
        "distinct-2": 0.8508239375542064,
        "vocab_size-2": 981,
        "unique-2": 882,
        "entropy-2": 9.774617606603842,
        "cond_entropy-2": 1.6441265536811485,
        "distinct-3": 0.9416666666666667,
        "vocab_size-3": 1017,
        "unique-3": 960,
        "entropy-3": 9.955501198894694,
        "cond_entropy-3": 0.17510046078298347,
        "total_length-nopunct": 1053,
        "mean_pred_length-nopunct": 14.424657534246576,
        "std_pred_length-nopunct": 5.090732402077968,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5441595441595442,
        "vocab_size-1-nopunct": 573,
        "unique-1-nopunct": 445,
        "entropy-1-nopunct": 8.184348124048068,
        "distinct-2-nopunct": 0.8642857142857143,
        "vocab_size-2-nopunct": 847,
        "unique-2-nopunct": 772,
        "entropy-2-nopunct": 9.564093263705576,
        "cond_entropy-2-nopunct": 1.4699379958557248,
        "distinct-3-nopunct": 0.9503858875413451,
        "vocab_size-3-nopunct": 862,
        "unique-3-nopunct": 822,
        "entropy-3-nopunct": 9.721028572384778,
        "cond_entropy-3-nopunct": 0.16817650084739108,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30697674418604654,
            "2": 0.5,
            "3": 0.7757575757575758
        },
        "nist": 7.779325791336687,
        "rouge1": {
            "precision": 0.79508,
            "recall": 0.76763,
            "fmeasure": 0.77306
        },
        "rouge2": {
            "precision": 0.58227,
            "recall": 0.57058,
            "fmeasure": 0.57034
        },
        "rougeL": {
            "precision": 0.70249,
            "recall": 0.68825,
            "fmeasure": 0.68773
        },
        "rougeLsum": {
            "precision": 0.70249,
            "recall": 0.68825,
            "fmeasure": 0.68773
        },
        "bleu": 53.16119,
        "nubia": {
            "semantic_relation": 4.21629,
            "contradiction": 7.5332,
            "irrelevancy": 29.72651,
            "logical_agreement": 62.74029,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.64625,
            "nubia_score": 0.74089
        },
        "bleurt": 0.30197,
        "meteor": 0.4133896164219757,
        "bertscore": {
            "precision": 0.94179,
            "recall": 0.93428,
            "f1": 0.93688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 136,
        "msttr-100": 0.65762,
        "msttr-100_nopunct": 0.695,
        "total_length": 2155,
        "mean_pred_length": 15.845588235294118,
        "std_pred_length": 4.609578704225564,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.3763341067285383,
        "vocab_size-1": 811,
        "unique-1": 629,
        "entropy-1": 7.739681700578914,
        "distinct-2": 0.721644378405151,
        "vocab_size-2": 1457,
        "unique-2": 1320,
        "entropy-2": 9.861021305093386,
        "cond_entropy-2": 1.8976199425741165,
        "distinct-3": 0.8268720127456187,
        "vocab_size-3": 1557,
        "unique-3": 1482,
        "entropy-3": 10.203707559732392,
        "cond_entropy-3": 0.3967692427252198,
        "total_length-nopunct": 1881,
        "mean_pred_length-nopunct": 13.830882352941176,
        "std_pred_length-nopunct": 4.073867845359406,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4274322169059011,
        "vocab_size-1-nopunct": 804,
        "unique-1-nopunct": 628,
        "entropy-1-nopunct": 8.002090974764696,
        "distinct-2-nopunct": 0.729512893982808,
        "vocab_size-2-nopunct": 1273,
        "unique-2-nopunct": 1172,
        "entropy-2-nopunct": 9.650331689812134,
        "cond_entropy-2-nopunct": 1.8085539101463848,
        "distinct-3-nopunct": 0.8328154133001865,
        "vocab_size-3-nopunct": 1340,
        "unique-3-nopunct": 1285,
        "entropy-3-nopunct": 9.992062926780433,
        "cond_entropy-3-nopunct": 0.40980825209922567,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2831168831168831,
            "2": 0.4577922077922078,
            "3": 0.7808792742498255
        },
        "nist": 7.823958192646222,
        "rouge1": {
            "precision": 0.7604,
            "recall": 0.75284,
            "fmeasure": 0.74898
        },
        "rouge2": {
            "precision": 0.54984,
            "recall": 0.54591,
            "fmeasure": 0.54168
        },
        "rougeL": {
            "precision": 0.67534,
            "recall": 0.67168,
            "fmeasure": 0.66568
        },
        "rougeLsum": {
            "precision": 0.67534,
            "recall": 0.67168,
            "fmeasure": 0.66568
        },
        "bleu": 50.70314,
        "nubia": {
            "semantic_relation": 4.19289,
            "contradiction": 6.57185,
            "irrelevancy": 28.72204,
            "logical_agreement": 64.70612,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.50496,
            "nubia_score": 0.74166
        },
        "bleurt": 0.31956,
        "meteor": 0.4032788767767491,
        "bertscore": {
            "precision": 0.93376,
            "recall": 0.93,
            "f1": 0.9307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.5714285714285714
        },
        "nist": 1.8081452092099328,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.42857,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.52083,
            "recall": 0.33889,
            "fmeasure": 0.4087
        },
        "rougeL": {
            "precision": 0.58824,
            "recall": 0.43651,
            "fmeasure": 0.49903
        },
        "rougeLsum": {
            "precision": 0.58824,
            "recall": 0.43651,
            "fmeasure": 0.49903
        },
        "bleu": 31.48301,
        "nubia": {
            "semantic_relation": 3.47534,
            "contradiction": 2.57929,
            "irrelevancy": 10.56858,
            "logical_agreement": 86.85213,
            "grammar_ref": 3.5675,
            "grammar_hyp": 4.87024,
            "nubia_score": 0.41113
        },
        "bleurt": -0.41189,
        "meteor": 0.22944830926836596,
        "bertscore": {
            "precision": 0.92701,
            "recall": 0.8705,
            "f1": 0.89608
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 64,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 1111,
        "mean_pred_length": 17.359375,
        "std_pred_length": 5.418046198527196,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.49054905490549056,
        "vocab_size-1": 545,
        "unique-1": 429,
        "entropy-1": 7.831452930248114,
        "distinct-2": 0.8968481375358166,
        "vocab_size-2": 939,
        "unique-2": 870,
        "entropy-2": 9.76117936838858,
        "cond_entropy-2": 1.7497068698983733,
        "distinct-3": 0.9847405900305188,
        "vocab_size-3": 968,
        "unique-3": 953,
        "entropy-3": 9.910528786401835,
        "cond_entropy-3": 0.1540091936434004,
        "total_length-nopunct": 969,
        "mean_pred_length-nopunct": 15.140625,
        "std_pred_length-nopunct": 4.990200357638458,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5552115583075335,
        "vocab_size-1-nopunct": 538,
        "unique-1-nopunct": 428,
        "entropy-1-nopunct": 8.086232700930877,
        "distinct-2-nopunct": 0.907182320441989,
        "vocab_size-2-nopunct": 821,
        "unique-2-nopunct": 770,
        "entropy-2-nopunct": 9.566992183754715,
        "cond_entropy-2-nopunct": 1.5753496755435294,
        "distinct-3-nopunct": 0.990487514863258,
        "vocab_size-3-nopunct": 833,
        "unique-3-nopunct": 825,
        "entropy-3-nopunct": 9.696937019981526,
        "cond_entropy-3-nopunct": 0.14576651884957723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20085470085470086,
            "2": 0.44493392070484583,
            "3": 0.7538461538461538
        },
        "nist": 7.007762730743973,
        "rouge1": {
            "precision": 0.74538,
            "recall": 0.71813,
            "fmeasure": 0.72249
        },
        "rouge2": {
            "precision": 0.4898,
            "recall": 0.48125,
            "fmeasure": 0.47974
        },
        "rougeL": {
            "precision": 0.60654,
            "recall": 0.59264,
            "fmeasure": 0.59253
        },
        "rougeLsum": {
            "precision": 0.60654,
            "recall": 0.59264,
            "fmeasure": 0.59253
        },
        "bleu": 42.67872,
        "nubia": {
            "semantic_relation": 4.17104,
            "contradiction": 11.37598,
            "irrelevancy": 29.6547,
            "logical_agreement": 58.96932,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.69356,
            "nubia_score": 0.7082
        },
        "bleurt": 0.21236,
        "meteor": 0.37386704979231444,
        "bertscore": {
            "precision": 0.9244,
            "recall": 0.92049,
            "f1": 0.92059
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 83,
        "msttr-100": 0.72143,
        "msttr-100_nopunct": 0.78333,
        "total_length": 1435,
        "mean_pred_length": 17.289156626506024,
        "std_pred_length": 5.205488578117708,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.48501742160278744,
        "vocab_size-1": 696,
        "unique-1": 562,
        "entropy-1": 8.086933521240725,
        "distinct-2": 0.8764792899408284,
        "vocab_size-2": 1185,
        "unique-2": 1095,
        "entropy-2": 10.067935892735662,
        "cond_entropy-2": 1.7999196765459817,
        "distinct-3": 0.9700551615445232,
        "vocab_size-3": 1231,
        "unique-3": 1201,
        "entropy-3": 10.24366880852664,
        "cond_entropy-3": 0.16708411645283777,
        "total_length-nopunct": 1223,
        "mean_pred_length-nopunct": 14.734939759036145,
        "std_pred_length-nopunct": 4.5524634860207005,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.562551103843009,
        "vocab_size-1-nopunct": 688,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 8.404240688886055,
        "distinct-2-nopunct": 0.9008771929824562,
        "vocab_size-2-nopunct": 1027,
        "unique-2-nopunct": 969,
        "entropy-2-nopunct": 9.876795252564353,
        "cond_entropy-2-nopunct": 1.5590208449751177,
        "distinct-3-nopunct": 0.978240302743614,
        "vocab_size-3-nopunct": 1034,
        "unique-3-nopunct": 1017,
        "entropy-3-nopunct": 9.996563824107477,
        "cond_entropy-3-nopunct": 0.13686970407708635,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1935483870967742,
            "2": 0.5,
            "3": 0.7564102564102564
        },
        "nist": 7.413865894664847,
        "rouge1": {
            "precision": 0.7539,
            "recall": 0.71169,
            "fmeasure": 0.72111
        },
        "rouge2": {
            "precision": 0.51694,
            "recall": 0.48576,
            "fmeasure": 0.49383
        },
        "rougeL": {
            "precision": 0.63862,
            "recall": 0.60554,
            "fmeasure": 0.61267
        },
        "rougeLsum": {
            "precision": 0.63862,
            "recall": 0.60554,
            "fmeasure": 0.61267
        },
        "bleu": 47.62845,
        "nubia": {
            "semantic_relation": 4.22391,
            "contradiction": 12.94955,
            "irrelevancy": 24.69991,
            "logical_agreement": 62.35054,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.73548,
            "nubia_score": 0.7087
        },
        "bleurt": 0.25373,
        "meteor": 0.3811368466341015,
        "bertscore": {
            "precision": 0.92801,
            "recall": 0.92396,
            "f1": 0.92471
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 131,
        "msttr-100": 0.73952,
        "msttr-100_nopunct": 0.77944,
        "total_length": 2151,
        "mean_pred_length": 16.419847328244273,
        "std_pred_length": 5.7716789445781504,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.4686192468619247,
        "vocab_size-1": 1008,
        "unique-1": 817,
        "entropy-1": 8.41256080332958,
        "distinct-2": 0.8678217821782178,
        "vocab_size-2": 1753,
        "unique-2": 1617,
        "entropy-2": 10.595192396536175,
        "cond_entropy-2": 1.9328244599318292,
        "distinct-3": 0.9666490206458443,
        "vocab_size-3": 1826,
        "unique-3": 1785,
        "entropy-3": 10.805837200780468,
        "cond_entropy-3": 0.2172905309487791,
        "total_length-nopunct": 1891,
        "mean_pred_length-nopunct": 14.435114503816793,
        "std_pred_length-nopunct": 5.391680383081057,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5267054468535166,
        "vocab_size-1-nopunct": 996,
        "unique-1-nopunct": 813,
        "entropy-1-nopunct": 8.682516575152114,
        "distinct-2-nopunct": 0.8795454545454545,
        "vocab_size-2-nopunct": 1548,
        "unique-2-nopunct": 1447,
        "entropy-2-nopunct": 10.412780478956831,
        "cond_entropy-2-nopunct": 1.832900346804576,
        "distinct-3-nopunct": 0.9760589318600368,
        "vocab_size-3-nopunct": 1590,
        "unique-3-nopunct": 1561,
        "entropy-3-nopunct": 10.61635188913428,
        "cond_entropy-3-nopunct": 0.22247382063273186,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23342175066312998,
            "2": 0.4831730769230769,
            "3": 0.7103786816269285
        },
        "nist": 7.397478292627519,
        "rouge1": {
            "precision": 0.73942,
            "recall": 0.69456,
            "fmeasure": 0.70471
        },
        "rouge2": {
            "precision": 0.49008,
            "recall": 0.46046,
            "fmeasure": 0.4672
        },
        "rougeL": {
            "precision": 0.62702,
            "recall": 0.58586,
            "fmeasure": 0.59545
        },
        "rougeLsum": {
            "precision": 0.62702,
            "recall": 0.58586,
            "fmeasure": 0.59545
        },
        "bleu": 40.39929,
        "nubia": {
            "semantic_relation": 4.12589,
            "contradiction": 9.48214,
            "irrelevancy": 29.75908,
            "logical_agreement": 60.75878,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.80637,
            "nubia_score": 0.67848
        },
        "bleurt": 0.17585,
        "meteor": 0.3706110170142918,
        "bertscore": {
            "precision": 0.92161,
            "recall": 0.91638,
            "f1": 0.91777
        }
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.7124,
        "msttr-100_nopunct": 0.76636,
        "total_length": 2530,
        "mean_pred_length": 16.866666666666667,
        "std_pred_length": 4.931080566727292,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.424901185770751,
        "vocab_size-1": 1075,
        "unique-1": 861,
        "entropy-1": 8.347713249761673,
        "distinct-2": 0.795798319327731,
        "vocab_size-2": 1894,
        "unique-2": 1699,
        "entropy-2": 10.577363729610543,
        "cond_entropy-2": 2.0222780465852717,
        "distinct-3": 0.9237668161434978,
        "vocab_size-3": 2060,
        "unique-3": 1968,
        "entropy-3": 10.926772475155047,
        "cond_entropy-3": 0.36864969589751345,
        "total_length-nopunct": 2216,
        "mean_pred_length-nopunct": 14.773333333333333,
        "std_pred_length-nopunct": 4.6161263221690785,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.48194945848375453,
        "vocab_size-1-nopunct": 1068,
        "unique-1-nopunct": 859,
        "entropy-1-nopunct": 8.664386460606472,
        "distinct-2-nopunct": 0.808809293320426,
        "vocab_size-2-nopunct": 1671,
        "unique-2-nopunct": 1525,
        "entropy-2-nopunct": 10.388808668496841,
        "cond_entropy-2-nopunct": 1.835436027985039,
        "distinct-3-nopunct": 0.9384133611691023,
        "vocab_size-3-nopunct": 1798,
        "unique-3-nopunct": 1736,
        "entropy-3-nopunct": 10.742582873446121,
        "cond_entropy-3-nopunct": 0.37883987871776176,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22172949002217296,
            "2": 0.4864864864864865,
            "3": 0.7915234822451317
        },
        "nist": 8.306371661778545,
        "rouge1": {
            "precision": 0.80149,
            "recall": 0.77844,
            "fmeasure": 0.78153
        },
        "rouge2": {
            "precision": 0.57601,
            "recall": 0.56785,
            "fmeasure": 0.56594
        },
        "rougeL": {
            "precision": 0.68229,
            "recall": 0.66953,
            "fmeasure": 0.669
        },
        "rougeLsum": {
            "precision": 0.68229,
            "recall": 0.66953,
            "fmeasure": 0.669
        },
        "bleu": 47.06086,
        "nubia": {
            "semantic_relation": 4.43851,
            "contradiction": 6.79935,
            "irrelevancy": 23.07775,
            "logical_agreement": 70.1229,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.21894,
            "nubia_score": 0.77329
        },
        "bleurt": 0.35235,
        "meteor": 0.40664233783132175,
        "bertscore": {
            "precision": 0.94665,
            "recall": 0.94187,
            "f1": 0.94304
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 162,
        "mean_pred_length": 13.5,
        "std_pred_length": 5.454356057317857,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 108,
        "unique-1": 87,
        "entropy-1": 6.349988828015423,
        "distinct-2": 0.9466666666666667,
        "vocab_size-2": 142,
        "unique-2": 135,
        "entropy-2": 7.1171194404814395,
        "cond_entropy-2": 0.5926278544221547,
        "distinct-3": 0.9710144927536232,
        "vocab_size-3": 134,
        "unique-3": 130,
        "entropy-3": 7.0505534422854135,
        "cond_entropy-3": -0.0568530199339185,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 4.6067583203617515,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7357142857142858,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.395040248948752,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 120,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 6.869102441389348,
        "cond_entropy-2-nopunct": 0.5116474519402499,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.789015477886177,
        "cond_entropy-3-nopunct": -0.0751665264055014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.6071428571428571,
            "3": 0.75
        },
        "nist": 5.3027246742627545,
        "rouge1": {
            "precision": 0.76053,
            "recall": 0.74459,
            "fmeasure": 0.73733
        },
        "rouge2": {
            "precision": 0.53837,
            "recall": 0.49861,
            "fmeasure": 0.50837
        },
        "rougeL": {
            "precision": 0.64506,
            "recall": 0.61612,
            "fmeasure": 0.61846
        },
        "rougeLsum": {
            "precision": 0.64506,
            "recall": 0.61612,
            "fmeasure": 0.61846
        },
        "bleu": 43.78802,
        "nubia": {
            "semantic_relation": 4.33048,
            "contradiction": 10.4266,
            "irrelevancy": 24.32181,
            "logical_agreement": 65.25159,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.27455,
            "nubia_score": 0.78502
        },
        "bleurt": 0.24009,
        "meteor": 0.3883450059875107,
        "bertscore": {
            "precision": 0.92366,
            "recall": 0.92164,
            "f1": 0.92004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.190149853831488,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.9011,
            "fmeasure": 0.76613
        },
        "rouge2": {
            "precision": 0.43137,
            "recall": 0.59829,
            "fmeasure": 0.50115
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.60073,
            "fmeasure": 0.51075
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.60073,
            "fmeasure": 0.51075
        },
        "bleu": 30.29914,
        "nubia": {
            "semantic_relation": 4.99816,
            "contradiction": 0.33648,
            "irrelevancy": 95.02052,
            "logical_agreement": 4.64299,
            "grammar_ref": 5.12321,
            "grammar_hyp": 3.9945,
            "nubia_score": 0.98845
        },
        "bleurt": 0.38065,
        "meteor": 0.468852052219599,
        "bertscore": {
            "precision": 0.91088,
            "recall": 0.94794,
            "f1": 0.92904
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.74,
        "total_length": 158,
        "mean_pred_length": 15.8,
        "std_pred_length": 5.7758116312774614,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.620253164556962,
        "vocab_size-1": 98,
        "unique-1": 74,
        "entropy-1": 6.243892912608315,
        "distinct-2": 0.8716216216216216,
        "vocab_size-2": 129,
        "unique-2": 118,
        "entropy-2": 6.911891879025518,
        "cond_entropy-2": 0.5468472998138808,
        "distinct-3": 0.9130434782608695,
        "vocab_size-3": 126,
        "unique-3": 120,
        "entropy-3": 6.9017902175536685,
        "cond_entropy-3": -0.0030319885295708986,
        "total_length-nopunct": 145,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 5.408326913195984,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6620689655172414,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.276923207208816,
        "distinct-2-nopunct": 0.8666666666666667,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.765414856181899,
        "cond_entropy-2-nopunct": 0.540564677329089,
        "distinct-3-nopunct": 0.904,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 107,
        "entropy-3-nopunct": 6.73754968455825,
        "cond_entropy-3-nopunct": -0.002953112354128457,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.5454545454545454,
            "3": 0.9150943396226415
        },
        "nist": 5.664871910910593,
        "rouge1": {
            "precision": 0.81096,
            "recall": 0.92425,
            "fmeasure": 0.85298
        },
        "rouge2": {
            "precision": 0.7339,
            "recall": 0.83476,
            "fmeasure": 0.76718
        },
        "rougeL": {
            "precision": 0.7683,
            "recall": 0.8622,
            "fmeasure": 0.80253
        },
        "rougeLsum": {
            "precision": 0.7683,
            "recall": 0.8622,
            "fmeasure": 0.80253
        },
        "bleu": 63.88325,
        "nubia": {
            "semantic_relation": 4.61981,
            "contradiction": 1.19826,
            "irrelevancy": 34.56754,
            "logical_agreement": 64.2342,
            "grammar_ref": 5.03704,
            "grammar_hyp": 4.76773,
            "nubia_score": 0.88511
        },
        "bleurt": 0.5917,
        "meteor": 0.5063963695480628,
        "bertscore": {
            "precision": 0.95195,
            "recall": 0.96305,
            "f1": 0.95653
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.755,
        "msttr-100_nopunct": 0.75,
        "total_length": 203,
        "mean_pred_length": 16.916666666666668,
        "std_pred_length": 5.908444991892725,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6551724137931034,
        "vocab_size-1": 133,
        "unique-1": 110,
        "entropy-1": 6.587822374001706,
        "distinct-2": 0.9581151832460733,
        "vocab_size-2": 183,
        "unique-2": 175,
        "entropy-2": 7.493659194527896,
        "cond_entropy-2": 0.7996110695802624,
        "distinct-3": 0.9888268156424581,
        "vocab_size-3": 177,
        "unique-3": 175,
        "entropy-3": 7.461469408549164,
        "cond_entropy-3": -0.02657394462624082,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 4.9518515055818595,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7485380116959064,
        "vocab_size-1-nopunct": 128,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.719267065140855,
        "distinct-2-nopunct": 0.9559748427672956,
        "vocab_size-2-nopunct": 152,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.224832640818916,
        "cond_entropy-2-nopunct": 0.5357420718807219,
        "distinct-3-nopunct": 0.9931972789115646,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.1860669026594834,
        "cond_entropy-3-nopunct": -0.03838067847520166,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.35,
            "3": 0.7307692307692307
        },
        "nist": 5.1012826724728075,
        "rouge1": {
            "precision": 0.70863,
            "recall": 0.67332,
            "fmeasure": 0.67392
        },
        "rouge2": {
            "precision": 0.45553,
            "recall": 0.44249,
            "fmeasure": 0.43837
        },
        "rougeL": {
            "precision": 0.59914,
            "recall": 0.56145,
            "fmeasure": 0.56822
        },
        "rougeLsum": {
            "precision": 0.59914,
            "recall": 0.56145,
            "fmeasure": 0.56822
        },
        "bleu": 33.52125,
        "nubia": {
            "semantic_relation": 4.05075,
            "contradiction": 4.62386,
            "irrelevancy": 30.56206,
            "logical_agreement": 64.81408,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.51144,
            "nubia_score": 0.71251
        },
        "bleurt": 0.11619,
        "meteor": 0.3291493240978753,
        "bertscore": {
            "precision": 0.91573,
            "recall": 0.91939,
            "f1": 0.91682
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.75
        },
        "nist": 3.5716744810816268,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.56746,
            "fmeasure": 0.58263
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33571,
            "fmeasure": 0.27303
        },
        "rougeL": {
            "precision": 0.4359,
            "recall": 0.52778,
            "fmeasure": 0.45472
        },
        "rougeLsum": {
            "precision": 0.4359,
            "recall": 0.52778,
            "fmeasure": 0.45472
        },
        "bleu": 17.92446,
        "nubia": {
            "semantic_relation": 3.78933,
            "contradiction": 6.80065,
            "irrelevancy": 91.20654,
            "logical_agreement": 1.99281,
            "grammar_ref": 5.89248,
            "grammar_hyp": 6.19489,
            "nubia_score": 0.45182
        },
        "bleurt": -0.19717,
        "meteor": 0.3065222695394499,
        "bertscore": {
            "precision": 0.88269,
            "recall": 0.92328,
            "f1": 0.88428
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 10.333333333333334,
        "std_pred_length": 3.2489314482696545,
        "median_pred_length": 10.5,
        "min_pred_length": 6,
        "max_pred_length": 15,
        "distinct-1": 0.7741935483870968,
        "vocab_size-1": 48,
        "unique-1": 42,
        "entropy-1": 5.334738698184185,
        "distinct-2": 0.9642857142857143,
        "vocab_size-2": 54,
        "unique-2": 52,
        "entropy-2": 5.735926350629037,
        "cond_entropy-2": 0.16677008353181927,
        "distinct-3": 0.98,
        "vocab_size-3": 49,
        "unique-3": 48,
        "entropy-3": 5.603856189774728,
        "cond_entropy-3": -0.12349873228287957,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.8284271247461903,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8518518518518519,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.407574770641922,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.5016291673878275,
        "cond_entropy-2-nopunct": 0.11663515485275987,
        "distinct-3-nopunct": 0.9761904761904762,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.344698375159714,
        "cond_entropy-3-nopunct": -0.1688355541328719,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6666666666666666,
            "3": 0.7575757575757576
        },
        "nist": 4.247724798276637,
        "rouge1": {
            "precision": 0.7088,
            "recall": 0.69048,
            "fmeasure": 0.68165
        },
        "rouge2": {
            "precision": 0.37664,
            "recall": 0.37108,
            "fmeasure": 0.36735
        },
        "rougeL": {
            "precision": 0.63254,
            "recall": 0.61111,
            "fmeasure": 0.61046
        },
        "rougeLsum": {
            "precision": 0.63254,
            "recall": 0.61111,
            "fmeasure": 0.61046
        },
        "bleu": 37.04483,
        "nubia": {
            "semantic_relation": 4.09374,
            "contradiction": 0.9265,
            "irrelevancy": 35.14316,
            "logical_agreement": 63.93034,
            "grammar_ref": 5.1808,
            "grammar_hyp": 5.65876,
            "nubia_score": 0.65127
        },
        "bleurt": 0.19692,
        "meteor": 0.37766540442265345,
        "bertscore": {
            "precision": 0.9197,
            "recall": 0.90781,
            "f1": 0.91239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.73316,
        "msttr-100_nopunct": 0.78063,
        "total_length": 1907,
        "mean_pred_length": 16.728070175438596,
        "std_pred_length": 5.5175717512473845,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.4735186156266387,
        "vocab_size-1": 903,
        "unique-1": 719,
        "entropy-1": 8.383040154547249,
        "distinct-2": 0.8661461238148355,
        "vocab_size-2": 1553,
        "unique-2": 1419,
        "entropy-2": 10.440872612939257,
        "cond_entropy-2": 1.8187187492870793,
        "distinct-3": 0.9708159618820726,
        "vocab_size-3": 1630,
        "unique-3": 1586,
        "entropy-3": 10.651969352651069,
        "cond_entropy-3": 0.20913079756101746,
        "total_length-nopunct": 1671,
        "mean_pred_length-nopunct": 14.657894736842104,
        "std_pred_length-nopunct": 5.133018241699656,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5338120885697187,
        "vocab_size-1-nopunct": 892,
        "unique-1-nopunct": 715,
        "entropy-1-nopunct": 8.669961606056,
        "distinct-2-nopunct": 0.8734746307000643,
        "vocab_size-2-nopunct": 1360,
        "unique-2-nopunct": 1257,
        "entropy-2-nopunct": 10.244876573497995,
        "cond_entropy-2-nopunct": 1.66590918851514,
        "distinct-3-nopunct": 0.9722799722799723,
        "vocab_size-3-nopunct": 1403,
        "unique-3-nopunct": 1368,
        "entropy-3-nopunct": 10.435867770576325,
        "cond_entropy-3-nopunct": 0.20578077479055595,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.216,
            "2": 0.5073891625615764,
            "3": 0.7732506643046945
        },
        "nist": 7.387724210189669,
        "rouge1": {
            "precision": 0.7283,
            "recall": 0.72211,
            "fmeasure": 0.71307
        },
        "rouge2": {
            "precision": 0.47981,
            "recall": 0.47881,
            "fmeasure": 0.47144
        },
        "rougeL": {
            "precision": 0.60864,
            "recall": 0.60843,
            "fmeasure": 0.59845
        },
        "rougeLsum": {
            "precision": 0.60864,
            "recall": 0.60843,
            "fmeasure": 0.59845
        },
        "bleu": 41.38678,
        "nubia": {
            "semantic_relation": 4.15439,
            "contradiction": 6.77829,
            "irrelevancy": 31.35903,
            "logical_agreement": 61.86267,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.78656,
            "nubia_score": 0.71171
        },
        "bleurt": 0.22656,
        "meteor": 0.37220908646658357,
        "bertscore": {
            "precision": 0.92111,
            "recall": 0.91879,
            "f1": 0.91836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.72667,
        "total_length": 414,
        "mean_pred_length": 15.923076923076923,
        "std_pred_length": 4.8510353924392495,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.5676328502415459,
        "vocab_size-1": 235,
        "unique-1": 188,
        "entropy-1": 7.066424410639242,
        "distinct-2": 0.904639175257732,
        "vocab_size-2": 351,
        "unique-2": 324,
        "entropy-2": 8.371062358889489,
        "cond_entropy-2": 1.1233997103645672,
        "distinct-3": 0.9779005524861878,
        "vocab_size-3": 354,
        "unique-3": 346,
        "entropy-3": 8.455646992055566,
        "cond_entropy-3": 0.08720925351340127,
        "total_length-nopunct": 360,
        "mean_pred_length-nopunct": 13.846153846153847,
        "std_pred_length-nopunct": 4.230769230769231,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6361111111111111,
        "vocab_size-1-nopunct": 229,
        "unique-1-nopunct": 187,
        "entropy-1-nopunct": 7.187093657149327,
        "distinct-2-nopunct": 0.9191616766467066,
        "vocab_size-2-nopunct": 307,
        "unique-2-nopunct": 289,
        "entropy-2-nopunct": 8.179994412182662,
        "cond_entropy-2-nopunct": 1.0550379419113542,
        "distinct-3-nopunct": 0.9805194805194806,
        "vocab_size-3-nopunct": 302,
        "unique-3-nopunct": 296,
        "entropy-3-nopunct": 8.22782550173382,
        "cond_entropy-3-nopunct": 0.05014113626171487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25287356321839083,
            "2": 0.5268817204301075,
            "3": 0.703862660944206
        },
        "nist": 5.789430421172402,
        "rouge1": {
            "precision": 0.67943,
            "recall": 0.68701,
            "fmeasure": 0.67002
        },
        "rouge2": {
            "precision": 0.4165,
            "recall": 0.41941,
            "fmeasure": 0.40868
        },
        "rougeL": {
            "precision": 0.5852,
            "recall": 0.5999,
            "fmeasure": 0.58014
        },
        "rougeLsum": {
            "precision": 0.5852,
            "recall": 0.5999,
            "fmeasure": 0.58014
        },
        "bleu": 38.98896,
        "nubia": {
            "semantic_relation": 3.90606,
            "contradiction": 8.24304,
            "irrelevancy": 41.74845,
            "logical_agreement": 50.00851,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.64987,
            "nubia_score": 0.6567
        },
        "bleurt": 0.11728,
        "meteor": 0.3493279902996049,
        "bertscore": {
            "precision": 0.90492,
            "recall": 0.90699,
            "f1": 0.90403
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.123105625617661,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.75,
        "vocab_size-1": 42,
        "unique-1": 34,
        "entropy-1": 5.208966082694626,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 51,
        "unique-2": 50,
        "entropy-2": 5.661978179679556,
        "cond_entropy-2": 0.34519585385900586,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.07381055075326928,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.123105625617661,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7884615384615384,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.209867121904039,
        "distinct-2-nopunct": 0.9791666666666666,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.543295834054493,
        "cond_entropy-2-nopunct": 0.3743097618368754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.08007633662931377,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42105263157894735,
            "2": 0.7142857142857143,
            "3": 0.625
        },
        "nist": 4.72437869767345,
        "rouge1": {
            "precision": 0.63374,
            "recall": 0.75237,
            "fmeasure": 0.65888
        },
        "rouge2": {
            "precision": 0.39501,
            "recall": 0.49961,
            "fmeasure": 0.42159
        },
        "rougeL": {
            "precision": 0.5583,
            "recall": 0.70139,
            "fmeasure": 0.60127
        },
        "rougeLsum": {
            "precision": 0.5583,
            "recall": 0.70139,
            "fmeasure": 0.60127
        },
        "bleu": 50.14815,
        "nubia": {
            "semantic_relation": 3.84112,
            "contradiction": 11.23435,
            "irrelevancy": 50.80291,
            "logical_agreement": 37.96274,
            "grammar_ref": 5.36601,
            "grammar_hyp": 4.47913,
            "nubia_score": 0.64843
        },
        "bleurt": 0.07693,
        "meteor": 0.4072563874400548,
        "bertscore": {
            "precision": 0.88659,
            "recall": 0.92428,
            "f1": 0.90375
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 111,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.71125,
        "total_length": 1865,
        "mean_pred_length": 16.8018018018018,
        "std_pred_length": 5.20709810041871,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.4058981233243968,
        "vocab_size-1": 757,
        "unique-1": 617,
        "entropy-1": 7.784389648479803,
        "distinct-2": 0.7434435575826682,
        "vocab_size-2": 1304,
        "unique-2": 1194,
        "entropy-2": 9.803311410511704,
        "cond_entropy-2": 1.8241417818254526,
        "distinct-3": 0.8423615337796714,
        "vocab_size-3": 1384,
        "unique-3": 1327,
        "entropy-3": 10.093041477423515,
        "cond_entropy-3": 0.3332521150130697,
        "total_length-nopunct": 1605,
        "mean_pred_length-nopunct": 14.45945945945946,
        "std_pred_length-nopunct": 4.473714589727249,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4654205607476635,
        "vocab_size-1-nopunct": 747,
        "unique-1-nopunct": 615,
        "entropy-1-nopunct": 8.038974229796688,
        "distinct-2-nopunct": 0.7576974564926372,
        "vocab_size-2-nopunct": 1132,
        "unique-2-nopunct": 1060,
        "entropy-2-nopunct": 9.580761151286994,
        "cond_entropy-2-nopunct": 1.6817063134277348,
        "distinct-3-nopunct": 0.8481561822125814,
        "vocab_size-3-nopunct": 1173,
        "unique-3-nopunct": 1134,
        "entropy-3-nopunct": 9.85290380231118,
        "cond_entropy-3-nopunct": 0.32839510551308465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.4222222222222222,
            "3": 0.7996807661612131
        },
        "nist": 7.772023728907493,
        "rouge1": {
            "precision": 0.78933,
            "recall": 0.76102,
            "fmeasure": 0.76568
        },
        "rouge2": {
            "precision": 0.60156,
            "recall": 0.58141,
            "fmeasure": 0.58296
        },
        "rougeL": {
            "precision": 0.71471,
            "recall": 0.69399,
            "fmeasure": 0.69441
        },
        "rougeLsum": {
            "precision": 0.71471,
            "recall": 0.69399,
            "fmeasure": 0.69441
        },
        "bleu": 53.45823,
        "nubia": {
            "semantic_relation": 4.2263,
            "contradiction": 9.76401,
            "irrelevancy": 24.6739,
            "logical_agreement": 65.5621,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.50213,
            "nubia_score": 0.74518
        },
        "bleurt": 0.36327,
        "meteor": 0.40901256549512566,
        "bertscore": {
            "precision": 0.93944,
            "recall": 0.93465,
            "f1": 0.9344
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 39,
        "msttr-100": 0.70833,
        "msttr-100_nopunct": 0.79,
        "total_length": 692,
        "mean_pred_length": 17.743589743589745,
        "std_pred_length": 5.591742761764078,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.5549132947976878,
        "vocab_size-1": 384,
        "unique-1": 319,
        "entropy-1": 7.54246615037951,
        "distinct-2": 0.9173047473200613,
        "vocab_size-2": 599,
        "unique-2": 571,
        "entropy-2": 9.116636625152262,
        "cond_entropy-2": 1.4285472699515742,
        "distinct-3": 0.988599348534202,
        "vocab_size-3": 607,
        "unique-3": 601,
        "entropy-3": 9.238064083966037,
        "cond_entropy-3": 0.1297952107671568,
        "total_length-nopunct": 581,
        "mean_pred_length-nopunct": 14.897435897435898,
        "std_pred_length-nopunct": 4.112487997300678,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6506024096385542,
        "vocab_size-1-nopunct": 378,
        "unique-1-nopunct": 318,
        "entropy-1-nopunct": 7.845078154142518,
        "distinct-2-nopunct": 0.940959409594096,
        "vocab_size-2-nopunct": 510,
        "unique-2-nopunct": 492,
        "entropy-2-nopunct": 8.914509550877916,
        "cond_entropy-2-nopunct": 1.1524303022146025,
        "distinct-3-nopunct": 0.9940357852882704,
        "vocab_size-3-nopunct": 500,
        "unique-3-nopunct": 497,
        "entropy-3-nopunct": 8.962486160382031,
        "cond_entropy-3-nopunct": 0.05501028769220717,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08270676691729323,
            "2": 0.6296296296296297,
            "3": 0.7047146401985112
        },
        "nist": 6.613119995252599,
        "rouge1": {
            "precision": 0.75808,
            "recall": 0.67902,
            "fmeasure": 0.70767
        },
        "rouge2": {
            "precision": 0.52952,
            "recall": 0.47397,
            "fmeasure": 0.49432
        },
        "rougeL": {
            "precision": 0.62698,
            "recall": 0.57514,
            "fmeasure": 0.59225
        },
        "rougeLsum": {
            "precision": 0.62698,
            "recall": 0.57514,
            "fmeasure": 0.59225
        },
        "bleu": 47.40232,
        "nubia": {
            "semantic_relation": 4.08702,
            "contradiction": 11.42691,
            "irrelevancy": 31.1673,
            "logical_agreement": 57.40579,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.45569,
            "nubia_score": 0.67273
        },
        "bleurt": 0.21078,
        "meteor": 0.3808448165446567,
        "bertscore": {
            "precision": 0.93012,
            "recall": 0.91935,
            "f1": 0.92376
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 369,
        "msttr-100": 0.63806,
        "msttr-100_nopunct": 0.69226,
        "total_length": 3632,
        "mean_pred_length": 9.842818428184282,
        "std_pred_length": 2.7104552507316306,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.21723568281938327,
        "vocab_size-1": 789,
        "unique-1": 428,
        "entropy-1": 7.524666875221909,
        "distinct-2": 0.5268158136684034,
        "vocab_size-2": 1719,
        "unique-2": 1197,
        "entropy-2": 10.178196649949367,
        "cond_entropy-2": 2.1756735993118257,
        "distinct-3": 0.7028334485141673,
        "vocab_size-3": 2034,
        "unique-3": 1623,
        "entropy-3": 10.695481604628581,
        "cond_entropy-3": 0.6087412398225496,
        "total_length-nopunct": 3166,
        "mean_pred_length-nopunct": 8.579945799457995,
        "std_pred_length-nopunct": 2.3843957487156358,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.24605180037902716,
        "vocab_size-1-nopunct": 779,
        "unique-1-nopunct": 423,
        "entropy-1-nopunct": 7.8254059330988825,
        "distinct-2-nopunct": 0.5055416517697533,
        "vocab_size-2-nopunct": 1414,
        "unique-2-nopunct": 960,
        "entropy-2-nopunct": 9.878604909140156,
        "cond_entropy-2-nopunct": 2.3623895648536553,
        "distinct-3-nopunct": 0.6935749588138386,
        "vocab_size-3-nopunct": 1684,
        "unique-3-nopunct": 1334,
        "entropy-3-nopunct": 10.414051662537373,
        "cond_entropy-3-nopunct": 0.6594639517509302,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22616525423728814,
            "2": 0.6908646003262643,
            "3": 0.8851261620185923,
            "4": 0.9473684210526315
        },
        "nist": 9.15068491815428,
        "rouge1": {
            "precision": 0.82339,
            "recall": 0.79048,
            "fmeasure": 0.79943
        },
        "rouge2": {
            "precision": 0.60506,
            "recall": 0.5806,
            "fmeasure": 0.58669
        },
        "rougeL": {
            "precision": 0.74865,
            "recall": 0.71745,
            "fmeasure": 0.72623
        },
        "rougeLsum": {
            "precision": 0.74865,
            "recall": 0.71745,
            "fmeasure": 0.72623
        },
        "bleu": 59.77499,
        "nubia": {
            "semantic_relation": 4.59015,
            "contradiction": 6.67274,
            "irrelevancy": 7.60937,
            "logical_agreement": 85.71789,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.39464,
            "nubia_score": 0.82102
        },
        "bleurt": 0.37092,
        "meteor": 0.4627968196358536,
        "bertscore": {
            "precision": 0.94722,
            "recall": 0.94467,
            "f1": 0.94501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78091,
        "total_length": 1320,
        "mean_pred_length": 16.5,
        "std_pred_length": 5.394441583704471,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.5,
        "vocab_size-1": 660,
        "unique-1": 528,
        "entropy-1": 8.110619894538647,
        "distinct-2": 0.9048387096774193,
        "vocab_size-2": 1122,
        "unique-2": 1052,
        "entropy-2": 10.017661897800894,
        "cond_entropy-2": 1.705879404458967,
        "distinct-3": 0.9870689655172413,
        "vocab_size-3": 1145,
        "unique-3": 1130,
        "entropy-3": 10.154047021049264,
        "cond_entropy-3": 0.1355811233548764,
        "total_length-nopunct": 1148,
        "mean_pred_length-nopunct": 14.35,
        "std_pred_length-nopunct": 4.944946915791919,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5670731707317073,
        "vocab_size-1-nopunct": 651,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 8.385180971776245,
        "distinct-2-nopunct": 0.9176029962546817,
        "vocab_size-2-nopunct": 980,
        "unique-2-nopunct": 930,
        "entropy-2-nopunct": 9.82437741993887,
        "cond_entropy-2-nopunct": 1.527315788975528,
        "distinct-3-nopunct": 0.9908906882591093,
        "vocab_size-3-nopunct": 979,
        "unique-3-nopunct": 970,
        "entropy-3-nopunct": 9.930148608102924,
        "cond_entropy-3-nopunct": 0.11925349427646799,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2288135593220339,
            "2": 0.41784037558685444,
            "3": 0.7158712541620422
        },
        "nist": 6.873374612773064,
        "rouge1": {
            "precision": 0.72636,
            "recall": 0.68944,
            "fmeasure": 0.69373
        },
        "rouge2": {
            "precision": 0.45876,
            "recall": 0.43234,
            "fmeasure": 0.436
        },
        "rougeL": {
            "precision": 0.62187,
            "recall": 0.59762,
            "fmeasure": 0.59738
        },
        "rougeLsum": {
            "precision": 0.62187,
            "recall": 0.59762,
            "fmeasure": 0.59738
        },
        "bleu": 39.20749,
        "nubia": {
            "semantic_relation": 4.09978,
            "contradiction": 9.9297,
            "irrelevancy": 29.63054,
            "logical_agreement": 60.43976,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.86118,
            "nubia_score": 0.67842
        },
        "bleurt": 0.15925,
        "meteor": 0.35471498806271556,
        "bertscore": {
            "precision": 0.91752,
            "recall": 0.90991,
            "f1": 0.9116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.55286,
        "msttr-100_nopunct": 0.58833,
        "total_length": 731,
        "mean_pred_length": 15.229166666666666,
        "std_pred_length": 3.641425907373222,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.35567715458276333,
        "vocab_size-1": 260,
        "unique-1": 207,
        "entropy-1": 6.482653250202505,
        "distinct-2": 0.6339677891654466,
        "vocab_size-2": 433,
        "unique-2": 380,
        "entropy-2": 8.137675060590086,
        "cond_entropy-2": 1.4924749310592538,
        "distinct-3": 0.7448818897637796,
        "vocab_size-3": 473,
        "unique-3": 432,
        "entropy-3": 8.482107894037586,
        "cond_entropy-3": 0.38927204445343544,
        "total_length-nopunct": 631,
        "mean_pred_length-nopunct": 13.145833333333334,
        "std_pred_length-nopunct": 3.2722926680777737,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.40253565768621236,
        "vocab_size-1-nopunct": 254,
        "unique-1-nopunct": 206,
        "entropy-1-nopunct": 6.6093228290913295,
        "distinct-2-nopunct": 0.6329331046312179,
        "vocab_size-2-nopunct": 369,
        "unique-2-nopunct": 322,
        "entropy-2-nopunct": 7.911604138615518,
        "cond_entropy-2-nopunct": 1.4103275979514387,
        "distinct-3-nopunct": 0.7439252336448599,
        "vocab_size-3-nopunct": 398,
        "unique-3-nopunct": 361,
        "entropy-3-nopunct": 8.235965769747034,
        "cond_entropy-3-nopunct": 0.3999394666223106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2972972972972973,
            "2": 0.6,
            "3": 0.8007889546351085
        },
        "nist": 6.981690980480877,
        "rouge1": {
            "precision": 0.79272,
            "recall": 0.78505,
            "fmeasure": 0.78016
        },
        "rouge2": {
            "precision": 0.60218,
            "recall": 0.60321,
            "fmeasure": 0.59522
        },
        "rougeL": {
            "precision": 0.72625,
            "recall": 0.72559,
            "fmeasure": 0.71781
        },
        "rougeLsum": {
            "precision": 0.72625,
            "recall": 0.72559,
            "fmeasure": 0.71781
        },
        "bleu": 58.60477,
        "nubia": {
            "semantic_relation": 4.39959,
            "contradiction": 3.70614,
            "irrelevancy": 31.67628,
            "logical_agreement": 64.61758,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.09355,
            "nubia_score": 0.84196
        },
        "bleurt": 0.47885,
        "meteor": 0.43422803121477593,
        "bertscore": {
            "precision": 0.93831,
            "recall": 0.93909,
            "f1": 0.9371
        }
    },
    "schema_guided_dialog_challenge_test_bfp02_parent": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.68437,
        "msttr-100_nopunct": 0.715,
        "total_length": 6420,
        "mean_pred_length": 12.84,
        "std_pred_length": 6.843858560782799,
        "median_pred_length": 11.5,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.15794392523364487,
        "vocab_size-1": 1014,
        "unique-1": 563,
        "entropy-1": 7.883406978161791,
        "distinct-2": 0.4998310810810811,
        "vocab_size-2": 2959,
        "unique-2": 2085,
        "entropy-2": 10.788418185769332,
        "cond_entropy-2": 2.69580769133612,
        "distinct-3": 0.7223247232472325,
        "vocab_size-3": 3915,
        "unique-3": 3232,
        "entropy-3": 11.603604592016547,
        "cond_entropy-3": 0.8464625855442158,
        "total_length-nopunct": 5676,
        "mean_pred_length-nopunct": 11.352,
        "std_pred_length-nopunct": 6.3664822311854445,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.17618040873854826,
        "vocab_size-1-nopunct": 1000,
        "unique-1-nopunct": 559,
        "entropy-1-nopunct": 8.049504812543734,
        "distinct-2-nopunct": 0.5156491499227203,
        "vocab_size-2-nopunct": 2669,
        "unique-2-nopunct": 1918,
        "entropy-2-nopunct": 10.634322449174762,
        "cond_entropy-2-nopunct": 2.7143092468316907,
        "distinct-3-nopunct": 0.7348727816976695,
        "vocab_size-3-nopunct": 3437,
        "unique-3-nopunct": 2884,
        "entropy-3-nopunct": 11.414867409256587,
        "cond_entropy-3-nopunct": 0.8238867018675433,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.56057172738365
        },
        "nist": 6.145145886404423,
        "rouge1": {
            "precision": 0.57938,
            "recall": 0.55224,
            "fmeasure": 0.55525
        },
        "rouge2": {
            "precision": 0.36106,
            "recall": 0.34229,
            "fmeasure": 0.34462
        },
        "rougeL": {
            "precision": 0.52125,
            "recall": 0.49544,
            "fmeasure": 0.49889
        },
        "rougeLsum": {
            "precision": 0.52125,
            "recall": 0.49544,
            "fmeasure": 0.49889
        },
        "bleu": 31.88288,
        "nubia": {
            "semantic_relation": 3.61142,
            "contradiction": 5.83101,
            "irrelevancy": 22.40353,
            "logical_agreement": 71.76546,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.75681,
            "nubia_score": 0.62978
        },
        "bleurt": -0.10607,
        "meteor": 0.3138694529419076,
        "bertscore": {
            "precision": 0.87209,
            "recall": 0.8636,
            "f1": 0.86738
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 350,
        "msttr-100": 0.66041,
        "msttr-100_nopunct": 0.6897,
        "total_length": 7406,
        "mean_pred_length": 21.16,
        "std_pred_length": 3.9932228301747164,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.1354307318390494,
        "vocab_size-1": 1003,
        "unique-1": 348,
        "entropy-1": 7.934917950448383,
        "distinct-2": 0.3843537414965986,
        "vocab_size-2": 2712,
        "unique-2": 1529,
        "entropy-2": 10.639015102726644,
        "cond_entropy-2": 2.623848389341134,
        "distinct-3": 0.5844020280345958,
        "vocab_size-3": 3919,
        "unique-3": 2769,
        "entropy-3": 11.506655981285677,
        "cond_entropy-3": 0.9278842260781004,
        "total_length-nopunct": 6649,
        "mean_pred_length-nopunct": 18.997142857142858,
        "std_pred_length-nopunct": 3.8570888885113277,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.14979696194916528,
        "vocab_size-1-nopunct": 996,
        "unique-1-nopunct": 348,
        "entropy-1-nopunct": 8.125731239417563,
        "distinct-2-nopunct": 0.3921257342435307,
        "vocab_size-2-nopunct": 2470,
        "unique-2-nopunct": 1432,
        "entropy-2-nopunct": 10.505366616225112,
        "cond_entropy-2-nopunct": 2.518266776073535,
        "distinct-3-nopunct": 0.5883341738107245,
        "vocab_size-3-nopunct": 3500,
        "unique-3-nopunct": 2521,
        "entropy-3-nopunct": 11.330250410423716,
        "cond_entropy-3-nopunct": 0.8780608828952285,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21557595498963578,
            "2": 0.5404392072844135,
            "3": 0.8276220145379024,
            "4": 0.6,
            "5": 0.6896551724137931
        },
        "nist": 8.33670971598014,
        "rouge1": {
            "precision": 0.75251,
            "recall": 0.71622,
            "fmeasure": 0.72637
        },
        "rouge2": {
            "precision": 0.49253,
            "recall": 0.46458,
            "fmeasure": 0.47266
        },
        "rougeL": {
            "precision": 0.60469,
            "recall": 0.57438,
            "fmeasure": 0.58267
        },
        "rougeLsum": {
            "precision": 0.60469,
            "recall": 0.57438,
            "fmeasure": 0.58267
        },
        "bleu": 44.98474,
        "nubia": {
            "semantic_relation": 4.31202,
            "contradiction": 8.13764,
            "irrelevancy": 9.52751,
            "logical_agreement": 82.33485,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.69971,
            "nubia_score": 0.73169
        },
        "bleurt": 0.07853,
        "meteor": 0.37490614976279335,
        "bertscore": {
            "precision": 0.9152,
            "recall": 0.90721,
            "f1": 0.90953
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 114,
        "msttr-100": 0.63889,
        "msttr-100_nopunct": 0.658,
        "total_length": 2748,
        "mean_pred_length": 24.105263157894736,
        "std_pred_length": 3.1242358253101563,
        "median_pred_length": 24.0,
        "min_pred_length": 17,
        "max_pred_length": 31,
        "distinct-1": 0.21433770014556042,
        "vocab_size-1": 589,
        "unique-1": 284,
        "entropy-1": 7.548881510280479,
        "distinct-2": 0.46924829157175396,
        "vocab_size-2": 1236,
        "unique-2": 806,
        "entropy-2": 9.658543710820139,
        "cond_entropy-2": 2.1847025997881913,
        "distinct-3": 0.625,
        "vocab_size-3": 1575,
        "unique-3": 1197,
        "entropy-3": 10.222249475562208,
        "cond_entropy-3": 0.6097400180996861,
        "total_length-nopunct": 2526,
        "mean_pred_length-nopunct": 22.157894736842106,
        "std_pred_length-nopunct": 2.957532599421174,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.23119556611243072,
        "vocab_size-1-nopunct": 584,
        "unique-1-nopunct": 283,
        "entropy-1-nopunct": 7.646552695759525,
        "distinct-2-nopunct": 0.48714759535655056,
        "vocab_size-2-nopunct": 1175,
        "unique-2-nopunct": 797,
        "entropy-2-nopunct": 9.59811413437571,
        "cond_entropy-2-nopunct": 2.035191095143426,
        "distinct-3-nopunct": 0.6288076588337685,
        "vocab_size-3-nopunct": 1445,
        "unique-3-nopunct": 1116,
        "entropy-3-nopunct": 10.08425595791852,
        "cond_entropy-3-nopunct": 0.5368342542650754,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.13703284258210646,
            "2": 0.3978494623655914,
            "3": 0.5654135338345865
        },
        "nist": 1.5901617024087649,
        "rouge1": {
            "precision": 0.76211,
            "recall": 0.44843,
            "fmeasure": 0.55466
        },
        "rouge2": {
            "precision": 0.47067,
            "recall": 0.25845,
            "fmeasure": 0.32689
        },
        "rougeL": {
            "precision": 0.59069,
            "recall": 0.3457,
            "fmeasure": 0.42752
        },
        "rougeLsum": {
            "precision": 0.59069,
            "recall": 0.3457,
            "fmeasure": 0.42752
        },
        "bleu": 22.88382,
        "nubia": {
            "semantic_relation": 3.25182,
            "contradiction": 7.09426,
            "irrelevancy": 14.20101,
            "logical_agreement": 78.70473,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.6976,
            "nubia_score": 0.36218
        },
        "bleurt": -0.43034,
        "meteor": 0.22034252485618439,
        "bertscore": {
            "precision": 0.89702,
            "recall": 0.82901,
            "f1": 0.86012
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.68667,
        "msttr-100_nopunct": 0.74,
        "total_length": 639,
        "mean_pred_length": 17.75,
        "std_pred_length": 5.55965126804031,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5414710485133021,
        "vocab_size-1": 346,
        "unique-1": 284,
        "entropy-1": 7.446636886730258,
        "distinct-2": 0.9137645107794361,
        "vocab_size-2": 551,
        "unique-2": 520,
        "entropy-2": 9.006184703634815,
        "cond_entropy-2": 1.4217379039172975,
        "distinct-3": 0.9876543209876543,
        "vocab_size-3": 560,
        "unique-3": 555,
        "entropy-3": 9.119850824405585,
        "cond_entropy-3": 0.12825846923195605,
        "total_length-nopunct": 564,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 4.904646323187388,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6028368794326241,
        "vocab_size-1-nopunct": 340,
        "unique-1-nopunct": 282,
        "entropy-1-nopunct": 7.591501663089413,
        "distinct-2-nopunct": 0.9185606060606061,
        "vocab_size-2-nopunct": 485,
        "unique-2-nopunct": 461,
        "entropy-2-nopunct": 8.818868728412117,
        "cond_entropy-2-nopunct": 1.3084710392233472,
        "distinct-3-nopunct": 0.9857723577235772,
        "vocab_size-3-nopunct": 485,
        "unique-3-nopunct": 480,
        "entropy-3-nopunct": 8.91099057240352,
        "cond_entropy-3-nopunct": 0.10455866121513077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2564102564102564,
            "2": 0.5073529411764706,
            "3": 0.7035175879396985
        },
        "nist": 6.238751843101218,
        "rouge1": {
            "precision": 0.72527,
            "recall": 0.6667,
            "fmeasure": 0.68482
        },
        "rouge2": {
            "precision": 0.45647,
            "recall": 0.41947,
            "fmeasure": 0.43114
        },
        "rougeL": {
            "precision": 0.60335,
            "recall": 0.55508,
            "fmeasure": 0.56993
        },
        "rougeLsum": {
            "precision": 0.60335,
            "recall": 0.55508,
            "fmeasure": 0.56993
        },
        "bleu": 36.81716,
        "nubia": {
            "semantic_relation": 4.07493,
            "contradiction": 14.88792,
            "irrelevancy": 27.80949,
            "logical_agreement": 57.30258,
            "grammar_ref": 4.71629,
            "grammar_hyp": 5.0459,
            "nubia_score": 0.6471
        },
        "bleurt": 0.14986,
        "meteor": 0.34350714059306614,
        "bertscore": {
            "precision": 0.92064,
            "recall": 0.91056,
            "f1": 0.91492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 123,
        "msttr-100": 0.65053,
        "msttr-100_nopunct": 0.69125,
        "total_length": 1904,
        "mean_pred_length": 15.479674796747968,
        "std_pred_length": 5.074004517682494,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.39863445378151263,
        "vocab_size-1": 759,
        "unique-1": 630,
        "entropy-1": 7.648999880837117,
        "distinct-2": 0.7344188658057271,
        "vocab_size-2": 1308,
        "unique-2": 1219,
        "entropy-2": 9.712230529013201,
        "cond_entropy-2": 1.8282945919728772,
        "distinct-3": 0.8208685162846804,
        "vocab_size-3": 1361,
        "unique-3": 1312,
        "entropy-3": 9.970440460797391,
        "cond_entropy-3": 0.3107979962394937,
        "total_length-nopunct": 1656,
        "mean_pred_length-nopunct": 13.463414634146341,
        "std_pred_length-nopunct": 4.419639618400329,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.45471014492753625,
        "vocab_size-1-nopunct": 753,
        "unique-1-nopunct": 630,
        "entropy-1-nopunct": 7.908504878682898,
        "distinct-2-nopunct": 0.7390737116764514,
        "vocab_size-2-nopunct": 1133,
        "unique-2-nopunct": 1062,
        "entropy-2-nopunct": 9.499072174605015,
        "cond_entropy-2-nopunct": 1.7460345831308344,
        "distinct-3-nopunct": 0.825531914893617,
        "vocab_size-3-nopunct": 1164,
        "unique-3-nopunct": 1126,
        "entropy-3-nopunct": 9.749320187270884,
        "cond_entropy-3-nopunct": 0.3348655273271397,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27208480565371024,
            "2": 0.43812709030100333,
            "3": 0.7582755966127791
        },
        "nist": 7.5053885095851385,
        "rouge1": {
            "precision": 0.76791,
            "recall": 0.75186,
            "fmeasure": 0.74863
        },
        "rouge2": {
            "precision": 0.54705,
            "recall": 0.52795,
            "fmeasure": 0.52947
        },
        "rougeL": {
            "precision": 0.66585,
            "recall": 0.64798,
            "fmeasure": 0.6466
        },
        "rougeLsum": {
            "precision": 0.66585,
            "recall": 0.64798,
            "fmeasure": 0.6466
        },
        "bleu": 48.88447,
        "nubia": {
            "semantic_relation": 4.27615,
            "contradiction": 8.42377,
            "irrelevancy": 25.0444,
            "logical_agreement": 66.53183,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.7403,
            "nubia_score": 0.75104
        },
        "bleurt": 0.36311,
        "meteor": 0.39658258079908204,
        "bertscore": {
            "precision": 0.92988,
            "recall": 0.92808,
            "f1": 0.92763
        }
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76952,
        "total_length": 2398,
        "mean_pred_length": 15.986666666666666,
        "std_pred_length": 5.350372780366699,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.420767306088407,
        "vocab_size-1": 1009,
        "unique-1": 798,
        "entropy-1": 8.276479684454737,
        "distinct-2": 0.822508896797153,
        "vocab_size-2": 1849,
        "unique-2": 1682,
        "entropy-2": 10.571328510177224,
        "cond_entropy-2": 2.0656491837682642,
        "distinct-3": 0.9523355576739753,
        "vocab_size-3": 1998,
        "unique-3": 1930,
        "entropy-3": 10.92359901930595,
        "cond_entropy-3": 0.35927252723928643,
        "total_length-nopunct": 2126,
        "mean_pred_length-nopunct": 14.173333333333334,
        "std_pred_length-nopunct": 4.955463875584426,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4717779868297272,
        "vocab_size-1-nopunct": 1003,
        "unique-1-nopunct": 797,
        "entropy-1-nopunct": 8.551976902066464,
        "distinct-2-nopunct": 0.8380566801619433,
        "vocab_size-2-nopunct": 1656,
        "unique-2-nopunct": 1524,
        "entropy-2-nopunct": 10.414526604058114,
        "cond_entropy-2-nopunct": 1.9642946316283498,
        "distinct-3-nopunct": 0.9627601314348302,
        "vocab_size-3-nopunct": 1758,
        "unique-3-nopunct": 1710,
        "entropy-3-nopunct": 10.748349264132342,
        "cond_entropy-3-nopunct": 0.36513109574351443,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19827586206896552,
            "2": 0.47297297297297297,
            "3": 0.8016877637130801
        },
        "nist": 8.087725212482423,
        "rouge1": {
            "precision": 0.7872,
            "recall": 0.75843,
            "fmeasure": 0.7622
        },
        "rouge2": {
            "precision": 0.55397,
            "recall": 0.53709,
            "fmeasure": 0.53655
        },
        "rougeL": {
            "precision": 0.66529,
            "recall": 0.64468,
            "fmeasure": 0.64511
        },
        "rougeLsum": {
            "precision": 0.66529,
            "recall": 0.64468,
            "fmeasure": 0.64511
        },
        "bleu": 46.36984,
        "nubia": {
            "semantic_relation": 4.35154,
            "contradiction": 7.18171,
            "irrelevancy": 25.29359,
            "logical_agreement": 67.52469,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.88175,
            "nubia_score": 0.75819
        },
        "bleurt": 0.30965,
        "meteor": 0.40511628411871853,
        "bertscore": {
            "precision": 0.9347,
            "recall": 0.93168,
            "f1": 0.93124
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 305,
        "msttr-100": 0.65904,
        "msttr-100_nopunct": 0.67833,
        "total_length": 7321,
        "mean_pred_length": 24.003278688524592,
        "std_pred_length": 3.185518832750501,
        "median_pred_length": 24.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.15202841141920503,
        "vocab_size-1": 1113,
        "unique-1": 457,
        "entropy-1": 7.997988346181442,
        "distinct-2": 0.4161915621436716,
        "vocab_size-2": 2920,
        "unique-2": 1780,
        "entropy-2": 10.684536045007864,
        "cond_entropy-2": 2.7292578074161016,
        "distinct-3": 0.6160035762181493,
        "vocab_size-3": 4134,
        "unique-3": 3064,
        "entropy-3": 11.585339830637286,
        "cond_entropy-3": 0.9594162151257317,
        "total_length-nopunct": 6687,
        "mean_pred_length-nopunct": 21.924590163934425,
        "std_pred_length-nopunct": 3.1127793567546154,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.16524599970091222,
        "vocab_size-1-nopunct": 1105,
        "unique-1-nopunct": 454,
        "entropy-1-nopunct": 8.13771994229959,
        "distinct-2-nopunct": 0.43074271388279534,
        "vocab_size-2-nopunct": 2749,
        "unique-2-nopunct": 1721,
        "entropy-2-nopunct": 10.63825188416776,
        "cond_entropy-2-nopunct": 2.6124868706259314,
        "distinct-3-nopunct": 0.6221819976962317,
        "vocab_size-3-nopunct": 3781,
        "unique-3-nopunct": 2836,
        "entropy-3-nopunct": 11.45876756513695,
        "cond_entropy-3-nopunct": 0.8820165230609871,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18494683827644096,
            "2": 0.494579945799458,
            "3": 0.7484386709967524
        },
        "nist": 6.827520880466914,
        "rouge1": {
            "precision": 0.73723,
            "recall": 0.62533,
            "fmeasure": 0.66769
        },
        "rouge2": {
            "precision": 0.46363,
            "recall": 0.38597,
            "fmeasure": 0.41479
        },
        "rougeL": {
            "precision": 0.5723,
            "recall": 0.4831,
            "fmeasure": 0.51652
        },
        "rougeLsum": {
            "precision": 0.5723,
            "recall": 0.4831,
            "fmeasure": 0.51652
        },
        "bleu": 37.81003,
        "nubia": {
            "semantic_relation": 3.78957,
            "contradiction": 12.56853,
            "irrelevancy": 13.36384,
            "logical_agreement": 74.06763,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.61475,
            "nubia_score": 0.56607
        },
        "bleurt": -0.15895,
        "meteor": 0.31741385456104,
        "bertscore": {
            "precision": 0.90111,
            "recall": 0.87655,
            "f1": 0.88728
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 110,
        "msttr-100": 0.72824,
        "msttr-100_nopunct": 0.766,
        "total_length": 1747,
        "mean_pred_length": 15.881818181818181,
        "std_pred_length": 5.426754962358961,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.47967945048654836,
        "vocab_size-1": 838,
        "unique-1": 687,
        "entropy-1": 8.243597849285825,
        "distinct-2": 0.8643860720830788,
        "vocab_size-2": 1415,
        "unique-2": 1314,
        "entropy-2": 10.285557968358052,
        "cond_entropy-2": 1.7910546276245423,
        "distinct-3": 0.9607072691552063,
        "vocab_size-3": 1467,
        "unique-3": 1429,
        "entropy-3": 10.483738499421294,
        "cond_entropy-3": 0.1934498222785049,
        "total_length-nopunct": 1538,
        "mean_pred_length-nopunct": 13.981818181818182,
        "std_pred_length-nopunct": 5.001784805413906,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5396618985695709,
        "vocab_size-1-nopunct": 830,
        "unique-1-nopunct": 686,
        "entropy-1-nopunct": 8.495047174001396,
        "distinct-2-nopunct": 0.8697478991596639,
        "vocab_size-2-nopunct": 1242,
        "unique-2-nopunct": 1163,
        "entropy-2-nopunct": 10.092884392475405,
        "cond_entropy-2-nopunct": 1.7172168357886304,
        "distinct-3-nopunct": 0.9613050075872535,
        "vocab_size-3-nopunct": 1267,
        "unique-3-nopunct": 1237,
        "entropy-3-nopunct": 10.270911573490162,
        "cond_entropy-3-nopunct": 0.20273017484683575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25132275132275134,
            "2": 0.5278514588859416,
            "3": 0.7981132075471699
        },
        "nist": 7.843515831219226,
        "rouge1": {
            "precision": 0.75919,
            "recall": 0.73471,
            "fmeasure": 0.73731
        },
        "rouge2": {
            "precision": 0.53877,
            "recall": 0.52062,
            "fmeasure": 0.52237
        },
        "rougeL": {
            "precision": 0.66991,
            "recall": 0.64991,
            "fmeasure": 0.65143
        },
        "rougeLsum": {
            "precision": 0.66991,
            "recall": 0.64991,
            "fmeasure": 0.65143
        },
        "bleu": 48.4434,
        "nubia": {
            "semantic_relation": 4.21661,
            "contradiction": 6.66503,
            "irrelevancy": 28.22397,
            "logical_agreement": 65.111,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.75716,
            "nubia_score": 0.74038
        },
        "bleurt": 0.28275,
        "meteor": 0.40225031394802474,
        "bertscore": {
            "precision": 0.9355,
            "recall": 0.92937,
            "f1": 0.93101
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 2.2959653156303634,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.92857,
            "fmeasure": 0.8125
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.61538,
            "fmeasure": 0.53333
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.68519,
            "fmeasure": 0.49151
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.68519,
            "fmeasure": 0.49151
        },
        "bleu": 20.59019,
        "nubia": {
            "semantic_relation": 3.83456,
            "contradiction": 0.18229,
            "irrelevancy": 99.70904,
            "logical_agreement": 0.10867,
            "grammar_ref": 4.76643,
            "grammar_hyp": 3.51807,
            "nubia_score": 0.77248
        },
        "bleurt": 0.22858,
        "meteor": 0.39644893657314245,
        "bertscore": {
            "precision": 0.88962,
            "recall": 0.92079,
            "f1": 0.90494
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 62,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77667,
        "total_length": 1057,
        "mean_pred_length": 17.048387096774192,
        "std_pred_length": 6.149816203272017,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 38,
        "distinct-1": 0.47019867549668876,
        "vocab_size-1": 497,
        "unique-1": 373,
        "entropy-1": 7.840453238454846,
        "distinct-2": 0.842211055276382,
        "vocab_size-2": 838,
        "unique-2": 741,
        "entropy-2": 9.56876093811693,
        "cond_entropy-2": 1.538877672110614,
        "distinct-3": 0.9281886387995713,
        "vocab_size-3": 866,
        "unique-3": 820,
        "entropy-3": 9.697679693660294,
        "cond_entropy-3": 0.12052335382160836,
        "total_length-nopunct": 901,
        "mean_pred_length-nopunct": 14.53225806451613,
        "std_pred_length-nopunct": 4.861692729026304,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.5405105438401776,
        "vocab_size-1-nopunct": 487,
        "unique-1-nopunct": 369,
        "entropy-1-nopunct": 8.111455602052628,
        "distinct-2-nopunct": 0.8617401668653158,
        "vocab_size-2-nopunct": 723,
        "unique-2-nopunct": 652,
        "entropy-2-nopunct": 9.369179704949126,
        "cond_entropy-2-nopunct": 1.330809124013397,
        "distinct-3-nopunct": 0.9433719433719434,
        "vocab_size-3-nopunct": 733,
        "unique-3-nopunct": 702,
        "entropy-3-nopunct": 9.474622799322116,
        "cond_entropy-3-nopunct": 0.09551713854341289,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1569767441860465,
            "2": 0.4463276836158192,
            "3": 0.8046647230320699
        },
        "nist": 7.353978435278682,
        "rouge1": {
            "precision": 0.77326,
            "recall": 0.76607,
            "fmeasure": 0.75918
        },
        "rouge2": {
            "precision": 0.55732,
            "recall": 0.55021,
            "fmeasure": 0.54564
        },
        "rougeL": {
            "precision": 0.66193,
            "recall": 0.65492,
            "fmeasure": 0.64847
        },
        "rougeLsum": {
            "precision": 0.66193,
            "recall": 0.65492,
            "fmeasure": 0.64847
        },
        "bleu": 50.66167,
        "nubia": {
            "semantic_relation": 4.23765,
            "contradiction": 6.97238,
            "irrelevancy": 30.46693,
            "logical_agreement": 62.5607,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.4699,
            "nubia_score": 0.75706
        },
        "bleurt": 0.309,
        "meteor": 0.40242575445611684,
        "bertscore": {
            "precision": 0.93176,
            "recall": 0.92723,
            "f1": 0.92716
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.4925,
        "msttr-100_nopunct": 0.48667,
        "total_length": 466,
        "mean_pred_length": 16.06896551724138,
        "std_pred_length": 4.762866671432807,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.33261802575107297,
        "vocab_size-1": 155,
        "unique-1": 121,
        "entropy-1": 5.868435666176233,
        "distinct-2": 0.5720823798627003,
        "vocab_size-2": 250,
        "unique-2": 218,
        "entropy-2": 7.1422536431248185,
        "cond_entropy-2": 1.1906722817636948,
        "distinct-3": 0.6617647058823529,
        "vocab_size-3": 270,
        "unique-3": 245,
        "entropy-3": 7.419030096205169,
        "cond_entropy-3": 0.3852270387785172,
        "total_length-nopunct": 398,
        "mean_pred_length-nopunct": 13.724137931034482,
        "std_pred_length-nopunct": 4.050513392101761,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.37185929648241206,
        "vocab_size-1-nopunct": 148,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 5.857821750768249,
        "distinct-2-nopunct": 0.5474254742547425,
        "vocab_size-2-nopunct": 202,
        "unique-2-nopunct": 174,
        "entropy-2-nopunct": 6.798133958108527,
        "cond_entropy-2-nopunct": 1.1332470740088822,
        "distinct-3-nopunct": 0.65,
        "vocab_size-3-nopunct": 221,
        "unique-3-nopunct": 200,
        "entropy-3-nopunct": 7.11297357925957,
        "cond_entropy-3-nopunct": 0.44591605023892983,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.47368421052631576,
            "3": 0.8284023668639053
        },
        "nist": 6.858978645089479,
        "rouge1": {
            "precision": 0.85999,
            "recall": 0.82462,
            "fmeasure": 0.83365
        },
        "rouge2": {
            "precision": 0.70793,
            "recall": 0.67445,
            "fmeasure": 0.68324
        },
        "rougeL": {
            "precision": 0.80158,
            "recall": 0.76668,
            "fmeasure": 0.77567
        },
        "rougeLsum": {
            "precision": 0.80158,
            "recall": 0.76668,
            "fmeasure": 0.77567
        },
        "bleu": 62.64156,
        "nubia": {
            "semantic_relation": 4.36551,
            "contradiction": 3.70487,
            "irrelevancy": 14.10661,
            "logical_agreement": 82.18852,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.29271,
            "nubia_score": 0.80927
        },
        "bleurt": 0.5257,
        "meteor": 0.43873995716132336,
        "bertscore": {
            "precision": 0.95807,
            "recall": 0.95141,
            "f1": 0.953
        }
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 79,
        "msttr-100": 0.65842,
        "msttr-100_nopunct": 0.67706,
        "total_length": 1903,
        "mean_pred_length": 24.088607594936708,
        "std_pred_length": 2.9604561460784566,
        "median_pred_length": 25.0,
        "min_pred_length": 19,
        "max_pred_length": 31,
        "distinct-1": 0.23699421965317918,
        "vocab_size-1": 451,
        "unique-1": 229,
        "entropy-1": 7.35393065500637,
        "distinct-2": 0.4764254385964912,
        "vocab_size-2": 869,
        "unique-2": 556,
        "entropy-2": 9.243976986987326,
        "cond_entropy-2": 1.951258397485931,
        "distinct-3": 0.602865329512894,
        "vocab_size-3": 1052,
        "unique-3": 782,
        "entropy-3": 9.654556705577098,
        "cond_entropy-3": 0.4540892228931785,
        "total_length-nopunct": 1749,
        "mean_pred_length-nopunct": 22.139240506329113,
        "std_pred_length-nopunct": 2.8628311083287703,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.2550028587764437,
        "vocab_size-1-nopunct": 446,
        "unique-1-nopunct": 229,
        "entropy-1-nopunct": 7.419441486118912,
        "distinct-2-nopunct": 0.49101796407185627,
        "vocab_size-2-nopunct": 820,
        "unique-2-nopunct": 537,
        "entropy-2-nopunct": 9.170300662162497,
        "cond_entropy-2-nopunct": 1.8270383742450966,
        "distinct-3-nopunct": 0.6084223758642363,
        "vocab_size-3-nopunct": 968,
        "unique-3-nopunct": 727,
        "entropy-3-nopunct": 9.531964667926166,
        "cond_entropy-3-nopunct": 0.4079229955493269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.2536327608982827,
            "3": 0.5100057175528874
        },
        "nist": 0.6134889140150648,
        "rouge1": {
            "precision": 0.77559,
            "recall": 0.39313,
            "fmeasure": 0.51363
        },
        "rouge2": {
            "precision": 0.46807,
            "recall": 0.22092,
            "fmeasure": 0.29476
        },
        "rougeL": {
            "precision": 0.61898,
            "recall": 0.30664,
            "fmeasure": 0.40319
        },
        "rougeLsum": {
            "precision": 0.61898,
            "recall": 0.30664,
            "fmeasure": 0.40319
        },
        "bleu": 17.47471,
        "nubia": {
            "semantic_relation": 3.00259,
            "contradiction": 7.30737,
            "irrelevancy": 11.99665,
            "logical_agreement": 80.69598,
            "grammar_ref": 3.96506,
            "grammar_hyp": 4.50708,
            "nubia_score": 0.32062
        },
        "bleurt": -0.55172,
        "meteor": 0.19467401129674272,
        "bertscore": {
            "precision": 0.89933,
            "recall": 0.81522,
            "f1": 0.85391
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.77667,
        "total_length": 425,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.535341001239219,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5741176470588235,
        "vocab_size-1": 244,
        "unique-1": 197,
        "entropy-1": 7.199942317234507,
        "distinct-2": 0.9325,
        "vocab_size-2": 373,
        "unique-2": 352,
        "entropy-2": 8.495081752263928,
        "cond_entropy-2": 1.1682916686451716,
        "distinct-3": 0.9866666666666667,
        "vocab_size-3": 370,
        "unique-3": 365,
        "entropy-3": 8.524080118716569,
        "cond_entropy-3": 0.02357029561428771,
        "total_length-nopunct": 361,
        "mean_pred_length-nopunct": 14.44,
        "std_pred_length-nopunct": 4.767221412940666,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6592797783933518,
        "vocab_size-1-nopunct": 238,
        "unique-1-nopunct": 196,
        "entropy-1-nopunct": 7.392530548441526,
        "distinct-2-nopunct": 0.9404761904761905,
        "vocab_size-2-nopunct": 316,
        "unique-2-nopunct": 301,
        "entropy-2-nopunct": 8.259118352831901,
        "cond_entropy-2-nopunct": 0.925600377184909,
        "distinct-3-nopunct": 0.9903536977491961,
        "vocab_size-3-nopunct": 308,
        "unique-3-nopunct": 305,
        "entropy-3-nopunct": 8.261478165629004,
        "cond_entropy-3-nopunct": 0.009851699448830836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18840579710144928,
            "2": 0.36231884057971014,
            "3": 0.734982332155477
        },
        "nist": 6.232917163179128,
        "rouge1": {
            "precision": 0.74846,
            "recall": 0.72137,
            "fmeasure": 0.72244
        },
        "rouge2": {
            "precision": 0.52803,
            "recall": 0.50655,
            "fmeasure": 0.50785
        },
        "rougeL": {
            "precision": 0.64668,
            "recall": 0.61874,
            "fmeasure": 0.62283
        },
        "rougeLsum": {
            "precision": 0.64668,
            "recall": 0.61874,
            "fmeasure": 0.62283
        },
        "bleu": 45.7511,
        "nubia": {
            "semantic_relation": 3.90519,
            "contradiction": 18.71678,
            "irrelevancy": 29.53013,
            "logical_agreement": 51.75309,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.7987,
            "nubia_score": 0.6112
        },
        "bleurt": 0.15287,
        "meteor": 0.38425748940735227,
        "bertscore": {
            "precision": 0.9247,
            "recall": 0.92035,
            "f1": 0.92092
        }
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.7084,
        "msttr-100_nopunct": 0.76682,
        "total_length": 2552,
        "mean_pred_length": 17.013333333333332,
        "std_pred_length": 5.108145999827682,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.4157523510971787,
        "vocab_size-1": 1061,
        "unique-1": 818,
        "entropy-1": 8.277293551683293,
        "distinct-2": 0.8101582014987511,
        "vocab_size-2": 1946,
        "unique-2": 1748,
        "entropy-2": 10.650848383075578,
        "cond_entropy-2": 2.142772425775749,
        "distinct-3": 0.94449378330373,
        "vocab_size-3": 2127,
        "unique-3": 2047,
        "entropy-3": 11.00482584679986,
        "cond_entropy-3": 0.3474618921759424,
        "total_length-nopunct": 2208,
        "mean_pred_length-nopunct": 14.72,
        "std_pred_length-nopunct": 4.497584536911638,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4759963768115942,
        "vocab_size-1-nopunct": 1051,
        "unique-1-nopunct": 816,
        "entropy-1-nopunct": 8.610025979281337,
        "distinct-2-nopunct": 0.8357628765792031,
        "vocab_size-2-nopunct": 1720,
        "unique-2-nopunct": 1577,
        "entropy-2-nopunct": 10.484069088804619,
        "cond_entropy-2-nopunct": 1.9783631192535513,
        "distinct-3-nopunct": 0.960167714884696,
        "vocab_size-3-nopunct": 1832,
        "unique-3-nopunct": 1780,
        "entropy-3-nopunct": 10.804599437662608,
        "cond_entropy-3-nopunct": 0.34603567445446354,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15513126491646778,
            "2": 0.33568904593639576,
            "3": 0.799140708915145
        },
        "nist": 8.236104998571749,
        "rouge1": {
            "precision": 0.80872,
            "recall": 0.77445,
            "fmeasure": 0.78481
        },
        "rouge2": {
            "precision": 0.5703,
            "recall": 0.54517,
            "fmeasure": 0.55247
        },
        "rougeL": {
            "precision": 0.71075,
            "recall": 0.67722,
            "fmeasure": 0.68785
        },
        "rougeLsum": {
            "precision": 0.71075,
            "recall": 0.67722,
            "fmeasure": 0.68785
        },
        "bleu": 48.92234,
        "nubia": {
            "semantic_relation": 4.47007,
            "contradiction": 4.78183,
            "irrelevancy": 18.27579,
            "logical_agreement": 76.94239,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.58861,
            "nubia_score": 0.80874
        },
        "bleurt": 0.39805,
        "meteor": 0.4124524825407202,
        "bertscore": {
            "precision": 0.94217,
            "recall": 0.93816,
            "f1": 0.9392
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.0224469564457176,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "nist": 2.3636363636363638,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.76923,
            "fmeasure": 0.625
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.58333,
            "fmeasure": 0.46667
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.76923,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.76923,
            "fmeasure": 0.625
        },
        "bleu": 40.12328,
        "nubia": {
            "semantic_relation": 3.87243,
            "contradiction": 0.1559,
            "irrelevancy": 99.71823,
            "logical_agreement": 0.12588,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.52401,
            "nubia_score": 0.78647
        },
        "bleurt": 0.45319,
        "meteor": 0.4943610196036882,
        "bertscore": {
            "precision": 0.90623,
            "recall": 0.96528,
            "f1": 0.93482
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 297,
        "msttr-100": 0.63964,
        "msttr-100_nopunct": 0.685,
        "total_length": 2831,
        "mean_pred_length": 9.531986531986531,
        "std_pred_length": 2.578038645768886,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 23,
        "distinct-1": 0.2387848816672554,
        "vocab_size-1": 676,
        "unique-1": 364,
        "entropy-1": 7.436217161789589,
        "distinct-2": 0.5564325177584846,
        "vocab_size-2": 1410,
        "unique-2": 998,
        "entropy-2": 9.949920707763736,
        "cond_entropy-2": 2.0233792547902882,
        "distinct-3": 0.7335717478766205,
        "vocab_size-3": 1641,
        "unique-3": 1332,
        "entropy-3": 10.430769921013004,
        "cond_entropy-3": 0.5584713901537316,
        "total_length-nopunct": 2475,
        "mean_pred_length-nopunct": 8.333333333333334,
        "std_pred_length-nopunct": 2.3079426610293696,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.2690909090909091,
        "vocab_size-1-nopunct": 666,
        "unique-1-nopunct": 359,
        "entropy-1-nopunct": 7.734802693961666,
        "distinct-2-nopunct": 0.5344352617079889,
        "vocab_size-2-nopunct": 1164,
        "unique-2-nopunct": 800,
        "entropy-2-nopunct": 9.652902905721874,
        "cond_entropy-2-nopunct": 2.2079070225529587,
        "distinct-3-nopunct": 0.7208931419457735,
        "vocab_size-3-nopunct": 1356,
        "unique-3-nopunct": 1087,
        "entropy-3-nopunct": 10.143458453199079,
        "cond_entropy-3-nopunct": 0.6041631157823225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22503419972640218,
            "2": 0.7015544041450777,
            "3": 0.8844519966015293,
            "4": 0.9473684210526315
        },
        "nist": 9.242562124086945,
        "rouge1": {
            "precision": 0.83148,
            "recall": 0.79932,
            "fmeasure": 0.80798
        },
        "rouge2": {
            "precision": 0.62157,
            "recall": 0.59591,
            "fmeasure": 0.60251
        },
        "rougeL": {
            "precision": 0.76289,
            "recall": 0.73151,
            "fmeasure": 0.74029
        },
        "rougeLsum": {
            "precision": 0.76289,
            "recall": 0.73151,
            "fmeasure": 0.74029
        },
        "bleu": 62.91748,
        "nubia": {
            "semantic_relation": 4.62504,
            "contradiction": 6.59047,
            "irrelevancy": 6.03323,
            "logical_agreement": 87.3763,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.33364,
            "nubia_score": 0.84093
        },
        "bleurt": 0.42342,
        "meteor": 0.47614072969791776,
        "bertscore": {
            "precision": 0.95291,
            "recall": 0.9503,
            "f1": 0.95071
        }
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 72,
        "msttr-100": 0.6175,
        "msttr-100_nopunct": 0.65,
        "total_length": 801,
        "mean_pred_length": 11.125,
        "std_pred_length": 2.8622907492659326,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.33707865168539325,
        "vocab_size-1": 270,
        "unique-1": 170,
        "entropy-1": 6.695218171707638,
        "distinct-2": 0.6460905349794238,
        "vocab_size-2": 471,
        "unique-2": 344,
        "entropy-2": 8.564675433570157,
        "cond_entropy-2": 1.5514834603078527,
        "distinct-3": 0.7534246575342466,
        "vocab_size-3": 495,
        "unique-3": 396,
        "entropy-3": 8.763651877809297,
        "cond_entropy-3": 0.2679144679716128,
        "total_length-nopunct": 691,
        "mean_pred_length-nopunct": 9.597222222222221,
        "std_pred_length-nopunct": 2.424754983167384,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3835021707670043,
        "vocab_size-1-nopunct": 265,
        "unique-1-nopunct": 169,
        "entropy-1-nopunct": 6.85734883491324,
        "distinct-2-nopunct": 0.6316639741518578,
        "vocab_size-2-nopunct": 391,
        "unique-2-nopunct": 279,
        "entropy-2-nopunct": 8.295615237944046,
        "cond_entropy-2-nopunct": 1.6589948568272843,
        "distinct-3-nopunct": 0.7550274223034735,
        "vocab_size-3-nopunct": 413,
        "unique-3-nopunct": 329,
        "entropy-3-nopunct": 8.508912094112818,
        "cond_entropy-3-nopunct": 0.2818602446658247,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.2300469483568075,
            "2": 0.6513409961685823,
            "3": 0.8875379939209727
        },
        "nist": 7.0257953660542265,
        "rouge1": {
            "precision": 0.79005,
            "recall": 0.75399,
            "fmeasure": 0.76413
        },
        "rouge2": {
            "precision": 0.53693,
            "recall": 0.51741,
            "fmeasure": 0.52139
        },
        "rougeL": {
            "precision": 0.68992,
            "recall": 0.65944,
            "fmeasure": 0.6682
        },
        "rougeLsum": {
            "precision": 0.68992,
            "recall": 0.65944,
            "fmeasure": 0.6682
        },
        "bleu": 48.68207,
        "nubia": {
            "semantic_relation": 4.44624,
            "contradiction": 7.01213,
            "irrelevancy": 14.11092,
            "logical_agreement": 78.87695,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.64625,
            "nubia_score": 0.7389
        },
        "bleurt": 0.15435,
        "meteor": 0.41801480077615705,
        "bertscore": {
            "precision": 0.92374,
            "recall": 0.92147,
            "f1": 0.9215
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 1654,
        "msttr-100": 0.51465,
        "msttr-100_nopunct": 0.51996,
        "total_length": 31021,
        "mean_pred_length": 18.755139056831922,
        "std_pred_length": 6.468219737825377,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.06115212275555269,
        "vocab_size-1": 1897,
        "unique-1": 624,
        "entropy-1": 8.151273619537257,
        "distinct-2": 0.22099635645452378,
        "vocab_size-2": 6490,
        "unique-2": 3253,
        "entropy-2": 11.260297999205681,
        "cond_entropy-2": 3.0502941521830698,
        "distinct-3": 0.3937863096741601,
        "vocab_size-3": 10913,
        "unique-3": 6863,
        "entropy-3": 12.470387926308613,
        "cond_entropy-3": 1.3175369075072654,
        "total_length-nopunct": 27973,
        "mean_pred_length-nopunct": 16.912333736396615,
        "std_pred_length-nopunct": 6.143698829155945,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.06745790583777214,
        "vocab_size-1-nopunct": 1887,
        "unique-1-nopunct": 623,
        "entropy-1-nopunct": 8.353619695228723,
        "distinct-2-nopunct": 0.23150575629773168,
        "vocab_size-2-nopunct": 6093,
        "unique-2-nopunct": 3231,
        "entropy-2-nopunct": 11.14186373188938,
        "cond_entropy-2-nopunct": 2.975675931687655,
        "distinct-3-nopunct": 0.4020677072775187,
        "vocab_size-3-nopunct": 9917,
        "unique-3-nopunct": 6413,
        "entropy-3-nopunct": 12.304816659212099,
        "cond_entropy-3-nopunct": 1.270218176432452,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19174375432634824,
            "2": 0.5006318449873631,
            "3": 0.7366442199775534,
            "4": 0.8909090909090909,
            "5": 0.6896551724137931
        },
        "nist": 6.9100286087314835,
        "rouge1": {
            "precision": 0.77601,
            "recall": 0.67767,
            "fmeasure": 0.71057
        },
        "rouge2": {
            "precision": 0.52112,
            "recall": 0.4535,
            "fmeasure": 0.47505
        },
        "rougeL": {
            "precision": 0.64358,
            "recall": 0.56399,
            "fmeasure": 0.5901
        },
        "rougeLsum": {
            "precision": 0.64358,
            "recall": 0.56399,
            "fmeasure": 0.5901
        },
        "bleu": 39.46136,
        "nubia": {
            "semantic_relation": 4.13578,
            "contradiction": 7.85926,
            "irrelevancy": 9.52427,
            "logical_agreement": 82.61648,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.83616,
            "nubia_score": 0.67466
        },
        "bleurt": 0.04664,
        "meteor": 0.3268549132526429,
        "bertscore": {
            "precision": 0.92132,
            "recall": 0.90098,
            "f1": 0.9095
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 6.018490028422597,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.964904158123496,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.05278407492995249,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 5.0990195135927845,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.923181998146335,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": -0.004170190416601392,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.36363636363636365,
            "3": 0.65625
        },
        "nist": 2.3079061508896443,
        "rouge1": {
            "precision": 0.84535,
            "recall": 0.74921,
            "fmeasure": 0.78407
        },
        "rouge2": {
            "precision": 0.62963,
            "recall": 0.58907,
            "fmeasure": 0.60135
        },
        "rougeL": {
            "precision": 0.81027,
            "recall": 0.7254,
            "fmeasure": 0.7557
        },
        "rougeLsum": {
            "precision": 0.81027,
            "recall": 0.7254,
            "fmeasure": 0.7557
        },
        "bleu": 33.33137,
        "nubia": {
            "semantic_relation": 4.17543,
            "contradiction": 26.35773,
            "irrelevancy": 6.79546,
            "logical_agreement": 66.84682,
            "grammar_ref": 5.04645,
            "grammar_hyp": 5.29659,
            "nubia_score": 0.65467
        },
        "bleurt": 0.45906,
        "meteor": 0.34480485709022535,
        "bertscore": {
            "precision": 0.96181,
            "recall": 0.93169,
            "f1": 0.9452
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 54,
        "msttr-100": 0.75222,
        "msttr-100_nopunct": 0.8075,
        "total_length": 903,
        "mean_pred_length": 16.72222222222222,
        "std_pred_length": 5.264896561421615,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.5271317829457365,
        "vocab_size-1": 476,
        "unique-1": 378,
        "entropy-1": 7.881759293212396,
        "distinct-2": 0.901060070671378,
        "vocab_size-2": 765,
        "unique-2": 719,
        "entropy-2": 9.46950037854515,
        "cond_entropy-2": 1.4013434317075488,
        "distinct-3": 0.9849056603773585,
        "vocab_size-3": 783,
        "unique-3": 772,
        "entropy-3": 9.603672826898693,
        "cond_entropy-3": 0.13759958246094986,
        "total_length-nopunct": 806,
        "mean_pred_length-nopunct": 14.925925925925926,
        "std_pred_length-nopunct": 4.954802578015155,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5806451612903226,
        "vocab_size-1-nopunct": 468,
        "unique-1-nopunct": 376,
        "entropy-1-nopunct": 8.072468841213121,
        "distinct-2-nopunct": 0.9029255319148937,
        "vocab_size-2-nopunct": 679,
        "unique-2-nopunct": 641,
        "entropy-2-nopunct": 9.29383446020231,
        "cond_entropy-2-nopunct": 1.2803606069950595,
        "distinct-3-nopunct": 0.9856733524355301,
        "vocab_size-3-nopunct": 688,
        "unique-3-nopunct": 679,
        "entropy-3-nopunct": 9.4173484303612,
        "cond_entropy-3-nopunct": 0.12806102824508078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20670391061452514,
            "2": 0.37714285714285717,
            "3": 0.7241935483870968
        },
        "nist": 6.421572609922708,
        "rouge1": {
            "precision": 0.72023,
            "recall": 0.68294,
            "fmeasure": 0.68792
        },
        "rouge2": {
            "precision": 0.48293,
            "recall": 0.46107,
            "fmeasure": 0.46139
        },
        "rougeL": {
            "precision": 0.61218,
            "recall": 0.59154,
            "fmeasure": 0.58871
        },
        "rougeLsum": {
            "precision": 0.61218,
            "recall": 0.59154,
            "fmeasure": 0.58871
        },
        "bleu": 37.29414,
        "nubia": {
            "semantic_relation": 4.11303,
            "contradiction": 5.39152,
            "irrelevancy": 32.60599,
            "logical_agreement": 62.00249,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.70592,
            "nubia_score": 0.69149
        },
        "bleurt": 0.19858,
        "meteor": 0.3650945978286418,
        "bertscore": {
            "precision": 0.9211,
            "recall": 0.91508,
            "f1": 0.91709
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 14.5,
        "std_pred_length": 7.932002689527196,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.6781609195402298,
        "vocab_size-1": 59,
        "unique-1": 48,
        "entropy-1": 5.575311961879025,
        "distinct-2": 0.8271604938271605,
        "vocab_size-2": 67,
        "unique-2": 61,
        "entropy-2": 5.90145771888058,
        "cond_entropy-2": 0.2470858647717028,
        "distinct-3": 0.88,
        "vocab_size-3": 66,
        "unique-3": 62,
        "entropy-3": 5.931956523742685,
        "cond_entropy-3": -0.0410964790842569,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 6.724747000610671,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.611552145330428,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.764857659740301,
        "cond_entropy-2-nopunct": 0.09356626024814299,
        "distinct-3-nopunct": 0.90625,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.777114648336087,
        "cond_entropy-3-nopunct": -0.07857813416627059,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7567567567567568
        },
        "nist": 4.176064970987163,
        "rouge1": {
            "precision": 0.86508,
            "recall": 0.86727,
            "fmeasure": 0.86274
        },
        "rouge2": {
            "precision": 0.78913,
            "recall": 0.78889,
            "fmeasure": 0.7867
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.79335,
            "fmeasure": 0.79034
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.79335,
            "fmeasure": 0.79034
        },
        "bleu": 49.58211,
        "nubia": {
            "semantic_relation": 4.69632,
            "contradiction": 0.6437,
            "irrelevancy": 18.99937,
            "logical_agreement": 80.35693,
            "grammar_ref": 5.92578,
            "grammar_hyp": 5.9153,
            "nubia_score": 0.88886
        },
        "bleurt": 0.68435,
        "meteor": 0.42207659646856327,
        "bertscore": {
            "precision": 0.96356,
            "recall": 0.95937,
            "f1": 0.96118
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.77143,
        "total_length": 823,
        "mean_pred_length": 17.145833333333332,
        "std_pred_length": 5.947652139476738,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.5236938031591738,
        "vocab_size-1": 431,
        "unique-1": 346,
        "entropy-1": 7.697715393849308,
        "distinct-2": 0.912258064516129,
        "vocab_size-2": 707,
        "unique-2": 662,
        "entropy-2": 9.373623907397851,
        "cond_entropy-2": 1.4904128432275323,
        "distinct-3": 0.9876203576341128,
        "vocab_size-3": 718,
        "unique-3": 709,
        "entropy-3": 9.481052269187646,
        "cond_entropy-3": 0.11124207905633905,
        "total_length-nopunct": 713,
        "mean_pred_length-nopunct": 14.854166666666666,
        "std_pred_length-nopunct": 5.224101132145978,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5946704067321178,
        "vocab_size-1-nopunct": 424,
        "unique-1-nopunct": 344,
        "entropy-1-nopunct": 7.924000658500197,
        "distinct-2-nopunct": 0.924812030075188,
        "vocab_size-2-nopunct": 615,
        "unique-2-nopunct": 585,
        "entropy-2-nopunct": 9.173936437321235,
        "cond_entropy-2-nopunct": 1.3157843563648626,
        "distinct-3-nopunct": 0.9918962722852512,
        "vocab_size-3-nopunct": 612,
        "unique-3-nopunct": 607,
        "entropy-3-nopunct": 9.252919223719942,
        "cond_entropy-3-nopunct": 0.09317590871181239,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.5576923076923077,
            "3": 0.7084942084942085
        },
        "nist": 6.562878542307064,
        "rouge1": {
            "precision": 0.73982,
            "recall": 0.68193,
            "fmeasure": 0.70077
        },
        "rouge2": {
            "precision": 0.4764,
            "recall": 0.44091,
            "fmeasure": 0.45034
        },
        "rougeL": {
            "precision": 0.61958,
            "recall": 0.57845,
            "fmeasure": 0.59014
        },
        "rougeLsum": {
            "precision": 0.61958,
            "recall": 0.57845,
            "fmeasure": 0.59014
        },
        "bleu": 38.96056,
        "nubia": {
            "semantic_relation": 4.06562,
            "contradiction": 5.61082,
            "irrelevancy": 36.93477,
            "logical_agreement": 57.45441,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.67927,
            "nubia_score": 0.69207
        },
        "bleurt": 0.19034,
        "meteor": 0.35543690834341946,
        "bertscore": {
            "precision": 0.92202,
            "recall": 0.9113,
            "f1": 0.91358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.188721875540867,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.3067316181128198,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.027169118440619,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.3379852264664119,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.375
        },
        "nist": 1.101502313615033,
        "rouge1": {
            "precision": 0.36111,
            "recall": 0.37963,
            "fmeasure": 0.35813
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.20175,
            "fmeasure": 0.1848
        },
        "rougeL": {
            "precision": 0.36111,
            "recall": 0.37963,
            "fmeasure": 0.35813
        },
        "rougeLsum": {
            "precision": 0.36111,
            "recall": 0.37963,
            "fmeasure": 0.35813
        },
        "bleu": 8.51659,
        "nubia": {
            "semantic_relation": 3.01395,
            "contradiction": 62.40661,
            "irrelevancy": 32.09841,
            "logical_agreement": 5.49498,
            "grammar_ref": 4.8547,
            "grammar_hyp": 6.09391,
            "nubia_score": 0.20151
        },
        "bleurt": -0.37258,
        "meteor": 0.18026922795137582,
        "bertscore": {
            "precision": 0.88997,
            "recall": 0.9055,
            "f1": 0.89767
        }
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.70813,
        "msttr-100_nopunct": 0.76286,
        "total_length": 1645,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 4.919672204850095,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.45167173252279635,
        "vocab_size-1": 743,
        "unique-1": 591,
        "entropy-1": 7.988817516910372,
        "distinct-2": 0.8363636363636363,
        "vocab_size-2": 1288,
        "unique-2": 1179,
        "entropy-2": 10.085714313719757,
        "cond_entropy-2": 1.8529437691477173,
        "distinct-3": 0.9498257839721255,
        "vocab_size-3": 1363,
        "unique-3": 1319,
        "entropy-3": 10.36698314914526,
        "cond_entropy-3": 0.30260711474285606,
        "total_length-nopunct": 1440,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 4.597544449593325,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5104166666666666,
        "vocab_size-1-nopunct": 735,
        "unique-1-nopunct": 589,
        "entropy-1-nopunct": 8.253228844148488,
        "distinct-2-nopunct": 0.846441947565543,
        "vocab_size-2-nopunct": 1130,
        "unique-2-nopunct": 1049,
        "entropy-2-nopunct": 9.887663708795017,
        "cond_entropy-2-nopunct": 1.758013755296976,
        "distinct-3-nopunct": 0.9658536585365853,
        "vocab_size-3-nopunct": 1188,
        "unique-3-nopunct": 1160,
        "entropy-3-nopunct": 10.184277267759708,
        "cond_entropy-3-nopunct": 0.3226193534153839,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23417721518987342,
            "2": 0.3220338983050847,
            "3": 0.7779675491033304
        },
        "nist": 7.629337261634711,
        "rouge1": {
            "precision": 0.78718,
            "recall": 0.75462,
            "fmeasure": 0.76103
        },
        "rouge2": {
            "precision": 0.53627,
            "recall": 0.50797,
            "fmeasure": 0.51497
        },
        "rougeL": {
            "precision": 0.66486,
            "recall": 0.63382,
            "fmeasure": 0.64075
        },
        "rougeLsum": {
            "precision": 0.66486,
            "recall": 0.63382,
            "fmeasure": 0.64075
        },
        "bleu": 42.67199,
        "nubia": {
            "semantic_relation": 4.45765,
            "contradiction": 5.31055,
            "irrelevancy": 23.77311,
            "logical_agreement": 70.91634,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.06279,
            "nubia_score": 0.78622
        },
        "bleurt": 0.35105,
        "meteor": 0.385271856628335,
        "bertscore": {
            "precision": 0.9369,
            "recall": 0.93199,
            "f1": 0.93363
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.67167,
        "msttr-100_nopunct": 0.716,
        "total_length": 619,
        "mean_pred_length": 17.194444444444443,
        "std_pred_length": 5.4864451375105885,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.531502423263328,
        "vocab_size-1": 329,
        "unique-1": 264,
        "entropy-1": 7.25505378880765,
        "distinct-2": 0.8919382504288165,
        "vocab_size-2": 520,
        "unique-2": 485,
        "entropy-2": 8.884557347620877,
        "cond_entropy-2": 1.490729321339143,
        "distinct-3": 0.9597806215722121,
        "vocab_size-3": 525,
        "unique-3": 508,
        "entropy-3": 9.008058014546092,
        "cond_entropy-3": 0.14342865617736744,
        "total_length-nopunct": 546,
        "mean_pred_length-nopunct": 15.166666666666666,
        "std_pred_length-nopunct": 5.30461015427985,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5897435897435898,
        "vocab_size-1-nopunct": 322,
        "unique-1-nopunct": 264,
        "entropy-1-nopunct": 7.390035305946313,
        "distinct-2-nopunct": 0.8941176470588236,
        "vocab_size-2-nopunct": 456,
        "unique-2-nopunct": 428,
        "entropy-2-nopunct": 8.686471966253551,
        "cond_entropy-2-nopunct": 1.4025701133615138,
        "distinct-3-nopunct": 0.9725738396624473,
        "vocab_size-3-nopunct": 461,
        "unique-3-nopunct": 451,
        "entropy-3-nopunct": 8.829113159222075,
        "cond_entropy-3-nopunct": 0.16602459579923812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23648648648648649,
            "2": 0.38202247191011235,
            "3": 0.7723970944309927
        },
        "nist": 6.741721700897683,
        "rouge1": {
            "precision": 0.78732,
            "recall": 0.7518,
            "fmeasure": 0.75785
        },
        "rouge2": {
            "precision": 0.5498,
            "recall": 0.52247,
            "fmeasure": 0.52712
        },
        "rougeL": {
            "precision": 0.68383,
            "recall": 0.65536,
            "fmeasure": 0.65827
        },
        "rougeLsum": {
            "precision": 0.68383,
            "recall": 0.65536,
            "fmeasure": 0.65827
        },
        "bleu": 45.43122,
        "nubia": {
            "semantic_relation": 4.13552,
            "contradiction": 5.78058,
            "irrelevancy": 30.30656,
            "logical_agreement": 63.91286,
            "grammar_ref": 4.82696,
            "grammar_hyp": 4.91911,
            "nubia_score": 0.6853
        },
        "bleurt": 0.24893,
        "meteor": 0.3769213860635119,
        "bertscore": {
            "precision": 0.94068,
            "recall": 0.92803,
            "f1": 0.93256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 88,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 5.557777333511022,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7386363636363636,
        "vocab_size-1": 65,
        "unique-1": 55,
        "entropy-1": 5.760750443008167,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 80,
        "unique-2": 78,
        "entropy-2": 6.308771516813209,
        "cond_entropy-2": 0.4100004890422146,
        "distinct-3": 1.0,
        "vocab_size-3": 76,
        "unique-3": 76,
        "entropy-3": 6.247927513443591,
        "cond_entropy-3": -0.056992912227129475,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 12.833333333333334,
        "std_pred_length-nopunct": 5.273097339852125,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8051948051948052,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.773615521850266,
        "distinct-2-nopunct": 0.971830985915493,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.093409091335663,
        "cond_entropy-2-nopunct": 0.3473854865708664,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.06584084493776614,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5769230769230769,
            "3": 0.7241379310344828
        },
        "nist": 4.717778299683707,
        "rouge1": {
            "precision": 0.75615,
            "recall": 0.61828,
            "fmeasure": 0.67355
        },
        "rouge2": {
            "precision": 0.50117,
            "recall": 0.4148,
            "fmeasure": 0.44952
        },
        "rougeL": {
            "precision": 0.59087,
            "recall": 0.50135,
            "fmeasure": 0.53643
        },
        "rougeLsum": {
            "precision": 0.59087,
            "recall": 0.50135,
            "fmeasure": 0.53643
        },
        "bleu": 44.74583,
        "nubia": {
            "semantic_relation": 4.14509,
            "contradiction": 0.41575,
            "irrelevancy": 43.41579,
            "logical_agreement": 56.16846,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.34755,
            "nubia_score": 0.73981
        },
        "bleurt": 0.16501,
        "meteor": 0.3621167389267065,
        "bertscore": {
            "precision": 0.92515,
            "recall": 0.89787,
            "f1": 0.91064
        }
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 125,
        "msttr-100": 0.46793,
        "msttr-100_nopunct": 0.46154,
        "total_length": 2955,
        "mean_pred_length": 23.64,
        "std_pred_length": 4.016764867402622,
        "median_pred_length": 25.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.13840947546531304,
        "vocab_size-1": 409,
        "unique-1": 144,
        "entropy-1": 7.029468364777245,
        "distinct-2": 0.3558303886925795,
        "vocab_size-2": 1007,
        "unique-2": 551,
        "entropy-2": 9.219954177352763,
        "cond_entropy-2": 2.2133436374754525,
        "distinct-3": 0.5375231053604437,
        "vocab_size-3": 1454,
        "unique-3": 993,
        "entropy-3": 9.988461326246254,
        "cond_entropy-3": 0.8263708050341094,
        "total_length-nopunct": 2680,
        "mean_pred_length-nopunct": 21.44,
        "std_pred_length-nopunct": 3.8707105290889428,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.15111940298507462,
        "vocab_size-1-nopunct": 405,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 7.113205747777888,
        "distinct-2-nopunct": 0.3690802348336595,
        "vocab_size-2-nopunct": 943,
        "unique-2-nopunct": 529,
        "entropy-2-nopunct": 9.127426646329704,
        "cond_entropy-2-nopunct": 2.1132318433820454,
        "distinct-3-nopunct": 0.5452674897119342,
        "vocab_size-3-nopunct": 1325,
        "unique-3-nopunct": 930,
        "entropy-3-nopunct": 9.835087514914344,
        "cond_entropy-3-nopunct": 0.7576245977843412,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.16514954486345904,
            "2": 0.4157303370786517,
            "3": 0.7214285714285714
        },
        "nist": 5.626283657163476,
        "rouge1": {
            "precision": 0.70789,
            "recall": 0.61602,
            "fmeasure": 0.64438
        },
        "rouge2": {
            "precision": 0.43453,
            "recall": 0.37404,
            "fmeasure": 0.39159
        },
        "rougeL": {
            "precision": 0.54915,
            "recall": 0.47902,
            "fmeasure": 0.49923
        },
        "rougeLsum": {
            "precision": 0.54915,
            "recall": 0.47902,
            "fmeasure": 0.49923
        },
        "bleu": 34.30778,
        "nubia": {
            "semantic_relation": 3.81999,
            "contradiction": 9.7621,
            "irrelevancy": 16.29568,
            "logical_agreement": 73.94222,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.62961,
            "nubia_score": 0.56921
        },
        "bleurt": -0.19895,
        "meteor": 0.29131315594728535,
        "bertscore": {
            "precision": 0.89403,
            "recall": 0.87006,
            "f1": 0.87986
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 112,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.74313,
        "total_length": 1831,
        "mean_pred_length": 16.348214285714285,
        "std_pred_length": 5.231617172519021,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 34,
        "distinct-1": 0.4369197160021846,
        "vocab_size-1": 800,
        "unique-1": 662,
        "entropy-1": 8.019519813204031,
        "distinct-2": 0.8016288539848749,
        "vocab_size-2": 1378,
        "unique-2": 1257,
        "entropy-2": 10.09462346369986,
        "cond_entropy-2": 1.8566631730970404,
        "distinct-3": 0.9054138145612943,
        "vocab_size-3": 1455,
        "unique-3": 1396,
        "entropy-3": 10.368896762085779,
        "cond_entropy-3": 0.290625072919317,
        "total_length-nopunct": 1601,
        "mean_pred_length-nopunct": 14.294642857142858,
        "std_pred_length-nopunct": 4.585766785970055,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4934415990006246,
        "vocab_size-1-nopunct": 790,
        "unique-1-nopunct": 658,
        "entropy-1-nopunct": 8.267861826452855,
        "distinct-2-nopunct": 0.8106111484217595,
        "vocab_size-2-nopunct": 1207,
        "unique-2-nopunct": 1117,
        "entropy-2-nopunct": 9.896397612501223,
        "cond_entropy-2-nopunct": 1.7441432278466336,
        "distinct-3-nopunct": 0.9106753812636166,
        "vocab_size-3-nopunct": 1254,
        "unique-3-nopunct": 1209,
        "entropy-3-nopunct": 10.161517124899,
        "cond_entropy-3-nopunct": 0.2982595533609064,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2433234421364985,
            "2": 0.4583333333333333,
            "3": 0.800524934383202
        },
        "nist": 7.404020893248075,
        "rouge1": {
            "precision": 0.74059,
            "recall": 0.73611,
            "fmeasure": 0.72799
        },
        "rouge2": {
            "precision": 0.51853,
            "recall": 0.51365,
            "fmeasure": 0.50902
        },
        "rougeL": {
            "precision": 0.63505,
            "recall": 0.6341,
            "fmeasure": 0.62553
        },
        "rougeLsum": {
            "precision": 0.63505,
            "recall": 0.6341,
            "fmeasure": 0.62553
        },
        "bleu": 44.93763,
        "nubia": {
            "semantic_relation": 4.12798,
            "contradiction": 9.57902,
            "irrelevancy": 28.52547,
            "logical_agreement": 61.89551,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.69322,
            "nubia_score": 0.71709
        },
        "bleurt": 0.23454,
        "meteor": 0.3831404120531088,
        "bertscore": {
            "precision": 0.92161,
            "recall": 0.92172,
            "f1": 0.92047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.68571,
        "msttr-100_nopunct": 0.73,
        "total_length": 780,
        "mean_pred_length": 16.595744680851062,
        "std_pred_length": 5.591252950084928,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.514102564102564,
        "vocab_size-1": 401,
        "unique-1": 332,
        "entropy-1": 7.441450214743238,
        "distinct-2": 0.869031377899045,
        "vocab_size-2": 637,
        "unique-2": 582,
        "entropy-2": 9.165791255164384,
        "cond_entropy-2": 1.5465445557100794,
        "distinct-3": 0.9446064139941691,
        "vocab_size-3": 648,
        "unique-3": 621,
        "entropy-3": 9.295068533696556,
        "cond_entropy-3": 0.14463919143231838,
        "total_length-nopunct": 674,
        "mean_pred_length-nopunct": 14.340425531914894,
        "std_pred_length-nopunct": 4.847796585441288,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5801186943620178,
        "vocab_size-1-nopunct": 391,
        "unique-1-nopunct": 329,
        "entropy-1-nopunct": 7.612067008284837,
        "distinct-2-nopunct": 0.8771929824561403,
        "vocab_size-2-nopunct": 550,
        "unique-2-nopunct": 508,
        "entropy-2-nopunct": 8.95171215355178,
        "cond_entropy-2-nopunct": 1.4548435808910407,
        "distinct-3-nopunct": 0.9534482758620689,
        "vocab_size-3-nopunct": 553,
        "unique-3-nopunct": 532,
        "entropy-3-nopunct": 9.077306029662683,
        "cond_entropy-3-nopunct": 0.14457429942953895,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1592920353982301,
            "2": 0.4823529411764706,
            "3": 0.725
        },
        "nist": 6.238342042938648,
        "rouge1": {
            "precision": 0.73778,
            "recall": 0.6917,
            "fmeasure": 0.70539
        },
        "rouge2": {
            "precision": 0.48704,
            "recall": 0.45543,
            "fmeasure": 0.46508
        },
        "rougeL": {
            "precision": 0.62386,
            "recall": 0.58627,
            "fmeasure": 0.59747
        },
        "rougeLsum": {
            "precision": 0.62386,
            "recall": 0.58627,
            "fmeasure": 0.59747
        },
        "bleu": 37.99953,
        "nubia": {
            "semantic_relation": 4.13628,
            "contradiction": 7.40817,
            "irrelevancy": 29.56292,
            "logical_agreement": 63.02891,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.77969,
            "nubia_score": 0.69254
        },
        "bleurt": 0.2116,
        "meteor": 0.3522328176066278,
        "bertscore": {
            "precision": 0.92142,
            "recall": 0.90879,
            "f1": 0.91412
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.746,
        "total_length": 605,
        "mean_pred_length": 17.285714285714285,
        "std_pred_length": 5.017520324232044,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.543801652892562,
        "vocab_size-1": 329,
        "unique-1": 263,
        "entropy-1": 7.433578104442194,
        "distinct-2": 0.9105263157894737,
        "vocab_size-2": 519,
        "unique-2": 486,
        "entropy-2": 8.943583673975128,
        "cond_entropy-2": 1.3623272409023297,
        "distinct-3": 0.9719626168224299,
        "vocab_size-3": 520,
        "unique-3": 510,
        "entropy-3": 8.99934898314554,
        "cond_entropy-3": 0.06584606660541009,
        "total_length-nopunct": 530,
        "mean_pred_length-nopunct": 15.142857142857142,
        "std_pred_length-nopunct": 4.905640235733658,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6075471698113207,
        "vocab_size-1-nopunct": 322,
        "unique-1-nopunct": 262,
        "entropy-1-nopunct": 7.5607867559983895,
        "distinct-2-nopunct": 0.9252525252525252,
        "vocab_size-2-nopunct": 458,
        "unique-2-nopunct": 434,
        "entropy-2-nopunct": 8.774216552357412,
        "cond_entropy-2-nopunct": 1.2942133918213554,
        "distinct-3-nopunct": 0.9782608695652174,
        "vocab_size-3-nopunct": 450,
        "unique-3-nopunct": 443,
        "entropy-3-nopunct": 8.797088610712892,
        "cond_entropy-3-nopunct": 0.03417072290186852,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1595744680851064,
            "2": 0.5398230088495575,
            "3": 0.7052896725440806
        },
        "nist": 6.324501985186158,
        "rouge1": {
            "precision": 0.72272,
            "recall": 0.70927,
            "fmeasure": 0.70506
        },
        "rouge2": {
            "precision": 0.50865,
            "recall": 0.50194,
            "fmeasure": 0.49744
        },
        "rougeL": {
            "precision": 0.62359,
            "recall": 0.61857,
            "fmeasure": 0.61248
        },
        "rougeLsum": {
            "precision": 0.62359,
            "recall": 0.61857,
            "fmeasure": 0.61248
        },
        "bleu": 42.72978,
        "nubia": {
            "semantic_relation": 3.9812,
            "contradiction": 7.73237,
            "irrelevancy": 40.80276,
            "logical_agreement": 51.46487,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.73282,
            "nubia_score": 0.64431
        },
        "bleurt": 0.15244,
        "meteor": 0.3786210677863272,
        "bertscore": {
            "precision": 0.92175,
            "recall": 0.91634,
            "f1": 0.91722
        }
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.72462,
        "msttr-100_nopunct": 0.78182,
        "total_length": 1328,
        "mean_pred_length": 16.810126582278482,
        "std_pred_length": 4.917228686837788,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.473644578313253,
        "vocab_size-1": 629,
        "unique-1": 493,
        "entropy-1": 7.973372145880924,
        "distinct-2": 0.8630904723779024,
        "vocab_size-2": 1078,
        "unique-2": 997,
        "entropy-2": 9.88887704661288,
        "cond_entropy-2": 1.7309133570133963,
        "distinct-3": 0.9615384615384616,
        "vocab_size-3": 1125,
        "unique-3": 1087,
        "entropy-3": 10.11001532514892,
        "cond_entropy-3": 0.2343150105742544,
        "total_length-nopunct": 1157,
        "mean_pred_length-nopunct": 14.645569620253164,
        "std_pred_length-nopunct": 4.584061475617624,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5367329299913569,
        "vocab_size-1-nopunct": 621,
        "unique-1-nopunct": 492,
        "entropy-1-nopunct": 8.25276484837465,
        "distinct-2-nopunct": 0.8738404452690167,
        "vocab_size-2-nopunct": 942,
        "unique-2-nopunct": 882,
        "entropy-2-nopunct": 9.693415546155732,
        "cond_entropy-2-nopunct": 1.528190875628576,
        "distinct-3-nopunct": 0.968968968968969,
        "vocab_size-3-nopunct": 968,
        "unique-3-nopunct": 941,
        "entropy-3-nopunct": 9.898765517437598,
        "cond_entropy-3-nopunct": 0.22253761574207015,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2196969696969697,
            "2": 0.4077669902912621,
            "3": 0.7961165048543689
        },
        "nist": 7.673400402078944,
        "rouge1": {
            "precision": 0.80897,
            "recall": 0.78028,
            "fmeasure": 0.78802
        },
        "rouge2": {
            "precision": 0.60254,
            "recall": 0.58071,
            "fmeasure": 0.58641
        },
        "rougeL": {
            "precision": 0.69887,
            "recall": 0.67328,
            "fmeasure": 0.68052
        },
        "rougeLsum": {
            "precision": 0.69887,
            "recall": 0.67328,
            "fmeasure": 0.68052
        },
        "bleu": 48.00531,
        "nubia": {
            "semantic_relation": 4.43765,
            "contradiction": 3.57885,
            "irrelevancy": 23.92581,
            "logical_agreement": 72.49534,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.79139,
            "nubia_score": 0.80357
        },
        "bleurt": 0.42032,
        "meteor": 0.40977187830205614,
        "bertscore": {
            "precision": 0.94328,
            "recall": 0.94017,
            "f1": 0.94057
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 91,
        "msttr-100": 0.69929,
        "msttr-100_nopunct": 0.76,
        "total_length": 1438,
        "mean_pred_length": 15.802197802197803,
        "std_pred_length": 4.679202947576709,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.40611961057023643,
        "vocab_size-1": 584,
        "unique-1": 453,
        "entropy-1": 7.700589568173982,
        "distinct-2": 0.749072011878248,
        "vocab_size-2": 1009,
        "unique-2": 897,
        "entropy-2": 9.601821422839945,
        "cond_entropy-2": 1.6778353095345084,
        "distinct-3": 0.8646496815286624,
        "vocab_size-3": 1086,
        "unique-3": 1023,
        "entropy-3": 9.890121157614919,
        "cond_entropy-3": 0.29386424583483844,
        "total_length-nopunct": 1245,
        "mean_pred_length-nopunct": 13.68131868131868,
        "std_pred_length-nopunct": 4.379972203432097,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4610441767068273,
        "vocab_size-1-nopunct": 574,
        "unique-1-nopunct": 448,
        "entropy-1-nopunct": 7.940668830668515,
        "distinct-2-nopunct": 0.7651646447140381,
        "vocab_size-2-nopunct": 883,
        "unique-2-nopunct": 793,
        "entropy-2-nopunct": 9.425841912408808,
        "cond_entropy-2-nopunct": 1.5913536160205806,
        "distinct-3-nopunct": 0.8673565380997178,
        "vocab_size-3-nopunct": 922,
        "unique-3-nopunct": 867,
        "entropy-3-nopunct": 9.662850820180424,
        "cond_entropy-3-nopunct": 0.2793061884247986,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22972972972972974,
            "2": 0.5,
            "3": 0.7888655462184874
        },
        "nist": 7.630010443949656,
        "rouge1": {
            "precision": 0.78789,
            "recall": 0.75408,
            "fmeasure": 0.7595
        },
        "rouge2": {
            "precision": 0.59133,
            "recall": 0.56547,
            "fmeasure": 0.56788
        },
        "rougeL": {
            "precision": 0.70811,
            "recall": 0.68251,
            "fmeasure": 0.68486
        },
        "rougeLsum": {
            "precision": 0.70811,
            "recall": 0.68251,
            "fmeasure": 0.68486
        },
        "bleu": 51.76196,
        "nubia": {
            "semantic_relation": 4.20933,
            "contradiction": 3.913,
            "irrelevancy": 27.61141,
            "logical_agreement": 68.47559,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.46576,
            "nubia_score": 0.74974
        },
        "bleurt": 0.3097,
        "meteor": 0.4109688526585489,
        "bertscore": {
            "precision": 0.93753,
            "recall": 0.93245,
            "f1": 0.93368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 78,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76545,
        "total_length": 1315,
        "mean_pred_length": 16.858974358974358,
        "std_pred_length": 6.277195925861342,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.47452471482889735,
        "vocab_size-1": 624,
        "unique-1": 466,
        "entropy-1": 8.066155346151684,
        "distinct-2": 0.8641875505254648,
        "vocab_size-2": 1069,
        "unique-2": 965,
        "entropy-2": 9.909378847490173,
        "cond_entropy-2": 1.6425746155909695,
        "distinct-3": 0.9646246764452114,
        "vocab_size-3": 1118,
        "unique-3": 1078,
        "entropy-3": 10.107262877320364,
        "cond_entropy-3": 0.18498442724945396,
        "total_length-nopunct": 1148,
        "mean_pred_length-nopunct": 14.717948717948717,
        "std_pred_length-nopunct": 5.661152904002714,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5365853658536586,
        "vocab_size-1-nopunct": 616,
        "unique-1-nopunct": 465,
        "entropy-1-nopunct": 8.294554639946876,
        "distinct-2-nopunct": 0.8785046728971962,
        "vocab_size-2-nopunct": 940,
        "unique-2-nopunct": 860,
        "entropy-2-nopunct": 9.731584196104611,
        "cond_entropy-2-nopunct": 1.5139953296625863,
        "distinct-3-nopunct": 0.9657258064516129,
        "vocab_size-3-nopunct": 958,
        "unique-3-nopunct": 925,
        "entropy-3-nopunct": 9.884886947985395,
        "cond_entropy-3-nopunct": 0.17435239809491668,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2575107296137339,
            "2": 0.46808510638297873,
            "3": 0.7907542579075426
        },
        "nist": 7.542894052483882,
        "rouge1": {
            "precision": 0.78029,
            "recall": 0.74041,
            "fmeasure": 0.74832
        },
        "rouge2": {
            "precision": 0.54966,
            "recall": 0.51887,
            "fmeasure": 0.52352
        },
        "rougeL": {
            "precision": 0.69978,
            "recall": 0.66236,
            "fmeasure": 0.66956
        },
        "rougeLsum": {
            "precision": 0.69978,
            "recall": 0.66236,
            "fmeasure": 0.66956
        },
        "bleu": 48.85208,
        "nubia": {
            "semantic_relation": 4.32824,
            "contradiction": 4.36606,
            "irrelevancy": 26.63153,
            "logical_agreement": 69.00241,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.74949,
            "nubia_score": 0.7636
        },
        "bleurt": 0.32501,
        "meteor": 0.4083956634304436,
        "bertscore": {
            "precision": 0.93577,
            "recall": 0.93207,
            "f1": 0.93235
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.7,
        "total_length": 262,
        "mean_pred_length": 15.411764705882353,
        "std_pred_length": 5.980938579987079,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5801526717557252,
        "vocab_size-1": 152,
        "unique-1": 124,
        "entropy-1": 6.502758167869528,
        "distinct-2": 0.8816326530612245,
        "vocab_size-2": 216,
        "unique-2": 199,
        "entropy-2": 7.605945898150952,
        "cond_entropy-2": 1.0338071268679447,
        "distinct-3": 0.9692982456140351,
        "vocab_size-3": 221,
        "unique-3": 215,
        "entropy-3": 7.768175595295637,
        "cond_entropy-3": 0.18688655983976024,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 13.764705882352942,
        "std_pred_length-nopunct": 5.620649028513531,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6282051282051282,
        "vocab_size-1-nopunct": 147,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.520104511859735,
        "distinct-2-nopunct": 0.8755760368663594,
        "vocab_size-2-nopunct": 190,
        "unique-2-nopunct": 175,
        "entropy-2-nopunct": 7.4066224305612955,
        "cond_entropy-2-nopunct": 0.9922986723020076,
        "distinct-3-nopunct": 0.965,
        "vocab_size-3-nopunct": 193,
        "unique-3-nopunct": 187,
        "entropy-3-nopunct": 7.570081752263923,
        "cond_entropy-3-nopunct": 0.1936282698626985,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.375,
            "3": 0.7251461988304093
        },
        "nist": 4.964259007124815,
        "rouge1": {
            "precision": 0.74033,
            "recall": 0.64118,
            "fmeasure": 0.67028
        },
        "rouge2": {
            "precision": 0.52688,
            "recall": 0.43746,
            "fmeasure": 0.46697
        },
        "rougeL": {
            "precision": 0.66409,
            "recall": 0.57589,
            "fmeasure": 0.60174
        },
        "rougeLsum": {
            "precision": 0.66409,
            "recall": 0.57589,
            "fmeasure": 0.60174
        },
        "bleu": 46.04943,
        "nubia": {
            "semantic_relation": 3.983,
            "contradiction": 11.61501,
            "irrelevancy": 17.37862,
            "logical_agreement": 71.00637,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.57637,
            "nubia_score": 0.64178
        },
        "bleurt": 0.11687,
        "meteor": 0.3508067261216219,
        "bertscore": {
            "precision": 0.91544,
            "recall": 0.90012,
            "f1": 0.90678
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 107,
        "mean_pred_length": 15.285714285714286,
        "std_pred_length": 5.573259772323188,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.6355140186915887,
        "vocab_size-1": 68,
        "unique-1": 49,
        "entropy-1": 5.790545435355774,
        "distinct-2": 0.93,
        "vocab_size-2": 93,
        "unique-2": 86,
        "entropy-2": 6.503856189774739,
        "cond_entropy-2": 0.6247775129488522,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 90,
        "unique-3": 87,
        "entropy-3": 6.474642682075779,
        "cond_entropy-3": -0.040181249634435465,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 5.540205551332947,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.755853363849513,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.291743877314177,
        "cond_entropy-2-nopunct": 0.5991135739994028,
        "distinct-3-nopunct": 0.9743589743589743,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.234120167580205,
        "cond_entropy-3-nopunct": -0.04706564035237632,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.15384615384615385,
            "3": 0.5733333333333334
        },
        "nist": 3.709476045961837,
        "rouge1": {
            "precision": 0.65038,
            "recall": 0.58885,
            "fmeasure": 0.61286
        },
        "rouge2": {
            "precision": 0.40074,
            "recall": 0.34877,
            "fmeasure": 0.36854
        },
        "rougeL": {
            "precision": 0.54063,
            "recall": 0.48615,
            "fmeasure": 0.50754
        },
        "rougeLsum": {
            "precision": 0.54063,
            "recall": 0.48615,
            "fmeasure": 0.50754
        },
        "bleu": 26.91516,
        "nubia": {
            "semantic_relation": 3.63861,
            "contradiction": 4.55915,
            "irrelevancy": 35.10728,
            "logical_agreement": 60.33356,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.34475,
            "nubia_score": 0.59664
        },
        "bleurt": 0.01468,
        "meteor": 0.2736441704846934,
        "bertscore": {
            "precision": 0.89941,
            "recall": 0.86114,
            "f1": 0.87543
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.755,
        "total_length": 259,
        "mean_pred_length": 14.38888888888889,
        "std_pred_length": 5.396901259970998,
        "median_pred_length": 12.5,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6177606177606177,
        "vocab_size-1": 160,
        "unique-1": 133,
        "entropy-1": 6.614091813845342,
        "distinct-2": 0.9336099585062241,
        "vocab_size-2": 225,
        "unique-2": 216,
        "entropy-2": 7.742095728517417,
        "cond_entropy-2": 0.9213244395814827,
        "distinct-3": 0.9820627802690582,
        "vocab_size-3": 219,
        "unique-3": 216,
        "entropy-3": 7.761640314708819,
        "cond_entropy-3": 0.033330617307234245,
        "total_length-nopunct": 226,
        "mean_pred_length-nopunct": 12.555555555555555,
        "std_pred_length-nopunct": 5.438772555786852,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6814159292035398,
        "vocab_size-1-nopunct": 154,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.713138392088229,
        "distinct-2-nopunct": 0.9326923076923077,
        "vocab_size-2-nopunct": 194,
        "unique-2-nopunct": 186,
        "entropy-2-nopunct": 7.525409083734499,
        "cond_entropy-2-nopunct": 0.8840338179246086,
        "distinct-3-nopunct": 0.9894736842105263,
        "vocab_size-3-nopunct": 188,
        "unique-3-nopunct": 186,
        "entropy-3-nopunct": 7.548802976752011,
        "cond_entropy-3-nopunct": 0.029449426803364848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20408163265306123,
            "2": 0.4642857142857143,
            "3": 0.711764705882353
        },
        "nist": 5.539237038270141,
        "rouge1": {
            "precision": 0.76036,
            "recall": 0.67892,
            "fmeasure": 0.70493
        },
        "rouge2": {
            "precision": 0.49619,
            "recall": 0.43561,
            "fmeasure": 0.45456
        },
        "rougeL": {
            "precision": 0.66254,
            "recall": 0.58979,
            "fmeasure": 0.61273
        },
        "rougeLsum": {
            "precision": 0.66254,
            "recall": 0.58979,
            "fmeasure": 0.61273
        },
        "bleu": 39.48199,
        "nubia": {
            "semantic_relation": 4.05596,
            "contradiction": 4.98166,
            "irrelevancy": 36.32226,
            "logical_agreement": 58.69608,
            "grammar_ref": 4.90853,
            "grammar_hyp": 5.04714,
            "nubia_score": 0.67877
        },
        "bleurt": 0.1771,
        "meteor": 0.33606750034309213,
        "bertscore": {
            "precision": 0.92353,
            "recall": 0.91456,
            "f1": 0.9183
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 81,
        "msttr-100": 0.72571,
        "msttr-100_nopunct": 0.80167,
        "total_length": 1420,
        "mean_pred_length": 17.530864197530864,
        "std_pred_length": 5.504400977160018,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.476056338028169,
        "vocab_size-1": 676,
        "unique-1": 531,
        "entropy-1": 8.108778832099883,
        "distinct-2": 0.864824495892457,
        "vocab_size-2": 1158,
        "unique-2": 1059,
        "entropy-2": 10.0243819463765,
        "cond_entropy-2": 1.7392494376105812,
        "distinct-3": 0.951510333863275,
        "vocab_size-3": 1197,
        "unique-3": 1149,
        "entropy-3": 10.192135970370545,
        "cond_entropy-3": 0.1650611263091873,
        "total_length-nopunct": 1211,
        "mean_pred_length-nopunct": 14.950617283950617,
        "std_pred_length-nopunct": 4.758102211596296,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.550784475639967,
        "vocab_size-1-nopunct": 667,
        "unique-1-nopunct": 528,
        "entropy-1-nopunct": 8.422509248861603,
        "distinct-2-nopunct": 0.8831858407079646,
        "vocab_size-2-nopunct": 998,
        "unique-2-nopunct": 927,
        "entropy-2-nopunct": 9.821915179604,
        "cond_entropy-2-nopunct": 1.487172378107008,
        "distinct-3-nopunct": 0.9590085795996187,
        "vocab_size-3-nopunct": 1006,
        "unique-3-nopunct": 973,
        "entropy-3-nopunct": 9.94561986341446,
        "cond_entropy-3-nopunct": 0.14024479781712273,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22866894197952217,
            "2": 0.5271317829457365,
            "3": 0.775175644028103
        },
        "nist": 7.528153484344547,
        "rouge1": {
            "precision": 0.75555,
            "recall": 0.73311,
            "fmeasure": 0.73164
        },
        "rouge2": {
            "precision": 0.54568,
            "recall": 0.52538,
            "fmeasure": 0.52505
        },
        "rougeL": {
            "precision": 0.65957,
            "recall": 0.64007,
            "fmeasure": 0.638
        },
        "rougeLsum": {
            "precision": 0.65957,
            "recall": 0.64007,
            "fmeasure": 0.638
        },
        "bleu": 49.30032,
        "nubia": {
            "semantic_relation": 4.16936,
            "contradiction": 3.12633,
            "irrelevancy": 33.99218,
            "logical_agreement": 62.88149,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.75021,
            "nubia_score": 0.70526
        },
        "bleurt": 0.21011,
        "meteor": 0.3985766384783402,
        "bertscore": {
            "precision": 0.9274,
            "recall": 0.92802,
            "f1": 0.92605
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.73167,
        "msttr-100_nopunct": 0.798,
        "total_length": 1221,
        "mean_pred_length": 15.455696202531646,
        "std_pred_length": 5.4721330123796745,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 30,
        "distinct-1": 0.5200655200655201,
        "vocab_size-1": 635,
        "unique-1": 522,
        "entropy-1": 8.041954752116682,
        "distinct-2": 0.9071803852889667,
        "vocab_size-2": 1036,
        "unique-2": 973,
        "entropy-2": 9.91367958697687,
        "cond_entropy-2": 1.6194314402731524,
        "distinct-3": 0.9821260583254939,
        "vocab_size-3": 1044,
        "unique-3": 1027,
        "entropy-3": 10.016757701846883,
        "cond_entropy-3": 0.08472894555714662,
        "total_length-nopunct": 1046,
        "mean_pred_length-nopunct": 13.240506329113924,
        "std_pred_length-nopunct": 4.677484961645055,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6003824091778203,
        "vocab_size-1-nopunct": 628,
        "unique-1-nopunct": 520,
        "entropy-1-nopunct": 8.367877688149798,
        "distinct-2-nopunct": 0.9307135470527405,
        "vocab_size-2-nopunct": 900,
        "unique-2-nopunct": 860,
        "entropy-2-nopunct": 9.730822122004252,
        "cond_entropy-2-nopunct": 1.4546090611687434,
        "distinct-3-nopunct": 0.9887387387387387,
        "vocab_size-3-nopunct": 878,
        "unique-3-nopunct": 868,
        "entropy-3-nopunct": 9.771893343827546,
        "cond_entropy-3-nopunct": 0.0540977101553669,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1832797427652733,
            "2": 0.4520547945205479,
            "3": 0.7246376811594203
        },
        "nist": 6.7714231061463295,
        "rouge1": {
            "precision": 0.74089,
            "recall": 0.6722,
            "fmeasure": 0.69013
        },
        "rouge2": {
            "precision": 0.51144,
            "recall": 0.4539,
            "fmeasure": 0.46708
        },
        "rougeL": {
            "precision": 0.65351,
            "recall": 0.58955,
            "fmeasure": 0.60519
        },
        "rougeLsum": {
            "precision": 0.65351,
            "recall": 0.58955,
            "fmeasure": 0.60519
        },
        "bleu": 40.71654,
        "nubia": {
            "semantic_relation": 4.0739,
            "contradiction": 10.56534,
            "irrelevancy": 30.8353,
            "logical_agreement": 58.59936,
            "grammar_ref": 4.80224,
            "grammar_hyp": 5.02265,
            "nubia_score": 0.66004
        },
        "bleurt": 0.15046,
        "meteor": 0.3571719774529783,
        "bertscore": {
            "precision": 0.92814,
            "recall": 0.91599,
            "f1": 0.92013
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.958039891549808,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8,
        "vocab_size-1": 40,
        "unique-1": 36,
        "entropy-1": 5.133660689688188,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.2603530489850477,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.1312445332782525,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.692582403567252,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8809523809523809,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.0886296251082035,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.19126502493228492,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.16046467219324617,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2692307692307692,
            "2": 0.1111111111111111,
            "3": 0.8
        },
        "nist": 4.923615718460338,
        "rouge1": {
            "precision": 0.7149,
            "recall": 0.71974,
            "fmeasure": 0.71266
        },
        "rouge2": {
            "precision": 0.54815,
            "recall": 0.59009,
            "fmeasure": 0.56461
        },
        "rougeL": {
            "precision": 0.68434,
            "recall": 0.69428,
            "fmeasure": 0.6852
        },
        "rougeLsum": {
            "precision": 0.68434,
            "recall": 0.69428,
            "fmeasure": 0.6852
        },
        "bleu": 59.1016,
        "nubia": {
            "semantic_relation": 4.18945,
            "contradiction": 23.24715,
            "irrelevancy": 39.6688,
            "logical_agreement": 37.08404,
            "grammar_ref": 6.02061,
            "grammar_hyp": 5.6361,
            "nubia_score": 0.73719
        },
        "bleurt": 0.26132,
        "meteor": 0.41410618909582725,
        "bertscore": {
            "precision": 0.92539,
            "recall": 0.941,
            "f1": 0.93195
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 1510,
        "msttr-100": 0.49793,
        "msttr-100_nopunct": 0.50774,
        "total_length": 27624,
        "mean_pred_length": 18.29403973509934,
        "std_pred_length": 6.460857505550668,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.0648349261511729,
        "vocab_size-1": 1791,
        "unique-1": 610,
        "entropy-1": 8.10431313188212,
        "distinct-2": 0.224400704602895,
        "vocab_size-2": 5860,
        "unique-2": 2980,
        "entropy-2": 11.140302841704667,
        "cond_entropy-2": 2.966136601047454,
        "distinct-3": 0.3920094293610795,
        "vocab_size-3": 9645,
        "unique-3": 6072,
        "entropy-3": 12.295881374479086,
        "cond_entropy-3": 1.267675922181258,
        "total_length-nopunct": 24879,
        "mean_pred_length-nopunct": 16.47615894039735,
        "std_pred_length-nopunct": 6.137639909350919,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.07158647855621207,
        "vocab_size-1-nopunct": 1781,
        "unique-1-nopunct": 609,
        "entropy-1-nopunct": 8.310952754522342,
        "distinct-2-nopunct": 0.2327870255466644,
        "vocab_size-2-nopunct": 5440,
        "unique-2-nopunct": 2884,
        "entropy-2-nopunct": 11.008556975222252,
        "cond_entropy-2-nopunct": 2.8924506897345528,
        "distinct-3-nopunct": 0.3975479207649023,
        "vocab_size-3-nopunct": 8690,
        "unique-3-nopunct": 5596,
        "entropy-3-nopunct": 12.117473665227559,
        "cond_entropy-3-nopunct": 1.222217388047932,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19534585824081982,
            "2": 0.5103798065581505,
            "3": 0.7434641562241587,
            "4": 0.9411764705882353,
            "5": 0.7619047619047619
        },
        "nist": 7.061265615283,
        "rouge1": {
            "precision": 0.78101,
            "recall": 0.6872,
            "fmeasure": 0.71774
        },
        "rouge2": {
            "precision": 0.5324,
            "recall": 0.46636,
            "fmeasure": 0.48671
        },
        "rougeL": {
            "precision": 0.65333,
            "recall": 0.57656,
            "fmeasure": 0.60094
        },
        "rougeLsum": {
            "precision": 0.65333,
            "recall": 0.57656,
            "fmeasure": 0.60094
        },
        "bleu": 40.70339,
        "nubia": {
            "semantic_relation": 4.17955,
            "contradiction": 7.70555,
            "irrelevancy": 9.30183,
            "logical_agreement": 82.99262,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.83732,
            "nubia_score": 0.68944
        },
        "bleurt": 0.08127,
        "meteor": 0.3329305179086352,
        "bertscore": {
            "precision": 0.92427,
            "recall": 0.90494,
            "f1": 0.91293
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.755,
        "total_length": 336,
        "mean_pred_length": 15.272727272727273,
        "std_pred_length": 4.013407282662566,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5654761904761905,
        "vocab_size-1": 190,
        "unique-1": 150,
        "entropy-1": 6.751549708795851,
        "distinct-2": 0.9235668789808917,
        "vocab_size-2": 290,
        "unique-2": 276,
        "entropy-2": 8.09307867081794,
        "cond_entropy-2": 1.1440429559635197,
        "distinct-3": 0.9863013698630136,
        "vocab_size-3": 288,
        "unique-3": 284,
        "entropy-3": 8.162427298606083,
        "cond_entropy-3": 0.07768398983477498,
        "total_length-nopunct": 293,
        "mean_pred_length-nopunct": 13.318181818181818,
        "std_pred_length-nopunct": 3.4428630215452904,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6245733788395904,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 148,
        "entropy-1-nopunct": 6.824736312519775,
        "distinct-2-nopunct": 0.922509225092251,
        "vocab_size-2-nopunct": 250,
        "unique-2-nopunct": 239,
        "entropy-2-nopunct": 7.870768183364379,
        "cond_entropy-2-nopunct": 1.1388010661282566,
        "distinct-3-nopunct": 0.9839357429718876,
        "vocab_size-3-nopunct": 245,
        "unique-3-nopunct": 241,
        "entropy-3-nopunct": 7.927873418011859,
        "cond_entropy-3-nopunct": 0.07176539077502979,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24,
            "2": 0.38181818181818183,
            "3": 0.8206521739130435
        },
        "nist": 5.630028564239976,
        "rouge1": {
            "precision": 0.68755,
            "recall": 0.76657,
            "fmeasure": 0.71171
        },
        "rouge2": {
            "precision": 0.46954,
            "recall": 0.52284,
            "fmeasure": 0.4843
        },
        "rougeL": {
            "precision": 0.6154,
            "recall": 0.69314,
            "fmeasure": 0.63936
        },
        "rougeLsum": {
            "precision": 0.6154,
            "recall": 0.69314,
            "fmeasure": 0.63936
        },
        "bleu": 41.73769,
        "nubia": {
            "semantic_relation": 4.22752,
            "contradiction": 2.93982,
            "irrelevancy": 31.16476,
            "logical_agreement": 65.89543,
            "grammar_ref": 5.03776,
            "grammar_hyp": 4.91883,
            "nubia_score": 0.72257
        },
        "bleurt": 0.20345,
        "meteor": 0.39254379409410545,
        "bertscore": {
            "precision": 0.91055,
            "recall": 0.92964,
            "f1": 0.91803
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 85,
        "mean_pred_length": 17.0,
        "std_pred_length": 7.014271166700073,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.7294117647058823,
        "vocab_size-1": 62,
        "unique-1": 47,
        "entropy-1": 5.775575606950325,
        "distinct-2": 0.9375,
        "vocab_size-2": 75,
        "unique-2": 70,
        "entropy-2": 6.196928094887358,
        "cond_entropy-2": 0.3411539147522363,
        "distinct-3": 0.9733333333333334,
        "vocab_size-3": 73,
        "unique-3": 71,
        "entropy-3": 6.1754853571625565,
        "cond_entropy-3": -0.0264427377248148,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 13.8,
        "std_pred_length-nopunct": 4.749736834815167,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.749757971239565,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.9375,
        "cond_entropy-2-nopunct": 0.16889566044313536,
        "distinct-3-nopunct": 0.9830508474576272,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.848744744277091,
        "cond_entropy-3-nopunct": -0.10040779809578583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09523809523809523,
            "2": 0.65,
            "3": 0.8478260869565217
        },
        "nist": 5.597014285488863,
        "rouge1": {
            "precision": 0.75413,
            "recall": 0.83113,
            "fmeasure": 0.77952
        },
        "rouge2": {
            "precision": 0.5639,
            "recall": 0.64377,
            "fmeasure": 0.59155
        },
        "rougeL": {
            "precision": 0.6855,
            "recall": 0.77578,
            "fmeasure": 0.71818
        },
        "rougeLsum": {
            "precision": 0.6855,
            "recall": 0.77578,
            "fmeasure": 0.71818
        },
        "bleu": 62.7253,
        "nubia": {
            "semantic_relation": 4.49677,
            "contradiction": 0.96283,
            "irrelevancy": 20.2848,
            "logical_agreement": 78.75237,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.63374,
            "nubia_score": 0.85302
        },
        "bleurt": 0.42614,
        "meteor": 0.4269798918719726,
        "bertscore": {
            "precision": 0.9429,
            "recall": 0.95127,
            "f1": 0.94587
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 8.5,
        "median_pred_length": 21.5,
        "min_pred_length": 13,
        "max_pred_length": 30,
        "distinct-1": 0.7209302325581395,
        "vocab_size-1": 31,
        "unique-1": 24,
        "entropy-1": 4.757546440698296,
        "distinct-2": 0.9024390243902439,
        "vocab_size-2": 37,
        "unique-2": 34,
        "entropy-2": 5.1440181631019,
        "cond_entropy-2": 0.41909212796476625,
        "distinct-3": 0.9487179487179487,
        "vocab_size-3": 37,
        "unique-3": 35,
        "entropy-3": 5.182838116298145,
        "cond_entropy-3": 0.049770406607330786,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8709677419354839,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.696131794257844,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.17964675370621433,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nist": 4.566736779607233,
        "rouge1": {
            "precision": 0.85476,
            "recall": 0.76914,
            "fmeasure": 0.80678
        },
        "rouge2": {
            "precision": 0.73611,
            "recall": 0.67235,
            "fmeasure": 0.70024
        },
        "rougeL": {
            "precision": 0.84683,
            "recall": 0.76319,
            "fmeasure": 0.79998
        },
        "rougeLsum": {
            "precision": 0.84683,
            "recall": 0.76319,
            "fmeasure": 0.79998
        },
        "bleu": 74.7709,
        "nubia": {
            "semantic_relation": 4.44051,
            "contradiction": 0.66627,
            "irrelevancy": 0.97997,
            "logical_agreement": 98.35377,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.56709,
            "nubia_score": 0.77919
        },
        "bleurt": 0.33838,
        "meteor": 0.4210136880006457,
        "bertscore": {
            "precision": 0.96861,
            "recall": 0.95986,
            "f1": 0.96391
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.0,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.8529411764705882,
        "vocab_size-1": 29,
        "unique-1": 24,
        "entropy-1": 4.793345194191515,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.16253715874966068,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8709677419354839,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.696131794257844,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.17964675370621433,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "nist": 3.077620519281586,
        "rouge1": {
            "precision": 0.69615,
            "recall": 0.74242,
            "fmeasure": 0.71646
        },
        "rouge2": {
            "precision": 0.43421,
            "recall": 0.475,
            "fmeasure": 0.45221
        },
        "rougeL": {
            "precision": 0.58269,
            "recall": 0.62554,
            "fmeasure": 0.60163
        },
        "rougeLsum": {
            "precision": 0.58269,
            "recall": 0.62554,
            "fmeasure": 0.60163
        },
        "bleu": 28.23447,
        "nubia": {
            "semantic_relation": 4.70678,
            "contradiction": 0.56812,
            "irrelevancy": 3.75308,
            "logical_agreement": 95.67879,
            "grammar_ref": 5.14789,
            "grammar_hyp": 4.86232,
            "nubia_score": 0.85896
        },
        "bleurt": 0.56092,
        "meteor": 0.3276903546793217,
        "bertscore": {
            "precision": 0.9128,
            "recall": 0.92886,
            "f1": 0.92071
        }
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 269,
        "msttr-100": 0.54476,
        "msttr-100_nopunct": 0.54912,
        "total_length": 6352,
        "mean_pred_length": 23.613382899628252,
        "std_pred_length": 4.0890604903249566,
        "median_pred_length": 24.0,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.12468513853904283,
        "vocab_size-1": 792,
        "unique-1": 321,
        "entropy-1": 7.6227591179118255,
        "distinct-2": 0.37284234752589185,
        "vocab_size-2": 2268,
        "unique-2": 1345,
        "entropy-2": 10.270217954631539,
        "cond_entropy-2": 2.6685168465751348,
        "distinct-3": 0.5801513587891297,
        "vocab_size-3": 3373,
        "unique-3": 2466,
        "entropy-3": 11.205242240772604,
        "cond_entropy-3": 0.9900386606391702,
        "total_length-nopunct": 5774,
        "mean_pred_length-nopunct": 21.46468401486989,
        "std_pred_length-nopunct": 3.9139985630368486,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.13578108763422236,
        "vocab_size-1-nopunct": 784,
        "unique-1-nopunct": 318,
        "entropy-1-nopunct": 7.732483306427325,
        "distinct-2-nopunct": 0.38782924613987285,
        "vocab_size-2-nopunct": 2135,
        "unique-2-nopunct": 1310,
        "entropy-2-nopunct": 10.197643597194173,
        "cond_entropy-2-nopunct": 2.574751338323819,
        "distinct-3-nopunct": 0.5951107715813598,
        "vocab_size-3-nopunct": 3116,
        "unique-3-nopunct": 2346,
        "entropy-3-nopunct": 11.077048379953712,
        "cond_entropy-3-nopunct": 0.9304239132428443,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.16464317441516138,
            "2": 0.41781198460692687,
            "3": 0.7015083355385022,
            "4": 0.25,
            "5": 0.5
        },
        "nist": 5.446727565132148,
        "rouge1": {
            "precision": 0.71627,
            "recall": 0.59553,
            "fmeasure": 0.63956
        },
        "rouge2": {
            "precision": 0.4176,
            "recall": 0.34442,
            "fmeasure": 0.37082
        },
        "rougeL": {
            "precision": 0.545,
            "recall": 0.45394,
            "fmeasure": 0.48704
        },
        "rougeLsum": {
            "precision": 0.545,
            "recall": 0.45394,
            "fmeasure": 0.48704
        },
        "bleu": 31.44474,
        "nubia": {
            "semantic_relation": 3.74333,
            "contradiction": 9.60627,
            "irrelevancy": 13.91948,
            "logical_agreement": 76.47425,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.7337,
            "nubia_score": 0.54266
        },
        "bleurt": -0.26186,
        "meteor": 0.28545467068765257,
        "bertscore": {
            "precision": 0.89206,
            "recall": 0.86439,
            "f1": 0.8765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 50,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.77143,
        "total_length": 808,
        "mean_pred_length": 16.16,
        "std_pred_length": 6.093800127998948,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.5544554455445545,
        "vocab_size-1": 448,
        "unique-1": 368,
        "entropy-1": 7.761831053128393,
        "distinct-2": 0.9182058047493403,
        "vocab_size-2": 696,
        "unique-2": 656,
        "entropy-2": 9.3545942415969,
        "cond_entropy-2": 1.4017115874948454,
        "distinct-3": 0.981638418079096,
        "vocab_size-3": 695,
        "unique-3": 683,
        "entropy-3": 9.429816160955813,
        "cond_entropy-3": 0.08168094454051368,
        "total_length-nopunct": 714,
        "mean_pred_length-nopunct": 14.28,
        "std_pred_length-nopunct": 5.575087443260419,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6190476190476191,
        "vocab_size-1-nopunct": 442,
        "unique-1-nopunct": 367,
        "entropy-1-nopunct": 7.9712693219053135,
        "distinct-2-nopunct": 0.9292168674698795,
        "vocab_size-2-nopunct": 617,
        "unique-2-nopunct": 590,
        "entropy-2-nopunct": 9.181098541589646,
        "cond_entropy-2-nopunct": 1.286602070055588,
        "distinct-3-nopunct": 0.988599348534202,
        "vocab_size-3-nopunct": 607,
        "unique-3-nopunct": 600,
        "entropy-3-nopunct": 9.239293542438617,
        "cond_entropy-3-nopunct": 0.07398823291395833,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22,
            "2": 0.49056603773584906,
            "3": 0.7098540145985401
        },
        "nist": 6.443313512423847,
        "rouge1": {
            "precision": 0.74689,
            "recall": 0.68982,
            "fmeasure": 0.70562
        },
        "rouge2": {
            "precision": 0.50851,
            "recall": 0.47566,
            "fmeasure": 0.48241
        },
        "rougeL": {
            "precision": 0.65311,
            "recall": 0.61278,
            "fmeasure": 0.62147
        },
        "rougeLsum": {
            "precision": 0.65311,
            "recall": 0.61278,
            "fmeasure": 0.62147
        },
        "bleu": 40.42076,
        "nubia": {
            "semantic_relation": 4.11232,
            "contradiction": 11.74741,
            "irrelevancy": 29.7282,
            "logical_agreement": 58.52439,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.86353,
            "nubia_score": 0.67756
        },
        "bleurt": 0.18637,
        "meteor": 0.3542505094976688,
        "bertscore": {
            "precision": 0.92316,
            "recall": 0.91088,
            "f1": 0.915
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.78,
        "total_length": 181,
        "mean_pred_length": 16.454545454545453,
        "std_pred_length": 4.3141129155289715,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6685082872928176,
        "vocab_size-1": 121,
        "unique-1": 97,
        "entropy-1": 6.509252069494849,
        "distinct-2": 0.9352941176470588,
        "vocab_size-2": 159,
        "unique-2": 148,
        "entropy-2": 7.2799791714317905,
        "cond_entropy-2": 0.6611224371163114,
        "distinct-3": 0.9748427672955975,
        "vocab_size-3": 155,
        "unique-3": 151,
        "entropy-3": 7.2625684898755205,
        "cond_entropy-3": -0.021036282740138912,
        "total_length-nopunct": 160,
        "mean_pred_length-nopunct": 14.545454545454545,
        "std_pred_length-nopunct": 4.29298871022458,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.73125,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.5872476260021475,
        "distinct-2-nopunct": 0.9463087248322147,
        "vocab_size-2-nopunct": 141,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.111785970126599,
        "cond_entropy-2-nopunct": 0.5519308619616082,
        "distinct-3-nopunct": 0.9782608695652174,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.065046195908602,
        "cond_entropy-3-nopunct": -0.05267304919123916,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2558139534883721,
            "2": 0.47368421052631576,
            "3": 0.6838235294117647
        },
        "nist": 5.522500108352074,
        "rouge1": {
            "precision": 0.73914,
            "recall": 0.67816,
            "fmeasure": 0.70103
        },
        "rouge2": {
            "precision": 0.50932,
            "recall": 0.46206,
            "fmeasure": 0.47826
        },
        "rougeL": {
            "precision": 0.60267,
            "recall": 0.54056,
            "fmeasure": 0.56447
        },
        "rougeLsum": {
            "precision": 0.60267,
            "recall": 0.54056,
            "fmeasure": 0.56447
        },
        "bleu": 38.62839,
        "nubia": {
            "semantic_relation": 4.24708,
            "contradiction": 12.25573,
            "irrelevancy": 28.79997,
            "logical_agreement": 58.9443,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.75995,
            "nubia_score": 0.71974
        },
        "bleurt": 0.21968,
        "meteor": 0.3695613006942564,
        "bertscore": {
            "precision": 0.92718,
            "recall": 0.90755,
            "f1": 0.91516
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.744,
        "msttr-100_nopunct": 0.7925,
        "total_length": 540,
        "mean_pred_length": 17.419354838709676,
        "std_pred_length": 5.374816987422272,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5907407407407408,
        "vocab_size-1": 319,
        "unique-1": 268,
        "entropy-1": 7.564860074747603,
        "distinct-2": 0.8939096267190569,
        "vocab_size-2": 455,
        "unique-2": 420,
        "entropy-2": 8.74370462507887,
        "cond_entropy-2": 1.0167397539323055,
        "distinct-3": 0.9581589958158996,
        "vocab_size-3": 458,
        "unique-3": 441,
        "entropy-3": 8.811421436637382,
        "cond_entropy-3": 0.07174912609561883,
        "total_length-nopunct": 466,
        "mean_pred_length-nopunct": 15.03225806451613,
        "std_pred_length-nopunct": 4.532918101405304,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6673819742489271,
        "vocab_size-1-nopunct": 311,
        "unique-1-nopunct": 264,
        "entropy-1-nopunct": 7.753470409464868,
        "distinct-2-nopunct": 0.9011494252873563,
        "vocab_size-2-nopunct": 392,
        "unique-2-nopunct": 363,
        "entropy-2-nopunct": 8.536402445942365,
        "cond_entropy-2-nopunct": 0.8456039049589446,
        "distinct-3-nopunct": 0.9678217821782178,
        "vocab_size-3-nopunct": 391,
        "unique-3-nopunct": 379,
        "entropy-3-nopunct": 8.591986513686999,
        "cond_entropy-3-nopunct": 0.06424144642750985,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2743362831858407,
            "2": 0.5,
            "3": 0.7878787878787878
        },
        "nist": 7.162651270054942,
        "rouge1": {
            "precision": 0.806,
            "recall": 0.76926,
            "fmeasure": 0.77762
        },
        "rouge2": {
            "precision": 0.61848,
            "recall": 0.59679,
            "fmeasure": 0.60018
        },
        "rougeL": {
            "precision": 0.70578,
            "recall": 0.68229,
            "fmeasure": 0.68636
        },
        "rougeLsum": {
            "precision": 0.70578,
            "recall": 0.68229,
            "fmeasure": 0.68636
        },
        "bleu": 54.95466,
        "nubia": {
            "semantic_relation": 4.20526,
            "contradiction": 10.21166,
            "irrelevancy": 29.6098,
            "logical_agreement": 60.17854,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.79996,
            "nubia_score": 0.7143
        },
        "bleurt": 0.3148,
        "meteor": 0.4281692486756712,
        "bertscore": {
            "precision": 0.93978,
            "recall": 0.93007,
            "f1": 0.93425
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.67,
        "msttr-100_nopunct": NaN,
        "total_length": 117,
        "mean_pred_length": 19.5,
        "std_pred_length": 7.088723439378913,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 81,
        "unique-1": 65,
        "entropy-1": 6.000163544129334,
        "distinct-2": 0.963963963963964,
        "vocab_size-2": 107,
        "unique-2": 103,
        "entropy-2": 6.722343794278048,
        "cond_entropy-2": 0.6527783992398476,
        "distinct-3": 1.0,
        "vocab_size-3": 105,
        "unique-3": 105,
        "entropy-3": 6.714245517666113,
        "cond_entropy-3": -0.0039798724935071715,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 5.120763831912406,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7653061224489796,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.9535467061614264,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 88,
        "entropy-2-nopunct": 6.480083695187461,
        "cond_entropy-2-nopunct": 0.5696563241099705,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 86,
        "unique-3-nopunct": 86,
        "entropy-3-nopunct": 6.426264754702099,
        "cond_entropy-3-nopunct": -0.050785573447938284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.5833333333333334,
            "3": 0.8024691358024691
        },
        "nist": 5.475014419738142,
        "rouge1": {
            "precision": 0.82858,
            "recall": 0.77991,
            "fmeasure": 0.79773
        },
        "rouge2": {
            "precision": 0.6325,
            "recall": 0.59752,
            "fmeasure": 0.60945
        },
        "rougeL": {
            "precision": 0.75691,
            "recall": 0.72417,
            "fmeasure": 0.73479
        },
        "rougeLsum": {
            "precision": 0.75691,
            "recall": 0.72417,
            "fmeasure": 0.73479
        },
        "bleu": 51.58328,
        "nubia": {
            "semantic_relation": 4.24153,
            "contradiction": 2.63063,
            "irrelevancy": 53.29938,
            "logical_agreement": 44.06999,
            "grammar_ref": 5.04309,
            "grammar_hyp": 5.03499,
            "nubia_score": 0.72881
        },
        "bleurt": 0.2664,
        "meteor": 0.3986997777141866,
        "bertscore": {
            "precision": 0.94291,
            "recall": 0.94134,
            "f1": 0.94186
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp02": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp02",
        "N": 359,
        "msttr-100": 0.73607,
        "msttr-100_nopunct": 0.7798,
        "total_length": 5676,
        "mean_pred_length": 15.81058495821727,
        "std_pred_length": 6.216860840548763,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.4036293164200141,
        "vocab_size-1": 2291,
        "unique-1": 1800,
        "entropy-1": 9.07253442704687,
        "distinct-2": 0.8452134662403611,
        "vocab_size-2": 4494,
        "unique-2": 4204,
        "entropy-2": 11.804201317313666,
        "cond_entropy-2": 2.468319525796256,
        "distinct-3": 0.954820492133925,
        "vocab_size-3": 4734,
        "unique-3": 4661,
        "entropy-3": 12.087125961094323,
        "cond_entropy-3": 0.3120362353745593,
        "total_length-nopunct": 5045,
        "mean_pred_length-nopunct": 14.052924791086351,
        "std_pred_length-nopunct": 5.601928246657091,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4523290386521308,
        "vocab_size-1-nopunct": 2282,
        "unique-1-nopunct": 1799,
        "entropy-1-nopunct": 9.407230253244697,
        "distinct-2-nopunct": 0.873026034997866,
        "vocab_size-2-nopunct": 4091,
        "unique-2-nopunct": 3842,
        "entropy-2-nopunct": 11.784948930839176,
        "cond_entropy-2-nopunct": 2.5403670878619304,
        "distinct-3-nopunct": 0.9824358678067946,
        "vocab_size-3-nopunct": 4251,
        "unique-3-nopunct": 4194,
        "entropy-3-nopunct": 12.039793013343768,
        "cond_entropy-3-nopunct": 0.2792130936795334,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp02.json",
        "local_recall": {
            "1": 0.043285024154589374,
            "2": 0.12980769230769232,
            "3": 0.21219226260257915,
            "4": 0.3314447592067989,
            "5": 0.4037184594953519,
            "6": 0.46798029556650245,
            "7": 0.5525114155251142,
            "8": 0.6378968253968254,
            "9": 0.7654676258992805
        },
        "nist": 8.788067091363136,
        "rouge1": {
            "precision": 0.72788,
            "recall": 0.65805,
            "fmeasure": 0.67704
        },
        "rouge2": {
            "precision": 0.51613,
            "recall": 0.46413,
            "fmeasure": 0.47478
        },
        "rougeL": {
            "precision": 0.68438,
            "recall": 0.62592,
            "fmeasure": 0.6399
        },
        "rougeLsum": {
            "precision": 0.68438,
            "recall": 0.62592,
            "fmeasure": 0.6399
        },
        "bleu": 48.54145,
        "sari": 43.66483,
        "nubia": {
            "semantic_relation": 3.68811,
            "contradiction": 6.80357,
            "irrelevancy": 26.68833,
            "logical_agreement": 66.5081,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.89175,
            "nubia_score": 0.45333
        },
        "bleurt": -0.43819,
        "meteor": 0.3376510068565184,
        "bertscore": {
            "precision": 0.89873,
            "recall": 0.90814,
            "f1": 0.89893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.83,
        "total_length": 252,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.277986629117476,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.6904761904761905,
        "vocab_size-1": 174,
        "unique-1": 149,
        "entropy-1": 6.992065785711827,
        "distinct-2": 0.9747899159663865,
        "vocab_size-2": 232,
        "unique-2": 226,
        "entropy-2": 7.844397595240763,
        "cond_entropy-2": 0.7253294898666237,
        "distinct-3": 1.0,
        "vocab_size-3": 224,
        "unique-3": 224,
        "entropy-3": 7.807354922057568,
        "cond_entropy-3": -0.03389141267891075,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 15.785714285714286,
        "std_pred_length-nopunct": 4.4589968671467455,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.755656108597285,
        "vocab_size-1-nopunct": 167,
        "unique-1-nopunct": 145,
        "entropy-1-nopunct": 7.085872259037967,
        "distinct-2-nopunct": 0.9758454106280193,
        "vocab_size-2-nopunct": 202,
        "unique-2-nopunct": 197,
        "entropy-2-nopunct": 7.645177778755337,
        "cond_entropy-2-nopunct": 0.5922930762630245,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 193,
        "unique-3-nopunct": 193,
        "entropy-3-nopunct": 7.592457037268058,
        "cond_entropy-3-nopunct": -0.054397795878913115,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1694915254237288,
            "2": 0.41304347826086957,
            "3": 0.703030303030303
        },
        "nist": 5.456147177147868,
        "rouge1": {
            "precision": 0.67677,
            "recall": 0.67384,
            "fmeasure": 0.6589
        },
        "rouge2": {
            "precision": 0.42381,
            "recall": 0.43024,
            "fmeasure": 0.41269
        },
        "rougeL": {
            "precision": 0.59931,
            "recall": 0.60554,
            "fmeasure": 0.58724
        },
        "rougeLsum": {
            "precision": 0.59931,
            "recall": 0.60554,
            "fmeasure": 0.58724
        },
        "bleu": 35.90035,
        "nubia": {
            "semantic_relation": 3.92281,
            "contradiction": 16.68329,
            "irrelevancy": 40.675,
            "logical_agreement": 42.64171,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.41912,
            "nubia_score": 0.66884
        },
        "bleurt": 0.05585,
        "meteor": 0.34912354698465453,
        "bertscore": {
            "precision": 0.90739,
            "recall": 0.90916,
            "f1": 0.90718
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 1295,
        "msttr-100": 0.6569,
        "msttr-100_nopunct": 0.68159,
        "total_length": 28446,
        "mean_pred_length": 21.966023166023167,
        "std_pred_length": 4.484077796254322,
        "median_pred_length": 23.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.061449764466005766,
        "vocab_size-1": 1748,
        "unique-1": 605,
        "entropy-1": 8.096469471592137,
        "distinct-2": 0.2154616772862878,
        "vocab_size-2": 5850,
        "unique-2": 2943,
        "entropy-2": 11.106902750587308,
        "cond_entropy-2": 3.0193510383720668,
        "distinct-3": 0.38521039603960394,
        "vocab_size-3": 9960,
        "unique-3": 6243,
        "entropy-3": 12.322782409451476,
        "cond_entropy-3": 1.3125637201506652,
        "total_length-nopunct": 25806,
        "mean_pred_length-nopunct": 19.92741312741313,
        "std_pred_length-nopunct": 4.365818160616074,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.0673874292800124,
        "vocab_size-1-nopunct": 1739,
        "unique-1-nopunct": 605,
        "entropy-1-nopunct": 8.274363906662678,
        "distinct-2-nopunct": 0.22965199298274244,
        "vocab_size-2-nopunct": 5629,
        "unique-2-nopunct": 3009,
        "entropy-2-nopunct": 11.040325821647567,
        "cond_entropy-2-nopunct": 2.9223919331128245,
        "distinct-3-nopunct": 0.3980013783597519,
        "vocab_size-3-nopunct": 9240,
        "unique-3-nopunct": 6008,
        "entropy-3-nopunct": 12.192799617345472,
        "cond_entropy-3-nopunct": 1.2481728488360277,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18184291057463448,
            "2": 0.46056634682892583,
            "3": 0.7158463526371432,
            "4": 0.7647058823529411,
            "5": 0.6896551724137931
        },
        "nist": 6.141831916856231,
        "rouge1": {
            "precision": 0.75454,
            "recall": 0.63259,
            "fmeasure": 0.67396
        },
        "rouge2": {
            "precision": 0.48525,
            "recall": 0.40248,
            "fmeasure": 0.42933
        },
        "rougeL": {
            "precision": 0.6007,
            "recall": 0.50411,
            "fmeasure": 0.53614
        },
        "rougeLsum": {
            "precision": 0.6007,
            "recall": 0.50411,
            "fmeasure": 0.53614
        },
        "bleu": 36.06274,
        "nubia": {
            "semantic_relation": 3.94045,
            "contradiction": 8.60023,
            "irrelevancy": 11.18742,
            "logical_agreement": 80.21235,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.67253,
            "nubia_score": 0.6097
        },
        "bleurt": -0.0901,
        "meteor": 0.30505037357214115,
        "bertscore": {
            "precision": 0.90975,
            "recall": 0.88258,
            "f1": 0.89423
        }
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 115,
        "msttr-100": 0.65056,
        "msttr-100_nopunct": 0.69188,
        "total_length": 1898,
        "mean_pred_length": 16.504347826086956,
        "std_pred_length": 4.3805378130077735,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.2692307692307692,
        "vocab_size-1": 511,
        "unique-1": 257,
        "entropy-1": 7.42627602978229,
        "distinct-2": 0.5664610207515424,
        "vocab_size-2": 1010,
        "unique-2": 708,
        "entropy-2": 9.497535313615018,
        "cond_entropy-2": 1.8877843999490194,
        "distinct-3": 0.7248201438848921,
        "vocab_size-3": 1209,
        "unique-3": 960,
        "entropy-3": 9.990656795578298,
        "cond_entropy-3": 0.5429940431770993,
        "total_length-nopunct": 1681,
        "mean_pred_length-nopunct": 14.617391304347827,
        "std_pred_length-nopunct": 4.260195155145405,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.3004164187983343,
        "vocab_size-1-nopunct": 505,
        "unique-1-nopunct": 257,
        "entropy-1-nopunct": 7.615151600166761,
        "distinct-2-nopunct": 0.5606641123882503,
        "vocab_size-2-nopunct": 878,
        "unique-2-nopunct": 619,
        "entropy-2-nopunct": 9.278037710483476,
        "cond_entropy-2-nopunct": 1.8007514310778459,
        "distinct-3-nopunct": 0.7181254307374225,
        "vocab_size-3-nopunct": 1042,
        "unique-3-nopunct": 824,
        "entropy-3-nopunct": 9.769060675864692,
        "cond_entropy-3-nopunct": 0.548855745452564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.23923444976076555,
            "2": 0.579047619047619,
            "3": 0.8450413223140496
        },
        "nist": 8.375369024766677,
        "rouge1": {
            "precision": 0.7917,
            "recall": 0.75632,
            "fmeasure": 0.7658
        },
        "rouge2": {
            "precision": 0.56163,
            "recall": 0.53393,
            "fmeasure": 0.54096
        },
        "rougeL": {
            "precision": 0.68673,
            "recall": 0.65349,
            "fmeasure": 0.66225
        },
        "rougeLsum": {
            "precision": 0.68673,
            "recall": 0.65349,
            "fmeasure": 0.66225
        },
        "bleu": 54.58503,
        "nubia": {
            "semantic_relation": 4.53409,
            "contradiction": 5.39075,
            "irrelevancy": 4.30029,
            "logical_agreement": 90.30895,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.66232,
            "nubia_score": 0.82185
        },
        "bleurt": 0.27901,
        "meteor": 0.4151981119459216,
        "bertscore": {
            "precision": 0.93881,
            "recall": 0.93438,
            "f1": 0.93534
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 771,
        "mean_pred_length": 16.0625,
        "std_pred_length": 5.261520098792744,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5343709468223087,
        "vocab_size-1": 412,
        "unique-1": 347,
        "entropy-1": 7.597994015619198,
        "distinct-2": 0.8907330567081605,
        "vocab_size-2": 644,
        "unique-2": 598,
        "entropy-2": 9.22138216689677,
        "cond_entropy-2": 1.4297675645285068,
        "distinct-3": 0.9644444444444444,
        "vocab_size-3": 651,
        "unique-3": 629,
        "entropy-3": 9.325395877117094,
        "cond_entropy-3": 0.09773336823243704,
        "total_length-nopunct": 684,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 5.2855936279664935,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5950292397660819,
        "vocab_size-1-nopunct": 407,
        "unique-1-nopunct": 346,
        "entropy-1-nopunct": 7.782191187873194,
        "distinct-2-nopunct": 0.8946540880503144,
        "vocab_size-2-nopunct": 569,
        "unique-2-nopunct": 530,
        "entropy-2-nopunct": 9.046180268267264,
        "cond_entropy-2-nopunct": 1.3520662432632082,
        "distinct-3-nopunct": 0.9659863945578231,
        "vocab_size-3-nopunct": 568,
        "unique-3-nopunct": 550,
        "entropy-3-nopunct": 9.129077489386836,
        "cond_entropy-3-nopunct": 0.09956682822285139,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16778523489932887,
            "2": 0.43125,
            "3": 0.7821782178217822
        },
        "nist": 6.966534243902565,
        "rouge1": {
            "precision": 0.76668,
            "recall": 0.73872,
            "fmeasure": 0.74549
        },
        "rouge2": {
            "precision": 0.52445,
            "recall": 0.51147,
            "fmeasure": 0.51258
        },
        "rougeL": {
            "precision": 0.64724,
            "recall": 0.62754,
            "fmeasure": 0.63145
        },
        "rougeLsum": {
            "precision": 0.64724,
            "recall": 0.62754,
            "fmeasure": 0.63145
        },
        "bleu": 45.50772,
        "nubia": {
            "semantic_relation": 4.25171,
            "contradiction": 4.29237,
            "irrelevancy": 25.72613,
            "logical_agreement": 69.9815,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.83534,
            "nubia_score": 0.74718
        },
        "bleurt": 0.30826,
        "meteor": 0.39096055602312973,
        "bertscore": {
            "precision": 0.93121,
            "recall": 0.92989,
            "f1": 0.92934
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 76,
        "msttr-100": 0.72167,
        "msttr-100_nopunct": 0.785,
        "total_length": 1257,
        "mean_pred_length": 16.539473684210527,
        "std_pred_length": 5.442137712414711,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.5186953062848051,
        "vocab_size-1": 652,
        "unique-1": 538,
        "entropy-1": 8.076047858545117,
        "distinct-2": 0.9017781541066893,
        "vocab_size-2": 1065,
        "unique-2": 1003,
        "entropy-2": 9.938506056278046,
        "cond_entropy-2": 1.6420676483276966,
        "distinct-3": 0.9764705882352941,
        "vocab_size-3": 1079,
        "unique-3": 1059,
        "entropy-3": 10.056419296804716,
        "cond_entropy-3": 0.12150959950789902,
        "total_length-nopunct": 1089,
        "mean_pred_length-nopunct": 14.328947368421053,
        "std_pred_length-nopunct": 4.666194656910199,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5913682277318641,
        "vocab_size-1-nopunct": 644,
        "unique-1-nopunct": 536,
        "entropy-1-nopunct": 8.353265081465745,
        "distinct-2-nopunct": 0.9111549851924975,
        "vocab_size-2-nopunct": 923,
        "unique-2-nopunct": 875,
        "entropy-2-nopunct": 9.736020556474914,
        "cond_entropy-2-nopunct": 1.4722030756718016,
        "distinct-3-nopunct": 0.9797225186766275,
        "vocab_size-3-nopunct": 918,
        "unique-3-nopunct": 901,
        "entropy-3-nopunct": 9.829738988988606,
        "cond_entropy-3-nopunct": 0.11003996727982433,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22408026755852842,
            "2": 0.47560975609756095,
            "3": 0.7617728531855956
        },
        "nist": 7.032113027616502,
        "rouge1": {
            "precision": 0.71184,
            "recall": 0.70692,
            "fmeasure": 0.69587
        },
        "rouge2": {
            "precision": 0.45357,
            "recall": 0.45235,
            "fmeasure": 0.44219
        },
        "rougeL": {
            "precision": 0.61541,
            "recall": 0.62217,
            "fmeasure": 0.60401
        },
        "rougeLsum": {
            "precision": 0.61541,
            "recall": 0.62217,
            "fmeasure": 0.60401
        },
        "bleu": 40.80448,
        "nubia": {
            "semantic_relation": 4.13717,
            "contradiction": 7.92811,
            "irrelevancy": 32.48133,
            "logical_agreement": 59.59056,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.66224,
            "nubia_score": 0.69771
        },
        "bleurt": 0.20238,
        "meteor": 0.37278043075248996,
        "bertscore": {
            "precision": 0.91851,
            "recall": 0.91986,
            "f1": 0.91686
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.58,
        "msttr-100_nopunct": 0.63,
        "total_length": 144,
        "mean_pred_length": 13.090909090909092,
        "std_pred_length": 3.5279287112604103,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.6041666666666666,
        "vocab_size-1": 87,
        "unique-1": 64,
        "entropy-1": 6.005644649833607,
        "distinct-2": 0.8270676691729323,
        "vocab_size-2": 110,
        "unique-2": 90,
        "entropy-2": 6.688704333981171,
        "cond_entropy-2": 0.49323514326550516,
        "distinct-3": 0.8688524590163934,
        "vocab_size-3": 106,
        "unique-3": 90,
        "entropy-3": 6.668442255595687,
        "cond_entropy-3": -0.026184442200598713,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 11.636363636363637,
        "std_pred_length-nopunct": 3.255002507266938,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6484375,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 6.024627067777489,
        "distinct-2-nopunct": 0.8290598290598291,
        "vocab_size-2-nopunct": 97,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.511390360609029,
        "cond_entropy-2-nopunct": 0.5242782693406426,
        "distinct-3-nopunct": 0.8584905660377359,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.4449015866386565,
        "cond_entropy-3-nopunct": -0.02923671785039384,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.3103448275862069,
            "3": 0.6881720430107527
        },
        "nist": 4.829150040540784,
        "rouge1": {
            "precision": 0.67924,
            "recall": 0.66482,
            "fmeasure": 0.65991
        },
        "rouge2": {
            "precision": 0.4285,
            "recall": 0.44426,
            "fmeasure": 0.42548
        },
        "rougeL": {
            "precision": 0.60259,
            "recall": 0.62933,
            "fmeasure": 0.60456
        },
        "rougeLsum": {
            "precision": 0.60259,
            "recall": 0.62933,
            "fmeasure": 0.60456
        },
        "bleu": 33.41312,
        "nubia": {
            "semantic_relation": 4.23053,
            "contradiction": 7.81356,
            "irrelevancy": 47.96307,
            "logical_agreement": 44.22337,
            "grammar_ref": 5.00152,
            "grammar_hyp": 5.13708,
            "nubia_score": 0.7087
        },
        "bleurt": 0.29259,
        "meteor": 0.3608549105699427,
        "bertscore": {
            "precision": 0.90882,
            "recall": 0.9146,
            "f1": 0.91139
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.7075,
        "msttr-100_nopunct": 0.77667,
        "total_length": 410,
        "mean_pred_length": 17.083333333333332,
        "std_pred_length": 4.915254034352875,
        "median_pred_length": 18.5,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.5902439024390244,
        "vocab_size-1": 242,
        "unique-1": 200,
        "entropy-1": 7.0848759312921805,
        "distinct-2": 0.9352331606217616,
        "vocab_size-2": 361,
        "unique-2": 349,
        "entropy-2": 8.416141347084197,
        "cond_entropy-2": 1.1997808967212278,
        "distinct-3": 0.994475138121547,
        "vocab_size-3": 360,
        "unique-3": 358,
        "entropy-3": 8.488796163326285,
        "cond_entropy-3": 0.08434425426531812,
        "total_length-nopunct": 355,
        "mean_pred_length-nopunct": 14.791666666666666,
        "std_pred_length-nopunct": 4.252246138480488,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6676056338028169,
        "vocab_size-1-nopunct": 237,
        "unique-1-nopunct": 200,
        "entropy-1-nopunct": 7.287259163093468,
        "distinct-2-nopunct": 0.9274924471299094,
        "vocab_size-2-nopunct": 307,
        "unique-2-nopunct": 296,
        "entropy-2-nopunct": 8.171116843632033,
        "cond_entropy-2-nopunct": 0.9528637915067681,
        "distinct-3-nopunct": 0.993485342019544,
        "vocab_size-3-nopunct": 305,
        "unique-3-nopunct": 303,
        "entropy-3-nopunct": 8.249065529409227,
        "cond_entropy-3-nopunct": 0.09355029332182105,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10714285714285714,
            "2": 0.41935483870967744,
            "3": 0.8395061728395061
        },
        "nist": 6.762438254402987,
        "rouge1": {
            "precision": 0.76807,
            "recall": 0.74607,
            "fmeasure": 0.74448
        },
        "rouge2": {
            "precision": 0.53999,
            "recall": 0.523,
            "fmeasure": 0.52271
        },
        "rougeL": {
            "precision": 0.6529,
            "recall": 0.62723,
            "fmeasure": 0.62998
        },
        "rougeLsum": {
            "precision": 0.6529,
            "recall": 0.62723,
            "fmeasure": 0.62998
        },
        "bleu": 53.52343,
        "nubia": {
            "semantic_relation": 4.06257,
            "contradiction": 3.85202,
            "irrelevancy": 37.96973,
            "logical_agreement": 58.17825,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.53357,
            "nubia_score": 0.71518
        },
        "bleurt": 0.14916,
        "meteor": 0.41301126967153917,
        "bertscore": {
            "precision": 0.92654,
            "recall": 0.92122,
            "f1": 0.92173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.755,
        "total_length": 242,
        "mean_pred_length": 14.235294117647058,
        "std_pred_length": 5.047182228026503,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6074380165289256,
        "vocab_size-1": 147,
        "unique-1": 116,
        "entropy-1": 6.610143673306146,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 210,
        "unique-2": 198,
        "entropy-2": 7.668203913429599,
        "cond_entropy-2": 0.8654525516201315,
        "distinct-3": 0.9807692307692307,
        "vocab_size-3": 204,
        "unique-3": 200,
        "entropy-3": 7.66197817967953,
        "cond_entropy-3": -0.02680301153748363,
        "total_length-nopunct": 217,
        "mean_pred_length-nopunct": 12.764705882352942,
        "std_pred_length-nopunct": 4.845002419288,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6682027649769585,
        "vocab_size-1-nopunct": 145,
        "unique-1-nopunct": 116,
        "entropy-1-nopunct": 6.7284599445763575,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 190,
        "unique-2-nopunct": 182,
        "entropy-2-nopunct": 7.53385618977474,
        "cond_entropy-2-nopunct": 0.8202841921635572,
        "distinct-3-nopunct": 0.9890710382513661,
        "vocab_size-3-nopunct": 181,
        "unique-3-nopunct": 179,
        "entropy-3-nopunct": 7.493841914786769,
        "cond_entropy-3-nopunct": -0.04618913837592808,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.4098360655737705,
            "3": 0.7018633540372671
        },
        "nist": 5.191335419535112,
        "rouge1": {
            "precision": 0.70038,
            "recall": 0.65979,
            "fmeasure": 0.67147
        },
        "rouge2": {
            "precision": 0.42987,
            "recall": 0.40317,
            "fmeasure": 0.41117
        },
        "rougeL": {
            "precision": 0.58991,
            "recall": 0.55107,
            "fmeasure": 0.56319
        },
        "rougeLsum": {
            "precision": 0.58991,
            "recall": 0.55107,
            "fmeasure": 0.56319
        },
        "bleu": 35.33866,
        "nubia": {
            "semantic_relation": 4.07964,
            "contradiction": 10.03639,
            "irrelevancy": 29.93524,
            "logical_agreement": 60.02837,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.75494,
            "nubia_score": 0.68422
        },
        "bleurt": 0.18009,
        "meteor": 0.347722693038803,
        "bertscore": {
            "precision": 0.92405,
            "recall": 0.90932,
            "f1": 0.91537
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 57,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.76375,
        "total_length": 926,
        "mean_pred_length": 16.24561403508772,
        "std_pred_length": 4.921420069467134,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5183585313174947,
        "vocab_size-1": 480,
        "unique-1": 385,
        "entropy-1": 7.767611228348393,
        "distinct-2": 0.8849252013808976,
        "vocab_size-2": 769,
        "unique-2": 720,
        "entropy-2": 9.447847155668512,
        "cond_entropy-2": 1.4760366091229955,
        "distinct-3": 0.958128078817734,
        "vocab_size-3": 778,
        "unique-3": 758,
        "entropy-3": 9.565558146238544,
        "cond_entropy-3": 0.1290668151181092,
        "total_length-nopunct": 829,
        "mean_pred_length-nopunct": 14.543859649122806,
        "std_pred_length-nopunct": 4.588582992061762,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5705669481302774,
        "vocab_size-1-nopunct": 473,
        "unique-1-nopunct": 382,
        "entropy-1-nopunct": 7.933666709122402,
        "distinct-2-nopunct": 0.883419689119171,
        "vocab_size-2-nopunct": 682,
        "unique-2-nopunct": 640,
        "entropy-2-nopunct": 9.266307159056709,
        "cond_entropy-2-nopunct": 1.4378724255740662,
        "distinct-3-nopunct": 0.9538461538461539,
        "vocab_size-3-nopunct": 682,
        "unique-3-nopunct": 663,
        "entropy-3-nopunct": 9.371282578506914,
        "cond_entropy-3-nopunct": 0.12538177337740383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21658986175115208,
            "2": 0.5121951219512195,
            "3": 0.7988614800759013
        },
        "nist": 7.136121711430815,
        "rouge1": {
            "precision": 0.75695,
            "recall": 0.76945,
            "fmeasure": 0.7528
        },
        "rouge2": {
            "precision": 0.52251,
            "recall": 0.53301,
            "fmeasure": 0.52037
        },
        "rougeL": {
            "precision": 0.6441,
            "recall": 0.65406,
            "fmeasure": 0.6402
        },
        "rougeLsum": {
            "precision": 0.6441,
            "recall": 0.65406,
            "fmeasure": 0.6402
        },
        "bleu": 45.59629,
        "nubia": {
            "semantic_relation": 4.23066,
            "contradiction": 7.24266,
            "irrelevancy": 31.09297,
            "logical_agreement": 61.66436,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.78742,
            "nubia_score": 0.73728
        },
        "bleurt": 0.25913,
        "meteor": 0.40973216135301843,
        "bertscore": {
            "precision": 0.92771,
            "recall": 0.93196,
            "f1": 0.92728
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.8,
        "total_length": 302,
        "mean_pred_length": 17.764705882352942,
        "std_pred_length": 6.366543172893618,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.6125827814569537,
        "vocab_size-1": 185,
        "unique-1": 151,
        "entropy-1": 6.925830437637789,
        "distinct-2": 0.8982456140350877,
        "vocab_size-2": 256,
        "unique-2": 234,
        "entropy-2": 7.931048152873813,
        "cond_entropy-2": 0.8915941881839762,
        "distinct-3": 0.9552238805970149,
        "vocab_size-3": 256,
        "unique-3": 246,
        "entropy-3": 7.970903462829654,
        "cond_entropy-3": 0.04658698628063273,
        "total_length-nopunct": 252,
        "mean_pred_length-nopunct": 14.823529411764707,
        "std_pred_length-nopunct": 4.81706884413488,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 7.121018467701501,
        "distinct-2-nopunct": 0.9361702127659575,
        "vocab_size-2-nopunct": 220,
        "unique-2-nopunct": 208,
        "entropy-2-nopunct": 7.739220510367149,
        "cond_entropy-2-nopunct": 0.680144360744711,
        "distinct-3-nopunct": 0.9724770642201835,
        "vocab_size-3-nopunct": 212,
        "unique-3-nopunct": 206,
        "entropy-3-nopunct": 7.71313845321728,
        "cond_entropy-3-nopunct": -0.015375454327108252,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14893617021276595,
            "2": 0.34210526315789475,
            "3": 0.7741935483870968
        },
        "nist": 6.335265111399512,
        "rouge1": {
            "precision": 0.77127,
            "recall": 0.74237,
            "fmeasure": 0.7475
        },
        "rouge2": {
            "precision": 0.54834,
            "recall": 0.52551,
            "fmeasure": 0.53016
        },
        "rougeL": {
            "precision": 0.6443,
            "recall": 0.62431,
            "fmeasure": 0.6271
        },
        "rougeLsum": {
            "precision": 0.6443,
            "recall": 0.62431,
            "fmeasure": 0.6271
        },
        "bleu": 54.09549,
        "nubia": {
            "semantic_relation": 4.28788,
            "contradiction": 4.55937,
            "irrelevancy": 26.23861,
            "logical_agreement": 69.20202,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.60885,
            "nubia_score": 0.74356
        },
        "bleurt": 0.24316,
        "meteor": 0.4236872416536768,
        "bertscore": {
            "precision": 0.92928,
            "recall": 0.92592,
            "f1": 0.92662
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.7725,
        "total_length": 475,
        "mean_pred_length": 16.379310344827587,
        "std_pred_length": 5.365366543402733,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5789473684210527,
        "vocab_size-1": 275,
        "unique-1": 232,
        "entropy-1": 7.241423498165598,
        "distinct-2": 0.9170403587443946,
        "vocab_size-2": 409,
        "unique-2": 383,
        "entropy-2": 8.604096228371425,
        "cond_entropy-2": 1.1798237188380636,
        "distinct-3": 0.9832134292565947,
        "vocab_size-3": 410,
        "unique-3": 404,
        "entropy-3": 8.668520150178047,
        "cond_entropy-3": 0.061911737089083894,
        "total_length-nopunct": 407,
        "mean_pred_length-nopunct": 14.03448275862069,
        "std_pred_length-nopunct": 4.358762546796729,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6609336609336609,
        "vocab_size-1-nopunct": 269,
        "unique-1-nopunct": 230,
        "entropy-1-nopunct": 7.421409817464955,
        "distinct-2-nopunct": 0.9312169312169312,
        "vocab_size-2-nopunct": 352,
        "unique-2-nopunct": 335,
        "entropy-2-nopunct": 8.392230089547846,
        "cond_entropy-2-nopunct": 1.038583598572341,
        "distinct-3-nopunct": 0.997134670487106,
        "vocab_size-3-nopunct": 348,
        "unique-3-nopunct": 347,
        "entropy-3-nopunct": 8.441352567183902,
        "cond_entropy-3-nopunct": 0.04962525758837007,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20388349514563106,
            "2": 0.47674418604651164,
            "3": 0.7317880794701986
        },
        "nist": 6.312164207777751,
        "rouge1": {
            "precision": 0.7406,
            "recall": 0.7209,
            "fmeasure": 0.71681
        },
        "rouge2": {
            "precision": 0.5075,
            "recall": 0.48423,
            "fmeasure": 0.48715
        },
        "rougeL": {
            "precision": 0.64645,
            "recall": 0.62038,
            "fmeasure": 0.62177
        },
        "rougeLsum": {
            "precision": 0.64645,
            "recall": 0.62038,
            "fmeasure": 0.62177
        },
        "bleu": 41.80934,
        "nubia": {
            "semantic_relation": 4.1558,
            "contradiction": 8.00089,
            "irrelevancy": 33.12432,
            "logical_agreement": 58.87478,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.64829,
            "nubia_score": 0.69923
        },
        "bleurt": 0.25904,
        "meteor": 0.3724781919251087,
        "bertscore": {
            "precision": 0.92702,
            "recall": 0.92505,
            "f1": 0.92469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 169,
        "msttr-100": 0.71179,
        "msttr-100_nopunct": 0.76,
        "total_length": 2824,
        "mean_pred_length": 16.71005917159763,
        "std_pred_length": 5.5431566100552585,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.3997875354107649,
        "vocab_size-1": 1129,
        "unique-1": 865,
        "entropy-1": 8.366151086652538,
        "distinct-2": 0.7894538606403013,
        "vocab_size-2": 2096,
        "unique-2": 1882,
        "entropy-2": 10.68709168671727,
        "cond_entropy-2": 2.09448313774707,
        "distinct-3": 0.9050683829444891,
        "vocab_size-3": 2250,
        "unique-3": 2135,
        "entropy-3": 11.013582266996599,
        "cond_entropy-3": 0.3326030328194569,
        "total_length-nopunct": 2446,
        "mean_pred_length-nopunct": 14.47337278106509,
        "std_pred_length-nopunct": 5.0207440557021625,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.45666394112837283,
        "vocab_size-1-nopunct": 1117,
        "unique-1-nopunct": 862,
        "entropy-1-nopunct": 8.66626491088048,
        "distinct-2-nopunct": 0.8058849363197189,
        "vocab_size-2-nopunct": 1835,
        "unique-2-nopunct": 1673,
        "entropy-2-nopunct": 10.497483267070908,
        "cond_entropy-2-nopunct": 1.9393231585433761,
        "distinct-3-nopunct": 0.9103415559772297,
        "vocab_size-3-nopunct": 1919,
        "unique-3-nopunct": 1826,
        "entropy-3-nopunct": 10.788887379683308,
        "cond_entropy-3-nopunct": 0.3158132913497867,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2405857740585774,
            "2": 0.4696629213483146,
            "3": 0.7628205128205128
        },
        "nist": 8.079046477162617,
        "rouge1": {
            "precision": 0.77069,
            "recall": 0.75203,
            "fmeasure": 0.75052
        },
        "rouge2": {
            "precision": 0.54982,
            "recall": 0.53911,
            "fmeasure": 0.53609
        },
        "rougeL": {
            "precision": 0.67451,
            "recall": 0.66189,
            "fmeasure": 0.65904
        },
        "rougeLsum": {
            "precision": 0.67451,
            "recall": 0.66189,
            "fmeasure": 0.65904
        },
        "bleu": 48.05656,
        "nubia": {
            "semantic_relation": 4.16819,
            "contradiction": 7.36784,
            "irrelevancy": 30.33587,
            "logical_agreement": 62.29629,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.69096,
            "nubia_score": 0.72766
        },
        "bleurt": 0.28704,
        "meteor": 0.3965985530404105,
        "bertscore": {
            "precision": 0.93081,
            "recall": 0.92857,
            "f1": 0.92845
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 32,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.734,
        "total_length": 604,
        "mean_pred_length": 18.875,
        "std_pred_length": 6.35781998801476,
        "median_pred_length": 18.5,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.5248344370860927,
        "vocab_size-1": 317,
        "unique-1": 242,
        "entropy-1": 7.388873458573712,
        "distinct-2": 0.8461538461538461,
        "vocab_size-2": 484,
        "unique-2": 427,
        "entropy-2": 8.762381656180509,
        "cond_entropy-2": 1.2855425409216226,
        "distinct-3": 0.912962962962963,
        "vocab_size-3": 493,
        "unique-3": 448,
        "entropy-3": 8.899945643339057,
        "cond_entropy-3": 0.14175721411944855,
        "total_length-nopunct": 541,
        "mean_pred_length-nopunct": 16.90625,
        "std_pred_length-nopunct": 5.719262272137902,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5767097966728281,
        "vocab_size-1-nopunct": 312,
        "unique-1-nopunct": 242,
        "entropy-1-nopunct": 7.493821223929937,
        "distinct-2-nopunct": 0.8487229862475442,
        "vocab_size-2-nopunct": 432,
        "unique-2-nopunct": 384,
        "entropy-2-nopunct": 8.591022195196219,
        "cond_entropy-2-nopunct": 1.1630691732227785,
        "distinct-3-nopunct": 0.9119496855345912,
        "vocab_size-3-nopunct": 435,
        "unique-3-nopunct": 395,
        "entropy-3-nopunct": 8.718579680315138,
        "cond_entropy-3-nopunct": 0.1319925985571124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19387755102040816,
            "2": 0.3253012048192771,
            "3": 0.7959183673469388
        },
        "nist": 6.408997752163071,
        "rouge1": {
            "precision": 0.7524,
            "recall": 0.73594,
            "fmeasure": 0.73449
        },
        "rouge2": {
            "precision": 0.5136,
            "recall": 0.52485,
            "fmeasure": 0.51162
        },
        "rougeL": {
            "precision": 0.64755,
            "recall": 0.63818,
            "fmeasure": 0.63379
        },
        "rougeLsum": {
            "precision": 0.64755,
            "recall": 0.63818,
            "fmeasure": 0.63379
        },
        "bleu": 45.89974,
        "nubia": {
            "semantic_relation": 4.18452,
            "contradiction": 8.08817,
            "irrelevancy": 32.17928,
            "logical_agreement": 59.73255,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.56089,
            "nubia_score": 0.70917
        },
        "bleurt": 0.21505,
        "meteor": 0.37812352585982717,
        "bertscore": {
            "precision": 0.9229,
            "recall": 0.92553,
            "f1": 0.92284
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nist": 2.415947705372627,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.55556,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "bleu": 25.21194,
        "nubia": {
            "semantic_relation": 3.9393,
            "contradiction": 0.50698,
            "irrelevancy": 97.97126,
            "logical_agreement": 1.52176,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.93182,
            "nubia_score": 0.68311
        },
        "bleurt": 0.64341,
        "meteor": 0.4235494540099438,
        "bertscore": {
            "precision": 0.93993,
            "recall": 0.96605,
            "f1": 0.95235
        }
    },
    "schema_guided_dialog_challenge_test_bfp05_parent": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69483,
        "msttr-100_nopunct": 0.72132,
        "total_length": 6043,
        "mean_pred_length": 12.086,
        "std_pred_length": 6.422974700245986,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 30,
        "distinct-1": 0.1643223564454741,
        "vocab_size-1": 993,
        "unique-1": 545,
        "entropy-1": 7.852013078194489,
        "distinct-2": 0.5098322208190511,
        "vocab_size-2": 2826,
        "unique-2": 2003,
        "entropy-2": 10.73428261519567,
        "cond_entropy-2": 2.6349271320840377,
        "distinct-3": 0.7317073170731707,
        "vocab_size-3": 3690,
        "unique-3": 3082,
        "entropy-3": 11.502407070891651,
        "cond_entropy-3": 0.7861959661198012,
        "total_length-nopunct": 5327,
        "mean_pred_length-nopunct": 10.654,
        "std_pred_length-nopunct": 5.9858402918888505,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.18415618547024593,
        "vocab_size-1-nopunct": 981,
        "unique-1-nopunct": 541,
        "entropy-1-nopunct": 8.03564849964642,
        "distinct-2-nopunct": 0.5220633934120572,
        "vocab_size-2-nopunct": 2520,
        "unique-2-nopunct": 1818,
        "entropy-2-nopunct": 10.553235607880135,
        "cond_entropy-2-nopunct": 2.651470954392797,
        "distinct-3-nopunct": 0.7411601571527617,
        "vocab_size-3-nopunct": 3207,
        "unique-3-nopunct": 2719,
        "entropy-3-nopunct": 11.293766910468454,
        "cond_entropy-3-nopunct": 0.770332094473113,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5602784902894833
        },
        "nist": 6.073596635685695,
        "rouge1": {
            "precision": 0.57526,
            "recall": 0.54624,
            "fmeasure": 0.54986
        },
        "rouge2": {
            "precision": 0.35818,
            "recall": 0.33905,
            "fmeasure": 0.34209
        },
        "rougeL": {
            "precision": 0.51712,
            "recall": 0.4899,
            "fmeasure": 0.49383
        },
        "rougeLsum": {
            "precision": 0.51712,
            "recall": 0.4899,
            "fmeasure": 0.49383
        },
        "bleu": 32.09703,
        "nubia": {
            "semantic_relation": 3.57809,
            "contradiction": 5.4519,
            "irrelevancy": 24.77608,
            "logical_agreement": 69.77201,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.7337,
            "nubia_score": 0.62369
        },
        "bleurt": -0.11503,
        "meteor": 0.31196563559316043,
        "bertscore": {
            "precision": 0.87044,
            "recall": 0.86311,
            "f1": 0.86633
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.964904158123496,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.16518880750326753,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9117647058823529,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.8887896794220005,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.12362739319226905,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.8181818181818182,
            "3": 0.46153846153846156
        },
        "nist": 2.7089016144924107,
        "rouge1": {
            "precision": 0.60938,
            "recall": 0.58196,
            "fmeasure": 0.55456
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.36111,
            "fmeasure": 0.33667
        },
        "rougeL": {
            "precision": 0.39062,
            "recall": 0.37427,
            "fmeasure": 0.3562
        },
        "rougeLsum": {
            "precision": 0.39062,
            "recall": 0.37427,
            "fmeasure": 0.3562
        },
        "bleu": 19.26738,
        "nubia": {
            "semantic_relation": 3.17651,
            "contradiction": 47.37125,
            "irrelevancy": 51.28864,
            "logical_agreement": 1.34011,
            "grammar_ref": 4.83168,
            "grammar_hyp": 5.06913,
            "nubia_score": 0.29874
        },
        "bleurt": -0.62075,
        "meteor": 0.2399223662894136,
        "bertscore": {
            "precision": 0.87093,
            "recall": 0.86747,
            "f1": 0.86713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.76,
        "total_length": 320,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.358898943540674,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.596875,
        "vocab_size-1": 191,
        "unique-1": 157,
        "entropy-1": 6.823840337636564,
        "distinct-2": 0.93,
        "vocab_size-2": 279,
        "unique-2": 266,
        "entropy-2": 8.050452773814845,
        "cond_entropy-2": 1.0483048498856034,
        "distinct-3": 0.975,
        "vocab_size-3": 273,
        "unique-3": 267,
        "entropy-3": 8.076586990151538,
        "cond_entropy-3": 0.03173178181395506,
        "total_length-nopunct": 280,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.123105625617661,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6678571428571428,
        "vocab_size-1-nopunct": 187,
        "unique-1-nopunct": 156,
        "entropy-1-nopunct": 6.982320815366776,
        "distinct-2-nopunct": 0.9307692307692308,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 232,
        "entropy-2-nopunct": 7.839637909165657,
        "cond_entropy-2-nopunct": 0.9195646189119742,
        "distinct-3-nopunct": 0.9833333333333333,
        "vocab_size-3-nopunct": 236,
        "unique-3-nopunct": 233,
        "entropy-3-nopunct": 7.87041189768288,
        "cond_entropy-3-nopunct": 0.03279345966640237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22,
            "2": 0.4918032786885246,
            "3": 0.6178010471204188
        },
        "nist": 4.709336427516219,
        "rouge1": {
            "precision": 0.63611,
            "recall": 0.66762,
            "fmeasure": 0.63431
        },
        "rouge2": {
            "precision": 0.383,
            "recall": 0.39799,
            "fmeasure": 0.38151
        },
        "rougeL": {
            "precision": 0.50285,
            "recall": 0.54179,
            "fmeasure": 0.50796
        },
        "rougeLsum": {
            "precision": 0.50285,
            "recall": 0.54179,
            "fmeasure": 0.50796
        },
        "bleu": 27.80783,
        "nubia": {
            "semantic_relation": 4.04742,
            "contradiction": 10.71988,
            "irrelevancy": 29.47941,
            "logical_agreement": 59.80071,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.42329,
            "nubia_score": 0.66853
        },
        "bleurt": 0.14357,
        "meteor": 0.3288143981433705,
        "bertscore": {
            "precision": 0.90036,
            "recall": 0.90641,
            "f1": 0.90203
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 56,
        "msttr-100": 0.73111,
        "msttr-100_nopunct": 0.7925,
        "total_length": 934,
        "mean_pred_length": 16.678571428571427,
        "std_pred_length": 5.345582765427996,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.5064239828693791,
        "vocab_size-1": 473,
        "unique-1": 382,
        "entropy-1": 7.778526318581495,
        "distinct-2": 0.8940774487471527,
        "vocab_size-2": 785,
        "unique-2": 732,
        "entropy-2": 9.51529108521719,
        "cond_entropy-2": 1.5219629744128473,
        "distinct-3": 0.9659367396593674,
        "vocab_size-3": 794,
        "unique-3": 774,
        "entropy-3": 9.606328464449954,
        "cond_entropy-3": 0.0967746279939083,
        "total_length-nopunct": 808,
        "mean_pred_length-nopunct": 14.428571428571429,
        "std_pred_length-nopunct": 4.85451609644177,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5767326732673267,
        "vocab_size-1-nopunct": 466,
        "unique-1-nopunct": 381,
        "entropy-1-nopunct": 8.036200895615723,
        "distinct-2-nopunct": 0.9029255319148937,
        "vocab_size-2-nopunct": 679,
        "unique-2-nopunct": 638,
        "entropy-2-nopunct": 9.309646269366015,
        "cond_entropy-2-nopunct": 1.3484810411980113,
        "distinct-3-nopunct": 0.9669540229885057,
        "vocab_size-3-nopunct": 673,
        "unique-3-nopunct": 656,
        "entropy-3-nopunct": 9.368935198428813,
        "cond_entropy-3-nopunct": 0.07756017131772946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.4240506329113924,
            "3": 0.7679127725856698
        },
        "nist": 7.024254328724057,
        "rouge1": {
            "precision": 0.77506,
            "recall": 0.71805,
            "fmeasure": 0.73377
        },
        "rouge2": {
            "precision": 0.54466,
            "recall": 0.49597,
            "fmeasure": 0.50988
        },
        "rougeL": {
            "precision": 0.6771,
            "recall": 0.62685,
            "fmeasure": 0.64069
        },
        "rougeLsum": {
            "precision": 0.6771,
            "recall": 0.62685,
            "fmeasure": 0.64069
        },
        "bleu": 45.87031,
        "nubia": {
            "semantic_relation": 4.2277,
            "contradiction": 10.95226,
            "irrelevancy": 25.4312,
            "logical_agreement": 63.61654,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.93866,
            "nubia_score": 0.71244
        },
        "bleurt": 0.28379,
        "meteor": 0.39558575237392274,
        "bertscore": {
            "precision": 0.92966,
            "recall": 0.92307,
            "f1": 0.92517
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.732,
        "msttr-100_nopunct": 0.762,
        "total_length": 597,
        "mean_pred_length": 16.583333333333332,
        "std_pred_length": 4.768967975941499,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.559463986599665,
        "vocab_size-1": 334,
        "unique-1": 278,
        "entropy-1": 7.416892329633727,
        "distinct-2": 0.9358288770053476,
        "vocab_size-2": 525,
        "unique-2": 502,
        "entropy-2": 8.973798075647963,
        "cond_entropy-2": 1.3805458920090343,
        "distinct-3": 0.9923809523809524,
        "vocab_size-3": 521,
        "unique-3": 517,
        "entropy-3": 9.02093551731536,
        "cond_entropy-3": 0.05416624139813421,
        "total_length-nopunct": 525,
        "mean_pred_length-nopunct": 14.583333333333334,
        "std_pred_length-nopunct": 4.462031176742519,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6209523809523809,
        "vocab_size-1-nopunct": 326,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 7.565750608775947,
        "distinct-2-nopunct": 0.9284253578732107,
        "vocab_size-2-nopunct": 454,
        "unique-2-nopunct": 432,
        "entropy-2-nopunct": 8.756449275682167,
        "cond_entropy-2-nopunct": 1.2645300064497553,
        "distinct-3-nopunct": 0.9911699779249448,
        "vocab_size-3-nopunct": 449,
        "unique-3-nopunct": 445,
        "entropy-3-nopunct": 8.805707195896161,
        "cond_entropy-3-nopunct": 0.058928316800529006,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15432098765432098,
            "2": 0.5677966101694916,
            "3": 0.796923076923077
        },
        "nist": 6.30579606784644,
        "rouge1": {
            "precision": 0.71353,
            "recall": 0.75507,
            "fmeasure": 0.72338
        },
        "rouge2": {
            "precision": 0.4892,
            "recall": 0.52403,
            "fmeasure": 0.49551
        },
        "rougeL": {
            "precision": 0.60645,
            "recall": 0.65386,
            "fmeasure": 0.61913
        },
        "rougeLsum": {
            "precision": 0.60645,
            "recall": 0.65386,
            "fmeasure": 0.61913
        },
        "bleu": 42.9336,
        "nubia": {
            "semantic_relation": 4.15799,
            "contradiction": 4.65954,
            "irrelevancy": 49.27907,
            "logical_agreement": 46.0614,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.44516,
            "nubia_score": 0.72422
        },
        "bleurt": 0.21057,
        "meteor": 0.40343570091450187,
        "bertscore": {
            "precision": 0.91944,
            "recall": 0.93261,
            "f1": 0.92396
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.74,
        "total_length": 222,
        "mean_pred_length": 18.5,
        "std_pred_length": 6.409628174343137,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.536036036036036,
        "vocab_size-1": 119,
        "unique-1": 85,
        "entropy-1": 6.33238654320878,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 175,
        "unique-2": 154,
        "entropy-2": 7.3163937318488035,
        "cond_entropy-2": 0.8970553240119375,
        "distinct-3": 0.9141414141414141,
        "vocab_size-3": 181,
        "unique-3": 170,
        "entropy-3": 7.432288185692453,
        "cond_entropy-3": 0.12990567318611806,
        "total_length-nopunct": 186,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.267826876426369,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6075268817204301,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.339629790511418,
        "distinct-2-nopunct": 0.8448275862068966,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 132,
        "entropy-2-nopunct": 7.063408438277976,
        "cond_entropy-2-nopunct": 0.7801544279185297,
        "distinct-3-nopunct": 0.9197530864197531,
        "vocab_size-3-nopunct": 149,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.157690897919627,
        "cond_entropy-3-nopunct": 0.12239616760985253,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.5,
            "3": 0.8057553956834532
        },
        "nist": 5.89271356622993,
        "rouge1": {
            "precision": 0.76755,
            "recall": 0.73904,
            "fmeasure": 0.7434
        },
        "rouge2": {
            "precision": 0.58166,
            "recall": 0.55816,
            "fmeasure": 0.56085
        },
        "rougeL": {
            "precision": 0.71221,
            "recall": 0.68117,
            "fmeasure": 0.68653
        },
        "rougeLsum": {
            "precision": 0.71221,
            "recall": 0.68117,
            "fmeasure": 0.68653
        },
        "bleu": 55.70054,
        "nubia": {
            "semantic_relation": 3.95749,
            "contradiction": 8.97619,
            "irrelevancy": 31.88147,
            "logical_agreement": 59.14234,
            "grammar_ref": 4.07585,
            "grammar_hyp": 4.14725,
            "nubia_score": 0.68753
        },
        "bleurt": 0.33428,
        "meteor": 0.4069625660271242,
        "bertscore": {
            "precision": 0.93357,
            "recall": 0.93113,
            "f1": 0.9305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 23,
        "entropy-1": 4.696131794257844,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.04171571922345565,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015322,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": -0.031031312388743976,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.7777777777777778
        },
        "nist": 3.6163443838297864,
        "rouge1": {
            "precision": 0.76042,
            "recall": 0.71154,
            "fmeasure": 0.73048
        },
        "rouge2": {
            "precision": 0.54444,
            "recall": 0.49145,
            "fmeasure": 0.51387
        },
        "rougeL": {
            "precision": 0.68371,
            "recall": 0.63818,
            "fmeasure": 0.65602
        },
        "rougeLsum": {
            "precision": 0.68371,
            "recall": 0.63818,
            "fmeasure": 0.65602
        },
        "bleu": 47.11489,
        "nubia": {
            "semantic_relation": 4.19807,
            "contradiction": 13.5569,
            "irrelevancy": 36.10238,
            "logical_agreement": 50.34071,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.27821,
            "nubia_score": 0.68608
        },
        "bleurt": 0.26626,
        "meteor": 0.3377134252231262,
        "bertscore": {
            "precision": 0.92136,
            "recall": 0.90836,
            "f1": 0.91271
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nist": 2.830817410580225,
        "rouge1": {
            "precision": 0.60606,
            "recall": 0.76852,
            "fmeasure": 0.67719
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.47619,
            "fmeasure": 0.41394
        },
        "rougeL": {
            "precision": 0.42424,
            "recall": 0.53704,
            "fmeasure": 0.47368
        },
        "rougeLsum": {
            "precision": 0.42424,
            "recall": 0.53704,
            "fmeasure": 0.47368
        },
        "bleu": 43.24227,
        "nubia": {
            "semantic_relation": 3.90782,
            "contradiction": 0.15616,
            "irrelevancy": 99.6709,
            "logical_agreement": 0.17293,
            "grammar_ref": 4.0172,
            "grammar_hyp": 3.78097,
            "nubia_score": 0.7831
        },
        "bleurt": -0.22723,
        "meteor": 0.4370900223221626,
        "bertscore": {
            "precision": 0.90016,
            "recall": 0.94294,
            "f1": 0.91532
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 518,
        "msttr-100": 0.66648,
        "msttr-100_nopunct": 0.68806,
        "total_length": 10821,
        "mean_pred_length": 20.88996138996139,
        "std_pred_length": 4.804825397738858,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.08816190740227335,
        "vocab_size-1": 954,
        "unique-1": 347,
        "entropy-1": 7.698527046458523,
        "distinct-2": 0.2469183732893332,
        "vocab_size-2": 2544,
        "unique-2": 1313,
        "entropy-2": 10.108283261069042,
        "cond_entropy-2": 2.4232642387682137,
        "distinct-3": 0.3821154828819622,
        "vocab_size-3": 3739,
        "unique-3": 2324,
        "entropy-3": 10.933453145590288,
        "cond_entropy-3": 0.9234321916331848,
        "total_length-nopunct": 9800,
        "mean_pred_length-nopunct": 18.91891891891892,
        "std_pred_length-nopunct": 4.664123027848696,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.09653061224489796,
        "vocab_size-1-nopunct": 946,
        "unique-1-nopunct": 346,
        "entropy-1-nopunct": 7.854170677970809,
        "distinct-2-nopunct": 0.2546864899806076,
        "vocab_size-2-nopunct": 2364,
        "unique-2-nopunct": 1254,
        "entropy-2-nopunct": 9.984624352172547,
        "cond_entropy-2-nopunct": 2.277545370068422,
        "distinct-3-nopunct": 0.3864673664993154,
        "vocab_size-3-nopunct": 3387,
        "unique-3-nopunct": 2151,
        "entropy-3-nopunct": 10.76482671968492,
        "cond_entropy-3-nopunct": 0.8762208088750713,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.20077017328899002,
            "2": 0.47284806470248414,
            "3": 0.6899114032580738,
            "4": 0.9473684210526315
        },
        "nist": 4.581457469502372,
        "rouge1": {
            "precision": 0.80371,
            "recall": 0.63654,
            "fmeasure": 0.69116
        },
        "rouge2": {
            "precision": 0.5706,
            "recall": 0.44606,
            "fmeasure": 0.48505
        },
        "rougeL": {
            "precision": 0.66468,
            "recall": 0.52786,
            "fmeasure": 0.57151
        },
        "rougeLsum": {
            "precision": 0.66468,
            "recall": 0.52786,
            "fmeasure": 0.57151
        },
        "bleu": 38.56787,
        "nubia": {
            "semantic_relation": 3.9989,
            "contradiction": 4.54019,
            "irrelevancy": 8.08287,
            "logical_agreement": 87.37695,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.50582,
            "nubia_score": 0.63867
        },
        "bleurt": 0.00721,
        "meteor": 0.31123117635018854,
        "bertscore": {
            "precision": 0.93188,
            "recall": 0.89525,
            "f1": 0.91163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.735,
        "total_length": 310,
        "mean_pred_length": 17.22222222222222,
        "std_pred_length": 6.178417233092374,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5838709677419355,
        "vocab_size-1": 181,
        "unique-1": 146,
        "entropy-1": 6.790774771017628,
        "distinct-2": 0.8904109589041096,
        "vocab_size-2": 260,
        "unique-2": 240,
        "entropy-2": 7.920061202944554,
        "cond_entropy-2": 1.020152645908001,
        "distinct-3": 0.9562043795620438,
        "vocab_size-3": 262,
        "unique-3": 253,
        "entropy-3": 8.00038650813507,
        "cond_entropy-3": 0.09074771543453675,
        "total_length-nopunct": 270,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.754225500544023,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6407407407407407,
        "vocab_size-1-nopunct": 173,
        "unique-1-nopunct": 143,
        "entropy-1-nopunct": 6.796385737058254,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 224,
        "unique-2-nopunct": 208,
        "entropy-2-nopunct": 7.696443019003232,
        "cond_entropy-2-nopunct": 0.973322262020947,
        "distinct-3-nopunct": 0.9487179487179487,
        "vocab_size-3-nopunct": 222,
        "unique-3-nopunct": 213,
        "entropy-3-nopunct": 7.756027593505767,
        "cond_entropy-3-nopunct": 0.08118741330999814,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.11764705882352941,
            "3": 0.759825327510917
        },
        "nist": 6.109201969615874,
        "rouge1": {
            "precision": 0.76482,
            "recall": 0.71962,
            "fmeasure": 0.73392
        },
        "rouge2": {
            "precision": 0.59566,
            "recall": 0.55669,
            "fmeasure": 0.56812
        },
        "rougeL": {
            "precision": 0.7147,
            "recall": 0.67239,
            "fmeasure": 0.68599
        },
        "rougeLsum": {
            "precision": 0.7147,
            "recall": 0.67239,
            "fmeasure": 0.68599
        },
        "bleu": 53.78048,
        "nubia": {
            "semantic_relation": 4.34154,
            "contradiction": 3.42672,
            "irrelevancy": 26.68733,
            "logical_agreement": 69.88595,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.40191,
            "nubia_score": 0.77909
        },
        "bleurt": 0.27819,
        "meteor": 0.39543699360499573,
        "bertscore": {
            "precision": 0.93133,
            "recall": 0.93105,
            "f1": 0.93061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.73667,
        "msttr-100_nopunct": 0.788,
        "total_length": 639,
        "mean_pred_length": 20.612903225806452,
        "std_pred_length": 6.419111682864411,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.5602503912363067,
        "vocab_size-1": 358,
        "unique-1": 281,
        "entropy-1": 7.661792183398072,
        "distinct-2": 0.9029605263157895,
        "vocab_size-2": 549,
        "unique-2": 509,
        "entropy-2": 9.019048376114483,
        "cond_entropy-2": 1.284614225760512,
        "distinct-3": 0.9705372616984402,
        "vocab_size-3": 560,
        "unique-3": 545,
        "entropy-3": 9.110885437580663,
        "cond_entropy-3": 0.10413386087216432,
        "total_length-nopunct": 560,
        "mean_pred_length-nopunct": 18.06451612903226,
        "std_pred_length-nopunct": 5.6164245535633155,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6285714285714286,
        "vocab_size-1-nopunct": 352,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.844208102328867,
        "distinct-2-nopunct": 0.9092627599243857,
        "vocab_size-2-nopunct": 481,
        "unique-2-nopunct": 447,
        "entropy-2-nopunct": 8.835329772194749,
        "cond_entropy-2-nopunct": 1.05447780267907,
        "distinct-3-nopunct": 0.9759036144578314,
        "vocab_size-3-nopunct": 486,
        "unique-3-nopunct": 475,
        "entropy-3-nopunct": 8.910293322625884,
        "cond_entropy-3-nopunct": 0.08613949086799923,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2616822429906542,
            "2": 0.4177215189873418,
            "3": 0.7389277389277389
        },
        "nist": 6.444882078745663,
        "rouge1": {
            "precision": 0.74988,
            "recall": 0.73282,
            "fmeasure": 0.73265
        },
        "rouge2": {
            "precision": 0.52557,
            "recall": 0.51734,
            "fmeasure": 0.51425
        },
        "rougeL": {
            "precision": 0.6206,
            "recall": 0.60661,
            "fmeasure": 0.60521
        },
        "rougeLsum": {
            "precision": 0.6206,
            "recall": 0.60661,
            "fmeasure": 0.60521
        },
        "bleu": 43.16619,
        "nubia": {
            "semantic_relation": 4.09317,
            "contradiction": 6.19703,
            "irrelevancy": 30.75553,
            "logical_agreement": 63.04744,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.74866,
            "nubia_score": 0.69228
        },
        "bleurt": 0.18236,
        "meteor": 0.38457609133581055,
        "bertscore": {
            "precision": 0.92603,
            "recall": 0.92491,
            "f1": 0.92434
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 51,
        "msttr-100": 0.70375,
        "msttr-100_nopunct": 0.75857,
        "total_length": 863,
        "mean_pred_length": 16.92156862745098,
        "std_pred_length": 5.970000615019188,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.5365005793742758,
        "vocab_size-1": 463,
        "unique-1": 390,
        "entropy-1": 7.596797965500582,
        "distinct-2": 0.9027093596059114,
        "vocab_size-2": 733,
        "unique-2": 685,
        "entropy-2": 9.39022297614434,
        "cond_entropy-2": 1.6043660456606221,
        "distinct-3": 0.9802890932982917,
        "vocab_size-3": 746,
        "unique-3": 731,
        "entropy-3": 9.532330830100223,
        "cond_entropy-3": 0.15166879021193444,
        "total_length-nopunct": 744,
        "mean_pred_length-nopunct": 14.588235294117647,
        "std_pred_length-nopunct": 5.134185582124539,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.614247311827957,
        "vocab_size-1-nopunct": 457,
        "unique-1-nopunct": 388,
        "entropy-1-nopunct": 7.87070259311338,
        "distinct-2-nopunct": 0.911976911976912,
        "vocab_size-2-nopunct": 632,
        "unique-2-nopunct": 597,
        "entropy-2-nopunct": 9.172458951056974,
        "cond_entropy-2-nopunct": 1.4046948566671795,
        "distinct-3-nopunct": 0.9875389408099688,
        "vocab_size-3-nopunct": 634,
        "unique-3-nopunct": 626,
        "entropy-3-nopunct": 9.301507368742165,
        "cond_entropy-3-nopunct": 0.1453675487524971,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24479166666666666,
            "2": 0.45652173913043476,
            "3": 0.7685352622061483
        },
        "nist": 7.214173694275284,
        "rouge1": {
            "precision": 0.77769,
            "recall": 0.74326,
            "fmeasure": 0.7467
        },
        "rouge2": {
            "precision": 0.53775,
            "recall": 0.52736,
            "fmeasure": 0.52343
        },
        "rougeL": {
            "precision": 0.65644,
            "recall": 0.63196,
            "fmeasure": 0.63088
        },
        "rougeLsum": {
            "precision": 0.65644,
            "recall": 0.63196,
            "fmeasure": 0.63088
        },
        "bleu": 46.47469,
        "nubia": {
            "semantic_relation": 4.26043,
            "contradiction": 4.14378,
            "irrelevancy": 23.78666,
            "logical_agreement": 72.06956,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.84929,
            "nubia_score": 0.73218
        },
        "bleurt": 0.31641,
        "meteor": 0.39082492626607757,
        "bertscore": {
            "precision": 0.9356,
            "recall": 0.92913,
            "f1": 0.93045
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7375,
        "msttr-100_nopunct": 0.78333,
        "total_length": 458,
        "mean_pred_length": 15.793103448275861,
        "std_pred_length": 4.574135006562877,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5851528384279476,
        "vocab_size-1": 268,
        "unique-1": 216,
        "entropy-1": 7.272587359209137,
        "distinct-2": 0.9207459207459208,
        "vocab_size-2": 395,
        "unique-2": 370,
        "entropy-2": 8.556594006492206,
        "cond_entropy-2": 1.0799622449021675,
        "distinct-3": 0.985,
        "vocab_size-3": 394,
        "unique-3": 388,
        "entropy-3": 8.613856189774749,
        "cond_entropy-3": 0.07090957103058826,
        "total_length-nopunct": 397,
        "mean_pred_length-nopunct": 13.689655172413794,
        "std_pred_length-nopunct": 4.069257733516469,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6624685138539043,
        "vocab_size-1-nopunct": 263,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.485873901938421,
        "distinct-2-nopunct": 0.9157608695652174,
        "vocab_size-2-nopunct": 337,
        "unique-2-nopunct": 315,
        "entropy-2-nopunct": 8.320423674801201,
        "cond_entropy-2-nopunct": 0.8934670420480694,
        "distinct-3-nopunct": 0.9852507374631269,
        "vocab_size-3-nopunct": 334,
        "unique-3-nopunct": 329,
        "entropy-3-nopunct": 8.375642938062645,
        "cond_entropy-3-nopunct": 0.06669716932760117,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.40816326530612246,
            "3": 0.8328358208955224
        },
        "nist": 7.245863638840382,
        "rouge1": {
            "precision": 0.81639,
            "recall": 0.81005,
            "fmeasure": 0.80122
        },
        "rouge2": {
            "precision": 0.63228,
            "recall": 0.62582,
            "fmeasure": 0.61706
        },
        "rougeL": {
            "precision": 0.72089,
            "recall": 0.71407,
            "fmeasure": 0.70573
        },
        "rougeLsum": {
            "precision": 0.72089,
            "recall": 0.71407,
            "fmeasure": 0.70573
        },
        "bleu": 58.91343,
        "nubia": {
            "semantic_relation": 4.56116,
            "contradiction": 1.56801,
            "irrelevancy": 24.97215,
            "logical_agreement": 73.45984,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.59108,
            "nubia_score": 0.83775
        },
        "bleurt": 0.40311,
        "meteor": 0.44955320601470306,
        "bertscore": {
            "precision": 0.95176,
            "recall": 0.95001,
            "f1": 0.94879
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 13.625,
        "std_pred_length": 2.6427968139832467,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.6972477064220184,
        "vocab_size-1": 76,
        "unique-1": 62,
        "entropy-1": 5.921040320853639,
        "distinct-2": 0.9306930693069307,
        "vocab_size-2": 94,
        "unique-2": 87,
        "entropy-2": 6.519597621365641,
        "cond_entropy-2": 0.42803405329801003,
        "distinct-3": 0.9354838709677419,
        "vocab_size-3": 87,
        "unique-3": 81,
        "entropy-3": 6.41012655304352,
        "cond_entropy-3": -0.09754729529967732,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 11.875,
        "std_pred_length-nopunct": 2.6190408549696205,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7684210526315789,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.972707650928836,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.305012461365965,
        "cond_entropy-2-nopunct": 0.3872149674396256,
        "distinct-3-nopunct": 0.9367088607594937,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.1771984696960915,
        "cond_entropy-3-nopunct": -0.11384629197542308,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.1,
            "3": 0.7857142857142857
        },
        "nist": 5.052842625212099,
        "rouge1": {
            "precision": 0.75265,
            "recall": 0.73664,
            "fmeasure": 0.73297
        },
        "rouge2": {
            "precision": 0.51687,
            "recall": 0.514,
            "fmeasure": 0.50889
        },
        "rougeL": {
            "precision": 0.64293,
            "recall": 0.64536,
            "fmeasure": 0.63502
        },
        "rougeLsum": {
            "precision": 0.64293,
            "recall": 0.64536,
            "fmeasure": 0.63502
        },
        "bleu": 48.67439,
        "nubia": {
            "semantic_relation": 3.93179,
            "contradiction": 24.72535,
            "irrelevancy": 9.28367,
            "logical_agreement": 65.99098,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.00074,
            "nubia_score": 0.6681
        },
        "bleurt": 0.2842,
        "meteor": 0.3854933879058854,
        "bertscore": {
            "precision": 0.92266,
            "recall": 0.91162,
            "f1": 0.9154
        }
    },
    "web_nlg_en_validation": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_validation",
        "N": 1667,
        "msttr-100": 0.56797,
        "msttr-100_nopunct": 0.59507,
        "total_length": 31048,
        "mean_pred_length": 18.625074985003,
        "std_pred_length": 6.622056538026353,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 35,
        "distinct-1": 0.11385596495748518,
        "vocab_size-1": 3535,
        "unique-1": 1404,
        "entropy-1": 8.769340734914103,
        "distinct-2": 0.37272386916714884,
        "vocab_size-2": 10951,
        "unique-2": 6689,
        "entropy-2": 12.247767106658872,
        "cond_entropy-2": 3.378313791100792,
        "distinct-3": 0.6013206321714657,
        "vocab_size-3": 16665,
        "unique-3": 12397,
        "entropy-3": 13.478609263807714,
        "cond_entropy-3": 1.3069805936644376,
        "total_length-nopunct": 27699,
        "mean_pred_length-nopunct": 16.61607678464307,
        "std_pred_length-nopunct": 6.1209705300105055,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.12726091194627964,
        "vocab_size-1-nopunct": 3525,
        "unique-1-nopunct": 1404,
        "entropy-1-nopunct": 9.091919568611774,
        "distinct-2-nopunct": 0.38809926244622006,
        "vocab_size-2-nopunct": 10103,
        "unique-2-nopunct": 6305,
        "entropy-2-nopunct": 12.164152185321607,
        "cond_entropy-2-nopunct": 3.2489023150955534,
        "distinct-3-nopunct": 0.612435871126616,
        "vocab_size-3-nopunct": 14922,
        "unique-3-nopunct": 11244,
        "entropy-3-nopunct": 13.328390740620257,
        "cond_entropy-3-nopunct": 1.2403119285645368,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_validation.json",
        "local_recall": {
            "1": 0.29042409710774764,
            "2": 0.6410919540229885,
            "3": 0.8085786986550345,
            "4": 0.851063829787234,
            "5": 0.9714285714285714,
            "6": 1.0,
            "7": 0.9545454545454546,
            "8": 1.0
        },
        "nist": 9.875594385917696,
        "rouge1": {
            "precision": 0.82346,
            "recall": 0.75146,
            "fmeasure": 0.77665
        },
        "rouge2": {
            "precision": 0.60817,
            "recall": 0.55611,
            "fmeasure": 0.57383
        },
        "rougeL": {
            "precision": 0.70029,
            "recall": 0.64293,
            "fmeasure": 0.66242
        },
        "rougeLsum": {
            "precision": 0.70029,
            "recall": 0.64293,
            "fmeasure": 0.66242
        },
        "bleu": 52.9312,
        "nubia": {
            "semantic_relation": 4.40712,
            "contradiction": 3.88383,
            "irrelevancy": 6.23293,
            "logical_agreement": 89.88324,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.71046,
            "nubia_score": 0.7734
        },
        "bleurt": 0.26118,
        "meteor": 0.39224295159908795,
        "bertscore": {
            "precision": 0.94573,
            "recall": 0.93161,
            "f1": 0.93757
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 898,
        "msttr-100": 0.70535,
        "msttr-100_nopunct": 0.75648,
        "total_length": 10160,
        "mean_pred_length": 11.31403118040089,
        "std_pred_length": 3.833889906080426,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 27,
        "distinct-1": 0.3266732283464567,
        "vocab_size-1": 3319,
        "unique-1": 2435,
        "entropy-1": 9.03920711145373,
        "distinct-2": 0.6878643921399266,
        "vocab_size-2": 6371,
        "unique-2": 5458,
        "entropy-2": 11.997464336385795,
        "cond_entropy-2": 2.4269615691983715,
        "distinct-3": 0.8454088952654233,
        "vocab_size-3": 7071,
        "unique-3": 6451,
        "entropy-3": 12.58095703270623,
        "cond_entropy-3": 0.563383282872411,
        "total_length-nopunct": 8859,
        "mean_pred_length-nopunct": 9.865256124721604,
        "std_pred_length-nopunct": 3.4234706713715077,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.3730669375776047,
        "vocab_size-1-nopunct": 3305,
        "unique-1-nopunct": 2433,
        "entropy-1-nopunct": 9.49642013268263,
        "distinct-2-nopunct": 0.7075744253234518,
        "vocab_size-2-nopunct": 5633,
        "unique-2-nopunct": 4903,
        "entropy-2-nopunct": 11.828697865501251,
        "cond_entropy-2-nopunct": 2.535988407786025,
        "distinct-3-nopunct": 0.8502052952003398,
        "vocab_size-3-nopunct": 6005,
        "unique-3-nopunct": 5488,
        "entropy-3-nopunct": 12.348685933597343,
        "cond_entropy-3-nopunct": 0.5997426940985322,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25219473264166004,
            "2": 0.5469083155650319,
            "3": 0.7569816904013316
        },
        "nist": 8.727020471634356,
        "rouge1": {
            "precision": 0.73423,
            "recall": 0.72255,
            "fmeasure": 0.71335
        },
        "rouge2": {
            "precision": 0.5363,
            "recall": 0.53309,
            "fmeasure": 0.52272
        },
        "rougeL": {
            "precision": 0.69103,
            "recall": 0.68599,
            "fmeasure": 0.67445
        },
        "rougeLsum": {
            "precision": 0.69103,
            "recall": 0.68599,
            "fmeasure": 0.67445
        },
        "bleu": 49.42221,
        "nubia": {
            "semantic_relation": 4.07169,
            "contradiction": 10.78648,
            "irrelevancy": 32.26343,
            "logical_agreement": 56.95009,
            "grammar_ref": 5.09815,
            "grammar_hyp": 5.07706,
            "nubia_score": 0.69736
        },
        "bleurt": 0.30914,
        "meteor": 0.4001776525109601,
        "bertscore": {
            "precision": 0.92949,
            "recall": 0.92633,
            "f1": 0.92629
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.665,
        "msttr-100_nopunct": 0.69,
        "total_length": 247,
        "mean_pred_length": 17.642857142857142,
        "std_pred_length": 4.863965796066633,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.5951417004048583,
        "vocab_size-1": 147,
        "unique-1": 118,
        "entropy-1": 6.484035719387581,
        "distinct-2": 0.9227467811158798,
        "vocab_size-2": 215,
        "unique-2": 206,
        "entropy-2": 7.654937700439021,
        "cond_entropy-2": 1.116315544235485,
        "distinct-3": 0.9908675799086758,
        "vocab_size-3": 217,
        "unique-3": 215,
        "entropy-3": 7.756522219418535,
        "cond_entropy-3": 0.11496113185174993,
        "total_length-nopunct": 228,
        "mean_pred_length-nopunct": 16.285714285714285,
        "std_pred_length-nopunct": 5.118992247762548,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6359649122807017,
        "vocab_size-1-nopunct": 145,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.517358095082163,
        "distinct-2-nopunct": 0.9158878504672897,
        "vocab_size-2-nopunct": 196,
        "unique-2-nopunct": 187,
        "entropy-2-nopunct": 7.513640409288202,
        "cond_entropy-2-nopunct": 1.0776722528376637,
        "distinct-3-nopunct": 0.99,
        "vocab_size-3-nopunct": 198,
        "unique-3-nopunct": 196,
        "entropy-3-nopunct": 7.623856189774742,
        "cond_entropy-3-nopunct": 0.12616364088439552,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.38461538461538464,
            "3": 0.8253968253968254
        },
        "nist": 4.995050346459122,
        "rouge1": {
            "precision": 0.64748,
            "recall": 0.75115,
            "fmeasure": 0.68317
        },
        "rouge2": {
            "precision": 0.42965,
            "recall": 0.48352,
            "fmeasure": 0.44883
        },
        "rougeL": {
            "precision": 0.55653,
            "recall": 0.64267,
            "fmeasure": 0.58605
        },
        "rougeLsum": {
            "precision": 0.55653,
            "recall": 0.64267,
            "fmeasure": 0.58605
        },
        "bleu": 38.07961,
        "nubia": {
            "semantic_relation": 4.00209,
            "contradiction": 15.13902,
            "irrelevancy": 39.54515,
            "logical_agreement": 45.31583,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.52605,
            "nubia_score": 0.66352
        },
        "bleurt": 0.03292,
        "meteor": 0.3844441127044981,
        "bertscore": {
            "precision": 0.89268,
            "recall": 0.91779,
            "f1": 0.90333
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 146,
        "mean_pred_length": 16.22222222222222,
        "std_pred_length": 5.202088849208722,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.6506849315068494,
        "vocab_size-1": 95,
        "unique-1": 79,
        "entropy-1": 6.114047307539576,
        "distinct-2": 0.948905109489051,
        "vocab_size-2": 130,
        "unique-2": 125,
        "entropy-2": 6.981243761792629,
        "cond_entropy-2": 0.7196390995675048,
        "distinct-3": 1.0,
        "vocab_size-3": 128,
        "unique-3": 128,
        "entropy-3": 7.0,
        "cond_entropy-3": 0.02696791703947323,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 14.444444444444445,
        "std_pred_length-nopunct": 4.901498888913951,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7153846153846154,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.189026099624577,
        "distinct-2-nopunct": 0.9421487603305785,
        "vocab_size-2-nopunct": 114,
        "unique-2-nopunct": 109,
        "entropy-2-nopunct": 6.7866318323159245,
        "cond_entropy-2-nopunct": 0.6251276369821878,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.807354922057591,
        "cond_entropy-3-nopunct": 0.031348827640152496,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.5227272727272727,
            "3": 0.7910447761194029
        },
        "nist": 4.872951421333828,
        "rouge1": {
            "precision": 0.69324,
            "recall": 0.70576,
            "fmeasure": 0.69059
        },
        "rouge2": {
            "precision": 0.4119,
            "recall": 0.41981,
            "fmeasure": 0.40901
        },
        "rougeL": {
            "precision": 0.57256,
            "recall": 0.59303,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.57256,
            "recall": 0.59303,
            "fmeasure": 0.57143
        },
        "bleu": 29.40463,
        "nubia": {
            "semantic_relation": 4.19263,
            "contradiction": 0.40324,
            "irrelevancy": 38.08152,
            "logical_agreement": 61.51524,
            "grammar_ref": 5.14381,
            "grammar_hyp": 5.11628,
            "nubia_score": 0.68194
        },
        "bleurt": 0.23328,
        "meteor": 0.3555704904924867,
        "bertscore": {
            "precision": 0.89905,
            "recall": 0.90924,
            "f1": 0.90305
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.756,
        "msttr-100_nopunct": 0.7975,
        "total_length": 563,
        "mean_pred_length": 18.161290322580644,
        "std_pred_length": 5.0551588098824505,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.5595026642984015,
        "vocab_size-1": 315,
        "unique-1": 247,
        "entropy-1": 7.4965200111199275,
        "distinct-2": 0.924812030075188,
        "vocab_size-2": 492,
        "unique-2": 455,
        "entropy-2": 8.899728135685192,
        "cond_entropy-2": 1.2537206087217951,
        "distinct-3": 0.9660678642714571,
        "vocab_size-3": 484,
        "unique-3": 467,
        "entropy-3": 8.90080252173804,
        "cond_entropy-3": 0.0027154704727884713,
        "total_length-nopunct": 495,
        "mean_pred_length-nopunct": 15.96774193548387,
        "std_pred_length-nopunct": 4.645385299258179,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6262626262626263,
        "vocab_size-1-nopunct": 310,
        "unique-1-nopunct": 246,
        "entropy-1-nopunct": 7.661119023492406,
        "distinct-2-nopunct": 0.9353448275862069,
        "vocab_size-2-nopunct": 434,
        "unique-2-nopunct": 407,
        "entropy-2-nopunct": 8.722733392752321,
        "cond_entropy-2-nopunct": 1.1113348949755741,
        "distinct-3-nopunct": 0.9676674364896074,
        "vocab_size-3-nopunct": 419,
        "unique-3-nopunct": 405,
        "entropy-3-nopunct": 8.693558087705961,
        "cond_entropy-3-nopunct": -0.019492451296543496,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.32432432432432434,
            "2": 0.43373493975903615,
            "3": 0.7413333333333333
        },
        "nist": 6.608422278697656,
        "rouge1": {
            "precision": 0.73627,
            "recall": 0.72375,
            "fmeasure": 0.71946
        },
        "rouge2": {
            "precision": 0.49605,
            "recall": 0.48719,
            "fmeasure": 0.48516
        },
        "rougeL": {
            "precision": 0.62815,
            "recall": 0.62128,
            "fmeasure": 0.61828
        },
        "rougeLsum": {
            "precision": 0.62815,
            "recall": 0.62128,
            "fmeasure": 0.61828
        },
        "bleu": 43.88073,
        "nubia": {
            "semantic_relation": 4.13993,
            "contradiction": 9.42685,
            "irrelevancy": 35.26979,
            "logical_agreement": 55.30336,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.77895,
            "nubia_score": 0.71012
        },
        "bleurt": 0.22019,
        "meteor": 0.3647623861728619,
        "bertscore": {
            "precision": 0.92096,
            "recall": 0.91634,
            "f1": 0.91798
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 1322,
        "msttr-100": 0.51425,
        "msttr-100_nopunct": 0.52148,
        "total_length": 24059,
        "mean_pred_length": 18.198940998487142,
        "std_pred_length": 6.837462355692001,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.0665863086578827,
        "vocab_size-1": 1602,
        "unique-1": 562,
        "entropy-1": 8.017707277323828,
        "distinct-2": 0.2318247789945903,
        "vocab_size-2": 5271,
        "unique-2": 2692,
        "entropy-2": 11.046529480793131,
        "cond_entropy-2": 2.944670951961636,
        "distinct-3": 0.40616390380574363,
        "vocab_size-3": 8698,
        "unique-3": 5539,
        "entropy-3": 12.193869715095566,
        "cond_entropy-3": 1.2500230754445236,
        "total_length-nopunct": 21653,
        "mean_pred_length-nopunct": 16.37897125567322,
        "std_pred_length-nopunct": 6.452616504847405,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.07352329931187364,
        "vocab_size-1-nopunct": 1592,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 8.21357278452268,
        "distinct-2-nopunct": 0.24042103192169592,
        "vocab_size-2-nopunct": 4888,
        "unique-2-nopunct": 2608,
        "entropy-2-nopunct": 10.917231359207962,
        "cond_entropy-2-nopunct": 2.8938430616464004,
        "distinct-3-nopunct": 0.4143300541848598,
        "vocab_size-3-nopunct": 7876,
        "unique-3-nopunct": 5142,
        "entropy-3-nopunct": 12.023344098563124,
        "cond_entropy-3-nopunct": 1.2089504139538834,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19664776094133582,
            "2": 0.5170765987350667,
            "3": 0.7642782191575476,
            "4": 0.9411764705882353,
            "5": 0.7619047619047619
        },
        "nist": 7.677717077650689,
        "rouge1": {
            "precision": 0.77563,
            "recall": 0.703,
            "fmeasure": 0.72725
        },
        "rouge2": {
            "precision": 0.52391,
            "recall": 0.47493,
            "fmeasure": 0.49057
        },
        "rougeL": {
            "precision": 0.64814,
            "recall": 0.59003,
            "fmeasure": 0.60906
        },
        "rougeLsum": {
            "precision": 0.64814,
            "recall": 0.59003,
            "fmeasure": 0.60906
        },
        "bleu": 41.94194,
        "nubia": {
            "semantic_relation": 4.22044,
            "contradiction": 7.86458,
            "irrelevancy": 9.30776,
            "logical_agreement": 82.82766,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.86576,
            "nubia_score": 0.70241
        },
        "bleurt": 0.10454,
        "meteor": 0.3435815685399785,
        "bertscore": {
            "precision": 0.92215,
            "recall": 0.90687,
            "f1": 0.91294
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "nist": 3.3359024374902604,
        "rouge1": {
            "precision": 0.89744,
            "recall": 0.8006,
            "fmeasure": 0.84547
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.6906,
            "fmeasure": 0.73086
        },
        "rougeL": {
            "precision": 0.89744,
            "recall": 0.8006,
            "fmeasure": 0.84547
        },
        "rougeLsum": {
            "precision": 0.89744,
            "recall": 0.8006,
            "fmeasure": 0.84547
        },
        "bleu": 72.8596,
        "nubia": {
            "semantic_relation": 4.43076,
            "contradiction": 0.18056,
            "irrelevancy": 0.42554,
            "logical_agreement": 99.39391,
            "grammar_ref": 3.66146,
            "grammar_hyp": 3.60294,
            "nubia_score": 0.89156
        },
        "bleurt": 0.49018,
        "meteor": 0.5303137097457615,
        "bertscore": {
            "precision": 0.9846,
            "recall": 0.96474,
            "f1": 0.97457
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.734521664779752,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.2875371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.506890595608519,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.2576071835919428,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "nist": 3.484572895815618,
        "rouge1": {
            "precision": 0.80392,
            "recall": 0.83791,
            "fmeasure": 0.81985
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.60635,
            "fmeasure": 0.57204
        },
        "rougeL": {
            "precision": 0.76471,
            "recall": 0.84861,
            "fmeasure": 0.80429
        },
        "rougeLsum": {
            "precision": 0.76471,
            "recall": 0.84861,
            "fmeasure": 0.80429
        },
        "bleu": 52.71238,
        "nubia": {
            "semantic_relation": 4.06897,
            "contradiction": 0.60017,
            "irrelevancy": 97.39459,
            "logical_agreement": 2.00524,
            "grammar_ref": 5.18542,
            "grammar_hyp": 5.17904,
            "nubia_score": 0.64282
        },
        "bleurt": 0.50069,
        "meteor": 0.4457661928359352,
        "bertscore": {
            "precision": 0.95557,
            "recall": 0.97723,
            "f1": 0.96628
        }
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 1177,
        "msttr-100": 0.63748,
        "msttr-100_nopunct": 0.65985,
        "total_length": 22250,
        "mean_pred_length": 18.903993203058622,
        "std_pred_length": 6.705616613316007,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.05676404494382022,
        "vocab_size-1": 1263,
        "unique-1": 416,
        "entropy-1": 7.7556064860587375,
        "distinct-2": 0.21510938167323115,
        "vocab_size-2": 4533,
        "unique-2": 2274,
        "entropy-2": 10.758808635127119,
        "cond_entropy-2": 2.9496317530260763,
        "distinct-3": 0.39580820265379973,
        "vocab_size-3": 7875,
        "unique-3": 5005,
        "entropy-3": 11.991359882707089,
        "cond_entropy-3": 1.33568035964901,
        "total_length-nopunct": 20060,
        "mean_pred_length-nopunct": 17.043330501274426,
        "std_pred_length-nopunct": 6.353825983270883,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.0625124626121635,
        "vocab_size-1-nopunct": 1254,
        "unique-1-nopunct": 414,
        "entropy-1-nopunct": 7.914266067528254,
        "distinct-2-nopunct": 0.22660594185245989,
        "vocab_size-2-nopunct": 4279,
        "unique-2-nopunct": 2284,
        "entropy-2-nopunct": 10.633917821863996,
        "cond_entropy-2-nopunct": 2.901591960642284,
        "distinct-3-nopunct": 0.4076584208742799,
        "vocab_size-3-nopunct": 7218,
        "unique-3-nopunct": 4752,
        "entropy-3-nopunct": 11.827665232935466,
        "cond_entropy-3-nopunct": 1.2915265837632608,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18372984050610353,
            "2": 0.4985493968544816,
            "3": 0.7567612273591928,
            "4": 0.6,
            "5": 0.6896551724137931
        },
        "nist": 7.1347607553156385,
        "rouge1": {
            "precision": 0.75328,
            "recall": 0.68218,
            "fmeasure": 0.70639
        },
        "rouge2": {
            "precision": 0.4848,
            "recall": 0.44013,
            "fmeasure": 0.45462
        },
        "rougeL": {
            "precision": 0.6174,
            "recall": 0.56138,
            "fmeasure": 0.58007
        },
        "rougeLsum": {
            "precision": 0.6174,
            "recall": 0.56138,
            "fmeasure": 0.58007
        },
        "bleu": 37.98199,
        "nubia": {
            "semantic_relation": 4.13054,
            "contradiction": 9.55987,
            "irrelevancy": 11.23635,
            "logical_agreement": 79.20377,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.92513,
            "nubia_score": 0.66931
        },
        "bleurt": 0.01601,
        "meteor": 0.3273516143260383,
        "bertscore": {
            "precision": 0.91206,
            "recall": 0.89747,
            "f1": 0.90318
        }
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 457,
        "msttr-100": 0.48515,
        "msttr-100_nopunct": 0.48744,
        "total_length": 9917,
        "mean_pred_length": 21.700218818380744,
        "std_pred_length": 4.189684628051886,
        "median_pred_length": 22.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.11908843400221841,
        "vocab_size-1": 1181,
        "unique-1": 521,
        "entropy-1": 7.849893305395722,
        "distinct-2": 0.33224101479915435,
        "vocab_size-2": 3143,
        "unique-2": 1871,
        "entropy-2": 10.507259717758064,
        "cond_entropy-2": 2.679056933698101,
        "distinct-3": 0.5082750194379652,
        "vocab_size-3": 4576,
        "unique-3": 3277,
        "entropy-3": 11.443001156562927,
        "cond_entropy-3": 1.019095614900227,
        "total_length-nopunct": 9000,
        "mean_pred_length-nopunct": 19.693654266958426,
        "std_pred_length-nopunct": 4.1606449375335535,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.1302222222222222,
        "vocab_size-1-nopunct": 1172,
        "unique-1-nopunct": 517,
        "entropy-1-nopunct": 8.005566577661883,
        "distinct-2-nopunct": 0.3421514690389793,
        "vocab_size-2-nopunct": 2923,
        "unique-2-nopunct": 1799,
        "entropy-2-nopunct": 10.40060235564857,
        "cond_entropy-2-nopunct": 2.532840173923391,
        "distinct-3-nopunct": 0.5093989611674499,
        "vocab_size-3-nopunct": 4119,
        "unique-3-nopunct": 2980,
        "entropy-3-nopunct": 11.27692756114623,
        "cond_entropy-3-nopunct": 0.9605885891790931,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.17414529914529914,
            "2": 0.4424890006285355,
            "3": 0.6726209808379344,
            "4": 0.25,
            "5": 0.5
        },
        "nist": 4.376248988073674,
        "rouge1": {
            "precision": 0.75847,
            "recall": 0.58754,
            "fmeasure": 0.64421
        },
        "rouge2": {
            "precision": 0.48938,
            "recall": 0.36978,
            "fmeasure": 0.40733
        },
        "rougeL": {
            "precision": 0.60455,
            "recall": 0.4654,
            "fmeasure": 0.5104
        },
        "rougeLsum": {
            "precision": 0.60455,
            "recall": 0.4654,
            "fmeasure": 0.5104
        },
        "bleu": 32.71588,
        "nubia": {
            "semantic_relation": 3.8045,
            "contradiction": 8.36432,
            "irrelevancy": 12.00271,
            "logical_agreement": 79.63297,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.69404,
            "nubia_score": 0.56552
        },
        "bleurt": -0.18802,
        "meteor": 0.2835758691305943,
        "bertscore": {
            "precision": 0.91147,
            "recall": 0.87548,
            "f1": 0.89146
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 13.4,
        "std_pred_length": 5.388877434122992,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.5522388059701493,
        "vocab_size-1": 37,
        "unique-1": 21,
        "entropy-1": 4.931177249900939,
        "distinct-2": 0.7419354838709677,
        "vocab_size-2": 46,
        "unique-2": 32,
        "entropy-2": 5.413716068381608,
        "cond_entropy-2": 0.4772897814287933,
        "distinct-3": 0.8070175438596491,
        "vocab_size-3": 46,
        "unique-3": 35,
        "entropy-3": 5.446925101884041,
        "cond_entropy-3": 0.045531861748514466,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 5.3516352641038605,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5714285714285714,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.897294208939474,
        "distinct-2-nopunct": 0.7413793103448276,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.314709012294349,
        "cond_entropy-2-nopunct": 0.4558631407921126,
        "distinct-3-nopunct": 0.8113207547169812,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.350561963997161,
        "cond_entropy-3-nopunct": 0.027295119867412482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.5357142857142857
        },
        "nist": 2.4222359965931086,
        "rouge1": {
            "precision": 0.51659,
            "recall": 0.5365,
            "fmeasure": 0.49074
        },
        "rouge2": {
            "precision": 0.20736,
            "recall": 0.20985,
            "fmeasure": 0.18948
        },
        "rougeL": {
            "precision": 0.45123,
            "recall": 0.48092,
            "fmeasure": 0.43333
        },
        "rougeLsum": {
            "precision": 0.45123,
            "recall": 0.48092,
            "fmeasure": 0.43333
        },
        "bleu": 6.89004,
        "nubia": {
            "semantic_relation": 2.80732,
            "contradiction": 30.52104,
            "irrelevancy": 68.83282,
            "logical_agreement": 0.64615,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.57784,
            "nubia_score": 0.29295
        },
        "bleurt": -0.5563,
        "meteor": 0.21193994333176835,
        "bertscore": {
            "precision": 0.8497,
            "recall": 0.84285,
            "f1": 0.84577
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 56,
        "msttr-100": 0.61667,
        "msttr-100_nopunct": 0.652,
        "total_length": 615,
        "mean_pred_length": 10.982142857142858,
        "std_pred_length": 4.600042978947399,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.3170731707317073,
        "vocab_size-1": 195,
        "unique-1": 114,
        "entropy-1": 6.3844737472400155,
        "distinct-2": 0.6135957066189625,
        "vocab_size-2": 343,
        "unique-2": 249,
        "entropy-2": 8.05673729869622,
        "cond_entropy-2": 1.386877692758929,
        "distinct-3": 0.7554671968190855,
        "vocab_size-3": 380,
        "unique-3": 309,
        "entropy-3": 8.364146244141695,
        "cond_entropy-3": 0.3490471031018999,
        "total_length-nopunct": 538,
        "mean_pred_length-nopunct": 9.607142857142858,
        "std_pred_length-nopunct": 4.287350877992191,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.3550185873605948,
        "vocab_size-1-nopunct": 191,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.502191820025737,
        "distinct-2-nopunct": 0.6016597510373444,
        "vocab_size-2-nopunct": 290,
        "unique-2-nopunct": 209,
        "entropy-2-nopunct": 7.794648185048672,
        "cond_entropy-2-nopunct": 1.4407893968153973,
        "distinct-3-nopunct": 0.744131455399061,
        "vocab_size-3-nopunct": 317,
        "unique-3-nopunct": 257,
        "entropy-3-nopunct": 8.084322664030951,
        "cond_entropy-3-nopunct": 0.34082042561675013,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.21098265895953758,
            "2": 0.6302083333333334,
            "3": 0.9021739130434783
        },
        "nist": 7.123927435832687,
        "rouge1": {
            "precision": 0.82498,
            "recall": 0.77287,
            "fmeasure": 0.7902
        },
        "rouge2": {
            "precision": 0.59303,
            "recall": 0.55873,
            "fmeasure": 0.56861
        },
        "rougeL": {
            "precision": 0.73509,
            "recall": 0.68739,
            "fmeasure": 0.70261
        },
        "rougeLsum": {
            "precision": 0.73509,
            "recall": 0.68739,
            "fmeasure": 0.70261
        },
        "bleu": 52.90964,
        "nubia": {
            "semantic_relation": 4.68573,
            "contradiction": 3.51332,
            "irrelevancy": 5.20596,
            "logical_agreement": 91.28072,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.47811,
            "nubia_score": 0.84566
        },
        "bleurt": 0.34703,
        "meteor": 0.45379431995114383,
        "bertscore": {
            "precision": 0.94905,
            "recall": 0.94464,
            "f1": 0.94563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.7475,
        "total_length": 459,
        "mean_pred_length": 17.653846153846153,
        "std_pred_length": 5.377605327025631,
        "median_pred_length": 17.5,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5729847494553377,
        "vocab_size-1": 263,
        "unique-1": 215,
        "entropy-1": 7.232347740908505,
        "distinct-2": 0.9006928406466512,
        "vocab_size-2": 390,
        "unique-2": 361,
        "entropy-2": 8.51733692714291,
        "cond_entropy-2": 1.1708718709584498,
        "distinct-3": 0.9778869778869779,
        "vocab_size-3": 398,
        "unique-3": 389,
        "entropy-3": 8.624658940040193,
        "cond_entropy-3": 0.10365654846245706,
        "total_length-nopunct": 411,
        "mean_pred_length-nopunct": 15.807692307692308,
        "std_pred_length-nopunct": 4.747624756486381,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6228710462287105,
        "vocab_size-1-nopunct": 256,
        "unique-1-nopunct": 213,
        "entropy-1-nopunct": 7.279093283353947,
        "distinct-2-nopunct": 0.9168831168831169,
        "vocab_size-2-nopunct": 353,
        "unique-2-nopunct": 333,
        "entropy-2-nopunct": 8.378860122544724,
        "cond_entropy-2-nopunct": 1.1469987973261249,
        "distinct-3-nopunct": 0.9832869080779945,
        "vocab_size-3-nopunct": 353,
        "unique-3-nopunct": 347,
        "entropy-3-nopunct": 8.454413849979057,
        "cond_entropy-3-nopunct": 0.08239555846215633,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16470588235294117,
            "2": 0.5671641791044776,
            "3": 0.7598425196850394
        },
        "nist": 6.216199766650834,
        "rouge1": {
            "precision": 0.73584,
            "recall": 0.72532,
            "fmeasure": 0.71887
        },
        "rouge2": {
            "precision": 0.51434,
            "recall": 0.50784,
            "fmeasure": 0.50269
        },
        "rougeL": {
            "precision": 0.62356,
            "recall": 0.62336,
            "fmeasure": 0.61328
        },
        "rougeLsum": {
            "precision": 0.62356,
            "recall": 0.62336,
            "fmeasure": 0.61328
        },
        "bleu": 44.34812,
        "nubia": {
            "semantic_relation": 4.08996,
            "contradiction": 14.87017,
            "irrelevancy": 40.8638,
            "logical_agreement": 44.26603,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.63185,
            "nubia_score": 0.68513
        },
        "bleurt": 0.18999,
        "meteor": 0.39076978318338224,
        "bertscore": {
            "precision": 0.92349,
            "recall": 0.93013,
            "f1": 0.92422
        }
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 28,
        "msttr-100": 0.555,
        "msttr-100_nopunct": 0.535,
        "total_length": 290,
        "mean_pred_length": 10.357142857142858,
        "std_pred_length": 3.7149724639845267,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.3758620689655172,
        "vocab_size-1": 109,
        "unique-1": 70,
        "entropy-1": 5.654932502008378,
        "distinct-2": 0.6984732824427481,
        "vocab_size-2": 183,
        "unique-2": 138,
        "entropy-2": 7.28800229563614,
        "cond_entropy-2": 1.4129071291459547,
        "distinct-3": 0.8205128205128205,
        "vocab_size-3": 192,
        "unique-3": 161,
        "entropy-3": 7.471714238749438,
        "cond_entropy-3": 0.22162553185366124,
        "total_length-nopunct": 255,
        "mean_pred_length-nopunct": 9.107142857142858,
        "std_pred_length-nopunct": 2.9921240152187845,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.403921568627451,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 5.657642660531455,
        "distinct-2-nopunct": 0.6784140969162996,
        "vocab_size-2-nopunct": 154,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 7.027869082241799,
        "cond_entropy-2-nopunct": 1.5435792240897248,
        "distinct-3-nopunct": 0.7989949748743719,
        "vocab_size-3-nopunct": 159,
        "unique-3-nopunct": 130,
        "entropy-3-nopunct": 7.187960236045443,
        "cond_entropy-3-nopunct": 0.22724202486581704,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.1292517006802721,
            "2": 0.6808510638297872,
            "3": 0.8296296296296296,
            "4": 1.0
        },
        "nist": 6.872656788145202,
        "rouge1": {
            "precision": 0.81688,
            "recall": 0.78347,
            "fmeasure": 0.79062
        },
        "rouge2": {
            "precision": 0.60215,
            "recall": 0.58839,
            "fmeasure": 0.5893
        },
        "rougeL": {
            "precision": 0.74913,
            "recall": 0.71563,
            "fmeasure": 0.72499
        },
        "rougeLsum": {
            "precision": 0.74913,
            "recall": 0.71563,
            "fmeasure": 0.72499
        },
        "bleu": 57.82901,
        "nubia": {
            "semantic_relation": 4.37839,
            "contradiction": 14.96223,
            "irrelevancy": 3.08747,
            "logical_agreement": 81.9503,
            "grammar_ref": 4.67502,
            "grammar_hyp": 5.00173,
            "nubia_score": 0.75239
        },
        "bleurt": 0.36655,
        "meteor": 0.4359937128124361,
        "bertscore": {
            "precision": 0.93805,
            "recall": 0.92903,
            "f1": 0.93173
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.71,
        "total_length": 166,
        "mean_pred_length": 13.833333333333334,
        "std_pred_length": 5.727613425813193,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6204819277108434,
        "vocab_size-1": 103,
        "unique-1": 85,
        "entropy-1": 6.08767320405985,
        "distinct-2": 0.961038961038961,
        "vocab_size-2": 148,
        "unique-2": 143,
        "entropy-2": 7.183962595875675,
        "cond_entropy-2": 0.9082576912297723,
        "distinct-3": 0.9859154929577465,
        "vocab_size-3": 140,
        "unique-3": 138,
        "entropy-3": 7.121578105420182,
        "cond_entropy-3": -0.05538528385103999,
        "total_length-nopunct": 143,
        "mean_pred_length-nopunct": 11.916666666666666,
        "std_pred_length-nopunct": 5.29871577732651,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7062937062937062,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.234152480520036,
        "distinct-2-nopunct": 0.9618320610687023,
        "vocab_size-2-nopunct": 126,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 6.951324623658341,
        "cond_entropy-2-nopunct": 0.7943372292077769,
        "distinct-3-nopunct": 0.9915966386554622,
        "vocab_size-3-nopunct": 118,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 6.878011040618867,
        "cond_entropy-3-nopunct": -0.06503475501804924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20689655172413793,
            "2": 0.5476190476190477,
            "3": 0.719626168224299
        },
        "nist": 5.533455464261688,
        "rouge1": {
            "precision": 0.81893,
            "recall": 0.7018,
            "fmeasure": 0.74294
        },
        "rouge2": {
            "precision": 0.50593,
            "recall": 0.43642,
            "fmeasure": 0.46003
        },
        "rougeL": {
            "precision": 0.71021,
            "recall": 0.61137,
            "fmeasure": 0.64549
        },
        "rougeLsum": {
            "precision": 0.71021,
            "recall": 0.61137,
            "fmeasure": 0.64549
        },
        "bleu": 43.06967,
        "nubia": {
            "semantic_relation": 4.24438,
            "contradiction": 13.17585,
            "irrelevancy": 19.98138,
            "logical_agreement": 66.84277,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.38895,
            "nubia_score": 0.69244
        },
        "bleurt": 0.06541,
        "meteor": 0.37185212131032075,
        "bertscore": {
            "precision": 0.91595,
            "recall": 0.90739,
            "f1": 0.90883
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.69857,
        "msttr-100_nopunct": 0.74833,
        "total_length": 721,
        "mean_pred_length": 16.767441860465116,
        "std_pred_length": 4.381977939837722,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.5117891816920943,
        "vocab_size-1": 369,
        "unique-1": 296,
        "entropy-1": 7.4087838675925495,
        "distinct-2": 0.8938053097345132,
        "vocab_size-2": 606,
        "unique-2": 562,
        "entropy-2": 9.139555893411572,
        "cond_entropy-2": 1.5452115359587193,
        "distinct-3": 0.9811023622047244,
        "vocab_size-3": 623,
        "unique-3": 611,
        "entropy-3": 9.272817506068915,
        "cond_entropy-3": 0.14264861719203056,
        "total_length-nopunct": 636,
        "mean_pred_length-nopunct": 14.790697674418604,
        "std_pred_length-nopunct": 4.332452656969065,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5723270440251572,
        "vocab_size-1-nopunct": 364,
        "unique-1-nopunct": 295,
        "entropy-1-nopunct": 7.601952023545355,
        "distinct-2-nopunct": 0.8920741989881956,
        "vocab_size-2-nopunct": 529,
        "unique-2-nopunct": 493,
        "entropy-2-nopunct": 8.931487061873385,
        "cond_entropy-2-nopunct": 1.4180030073128063,
        "distinct-3-nopunct": 0.9854545454545455,
        "vocab_size-3-nopunct": 542,
        "unique-3-nopunct": 534,
        "entropy-3-nopunct": 9.074196899321034,
        "cond_entropy-3-nopunct": 0.15159588836309573,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2713178294573643,
            "2": 0.6379310344827587,
            "3": 0.8209606986899564
        },
        "nist": 7.4732394633058,
        "rouge1": {
            "precision": 0.81568,
            "recall": 0.78673,
            "fmeasure": 0.79186
        },
        "rouge2": {
            "precision": 0.59032,
            "recall": 0.58473,
            "fmeasure": 0.57995
        },
        "rougeL": {
            "precision": 0.722,
            "recall": 0.70638,
            "fmeasure": 0.70541
        },
        "rougeLsum": {
            "precision": 0.722,
            "recall": 0.70638,
            "fmeasure": 0.70541
        },
        "bleu": 50.66647,
        "nubia": {
            "semantic_relation": 4.45456,
            "contradiction": 1.25741,
            "irrelevancy": 20.46818,
            "logical_agreement": 78.27441,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.68211,
            "nubia_score": 0.79694
        },
        "bleurt": 0.35745,
        "meteor": 0.4217122716200781,
        "bertscore": {
            "precision": 0.94329,
            "recall": 0.94127,
            "f1": 0.94117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76333,
        "total_length": 345,
        "mean_pred_length": 18.157894736842106,
        "std_pred_length": 5.421819056705647,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.5942028985507246,
        "vocab_size-1": 205,
        "unique-1": 169,
        "entropy-1": 6.990513491202598,
        "distinct-2": 0.9141104294478528,
        "vocab_size-2": 298,
        "unique-2": 276,
        "entropy-2": 8.1600478628068,
        "cond_entropy-2": 1.0694081205268107,
        "distinct-3": 0.9641693811074918,
        "vocab_size-3": 296,
        "unique-3": 285,
        "entropy-3": 8.190433607585119,
        "cond_entropy-3": 0.009489736755801928,
        "total_length-nopunct": 304,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.779341509366944,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6578947368421053,
        "vocab_size-1-nopunct": 200,
        "unique-1-nopunct": 168,
        "entropy-1-nopunct": 7.0628724937000955,
        "distinct-2-nopunct": 0.9228070175438596,
        "vocab_size-2-nopunct": 263,
        "unique-2-nopunct": 245,
        "entropy-2-nopunct": 7.988117144124657,
        "cond_entropy-2-nopunct": 0.9825994587532618,
        "distinct-3-nopunct": 0.9624060150375939,
        "vocab_size-3-nopunct": 256,
        "unique-3-nopunct": 246,
        "entropy-3-nopunct": 7.980094465576431,
        "cond_entropy-3-nopunct": 0.00012513473602902532,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29508196721311475,
            "2": 0.4745762711864407,
            "3": 0.7053140096618358
        },
        "nist": 5.509511108514508,
        "rouge1": {
            "precision": 0.69859,
            "recall": 0.71772,
            "fmeasure": 0.69603
        },
        "rouge2": {
            "precision": 0.44107,
            "recall": 0.43996,
            "fmeasure": 0.4314
        },
        "rougeL": {
            "precision": 0.60586,
            "recall": 0.60874,
            "fmeasure": 0.59599
        },
        "rougeLsum": {
            "precision": 0.60586,
            "recall": 0.60874,
            "fmeasure": 0.59599
        },
        "bleu": 36.66176,
        "nubia": {
            "semantic_relation": 3.86513,
            "contradiction": 14.09491,
            "irrelevancy": 38.53338,
            "logical_agreement": 47.37171,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.49025,
            "nubia_score": 0.64479
        },
        "bleurt": 0.10315,
        "meteor": 0.34649599923662144,
        "bertscore": {
            "precision": 0.90436,
            "recall": 0.91103,
            "f1": 0.90671
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 4.784233364802441,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.7115384615384616,
        "vocab_size-1": 37,
        "unique-1": 30,
        "entropy-1": 4.972087737738647,
        "distinct-2": 0.9795918367346939,
        "vocab_size-2": 48,
        "unique-2": 47,
        "entropy-2": 5.5738935175845965,
        "cond_entropy-2": 0.5493602377856216,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.0476696271886302,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 3.858612300930075,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.888535812301757,
        "distinct-2-nopunct": 0.975609756097561,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.308771516813203,
        "cond_entropy-2-nopunct": 0.46200856838965854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.0569929122271295,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.16666666666666666,
            "3": 0.9090909090909091
        },
        "nist": 4.658849434636845,
        "rouge1": {
            "precision": 0.81158,
            "recall": 0.86976,
            "fmeasure": 0.83853
        },
        "rouge2": {
            "precision": 0.58016,
            "recall": 0.62893,
            "fmeasure": 0.60275
        },
        "rougeL": {
            "precision": 0.63869,
            "recall": 0.68804,
            "fmeasure": 0.6617
        },
        "rougeLsum": {
            "precision": 0.63869,
            "recall": 0.68804,
            "fmeasure": 0.6617
        },
        "bleu": 43.8939,
        "nubia": {
            "semantic_relation": 4.95276,
            "contradiction": 0.34824,
            "irrelevancy": 1.11441,
            "logical_agreement": 98.53736,
            "grammar_ref": 5.15044,
            "grammar_hyp": 4.86154,
            "nubia_score": 0.97237
        },
        "bleurt": 0.62721,
        "meteor": 0.46721173829236634,
        "bertscore": {
            "precision": 0.95515,
            "recall": 0.96896,
            "f1": 0.962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "total_length": 167,
        "mean_pred_length": 15.181818181818182,
        "std_pred_length": 4.529061348029509,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6646706586826348,
        "vocab_size-1": 111,
        "unique-1": 90,
        "entropy-1": 6.371097569865229,
        "distinct-2": 0.9743589743589743,
        "vocab_size-2": 152,
        "unique-2": 149,
        "entropy-2": 7.229281145130448,
        "cond_entropy-2": 0.7078268942544428,
        "distinct-3": 1.0,
        "vocab_size-3": 145,
        "unique-3": 145,
        "entropy-3": 7.179909090014958,
        "cond_entropy-3": -0.045114594349634746,
        "total_length-nopunct": 149,
        "mean_pred_length-nopunct": 13.545454545454545,
        "std_pred_length-nopunct": 3.985510948505995,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7315436241610739,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.471516906930237,
        "distinct-2-nopunct": 0.9710144927536232,
        "vocab_size-2-nopunct": 134,
        "unique-2-nopunct": 131,
        "entropy-2-nopunct": 7.045083242994374,
        "cond_entropy-2-nopunct": 0.6331617545340813,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 127,
        "unique-3-nopunct": 127,
        "entropy-3-nopunct": 6.988684686772147,
        "cond_entropy-3-nopunct": -0.05090364794172402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4090909090909091,
            "3": 0.753968253968254
        },
        "nist": 5.601146829397593,
        "rouge1": {
            "precision": 0.80793,
            "recall": 0.7695,
            "fmeasure": 0.77872
        },
        "rouge2": {
            "precision": 0.58413,
            "recall": 0.56362,
            "fmeasure": 0.56742
        },
        "rougeL": {
            "precision": 0.68052,
            "recall": 0.64827,
            "fmeasure": 0.65527
        },
        "rougeLsum": {
            "precision": 0.68052,
            "recall": 0.64827,
            "fmeasure": 0.65527
        },
        "bleu": 47.82568,
        "nubia": {
            "semantic_relation": 4.32301,
            "contradiction": 1.548,
            "irrelevancy": 36.65715,
            "logical_agreement": 61.79485,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.93015,
            "nubia_score": 0.71707
        },
        "bleurt": 0.14628,
        "meteor": 0.4070271531960552,
        "bertscore": {
            "precision": 0.92805,
            "recall": 0.92879,
            "f1": 0.9276
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.69875,
        "msttr-100_nopunct": 0.75,
        "total_length": 822,
        "mean_pred_length": 17.48936170212766,
        "std_pred_length": 5.177168947984997,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5206812652068127,
        "vocab_size-1": 428,
        "unique-1": 344,
        "entropy-1": 7.609886190942685,
        "distinct-2": 0.895483870967742,
        "vocab_size-2": 694,
        "unique-2": 643,
        "entropy-2": 9.325623230552415,
        "cond_entropy-2": 1.5117693070699025,
        "distinct-3": 0.9711538461538461,
        "vocab_size-3": 707,
        "unique-3": 687,
        "entropy-3": 9.44906539912431,
        "cond_entropy-3": 0.1327885637252088,
        "total_length-nopunct": 724,
        "mean_pred_length-nopunct": 15.404255319148936,
        "std_pred_length-nopunct": 4.578671992118225,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5842541436464088,
        "vocab_size-1-nopunct": 423,
        "unique-1-nopunct": 344,
        "entropy-1-nopunct": 7.818547408815541,
        "distinct-2-nopunct": 0.8951255539143279,
        "vocab_size-2-nopunct": 606,
        "unique-2-nopunct": 564,
        "entropy-2-nopunct": 9.121804052459753,
        "cond_entropy-2-nopunct": 1.3958697904444073,
        "distinct-3-nopunct": 0.9746031746031746,
        "vocab_size-3-nopunct": 614,
        "unique-3-nopunct": 598,
        "entropy-3-nopunct": 9.24841436759362,
        "cond_entropy-3-nopunct": 0.13965281456616363,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.4263565891472868,
            "3": 0.7836363636363637
        },
        "nist": 6.857915530631846,
        "rouge1": {
            "precision": 0.77173,
            "recall": 0.76283,
            "fmeasure": 0.75755
        },
        "rouge2": {
            "precision": 0.53403,
            "recall": 0.53264,
            "fmeasure": 0.52619
        },
        "rougeL": {
            "precision": 0.66912,
            "recall": 0.66606,
            "fmeasure": 0.65916
        },
        "rougeLsum": {
            "precision": 0.66912,
            "recall": 0.66606,
            "fmeasure": 0.65916
        },
        "bleu": 47.83107,
        "nubia": {
            "semantic_relation": 4.1672,
            "contradiction": 9.46184,
            "irrelevancy": 25.36924,
            "logical_agreement": 65.16891,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.3088,
            "nubia_score": 0.72803
        },
        "bleurt": 0.30111,
        "meteor": 0.40517452981479446,
        "bertscore": {
            "precision": 0.92972,
            "recall": 0.9271,
            "f1": 0.92715
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.277613436819116,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "nist": 2.0435341581086592,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.36667,
            "fmeasure": 0.38182
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.275,
            "fmeasure": 0.28636
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.275,
            "fmeasure": 0.28636
        },
        "bleu": 5.94232,
        "nubia": {
            "semantic_relation": 2.97727,
            "contradiction": 0.37747,
            "irrelevancy": 1.21417,
            "logical_agreement": 98.40836,
            "grammar_ref": 5.93899,
            "grammar_hyp": 6.26038,
            "nubia_score": 0.35329
        },
        "bleurt": -0.66902,
        "meteor": 0.21637010676156582,
        "bertscore": {
            "precision": 0.79584,
            "recall": 0.78203,
            "f1": 0.78888
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 28,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.7725,
        "total_length": 470,
        "mean_pred_length": 16.785714285714285,
        "std_pred_length": 4.6164081805875785,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5702127659574469,
        "vocab_size-1": 268,
        "unique-1": 215,
        "entropy-1": 7.252050199821085,
        "distinct-2": 0.9049773755656109,
        "vocab_size-2": 400,
        "unique-2": 372,
        "entropy-2": 8.55935154127228,
        "cond_entropy-2": 1.1273608014401222,
        "distinct-3": 0.9710144927536232,
        "vocab_size-3": 402,
        "unique-3": 390,
        "entropy-3": 8.635515943006595,
        "cond_entropy-3": 0.08013672300279867,
        "total_length-nopunct": 413,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 3.641281171707092,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.639225181598063,
        "vocab_size-1-nopunct": 264,
        "unique-1-nopunct": 215,
        "entropy-1-nopunct": 7.412201455871142,
        "distinct-2-nopunct": 0.9142857142857143,
        "vocab_size-2-nopunct": 352,
        "unique-2-nopunct": 332,
        "entropy-2-nopunct": 8.3750401875135,
        "cond_entropy-2-nopunct": 1.0391659654412146,
        "distinct-3-nopunct": 0.9775910364145658,
        "vocab_size-3-nopunct": 349,
        "unique-3-nopunct": 341,
        "entropy-3-nopunct": 8.434962336858295,
        "cond_entropy-3-nopunct": 0.07668092958546457,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14102564102564102,
            "2": 0.5866666666666667,
            "3": 0.7368421052631579
        },
        "nist": 6.586083543263021,
        "rouge1": {
            "precision": 0.81042,
            "recall": 0.7202,
            "fmeasure": 0.75643
        },
        "rouge2": {
            "precision": 0.57785,
            "recall": 0.51533,
            "fmeasure": 0.54035
        },
        "rougeL": {
            "precision": 0.68081,
            "recall": 0.61881,
            "fmeasure": 0.64159
        },
        "rougeLsum": {
            "precision": 0.68081,
            "recall": 0.61881,
            "fmeasure": 0.64159
        },
        "bleu": 49.10286,
        "nubia": {
            "semantic_relation": 4.12566,
            "contradiction": 2.87697,
            "irrelevancy": 28.8789,
            "logical_agreement": 68.24413,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.70095,
            "nubia_score": 0.69835
        },
        "bleurt": 0.25131,
        "meteor": 0.3883778152190094,
        "bertscore": {
            "precision": 0.9374,
            "recall": 0.92365,
            "f1": 0.92795
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78167,
        "total_length": 680,
        "mean_pred_length": 15.454545454545455,
        "std_pred_length": 4.207431441965867,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5338235294117647,
        "vocab_size-1": 363,
        "unique-1": 296,
        "entropy-1": 7.528129904368255,
        "distinct-2": 0.8726415094339622,
        "vocab_size-2": 555,
        "unique-2": 506,
        "entropy-2": 8.998112392492192,
        "cond_entropy-2": 1.2654201635995512,
        "distinct-3": 0.9476351351351351,
        "vocab_size-3": 561,
        "unique-3": 539,
        "entropy-3": 9.09324730562981,
        "cond_entropy-3": 0.09570945664853127,
        "total_length-nopunct": 601,
        "mean_pred_length-nopunct": 13.659090909090908,
        "std_pred_length-nopunct": 4.050494817236878,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5923460898502496,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 293,
        "entropy-1-nopunct": 7.707470032641083,
        "distinct-2-nopunct": 0.8761220825852782,
        "vocab_size-2-nopunct": 488,
        "unique-2-nopunct": 449,
        "entropy-2-nopunct": 8.807917174554698,
        "cond_entropy-2-nopunct": 1.1766771024421958,
        "distinct-3-nopunct": 0.949317738791423,
        "vocab_size-3-nopunct": 487,
        "unique-3-nopunct": 469,
        "entropy-3-nopunct": 8.889678368399782,
        "cond_entropy-3-nopunct": 0.09354332168209115,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2785714285714286,
            "2": 0.5448717948717948,
            "3": 0.7294685990338164
        },
        "nist": 6.6475955552376504,
        "rouge1": {
            "precision": 0.73936,
            "recall": 0.71915,
            "fmeasure": 0.71989
        },
        "rouge2": {
            "precision": 0.51794,
            "recall": 0.51055,
            "fmeasure": 0.50717
        },
        "rougeL": {
            "precision": 0.65436,
            "recall": 0.63812,
            "fmeasure": 0.63824
        },
        "rougeLsum": {
            "precision": 0.65436,
            "recall": 0.63812,
            "fmeasure": 0.63824
        },
        "bleu": 45.72816,
        "nubia": {
            "semantic_relation": 4.20013,
            "contradiction": 6.36092,
            "irrelevancy": 29.99762,
            "logical_agreement": 63.64146,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.4881,
            "nubia_score": 0.73543
        },
        "bleurt": 0.25089,
        "meteor": 0.38976661845684984,
        "bertscore": {
            "precision": 0.92429,
            "recall": 0.92327,
            "f1": 0.92228
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 5.436502143433364,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.6808510638297872,
        "vocab_size-1": 32,
        "unique-1": 24,
        "entropy-1": 4.764814054257133,
        "distinct-2": 0.9318181818181818,
        "vocab_size-2": 41,
        "unique-2": 38,
        "entropy-2": 5.32306798227366,
        "cond_entropy-2": 0.5040365846096662,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": 0.04446184939542047,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 5.436502143433364,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7317073170731707,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.6841461393879165,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.090032776601483,
        "cond_entropy-2-nopunct": 0.40641867920541797,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": 0.024212646358523923,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.18181818181818182,
            "3": 0.53125
        },
        "nist": 3.052617313195405,
        "rouge1": {
            "precision": 0.6185,
            "recall": 0.51218,
            "fmeasure": 0.53835
        },
        "rouge2": {
            "precision": 0.33635,
            "recall": 0.32864,
            "fmeasure": 0.31315
        },
        "rougeL": {
            "precision": 0.40273,
            "recall": 0.42359,
            "fmeasure": 0.40519
        },
        "rougeLsum": {
            "precision": 0.40273,
            "recall": 0.42359,
            "fmeasure": 0.40519
        },
        "bleu": 21.92186,
        "nubia": {
            "semantic_relation": 4.05117,
            "contradiction": 28.43455,
            "irrelevancy": 35.89806,
            "logical_agreement": 35.66739,
            "grammar_ref": 4.07664,
            "grammar_hyp": 4.37189,
            "nubia_score": 0.69965
        },
        "bleurt": 0.03599,
        "meteor": 0.24509530807203497,
        "bertscore": {
            "precision": 0.89779,
            "recall": 0.88538,
            "f1": 0.88131
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.76,
        "total_length": 261,
        "mean_pred_length": 17.4,
        "std_pred_length": 4.841487374764082,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.5938697318007663,
        "vocab_size-1": 155,
        "unique-1": 122,
        "entropy-1": 6.68518517065246,
        "distinct-2": 0.9715447154471545,
        "vocab_size-2": 239,
        "unique-2": 233,
        "entropy-2": 7.882535287850811,
        "cond_entropy-2": 1.1035173512727223,
        "distinct-3": 1.0,
        "vocab_size-3": 231,
        "unique-3": 231,
        "entropy-3": 7.851749041416027,
        "cond_entropy-3": -0.026891492052344798,
        "total_length-nopunct": 228,
        "mean_pred_length-nopunct": 15.2,
        "std_pred_length-nopunct": 4.735680169380811,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6622807017543859,
        "vocab_size-1-nopunct": 151,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.766690808679557,
        "distinct-2-nopunct": 0.9671361502347418,
        "vocab_size-2-nopunct": 206,
        "unique-2-nopunct": 200,
        "entropy-2-nopunct": 7.665437847915251,
        "cond_entropy-2-nopunct": 0.9354750349203548,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 198,
        "unique-3-nopunct": 198,
        "entropy-3-nopunct": 7.629356620079592,
        "cond_entropy-3-nopunct": -0.03083336629691839,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.34285714285714286,
            "2": 0.5,
            "3": 0.7239583333333334
        },
        "nist": 5.86458210472134,
        "rouge1": {
            "precision": 0.78733,
            "recall": 0.72558,
            "fmeasure": 0.74771
        },
        "rouge2": {
            "precision": 0.56873,
            "recall": 0.52466,
            "fmeasure": 0.53978
        },
        "rougeL": {
            "precision": 0.72509,
            "recall": 0.66541,
            "fmeasure": 0.68662
        },
        "rougeLsum": {
            "precision": 0.72509,
            "recall": 0.66541,
            "fmeasure": 0.68662
        },
        "bleu": 43.38386,
        "nubia": {
            "semantic_relation": 4.25769,
            "contradiction": 5.16293,
            "irrelevancy": 37.32369,
            "logical_agreement": 57.51338,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.40723,
            "nubia_score": 0.72886
        },
        "bleurt": 0.24642,
        "meteor": 0.3754124593498627,
        "bertscore": {
            "precision": 0.93379,
            "recall": 0.92946,
            "f1": 0.92817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.7325,
        "msttr-100_nopunct": 0.80333,
        "total_length": 408,
        "mean_pred_length": 17.73913043478261,
        "std_pred_length": 4.560867492849862,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5808823529411765,
        "vocab_size-1": 237,
        "unique-1": 188,
        "entropy-1": 7.115879346211171,
        "distinct-2": 0.9064935064935065,
        "vocab_size-2": 349,
        "unique-2": 320,
        "entropy-2": 8.380234992708306,
        "cond_entropy-2": 1.08710534237553,
        "distinct-3": 0.9585635359116023,
        "vocab_size-3": 347,
        "unique-3": 332,
        "entropy-3": 8.416972958906397,
        "cond_entropy-3": 0.038934186601744025,
        "total_length-nopunct": 361,
        "mean_pred_length-nopunct": 15.695652173913043,
        "std_pred_length-nopunct": 4.185220191690045,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6426592797783933,
        "vocab_size-1-nopunct": 232,
        "unique-1-nopunct": 187,
        "entropy-1-nopunct": 7.2595164714149,
        "distinct-2-nopunct": 0.9053254437869822,
        "vocab_size-2-nopunct": 306,
        "unique-2-nopunct": 281,
        "entropy-2-nopunct": 8.187078659635722,
        "cond_entropy-2-nopunct": 0.9811004626971429,
        "distinct-3-nopunct": 0.9650793650793651,
        "vocab_size-3-nopunct": 304,
        "unique-3-nopunct": 293,
        "entropy-3-nopunct": 8.229366748545962,
        "cond_entropy-3-nopunct": 0.038311875771914104,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15584415584415584,
            "2": 0.6521739130434783,
            "3": 0.8464912280701754
        },
        "nist": 6.244250642936005,
        "rouge1": {
            "precision": 0.75895,
            "recall": 0.7854,
            "fmeasure": 0.76465
        },
        "rouge2": {
            "precision": 0.54504,
            "recall": 0.5697,
            "fmeasure": 0.5513
        },
        "rougeL": {
            "precision": 0.66,
            "recall": 0.68327,
            "fmeasure": 0.66539
        },
        "rougeLsum": {
            "precision": 0.66,
            "recall": 0.68327,
            "fmeasure": 0.66539
        },
        "bleu": 47.74565,
        "nubia": {
            "semantic_relation": 4.29223,
            "contradiction": 6.03533,
            "irrelevancy": 40.01999,
            "logical_agreement": 53.94468,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.6939,
            "nubia_score": 0.76878
        },
        "bleurt": 0.27661,
        "meteor": 0.4261667438375678,
        "bertscore": {
            "precision": 0.92659,
            "recall": 0.93746,
            "f1": 0.93028
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 120,
        "msttr-100": 0.347,
        "msttr-100_nopunct": 0.35333,
        "total_length": 2061,
        "mean_pred_length": 17.175,
        "std_pred_length": 4.893298989434428,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.08296943231441048,
        "vocab_size-1": 171,
        "unique-1": 24,
        "entropy-1": 6.0330149068404575,
        "distinct-2": 0.1942297784647089,
        "vocab_size-2": 377,
        "unique-2": 105,
        "entropy-2": 7.556102159812741,
        "cond_entropy-2": 1.4272848771846742,
        "distinct-3": 0.2602965403624382,
        "vocab_size-3": 474,
        "unique-3": 153,
        "entropy-3": 8.152867071249311,
        "cond_entropy-3": 0.6826951402800701,
        "total_length-nopunct": 1893,
        "mean_pred_length-nopunct": 15.775,
        "std_pred_length-nopunct": 4.643027927261835,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.08874801901743265,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 6.073086818205968,
        "distinct-2-nopunct": 0.19232938522278623,
        "vocab_size-2-nopunct": 341,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 7.3892857688235845,
        "cond_entropy-2-nopunct": 1.4542975896865866,
        "distinct-3-nopunct": 0.26073805202661826,
        "vocab_size-3-nopunct": 431,
        "unique-3-nopunct": 142,
        "entropy-3-nopunct": 8.01869639993093,
        "cond_entropy-3-nopunct": 0.7167488899546614,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.5956029313790806
        },
        "nist": 3.259900783153681,
        "rouge1": {
            "precision": 0.52305,
            "recall": 0.63034,
            "fmeasure": 0.54769
        },
        "rouge2": {
            "precision": 0.30384,
            "recall": 0.36756,
            "fmeasure": 0.31597
        },
        "rougeL": {
            "precision": 0.41272,
            "recall": 0.49847,
            "fmeasure": 0.43113
        },
        "rougeLsum": {
            "precision": 0.41272,
            "recall": 0.49847,
            "fmeasure": 0.43113
        },
        "bleu": 18.72123,
        "nubia": {
            "semantic_relation": 3.44793,
            "contradiction": 4.95902,
            "irrelevancy": 76.14842,
            "logical_agreement": 18.89256,
            "grammar_ref": 5.42765,
            "grammar_hyp": 4.98405,
            "nubia_score": 0.50475
        },
        "bleurt": -0.34994,
        "meteor": 0.28283720987059674,
        "bertscore": {
            "precision": 0.86049,
            "recall": 0.87865,
            "f1": 0.86871
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.735,
        "total_length": 277,
        "mean_pred_length": 15.38888888888889,
        "std_pred_length": 4.547757553501737,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5812274368231047,
        "vocab_size-1": 161,
        "unique-1": 129,
        "entropy-1": 6.597653361869759,
        "distinct-2": 0.9227799227799228,
        "vocab_size-2": 239,
        "unique-2": 226,
        "entropy-2": 7.813992360995476,
        "cond_entropy-2": 1.0264814826518112,
        "distinct-3": 0.991701244813278,
        "vocab_size-3": 239,
        "unique-3": 237,
        "entropy-3": 7.896291825856551,
        "cond_entropy-3": 0.09744754237320333,
        "total_length-nopunct": 244,
        "mean_pred_length-nopunct": 13.555555555555555,
        "std_pred_length-nopunct": 3.9471821485181358,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6516393442622951,
        "vocab_size-1-nopunct": 159,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.758839767507648,
        "distinct-2-nopunct": 0.9203539823008849,
        "vocab_size-2-nopunct": 208,
        "unique-2-nopunct": 197,
        "entropy-2-nopunct": 7.605447435809103,
        "cond_entropy-2-nopunct": 0.9285067557362454,
        "distinct-3-nopunct": 0.9951923076923077,
        "vocab_size-3-nopunct": 207,
        "unique-3-nopunct": 206,
        "entropy-3-nopunct": 7.690824333525683,
        "cond_entropy-3-nopunct": 0.10395943367292766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26136363636363635,
            "2": 0.3728813559322034,
            "3": 0.7453416149068323
        },
        "nist": 5.888475562165755,
        "rouge1": {
            "precision": 0.70109,
            "recall": 0.68168,
            "fmeasure": 0.67934
        },
        "rouge2": {
            "precision": 0.44119,
            "recall": 0.43535,
            "fmeasure": 0.42949
        },
        "rougeL": {
            "precision": 0.5764,
            "recall": 0.55139,
            "fmeasure": 0.55426
        },
        "rougeLsum": {
            "precision": 0.5764,
            "recall": 0.55139,
            "fmeasure": 0.55426
        },
        "bleu": 38.87944,
        "nubia": {
            "semantic_relation": 4.23435,
            "contradiction": 12.22327,
            "irrelevancy": 28.22332,
            "logical_agreement": 59.55341,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.64346,
            "nubia_score": 0.73581
        },
        "bleurt": 0.19169,
        "meteor": 0.3616681444050407,
        "bertscore": {
            "precision": 0.91514,
            "recall": 0.91137,
            "f1": 0.91106
        }
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 453,
        "msttr-100": 0.5442,
        "msttr-100_nopunct": 0.56432,
        "total_length": 5041,
        "mean_pred_length": 11.1280353200883,
        "std_pred_length": 3.9885525907491703,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 25,
        "distinct-1": 0.1793294981154533,
        "vocab_size-1": 904,
        "unique-1": 452,
        "entropy-1": 7.613476829330875,
        "distinct-2": 0.468613775065388,
        "vocab_size-2": 2150,
        "unique-2": 1421,
        "entropy-2": 10.367187065192637,
        "cond_entropy-2": 2.3562366055800346,
        "distinct-3": 0.6575574365175333,
        "vocab_size-3": 2719,
        "unique-3": 2099,
        "entropy-3": 11.032516957419684,
        "cond_entropy-3": 0.7631065830402383,
        "total_length-nopunct": 4409,
        "mean_pred_length-nopunct": 9.73289183222958,
        "std_pred_length-nopunct": 3.6262106638454843,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.20276706736221364,
        "vocab_size-1-nopunct": 894,
        "unique-1-nopunct": 448,
        "entropy-1-nopunct": 7.88546188838809,
        "distinct-2-nopunct": 0.45197168857431747,
        "vocab_size-2-nopunct": 1788,
        "unique-2-nopunct": 1166,
        "entropy-2-nopunct": 10.073575425476788,
        "cond_entropy-2-nopunct": 2.4669195983012258,
        "distinct-3-nopunct": 0.6494433342848986,
        "vocab_size-3-nopunct": 2275,
        "unique-3-nopunct": 1745,
        "entropy-3-nopunct": 10.762842457967873,
        "cond_entropy-3-nopunct": 0.8019492850466867,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.22038461538461537,
            "2": 0.654911838790932,
            "3": 0.8773200543232231,
            "4": 0.9473684210526315
        },
        "nist": 9.147377995264872,
        "rouge1": {
            "precision": 0.81297,
            "recall": 0.78109,
            "fmeasure": 0.78954
        },
        "rouge2": {
            "precision": 0.58827,
            "recall": 0.56553,
            "fmeasure": 0.57072
        },
        "rougeL": {
            "precision": 0.72793,
            "recall": 0.69693,
            "fmeasure": 0.70544
        },
        "rougeLsum": {
            "precision": 0.72793,
            "recall": 0.69693,
            "fmeasure": 0.70544
        },
        "bleu": 57.08877,
        "nubia": {
            "semantic_relation": 4.57749,
            "contradiction": 6.41823,
            "irrelevancy": 7.50072,
            "logical_agreement": 86.08104,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.31349,
            "nubia_score": 0.81653
        },
        "bleurt": 0.32795,
        "meteor": 0.44619370122649843,
        "bertscore": {
            "precision": 0.94299,
            "recall": 0.93976,
            "f1": 0.9402
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 4.459696053419884,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.75,
        "vocab_size-1": 75,
        "unique-1": 63,
        "entropy-1": 6.0024665349005595,
        "distinct-2": 0.9893617021276596,
        "vocab_size-2": 93,
        "unique-2": 92,
        "entropy-2": 6.533312255932943,
        "cond_entropy-2": 0.40678787980813175,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": -0.07242996031306767,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 2.9674156357941426,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8352941176470589,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.005102371707114,
        "distinct-2-nopunct": 0.9873417721518988,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.278464292480902,
        "cond_entropy-2-nopunct": 0.30406738136345574,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.086558929023113,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.2,
            "3": 0.7948717948717948
        },
        "nist": 5.2780131131558425,
        "rouge1": {
            "precision": 0.75427,
            "recall": 0.78909,
            "fmeasure": 0.75985
        },
        "rouge2": {
            "precision": 0.55143,
            "recall": 0.5981,
            "fmeasure": 0.56527
        },
        "rougeL": {
            "precision": 0.60812,
            "recall": 0.66095,
            "fmeasure": 0.62458
        },
        "rougeLsum": {
            "precision": 0.60812,
            "recall": 0.66095,
            "fmeasure": 0.62458
        },
        "bleu": 52.98805,
        "nubia": {
            "semantic_relation": 4.29749,
            "contradiction": 1.07933,
            "irrelevancy": 35.39223,
            "logical_agreement": 63.52845,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.8272,
            "nubia_score": 0.74283
        },
        "bleurt": 0.32608,
        "meteor": 0.4424247752797954,
        "bertscore": {
            "precision": 0.93828,
            "recall": 0.94355,
            "f1": 0.93435
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "total_length": 198,
        "mean_pred_length": 15.23076923076923,
        "std_pred_length": 4.245429146629732,
        "median_pred_length": 16.0,
        "min_pred_length": 4,
        "max_pred_length": 20,
        "distinct-1": 0.6161616161616161,
        "vocab_size-1": 122,
        "unique-1": 97,
        "entropy-1": 6.432783048604684,
        "distinct-2": 0.9405405405405406,
        "vocab_size-2": 174,
        "unique-2": 165,
        "entropy-2": 7.401651730786571,
        "cond_entropy-2": 0.7929213313350773,
        "distinct-3": 0.9883720930232558,
        "vocab_size-3": 170,
        "unique-3": 168,
        "entropy-3": 7.4030089407485775,
        "cond_entropy-3": 0.011162363953227757,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 13.153846153846153,
        "std_pred_length-nopunct": 3.8996282632727923,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.695906432748538,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.594986231374985,
        "distinct-2-nopunct": 0.9430379746835443,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.177198469696105,
        "cond_entropy-2-nopunct": 0.6372581983568051,
        "distinct-3-nopunct": 0.9862068965517241,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.152322883118406,
        "cond_entropy-3-nopunct": -0.013526830575961497,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.09090909090909091,
            "3": 0.9605263157894737
        },
        "nist": 6.858181900192991,
        "rouge1": {
            "precision": 0.90558,
            "recall": 0.90332,
            "fmeasure": 0.90121
        },
        "rouge2": {
            "precision": 0.76918,
            "recall": 0.76662,
            "fmeasure": 0.76505
        },
        "rougeL": {
            "precision": 0.86573,
            "recall": 0.863,
            "fmeasure": 0.86136
        },
        "rougeLsum": {
            "precision": 0.86573,
            "recall": 0.863,
            "fmeasure": 0.86136
        },
        "bleu": 73.43357,
        "nubia": {
            "semantic_relation": 4.67788,
            "contradiction": 0.23086,
            "irrelevancy": 6.2015,
            "logical_agreement": 93.56763,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.24729,
            "nubia_score": 0.8833
        },
        "bleurt": 0.68048,
        "meteor": 0.5390016264274992,
        "bertscore": {
            "precision": 0.97315,
            "recall": 0.97498,
            "f1": 0.97379
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.705,
        "total_length": 255,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.491019437140312,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.5803921568627451,
        "vocab_size-1": 148,
        "unique-1": 115,
        "entropy-1": 6.614876817169575,
        "distinct-2": 0.9208333333333333,
        "vocab_size-2": 221,
        "unique-2": 205,
        "entropy-2": 7.739121168498183,
        "cond_entropy-2": 0.9766686240972184,
        "distinct-3": 0.9822222222222222,
        "vocab_size-3": 221,
        "unique-3": 217,
        "entropy-3": 7.778225635661435,
        "cond_entropy-3": 0.04140020674847597,
        "total_length-nopunct": 230,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 6.128258770283411,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.6260869565217392,
        "vocab_size-1-nopunct": 144,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.6506549002593305,
        "distinct-2-nopunct": 0.9209302325581395,
        "vocab_size-2-nopunct": 198,
        "unique-2-nopunct": 184,
        "entropy-2-nopunct": 7.579520000722041,
        "cond_entropy-2-nopunct": 0.9797732276105248,
        "distinct-3-nopunct": 0.985,
        "vocab_size-3-nopunct": 197,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 7.613856189774741,
        "cond_entropy-3-nopunct": 0.046986652717716494,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2714285714285714,
            "2": 0.275,
            "3": 0.7485380116959064
        },
        "nist": 5.591273279507628,
        "rouge1": {
            "precision": 0.76363,
            "recall": 0.69484,
            "fmeasure": 0.71767
        },
        "rouge2": {
            "precision": 0.49794,
            "recall": 0.48614,
            "fmeasure": 0.48438
        },
        "rougeL": {
            "precision": 0.64175,
            "recall": 0.61223,
            "fmeasure": 0.61839
        },
        "rougeLsum": {
            "precision": 0.64175,
            "recall": 0.61223,
            "fmeasure": 0.61839
        },
        "bleu": 46.96463,
        "nubia": {
            "semantic_relation": 3.90081,
            "contradiction": 19.65334,
            "irrelevancy": 29.18465,
            "logical_agreement": 51.16201,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.89428,
            "nubia_score": 0.59224
        },
        "bleurt": 0.03837,
        "meteor": 0.37907560390271744,
        "bertscore": {
            "precision": 0.90657,
            "recall": 0.90262,
            "f1": 0.90279
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.7225,
        "msttr-100_nopunct": 0.77667,
        "total_length": 408,
        "mean_pred_length": 17.73913043478261,
        "std_pred_length": 5.210502698808543,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6029411764705882,
        "vocab_size-1": 246,
        "unique-1": 205,
        "entropy-1": 7.171647186993936,
        "distinct-2": 0.9402597402597402,
        "vocab_size-2": 362,
        "unique-2": 347,
        "entropy-2": 8.442204578552268,
        "cond_entropy-2": 1.1356985231602557,
        "distinct-3": 0.988950276243094,
        "vocab_size-3": 358,
        "unique-3": 354,
        "entropy-3": 8.47774643956938,
        "cond_entropy-3": 0.02275106353565643,
        "total_length-nopunct": 351,
        "mean_pred_length-nopunct": 15.26086956521739,
        "std_pred_length-nopunct": 4.756847616211426,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6866096866096866,
        "vocab_size-1-nopunct": 241,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 7.337557161769084,
        "distinct-2-nopunct": 0.9451219512195121,
        "vocab_size-2-nopunct": 310,
        "unique-2-nopunct": 297,
        "entropy-2-nopunct": 8.224468210549793,
        "cond_entropy-2-nopunct": 0.954361502578262,
        "distinct-3-nopunct": 0.9868852459016394,
        "vocab_size-3-nopunct": 301,
        "unique-3-nopunct": 297,
        "entropy-3-nopunct": 8.226435924253481,
        "cond_entropy-3-nopunct": 0.008724852272831223,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.43373493975903615,
            "3": 0.7160493827160493
        },
        "nist": 6.229482271829271,
        "rouge1": {
            "precision": 0.75862,
            "recall": 0.72137,
            "fmeasure": 0.72522
        },
        "rouge2": {
            "precision": 0.52765,
            "recall": 0.5077,
            "fmeasure": 0.50586
        },
        "rougeL": {
            "precision": 0.64039,
            "recall": 0.625,
            "fmeasure": 0.62002
        },
        "rougeLsum": {
            "precision": 0.64039,
            "recall": 0.625,
            "fmeasure": 0.62002
        },
        "bleu": 44.39295,
        "nubia": {
            "semantic_relation": 4.21059,
            "contradiction": 9.87727,
            "irrelevancy": 36.04129,
            "logical_agreement": 54.08145,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.52711,
            "nubia_score": 0.70753
        },
        "bleurt": 0.25003,
        "meteor": 0.38494630625807874,
        "bertscore": {
            "precision": 0.92596,
            "recall": 0.92161,
            "f1": 0.92206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.78333,
        "total_length": 364,
        "mean_pred_length": 18.2,
        "std_pred_length": 6.508456038109192,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.5851648351648352,
        "vocab_size-1": 213,
        "unique-1": 170,
        "entropy-1": 7.078616629880979,
        "distinct-2": 0.9011627906976745,
        "vocab_size-2": 310,
        "unique-2": 284,
        "entropy-2": 8.211034812791318,
        "cond_entropy-2": 0.9973161776207939,
        "distinct-3": 0.9537037037037037,
        "vocab_size-3": 309,
        "unique-3": 298,
        "entropy-3": 8.237937811499862,
        "cond_entropy-3": 0.025513218881571115,
        "total_length-nopunct": 317,
        "mean_pred_length-nopunct": 15.85,
        "std_pred_length-nopunct": 5.597097462078001,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6561514195583596,
        "vocab_size-1-nopunct": 208,
        "unique-1-nopunct": 170,
        "entropy-1-nopunct": 7.221717827220029,
        "distinct-2-nopunct": 0.9158249158249159,
        "vocab_size-2-nopunct": 272,
        "unique-2-nopunct": 252,
        "entropy-2-nopunct": 8.033260408643162,
        "cond_entropy-2-nopunct": 0.8544126960978415,
        "distinct-3-nopunct": 0.9638989169675091,
        "vocab_size-3-nopunct": 267,
        "unique-3-nopunct": 260,
        "entropy-3-nopunct": 8.033364323065511,
        "cond_entropy-3-nopunct": 0.00956663732180478,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19607843137254902,
            "2": 0.5185185185185185,
            "3": 0.88
        },
        "nist": 6.504586376565339,
        "rouge1": {
            "precision": 0.77829,
            "recall": 0.82622,
            "fmeasure": 0.79523
        },
        "rouge2": {
            "precision": 0.60176,
            "recall": 0.63443,
            "fmeasure": 0.61248
        },
        "rougeL": {
            "precision": 0.66691,
            "recall": 0.69475,
            "fmeasure": 0.67465
        },
        "rougeLsum": {
            "precision": 0.66691,
            "recall": 0.69475,
            "fmeasure": 0.67465
        },
        "bleu": 55.50811,
        "nubia": {
            "semantic_relation": 4.48869,
            "contradiction": 5.87133,
            "irrelevancy": 32.72574,
            "logical_agreement": 61.40294,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.45688,
            "nubia_score": 0.83266
        },
        "bleurt": 0.43882,
        "meteor": 0.44616179795248767,
        "bertscore": {
            "precision": 0.93989,
            "recall": 0.94593,
            "f1": 0.94188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.655,
        "msttr-100_nopunct": 0.74,
        "total_length": 293,
        "mean_pred_length": 17.235294117647058,
        "std_pred_length": 6.178991082357034,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 35,
        "distinct-1": 0.5870307167235495,
        "vocab_size-1": 172,
        "unique-1": 140,
        "entropy-1": 6.691507005973565,
        "distinct-2": 0.9420289855072463,
        "vocab_size-2": 260,
        "unique-2": 247,
        "entropy-2": 7.982600951335506,
        "cond_entropy-2": 1.1656117931474406,
        "distinct-3": 0.9845559845559846,
        "vocab_size-3": 255,
        "unique-3": 251,
        "entropy-3": 7.985920256798488,
        "cond_entropy-3": 0.01158455485496172,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 14.647058823529411,
        "std_pred_length-nopunct": 4.849999108193832,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6746987951807228,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 140,
        "entropy-1-nopunct": 6.861165864666515,
        "distinct-2-nopunct": 0.9396551724137931,
        "vocab_size-2-nopunct": 218,
        "unique-2-nopunct": 207,
        "entropy-2-nopunct": 7.7254168248596065,
        "cond_entropy-2-nopunct": 0.9250063509047757,
        "distinct-3-nopunct": 0.9813953488372092,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 207,
        "entropy-3-nopunct": 7.7109835472638535,
        "cond_entropy-3-nopunct": -0.008602622272235417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14583333333333334,
            "2": 0.5416666666666666,
            "3": 0.7655502392344498
        },
        "nist": 6.162587979849412,
        "rouge1": {
            "precision": 0.79523,
            "recall": 0.74902,
            "fmeasure": 0.76638
        },
        "rouge2": {
            "precision": 0.53887,
            "recall": 0.48997,
            "fmeasure": 0.5075
        },
        "rougeL": {
            "precision": 0.69777,
            "recall": 0.64653,
            "fmeasure": 0.66522
        },
        "rougeLsum": {
            "precision": 0.69777,
            "recall": 0.64653,
            "fmeasure": 0.66522
        },
        "bleu": 43.43663,
        "nubia": {
            "semantic_relation": 4.26241,
            "contradiction": 6.37909,
            "irrelevancy": 23.27674,
            "logical_agreement": 70.34416,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.58496,
            "nubia_score": 0.735
        },
        "bleurt": 0.30013,
        "meteor": 0.3847012080719891,
        "bertscore": {
            "precision": 0.93295,
            "recall": 0.9239,
            "f1": 0.92713
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.73,
        "total_length": 173,
        "mean_pred_length": 17.3,
        "std_pred_length": 4.648655719667784,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6473988439306358,
        "vocab_size-1": 112,
        "unique-1": 92,
        "entropy-1": 6.370499831881702,
        "distinct-2": 0.950920245398773,
        "vocab_size-2": 155,
        "unique-2": 149,
        "entropy-2": 7.241306221689217,
        "cond_entropy-2": 0.7888510766636297,
        "distinct-3": 0.9869281045751634,
        "vocab_size-3": 151,
        "unique-3": 149,
        "entropy-3": 7.2312440518429595,
        "cond_entropy-3": -0.0030411285036092044,
        "total_length-nopunct": 155,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.031128874149275,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6903225806451613,
        "vocab_size-1-nopunct": 107,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.370042289072858,
        "distinct-2-nopunct": 0.9724137931034482,
        "vocab_size-2-nopunct": 141,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.119530555517277,
        "cond_entropy-2-nopunct": 0.8010459123843601,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 7.076815597050856,
        "cond_entropy-3-nopunct": -0.04564988183696697,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.45161290322580644,
            "2": 0.3,
            "3": 0.7207207207207207
        },
        "nist": 5.218168846644432,
        "rouge1": {
            "precision": 0.70843,
            "recall": 0.68812,
            "fmeasure": 0.68697
        },
        "rouge2": {
            "precision": 0.43018,
            "recall": 0.41098,
            "fmeasure": 0.4141
        },
        "rougeL": {
            "precision": 0.59589,
            "recall": 0.57636,
            "fmeasure": 0.57713
        },
        "rougeLsum": {
            "precision": 0.59589,
            "recall": 0.57636,
            "fmeasure": 0.57713
        },
        "bleu": 36.4252,
        "nubia": {
            "semantic_relation": 4.14509,
            "contradiction": 7.096,
            "irrelevancy": 38.77855,
            "logical_agreement": 54.12545,
            "grammar_ref": 4.7085,
            "grammar_hyp": 4.91659,
            "nubia_score": 0.67282
        },
        "bleurt": 0.07412,
        "meteor": 0.32719128559088556,
        "bertscore": {
            "precision": 0.91898,
            "recall": 0.91178,
            "f1": 0.91358
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.725,
        "total_length": 314,
        "mean_pred_length": 16.526315789473685,
        "std_pred_length": 5.62296439005761,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.554140127388535,
        "vocab_size-1": 174,
        "unique-1": 139,
        "entropy-1": 6.6950700952896165,
        "distinct-2": 0.9186440677966101,
        "vocab_size-2": 271,
        "unique-2": 258,
        "entropy-2": 7.9809298952625864,
        "cond_entropy-2": 1.1868364219537473,
        "distinct-3": 0.9855072463768116,
        "vocab_size-3": 272,
        "unique-3": 268,
        "entropy-3": 8.079538949531752,
        "cond_entropy-3": 0.11400464749649052,
        "total_length-nopunct": 285,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.505977612893482,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5929824561403508,
        "vocab_size-1-nopunct": 169,
        "unique-1-nopunct": 136,
        "entropy-1-nopunct": 6.731653903817388,
        "distinct-2-nopunct": 0.9060150375939849,
        "vocab_size-2-nopunct": 241,
        "unique-2-nopunct": 227,
        "entropy-2-nopunct": 7.799740448843204,
        "cond_entropy-2-nopunct": 1.1497338826369532,
        "distinct-3-nopunct": 0.979757085020243,
        "vocab_size-3-nopunct": 242,
        "unique-3-nopunct": 237,
        "entropy-3-nopunct": 7.907881401625194,
        "cond_entropy-3-nopunct": 0.12779802867877968,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2597402597402597,
            "2": 0.23529411764705882,
            "3": 0.6336206896551724
        },
        "nist": 5.248907883154115,
        "rouge1": {
            "precision": 0.69351,
            "recall": 0.64049,
            "fmeasure": 0.65588
        },
        "rouge2": {
            "precision": 0.47913,
            "recall": 0.46169,
            "fmeasure": 0.46432
        },
        "rougeL": {
            "precision": 0.59762,
            "recall": 0.56062,
            "fmeasure": 0.57166
        },
        "rougeLsum": {
            "precision": 0.59762,
            "recall": 0.56062,
            "fmeasure": 0.57166
        },
        "bleu": 40.17028,
        "nubia": {
            "semantic_relation": 3.8355,
            "contradiction": 15.87372,
            "irrelevancy": 36.11518,
            "logical_agreement": 48.0111,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.70955,
            "nubia_score": 0.59355
        },
        "bleurt": 0.05019,
        "meteor": 0.3430597627388923,
        "bertscore": {
            "precision": 0.90732,
            "recall": 0.89516,
            "f1": 0.8991
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 88,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.714045207910317,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.75,
        "vocab_size-1": 66,
        "unique-1": 58,
        "entropy-1": 5.7674560164829725,
        "distinct-2": 1.0,
        "vocab_size-2": 82,
        "unique-2": 82,
        "entropy-2": 6.357552004618087,
        "cond_entropy-2": 0.49914736787279007,
        "distinct-3": 1.0,
        "vocab_size-3": 76,
        "unique-3": 76,
        "entropy-3": 6.247927513443591,
        "cond_entropy-3": -0.10962449117449807,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.123105625617661,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7948717948717948,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.714513436644551,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.1699250014423175,
        "cond_entropy-2-nopunct": 0.5029856299825757,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.044394119358462,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.2222222222222222,
            "3": 0.5324675324675324
        },
        "nist": 2.7265521789307985,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.50037,
            "fmeasure": 0.57405
        },
        "rouge2": {
            "precision": 0.37246,
            "recall": 0.26219,
            "fmeasure": 0.30264
        },
        "rougeL": {
            "precision": 0.55278,
            "recall": 0.40713,
            "fmeasure": 0.46114
        },
        "rougeLsum": {
            "precision": 0.55278,
            "recall": 0.40713,
            "fmeasure": 0.46114
        },
        "bleu": 23.35672,
        "nubia": {
            "semantic_relation": 3.63563,
            "contradiction": 17.86937,
            "irrelevancy": 29.51312,
            "logical_agreement": 52.61751,
            "grammar_ref": 4.85958,
            "grammar_hyp": 5.23855,
            "nubia_score": 0.51348
        },
        "bleurt": -0.03262,
        "meteor": 0.2500107217690004,
        "bertscore": {
            "precision": 0.90236,
            "recall": 0.85915,
            "f1": 0.87642
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.728,
        "msttr-100_nopunct": 0.76,
        "total_length": 520,
        "mean_pred_length": 16.774193548387096,
        "std_pred_length": 5.717599752543103,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5673076923076923,
        "vocab_size-1": 295,
        "unique-1": 243,
        "entropy-1": 7.317919559349288,
        "distinct-2": 0.8977505112474438,
        "vocab_size-2": 439,
        "unique-2": 404,
        "entropy-2": 8.686463961721996,
        "cond_entropy-2": 1.2515685247587707,
        "distinct-3": 0.9519650655021834,
        "vocab_size-3": 436,
        "unique-3": 414,
        "entropy-3": 8.74313391910133,
        "cond_entropy-3": 0.0690368296285117,
        "total_length-nopunct": 471,
        "mean_pred_length-nopunct": 15.193548387096774,
        "std_pred_length-nopunct": 5.549887269059759,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6157112526539278,
        "vocab_size-1-nopunct": 290,
        "unique-1-nopunct": 242,
        "entropy-1-nopunct": 7.423457071272815,
        "distinct-2-nopunct": 0.8954545454545455,
        "vocab_size-2-nopunct": 394,
        "unique-2-nopunct": 363,
        "entropy-2-nopunct": 8.524782774912008,
        "cond_entropy-2-nopunct": 1.1889505877933455,
        "distinct-3-nopunct": 0.9486552567237164,
        "vocab_size-3-nopunct": 388,
        "unique-3-nopunct": 367,
        "entropy-3-nopunct": 8.57326754638922,
        "cond_entropy-3-nopunct": 0.0630419477534735,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21518987341772153,
            "2": 0.5,
            "3": 0.6788732394366197
        },
        "nist": 5.940059876414709,
        "rouge1": {
            "precision": 0.71539,
            "recall": 0.6854,
            "fmeasure": 0.69301
        },
        "rouge2": {
            "precision": 0.48878,
            "recall": 0.46796,
            "fmeasure": 0.47302
        },
        "rougeL": {
            "precision": 0.61321,
            "recall": 0.58644,
            "fmeasure": 0.59267
        },
        "rougeLsum": {
            "precision": 0.61321,
            "recall": 0.58644,
            "fmeasure": 0.59267
        },
        "bleu": 39.49381,
        "nubia": {
            "semantic_relation": 4.02747,
            "contradiction": 8.23055,
            "irrelevancy": 31.20433,
            "logical_agreement": 60.56512,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.59499,
            "nubia_score": 0.69195
        },
        "bleurt": 0.15532,
        "meteor": 0.3503936953355428,
        "bertscore": {
            "precision": 0.91356,
            "recall": 0.90196,
            "f1": 0.90663
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.75,
        "total_length": 195,
        "mean_pred_length": 17.727272727272727,
        "std_pred_length": 5.528289380185735,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6205128205128205,
        "vocab_size-1": 121,
        "unique-1": 99,
        "entropy-1": 6.373267268250852,
        "distinct-2": 0.9239130434782609,
        "vocab_size-2": 170,
        "unique-2": 161,
        "entropy-2": 7.340900866522041,
        "cond_entropy-2": 0.8809236443989488,
        "distinct-3": 0.9884393063583815,
        "vocab_size-3": 171,
        "unique-3": 169,
        "entropy-3": 7.411506840353489,
        "cond_entropy-3": 0.08222026276142762,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 15.545454545454545,
        "std_pred_length-nopunct": 5.087661301684808,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6783625730994152,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.429002112250648,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 150,
        "unique-2-nopunct": 143,
        "entropy-2-nopunct": 7.1743678419221375,
        "cond_entropy-2-nopunct": 0.800849194852656,
        "distinct-3-nopunct": 0.9865771812080537,
        "vocab_size-3-nopunct": 147,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.192322882878277,
        "cond_entropy-3-nopunct": 0.028848750906589928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.23809523809523808,
            "3": 0.6456692913385826
        },
        "nist": 4.661230141814506,
        "rouge1": {
            "precision": 0.61724,
            "recall": 0.64559,
            "fmeasure": 0.61593
        },
        "rouge2": {
            "precision": 0.35194,
            "recall": 0.37917,
            "fmeasure": 0.35618
        },
        "rougeL": {
            "precision": 0.50251,
            "recall": 0.54064,
            "fmeasure": 0.509
        },
        "rougeLsum": {
            "precision": 0.50251,
            "recall": 0.54064,
            "fmeasure": 0.509
        },
        "bleu": 30.19692,
        "nubia": {
            "semantic_relation": 3.75991,
            "contradiction": 13.03806,
            "irrelevancy": 41.79308,
            "logical_agreement": 45.16887,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.41294,
            "nubia_score": 0.61308
        },
        "bleurt": 0.04402,
        "meteor": 0.3146683508660715,
        "bertscore": {
            "precision": 0.88179,
            "recall": 0.89742,
            "f1": 0.88611
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.76,
        "total_length": 151,
        "mean_pred_length": 18.875,
        "std_pred_length": 7.201345360417038,
        "median_pred_length": 18.5,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.6688741721854304,
        "vocab_size-1": 101,
        "unique-1": 84,
        "entropy-1": 6.223832822265214,
        "distinct-2": 0.965034965034965,
        "vocab_size-2": 138,
        "unique-2": 134,
        "entropy-2": 7.084662333266764,
        "cond_entropy-2": 0.7801658108761849,
        "distinct-3": 1.0,
        "vocab_size-3": 135,
        "unique-3": 135,
        "entropy-3": 7.076815597050856,
        "cond_entropy-3": -0.0033899063781995488,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.830951894845301,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7578125,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.323989648336088,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 6.833933199757171,
        "cond_entropy-2-nopunct": 0.5466775748653303,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.807354922057591,
        "cond_entropy-3-nopunct": -0.02136703513874063,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.48717948717948717,
            "3": 0.6666666666666666
        },
        "nist": 4.7113895150683165,
        "rouge1": {
            "precision": 0.72779,
            "recall": 0.65479,
            "fmeasure": 0.67309
        },
        "rouge2": {
            "precision": 0.4618,
            "recall": 0.39315,
            "fmeasure": 0.41383
        },
        "rougeL": {
            "precision": 0.5582,
            "recall": 0.49185,
            "fmeasure": 0.51218
        },
        "rougeLsum": {
            "precision": 0.5582,
            "recall": 0.49185,
            "fmeasure": 0.51218
        },
        "bleu": 23.18869,
        "nubia": {
            "semantic_relation": 3.8792,
            "contradiction": 3.95581,
            "irrelevancy": 47.73791,
            "logical_agreement": 48.30628,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.71449,
            "nubia_score": 0.59601
        },
        "bleurt": -0.08085,
        "meteor": 0.3343581870883982,
        "bertscore": {
            "precision": 0.90779,
            "recall": 0.89571,
            "f1": 0.90061
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.75
        },
        "nist": 1.9220316431016136,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.18182,
            "fmeasure": 0.18182
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "bleu": 10.04917,
        "nubia": {
            "semantic_relation": 2.96194,
            "contradiction": 1.07976,
            "irrelevancy": 98.78285,
            "logical_agreement": 0.13739,
            "grammar_ref": 3.85254,
            "grammar_hyp": 4.69107,
            "nubia_score": 0.30812
        },
        "bleurt": -0.5516,
        "meteor": 0.2572547310415535,
        "bertscore": {
            "precision": 0.85058,
            "recall": 0.86792,
            "f1": 0.85916
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "total_length": 213,
        "mean_pred_length": 14.2,
        "std_pred_length": 5.516037224916695,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.647887323943662,
        "vocab_size-1": 138,
        "unique-1": 115,
        "entropy-1": 6.577847819443153,
        "distinct-2": 0.9494949494949495,
        "vocab_size-2": 188,
        "unique-2": 179,
        "entropy-2": 7.524533955927253,
        "cond_entropy-2": 0.7913690186856849,
        "distinct-3": 0.9836065573770492,
        "vocab_size-3": 180,
        "unique-3": 177,
        "entropy-3": 7.482912953038135,
        "cond_entropy-3": -0.05488690473456416,
        "total_length-nopunct": 186,
        "mean_pred_length-nopunct": 12.4,
        "std_pred_length-nopunct": 4.868949236402724,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7150537634408602,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.677588384087223,
        "distinct-2-nopunct": 0.9590643274853801,
        "vocab_size-2-nopunct": 164,
        "unique-2-nopunct": 158,
        "entropy-2-nopunct": 7.3315666230603735,
        "cond_entropy-2-nopunct": 0.6924794460049093,
        "distinct-3-nopunct": 0.9871794871794872,
        "vocab_size-3-nopunct": 154,
        "unique-3-nopunct": 152,
        "entropy-3-nopunct": 7.25976119322124,
        "cond_entropy-3-nopunct": -0.08382874153184748,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09615384615384616,
            "2": 0.3409090909090909,
            "3": 0.7452229299363057
        },
        "nist": 4.8712199638999865,
        "rouge1": {
            "precision": 0.79279,
            "recall": 0.6874,
            "fmeasure": 0.72491
        },
        "rouge2": {
            "precision": 0.51058,
            "recall": 0.46254,
            "fmeasure": 0.47939
        },
        "rougeL": {
            "precision": 0.66436,
            "recall": 0.58114,
            "fmeasure": 0.61082
        },
        "rougeLsum": {
            "precision": 0.66436,
            "recall": 0.58114,
            "fmeasure": 0.61082
        },
        "bleu": 40.75922,
        "nubia": {
            "semantic_relation": 4.21758,
            "contradiction": 2.6642,
            "irrelevancy": 41.62657,
            "logical_agreement": 55.70923,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.96217,
            "nubia_score": 0.68456
        },
        "bleurt": 0.19631,
        "meteor": 0.3622240767449158,
        "bertscore": {
            "precision": 0.9215,
            "recall": 0.91287,
            "f1": 0.91631
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "total_length": 101,
        "mean_pred_length": 14.428571428571429,
        "std_pred_length": 2.8713930346059686,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.7128712871287128,
        "vocab_size-1": 72,
        "unique-1": 60,
        "entropy-1": 5.875681161567058,
        "distinct-2": 0.9574468085106383,
        "vocab_size-2": 90,
        "unique-2": 86,
        "entropy-2": 6.4694824686989,
        "cond_entropy-2": 0.4430164964285466,
        "distinct-3": 0.9885057471264368,
        "vocab_size-3": 86,
        "unique-3": 85,
        "entropy-3": 6.419954990101596,
        "cond_entropy-3": -0.042679838587529745,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 2.770102775666474,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7701149425287356,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.852321909811322,
        "distinct-2-nopunct": 0.9625,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.246928094887356,
        "cond_entropy-2-nopunct": 0.42128557385431076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.0499117551854272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.3333333333333333,
            "3": 0.7777777777777778
        },
        "nist": 5.2189569782769585,
        "rouge1": {
            "precision": 0.74161,
            "recall": 0.71967,
            "fmeasure": 0.72633
        },
        "rouge2": {
            "precision": 0.52209,
            "recall": 0.50799,
            "fmeasure": 0.51111
        },
        "rougeL": {
            "precision": 0.65443,
            "recall": 0.64459,
            "fmeasure": 0.64544
        },
        "rougeLsum": {
            "precision": 0.65443,
            "recall": 0.64459,
            "fmeasure": 0.64544
        },
        "bleu": 45.84384,
        "nubia": {
            "semantic_relation": 4.28176,
            "contradiction": 6.20631,
            "irrelevancy": 34.97621,
            "logical_agreement": 58.81749,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.46633,
            "nubia_score": 0.74729
        },
        "bleurt": 0.15144,
        "meteor": 0.3961632683391331,
        "bertscore": {
            "precision": 0.93753,
            "recall": 0.93823,
            "f1": 0.93745
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_bfp05": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_test_asset_bfp05",
        "N": 359,
        "msttr-100": 0.75105,
        "msttr-100_nopunct": 0.7949,
        "total_length": 5758,
        "mean_pred_length": 16.03899721448468,
        "std_pred_length": 6.09293257854356,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.4435567905522751,
        "vocab_size-1": 2554,
        "unique-1": 2113,
        "entropy-1": 9.292968747539074,
        "distinct-2": 0.8636784589738841,
        "vocab_size-2": 4663,
        "unique-2": 4412,
        "entropy-2": 11.89213322799754,
        "cond_entropy-2": 2.3326846841278432,
        "distinct-3": 0.9591269841269842,
        "vocab_size-3": 4834,
        "unique-3": 4765,
        "entropy-3": 12.134086426296983,
        "cond_entropy-3": 0.26879876891185983,
        "total_length-nopunct": 5123,
        "mean_pred_length-nopunct": 14.270194986072424,
        "std_pred_length-nopunct": 5.446317169801036,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.49658403279328517,
        "vocab_size-1-nopunct": 2544,
        "unique-1-nopunct": 2111,
        "entropy-1-nopunct": 9.641822105144495,
        "distinct-2-nopunct": 0.8895885810243492,
        "vocab_size-2-nopunct": 4238,
        "unique-2-nopunct": 4028,
        "entropy-2-nopunct": 11.853826666512255,
        "cond_entropy-2-nopunct": 2.3652433997819258,
        "distinct-3-nopunct": 0.9836549375709421,
        "vocab_size-3-nopunct": 4333,
        "unique-3-nopunct": 4280,
        "entropy-3-nopunct": 12.068080954768307,
        "cond_entropy-3-nopunct": 0.23836626674592795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_bfp05.json",
        "local_recall": {
            "1": 0.036521739130434785,
            "2": 0.12362637362637363,
            "3": 0.21570926143024619,
            "4": 0.3073654390934844,
            "5": 0.36254980079681276,
            "6": 0.4100985221674877,
            "7": 0.5068493150684932,
            "8": 0.5763888888888888,
            "9": 0.7079136690647482
        },
        "nist": 7.717183652069244,
        "rouge1": {
            "precision": 0.66314,
            "recall": 0.6037,
            "fmeasure": 0.61919
        },
        "rouge2": {
            "precision": 0.43843,
            "recall": 0.39231,
            "fmeasure": 0.40255
        },
        "rougeL": {
            "precision": 0.62988,
            "recall": 0.57375,
            "fmeasure": 0.58813
        },
        "rougeLsum": {
            "precision": 0.62988,
            "recall": 0.57375,
            "fmeasure": 0.58813
        },
        "bleu": 37.66625,
        "sari": 43.08645,
        "nubia": {
            "semantic_relation": 3.46984,
            "contradiction": 9.25592,
            "irrelevancy": 26.44247,
            "logical_agreement": 64.30162,
            "grammar_ref": 4.57404,
            "grammar_hyp": 6.46913,
            "nubia_score": 0.36834
        },
        "bleurt": -0.76425,
        "meteor": 0.29126373228784125,
        "bertscore": {
            "precision": 0.86358,
            "recall": 0.88712,
            "f1": 0.87086
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.688,
        "msttr-100_nopunct": 0.742,
        "total_length": 588,
        "mean_pred_length": 16.8,
        "std_pred_length": 6.2463703746370065,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5357142857142857,
        "vocab_size-1": 315,
        "unique-1": 248,
        "entropy-1": 7.35710561198866,
        "distinct-2": 0.8842676311030742,
        "vocab_size-2": 489,
        "unique-2": 445,
        "entropy-2": 8.83037910429219,
        "cond_entropy-2": 1.3265347930066365,
        "distinct-3": 0.9420849420849421,
        "vocab_size-3": 488,
        "unique-3": 461,
        "entropy-3": 8.896606236515646,
        "cond_entropy-3": 0.07441538957341047,
        "total_length-nopunct": 526,
        "mean_pred_length-nopunct": 15.028571428571428,
        "std_pred_length-nopunct": 5.739515730122754,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5855513307984791,
        "vocab_size-1-nopunct": 308,
        "unique-1-nopunct": 245,
        "entropy-1-nopunct": 7.486948728105871,
        "distinct-2-nopunct": 0.8859470468431772,
        "vocab_size-2-nopunct": 435,
        "unique-2-nopunct": 397,
        "entropy-2-nopunct": 8.659032155329292,
        "cond_entropy-2-nopunct": 1.2470512156901732,
        "distinct-3-nopunct": 0.9429824561403509,
        "vocab_size-3-nopunct": 430,
        "unique-3-nopunct": 406,
        "entropy-3-nopunct": 8.715544016348286,
        "cond_entropy-3-nopunct": 0.0657973534833961,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.211340206185567,
            "2": 0.40540540540540543,
            "3": 0.7346368715083799
        },
        "nist": 6.203728612976378,
        "rouge1": {
            "precision": 0.73419,
            "recall": 0.69037,
            "fmeasure": 0.7014
        },
        "rouge2": {
            "precision": 0.48494,
            "recall": 0.45091,
            "fmeasure": 0.46212
        },
        "rougeL": {
            "precision": 0.62498,
            "recall": 0.59041,
            "fmeasure": 0.60008
        },
        "rougeLsum": {
            "precision": 0.62498,
            "recall": 0.59041,
            "fmeasure": 0.60008
        },
        "bleu": 38.97839,
        "nubia": {
            "semantic_relation": 4.04191,
            "contradiction": 14.65117,
            "irrelevancy": 28.74468,
            "logical_agreement": 56.60415,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.84604,
            "nubia_score": 0.66953
        },
        "bleurt": 0.15782,
        "meteor": 0.3457302427276358,
        "bertscore": {
            "precision": 0.92709,
            "recall": 0.9117,
            "f1": 0.91798
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.74,
        "total_length": 273,
        "mean_pred_length": 15.166666666666666,
        "std_pred_length": 4.166666666666667,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.5567765567765568,
        "vocab_size-1": 152,
        "unique-1": 120,
        "entropy-1": 6.48796034993962,
        "distinct-2": 0.9019607843137255,
        "vocab_size-2": 230,
        "unique-2": 210,
        "entropy-2": 7.7781988663539146,
        "cond_entropy-2": 1.1310207671452022,
        "distinct-3": 0.9578059071729957,
        "vocab_size-3": 227,
        "unique-3": 218,
        "entropy-3": 7.801169883910266,
        "cond_entropy-3": 0.03938782037948689,
        "total_length-nopunct": 234,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.972125095937662,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6324786324786325,
        "vocab_size-1-nopunct": 148,
        "unique-1-nopunct": 118,
        "entropy-1-nopunct": 6.664449789076576,
        "distinct-2-nopunct": 0.9027777777777778,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 179,
        "entropy-2-nopunct": 7.53674206013215,
        "cond_entropy-2-nopunct": 0.9515585036870601,
        "distinct-3-nopunct": 0.9646464646464646,
        "vocab_size-3-nopunct": 191,
        "unique-3-nopunct": 185,
        "entropy-3-nopunct": 7.554836986230283,
        "cond_entropy-3-nopunct": 0.02782531981816239,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2692307692307692,
            "2": 0.3448275862068966,
            "3": 0.7934782608695652
        },
        "nist": 5.917816348199707,
        "rouge1": {
            "precision": 0.75848,
            "recall": 0.75792,
            "fmeasure": 0.74765
        },
        "rouge2": {
            "precision": 0.54098,
            "recall": 0.54137,
            "fmeasure": 0.53228
        },
        "rougeL": {
            "precision": 0.63487,
            "recall": 0.65209,
            "fmeasure": 0.63234
        },
        "rougeLsum": {
            "precision": 0.63487,
            "recall": 0.65209,
            "fmeasure": 0.63234
        },
        "bleu": 39.64819,
        "nubia": {
            "semantic_relation": 4.29582,
            "contradiction": 7.34282,
            "irrelevancy": 22.03339,
            "logical_agreement": 70.62379,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.62035,
            "nubia_score": 0.7567
        },
        "bleurt": 0.27704,
        "meteor": 0.39768822001223003,
        "bertscore": {
            "precision": 0.93181,
            "recall": 0.93569,
            "f1": 0.93213
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.755,
        "total_length": 319,
        "mean_pred_length": 15.19047619047619,
        "std_pred_length": 4.181809219066695,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.6144200626959248,
        "vocab_size-1": 196,
        "unique-1": 161,
        "entropy-1": 6.945853952677632,
        "distinct-2": 0.9261744966442953,
        "vocab_size-2": 276,
        "unique-2": 260,
        "entropy-2": 8.047961976808935,
        "cond_entropy-2": 0.9086991985779583,
        "distinct-3": 0.9963898916967509,
        "vocab_size-3": 276,
        "unique-3": 275,
        "entropy-3": 8.106521949442739,
        "cond_entropy-3": 0.047153654635728806,
        "total_length-nopunct": 277,
        "mean_pred_length-nopunct": 13.19047619047619,
        "std_pred_length-nopunct": 3.8249686910520384,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6895306859205776,
        "vocab_size-1-nopunct": 191,
        "unique-1-nopunct": 160,
        "entropy-1-nopunct": 7.092169902328498,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 240,
        "unique-2-nopunct": 228,
        "entropy-2-nopunct": 7.853477441389348,
        "cond_entropy-2-nopunct": 0.8232921290507774,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 235,
        "entropy-3-nopunct": 7.876516946564981,
        "cond_entropy-3-nopunct": 0.036133010413199565,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5319148936170213,
            "3": 0.7525773195876289
        },
        "nist": 6.521403684111634,
        "rouge1": {
            "precision": 0.78115,
            "recall": 0.72415,
            "fmeasure": 0.74407
        },
        "rouge2": {
            "precision": 0.52997,
            "recall": 0.50602,
            "fmeasure": 0.51259
        },
        "rougeL": {
            "precision": 0.67102,
            "recall": 0.6336,
            "fmeasure": 0.64547
        },
        "rougeLsum": {
            "precision": 0.67102,
            "recall": 0.6336,
            "fmeasure": 0.64547
        },
        "bleu": 49.19801,
        "nubia": {
            "semantic_relation": 4.16596,
            "contradiction": 18.00557,
            "irrelevancy": 30.10061,
            "logical_agreement": 51.89382,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.80137,
            "nubia_score": 0.7125
        },
        "bleurt": 0.302,
        "meteor": 0.39810426824229583,
        "bertscore": {
            "precision": 0.9444,
            "recall": 0.93329,
            "f1": 0.93801
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.76,
        "total_length": 688,
        "mean_pred_length": 16.38095238095238,
        "std_pred_length": 5.246097783125414,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5305232558139535,
        "vocab_size-1": 365,
        "unique-1": 284,
        "entropy-1": 7.531743628726589,
        "distinct-2": 0.8993808049535603,
        "vocab_size-2": 581,
        "unique-2": 532,
        "entropy-2": 9.093084898017391,
        "cond_entropy-2": 1.3561639227110007,
        "distinct-3": 0.9768211920529801,
        "vocab_size-3": 590,
        "unique-3": 577,
        "entropy-3": 9.190797309685689,
        "cond_entropy-3": 0.10959457918548594,
        "total_length-nopunct": 605,
        "mean_pred_length-nopunct": 14.404761904761905,
        "std_pred_length-nopunct": 4.736180517641997,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5933884297520661,
        "vocab_size-1-nopunct": 359,
        "unique-1-nopunct": 283,
        "entropy-1-nopunct": 7.743607660197291,
        "distinct-2-nopunct": 0.8969804618117229,
        "vocab_size-2-nopunct": 505,
        "unique-2-nopunct": 462,
        "entropy-2-nopunct": 8.885171507265254,
        "cond_entropy-2-nopunct": 1.2246986581256378,
        "distinct-3-nopunct": 0.9788867562380038,
        "vocab_size-3-nopunct": 510,
        "unique-3-nopunct": 499,
        "entropy-3-nopunct": 8.98291307475449,
        "cond_entropy-3-nopunct": 0.11036426115953951,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.4339622641509434,
            "3": 0.7617977528089888
        },
        "nist": 6.6206556896891,
        "rouge1": {
            "precision": 0.73527,
            "recall": 0.73398,
            "fmeasure": 0.72923
        },
        "rouge2": {
            "precision": 0.49625,
            "recall": 0.49134,
            "fmeasure": 0.48962
        },
        "rougeL": {
            "precision": 0.63112,
            "recall": 0.6217,
            "fmeasure": 0.62161
        },
        "rougeLsum": {
            "precision": 0.63112,
            "recall": 0.6217,
            "fmeasure": 0.62161
        },
        "bleu": 40.79182,
        "nubia": {
            "semantic_relation": 4.1603,
            "contradiction": 8.86718,
            "irrelevancy": 30.5228,
            "logical_agreement": 60.61002,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.6247,
            "nubia_score": 0.7231
        },
        "bleurt": 0.21168,
        "meteor": 0.3814213368560903,
        "bertscore": {
            "precision": 0.92842,
            "recall": 0.92411,
            "f1": 0.92476
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 4.9216076867444665,
        "median_pred_length": 20.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.7758620689655172,
        "vocab_size-1": 45,
        "unique-1": 35,
        "entropy-1": 5.362207072676476,
        "distinct-2": 0.9272727272727272,
        "vocab_size-2": 51,
        "unique-2": 47,
        "entropy-2": 5.63590516807011,
        "cond_entropy-2": 0.26437667298187784,
        "distinct-3": 0.9615384615384616,
        "vocab_size-3": 50,
        "unique-3": 48,
        "entropy-3": 5.623516641218018,
        "cond_entropy-3": -0.003996918460490562,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 4.898979485566356,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7962962962962963,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.2964636595308106,
        "distinct-2-nopunct": 0.9215686274509803,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.515562596873461,
        "cond_entropy-2-nopunct": 0.24606504573280086,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.5016291673878275,
        "cond_entropy-3-nopunct": -0.004129507917006085,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.5,
            "3": 0.7222222222222222
        },
        "nist": 3.5367989586571422,
        "rouge1": {
            "precision": 0.57333,
            "recall": 0.63795,
            "fmeasure": 0.60305
        },
        "rouge2": {
            "precision": 0.29882,
            "recall": 0.32755,
            "fmeasure": 0.31216
        },
        "rougeL": {
            "precision": 0.41871,
            "recall": 0.45648,
            "fmeasure": 0.43588
        },
        "rougeLsum": {
            "precision": 0.41871,
            "recall": 0.45648,
            "fmeasure": 0.43588
        },
        "bleu": 17.96011,
        "nubia": {
            "semantic_relation": 4.01883,
            "contradiction": 0.54614,
            "irrelevancy": 63.8954,
            "logical_agreement": 35.55845,
            "grammar_ref": 4.57112,
            "grammar_hyp": 4.38624,
            "nubia_score": 0.68176
        },
        "bleurt": 0.00117,
        "meteor": 0.35734453289867923,
        "bertscore": {
            "precision": 0.87612,
            "recall": 0.90087,
            "f1": 0.8861
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 88,
        "mean_pred_length": 17.6,
        "std_pred_length": 7.08801805866774,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.7954545454545454,
        "vocab_size-1": 70,
        "unique-1": 63,
        "entropy-1": 5.916540283287106,
        "distinct-2": 0.963855421686747,
        "vocab_size-2": 80,
        "unique-2": 78,
        "entropy-2": 6.293655244573878,
        "cond_entropy-2": 0.3134337164283484,
        "distinct-3": 1.0,
        "vocab_size-3": 78,
        "unique-3": 78,
        "entropy-3": 6.285402218862257,
        "cond_entropy-3": -0.0030360906620678432,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 7.183313998427188,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.849747626002141,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.138753523800377,
        "cond_entropy-2-nopunct": 0.3204845957239038,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.129283016944973,
        "cond_entropy-3-nopunct": -0.00303728066286483,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nist": 5.156369099825775,
        "rouge1": {
            "precision": 0.82556,
            "recall": 0.73971,
            "fmeasure": 0.77794
        },
        "rouge2": {
            "precision": 0.60349,
            "recall": 0.53883,
            "fmeasure": 0.56756
        },
        "rougeL": {
            "precision": 0.67222,
            "recall": 0.60096,
            "fmeasure": 0.63277
        },
        "rougeLsum": {
            "precision": 0.67222,
            "recall": 0.60096,
            "fmeasure": 0.63277
        },
        "bleu": 47.44893,
        "nubia": {
            "semantic_relation": 4.33286,
            "contradiction": 0.74374,
            "irrelevancy": 39.90803,
            "logical_agreement": 59.34824,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.89577,
            "nubia_score": 0.75071
        },
        "bleurt": 0.29372,
        "meteor": 0.4027003003411382,
        "bertscore": {
            "precision": 0.92437,
            "recall": 0.91329,
            "f1": 0.91861
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.69667,
        "msttr-100_nopunct": 0.725,
        "total_length": 321,
        "mean_pred_length": 17.833333333333332,
        "std_pred_length": 5.7759078170544855,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.5887850467289719,
        "vocab_size-1": 189,
        "unique-1": 154,
        "entropy-1": 6.875618712074328,
        "distinct-2": 0.9207920792079208,
        "vocab_size-2": 279,
        "unique-2": 263,
        "entropy-2": 8.058770343271869,
        "cond_entropy-2": 1.0548169577680175,
        "distinct-3": 0.9824561403508771,
        "vocab_size-3": 280,
        "unique-3": 275,
        "entropy-3": 8.119730389753874,
        "cond_entropy-3": 0.07260659217889794,
        "total_length-nopunct": 288,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.477225575051661,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6388888888888888,
        "vocab_size-1-nopunct": 184,
        "unique-1-nopunct": 151,
        "entropy-1-nopunct": 6.960177467131239,
        "distinct-2-nopunct": 0.9222222222222223,
        "vocab_size-2-nopunct": 249,
        "unique-2-nopunct": 235,
        "entropy-2-nopunct": 7.894891836018384,
        "cond_entropy-2-nopunct": 1.0042530933967355,
        "distinct-3-nopunct": 0.9801587301587301,
        "vocab_size-3-nopunct": 247,
        "unique-3-nopunct": 242,
        "entropy-3-nopunct": 7.937597383817388,
        "cond_entropy-3-nopunct": 0.0557001021584656,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.5070422535211268,
            "3": 0.6881720430107527
        },
        "nist": 5.522981791018251,
        "rouge1": {
            "precision": 0.66242,
            "recall": 0.66856,
            "fmeasure": 0.65505
        },
        "rouge2": {
            "precision": 0.42279,
            "recall": 0.42543,
            "fmeasure": 0.41449
        },
        "rougeL": {
            "precision": 0.56063,
            "recall": 0.58014,
            "fmeasure": 0.56118
        },
        "rougeLsum": {
            "precision": 0.56063,
            "recall": 0.58014,
            "fmeasure": 0.56118
        },
        "bleu": 34.2746,
        "nubia": {
            "semantic_relation": 3.75072,
            "contradiction": 11.64063,
            "irrelevancy": 47.76707,
            "logical_agreement": 40.5923,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.56682,
            "nubia_score": 0.60397
        },
        "bleurt": -0.06899,
        "meteor": 0.34203108856535325,
        "bertscore": {
            "precision": 0.89379,
            "recall": 0.90014,
            "f1": 0.89533
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.430632409490749,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.15916418769779478,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.18150945892357132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9130434782608695
        },
        "nist": 4.62659561422963,
        "rouge1": {
            "precision": 0.9119,
            "recall": 0.92857,
            "fmeasure": 0.9198
        },
        "rouge2": {
            "precision": 0.84758,
            "recall": 0.86378,
            "fmeasure": 0.8552
        },
        "rougeL": {
            "precision": 0.9119,
            "recall": 0.92857,
            "fmeasure": 0.9198
        },
        "rougeLsum": {
            "precision": 0.9119,
            "recall": 0.92857,
            "fmeasure": 0.9198
        },
        "bleu": 84.62454,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.72774,
            "irrelevancy": 0.64505,
            "logical_agreement": 98.62721,
            "grammar_ref": 4.84371,
            "grammar_hyp": 4.70968,
            "nubia_score": 0.98621
        },
        "bleurt": 0.87341,
        "meteor": 0.5980597342300946,
        "bertscore": {
            "precision": 0.99346,
            "recall": 0.99346,
            "f1": 0.99346
        }
    },
    "schema_guided_dialog_challenge_test_nopunc_parent": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.7006,
        "msttr-100_nopunct": 0.72407,
        "total_length": 6770,
        "mean_pred_length": 13.54,
        "std_pred_length": 7.018005414645959,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.16322008862629248,
        "vocab_size-1": 1105,
        "unique-1": 638,
        "entropy-1": 7.9671339298715,
        "distinct-2": 0.5070175438596491,
        "vocab_size-2": 3179,
        "unique-2": 2265,
        "entropy-2": 10.887851597708174,
        "cond_entropy-2": 2.72244888943539,
        "distinct-3": 0.7322357019064125,
        "vocab_size-3": 4225,
        "unique-3": 3552,
        "entropy-3": 11.69500056092654,
        "cond_entropy-3": 0.8291997882555422,
        "total_length-nopunct": 5996,
        "mean_pred_length-nopunct": 11.992,
        "std_pred_length-nopunct": 6.506607103552511,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.1822881921280854,
        "vocab_size-1-nopunct": 1093,
        "unique-1-nopunct": 637,
        "entropy-1-nopunct": 8.13464577765197,
        "distinct-2-nopunct": 0.5238355167394468,
        "vocab_size-2-nopunct": 2879,
        "unique-2-nopunct": 2107,
        "entropy-2-nopunct": 10.729535261959024,
        "cond_entropy-2-nopunct": 2.7189737391204214,
        "distinct-3-nopunct": 0.7438463077846708,
        "vocab_size-3-nopunct": 3717,
        "unique-3-nopunct": 3173,
        "entropy-3-nopunct": 11.504195921709291,
        "cond_entropy-3-nopunct": 0.8099681637213182,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5586536875103119
        },
        "nist": 6.103889351788272,
        "rouge1": {
            "precision": 0.57654,
            "recall": 0.54507,
            "fmeasure": 0.548
        },
        "rouge2": {
            "precision": 0.35472,
            "recall": 0.33364,
            "fmeasure": 0.3354
        },
        "rougeL": {
            "precision": 0.51915,
            "recall": 0.49105,
            "fmeasure": 0.49359
        },
        "rougeLsum": {
            "precision": 0.51915,
            "recall": 0.49105,
            "fmeasure": 0.49359
        },
        "bleu": 31.36566,
        "nubia": {
            "semantic_relation": 3.64341,
            "contradiction": 6.8875,
            "irrelevancy": 21.35978,
            "logical_agreement": 71.75272,
            "grammar_ref": 4.79983,
            "grammar_hyp": 4.67325,
            "nubia_score": 0.63527
        },
        "bleurt": -0.08835,
        "meteor": 0.30960987215197283,
        "bertscore": {
            "precision": 0.87198,
            "recall": 0.86228,
            "f1": 0.86661
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.6,
        "msttr-100_nopunct": 0.65,
        "total_length": 156,
        "mean_pred_length": 15.6,
        "std_pred_length": 6.102458520956943,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 24,
        "distinct-1": 0.5705128205128205,
        "vocab_size-1": 89,
        "unique-1": 68,
        "entropy-1": 5.947512125630538,
        "distinct-2": 0.8767123287671232,
        "vocab_size-2": 128,
        "unique-2": 116,
        "entropy-2": 6.903014264490108,
        "cond_entropy-2": 0.819609125047548,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 128,
        "unique-3": 121,
        "entropy-3": 6.964265139028537,
        "cond_entropy-3": 0.05292810206711457,
        "total_length-nopunct": 138,
        "mean_pred_length-nopunct": 13.8,
        "std_pred_length-nopunct": 6.209669878504009,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6304347826086957,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.010759430725452,
        "distinct-2-nopunct": 0.8828125,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 104,
        "entropy-2-nopunct": 6.719732007961506,
        "cond_entropy-2-nopunct": 0.7387204308226519,
        "distinct-3-nopunct": 0.9491525423728814,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 107,
        "entropy-3-nopunct": 6.774550782394346,
        "cond_entropy-3-nopunct": 0.0517065279832094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2033898305084746,
            "2": 0.15384615384615385,
            "3": 0.6078431372549019
        },
        "nist": 4.06343065449458,
        "rouge1": {
            "precision": 0.65402,
            "recall": 0.60377,
            "fmeasure": 0.58701
        },
        "rouge2": {
            "precision": 0.35984,
            "recall": 0.34077,
            "fmeasure": 0.32146
        },
        "rougeL": {
            "precision": 0.50396,
            "recall": 0.48386,
            "fmeasure": 0.45866
        },
        "rougeLsum": {
            "precision": 0.50396,
            "recall": 0.48386,
            "fmeasure": 0.45866
        },
        "bleu": 20.7053,
        "nubia": {
            "semantic_relation": 3.80515,
            "contradiction": 8.74266,
            "irrelevancy": 39.43737,
            "logical_agreement": 51.81997,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.76669,
            "nubia_score": 0.5809
        },
        "bleurt": 0.10735,
        "meteor": 0.2821461362635453,
        "bertscore": {
            "precision": 0.88492,
            "recall": 0.88318,
            "f1": 0.88047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.76,
        "total_length": 383,
        "mean_pred_length": 16.652173913043477,
        "std_pred_length": 6.734781205265524,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5848563968668408,
        "vocab_size-1": 224,
        "unique-1": 187,
        "entropy-1": 6.993771562931137,
        "distinct-2": 0.9222222222222223,
        "vocab_size-2": 332,
        "unique-2": 316,
        "entropy-2": 8.291009311541327,
        "cond_entropy-2": 1.1585497084410397,
        "distinct-3": 0.9821958456973294,
        "vocab_size-3": 331,
        "unique-3": 326,
        "entropy-3": 8.358756450314887,
        "cond_entropy-3": 0.07551985999056578,
        "total_length-nopunct": 335,
        "mean_pred_length-nopunct": 14.565217391304348,
        "std_pred_length-nopunct": 6.170237730298014,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6507462686567164,
        "vocab_size-1-nopunct": 218,
        "unique-1-nopunct": 185,
        "entropy-1-nopunct": 7.117574254077096,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 288,
        "unique-2-nopunct": 275,
        "entropy-2-nopunct": 8.081719927126192,
        "cond_entropy-2-nopunct": 1.0449796144567454,
        "distinct-3-nopunct": 0.9826989619377162,
        "vocab_size-3-nopunct": 284,
        "unique-3-nopunct": 280,
        "entropy-3-nopunct": 8.137711538894555,
        "cond_entropy-3-nopunct": 0.06874141353279435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1506849315068493,
            "2": 0.3488372093023256,
            "3": 0.7863247863247863
        },
        "nist": 6.116683982935495,
        "rouge1": {
            "precision": 0.73388,
            "recall": 0.72045,
            "fmeasure": 0.71166
        },
        "rouge2": {
            "precision": 0.53395,
            "recall": 0.51161,
            "fmeasure": 0.51165
        },
        "rougeL": {
            "precision": 0.63012,
            "recall": 0.62416,
            "fmeasure": 0.61446
        },
        "rougeLsum": {
            "precision": 0.63012,
            "recall": 0.62416,
            "fmeasure": 0.61446
        },
        "bleu": 46.63322,
        "nubia": {
            "semantic_relation": 4.28626,
            "contradiction": 0.60317,
            "irrelevancy": 23.85568,
            "logical_agreement": 75.54115,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.59501,
            "nubia_score": 0.74521
        },
        "bleurt": 0.33033,
        "meteor": 0.37230255927764894,
        "bertscore": {
            "precision": 0.92782,
            "recall": 0.91604,
            "f1": 0.91977
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.8648648648648649,
        "vocab_size-1": 32,
        "unique-1": 29,
        "entropy-1": 4.898378365512008,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.07668263744972706,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.13326653086346418,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.851409765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.021942633133208995,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5714285714285714,
            "3": 0.75
        },
        "nist": 4.771999673670888,
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.727,
            "fmeasure": 0.78907
        },
        "rouge2": {
            "precision": 0.65783,
            "recall": 0.54526,
            "fmeasure": 0.59274
        },
        "rougeL": {
            "precision": 0.76852,
            "recall": 0.63042,
            "fmeasure": 0.68788
        },
        "rougeLsum": {
            "precision": 0.76852,
            "recall": 0.63042,
            "fmeasure": 0.68788
        },
        "bleu": 45.18574,
        "nubia": {
            "semantic_relation": 4.49882,
            "contradiction": 0.99789,
            "irrelevancy": 1.90899,
            "logical_agreement": 97.09312,
            "grammar_ref": 5.80868,
            "grammar_hyp": 5.70885,
            "nubia_score": 0.81277
        },
        "bleurt": 0.25927,
        "meteor": 0.4092132845192701,
        "bertscore": {
            "precision": 0.93681,
            "recall": 0.9215,
            "f1": 0.92758
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "total_length": 425,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.692099788303083,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.6164705882352941,
        "vocab_size-1": 262,
        "unique-1": 223,
        "entropy-1": 7.321909500616709,
        "distinct-2": 0.93,
        "vocab_size-2": 372,
        "unique-2": 355,
        "entropy-2": 8.472283213567017,
        "cond_entropy-2": 1.0173654038564812,
        "distinct-3": 0.9893333333333333,
        "vocab_size-3": 371,
        "unique-3": 367,
        "entropy-3": 8.529413452049901,
        "cond_entropy-3": 0.06434187022817062,
        "total_length-nopunct": 380,
        "mean_pred_length-nopunct": 15.2,
        "std_pred_length-nopunct": 5.455272678794342,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6763157894736842,
        "vocab_size-1-nopunct": 257,
        "unique-1-nopunct": 223,
        "entropy-1-nopunct": 7.441574158337023,
        "distinct-2-nopunct": 0.9352112676056338,
        "vocab_size-2-nopunct": 332,
        "unique-2-nopunct": 320,
        "entropy-2-nopunct": 8.306522565143945,
        "cond_entropy-2-nopunct": 0.9387710441304027,
        "distinct-3-nopunct": 0.990909090909091,
        "vocab_size-3-nopunct": 327,
        "unique-3-nopunct": 325,
        "entropy-3-nopunct": 8.345852858178702,
        "cond_entropy-3-nopunct": 0.05184185737173291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17857142857142858,
            "2": 0.37209302325581395,
            "3": 0.8538961038961039
        },
        "nist": 6.891626672159807,
        "rouge1": {
            "precision": 0.81118,
            "recall": 0.80277,
            "fmeasure": 0.80027
        },
        "rouge2": {
            "precision": 0.63447,
            "recall": 0.64286,
            "fmeasure": 0.63507
        },
        "rougeL": {
            "precision": 0.73179,
            "recall": 0.72231,
            "fmeasure": 0.72137
        },
        "rougeLsum": {
            "precision": 0.73179,
            "recall": 0.72231,
            "fmeasure": 0.72137
        },
        "bleu": 58.80857,
        "nubia": {
            "semantic_relation": 4.24814,
            "contradiction": 10.12731,
            "irrelevancy": 21.23252,
            "logical_agreement": 68.64017,
            "grammar_ref": 4.85173,
            "grammar_hyp": 5.0625,
            "nubia_score": 0.71796
        },
        "bleurt": 0.39806,
        "meteor": 0.4505663864663054,
        "bertscore": {
            "precision": 0.94821,
            "recall": 0.94419,
            "f1": 0.94545
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 81,
        "mean_pred_length": 16.2,
        "std_pred_length": 5.775811631277461,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7530864197530864,
        "vocab_size-1": 61,
        "unique-1": 53,
        "entropy-1": 5.674218558922968,
        "distinct-2": 0.9736842105263158,
        "vocab_size-2": 74,
        "unique-2": 73,
        "entropy-2": 6.185363204204598,
        "cond_entropy-2": 0.44967302975277906,
        "distinct-3": 1.0,
        "vocab_size-3": 71,
        "unique-3": 71,
        "entropy-3": 6.149747119504677,
        "cond_entropy-3": -0.03121014742955899,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 3.1999999999999997,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8382352941176471,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.621999834567943,
        "distinct-2-nopunct": 0.9682539682539683,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.901805518703675,
        "cond_entropy-2-nopunct": 0.31674719260258893,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.03731810936952599,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.21875,
            "3": 0.675
        },
        "nist": 3.6719982200725303,
        "rouge1": {
            "precision": 0.59456,
            "recall": 0.62653,
            "fmeasure": 0.59527
        },
        "rouge2": {
            "precision": 0.32019,
            "recall": 0.35489,
            "fmeasure": 0.32307
        },
        "rougeL": {
            "precision": 0.44814,
            "recall": 0.48214,
            "fmeasure": 0.44585
        },
        "rougeLsum": {
            "precision": 0.44814,
            "recall": 0.48214,
            "fmeasure": 0.44585
        },
        "bleu": 17.99742,
        "nubia": {
            "semantic_relation": 3.5387,
            "contradiction": 4.19304,
            "irrelevancy": 39.26767,
            "logical_agreement": 56.5393,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.26777,
            "nubia_score": 0.51533
        },
        "bleurt": -0.1175,
        "meteor": 0.3019960042409738,
        "bertscore": {
            "precision": 0.8937,
            "recall": 0.88733,
            "f1": 0.88459
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.775,
        "total_length": 284,
        "mean_pred_length": 17.75,
        "std_pred_length": 5.153882032022076,
        "median_pred_length": 18.5,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6267605633802817,
        "vocab_size-1": 178,
        "unique-1": 148,
        "entropy-1": 6.892066601819166,
        "distinct-2": 0.9291044776119403,
        "vocab_size-2": 249,
        "unique-2": 231,
        "entropy-2": 7.9214814012705626,
        "cond_entropy-2": 0.9439794945048551,
        "distinct-3": 0.9722222222222222,
        "vocab_size-3": 245,
        "unique-3": 238,
        "entropy-3": 7.921724367944372,
        "cond_entropy-3": 0.00942441360628479,
        "total_length-nopunct": 256,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.671875,
        "vocab_size-1-nopunct": 172,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 6.940850910135222,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 224,
        "unique-2-nopunct": 209,
        "entropy-2-nopunct": 7.770411897682879,
        "cond_entropy-2-nopunct": 0.8960042602052671,
        "distinct-3-nopunct": 0.9732142857142857,
        "vocab_size-3-nopunct": 218,
        "unique-3-nopunct": 212,
        "entropy-3-nopunct": 7.753783493486141,
        "cond_entropy-3-nopunct": -0.006879925773398932,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.425,
            "3": 0.8288770053475936
        },
        "nist": 6.090937501830358,
        "rouge1": {
            "precision": 0.74848,
            "recall": 0.77602,
            "fmeasure": 0.74994
        },
        "rouge2": {
            "precision": 0.49899,
            "recall": 0.53015,
            "fmeasure": 0.5055
        },
        "rougeL": {
            "precision": 0.64078,
            "recall": 0.6662,
            "fmeasure": 0.64371
        },
        "rougeLsum": {
            "precision": 0.64078,
            "recall": 0.6662,
            "fmeasure": 0.64371
        },
        "bleu": 43.71736,
        "nubia": {
            "semantic_relation": 4.21534,
            "contradiction": 18.93398,
            "irrelevancy": 34.54329,
            "logical_agreement": 46.52273,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.60399,
            "nubia_score": 0.73457
        },
        "bleurt": 0.2742,
        "meteor": 0.39768356430254276,
        "bertscore": {
            "precision": 0.93182,
            "recall": 0.93806,
            "f1": 0.93298
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 75,
        "msttr-100": 0.71583,
        "msttr-100_nopunct": 0.78273,
        "total_length": 1282,
        "mean_pred_length": 17.093333333333334,
        "std_pred_length": 5.854168505337789,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.4734789391575663,
        "vocab_size-1": 607,
        "unique-1": 463,
        "entropy-1": 7.977634091283423,
        "distinct-2": 0.8458989229494615,
        "vocab_size-2": 1021,
        "unique-2": 926,
        "entropy-2": 9.796834268620074,
        "cond_entropy-2": 1.620331045641664,
        "distinct-3": 0.9399293286219081,
        "vocab_size-3": 1064,
        "unique-3": 1022,
        "entropy-3": 10.002847885046823,
        "cond_entropy-3": 0.2102216680196321,
        "total_length-nopunct": 1114,
        "mean_pred_length-nopunct": 14.853333333333333,
        "std_pred_length-nopunct": 5.027108733876981,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5359066427289049,
        "vocab_size-1-nopunct": 597,
        "unique-1-nopunct": 460,
        "entropy-1-nopunct": 8.20997520492917,
        "distinct-2-nopunct": 0.848893166506256,
        "vocab_size-2-nopunct": 882,
        "unique-2-nopunct": 804,
        "entropy-2-nopunct": 9.577280097331831,
        "cond_entropy-2-nopunct": 1.4649376477699776,
        "distinct-3-nopunct": 0.9408713692946058,
        "vocab_size-3-nopunct": 907,
        "unique-3-nopunct": 873,
        "entropy-3-nopunct": 9.77204448404022,
        "cond_entropy-3-nopunct": 0.21812808029331532,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25660377358490566,
            "2": 0.4675925925925926,
            "3": 0.7885350318471338
        },
        "nist": 7.3823787384106545,
        "rouge1": {
            "precision": 0.75747,
            "recall": 0.73817,
            "fmeasure": 0.7354
        },
        "rouge2": {
            "precision": 0.54486,
            "recall": 0.53564,
            "fmeasure": 0.53015
        },
        "rougeL": {
            "precision": 0.6488,
            "recall": 0.63819,
            "fmeasure": 0.63237
        },
        "rougeLsum": {
            "precision": 0.6488,
            "recall": 0.63819,
            "fmeasure": 0.63237
        },
        "bleu": 47.76624,
        "nubia": {
            "semantic_relation": 4.1583,
            "contradiction": 7.81205,
            "irrelevancy": 32.6608,
            "logical_agreement": 59.52716,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.89516,
            "nubia_score": 0.70799
        },
        "bleurt": 0.22973,
        "meteor": 0.39315034808812704,
        "bertscore": {
            "precision": 0.93039,
            "recall": 0.92726,
            "f1": 0.9268
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 64,
        "mean_pred_length": 12.8,
        "std_pred_length": 5.706137047074843,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.59375,
        "vocab_size-1": 38,
        "unique-1": 26,
        "entropy-1": 4.965018266288633,
        "distinct-2": 0.847457627118644,
        "vocab_size-2": 50,
        "unique-2": 42,
        "entropy-2": 5.5647636001726255,
        "cond_entropy-2": 0.5518624299612317,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 51,
        "unique-3": 48,
        "entropy-3": 5.643776391052356,
        "cond_entropy-3": 0.07140903617502499,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 11.6,
        "std_pred_length-nopunct": 5.782732917920384,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6206896551724138,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.888345978618477,
        "distinct-2-nopunct": 0.8490566037735849,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.411790501692187,
        "cond_entropy-2-nopunct": 0.5551096189435841,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.501629167387827,
        "cond_entropy-3-nopunct": 0.05672876492298094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.6904761904761905
        },
        "nist": 3.3752307575670435,
        "rouge1": {
            "precision": 0.77783,
            "recall": 0.70805,
            "fmeasure": 0.72919
        },
        "rouge2": {
            "precision": 0.5855,
            "recall": 0.54548,
            "fmeasure": 0.55448
        },
        "rougeL": {
            "precision": 0.66279,
            "recall": 0.61174,
            "fmeasure": 0.62638
        },
        "rougeLsum": {
            "precision": 0.66279,
            "recall": 0.61174,
            "fmeasure": 0.62638
        },
        "bleu": 33.18115,
        "nubia": {
            "semantic_relation": 4.38949,
            "contradiction": 0.64205,
            "irrelevancy": 4.87687,
            "logical_agreement": 94.48109,
            "grammar_ref": 3.91039,
            "grammar_hyp": 4.00222,
            "nubia_score": 0.82183
        },
        "bleurt": 0.12764,
        "meteor": 0.3445689957972324,
        "bertscore": {
            "precision": 0.92388,
            "recall": 0.91554,
            "f1": 0.91921
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.75143,
        "msttr-100_nopunct": 0.795,
        "total_length": 707,
        "mean_pred_length": 16.833333333333332,
        "std_pred_length": 4.700135087555446,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5756718528995757,
        "vocab_size-1": 407,
        "unique-1": 336,
        "entropy-1": 7.774433409023923,
        "distinct-2": 0.9308270676691729,
        "vocab_size-2": 619,
        "unique-2": 589,
        "entropy-2": 9.208978495830715,
        "cond_entropy-2": 1.216711317088774,
        "distinct-3": 0.9903691813804173,
        "vocab_size-3": 617,
        "unique-3": 611,
        "entropy-3": 9.263826715784736,
        "cond_entropy-3": 0.048533204627307536,
        "total_length-nopunct": 625,
        "mean_pred_length-nopunct": 14.880952380952381,
        "std_pred_length-nopunct": 4.1929781491962475,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6416,
        "vocab_size-1-nopunct": 401,
        "unique-1-nopunct": 335,
        "entropy-1-nopunct": 7.963130139195953,
        "distinct-2-nopunct": 0.934819897084048,
        "vocab_size-2-nopunct": 545,
        "unique-2-nopunct": 521,
        "entropy-2-nopunct": 9.02633268558324,
        "cond_entropy-2-nopunct": 1.1370404393444504,
        "distinct-3-nopunct": 0.988909426987061,
        "vocab_size-3-nopunct": 535,
        "unique-3-nopunct": 530,
        "entropy-3-nopunct": 9.055908281974403,
        "cond_entropy-3-nopunct": 0.03283403313789661,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1565217391304348,
            "2": 0.5591397849462365,
            "3": 0.7830578512396694
        },
        "nist": 6.81423183327087,
        "rouge1": {
            "precision": 0.77891,
            "recall": 0.7815,
            "fmeasure": 0.76979
        },
        "rouge2": {
            "precision": 0.58083,
            "recall": 0.57485,
            "fmeasure": 0.57077
        },
        "rougeL": {
            "precision": 0.67054,
            "recall": 0.66212,
            "fmeasure": 0.65704
        },
        "rougeLsum": {
            "precision": 0.67054,
            "recall": 0.66212,
            "fmeasure": 0.65704
        },
        "bleu": 48.96187,
        "nubia": {
            "semantic_relation": 4.37039,
            "contradiction": 8.15398,
            "irrelevancy": 22.88617,
            "logical_agreement": 68.95985,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.55771,
            "nubia_score": 0.7705
        },
        "bleurt": 0.36988,
        "meteor": 0.4179835724432544,
        "bertscore": {
            "precision": 0.93429,
            "recall": 0.93815,
            "f1": 0.9355
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.81,
        "total_length": 187,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.78399044384977,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6737967914438503,
        "vocab_size-1": 126,
        "unique-1": 107,
        "entropy-1": 6.511437031637932,
        "distinct-2": 0.9659090909090909,
        "vocab_size-2": 170,
        "unique-2": 165,
        "entropy-2": 7.386960666920469,
        "cond_entropy-2": 0.7633369713223482,
        "distinct-3": 0.9939393939393939,
        "vocab_size-3": 164,
        "unique-3": 163,
        "entropy-3": 7.354201002124596,
        "cond_entropy-3": -0.02792826801473308,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 14.272727272727273,
        "std_pred_length-nopunct": 4.919181548534066,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7707006369426752,
        "vocab_size-1-nopunct": 121,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.627307653538068,
        "distinct-2-nopunct": 0.9726027397260274,
        "vocab_size-2-nopunct": 142,
        "unique-2-nopunct": 139,
        "entropy-2-nopunct": 7.1298595759884895,
        "cond_entropy-2-nopunct": 0.5528289364839027,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 135,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 7.076815597050856,
        "cond_entropy-3-nopunct": -0.04815794329464207,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.10810810810810811,
            "2": 0.625,
            "3": 0.6134453781512605
        },
        "nist": 4.4002802972415065,
        "rouge1": {
            "precision": 0.71446,
            "recall": 0.64085,
            "fmeasure": 0.65606
        },
        "rouge2": {
            "precision": 0.44032,
            "recall": 0.3927,
            "fmeasure": 0.40451
        },
        "rougeL": {
            "precision": 0.56535,
            "recall": 0.4914,
            "fmeasure": 0.5105
        },
        "rougeLsum": {
            "precision": 0.56535,
            "recall": 0.4914,
            "fmeasure": 0.5105
        },
        "bleu": 30.81632,
        "nubia": {
            "semantic_relation": 3.48365,
            "contradiction": 14.86141,
            "irrelevancy": 27.20765,
            "logical_agreement": 57.93094,
            "grammar_ref": 4.70623,
            "grammar_hyp": 5.18246,
            "nubia_score": 0.52108
        },
        "bleurt": 0.01151,
        "meteor": 0.2948505631718133,
        "bertscore": {
            "precision": 0.90833,
            "recall": 0.89385,
            "f1": 0.89814
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.8660254037844386,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 15,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 39,
        "unique-1": 31,
        "entropy-1": 5.0674909192234,
        "distinct-2": 1.0,
        "vocab_size-2": 50,
        "unique-2": 50,
        "entropy-2": 5.643856189774728,
        "cond_entropy-2": 0.47135699718653123,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.7071067811865476,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.019974678246913,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.4908194697062263,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.13750352374993507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.5714285714285714,
            "3": 0.6756756756756757
        },
        "nist": 4.082040594949998,
        "rouge1": {
            "precision": 0.73344,
            "recall": 0.74605,
            "fmeasure": 0.73487
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.46353,
            "fmeasure": 0.45578
        },
        "rougeL": {
            "precision": 0.61325,
            "recall": 0.62693,
            "fmeasure": 0.61614
        },
        "rougeLsum": {
            "precision": 0.61325,
            "recall": 0.62693,
            "fmeasure": 0.61614
        },
        "bleu": 33.88817,
        "nubia": {
            "semantic_relation": 3.68784,
            "contradiction": 25.56256,
            "irrelevancy": 32.98803,
            "logical_agreement": 41.44942,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.53165,
            "nubia_score": 0.60195
        },
        "bleurt": 0.2744,
        "meteor": 0.3713022589953709,
        "bertscore": {
            "precision": 0.94095,
            "recall": 0.92454,
            "f1": 0.92776
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.775,
        "total_length": 239,
        "mean_pred_length": 19.916666666666668,
        "std_pred_length": 4.590902840279774,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.6234309623430963,
        "vocab_size-1": 149,
        "unique-1": 121,
        "entropy-1": 6.637108332321528,
        "distinct-2": 0.947136563876652,
        "vocab_size-2": 215,
        "unique-2": 207,
        "entropy-2": 7.696549478461263,
        "cond_entropy-2": 1.0005679157209706,
        "distinct-3": 0.9953488372093023,
        "vocab_size-3": 214,
        "unique-3": 213,
        "entropy-3": 7.738890524008039,
        "cond_entropy-3": 0.040294478597740414,
        "total_length-nopunct": 209,
        "mean_pred_length-nopunct": 17.416666666666668,
        "std_pred_length-nopunct": 4.821105221373576,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.69377990430622,
        "vocab_size-1-nopunct": 145,
        "unique-1-nopunct": 121,
        "entropy-1-nopunct": 6.691876252101491,
        "distinct-2-nopunct": 0.949238578680203,
        "vocab_size-2-nopunct": 187,
        "unique-2-nopunct": 181,
        "entropy-2-nopunct": 7.492560575779551,
        "cond_entropy-2-nopunct": 0.8574650067225424,
        "distinct-3-nopunct": 0.9945945945945946,
        "vocab_size-3-nopunct": 184,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.52057064970549,
        "cond_entropy-3-nopunct": 0.0364095059481893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14,
            "2": 0.23076923076923078,
            "3": 0.7294117647058823
        },
        "nist": 5.150424497640477,
        "rouge1": {
            "precision": 0.73787,
            "recall": 0.71015,
            "fmeasure": 0.71667
        },
        "rouge2": {
            "precision": 0.47363,
            "recall": 0.46464,
            "fmeasure": 0.4644
        },
        "rougeL": {
            "precision": 0.60659,
            "recall": 0.60051,
            "fmeasure": 0.59834
        },
        "rougeLsum": {
            "precision": 0.60659,
            "recall": 0.60051,
            "fmeasure": 0.59834
        },
        "bleu": 31.9994,
        "nubia": {
            "semantic_relation": 4.2041,
            "contradiction": 7.30566,
            "irrelevancy": 30.78075,
            "logical_agreement": 61.91358,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.41326,
            "nubia_score": 0.74645
        },
        "bleurt": 0.16529,
        "meteor": 0.3312040757604919,
        "bertscore": {
            "precision": 0.91811,
            "recall": 0.91139,
            "f1": 0.91366
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 18.25,
        "std_pred_length": 4.710360920354193,
        "median_pred_length": 16.5,
        "min_pred_length": 14,
        "max_pred_length": 26,
        "distinct-1": 0.7945205479452054,
        "vocab_size-1": 58,
        "unique-1": 48,
        "entropy-1": 5.713730209535319,
        "distinct-2": 1.0,
        "vocab_size-2": 69,
        "unique-2": 69,
        "entropy-2": 6.108524456778164,
        "cond_entropy-2": 0.3064518906831295,
        "distinct-3": 1.0,
        "vocab_size-3": 65,
        "unique-3": 65,
        "entropy-3": 6.022367813028458,
        "cond_entropy-3": -0.08615664374971463,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 4.153311931459037,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.639017035992346,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.954196310386873,
        "cond_entropy-2-nopunct": 0.3413326346117035,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.09621531525930284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "nist": 4.940423058615195,
        "rouge1": {
            "precision": 0.75055,
            "recall": 0.87673,
            "fmeasure": 0.80679
        },
        "rouge2": {
            "precision": 0.59406,
            "recall": 0.6764,
            "fmeasure": 0.62801
        },
        "rougeL": {
            "precision": 0.70277,
            "recall": 0.81237,
            "fmeasure": 0.75237
        },
        "rougeLsum": {
            "precision": 0.70277,
            "recall": 0.81237,
            "fmeasure": 0.75237
        },
        "bleu": 47.93281,
        "nubia": {
            "semantic_relation": 4.23792,
            "contradiction": 30.8644,
            "irrelevancy": 15.97911,
            "logical_agreement": 53.15649,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.96653,
            "nubia_score": 0.75467
        },
        "bleurt": 0.27514,
        "meteor": 0.4395890533470699,
        "bertscore": {
            "precision": 0.94592,
            "recall": 0.94683,
            "f1": 0.94383
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.74,
        "total_length": 183,
        "mean_pred_length": 15.25,
        "std_pred_length": 3.8106211217245587,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.6174863387978142,
        "vocab_size-1": 113,
        "unique-1": 92,
        "entropy-1": 6.270805727709123,
        "distinct-2": 0.9181286549707602,
        "vocab_size-2": 157,
        "unique-2": 147,
        "entropy-2": 7.2364516376423005,
        "cond_entropy-2": 0.8187744568448111,
        "distinct-3": 0.9748427672955975,
        "vocab_size-3": 155,
        "unique-3": 152,
        "entropy-3": 7.257820769736129,
        "cond_entropy-3": 0.02248114798644723,
        "total_length-nopunct": 155,
        "mean_pred_length-nopunct": 12.916666666666666,
        "std_pred_length-nopunct": 3.6161289922911886,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6967741935483871,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.327525576390388,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 132,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 6.9901883821875535,
        "cond_entropy-2-nopunct": 0.7142934767524619,
        "distinct-3-nopunct": 0.9770992366412213,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 126,
        "entropy-3-nopunct": 6.981858974803378,
        "cond_entropy-3-nopunct": -0.00041951841401588995,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.17142857142857143,
            "2": 0.3103448275862069,
            "3": 0.7520661157024794
        },
        "nist": 5.311278678052494,
        "rouge1": {
            "precision": 0.76093,
            "recall": 0.70206,
            "fmeasure": 0.7221
        },
        "rouge2": {
            "precision": 0.51134,
            "recall": 0.47169,
            "fmeasure": 0.48482
        },
        "rougeL": {
            "precision": 0.69126,
            "recall": 0.62958,
            "fmeasure": 0.65161
        },
        "rougeLsum": {
            "precision": 0.69126,
            "recall": 0.62958,
            "fmeasure": 0.65161
        },
        "bleu": 38.3224,
        "nubia": {
            "semantic_relation": 4.48024,
            "contradiction": 4.9339,
            "irrelevancy": 11.23151,
            "logical_agreement": 83.83458,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.19762,
            "nubia_score": 0.85191
        },
        "bleurt": 0.47249,
        "meteor": 0.3735109374311142,
        "bertscore": {
            "precision": 0.9416,
            "recall": 0.93217,
            "f1": 0.93501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.775,
        "total_length": 239,
        "mean_pred_length": 17.071428571428573,
        "std_pred_length": 4.431450676927457,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6317991631799164,
        "vocab_size-1": 151,
        "unique-1": 122,
        "entropy-1": 6.72262975955228,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 220,
        "unique-2": 216,
        "entropy-2": 7.765981691207378,
        "cond_entropy-2": 0.9254664590744747,
        "distinct-3": 1.0,
        "vocab_size-3": 211,
        "unique-3": 211,
        "entropy-3": 7.721099188707212,
        "cond_entropy-3": -0.041710971693911206,
        "total_length-nopunct": 210,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.6449573777637356,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 147,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.804647509302215,
        "distinct-2-nopunct": 0.9744897959183674,
        "vocab_size-2-nopunct": 191,
        "unique-2-nopunct": 187,
        "entropy-2-nopunct": 7.559837969104156,
        "cond_entropy-2-nopunct": 0.7886825369226216,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 182,
        "unique-3-nopunct": 182,
        "entropy-3-nopunct": 7.507794640198715,
        "cond_entropy-3-nopunct": -0.05331692093759189,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22950819672131148,
            "2": 0.34285714285714286,
            "3": 0.6918238993710691
        },
        "nist": 5.216314053455017,
        "rouge1": {
            "precision": 0.6696,
            "recall": 0.66728,
            "fmeasure": 0.65542
        },
        "rouge2": {
            "precision": 0.4253,
            "recall": 0.40389,
            "fmeasure": 0.40935
        },
        "rougeL": {
            "precision": 0.56926,
            "recall": 0.56707,
            "fmeasure": 0.55615
        },
        "rougeLsum": {
            "precision": 0.56926,
            "recall": 0.56707,
            "fmeasure": 0.55615
        },
        "bleu": 34.71787,
        "nubia": {
            "semantic_relation": 4.13459,
            "contradiction": 15.73653,
            "irrelevancy": 39.90894,
            "logical_agreement": 44.35453,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.37838,
            "nubia_score": 0.71994
        },
        "bleurt": 0.23127,
        "meteor": 0.3432740444164006,
        "bertscore": {
            "precision": 0.91585,
            "recall": 0.91034,
            "f1": 0.91079
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 4.988876515698588,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.8043478260869565,
        "vocab_size-1": 37,
        "unique-1": 30,
        "entropy-1": 5.099436412484686,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.3099068685131532,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.1043366598147359,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 4.988876515698588,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.813953488372093,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.019060684834029,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.33340771529343743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.7272727272727273
        },
        "nist": 2.8471632533271025,
        "rouge1": {
            "precision": 0.55026,
            "recall": 0.70048,
            "fmeasure": 0.59742
        },
        "rouge2": {
            "precision": 0.36111,
            "recall": 0.37222,
            "fmeasure": 0.36543
        },
        "rougeL": {
            "precision": 0.51323,
            "recall": 0.679,
            "fmeasure": 0.56649
        },
        "rougeLsum": {
            "precision": 0.51323,
            "recall": 0.679,
            "fmeasure": 0.56649
        },
        "bleu": 35.84279,
        "nubia": {
            "semantic_relation": 3.78228,
            "contradiction": 0.31699,
            "irrelevancy": 65.63117,
            "logical_agreement": 34.05183,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.79817,
            "nubia_score": 0.64001
        },
        "bleurt": 0.08205,
        "meteor": 0.33215211116832016,
        "bertscore": {
            "precision": 0.85061,
            "recall": 0.88415,
            "f1": 0.86677
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.71,
        "total_length": 236,
        "mean_pred_length": 16.857142857142858,
        "std_pred_length": 4.549052379454474,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.5423728813559322,
        "vocab_size-1": 128,
        "unique-1": 98,
        "entropy-1": 6.314391710994074,
        "distinct-2": 0.8468468468468469,
        "vocab_size-2": 188,
        "unique-2": 163,
        "entropy-2": 7.440041837237227,
        "cond_entropy-2": 1.030767102497631,
        "distinct-3": 0.9086538461538461,
        "vocab_size-3": 189,
        "unique-3": 171,
        "entropy-3": 7.514118143611441,
        "cond_entropy-3": 0.07869763525682116,
        "total_length-nopunct": 202,
        "mean_pred_length-nopunct": 14.428571428571429,
        "std_pred_length-nopunct": 4.152697672499609,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6138613861386139,
        "vocab_size-1-nopunct": 124,
        "unique-1-nopunct": 98,
        "entropy-1-nopunct": 6.354265040304125,
        "distinct-2-nopunct": 0.8457446808510638,
        "vocab_size-2-nopunct": 159,
        "unique-2-nopunct": 138,
        "entropy-2-nopunct": 7.193332750821836,
        "cond_entropy-2-nopunct": 0.9255318072956916,
        "distinct-3-nopunct": 0.9080459770114943,
        "vocab_size-3-nopunct": 158,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.254697015951217,
        "cond_entropy-3-nopunct": 0.07893659508333305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.3333333333333333,
            "3": 0.6941176470588235
        },
        "nist": 5.662431778144219,
        "rouge1": {
            "precision": 0.7401,
            "recall": 0.69482,
            "fmeasure": 0.71009
        },
        "rouge2": {
            "precision": 0.51101,
            "recall": 0.48161,
            "fmeasure": 0.49177
        },
        "rougeL": {
            "precision": 0.65297,
            "recall": 0.60857,
            "fmeasure": 0.62522
        },
        "rougeLsum": {
            "precision": 0.65297,
            "recall": 0.60857,
            "fmeasure": 0.62522
        },
        "bleu": 45.57338,
        "nubia": {
            "semantic_relation": 4.35415,
            "contradiction": 13.31796,
            "irrelevancy": 9.46199,
            "logical_agreement": 77.22005,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.80303,
            "nubia_score": 0.76973
        },
        "bleurt": 0.37046,
        "meteor": 0.36960115499262935,
        "bertscore": {
            "precision": 0.93756,
            "recall": 0.92916,
            "f1": 0.93213
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 1.0,
        "median_pred_length": 17.0,
        "min_pred_length": 16,
        "max_pred_length": 18,
        "distinct-1": 0.7352941176470589,
        "vocab_size-1": 25,
        "unique-1": 19,
        "entropy-1": 4.477024973539648,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.4986273931922691,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.413909765557392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.5320535123473009,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.7777777777777778
        },
        "nist": 3.4537643084697067,
        "rouge1": {
            "precision": 0.81176,
            "recall": 0.63931,
            "fmeasure": 0.70939
        },
        "rouge2": {
            "precision": 0.56696,
            "recall": 0.43899,
            "fmeasure": 0.49027
        },
        "rougeL": {
            "precision": 0.59804,
            "recall": 0.47418,
            "fmeasure": 0.52309
        },
        "rougeLsum": {
            "precision": 0.59804,
            "recall": 0.47418,
            "fmeasure": 0.52309
        },
        "bleu": 32.20595,
        "nubia": {
            "semantic_relation": 4.29941,
            "contradiction": 1.01192,
            "irrelevancy": 18.18692,
            "logical_agreement": 80.80116,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.37717,
            "nubia_score": 0.85089
        },
        "bleurt": 0.20922,
        "meteor": 0.3158939317849258,
        "bertscore": {
            "precision": 0.94649,
            "recall": 0.91951,
            "f1": 0.93175
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 13.2,
        "std_pred_length": 5.192301994298868,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 54,
        "unique-1": 47,
        "entropy-1": 5.603190854528706,
        "distinct-2": 1.0,
        "vocab_size-2": 61,
        "unique-2": 61,
        "entropy-2": 5.930737337562883,
        "cond_entropy-2": 0.17338871007864465,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.1233824155052819,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 11.2,
        "std_pred_length-nopunct": 4.166533331199932,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8928571428571429,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.57958907380469,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.11516625328964555,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": -0.14886338591448275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.673469387755102
        },
        "nist": 5.058240553687487,
        "rouge1": {
            "precision": 0.74979,
            "recall": 0.69407,
            "fmeasure": 0.71711
        },
        "rouge2": {
            "precision": 0.52193,
            "recall": 0.5065,
            "fmeasure": 0.51173
        },
        "rougeL": {
            "precision": 0.67233,
            "recall": 0.65751,
            "fmeasure": 0.66237
        },
        "rougeLsum": {
            "precision": 0.67233,
            "recall": 0.65751,
            "fmeasure": 0.66237
        },
        "bleu": 45.43288,
        "nubia": {
            "semantic_relation": 4.06418,
            "contradiction": 38.01796,
            "irrelevancy": 19.21808,
            "logical_agreement": 42.76396,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.52413,
            "nubia_score": 0.64333
        },
        "bleurt": 0.40779,
        "meteor": 0.38932022364083696,
        "bertscore": {
            "precision": 0.94434,
            "recall": 0.93822,
            "f1": 0.9381
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 63,
        "mean_pred_length": 15.75,
        "std_pred_length": 2.680951323690902,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.6984126984126984,
        "vocab_size-1": 44,
        "unique-1": 34,
        "entropy-1": 5.250701550312343,
        "distinct-2": 0.8983050847457628,
        "vocab_size-2": 53,
        "unique-2": 49,
        "entropy-2": 5.653663812000364,
        "cond_entropy-2": 0.31662859207362654,
        "distinct-3": 0.9636363636363636,
        "vocab_size-3": 53,
        "unique-3": 52,
        "entropy-3": 5.694907213485321,
        "cond_entropy-3": -0.02855606310990893,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 2.384848003542364,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7636363636363637,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.24000630423707,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5399765674192745,
        "cond_entropy-2-nopunct": 0.24919626582900095,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.07528329880449633,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.7413793103448276
        },
        "nist": 4.111326313817052,
        "rouge1": {
            "precision": 0.86722,
            "recall": 0.74745,
            "fmeasure": 0.78756
        },
        "rouge2": {
            "precision": 0.62877,
            "recall": 0.57585,
            "fmeasure": 0.5907
        },
        "rougeL": {
            "precision": 0.78889,
            "recall": 0.6833,
            "fmeasure": 0.71868
        },
        "rougeLsum": {
            "precision": 0.78889,
            "recall": 0.6833,
            "fmeasure": 0.71868
        },
        "bleu": 35.34969,
        "nubia": {
            "semantic_relation": 4.50733,
            "contradiction": 1.00808,
            "irrelevancy": 26.01261,
            "logical_agreement": 72.97931,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.65019,
            "nubia_score": 0.80242
        },
        "bleurt": 0.23479,
        "meteor": 0.3771865242805892,
        "bertscore": {
            "precision": 0.94125,
            "recall": 0.92151,
            "f1": 0.92912
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.73333,
        "total_length": 383,
        "mean_pred_length": 16.652173913043477,
        "std_pred_length": 4.751280794390661,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5509138381201044,
        "vocab_size-1": 211,
        "unique-1": 168,
        "entropy-1": 6.965056421288273,
        "distinct-2": 0.8833333333333333,
        "vocab_size-2": 318,
        "unique-2": 291,
        "entropy-2": 8.209146325466275,
        "cond_entropy-2": 1.0872100477981532,
        "distinct-3": 0.9643916913946587,
        "vocab_size-3": 325,
        "unique-3": 315,
        "entropy-3": 8.320908119447934,
        "cond_entropy-3": 0.10283740444317362,
        "total_length-nopunct": 333,
        "mean_pred_length-nopunct": 14.478260869565217,
        "std_pred_length-nopunct": 4.312464898079109,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6186186186186187,
        "vocab_size-1-nopunct": 206,
        "unique-1-nopunct": 168,
        "entropy-1-nopunct": 7.083112790599977,
        "distinct-2-nopunct": 0.8903225806451613,
        "vocab_size-2-nopunct": 276,
        "unique-2-nopunct": 255,
        "entropy-2-nopunct": 8.004302913317785,
        "cond_entropy-2-nopunct": 0.9684294235481722,
        "distinct-3-nopunct": 0.9686411149825784,
        "vocab_size-3-nopunct": 278,
        "unique-3-nopunct": 270,
        "entropy-3-nopunct": 8.099558886598427,
        "cond_entropy-3-nopunct": 0.08916501270572519,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.5573770491803278,
            "3": 0.7457627118644068
        },
        "nist": 6.07974692802114,
        "rouge1": {
            "precision": 0.74998,
            "recall": 0.75145,
            "fmeasure": 0.74393
        },
        "rouge2": {
            "precision": 0.55859,
            "recall": 0.56556,
            "fmeasure": 0.55675
        },
        "rougeL": {
            "precision": 0.67124,
            "recall": 0.67142,
            "fmeasure": 0.66603
        },
        "rougeLsum": {
            "precision": 0.67124,
            "recall": 0.67142,
            "fmeasure": 0.66603
        },
        "bleu": 48.38267,
        "nubia": {
            "semantic_relation": 4.20609,
            "contradiction": 11.54325,
            "irrelevancy": 27.32629,
            "logical_agreement": 61.13046,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.18165,
            "nubia_score": 0.74223
        },
        "bleurt": 0.25174,
        "meteor": 0.4095644506465266,
        "bertscore": {
            "precision": 0.92298,
            "recall": 0.92103,
            "f1": 0.92014
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.755,
        "total_length": 464,
        "mean_pred_length": 18.56,
        "std_pred_length": 5.872512239237991,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.5818965517241379,
        "vocab_size-1": 270,
        "unique-1": 219,
        "entropy-1": 7.2988693478897275,
        "distinct-2": 0.9362186788154897,
        "vocab_size-2": 411,
        "unique-2": 390,
        "entropy-2": 8.632805062312475,
        "cond_entropy-2": 1.2133069670062921,
        "distinct-3": 0.9879227053140096,
        "vocab_size-3": 409,
        "unique-3": 404,
        "entropy-3": 8.669332368127371,
        "cond_entropy-3": 0.042884314705071466,
        "total_length-nopunct": 411,
        "mean_pred_length-nopunct": 16.44,
        "std_pred_length-nopunct": 5.052365782482499,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6423357664233577,
        "vocab_size-1-nopunct": 264,
        "unique-1-nopunct": 219,
        "entropy-1-nopunct": 7.389252243808812,
        "distinct-2-nopunct": 0.9378238341968912,
        "vocab_size-2-nopunct": 362,
        "unique-2-nopunct": 345,
        "entropy-2-nopunct": 8.44796367584107,
        "cond_entropy-2-nopunct": 1.1293230788083433,
        "distinct-3-nopunct": 0.9889196675900277,
        "vocab_size-3-nopunct": 357,
        "unique-3-nopunct": 353,
        "entropy-3-nopunct": 8.473694362067253,
        "cond_entropy-3-nopunct": 0.03296706859642402,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2826086956521739,
            "2": 0.5,
            "3": 0.7813620071684588
        },
        "nist": 6.344675671344707,
        "rouge1": {
            "precision": 0.74163,
            "recall": 0.78184,
            "fmeasure": 0.74821
        },
        "rouge2": {
            "precision": 0.53004,
            "recall": 0.55974,
            "fmeasure": 0.53526
        },
        "rougeL": {
            "precision": 0.62117,
            "recall": 0.65692,
            "fmeasure": 0.62984
        },
        "rougeLsum": {
            "precision": 0.62117,
            "recall": 0.65692,
            "fmeasure": 0.62984
        },
        "bleu": 43.82325,
        "nubia": {
            "semantic_relation": 4.14877,
            "contradiction": 12.42578,
            "irrelevancy": 28.16696,
            "logical_agreement": 59.40725,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.57083,
            "nubia_score": 0.71637
        },
        "bleurt": 0.24776,
        "meteor": 0.40834200327448006,
        "bertscore": {
            "precision": 0.92529,
            "recall": 0.93089,
            "f1": 0.92501
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 46,
        "msttr-100": 0.72857,
        "msttr-100_nopunct": 0.77,
        "total_length": 754,
        "mean_pred_length": 16.391304347826086,
        "std_pred_length": 5.534391529610512,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.5384615384615384,
        "vocab_size-1": 406,
        "unique-1": 329,
        "entropy-1": 7.665241573628945,
        "distinct-2": 0.9180790960451978,
        "vocab_size-2": 650,
        "unique-2": 611,
        "entropy-2": 9.265524620967803,
        "cond_entropy-2": 1.42423943112589,
        "distinct-3": 0.9848942598187311,
        "vocab_size-3": 652,
        "unique-3": 642,
        "entropy-3": 9.340475926444725,
        "cond_entropy-3": 0.07123655507996236,
        "total_length-nopunct": 668,
        "mean_pred_length-nopunct": 14.521739130434783,
        "std_pred_length-nopunct": 5.273968600732497,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5988023952095808,
        "vocab_size-1-nopunct": 400,
        "unique-1-nopunct": 327,
        "entropy-1-nopunct": 7.851428248336059,
        "distinct-2-nopunct": 0.9228295819935691,
        "vocab_size-2-nopunct": 574,
        "unique-2-nopunct": 542,
        "entropy-2-nopunct": 9.086544668350605,
        "cond_entropy-2-nopunct": 1.3118524498025472,
        "distinct-3-nopunct": 0.9895833333333334,
        "vocab_size-3-nopunct": 570,
        "unique-3-nopunct": 564,
        "entropy-3-nopunct": 9.149091668109042,
        "cond_entropy-3-nopunct": 0.06416922316444104,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.3357664233576642,
            "3": 0.7154150197628458
        },
        "nist": 6.176119279500915,
        "rouge1": {
            "precision": 0.73944,
            "recall": 0.71842,
            "fmeasure": 0.71545
        },
        "rouge2": {
            "precision": 0.49311,
            "recall": 0.47656,
            "fmeasure": 0.4773
        },
        "rougeL": {
            "precision": 0.63494,
            "recall": 0.61996,
            "fmeasure": 0.61713
        },
        "rougeLsum": {
            "precision": 0.63494,
            "recall": 0.61996,
            "fmeasure": 0.61713
        },
        "bleu": 38.97553,
        "nubia": {
            "semantic_relation": 4.19025,
            "contradiction": 11.63478,
            "irrelevancy": 27.56165,
            "logical_agreement": 60.80356,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.69543,
            "nubia_score": 0.709
        },
        "bleurt": 0.29927,
        "meteor": 0.3491684012915901,
        "bertscore": {
            "precision": 0.92059,
            "recall": 0.91839,
            "f1": 0.91801
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "nist": 1.7545968262860026,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "bleu": 13.8881,
        "nubia": {
            "semantic_relation": 3.59863,
            "contradiction": 0.55741,
            "irrelevancy": 1.188,
            "logical_agreement": 98.2546,
            "grammar_ref": 6.80479,
            "grammar_hyp": 6.28873,
            "nubia_score": 0.68776
        },
        "bleurt": -0.34169,
        "meteor": 0.309443795471007,
        "bertscore": {
            "precision": 0.8664,
            "recall": 0.88125,
            "f1": 0.87376
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8461538461538461
        },
        "nist": 2.7512363631171266,
        "rouge1": {
            "precision": 0.73684,
            "recall": 0.76413,
            "fmeasure": 0.75012
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.51961,
            "fmeasure": 0.50952
        },
        "rougeL": {
            "precision": 0.63158,
            "recall": 0.65497,
            "fmeasure": 0.64296
        },
        "rougeLsum": {
            "precision": 0.63158,
            "recall": 0.65497,
            "fmeasure": 0.64296
        },
        "bleu": 30.75262,
        "nubia": {
            "semantic_relation": 4.95077,
            "contradiction": 0.25334,
            "irrelevancy": 21.40638,
            "logical_agreement": 78.34029,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.76105,
            "nubia_score": 0.92064
        },
        "bleurt": 0.65508,
        "meteor": 0.4631899630193106,
        "bertscore": {
            "precision": 0.93631,
            "recall": 0.94053,
            "f1": 0.93807
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.775,
        "total_length": 290,
        "mean_pred_length": 17.058823529411764,
        "std_pred_length": 5.672125737377729,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.5793103448275863,
        "vocab_size-1": 168,
        "unique-1": 135,
        "entropy-1": 6.644590617050036,
        "distinct-2": 0.8791208791208791,
        "vocab_size-2": 240,
        "unique-2": 216,
        "entropy-2": 7.815798750903564,
        "cond_entropy-2": 1.0521497276494491,
        "distinct-3": 0.94140625,
        "vocab_size-3": 241,
        "unique-3": 228,
        "entropy-3": 7.875,
        "cond_entropy-3": 0.07759301718341581,
        "total_length-nopunct": 247,
        "mean_pred_length-nopunct": 14.529411764705882,
        "std_pred_length-nopunct": 4.7044115348546365,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6639676113360324,
        "vocab_size-1-nopunct": 164,
        "unique-1-nopunct": 135,
        "entropy-1-nopunct": 6.780913518018471,
        "distinct-2-nopunct": 0.8956521739130435,
        "vocab_size-2-nopunct": 206,
        "unique-2-nopunct": 189,
        "entropy-2-nopunct": 7.603709005403335,
        "cond_entropy-2-nopunct": 0.90038989230066,
        "distinct-3-nopunct": 0.9577464788732394,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 195,
        "entropy-3-nopunct": 7.650202577972356,
        "cond_entropy-3-nopunct": 0.06109581564032135,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16923076923076924,
            "2": 0.631578947368421,
            "3": 0.8197674418604651
        },
        "nist": 6.472876200171146,
        "rouge1": {
            "precision": 0.80357,
            "recall": 0.78632,
            "fmeasure": 0.78493
        },
        "rouge2": {
            "precision": 0.56512,
            "recall": 0.5641,
            "fmeasure": 0.55841
        },
        "rougeL": {
            "precision": 0.64749,
            "recall": 0.63966,
            "fmeasure": 0.63629
        },
        "rougeLsum": {
            "precision": 0.64749,
            "recall": 0.63966,
            "fmeasure": 0.63629
        },
        "bleu": 46.64572,
        "nubia": {
            "semantic_relation": 4.30035,
            "contradiction": 11.01299,
            "irrelevancy": 19.49368,
            "logical_agreement": 69.49333,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.9891,
            "nubia_score": 0.72602
        },
        "bleurt": 0.25549,
        "meteor": 0.41358616143313276,
        "bertscore": {
            "precision": 0.94738,
            "recall": 0.94566,
            "f1": 0.94584
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966054,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.17355726227518528,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6
        },
        "nist": 1.7503473569799732,
        "rouge1": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.48148,
            "fmeasure": 0.37778
        },
        "rougeL": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "rougeLsum": {
            "precision": 0.47917,
            "recall": 0.71818,
            "fmeasure": 0.57455
        },
        "bleu": 18.29565,
        "nubia": {
            "semantic_relation": 3.99409,
            "contradiction": 0.26568,
            "irrelevancy": 22.76223,
            "logical_agreement": 76.97209,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.24002,
            "nubia_score": 0.64181
        },
        "bleurt": 0.12284,
        "meteor": 0.35356235305705724,
        "bertscore": {
            "precision": 0.87103,
            "recall": 0.90546,
            "f1": 0.88791
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.755,
        "total_length": 285,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 5.3877432917482055,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6175438596491228,
        "vocab_size-1": 176,
        "unique-1": 144,
        "entropy-1": 6.868756276241367,
        "distinct-2": 0.951310861423221,
        "vocab_size-2": 254,
        "unique-2": 244,
        "entropy-2": 7.952999723814247,
        "cond_entropy-2": 0.9477106912301008,
        "distinct-3": 0.9879518072289156,
        "vocab_size-3": 246,
        "unique-3": 243,
        "entropy-3": 7.935905546525914,
        "cond_entropy-3": -0.009308909249338358,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 13.944444444444445,
        "std_pred_length-nopunct": 4.766459461955922,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6852589641434262,
        "vocab_size-1-nopunct": 172,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 6.9601072367717824,
        "distinct-2-nopunct": 0.944206008583691,
        "vocab_size-2-nopunct": 220,
        "unique-2-nopunct": 210,
        "entropy-2-nopunct": 7.740774610310267,
        "cond_entropy-2-nopunct": 0.8459285482561336,
        "distinct-3-nopunct": 0.986046511627907,
        "vocab_size-3-nopunct": 212,
        "unique-3-nopunct": 209,
        "entropy-3-nopunct": 7.720285872845251,
        "cond_entropy-3-nopunct": -0.010156609008245618,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.32,
            "3": 0.6515151515151515
        },
        "nist": 5.210877676179178,
        "rouge1": {
            "precision": 0.70767,
            "recall": 0.65518,
            "fmeasure": 0.66697
        },
        "rouge2": {
            "precision": 0.48585,
            "recall": 0.45697,
            "fmeasure": 0.46018
        },
        "rougeL": {
            "precision": 0.59831,
            "recall": 0.58089,
            "fmeasure": 0.57388
        },
        "rougeLsum": {
            "precision": 0.59831,
            "recall": 0.58089,
            "fmeasure": 0.57388
        },
        "bleu": 36.04124,
        "nubia": {
            "semantic_relation": 3.91123,
            "contradiction": 21.91486,
            "irrelevancy": 16.58241,
            "logical_agreement": 61.50273,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.59125,
            "nubia_score": 0.62107
        },
        "bleurt": 0.09385,
        "meteor": 0.3512954768010852,
        "bertscore": {
            "precision": 0.91137,
            "recall": 0.90024,
            "f1": 0.90302
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.74,
        "total_length": 317,
        "mean_pred_length": 18.647058823529413,
        "std_pred_length": 5.290848663945614,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.555205047318612,
        "vocab_size-1": 176,
        "unique-1": 130,
        "entropy-1": 6.847760896929616,
        "distinct-2": 0.8866666666666667,
        "vocab_size-2": 266,
        "unique-2": 239,
        "entropy-2": 7.980054722218966,
        "cond_entropy-2": 1.0373833564751915,
        "distinct-3": 0.9540636042402827,
        "vocab_size-3": 270,
        "unique-3": 258,
        "entropy-3": 8.050118004308313,
        "cond_entropy-3": 0.08500670067850007,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 16.352941176470587,
        "std_pred_length-nopunct": 4.405092994552719,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6151079136690647,
        "vocab_size-1-nopunct": 171,
        "unique-1-nopunct": 129,
        "entropy-1-nopunct": 6.9329687730159035,
        "distinct-2-nopunct": 0.8812260536398467,
        "vocab_size-2-nopunct": 230,
        "unique-2-nopunct": 205,
        "entropy-2-nopunct": 7.767851195876648,
        "cond_entropy-2-nopunct": 0.8945627546396997,
        "distinct-3-nopunct": 0.9590163934426229,
        "vocab_size-3-nopunct": 234,
        "unique-3-nopunct": 225,
        "entropy-3-nopunct": 7.845676323209718,
        "cond_entropy-3-nopunct": 0.08534959090301279,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22,
            "2": 0.5952380952380952,
            "3": 0.7358490566037735
        },
        "nist": 5.670088875184574,
        "rouge1": {
            "precision": 0.69563,
            "recall": 0.72742,
            "fmeasure": 0.70122
        },
        "rouge2": {
            "precision": 0.42373,
            "recall": 0.45301,
            "fmeasure": 0.43158
        },
        "rougeL": {
            "precision": 0.56714,
            "recall": 0.5904,
            "fmeasure": 0.568
        },
        "rougeLsum": {
            "precision": 0.56714,
            "recall": 0.5904,
            "fmeasure": 0.568
        },
        "bleu": 36.01702,
        "nubia": {
            "semantic_relation": 4.12764,
            "contradiction": 12.27255,
            "irrelevancy": 38.89399,
            "logical_agreement": 48.83346,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.51575,
            "nubia_score": 0.69239
        },
        "bleurt": 0.11045,
        "meteor": 0.359054843726117,
        "bertscore": {
            "precision": 0.90922,
            "recall": 0.91246,
            "f1": 0.90825
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.262692390839622,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 21,
        "unique-2": 20,
        "entropy-2": 4.368522527728205,
        "cond_entropy-2": 0.11768784439846629,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.186704345910024,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.12336199461765368,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.029610672108602003,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.47058823529411764
        },
        "nist": 1.8186821230869705,
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.38462,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.21739,
            "recall": 0.2,
            "fmeasure": 0.20833
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.23077,
            "fmeasure": 0.24
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.23077,
            "fmeasure": 0.24
        },
        "bleu": 14.52965,
        "nubia": {
            "semantic_relation": 2.82882,
            "contradiction": 0.45171,
            "irrelevancy": 99.3605,
            "logical_agreement": 0.18779,
            "grammar_ref": 4.71547,
            "grammar_hyp": 5.60309,
            "nubia_score": 0.24548
        },
        "bleurt": -0.75545,
        "meteor": 0.24643060694810032,
        "bertscore": {
            "precision": 0.83236,
            "recall": 0.82986,
            "f1": 0.83047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.8,
        "total_length": 121,
        "mean_pred_length": 17.285714285714285,
        "std_pred_length": 7.496938150515387,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.7107438016528925,
        "vocab_size-1": 86,
        "unique-1": 67,
        "entropy-1": 6.170686997497898,
        "distinct-2": 0.9824561403508771,
        "vocab_size-2": 112,
        "unique-2": 110,
        "entropy-2": 6.797802294866507,
        "cond_entropy-2": 0.48884541735489073,
        "distinct-3": 0.9906542056074766,
        "vocab_size-3": 106,
        "unique-3": 105,
        "entropy-3": 6.7227753976160916,
        "cond_entropy-3": -0.07273143897854793,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 14.714285714285714,
        "std_pred_length-nopunct": 6.295447010437345,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7961165048543689,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.230000041662319,
        "distinct-2-nopunct": 0.9791666666666666,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.5432958340544936,
        "cond_entropy-2-nopunct": 0.3361656194614154,
        "distinct-3-nopunct": 0.9887640449438202,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.45326152085405,
        "cond_entropy-3-nopunct": -0.08675715964239877,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.7096774193548387,
            "3": 0.654320987654321
        },
        "nist": 4.899667713977816,
        "rouge1": {
            "precision": 0.82833,
            "recall": 0.67605,
            "fmeasure": 0.73008
        },
        "rouge2": {
            "precision": 0.48737,
            "recall": 0.40379,
            "fmeasure": 0.43337
        },
        "rougeL": {
            "precision": 0.64326,
            "recall": 0.52711,
            "fmeasure": 0.56958
        },
        "rougeLsum": {
            "precision": 0.64326,
            "recall": 0.52711,
            "fmeasure": 0.56958
        },
        "bleu": 39.30291,
        "nubia": {
            "semantic_relation": 4.17199,
            "contradiction": 2.31724,
            "irrelevancy": 17.55698,
            "logical_agreement": 80.12578,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.91368,
            "nubia_score": 0.69377
        },
        "bleurt": 0.1177,
        "meteor": 0.3410725132343354,
        "bertscore": {
            "precision": 0.91989,
            "recall": 0.88353,
            "f1": 0.89991
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.81,
        "total_length": 178,
        "mean_pred_length": 16.181818181818183,
        "std_pred_length": 5.9820668641316725,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.7078651685393258,
        "vocab_size-1": 126,
        "unique-1": 111,
        "entropy-1": 6.525891192234319,
        "distinct-2": 0.9640718562874252,
        "vocab_size-2": 161,
        "unique-2": 156,
        "entropy-2": 7.307327720604787,
        "cond_entropy-2": 0.6450831372158562,
        "distinct-3": 0.9935897435897436,
        "vocab_size-3": 155,
        "unique-3": 154,
        "entropy-3": 7.272581706041753,
        "cond_entropy-3": -0.042180999879986775,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 13.636363636363637,
        "std_pred_length-nopunct": 4.940973906073161,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8133333333333334,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 111,
        "entropy-1-nopunct": 6.673329940279519,
        "distinct-2-nopunct": 0.9712230215827338,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 132,
        "entropy-2-nopunct": 7.055956270549684,
        "cond_entropy-2-nopunct": 0.4265858716541638,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 128,
        "entropy-3-nopunct": 7.0,
        "cond_entropy-3-nopunct": -0.050543514112855466,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.47368421052631576,
            "3": 0.7714285714285715
        },
        "nist": 5.822201877419238,
        "rouge1": {
            "precision": 0.78295,
            "recall": 0.75613,
            "fmeasure": 0.76512
        },
        "rouge2": {
            "precision": 0.57421,
            "recall": 0.5601,
            "fmeasure": 0.56477
        },
        "rougeL": {
            "precision": 0.72304,
            "recall": 0.7043,
            "fmeasure": 0.70943
        },
        "rougeLsum": {
            "precision": 0.72304,
            "recall": 0.7043,
            "fmeasure": 0.70943
        },
        "bleu": 51.34031,
        "nubia": {
            "semantic_relation": 4.44857,
            "contradiction": 6.16239,
            "irrelevancy": 27.58271,
            "logical_agreement": 66.25489,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.54286,
            "nubia_score": 0.81786
        },
        "bleurt": 0.3386,
        "meteor": 0.43353282298698276,
        "bertscore": {
            "precision": 0.93025,
            "recall": 0.92866,
            "f1": 0.9282
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.755,
        "total_length": 278,
        "mean_pred_length": 16.352941176470587,
        "std_pred_length": 3.999134854537302,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.60431654676259,
        "vocab_size-1": 168,
        "unique-1": 136,
        "entropy-1": 6.783079744297902,
        "distinct-2": 0.9195402298850575,
        "vocab_size-2": 240,
        "unique-2": 224,
        "entropy-2": 7.845493580958987,
        "cond_entropy-2": 0.9172271839756743,
        "distinct-3": 0.9713114754098361,
        "vocab_size-3": 237,
        "unique-3": 230,
        "entropy-3": 7.873360288382519,
        "cond_entropy-3": 0.03647740851118546,
        "total_length-nopunct": 247,
        "mean_pred_length-nopunct": 14.529411764705882,
        "std_pred_length-nopunct": 4.174398823343569,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.659919028340081,
        "vocab_size-1-nopunct": 163,
        "unique-1-nopunct": 135,
        "entropy-1-nopunct": 6.85236584468926,
        "distinct-2-nopunct": 0.9173913043478261,
        "vocab_size-2-nopunct": 211,
        "unique-2-nopunct": 197,
        "entropy-2-nopunct": 7.655882918446815,
        "cond_entropy-2-nopunct": 0.8458002606341681,
        "distinct-3-nopunct": 0.971830985915493,
        "vocab_size-3-nopunct": 207,
        "unique-3-nopunct": 201,
        "entropy-3-nopunct": 7.678371592056863,
        "cond_entropy-3-nopunct": 0.032926801555814234,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12121212121212122,
            "2": 0.42857142857142855,
            "3": 0.7956989247311828
        },
        "nist": 6.068523225431946,
        "rouge1": {
            "precision": 0.72923,
            "recall": 0.75189,
            "fmeasure": 0.73413
        },
        "rouge2": {
            "precision": 0.52772,
            "recall": 0.57218,
            "fmeasure": 0.54385
        },
        "rougeL": {
            "precision": 0.65379,
            "recall": 0.67945,
            "fmeasure": 0.66065
        },
        "rougeLsum": {
            "precision": 0.65379,
            "recall": 0.67945,
            "fmeasure": 0.66065
        },
        "bleu": 48.40432,
        "nubia": {
            "semantic_relation": 4.3636,
            "contradiction": 17.33197,
            "irrelevancy": 29.54271,
            "logical_agreement": 53.12532,
            "grammar_ref": 4.21928,
            "grammar_hyp": 4.13604,
            "nubia_score": 0.77848
        },
        "bleurt": 0.37431,
        "meteor": 0.39567904360010897,
        "bertscore": {
            "precision": 0.93543,
            "recall": 0.9399,
            "f1": 0.9351
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.76,
        "total_length": 131,
        "mean_pred_length": 16.375,
        "std_pred_length": 4.580870550452174,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7175572519083969,
        "vocab_size-1": 94,
        "unique-1": 84,
        "entropy-1": 6.15028876892897,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 120,
        "unique-2": 118,
        "entropy-2": 6.887596720768793,
        "cond_entropy-2": 0.6187192478273533,
        "distinct-3": 1.0,
        "vocab_size-3": 115,
        "unique-3": 115,
        "entropy-3": 6.84549005094439,
        "cond_entropy-3": -0.03828630220213861,
        "total_length-nopunct": 118,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 4.437059837324712,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7627118644067796,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.1365489814185485,
        "distinct-2-nopunct": 0.9727272727272728,
        "vocab_size-2-nopunct": 107,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.719951645323182,
        "cond_entropy-2-nopunct": 0.6285731415732203,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 102,
        "entropy-3-nopunct": 6.6724253419715,
        "cond_entropy-3-nopunct": -0.04270998427705158,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.375,
            "3": 0.8157894736842105
        },
        "nist": 4.96940801838014,
        "rouge1": {
            "precision": 0.70668,
            "recall": 0.7106,
            "fmeasure": 0.68844
        },
        "rouge2": {
            "precision": 0.46403,
            "recall": 0.44467,
            "fmeasure": 0.43492
        },
        "rougeL": {
            "precision": 0.5504,
            "recall": 0.57673,
            "fmeasure": 0.54381
        },
        "rougeLsum": {
            "precision": 0.5504,
            "recall": 0.57673,
            "fmeasure": 0.54381
        },
        "bleu": 39.83885,
        "nubia": {
            "semantic_relation": 4.28286,
            "contradiction": 0.97977,
            "irrelevancy": 45.22445,
            "logical_agreement": 53.79578,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.59862,
            "nubia_score": 0.73147
        },
        "bleurt": 0.13648,
        "meteor": 0.3588646882630123,
        "bertscore": {
            "precision": 0.90358,
            "recall": 0.90163,
            "f1": 0.89858
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.9370039370059056,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 17,
        "distinct-1": 0.6590909090909091,
        "vocab_size-1": 29,
        "unique-1": 21,
        "entropy-1": 4.646376220664175,
        "distinct-2": 0.875,
        "vocab_size-2": 35,
        "unique-2": 32,
        "entropy-2": 5.03418371977919,
        "cond_entropy-2": 0.26911303891232496,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 33,
        "unique-3": 31,
        "entropy-3": 4.982289237493325,
        "cond_entropy-3": -0.15200309344504975,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 9.25,
        "std_pred_length-nopunct": 3.112474899497183,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7297297297297297,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.587303365395064,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.839700558686835,
        "cond_entropy-2-nopunct": 0.18372181446668367,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.789015477886192,
        "cond_entropy-3-nopunct": -0.18641312423088147,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.7096774193548387
        },
        "nist": 3.562803704337211,
        "rouge1": {
            "precision": 0.85782,
            "recall": 0.70957,
            "fmeasure": 0.76083
        },
        "rouge2": {
            "precision": 0.6622,
            "recall": 0.56568,
            "fmeasure": 0.59644
        },
        "rougeL": {
            "precision": 0.84266,
            "recall": 0.70561,
            "fmeasure": 0.75214
        },
        "rougeLsum": {
            "precision": 0.84266,
            "recall": 0.70561,
            "fmeasure": 0.75214
        },
        "bleu": 45.54019,
        "nubia": {
            "semantic_relation": 4.31204,
            "contradiction": 0.37064,
            "irrelevancy": 42.52133,
            "logical_agreement": 57.10803,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.00996,
            "nubia_score": 0.88087
        },
        "bleurt": 0.39367,
        "meteor": 0.4132630881588244,
        "bertscore": {
            "precision": 0.95466,
            "recall": 0.94059,
            "f1": 0.94717
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.81,
        "msttr-100_nopunct": 0.86,
        "total_length": 178,
        "mean_pred_length": 17.8,
        "std_pred_length": 5.1536394906900505,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.7528089887640449,
        "vocab_size-1": 134,
        "unique-1": 121,
        "entropy-1": 6.71734175422654,
        "distinct-2": 0.9940476190476191,
        "vocab_size-2": 167,
        "unique-2": 166,
        "entropy-2": 7.380412660874028,
        "cond_entropy-2": 0.5653561255009987,
        "distinct-3": 1.0,
        "vocab_size-3": 158,
        "unique-3": 158,
        "entropy-3": 7.303780748177119,
        "cond_entropy-3": -0.07587844675355629,
        "total_length-nopunct": 157,
        "mean_pred_length-nopunct": 15.7,
        "std_pred_length-nopunct": 4.605431575867782,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.821656050955414,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.765998338320343,
        "distinct-2-nopunct": 0.9931972789115646,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.186066902659483,
        "cond_entropy-2-nopunct": 0.4560292725412744,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 137,
        "unique-3-nopunct": 137,
        "entropy-3-nopunct": 7.098032082960511,
        "cond_entropy-3-nopunct": -0.08704172172985206,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.5263157894736842,
            "3": 0.7623762376237624
        },
        "nist": 4.946650486005185,
        "rouge1": {
            "precision": 0.67067,
            "recall": 0.66194,
            "fmeasure": 0.66234
        },
        "rouge2": {
            "precision": 0.42224,
            "recall": 0.4167,
            "fmeasure": 0.41641
        },
        "rougeL": {
            "precision": 0.49952,
            "recall": 0.4885,
            "fmeasure": 0.49121
        },
        "rougeLsum": {
            "precision": 0.49952,
            "recall": 0.4885,
            "fmeasure": 0.49121
        },
        "bleu": 39.00181,
        "nubia": {
            "semantic_relation": 3.95008,
            "contradiction": 12.11826,
            "irrelevancy": 33.62709,
            "logical_agreement": 54.25465,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.98316,
            "nubia_score": 0.65064
        },
        "bleurt": 0.14717,
        "meteor": 0.3701918193259111,
        "bertscore": {
            "precision": 0.89446,
            "recall": 0.89627,
            "f1": 0.89426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.7875,
        "total_length": 474,
        "mean_pred_length": 15.290322580645162,
        "std_pred_length": 5.0237728296897375,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5590717299578059,
        "vocab_size-1": 265,
        "unique-1": 207,
        "entropy-1": 7.273428729038587,
        "distinct-2": 0.8984198645598194,
        "vocab_size-2": 398,
        "unique-2": 373,
        "entropy-2": 8.531808818601139,
        "cond_entropy-2": 1.0675647674361513,
        "distinct-3": 0.9733009708737864,
        "vocab_size-3": 401,
        "unique-3": 393,
        "entropy-3": 8.627605715274232,
        "cond_entropy-3": 0.09589392620851774,
        "total_length-nopunct": 418,
        "mean_pred_length-nopunct": 13.483870967741936,
        "std_pred_length-nopunct": 4.710119289921027,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6196172248803827,
        "vocab_size-1-nopunct": 259,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 7.406321180772291,
        "distinct-2-nopunct": 0.9043927648578811,
        "vocab_size-2-nopunct": 350,
        "unique-2-nopunct": 333,
        "entropy-2-nopunct": 8.34065008433668,
        "cond_entropy-2-nopunct": 0.9920768888302873,
        "distinct-3-nopunct": 0.9803370786516854,
        "vocab_size-3-nopunct": 349,
        "unique-3-nopunct": 345,
        "entropy-3-nopunct": 8.43004617673471,
        "cond_entropy-3-nopunct": 0.09993486999515712,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29591836734693877,
            "2": 0.5463917525773195,
            "3": 0.7751677852348994
        },
        "nist": 6.604555611639108,
        "rouge1": {
            "precision": 0.7762,
            "recall": 0.74132,
            "fmeasure": 0.74243
        },
        "rouge2": {
            "precision": 0.54378,
            "recall": 0.52556,
            "fmeasure": 0.52214
        },
        "rougeL": {
            "precision": 0.66147,
            "recall": 0.63207,
            "fmeasure": 0.63244
        },
        "rougeLsum": {
            "precision": 0.66147,
            "recall": 0.63207,
            "fmeasure": 0.63244
        },
        "bleu": 48.00851,
        "nubia": {
            "semantic_relation": 4.24156,
            "contradiction": 5.0162,
            "irrelevancy": 30.76935,
            "logical_agreement": 64.21445,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.64795,
            "nubia_score": 0.72197
        },
        "bleurt": 0.27908,
        "meteor": 0.3975761751677703,
        "bertscore": {
            "precision": 0.93498,
            "recall": 0.92976,
            "f1": 0.93108
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.77,
        "total_length": 227,
        "mean_pred_length": 14.1875,
        "std_pred_length": 3.8603553916705646,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6475770925110133,
        "vocab_size-1": 147,
        "unique-1": 125,
        "entropy-1": 6.633002065643445,
        "distinct-2": 0.9383886255924171,
        "vocab_size-2": 198,
        "unique-2": 188,
        "entropy-2": 7.5848201010192335,
        "cond_entropy-2": 0.7645828875664197,
        "distinct-3": 0.9641025641025641,
        "vocab_size-3": 188,
        "unique-3": 181,
        "entropy-3": 7.535535441954776,
        "cond_entropy-3": -0.03810278520288991,
        "total_length-nopunct": 195,
        "mean_pred_length-nopunct": 12.1875,
        "std_pred_length-nopunct": 3.6609211614018675,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7282051282051282,
        "vocab_size-1-nopunct": 142,
        "unique-1-nopunct": 124,
        "entropy-1-nopunct": 6.759575807230708,
        "distinct-2-nopunct": 0.9385474860335196,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 160,
        "entropy-2-nopunct": 7.345520316358307,
        "cond_entropy-2-nopunct": 0.6393750795427353,
        "distinct-3-nopunct": 0.9693251533742331,
        "vocab_size-3-nopunct": 158,
        "unique-3-nopunct": 153,
        "entropy-3-nopunct": 7.2873784609795695,
        "cond_entropy-3-nopunct": -0.044566840811317274,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21951219512195122,
            "2": 0.391304347826087,
            "3": 0.8292682926829268
        },
        "nist": 6.344754861982879,
        "rouge1": {
            "precision": 0.8063,
            "recall": 0.77938,
            "fmeasure": 0.78541
        },
        "rouge2": {
            "precision": 0.58641,
            "recall": 0.57108,
            "fmeasure": 0.57203
        },
        "rougeL": {
            "precision": 0.70855,
            "recall": 0.66933,
            "fmeasure": 0.68155
        },
        "rougeLsum": {
            "precision": 0.70855,
            "recall": 0.66933,
            "fmeasure": 0.68155
        },
        "bleu": 52.56718,
        "nubia": {
            "semantic_relation": 4.47269,
            "contradiction": 4.68749,
            "irrelevancy": 28.24663,
            "logical_agreement": 67.06587,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.53851,
            "nubia_score": 0.80824
        },
        "bleurt": 0.37535,
        "meteor": 0.4305330995883276,
        "bertscore": {
            "precision": 0.93616,
            "recall": 0.94095,
            "f1": 0.93637
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.625
        },
        "nist": 2.0818734482105152,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.625,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "bleu": 15.44788,
        "nubia": {
            "semantic_relation": 4.89215,
            "contradiction": 0.31878,
            "irrelevancy": 0.49621,
            "logical_agreement": 99.18501,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.92558,
            "nubia_score": 0.97134
        },
        "bleurt": 0.71323,
        "meteor": 0.35772595517358696,
        "bertscore": {
            "precision": 0.97848,
            "recall": 0.92917,
            "f1": 0.95319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.8,
        "total_length": 283,
        "mean_pred_length": 17.6875,
        "std_pred_length": 5.730605879835045,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.607773851590106,
        "vocab_size-1": 172,
        "unique-1": 141,
        "entropy-1": 6.797432316260728,
        "distinct-2": 0.9288389513108615,
        "vocab_size-2": 248,
        "unique-2": 232,
        "entropy-2": 7.908055903589529,
        "cond_entropy-2": 1.0111850048917592,
        "distinct-3": 0.9721115537848606,
        "vocab_size-3": 244,
        "unique-3": 237,
        "entropy-3": 7.915766661520487,
        "cond_entropy-3": 0.01744079956267413,
        "total_length-nopunct": 238,
        "mean_pred_length-nopunct": 14.875,
        "std_pred_length-nopunct": 4.3857011982122085,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 141,
        "entropy-1-nopunct": 6.988510582730679,
        "distinct-2-nopunct": 0.9234234234234234,
        "vocab_size-2-nopunct": 205,
        "unique-2-nopunct": 189,
        "entropy-2-nopunct": 7.637862319043053,
        "cond_entropy-2-nopunct": 0.705662163741415,
        "distinct-3-nopunct": 0.9611650485436893,
        "vocab_size-3-nopunct": 198,
        "unique-3-nopunct": 190,
        "entropy-3-nopunct": 7.608830624270597,
        "cond_entropy-3-nopunct": -0.016872195952501712,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3902439024390244,
            "3": 0.7621621621621621
        },
        "nist": 5.971905661411588,
        "rouge1": {
            "precision": 0.73978,
            "recall": 0.74277,
            "fmeasure": 0.73186
        },
        "rouge2": {
            "precision": 0.4965,
            "recall": 0.50199,
            "fmeasure": 0.49245
        },
        "rougeL": {
            "precision": 0.62845,
            "recall": 0.63276,
            "fmeasure": 0.62159
        },
        "rougeLsum": {
            "precision": 0.62845,
            "recall": 0.63276,
            "fmeasure": 0.62159
        },
        "bleu": 44.44446,
        "nubia": {
            "semantic_relation": 4.26977,
            "contradiction": 7.59013,
            "irrelevancy": 35.71112,
            "logical_agreement": 56.69875,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.46156,
            "nubia_score": 0.75279
        },
        "bleurt": 0.35301,
        "meteor": 0.39742030248531746,
        "bertscore": {
            "precision": 0.93407,
            "recall": 0.94378,
            "f1": 0.93764
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.74,
        "total_length": 157,
        "mean_pred_length": 17.444444444444443,
        "std_pred_length": 5.559998223643024,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.6624203821656051,
        "vocab_size-1": 104,
        "unique-1": 89,
        "entropy-1": 6.1671076915116645,
        "distinct-2": 0.9527027027027027,
        "vocab_size-2": 141,
        "unique-2": 137,
        "entropy-2": 7.096244666290005,
        "cond_entropy-2": 0.8355397958352304,
        "distinct-3": 1.0,
        "vocab_size-3": 139,
        "unique-3": 139,
        "entropy-3": 7.118941072723523,
        "cond_entropy-3": 0.030026466102927904,
        "total_length-nopunct": 136,
        "mean_pred_length-nopunct": 15.11111111111111,
        "std_pred_length-nopunct": 4.771313456351975,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7279411764705882,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.168201444127879,
        "distinct-2-nopunct": 0.9606299212598425,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 119,
        "entropy-2-nopunct": 6.894196497795771,
        "cond_entropy-2-nopunct": 0.7911395621253984,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 118,
        "unique-3-nopunct": 118,
        "entropy-3-nopunct": 6.882643049361832,
        "cond_entropy-3-nopunct": -0.004346722156087316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.25,
            "3": 0.7043478260869566
        },
        "nist": 5.26035857920962,
        "rouge1": {
            "precision": 0.78397,
            "recall": 0.71214,
            "fmeasure": 0.73846
        },
        "rouge2": {
            "precision": 0.51844,
            "recall": 0.45222,
            "fmeasure": 0.47843
        },
        "rougeL": {
            "precision": 0.60967,
            "recall": 0.54794,
            "fmeasure": 0.57107
        },
        "rougeLsum": {
            "precision": 0.60967,
            "recall": 0.54794,
            "fmeasure": 0.57107
        },
        "bleu": 35.10128,
        "nubia": {
            "semantic_relation": 4.39041,
            "contradiction": 8.72509,
            "irrelevancy": 29.27951,
            "logical_agreement": 61.9954,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.64998,
            "nubia_score": 0.78062
        },
        "bleurt": 0.27599,
        "meteor": 0.34172739661694024,
        "bertscore": {
            "precision": 0.92788,
            "recall": 0.91461,
            "f1": 0.92037
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 163,
        "mean_pred_length": 11.642857142857142,
        "std_pred_length": 3.5174492149271805,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 19,
        "distinct-1": 0.6503067484662577,
        "vocab_size-1": 106,
        "unique-1": 90,
        "entropy-1": 6.186630278691305,
        "distinct-2": 0.9530201342281879,
        "vocab_size-2": 142,
        "unique-2": 136,
        "entropy-2": 7.120142429843623,
        "cond_entropy-2": 0.684964509197632,
        "distinct-3": 0.9925925925925926,
        "vocab_size-3": 134,
        "unique-3": 133,
        "entropy-3": 7.062000782236041,
        "cond_entropy-3": -0.06268709006197172,
        "total_length-nopunct": 144,
        "mean_pred_length-nopunct": 10.285714285714286,
        "std_pred_length-nopunct": 3.1943828249996997,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.305276776930227,
        "distinct-2-nopunct": 0.9538461538461539,
        "vocab_size-2-nopunct": 124,
        "unique-2-nopunct": 119,
        "entropy-2-nopunct": 6.924253293781044,
        "cond_entropy-2-nopunct": 0.6890155564136713,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 116,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 6.857980995127556,
        "cond_entropy-3-nopunct": -0.07167227046843866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1891891891891892,
            "2": 0.36666666666666664,
            "3": 0.6953125
        },
        "nist": 5.079556234117933,
        "rouge1": {
            "precision": 0.74619,
            "recall": 0.67804,
            "fmeasure": 0.69769
        },
        "rouge2": {
            "precision": 0.50203,
            "recall": 0.4786,
            "fmeasure": 0.48073
        },
        "rougeL": {
            "precision": 0.6791,
            "recall": 0.62265,
            "fmeasure": 0.63635
        },
        "rougeLsum": {
            "precision": 0.6791,
            "recall": 0.62265,
            "fmeasure": 0.63635
        },
        "bleu": 46.35574,
        "nubia": {
            "semantic_relation": 4.09126,
            "contradiction": 11.08435,
            "irrelevancy": 15.2861,
            "logical_agreement": 73.62955,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.5034,
            "nubia_score": 0.7014
        },
        "bleurt": 0.24101,
        "meteor": 0.39285005720570376,
        "bertscore": {
            "precision": 0.92946,
            "recall": 0.91117,
            "f1": 0.91868
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 94,
        "mean_pred_length": 13.428571428571429,
        "std_pred_length": 4.776643856371568,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.7127659574468085,
        "vocab_size-1": 67,
        "unique-1": 56,
        "entropy-1": 5.78300028770975,
        "distinct-2": 0.9425287356321839,
        "vocab_size-2": 82,
        "unique-2": 77,
        "entropy-2": 6.328000967113094,
        "cond_entropy-2": 0.42880924197171066,
        "distinct-3": 0.9625,
        "vocab_size-3": 77,
        "unique-3": 74,
        "entropy-3": 6.246928094887358,
        "cond_entropy-3": -0.0960154009613662,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 11.714285714285714,
        "std_pred_length-nopunct": 4.948716593053935,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7682926829268293,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.759752614268646,
        "distinct-2-nopunct": 0.9466666666666667,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.122152023829222,
        "cond_entropy-2-nopunct": 0.3915273526598491,
        "distinct-3-nopunct": 0.9705882352941176,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.028639311838579,
        "cond_entropy-3-nopunct": -0.11194408453965914,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11428571428571428,
            "2": 0.55,
            "3": 0.7692307692307693
        },
        "nist": 5.281725366314079,
        "rouge1": {
            "precision": 0.80185,
            "recall": 0.74745,
            "fmeasure": 0.76389
        },
        "rouge2": {
            "precision": 0.59605,
            "recall": 0.55771,
            "fmeasure": 0.56644
        },
        "rougeL": {
            "precision": 0.73568,
            "recall": 0.66968,
            "fmeasure": 0.68778
        },
        "rougeLsum": {
            "precision": 0.73568,
            "recall": 0.66968,
            "fmeasure": 0.68778
        },
        "bleu": 51.17339,
        "nubia": {
            "semantic_relation": 4.17276,
            "contradiction": 7.70141,
            "irrelevancy": 41.38987,
            "logical_agreement": 50.90871,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.97559,
            "nubia_score": 0.71224
        },
        "bleurt": 0.18348,
        "meteor": 0.39258258720865136,
        "bertscore": {
            "precision": 0.92764,
            "recall": 0.92082,
            "f1": 0.92102
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.73,
        "total_length": 152,
        "mean_pred_length": 15.2,
        "std_pred_length": 3.3105890714493698,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.6447368421052632,
        "vocab_size-1": 98,
        "unique-1": 84,
        "entropy-1": 6.050471799836042,
        "distinct-2": 0.9225352112676056,
        "vocab_size-2": 131,
        "unique-2": 125,
        "entropy-2": 6.950700200444897,
        "cond_entropy-2": 0.7506176695327916,
        "distinct-3": 0.9924242424242424,
        "vocab_size-3": 131,
        "unique-3": 130,
        "entropy-3": 7.029242604206928,
        "cond_entropy-3": 0.09362171581203213,
        "total_length-nopunct": 136,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 3.136877428271624,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.107431866874269,
        "distinct-2-nopunct": 0.9206349206349206,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.7688302210674625,
        "cond_entropy-2-nopunct": 0.7312420823182602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 116,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 6.857980995127556,
        "cond_entropy-3-nopunct": 0.09849988633877982,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.37037037037037035,
            "2": 0.35294117647058826,
            "3": 0.8207547169811321
        },
        "nist": 5.933615644913142,
        "rouge1": {
            "precision": 0.76199,
            "recall": 0.76493,
            "fmeasure": 0.75375
        },
        "rouge2": {
            "precision": 0.49867,
            "recall": 0.52102,
            "fmeasure": 0.49919
        },
        "rougeL": {
            "precision": 0.61394,
            "recall": 0.64843,
            "fmeasure": 0.61968
        },
        "rougeLsum": {
            "precision": 0.61394,
            "recall": 0.64843,
            "fmeasure": 0.61968
        },
        "bleu": 46.15134,
        "nubia": {
            "semantic_relation": 4.51717,
            "contradiction": 6.2527,
            "irrelevancy": 31.87418,
            "logical_agreement": 61.87311,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.07269,
            "nubia_score": 0.81113
        },
        "bleurt": 0.24325,
        "meteor": 0.39272226365277985,
        "bertscore": {
            "precision": 0.93114,
            "recall": 0.93855,
            "f1": 0.93364
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 76,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.06201920231798,
        "median_pred_length": 18.5,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.7763157894736842,
        "vocab_size-1": 59,
        "unique-1": 50,
        "entropy-1": 5.688331131693843,
        "distinct-2": 0.9861111111111112,
        "vocab_size-2": 71,
        "unique-2": 70,
        "entropy-2": 6.14214722366454,
        "cond_entropy-2": 0.4188646756489674,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.05305039548609061,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 16.25,
        "std_pred_length-nopunct": 3.6314597615834874,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.679834543697837,
        "distinct-2-nopunct": 0.9836065573770492,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.897950452316981,
        "cond_entropy-2-nopunct": 0.24057710660804477,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.832890014164737,
        "cond_entropy-3-nopunct": -0.06275960409989875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.2,
            "3": 0.8214285714285714
        },
        "nist": 4.946557987636946,
        "rouge1": {
            "precision": 0.77292,
            "recall": 0.78419,
            "fmeasure": 0.77809
        },
        "rouge2": {
            "precision": 0.62591,
            "recall": 0.64503,
            "fmeasure": 0.63498
        },
        "rougeL": {
            "precision": 0.68958,
            "recall": 0.7173,
            "fmeasure": 0.7028
        },
        "rougeLsum": {
            "precision": 0.68958,
            "recall": 0.7173,
            "fmeasure": 0.7028
        },
        "bleu": 54.82534,
        "nubia": {
            "semantic_relation": 4.54733,
            "contradiction": 0.38344,
            "irrelevancy": 23.5219,
            "logical_agreement": 76.09466,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.46678,
            "nubia_score": 0.87314
        },
        "bleurt": 0.48798,
        "meteor": 0.42459348116099194,
        "bertscore": {
            "precision": 0.94493,
            "recall": 0.94583,
            "f1": 0.94416
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.74,
        "total_length": 123,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 4.422166387140534,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6747967479674797,
        "vocab_size-1": 83,
        "unique-1": 63,
        "entropy-1": 6.080618013726673,
        "distinct-2": 0.8859649122807017,
        "vocab_size-2": 101,
        "unique-2": 88,
        "entropy-2": 6.604819838726152,
        "cond_entropy-2": 0.34198904790764256,
        "distinct-3": 0.8952380952380953,
        "vocab_size-3": 94,
        "unique-3": 83,
        "entropy-3": 6.504721708142305,
        "cond_entropy-3": -0.08054925840338101,
        "total_length-nopunct": 109,
        "mean_pred_length-nopunct": 12.11111111111111,
        "std_pred_length-nopunct": 4.254264382017033,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7431192660550459,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.163832921282177,
        "distinct-2-nopunct": 0.88,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.403856189774738,
        "cond_entropy-2-nopunct": 0.29441489480707067,
        "distinct-3-nopunct": 0.8901098901098901,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.288014420418485,
        "cond_entropy-3-nopunct": -0.09210550561998473,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35135135135135137,
            "2": 0.65,
            "3": 0.8117647058823529
        },
        "nist": 5.749454705513605,
        "rouge1": {
            "precision": 0.83372,
            "recall": 0.75871,
            "fmeasure": 0.78764
        },
        "rouge2": {
            "precision": 0.64461,
            "recall": 0.59462,
            "fmeasure": 0.61265
        },
        "rougeL": {
            "precision": 0.79933,
            "recall": 0.73063,
            "fmeasure": 0.75676
        },
        "rougeLsum": {
            "precision": 0.79933,
            "recall": 0.73063,
            "fmeasure": 0.75676
        },
        "bleu": 59.4339,
        "nubia": {
            "semantic_relation": 4.16897,
            "contradiction": 0.41435,
            "irrelevancy": 29.09499,
            "logical_agreement": 70.49067,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.15581,
            "nubia_score": 0.6973
        },
        "bleurt": 0.28291,
        "meteor": 0.4258144708148957,
        "bertscore": {
            "precision": 0.95551,
            "recall": 0.93064,
            "f1": 0.94262
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.75,
        "total_length": 195,
        "mean_pred_length": 16.25,
        "std_pred_length": 6.391726423014886,
        "median_pred_length": 13.5,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6205128205128205,
        "vocab_size-1": 121,
        "unique-1": 93,
        "entropy-1": 6.438676101189262,
        "distinct-2": 0.9344262295081968,
        "vocab_size-2": 171,
        "unique-2": 159,
        "entropy-2": 7.38455229730043,
        "cond_entropy-2": 0.861146827464983,
        "distinct-3": 0.9766081871345029,
        "vocab_size-3": 167,
        "unique-3": 163,
        "entropy-3": 7.371068889154894,
        "cond_entropy-3": -0.004280071936156308,
        "total_length-nopunct": 176,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 5.962847939999439,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6590909090909091,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.4154054483994996,
        "distinct-2-nopunct": 0.9390243902439024,
        "vocab_size-2-nopunct": 154,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.23560078510591,
        "cond_entropy-2-nopunct": 0.8702342754135138,
        "distinct-3-nopunct": 0.9736842105263158,
        "vocab_size-3-nopunct": 148,
        "unique-3-nopunct": 144,
        "entropy-3-nopunct": 7.195295934496199,
        "cond_entropy-3-nopunct": -0.04383501749028741,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5483870967741935,
            "3": 0.7251908396946565
        },
        "nist": 5.620083119503383,
        "rouge1": {
            "precision": 0.75737,
            "recall": 0.7215,
            "fmeasure": 0.7287
        },
        "rouge2": {
            "precision": 0.58398,
            "recall": 0.57027,
            "fmeasure": 0.56988
        },
        "rougeL": {
            "precision": 0.64762,
            "recall": 0.64073,
            "fmeasure": 0.63512
        },
        "rougeLsum": {
            "precision": 0.64762,
            "recall": 0.64073,
            "fmeasure": 0.63512
        },
        "bleu": 51.56557,
        "nubia": {
            "semantic_relation": 4.01421,
            "contradiction": 9.70016,
            "irrelevancy": 33.7609,
            "logical_agreement": 56.53895,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.51119,
            "nubia_score": 0.66937
        },
        "bleurt": 0.11464,
        "meteor": 0.37211346088484976,
        "bertscore": {
            "precision": 0.9299,
            "recall": 0.9227,
            "f1": 0.92472
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.71667,
        "msttr-100_nopunct": 0.73,
        "total_length": 329,
        "mean_pred_length": 17.31578947368421,
        "std_pred_length": 4.867211798609218,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.5987841945288754,
        "vocab_size-1": 197,
        "unique-1": 156,
        "entropy-1": 6.989285132830476,
        "distinct-2": 0.9387096774193548,
        "vocab_size-2": 291,
        "unique-2": 281,
        "entropy-2": 8.112398961718842,
        "cond_entropy-2": 1.0149756199950675,
        "distinct-3": 0.9896907216494846,
        "vocab_size-3": 288,
        "unique-3": 285,
        "entropy-3": 8.164256786207252,
        "cond_entropy-3": 0.05911137578581099,
        "total_length-nopunct": 298,
        "mean_pred_length-nopunct": 15.68421052631579,
        "std_pred_length-nopunct": 4.365566600700572,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6442953020134228,
        "vocab_size-1-nopunct": 192,
        "unique-1-nopunct": 155,
        "entropy-1-nopunct": 7.020007951773751,
        "distinct-2-nopunct": 0.931899641577061,
        "vocab_size-2-nopunct": 260,
        "unique-2-nopunct": 250,
        "entropy-2-nopunct": 7.942204152323233,
        "cond_entropy-2-nopunct": 0.991010137124219,
        "distinct-3-nopunct": 0.9884615384615385,
        "vocab_size-3-nopunct": 257,
        "unique-3-nopunct": 254,
        "entropy-3-nopunct": 7.9992908899515305,
        "cond_entropy-3-nopunct": 0.06653453005374167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.43956043956043955,
            "3": 0.7745664739884393
        },
        "nist": 5.43142926014325,
        "rouge1": {
            "precision": 0.67211,
            "recall": 0.70515,
            "fmeasure": 0.68048
        },
        "rouge2": {
            "precision": 0.39993,
            "recall": 0.4465,
            "fmeasure": 0.41581
        },
        "rougeL": {
            "precision": 0.55585,
            "recall": 0.59441,
            "fmeasure": 0.56838
        },
        "rougeLsum": {
            "precision": 0.55585,
            "recall": 0.59441,
            "fmeasure": 0.56838
        },
        "bleu": 36.48049,
        "nubia": {
            "semantic_relation": 4.05032,
            "contradiction": 10.03596,
            "irrelevancy": 44.57079,
            "logical_agreement": 45.39326,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.82837,
            "nubia_score": 0.64461
        },
        "bleurt": 0.20163,
        "meteor": 0.33939844261897617,
        "bertscore": {
            "precision": 0.90158,
            "recall": 0.91072,
            "f1": 0.90377
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 0.9352452343132239,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.50501,
            "fmeasure": 0.57056
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.30864,
            "fmeasure": 0.35354
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.28571,
            "fmeasure": 0.36364
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.28571,
            "fmeasure": 0.36364
        },
        "bleu": 19.92393,
        "nubia": {
            "semantic_relation": 3.12489,
            "contradiction": 33.43973,
            "irrelevancy": 54.29558,
            "logical_agreement": 12.26469,
            "grammar_ref": 3.99891,
            "grammar_hyp": 6.01355,
            "nubia_score": 0.20349
        },
        "bleurt": -0.67917,
        "meteor": 0.32207167084798766,
        "bertscore": {
            "precision": 0.8951,
            "recall": 0.87272,
            "f1": 0.88377
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 4.5,
        "median_pred_length": 19.5,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.8717948717948718,
        "vocab_size-1": 34,
        "unique-1": 32,
        "entropy-1": 4.958353821370876,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.26877783601436245,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.900306619292896,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.06318565884014664,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.39473684210526316
        },
        "nist": 1.9587227356096075,
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.54408,
            "fmeasure": 0.55747
        },
        "rouge2": {
            "precision": 0.43929,
            "recall": 0.38454,
            "fmeasure": 0.38914
        },
        "rougeL": {
            "precision": 0.5381,
            "recall": 0.49505,
            "fmeasure": 0.49282
        },
        "rougeLsum": {
            "precision": 0.5381,
            "recall": 0.49505,
            "fmeasure": 0.49282
        },
        "bleu": 29.18459,
        "nubia": {
            "semantic_relation": 3.53563,
            "contradiction": 17.2371,
            "irrelevancy": 60.65955,
            "logical_agreement": 22.10334,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.7427,
            "nubia_score": 0.44085
        },
        "bleurt": -0.38345,
        "meteor": 0.25097460945936045,
        "bertscore": {
            "precision": 0.90506,
            "recall": 0.88674,
            "f1": 0.89486
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.79,
        "total_length": 170,
        "mean_pred_length": 14.166666666666666,
        "std_pred_length": 4.2784992176644785,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6647058823529411,
        "vocab_size-1": 113,
        "unique-1": 96,
        "entropy-1": 6.325222752646263,
        "distinct-2": 0.9683544303797469,
        "vocab_size-2": 153,
        "unique-2": 148,
        "entropy-2": 7.2404896089366115,
        "cond_entropy-2": 0.7253331106779289,
        "distinct-3": 1.0,
        "vocab_size-3": 146,
        "unique-3": 146,
        "entropy-3": 7.18982455888002,
        "cond_entropy-3": -0.04546303861215409,
        "total_length-nopunct": 149,
        "mean_pred_length-nopunct": 12.416666666666666,
        "std_pred_length-nopunct": 4.192420409368422,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.738255033557047,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.416231898109924,
        "distinct-2-nopunct": 0.9635036496350365,
        "vocab_size-2-nopunct": 132,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 7.0250393822305846,
        "cond_entropy-2-nopunct": 0.6602693597959056,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 125,
        "unique-3-nopunct": 125,
        "entropy-3-nopunct": 6.965784284662096,
        "cond_entropy-3-nopunct": -0.06024779829843977,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19736842105263158,
            "2": 0.25806451612903225,
            "3": 0.6634615384615384
        },
        "nist": 4.8227188436080315,
        "rouge1": {
            "precision": 0.70427,
            "recall": 0.65628,
            "fmeasure": 0.66416
        },
        "rouge2": {
            "precision": 0.40391,
            "recall": 0.37896,
            "fmeasure": 0.37891
        },
        "rougeL": {
            "precision": 0.62333,
            "recall": 0.58713,
            "fmeasure": 0.58983
        },
        "rougeLsum": {
            "precision": 0.62333,
            "recall": 0.58713,
            "fmeasure": 0.58983
        },
        "bleu": 26.91231,
        "nubia": {
            "semantic_relation": 3.75314,
            "contradiction": 22.17095,
            "irrelevancy": 40.65388,
            "logical_agreement": 37.17517,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.84512,
            "nubia_score": 0.54694
        },
        "bleurt": 0.13115,
        "meteor": 0.3375386526787699,
        "bertscore": {
            "precision": 0.91987,
            "recall": 0.90826,
            "f1": 0.9116
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.75,
        "total_length": 205,
        "mean_pred_length": 15.76923076923077,
        "std_pred_length": 4.422909695835401,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.6097560975609756,
        "vocab_size-1": 125,
        "unique-1": 100,
        "entropy-1": 6.403038129805574,
        "distinct-2": 0.9375,
        "vocab_size-2": 180,
        "unique-2": 173,
        "entropy-2": 7.4273340501665395,
        "cond_entropy-2": 0.862934170293033,
        "distinct-3": 0.9888268156424581,
        "vocab_size-3": 177,
        "unique-3": 175,
        "entropy-3": 7.461469408549164,
        "cond_entropy-3": 0.03999664250114711,
        "total_length-nopunct": 173,
        "mean_pred_length-nopunct": 13.307692307692308,
        "std_pred_length-nopunct": 3.7082987055981382,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6936416184971098,
        "vocab_size-1-nopunct": 120,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.570091305945175,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 150,
        "unique-2-nopunct": 145,
        "entropy-2-nopunct": 7.157773954221802,
        "cond_entropy-2-nopunct": 0.6157082262755391,
        "distinct-3-nopunct": 0.9931972789115646,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.1860669026594834,
        "cond_entropy-3-nopunct": 0.042809981285671456,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.058823529411764705,
            "3": 0.803921568627451
        },
        "nist": 5.652136711926483,
        "rouge1": {
            "precision": 0.75433,
            "recall": 0.74166,
            "fmeasure": 0.74519
        },
        "rouge2": {
            "precision": 0.57376,
            "recall": 0.56761,
            "fmeasure": 0.56827
        },
        "rougeL": {
            "precision": 0.60914,
            "recall": 0.5953,
            "fmeasure": 0.60005
        },
        "rougeLsum": {
            "precision": 0.60914,
            "recall": 0.5953,
            "fmeasure": 0.60005
        },
        "bleu": 49.27858,
        "nubia": {
            "semantic_relation": 4.30796,
            "contradiction": 7.50719,
            "irrelevancy": 18.45164,
            "logical_agreement": 74.04118,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.67288,
            "nubia_score": 0.79435
        },
        "bleurt": 0.4668,
        "meteor": 0.40821053369303917,
        "bertscore": {
            "precision": 0.94042,
            "recall": 0.93486,
            "f1": 0.93744
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "total_length": 103,
        "mean_pred_length": 17.166666666666668,
        "std_pred_length": 5.842849380986035,
        "median_pred_length": 16.5,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.7087378640776699,
        "vocab_size-1": 73,
        "unique-1": 60,
        "entropy-1": 5.886689455264745,
        "distinct-2": 0.979381443298969,
        "vocab_size-2": 95,
        "unique-2": 93,
        "entropy-2": 6.558675728785079,
        "cond_entropy-2": 0.6017721081293421,
        "distinct-3": 1.0,
        "vocab_size-3": 91,
        "unique-3": 91,
        "entropy-3": 6.507794640198703,
        "cond_entropy-3": -0.048162158032387686,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.155902766086006,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7634408602150538,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.903016236282976,
        "distinct-2-nopunct": 0.9770114942528736,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.39696648435447,
        "cond_entropy-2-nopunct": 0.5263278969100098,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.339850002884614,
        "cond_entropy-3-nopunct": -0.0537107769147207,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 4.662163841846065,
        "rouge1": {
            "precision": 0.74715,
            "recall": 0.76906,
            "fmeasure": 0.7522
        },
        "rouge2": {
            "precision": 0.45394,
            "recall": 0.47575,
            "fmeasure": 0.45998
        },
        "rougeL": {
            "precision": 0.54188,
            "recall": 0.57854,
            "fmeasure": 0.55404
        },
        "rougeLsum": {
            "precision": 0.54188,
            "recall": 0.57854,
            "fmeasure": 0.55404
        },
        "bleu": 31.66146,
        "nubia": {
            "semantic_relation": 4.21968,
            "contradiction": 34.12625,
            "irrelevancy": 29.91293,
            "logical_agreement": 35.96082,
            "grammar_ref": 5.40206,
            "grammar_hyp": 5.0839,
            "nubia_score": 0.74045
        },
        "bleurt": 0.08155,
        "meteor": 0.3792413857518345,
        "bertscore": {
            "precision": 0.92183,
            "recall": 0.92306,
            "f1": 0.921
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 37,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.788,
        "total_length": 626,
        "mean_pred_length": 16.91891891891892,
        "std_pred_length": 5.0155346694497975,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.5766773162939297,
        "vocab_size-1": 361,
        "unique-1": 297,
        "entropy-1": 7.637798352712781,
        "distinct-2": 0.9100169779286927,
        "vocab_size-2": 536,
        "unique-2": 500,
        "entropy-2": 8.988584880688203,
        "cond_entropy-2": 1.1678423590871359,
        "distinct-3": 0.9836956521739131,
        "vocab_size-3": 543,
        "unique-3": 535,
        "entropy-3": 9.07454821130328,
        "cond_entropy-3": 0.0880395143000459,
        "total_length-nopunct": 553,
        "mean_pred_length-nopunct": 14.945945945945946,
        "std_pred_length-nopunct": 4.501927190605219,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.64376130198915,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 296,
        "entropy-1-nopunct": 7.817810539730079,
        "distinct-2-nopunct": 0.9127906976744186,
        "vocab_size-2-nopunct": 471,
        "unique-2-nopunct": 442,
        "entropy-2-nopunct": 8.799949057732029,
        "cond_entropy-2-nopunct": 1.053739563027257,
        "distinct-3-nopunct": 0.9874739039665971,
        "vocab_size-3-nopunct": 473,
        "unique-3-nopunct": 468,
        "entropy-3-nopunct": 8.877253688111626,
        "cond_entropy-3-nopunct": 0.09153697550392909,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.41836734693877553,
            "3": 0.7101449275362319
        },
        "nist": 6.356784443268156,
        "rouge1": {
            "precision": 0.702,
            "recall": 0.714,
            "fmeasure": 0.69169
        },
        "rouge2": {
            "precision": 0.47005,
            "recall": 0.47965,
            "fmeasure": 0.46405
        },
        "rougeL": {
            "precision": 0.60032,
            "recall": 0.60908,
            "fmeasure": 0.5894
        },
        "rougeLsum": {
            "precision": 0.60032,
            "recall": 0.60908,
            "fmeasure": 0.5894
        },
        "bleu": 40.44953,
        "nubia": {
            "semantic_relation": 4.07018,
            "contradiction": 9.57296,
            "irrelevancy": 37.43809,
            "logical_agreement": 52.98896,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.82501,
            "nubia_score": 0.67945
        },
        "bleurt": 0.1134,
        "meteor": 0.37854355420604563,
        "bertscore": {
            "precision": 0.91844,
            "recall": 0.91527,
            "f1": 0.91544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.76,
        "total_length": 150,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.9396356140913875,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.7,
        "vocab_size-1": 105,
        "unique-1": 88,
        "entropy-1": 6.334037587015647,
        "distinct-2": 0.9785714285714285,
        "vocab_size-2": 137,
        "unique-2": 134,
        "entropy-2": 7.086425874087835,
        "cond_entropy-2": 0.6125203300851734,
        "distinct-3": 1.0,
        "vocab_size-3": 130,
        "unique-3": 130,
        "entropy-3": 7.022367813028455,
        "cond_entropy-3": -0.06076135776266604,
        "total_length-nopunct": 131,
        "mean_pred_length-nopunct": 13.1,
        "std_pred_length-nopunct": 4.635730794599704,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7633587786259542,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.345803153944967,
        "distinct-2-nopunct": 0.9752066115702479,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 115,
        "entropy-2-nopunct": 6.869276460415098,
        "cond_entropy-2-nopunct": 0.5720369302380984,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 111,
        "unique-3-nopunct": 111,
        "entropy-3-nopunct": 6.794415866350121,
        "cond_entropy-3-nopunct": -0.07039331687043451,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3235294117647059,
            "2": 0.41935483870967744,
            "3": 0.8061224489795918
        },
        "nist": 5.988638046356154,
        "rouge1": {
            "precision": 0.76825,
            "recall": 0.71051,
            "fmeasure": 0.71806
        },
        "rouge2": {
            "precision": 0.51736,
            "recall": 0.47664,
            "fmeasure": 0.4822
        },
        "rougeL": {
            "precision": 0.68027,
            "recall": 0.63462,
            "fmeasure": 0.6395
        },
        "rougeLsum": {
            "precision": 0.68027,
            "recall": 0.63462,
            "fmeasure": 0.6395
        },
        "bleu": 51.03914,
        "nubia": {
            "semantic_relation": 4.25489,
            "contradiction": 16.86932,
            "irrelevancy": 27.61489,
            "logical_agreement": 55.51578,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.86828,
            "nubia_score": 0.70367
        },
        "bleurt": 0.24695,
        "meteor": 0.43774728690484244,
        "bertscore": {
            "precision": 0.92688,
            "recall": 0.91518,
            "f1": 0.91989
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.744,
        "msttr-100_nopunct": 0.805,
        "total_length": 546,
        "mean_pred_length": 17.612903225806452,
        "std_pred_length": 6.083703346645823,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.5622710622710623,
        "vocab_size-1": 307,
        "unique-1": 241,
        "entropy-1": 7.518397722022424,
        "distinct-2": 0.8893203883495145,
        "vocab_size-2": 458,
        "unique-2": 417,
        "entropy-2": 8.745546917244853,
        "cond_entropy-2": 1.0833702626773747,
        "distinct-3": 0.9504132231404959,
        "vocab_size-3": 460,
        "unique-3": 437,
        "entropy-3": 8.818129998633811,
        "cond_entropy-3": 0.08115608314428405,
        "total_length-nopunct": 473,
        "mean_pred_length-nopunct": 15.258064516129032,
        "std_pred_length-nopunct": 5.167939265694034,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.638477801268499,
        "vocab_size-1-nopunct": 302,
        "unique-1-nopunct": 241,
        "entropy-1-nopunct": 7.723245527398477,
        "distinct-2-nopunct": 0.9095022624434389,
        "vocab_size-2-nopunct": 402,
        "unique-2-nopunct": 373,
        "entropy-2-nopunct": 8.570109205304323,
        "cond_entropy-2-nopunct": 0.9049997100807555,
        "distinct-3-nopunct": 0.9610705596107056,
        "vocab_size-3-nopunct": 395,
        "unique-3-nopunct": 379,
        "entropy-3-nopunct": 8.605135702903086,
        "cond_entropy-3-nopunct": 0.04172137345446177,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.375,
            "3": 0.8432432432432433
        },
        "nist": 7.396866184818903,
        "rouge1": {
            "precision": 0.80838,
            "recall": 0.80822,
            "fmeasure": 0.79972
        },
        "rouge2": {
            "precision": 0.61416,
            "recall": 0.62087,
            "fmeasure": 0.61002
        },
        "rougeL": {
            "precision": 0.71511,
            "recall": 0.7214,
            "fmeasure": 0.70911
        },
        "rougeLsum": {
            "precision": 0.71511,
            "recall": 0.7214,
            "fmeasure": 0.70911
        },
        "bleu": 56.30758,
        "nubia": {
            "semantic_relation": 4.40361,
            "contradiction": 2.22982,
            "irrelevancy": 19.07285,
            "logical_agreement": 78.69733,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.81063,
            "nubia_score": 0.75872
        },
        "bleurt": 0.36236,
        "meteor": 0.44701151292084124,
        "bertscore": {
            "precision": 0.94799,
            "recall": 0.94411,
            "f1": 0.94502
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.66,
        "total_length": 156,
        "mean_pred_length": 19.5,
        "std_pred_length": 7.053367989832942,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.6089743589743589,
        "vocab_size-1": 95,
        "unique-1": 73,
        "entropy-1": 6.113172370391459,
        "distinct-2": 0.9324324324324325,
        "vocab_size-2": 138,
        "unique-2": 131,
        "entropy-2": 7.055704125749465,
        "cond_entropy-2": 0.9010997538947718,
        "distinct-3": 1.0,
        "vocab_size-3": 140,
        "unique-3": 140,
        "entropy-3": 7.129283016944978,
        "cond_entropy-3": 0.08236456204575579,
        "total_length-nopunct": 139,
        "mean_pred_length-nopunct": 17.375,
        "std_pred_length-nopunct": 5.851014869234225,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6546762589928058,
        "vocab_size-1-nopunct": 91,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.075103527035552,
        "distinct-2-nopunct": 0.9465648854961832,
        "vocab_size-2-nopunct": 124,
        "unique-2-nopunct": 119,
        "entropy-2-nopunct": 6.911285596957299,
        "cond_entropy-2-nopunct": 0.8770271108797992,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.942514505339227,
        "cond_entropy-3-nopunct": 0.03917280461479745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.39285714285714285,
            "2": 0.48,
            "3": 0.7789473684210526
        },
        "nist": 5.888027535673673,
        "rouge1": {
            "precision": 0.78353,
            "recall": 0.76935,
            "fmeasure": 0.76714
        },
        "rouge2": {
            "precision": 0.57153,
            "recall": 0.54301,
            "fmeasure": 0.54876
        },
        "rougeL": {
            "precision": 0.72153,
            "recall": 0.70634,
            "fmeasure": 0.70513
        },
        "rougeLsum": {
            "precision": 0.72153,
            "recall": 0.70634,
            "fmeasure": 0.70513
        },
        "bleu": 47.04035,
        "nubia": {
            "semantic_relation": 4.09789,
            "contradiction": 4.78716,
            "irrelevancy": 35.91168,
            "logical_agreement": 59.30117,
            "grammar_ref": 4.94279,
            "grammar_hyp": 5.13366,
            "nubia_score": 0.65679
        },
        "bleurt": 0.07131,
        "meteor": 0.38317216595592335,
        "bertscore": {
            "precision": 0.94156,
            "recall": 0.93462,
            "f1": 0.93599
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.1763214467468543,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.403856189774723,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.14943964427976503,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.061400544664143256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.6666666666666666
        },
        "nist": 2.6584208081433944,
        "rouge1": {
            "precision": 0.52174,
            "recall": 0.43423,
            "fmeasure": 0.47385
        },
        "rouge2": {
            "precision": 0.22727,
            "recall": 0.18773,
            "fmeasure": 0.20556
        },
        "rougeL": {
            "precision": 0.34783,
            "recall": 0.35273,
            "fmeasure": 0.34909
        },
        "rougeLsum": {
            "precision": 0.34783,
            "recall": 0.35273,
            "fmeasure": 0.34909
        },
        "bleu": 17.54989,
        "nubia": {
            "semantic_relation": 3.1846,
            "contradiction": 0.07713,
            "irrelevancy": 99.50254,
            "logical_agreement": 0.42032,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.14808,
            "nubia_score": 0.55715
        },
        "bleurt": -0.33325,
        "meteor": 0.24368966911979706,
        "bertscore": {
            "precision": 0.84671,
            "recall": 0.8424,
            "f1": 0.84455
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.74,
        "total_length": 147,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 4.163331998932265,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 98,
        "unique-1": 84,
        "entropy-1": 6.10966000939598,
        "distinct-2": 0.9637681159420289,
        "vocab_size-2": 133,
        "unique-2": 130,
        "entropy-2": 7.0215679350390365,
        "cond_entropy-2": 0.7762614474255354,
        "distinct-3": 1.0,
        "vocab_size-3": 129,
        "unique-3": 129,
        "entropy-3": 7.011227255423235,
        "cond_entropy-3": -0.004273945540961289,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 14.444444444444445,
        "std_pred_length-nopunct": 3.6851386559504444,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7230769230769231,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.097808480009779,
        "distinct-2-nopunct": 0.9586776859504132,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 6.819689683555596,
        "cond_entropy-2-nopunct": 0.7823856167455433,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.807354922057591,
        "cond_entropy-3-nopunct": -0.004365458074133161,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.42857142857142855,
            "3": 0.7012987012987013
        },
        "nist": 4.2784155708695835,
        "rouge1": {
            "precision": 0.64032,
            "recall": 0.70966,
            "fmeasure": 0.66308
        },
        "rouge2": {
            "precision": 0.43067,
            "recall": 0.49261,
            "fmeasure": 0.45231
        },
        "rougeL": {
            "precision": 0.59343,
            "recall": 0.6649,
            "fmeasure": 0.61784
        },
        "rougeLsum": {
            "precision": 0.59343,
            "recall": 0.6649,
            "fmeasure": 0.61784
        },
        "bleu": 34.4202,
        "nubia": {
            "semantic_relation": 3.87823,
            "contradiction": 21.64226,
            "irrelevancy": 35.04926,
            "logical_agreement": 43.30848,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.87206,
            "nubia_score": 0.62716
        },
        "bleurt": 0.19299,
        "meteor": 0.34601516813963923,
        "bertscore": {
            "precision": 0.90658,
            "recall": 0.91065,
            "f1": 0.90756
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.5,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.321627262824397,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.4420481493764492,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029344,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.1000689306627525,
        "distinct-2-nopunct": 0.9583333333333334,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.501629167387823,
        "cond_entropy-2-nopunct": 0.4099244690149312,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.03462179117476821,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9473684210526315
        },
        "nist": 3.513238303413485,
        "rouge1": {
            "precision": 0.73764,
            "recall": 0.92857,
            "fmeasure": 0.81507
        },
        "rouge2": {
            "precision": 0.53889,
            "recall": 0.67892,
            "fmeasure": 0.59534
        },
        "rougeL": {
            "precision": 0.67464,
            "recall": 0.84788,
            "fmeasure": 0.74575
        },
        "rougeLsum": {
            "precision": 0.67464,
            "recall": 0.84788,
            "fmeasure": 0.74575
        },
        "bleu": 51.34578,
        "nubia": {
            "semantic_relation": 4.49517,
            "contradiction": 0.1614,
            "irrelevancy": 20.14839,
            "logical_agreement": 79.69021,
            "grammar_ref": 5.56806,
            "grammar_hyp": 4.75384,
            "nubia_score": 0.88488
        },
        "bleurt": 0.53958,
        "meteor": 0.5075500762618924,
        "bertscore": {
            "precision": 0.93699,
            "recall": 0.96111,
            "f1": 0.9488
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.78333,
        "total_length": 358,
        "mean_pred_length": 14.916666666666666,
        "std_pred_length": 3.80697459350014,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.611731843575419,
        "vocab_size-1": 219,
        "unique-1": 187,
        "entropy-1": 7.01879760010794,
        "distinct-2": 0.9520958083832335,
        "vocab_size-2": 318,
        "unique-2": 306,
        "entropy-2": 8.277387600844278,
        "cond_entropy-2": 1.0344023846718462,
        "distinct-3": 0.9967741935483871,
        "vocab_size-3": 309,
        "unique-3": 308,
        "entropy-3": 8.269672792370983,
        "cond_entropy-3": -0.005935451701985822,
        "total_length-nopunct": 312,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.593976442141304,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6891025641025641,
        "vocab_size-1-nopunct": 215,
        "unique-1-nopunct": 187,
        "entropy-1-nopunct": 7.179202095478093,
        "distinct-2-nopunct": 0.9548611111111112,
        "vocab_size-2-nopunct": 275,
        "unique-2-nopunct": 266,
        "entropy-2-nopunct": 8.06746050489948,
        "cond_entropy-2-nopunct": 0.9679939665758858,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 264,
        "unique-3-nopunct": 264,
        "entropy-3-nopunct": 8.044394119358463,
        "cond_entropy-3-nopunct": -0.017539310097772192,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1276595744680851,
            "2": 0.3953488372093023,
            "3": 0.7763713080168776
        },
        "nist": 6.085593274607368,
        "rouge1": {
            "precision": 0.7637,
            "recall": 0.72936,
            "fmeasure": 0.73576
        },
        "rouge2": {
            "precision": 0.51401,
            "recall": 0.4911,
            "fmeasure": 0.49491
        },
        "rougeL": {
            "precision": 0.6977,
            "recall": 0.67025,
            "fmeasure": 0.67461
        },
        "rougeLsum": {
            "precision": 0.6977,
            "recall": 0.67025,
            "fmeasure": 0.67461
        },
        "bleu": 40.99941,
        "nubia": {
            "semantic_relation": 4.19587,
            "contradiction": 13.53662,
            "irrelevancy": 29.4738,
            "logical_agreement": 56.98959,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.74395,
            "nubia_score": 0.72422
        },
        "bleurt": 0.27027,
        "meteor": 0.3868539969976198,
        "bertscore": {
            "precision": 0.93085,
            "recall": 0.92905,
            "f1": 0.92824
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 10.2,
        "std_pred_length": 1.7204650534085253,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 13,
        "distinct-1": 0.7843137254901961,
        "vocab_size-1": 40,
        "unique-1": 33,
        "entropy-1": 5.155473813018553,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.17189503804559267,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.1660099514389293,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 8.8,
        "std_pred_length-nopunct": 1.32664991614216,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.169547811769943,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.1530189977163221,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.1979393776119089,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.625,
            "3": 0.6578947368421053
        },
        "nist": 4.484864976140676,
        "rouge1": {
            "precision": 0.79129,
            "recall": 0.73889,
            "fmeasure": 0.76099
        },
        "rouge2": {
            "precision": 0.51352,
            "recall": 0.46366,
            "fmeasure": 0.48385
        },
        "rougeL": {
            "precision": 0.73675,
            "recall": 0.70926,
            "fmeasure": 0.71902
        },
        "rougeLsum": {
            "precision": 0.73675,
            "recall": 0.70926,
            "fmeasure": 0.71902
        },
        "bleu": 38.59737,
        "nubia": {
            "semantic_relation": 4.22762,
            "contradiction": 3.14973,
            "irrelevancy": 53.66274,
            "logical_agreement": 43.18753,
            "grammar_ref": 5.90284,
            "grammar_hyp": 4.98545,
            "nubia_score": 0.80342
        },
        "bleurt": 0.19163,
        "meteor": 0.40640754054959116,
        "bertscore": {
            "precision": 0.92844,
            "recall": 0.91625,
            "f1": 0.92218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 98,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 4.988876515698588,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.7448979591836735,
        "vocab_size-1": 73,
        "unique-1": 62,
        "entropy-1": 5.904008410525985,
        "distinct-2": 0.9782608695652174,
        "vocab_size-2": 90,
        "unique-2": 88,
        "entropy-2": 6.480083695187462,
        "cond_entropy-2": 0.4962336338690627,
        "distinct-3": 1.0,
        "vocab_size-3": 86,
        "unique-3": 86,
        "entropy-3": 6.426264754702099,
        "cond_entropy-3": -0.050785573447938326,
        "total_length-nopunct": 90,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0990195135927845,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7888888888888889,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.89980629060584,
        "distinct-2-nopunct": 0.9761904761904762,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.344698375159712,
        "cond_entropy-2-nopunct": 0.48718114210556546,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.285402218862257,
        "cond_entropy-3-nopunct": -0.05563315263446062,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2222222222222222,
            "3": 0.7916666666666666
        },
        "nist": 5.110139259773756,
        "rouge1": {
            "precision": 0.75602,
            "recall": 0.72512,
            "fmeasure": 0.73653
        },
        "rouge2": {
            "precision": 0.4704,
            "recall": 0.45404,
            "fmeasure": 0.45773
        },
        "rougeL": {
            "precision": 0.58873,
            "recall": 0.54771,
            "fmeasure": 0.56369
        },
        "rougeLsum": {
            "precision": 0.58873,
            "recall": 0.54771,
            "fmeasure": 0.56369
        },
        "bleu": 32.69618,
        "nubia": {
            "semantic_relation": 4.08814,
            "contradiction": 35.80675,
            "irrelevancy": 21.79308,
            "logical_agreement": 42.40018,
            "grammar_ref": 4.74863,
            "grammar_hyp": 5.04434,
            "nubia_score": 0.62764
        },
        "bleurt": 0.01329,
        "meteor": 0.3674321503306998,
        "bertscore": {
            "precision": 0.93409,
            "recall": 0.9166,
            "f1": 0.92434
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 15.6,
        "std_pred_length": 4.317406628984581,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.717948717948718,
        "vocab_size-1": 56,
        "unique-1": 49,
        "entropy-1": 5.450537917852462,
        "distinct-2": 0.958904109589041,
        "vocab_size-2": 70,
        "unique-2": 68,
        "entropy-2": 6.097291853370939,
        "cond_entropy-2": 0.544900251006309,
        "distinct-3": 1.0,
        "vocab_size-3": 68,
        "unique-3": 68,
        "entropy-3": 6.087462841250345,
        "cond_entropy-3": -0.0030251367155091037,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 3.6660605559646715,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7794117647058824,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.418201444127888,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 60,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.870059486957643,
        "cond_entropy-2-nopunct": 0.5049740267283623,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.85798099512757,
        "cond_entropy-3-nopunct": -0.002835350748836356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.2222222222222222,
            "3": 0.76
        },
        "nist": 5.115955155286423,
        "rouge1": {
            "precision": 0.77432,
            "recall": 0.79992,
            "fmeasure": 0.77898
        },
        "rouge2": {
            "precision": 0.5302,
            "recall": 0.55818,
            "fmeasure": 0.53725
        },
        "rougeL": {
            "precision": 0.66974,
            "recall": 0.73905,
            "fmeasure": 0.69851
        },
        "rougeLsum": {
            "precision": 0.66974,
            "recall": 0.73905,
            "fmeasure": 0.69851
        },
        "bleu": 44.71381,
        "nubia": {
            "semantic_relation": 4.64888,
            "contradiction": 1.80785,
            "irrelevancy": 19.24996,
            "logical_agreement": 78.94219,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.74729,
            "nubia_score": 0.84104
        },
        "bleurt": 0.42209,
        "meteor": 0.4187332975119674,
        "bertscore": {
            "precision": 0.94455,
            "recall": 0.93737,
            "f1": 0.94044
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.7,
        "total_length": 118,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 3.496029493900505,
        "median_pred_length": 19.5,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.652542372881356,
        "vocab_size-1": 77,
        "unique-1": 62,
        "entropy-1": 5.852662614951884,
        "distinct-2": 0.9464285714285714,
        "vocab_size-2": 106,
        "unique-2": 100,
        "entropy-2": 6.700212064914736,
        "cond_entropy-2": 0.7990694689987754,
        "distinct-3": 0.9716981132075472,
        "vocab_size-3": 103,
        "unique-3": 100,
        "entropy-3": 6.671316680978277,
        "cond_entropy-3": -0.022830693909499232,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 2.981423969999719,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6886792452830188,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.800388281813183,
        "distinct-2-nopunct": 0.94,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 88,
        "entropy-2-nopunct": 6.5238561897747385,
        "cond_entropy-2-nopunct": 0.7591198383265322,
        "distinct-3-nopunct": 0.9680851063829787,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.490759064443582,
        "cond_entropy-3-nopunct": -0.025437550863044715,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.7916666666666666
        },
        "nist": 3.6735522651420336,
        "rouge1": {
            "precision": 0.55,
            "recall": 0.71085,
            "fmeasure": 0.61208
        },
        "rouge2": {
            "precision": 0.30131,
            "recall": 0.39014,
            "fmeasure": 0.33388
        },
        "rougeL": {
            "precision": 0.44199,
            "recall": 0.5695,
            "fmeasure": 0.49086
        },
        "rougeLsum": {
            "precision": 0.44199,
            "recall": 0.5695,
            "fmeasure": 0.49086
        },
        "bleu": 28.778,
        "nubia": {
            "semantic_relation": 3.62546,
            "contradiction": 1.99829,
            "irrelevancy": 61.3893,
            "logical_agreement": 36.61242,
            "grammar_ref": 4.25456,
            "grammar_hyp": 3.99288,
            "nubia_score": 0.58655
        },
        "bleurt": -0.01322,
        "meteor": 0.36778790519198223,
        "bertscore": {
            "precision": 0.86523,
            "recall": 0.8958,
            "f1": 0.88004
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 1.0
        },
        "nist": 3.6962282398857416,
        "rouge1": {
            "precision": 0.80769,
            "recall": 0.95833,
            "fmeasure": 0.87478
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.61616,
            "fmeasure": 0.55072
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.78333,
            "fmeasure": 0.7113
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.78333,
            "fmeasure": 0.7113
        },
        "bleu": 48.54918,
        "nubia": {
            "semantic_relation": 4.44374,
            "contradiction": 0.24546,
            "irrelevancy": 56.66568,
            "logical_agreement": 43.08886,
            "grammar_ref": 4.59758,
            "grammar_hyp": 3.84134,
            "nubia_score": 0.87419
        },
        "bleurt": 0.68063,
        "meteor": 0.4921814572635894,
        "bertscore": {
            "precision": 0.89114,
            "recall": 0.95695,
            "f1": 0.92287
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.81,
        "total_length": 227,
        "mean_pred_length": 16.214285714285715,
        "std_pred_length": 5.101520381619742,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6299559471365639,
        "vocab_size-1": 143,
        "unique-1": 115,
        "entropy-1": 6.641559272852036,
        "distinct-2": 0.92018779342723,
        "vocab_size-2": 196,
        "unique-2": 182,
        "entropy-2": 7.562151462938723,
        "cond_entropy-2": 0.772630371618612,
        "distinct-3": 0.964824120603015,
        "vocab_size-3": 192,
        "unique-3": 185,
        "entropy-3": 7.56627286174969,
        "cond_entropy-3": 0.016261168670390704,
        "total_length-nopunct": 198,
        "mean_pred_length-nopunct": 14.142857142857142,
        "std_pred_length-nopunct": 4.549052379454474,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.702020202020202,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.740072781520936,
        "distinct-2-nopunct": 0.9239130434782609,
        "vocab_size-2-nopunct": 170,
        "unique-2-nopunct": 159,
        "entropy-2-nopunct": 7.356415828327875,
        "cond_entropy-2-nopunct": 0.6785711649581204,
        "distinct-3-nopunct": 0.9764705882352941,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 162,
        "entropy-3-nopunct": 7.362332112608261,
        "cond_entropy-3-nopunct": 0.013798906564003427,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.46875,
            "3": 0.8782051282051282
        },
        "nist": 6.22516293569017,
        "rouge1": {
            "precision": 0.81188,
            "recall": 0.83038,
            "fmeasure": 0.81672
        },
        "rouge2": {
            "precision": 0.64006,
            "recall": 0.65383,
            "fmeasure": 0.64403
        },
        "rougeL": {
            "precision": 0.6888,
            "recall": 0.70793,
            "fmeasure": 0.69548
        },
        "rougeLsum": {
            "precision": 0.6888,
            "recall": 0.70793,
            "fmeasure": 0.69548
        },
        "bleu": 59.39508,
        "nubia": {
            "semantic_relation": 4.43312,
            "contradiction": 8.61796,
            "irrelevancy": 19.32092,
            "logical_agreement": 72.06112,
            "grammar_ref": 4.89936,
            "grammar_hyp": 4.96505,
            "nubia_score": 0.77462
        },
        "bleurt": 0.45299,
        "meteor": 0.46483381875027896,
        "bertscore": {
            "precision": 0.95101,
            "recall": 0.93915,
            "f1": 0.94384
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 5.0,
        "median_pred_length": 22.0,
        "min_pred_length": 17,
        "max_pred_length": 27,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 36,
        "unique-1": 30,
        "entropy-1": 5.061482186720775,
        "distinct-2": 1.0,
        "vocab_size-2": 42,
        "unique-2": 42,
        "entropy-2": 5.3923174227787625,
        "cond_entropy-2": 0.302166161387343,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.07038932789139805,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.892407118592879,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.2972690158966975,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2,
            "3": 0.7368421052631579
        },
        "nist": 2.823016523401228,
        "rouge1": {
            "precision": 0.45641,
            "recall": 0.77281,
            "fmeasure": 0.57233
        },
        "rouge2": {
            "precision": 0.21952,
            "recall": 0.36792,
            "fmeasure": 0.27399
        },
        "rougeL": {
            "precision": 0.30812,
            "recall": 0.5095,
            "fmeasure": 0.38301
        },
        "rougeLsum": {
            "precision": 0.30812,
            "recall": 0.5095,
            "fmeasure": 0.38301
        },
        "bleu": 25.30619,
        "nubia": {
            "semantic_relation": 3.51009,
            "contradiction": 11.14305,
            "irrelevancy": 87.82588,
            "logical_agreement": 1.03107,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.8948,
            "nubia_score": 0.46792
        },
        "bleurt": -0.47056,
        "meteor": 0.3654990727007859,
        "bertscore": {
            "precision": 0.86061,
            "recall": 0.93146,
            "f1": 0.89438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 14.857142857142858,
        "std_pred_length": 6.243363823832046,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.7019230769230769,
        "vocab_size-1": 73,
        "unique-1": 63,
        "entropy-1": 5.828602848304009,
        "distinct-2": 0.9278350515463918,
        "vocab_size-2": 90,
        "unique-2": 85,
        "entropy-2": 6.434964388578891,
        "cond_entropy-2": 0.4666849798053548,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 85,
        "unique-3": 80,
        "entropy-3": 6.380741985218552,
        "cond_entropy-3": -0.06361530141300877,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 5.010193690500052,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8045977011494253,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.896854127982899,
        "distinct-2-nopunct": 0.9625,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.246928094887358,
        "cond_entropy-2-nopunct": 0.37285678659272053,
        "distinct-3-nopunct": 0.9863013698630136,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.162427298606055,
        "cond_entropy-3-nopunct": -0.10470627573337266,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.5185185185185185,
            "3": 0.5538461538461539
        },
        "nist": 4.1637774021881215,
        "rouge1": {
            "precision": 0.63217,
            "recall": 0.58508,
            "fmeasure": 0.58883
        },
        "rouge2": {
            "precision": 0.37524,
            "recall": 0.3777,
            "fmeasure": 0.36349
        },
        "rougeL": {
            "precision": 0.51721,
            "recall": 0.51551,
            "fmeasure": 0.49625
        },
        "rougeLsum": {
            "precision": 0.51721,
            "recall": 0.51551,
            "fmeasure": 0.49625
        },
        "bleu": 27.46676,
        "nubia": {
            "semantic_relation": 3.86117,
            "contradiction": 12.61847,
            "irrelevancy": 45.21109,
            "logical_agreement": 42.17043,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.61173,
            "nubia_score": 0.62214
        },
        "bleurt": 0.08725,
        "meteor": 0.3003194742967533,
        "bertscore": {
            "precision": 0.90422,
            "recall": 0.89758,
            "f1": 0.89952
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.725,
        "total_length": 338,
        "mean_pred_length": 15.363636363636363,
        "std_pred_length": 5.29618605950164,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.5739644970414202,
        "vocab_size-1": 194,
        "unique-1": 151,
        "entropy-1": 6.921971937218485,
        "distinct-2": 0.8860759493670886,
        "vocab_size-2": 280,
        "unique-2": 255,
        "entropy-2": 8.042295968167345,
        "cond_entropy-2": 0.9497461925996142,
        "distinct-3": 0.9591836734693877,
        "vocab_size-3": 282,
        "unique-3": 271,
        "entropy-3": 8.11547204720991,
        "cond_entropy-3": 0.06976715951219874,
        "total_length-nopunct": 293,
        "mean_pred_length-nopunct": 13.318181818181818,
        "std_pred_length-nopunct": 4.780513129897665,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6416382252559727,
        "vocab_size-1-nopunct": 188,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 7.041438090663077,
        "distinct-2-nopunct": 0.8929889298892989,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 223,
        "entropy-2-nopunct": 7.831690358767389,
        "cond_entropy-2-nopunct": 0.8420351566645914,
        "distinct-3-nopunct": 0.9598393574297188,
        "vocab_size-3-nopunct": 239,
        "unique-3-nopunct": 230,
        "entropy-3-nopunct": 7.876648970212004,
        "cond_entropy-3-nopunct": 0.03995942877284488,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11904761904761904,
            "2": 0.16666666666666666,
            "3": 0.849802371541502
        },
        "nist": 6.497750360741156,
        "rouge1": {
            "precision": 0.84116,
            "recall": 0.83381,
            "fmeasure": 0.82584
        },
        "rouge2": {
            "precision": 0.68988,
            "recall": 0.67944,
            "fmeasure": 0.67425
        },
        "rougeL": {
            "precision": 0.77007,
            "recall": 0.75339,
            "fmeasure": 0.75131
        },
        "rougeLsum": {
            "precision": 0.77007,
            "recall": 0.75339,
            "fmeasure": 0.75131
        },
        "bleu": 60.0939,
        "nubia": {
            "semantic_relation": 4.42709,
            "contradiction": 2.36168,
            "irrelevancy": 22.72881,
            "logical_agreement": 74.90951,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.53595,
            "nubia_score": 0.79958
        },
        "bleurt": 0.43625,
        "meteor": 0.4695467088394109,
        "bertscore": {
            "precision": 0.9518,
            "recall": 0.94474,
            "f1": 0.94714
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.775,
        "total_length": 252,
        "mean_pred_length": 18.0,
        "std_pred_length": 3.835920452027872,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 162,
        "unique-1": 140,
        "entropy-1": 6.692746573393073,
        "distinct-2": 0.9537815126050421,
        "vocab_size-2": 227,
        "unique-2": 219,
        "entropy-2": 7.7908056309459575,
        "cond_entropy-2": 0.9880640770474134,
        "distinct-3": 1.0,
        "vocab_size-3": 224,
        "unique-3": 224,
        "entropy-3": 7.807354922057568,
        "cond_entropy-3": 0.018585763670033194,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.585685828003181,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7008928571428571,
        "vocab_size-1-nopunct": 157,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.770097388516913,
        "distinct-2-nopunct": 0.9571428571428572,
        "vocab_size-2-nopunct": 201,
        "unique-2-nopunct": 195,
        "entropy-2-nopunct": 7.615412720036761,
        "cond_entropy-2-nopunct": 0.8778301815773109,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 196,
        "unique-3-nopunct": 196,
        "entropy-3-nopunct": 7.614709844115192,
        "cond_entropy-3-nopunct": 0.0012545688070627631,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15517241379310345,
            "2": 0.37209302325581395,
            "3": 0.781021897810219
        },
        "nist": 5.205941101207826,
        "rouge1": {
            "precision": 0.66675,
            "recall": 0.68593,
            "fmeasure": 0.67143
        },
        "rouge2": {
            "precision": 0.42382,
            "recall": 0.46336,
            "fmeasure": 0.43934
        },
        "rougeL": {
            "precision": 0.56169,
            "recall": 0.60011,
            "fmeasure": 0.57619
        },
        "rougeLsum": {
            "precision": 0.56169,
            "recall": 0.60011,
            "fmeasure": 0.57619
        },
        "bleu": 38.34446,
        "nubia": {
            "semantic_relation": 4.07053,
            "contradiction": 5.67796,
            "irrelevancy": 43.91096,
            "logical_agreement": 50.41109,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.49857,
            "nubia_score": 0.69245
        },
        "bleurt": 0.12567,
        "meteor": 0.3700622630875795,
        "bertscore": {
            "precision": 0.91067,
            "recall": 0.91487,
            "f1": 0.91175
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.61,
        "msttr-100_nopunct": NaN,
        "total_length": 115,
        "mean_pred_length": 14.375,
        "std_pred_length": 4.922842166878804,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.5565217391304348,
        "vocab_size-1": 64,
        "unique-1": 47,
        "entropy-1": 5.561788721331857,
        "distinct-2": 0.7850467289719626,
        "vocab_size-2": 84,
        "unique-2": 72,
        "entropy-2": 6.20305913149986,
        "cond_entropy-2": 0.5129490142511971,
        "distinct-3": 0.8383838383838383,
        "vocab_size-3": 83,
        "unique-3": 73,
        "entropy-3": 6.245518236241234,
        "cond_entropy-3": 0.06576478998590526,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 12.375,
        "std_pred_length-nopunct": 3.7728470681966426,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6262626262626263,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.623036893762036,
        "distinct-2-nopunct": 0.7582417582417582,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 5.87472166795214,
        "cond_entropy-2-nopunct": 0.2926587271093742,
        "distinct-3-nopunct": 0.8072289156626506,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 5.8690153349613885,
        "cond_entropy-3-nopunct": 0.031216363129395033,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.9135802469135802
        },
        "nist": 5.272784413110787,
        "rouge1": {
            "precision": 0.81829,
            "recall": 0.85197,
            "fmeasure": 0.82594
        },
        "rouge2": {
            "precision": 0.70614,
            "recall": 0.71306,
            "fmeasure": 0.70588
        },
        "rougeL": {
            "precision": 0.78356,
            "recall": 0.80236,
            "fmeasure": 0.78865
        },
        "rougeLsum": {
            "precision": 0.78356,
            "recall": 0.80236,
            "fmeasure": 0.78865
        },
        "bleu": 64.05975,
        "nubia": {
            "semantic_relation": 4.57497,
            "contradiction": 0.32234,
            "irrelevancy": 21.67004,
            "logical_agreement": 78.00763,
            "grammar_ref": 5.07225,
            "grammar_hyp": 4.82507,
            "nubia_score": 0.90914
        },
        "bleurt": 0.66404,
        "meteor": 0.5271159939514305,
        "bertscore": {
            "precision": 0.95033,
            "recall": 0.96603,
            "f1": 0.95751
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.84375,
        "vocab_size-1": 27,
        "unique-1": 23,
        "entropy-1": 4.663909765557392,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.1597226789658904,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8846153846153846,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.46967048737186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.13452278258006412,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3333333333333333,
            "3": 0.9411764705882353
        },
        "nist": 3.6760290767777293,
        "rouge1": {
            "precision": 0.66944,
            "recall": 0.80714,
            "fmeasure": 0.72849
        },
        "rouge2": {
            "precision": 0.45779,
            "recall": 0.58761,
            "fmeasure": 0.50953
        },
        "rougeL": {
            "precision": 0.63611,
            "recall": 0.7696,
            "fmeasure": 0.69318
        },
        "rougeLsum": {
            "precision": 0.63611,
            "recall": 0.7696,
            "fmeasure": 0.69318
        },
        "bleu": 41.92883,
        "nubia": {
            "semantic_relation": 4.29476,
            "contradiction": 2.48851,
            "irrelevancy": 29.54101,
            "logical_agreement": 67.97048,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.48366,
            "nubia_score": 0.76835
        },
        "bleurt": 0.41962,
        "meteor": 0.46850701031527003,
        "bertscore": {
            "precision": 0.90257,
            "recall": 0.92561,
            "f1": 0.91393
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.745,
        "total_length": 230,
        "mean_pred_length": 17.692307692307693,
        "std_pred_length": 4.6473253744594505,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.6,
        "vocab_size-1": 138,
        "unique-1": 108,
        "entropy-1": 6.553361085592593,
        "distinct-2": 0.9400921658986175,
        "vocab_size-2": 204,
        "unique-2": 196,
        "entropy-2": 7.618143787841894,
        "cond_entropy-2": 0.9205060212066031,
        "distinct-3": 0.9901960784313726,
        "vocab_size-3": 202,
        "unique-3": 201,
        "entropy-3": 7.649117069902068,
        "cond_entropy-3": 0.0069997981271968605,
        "total_length-nopunct": 203,
        "mean_pred_length-nopunct": 15.615384615384615,
        "std_pred_length-nopunct": 3.873747172927437,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6600985221674877,
        "vocab_size-1-nopunct": 134,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 6.62166761794281,
        "distinct-2-nopunct": 0.9578947368421052,
        "vocab_size-2-nopunct": 182,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.462673882138326,
        "cond_entropy-2-nopunct": 0.8599636515928133,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 177,
        "unique-3-nopunct": 177,
        "entropy-3-nopunct": 7.46760555008301,
        "cond_entropy-3-nopunct": -0.026550941344344887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14084507042253522,
            "2": 0.49056603773584906,
            "3": 0.7063492063492064
        },
        "nist": 4.897909818144215,
        "rouge1": {
            "precision": 0.65836,
            "recall": 0.67218,
            "fmeasure": 0.65255
        },
        "rouge2": {
            "precision": 0.38222,
            "recall": 0.38146,
            "fmeasure": 0.37523
        },
        "rougeL": {
            "precision": 0.54593,
            "recall": 0.5638,
            "fmeasure": 0.54466
        },
        "rougeLsum": {
            "precision": 0.54593,
            "recall": 0.5638,
            "fmeasure": 0.54466
        },
        "bleu": 34.07148,
        "nubia": {
            "semantic_relation": 3.72846,
            "contradiction": 35.39753,
            "irrelevancy": 40.95795,
            "logical_agreement": 23.64452,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.51902,
            "nubia_score": 0.56735
        },
        "bleurt": 0.06937,
        "meteor": 0.34225831374484156,
        "bertscore": {
            "precision": 0.9013,
            "recall": 0.90465,
            "f1": 0.90203
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 4.642796092394706,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.7959183673469388,
        "vocab_size-1": 39,
        "unique-1": 34,
        "entropy-1": 5.10950805835677,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.3436347206374565,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.09729720135491506,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.7416573867739413,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8809523809523809,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.106603137064476,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.2007771037757959,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5625,
            "3": 0.9333333333333333
        },
        "nist": 3.562014234696254,
        "rouge1": {
            "precision": 0.59954,
            "recall": 0.65772,
            "fmeasure": 0.6157
        },
        "rouge2": {
            "precision": 0.3451,
            "recall": 0.4,
            "fmeasure": 0.36543
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.59712,
            "fmeasure": 0.56972
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.59712,
            "fmeasure": 0.56972
        },
        "bleu": 41.19035,
        "nubia": {
            "semantic_relation": 3.5629,
            "contradiction": 3.60109,
            "irrelevancy": 65.01859,
            "logical_agreement": 31.38032,
            "grammar_ref": 4.86076,
            "grammar_hyp": 4.24975,
            "nubia_score": 0.61564
        },
        "bleurt": 0.16462,
        "meteor": 0.4006241563618232,
        "bertscore": {
            "precision": 0.89812,
            "recall": 0.91269,
            "f1": 0.90488
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "total_length": 112,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.111359122659224,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.7053571428571429,
        "vocab_size-1": 79,
        "unique-1": 64,
        "entropy-1": 6.019134610115686,
        "distinct-2": 0.9619047619047619,
        "vocab_size-2": 101,
        "unique-2": 97,
        "entropy-2": 6.638055041475637,
        "cond_entropy-2": 0.5513766381138239,
        "distinct-3": 0.9693877551020408,
        "vocab_size-3": 95,
        "unique-3": 92,
        "entropy-3": 6.5534853543193,
        "cond_entropy-3": -0.07912751028560795,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 14.285714285714286,
        "std_pred_length-nopunct": 6.922309394048981,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 6.032243595187434,
        "distinct-2-nopunct": 0.956989247311828,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.453137305731694,
        "cond_entropy-2-nopunct": 0.44542369078201854,
        "distinct-3-nopunct": 0.9651162790697675,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.3564973128416336,
        "cond_entropy-3-nopunct": -0.08963824245244507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.3125,
            "3": 0.8354430379746836
        },
        "nist": 5.65137573732107,
        "rouge1": {
            "precision": 0.85431,
            "recall": 0.84917,
            "fmeasure": 0.84825
        },
        "rouge2": {
            "precision": 0.71091,
            "recall": 0.70721,
            "fmeasure": 0.70658
        },
        "rougeL": {
            "precision": 0.82634,
            "recall": 0.82251,
            "fmeasure": 0.82154
        },
        "rougeLsum": {
            "precision": 0.82634,
            "recall": 0.82251,
            "fmeasure": 0.82154
        },
        "bleu": 58.84195,
        "nubia": {
            "semantic_relation": 4.3937,
            "contradiction": 3.21833,
            "irrelevancy": 22.32161,
            "logical_agreement": 74.46006,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.85709,
            "nubia_score": 0.79064
        },
        "bleurt": 0.50557,
        "meteor": 0.4352545426559337,
        "bertscore": {
            "precision": 0.96407,
            "recall": 0.95804,
            "f1": 0.96091
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 72,
        "mean_pred_length": 14.4,
        "std_pred_length": 3.3823069050575527,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.75,
        "vocab_size-1": 54,
        "unique-1": 43,
        "entropy-1": 5.54326645312615,
        "distinct-2": 0.9701492537313433,
        "vocab_size-2": 65,
        "unique-2": 63,
        "entropy-2": 6.006387697920453,
        "cond_entropy-2": 0.33660859206511584,
        "distinct-3": 1.0,
        "vocab_size-3": 62,
        "unique-3": 62,
        "entropy-3": 5.954196310386873,
        "cond_entropy-3": -0.04737675103863909,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.4641016151377544,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.537602043731121,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 56,
        "entropy-2-nopunct": 5.84022392894185,
        "cond_entropy-2-nopunct": 0.34301903265217976,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 55,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.7813597135246555,
        "cond_entropy-3-nopunct": -0.052803609356586054,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.4666666666666667,
            "3": 0.6964285714285714
        },
        "nist": 4.617290138263264,
        "rouge1": {
            "precision": 0.79509,
            "recall": 0.6544,
            "fmeasure": 0.71148
        },
        "rouge2": {
            "precision": 0.52651,
            "recall": 0.45432,
            "fmeasure": 0.48337
        },
        "rougeL": {
            "precision": 0.63926,
            "recall": 0.53948,
            "fmeasure": 0.5801
        },
        "rougeLsum": {
            "precision": 0.63926,
            "recall": 0.53948,
            "fmeasure": 0.5801
        },
        "bleu": 40.53016,
        "nubia": {
            "semantic_relation": 4.27278,
            "contradiction": 0.37654,
            "irrelevancy": 29.35755,
            "logical_agreement": 70.26591,
            "grammar_ref": 4.74509,
            "grammar_hyp": 5.15699,
            "nubia_score": 0.70604
        },
        "bleurt": 0.24889,
        "meteor": 0.35825542623670426,
        "bertscore": {
            "precision": 0.93867,
            "recall": 0.90414,
            "f1": 0.92091
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 117,
        "mean_pred_length": 19.5,
        "std_pred_length": 5.024937810560445,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 81,
        "unique-1": 71,
        "entropy-1": 5.9415759118876785,
        "distinct-2": 0.9819819819819819,
        "vocab_size-2": 109,
        "unique-2": 107,
        "entropy-2": 6.758379830314085,
        "cond_entropy-2": 0.7338594803209291,
        "distinct-3": 1.0,
        "vocab_size-3": 105,
        "unique-3": 105,
        "entropy-3": 6.714245517666113,
        "cond_entropy-3": -0.04207511058874547,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 15.833333333333334,
        "std_pred_length-nopunct": 4.058598553961973,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8105263157894737,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.016915345036413,
        "distinct-2-nopunct": 0.9887640449438202,
        "vocab_size-2-nopunct": 88,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 6.45326152085405,
        "cond_entropy-2-nopunct": 0.4736230475004021,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.375039431346932,
        "cond_entropy-3-nopunct": -0.0765976140773044,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.3617021276595745,
            "3": 0.9032258064516129
        },
        "nist": 5.034973365279129,
        "rouge1": {
            "precision": 0.85651,
            "recall": 0.72846,
            "fmeasure": 0.77624
        },
        "rouge2": {
            "precision": 0.53283,
            "recall": 0.47291,
            "fmeasure": 0.49619
        },
        "rougeL": {
            "precision": 0.65025,
            "recall": 0.55567,
            "fmeasure": 0.59092
        },
        "rougeLsum": {
            "precision": 0.65025,
            "recall": 0.55567,
            "fmeasure": 0.59092
        },
        "bleu": 47.21014,
        "nubia": {
            "semantic_relation": 4.12583,
            "contradiction": 5.23132,
            "irrelevancy": 29.33416,
            "logical_agreement": 65.43451,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.75462,
            "nubia_score": 0.69108
        },
        "bleurt": 0.23234,
        "meteor": 0.3864591808484317,
        "bertscore": {
            "precision": 0.95016,
            "recall": 0.92863,
            "f1": 0.9389
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.74,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.74,
        "vocab_size-1": 74,
        "unique-1": 59,
        "entropy-1": 5.988598315421431,
        "distinct-2": 0.9893617021276596,
        "vocab_size-2": 93,
        "unique-2": 92,
        "entropy-2": 6.533312255932943,
        "cond_entropy-2": 0.46303209765709974,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": -0.0724299603130677,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 14.833333333333334,
        "std_pred_length-nopunct": 3.3870669054835956,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7752808988764045,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.91487784713614,
        "distinct-2-nopunct": 0.9879518072289156,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.350943045804763,
        "cond_entropy-2-nopunct": 0.47660897581298073,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.266786540694905,
        "cond_entropy-3-nopunct": -0.08227886467799743,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.20833333333333334,
            "3": 0.7692307692307693
        },
        "nist": 5.4385882230659055,
        "rouge1": {
            "precision": 0.84377,
            "recall": 0.7297,
            "fmeasure": 0.77842
        },
        "rouge2": {
            "precision": 0.66818,
            "recall": 0.57811,
            "fmeasure": 0.6166
        },
        "rougeL": {
            "precision": 0.76559,
            "recall": 0.66284,
            "fmeasure": 0.70686
        },
        "rougeLsum": {
            "precision": 0.76559,
            "recall": 0.66284,
            "fmeasure": 0.70686
        },
        "bleu": 63.03798,
        "nubia": {
            "semantic_relation": 3.86367,
            "contradiction": 17.26465,
            "irrelevancy": 22.22917,
            "logical_agreement": 60.50618,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.43178,
            "nubia_score": 0.63422
        },
        "bleurt": 0.10848,
        "meteor": 0.403821010168306,
        "bertscore": {
            "precision": 0.9447,
            "recall": 0.93024,
            "f1": 0.93735
        }
    },
    "web_nlg_en_test": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 1779,
        "msttr-100": 0.65947,
        "msttr-100_nopunct": 0.68546,
        "total_length": 33976,
        "mean_pred_length": 19.098369870713885,
        "std_pred_length": 6.449082154590985,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.056834235931245584,
        "vocab_size-1": 1931,
        "unique-1": 630,
        "entropy-1": 8.132101098355058,
        "distinct-2": 0.20930521477156258,
        "vocab_size-2": 6739,
        "unique-2": 3345,
        "entropy-2": 11.256747679998275,
        "cond_entropy-2": 3.0751562266545927,
        "distinct-3": 0.3796107567887435,
        "vocab_size-3": 11547,
        "unique-3": 7204,
        "entropy-3": 12.503118598437434,
        "cond_entropy-3": 1.3548381380425982,
        "total_length-nopunct": 30653,
        "mean_pred_length-nopunct": 17.230466554243957,
        "std_pred_length-nopunct": 6.122485429283857,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.06266923302776237,
        "vocab_size-1-nopunct": 1921,
        "unique-1-nopunct": 629,
        "entropy-1-nopunct": 8.331650250107902,
        "distinct-2-nopunct": 0.22054443443928795,
        "vocab_size-2-nopunct": 6368,
        "unique-2-nopunct": 3340,
        "entropy-2-nopunct": 11.149541311538368,
        "cond_entropy-2-nopunct": 3.002620017762214,
        "distinct-3-nopunct": 0.38940763978593834,
        "vocab_size-3-nopunct": 10551,
        "unique-3-nopunct": 6780,
        "entropy-3-nopunct": 12.344799377343758,
        "cond_entropy-3-nopunct": 1.302864691651408,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18939698204142522,
            "2": 0.4940273866174614,
            "3": 0.7353333333333333,
            "4": 0.8909090909090909,
            "5": 0.6896551724137931
        },
        "nist": 6.88488270271856,
        "rouge1": {
            "precision": 0.77122,
            "recall": 0.67334,
            "fmeasure": 0.70592
        },
        "rouge2": {
            "precision": 0.51504,
            "recall": 0.44792,
            "fmeasure": 0.46918
        },
        "rougeL": {
            "precision": 0.63695,
            "recall": 0.55802,
            "fmeasure": 0.58372
        },
        "rougeLsum": {
            "precision": 0.63695,
            "recall": 0.55802,
            "fmeasure": 0.58372
        },
        "bleu": 39.02247,
        "nubia": {
            "semantic_relation": 4.11359,
            "contradiction": 7.99296,
            "irrelevancy": 10.00005,
            "logical_agreement": 82.00699,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.82165,
            "nubia_score": 0.66725
        },
        "bleurt": 0.02939,
        "meteor": 0.32380331966371717,
        "bertscore": {
            "precision": 0.9194,
            "recall": 0.89881,
            "f1": 0.90742
        }
    },
    "web_nlg_en_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_challenge_train_sample",
        "N": 502
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 9,
        "unique-1": 7,
        "entropy-1": 3.0957952550009344,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.262496476250065,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.9219280948873623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.29244135099939467,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.5175220807009246,
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.93939,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.63333,
            "recall": 0.80476,
            "fmeasure": 0.70392
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73365
        },
        "bleu": 60.76796,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.25117,
            "irrelevancy": 30.21179,
            "logical_agreement": 69.53704,
            "grammar_ref": 3.38649,
            "grammar_hyp": 2.86426,
            "nubia_score": 0.97277
        },
        "bleurt": 0.67878,
        "meteor": 0.4912092865802179,
        "bertscore": {
            "precision": 0.95103,
            "recall": 0.96123,
            "f1": 0.95272
        }
    },
    "web_nlg_en_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_challenge_validation_sample",
        "N": 499
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.76,
        "total_length": 120,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.278719262151,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.6916666666666667,
        "vocab_size-1": 83,
        "unique-1": 69,
        "entropy-1": 6.035679450241991,
        "distinct-2": 0.9196428571428571,
        "vocab_size-2": 103,
        "unique-2": 94,
        "entropy-2": 6.646640636343308,
        "cond_entropy-2": 0.4589048393418037,
        "distinct-3": 0.9519230769230769,
        "vocab_size-3": 99,
        "unique-3": 94,
        "entropy-3": 6.604285871987253,
        "cond_entropy-3": -0.04922289622420451,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 12.875,
        "std_pred_length-nopunct": 2.315032397181517,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7669902912621359,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.042998828760958,
        "distinct-2-nopunct": 0.9157894736842105,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.401434555699368,
        "cond_entropy-2-nopunct": 0.39157271206871763,
        "distinct-3-nopunct": 0.9540229885057471,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.350989472860218,
        "cond_entropy-3-nopunct": -0.057946595240840275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.4857142857142857,
            "3": 0.8840579710144928
        },
        "nist": 5.853333514882811,
        "rouge1": {
            "precision": 0.79162,
            "recall": 0.78635,
            "fmeasure": 0.78404
        },
        "rouge2": {
            "precision": 0.58359,
            "recall": 0.59458,
            "fmeasure": 0.58512
        },
        "rougeL": {
            "precision": 0.71064,
            "recall": 0.70926,
            "fmeasure": 0.70467
        },
        "rougeLsum": {
            "precision": 0.71064,
            "recall": 0.70926,
            "fmeasure": 0.70467
        },
        "bleu": 53.33551,
        "nubia": {
            "semantic_relation": 4.22623,
            "contradiction": 15.54229,
            "irrelevancy": 28.06713,
            "logical_agreement": 56.39059,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.48545,
            "nubia_score": 0.75311
        },
        "bleurt": 0.32758,
        "meteor": 0.4580118119866218,
        "bertscore": {
            "precision": 0.93894,
            "recall": 0.95593,
            "f1": 0.94426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.77667,
        "msttr-100_nopunct": 0.845,
        "total_length": 310,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.964876634922564,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6483870967741936,
        "vocab_size-1": 201,
        "unique-1": 162,
        "entropy-1": 7.170049065388352,
        "distinct-2": 0.9689655172413794,
        "vocab_size-2": 281,
        "unique-2": 272,
        "entropy-2": 8.117840124497691,
        "cond_entropy-2": 0.7402942368388649,
        "distinct-3": 0.9851851851851852,
        "vocab_size-3": 266,
        "unique-3": 262,
        "entropy-3": 8.047185967421214,
        "cond_entropy-3": -0.06605645592706681,
        "total_length-nopunct": 266,
        "mean_pred_length-nopunct": 13.3,
        "std_pred_length-nopunct": 4.371498598878879,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7255639097744361,
        "vocab_size-1-nopunct": 193,
        "unique-1-nopunct": 160,
        "entropy-1-nopunct": 7.287917830974242,
        "distinct-2-nopunct": 0.967479674796748,
        "vocab_size-2-nopunct": 238,
        "unique-2-nopunct": 230,
        "entropy-2-nopunct": 7.8774738549327745,
        "cond_entropy-2-nopunct": 0.6455004531854395,
        "distinct-3-nopunct": 0.9823008849557522,
        "vocab_size-3-nopunct": 222,
        "unique-3-nopunct": 218,
        "entropy-3-nopunct": 7.784780732326718,
        "cond_entropy-3-nopunct": -0.08693731283555643,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.45454545454545453,
            "3": 0.8009708737864077
        },
        "nist": 6.3473706134670875,
        "rouge1": {
            "precision": 0.78198,
            "recall": 0.7289,
            "fmeasure": 0.74327
        },
        "rouge2": {
            "precision": 0.55743,
            "recall": 0.53571,
            "fmeasure": 0.53592
        },
        "rougeL": {
            "precision": 0.71503,
            "recall": 0.66868,
            "fmeasure": 0.67971
        },
        "rougeLsum": {
            "precision": 0.71503,
            "recall": 0.66868,
            "fmeasure": 0.67971
        },
        "bleu": 49.20354,
        "nubia": {
            "semantic_relation": 4.44517,
            "contradiction": 10.27398,
            "irrelevancy": 22.87972,
            "logical_agreement": 66.84629,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.79233,
            "nubia_score": 0.77664
        },
        "bleurt": 0.38944,
        "meteor": 0.4176242512899059,
        "bertscore": {
            "precision": 0.94171,
            "recall": 0.93291,
            "f1": 0.9336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.76,
        "total_length": 223,
        "mean_pred_length": 15.928571428571429,
        "std_pred_length": 5.202530781322899,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5964125560538116,
        "vocab_size-1": 133,
        "unique-1": 105,
        "entropy-1": 6.480171434813072,
        "distinct-2": 0.9234449760765551,
        "vocab_size-2": 193,
        "unique-2": 181,
        "entropy-2": 7.539801476537101,
        "cond_entropy-2": 0.9326953455653888,
        "distinct-3": 0.9897435897435898,
        "vocab_size-3": 193,
        "unique-3": 191,
        "entropy-3": 7.586817493236827,
        "cond_entropy-3": 0.05904579709772229,
        "total_length-nopunct": 195,
        "mean_pred_length-nopunct": 13.928571428571429,
        "std_pred_length-nopunct": 5.444056860654636,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6615384615384615,
        "vocab_size-1-nopunct": 129,
        "unique-1-nopunct": 103,
        "entropy-1-nopunct": 6.590920422460129,
        "distinct-2-nopunct": 0.9281767955801105,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 158,
        "entropy-2-nopunct": 7.343687530693728,
        "cond_entropy-2-nopunct": 0.8060531633570277,
        "distinct-3-nopunct": 0.9880239520958084,
        "vocab_size-3-nopunct": 165,
        "unique-3-nopunct": 163,
        "entropy-3-nopunct": 7.359752196665645,
        "cond_entropy-3-nopunct": 0.023167761717136484,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5681818181818182,
            "3": 0.8357142857142857
        },
        "nist": 6.214123192959876,
        "rouge1": {
            "precision": 0.8432,
            "recall": 0.8075,
            "fmeasure": 0.81852
        },
        "rouge2": {
            "precision": 0.6975,
            "recall": 0.67293,
            "fmeasure": 0.68056
        },
        "rougeL": {
            "precision": 0.74729,
            "recall": 0.72679,
            "fmeasure": 0.7309
        },
        "rougeLsum": {
            "precision": 0.74729,
            "recall": 0.72679,
            "fmeasure": 0.7309
        },
        "bleu": 58.34201,
        "nubia": {
            "semantic_relation": 4.42144,
            "contradiction": 1.52573,
            "irrelevancy": 24.03886,
            "logical_agreement": 74.43541,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.89655,
            "nubia_score": 0.80643
        },
        "bleurt": 0.45045,
        "meteor": 0.4460269139043898,
        "bertscore": {
            "precision": 0.95413,
            "recall": 0.94783,
            "f1": 0.94872
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.77,
        "total_length": 135,
        "mean_pred_length": 16.875,
        "std_pred_length": 4.594493987372276,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6888888888888889,
        "vocab_size-1": 93,
        "unique-1": 79,
        "entropy-1": 6.1317820026779515,
        "distinct-2": 0.952755905511811,
        "vocab_size-2": 121,
        "unique-2": 117,
        "entropy-2": 6.878448466299709,
        "cond_entropy-2": 0.6408418081492141,
        "distinct-3": 0.9831932773109243,
        "vocab_size-3": 117,
        "unique-3": 115,
        "entropy-3": 6.861204317929792,
        "cond_entropy-3": -0.009833310018844174,
        "total_length-nopunct": 121,
        "mean_pred_length-nopunct": 15.125,
        "std_pred_length-nopunct": 4.567206476611277,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7355371900826446,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.112420797271783,
        "distinct-2-nopunct": 0.9557522123893806,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.713984272149719,
        "cond_entropy-2-nopunct": 0.649807187444493,
        "distinct-3-nopunct": 0.9809523809523809,
        "vocab_size-3-nopunct": 103,
        "unique-3-nopunct": 101,
        "entropy-3-nopunct": 6.676150279570875,
        "cond_entropy-3-nopunct": -0.03926677808239867,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.4166666666666667,
            "3": 0.704225352112676
        },
        "nist": 4.311537766778853,
        "rouge1": {
            "precision": 0.6937,
            "recall": 0.65631,
            "fmeasure": 0.66375
        },
        "rouge2": {
            "precision": 0.48106,
            "recall": 0.44845,
            "fmeasure": 0.45853
        },
        "rougeL": {
            "precision": 0.59874,
            "recall": 0.57237,
            "fmeasure": 0.57752
        },
        "rougeLsum": {
            "precision": 0.59874,
            "recall": 0.57237,
            "fmeasure": 0.57752
        },
        "bleu": 38.24765,
        "nubia": {
            "semantic_relation": 3.99278,
            "contradiction": 16.43852,
            "irrelevancy": 49.56727,
            "logical_agreement": 33.99421,
            "grammar_ref": 4.54831,
            "grammar_hyp": 4.23467,
            "nubia_score": 0.70342
        },
        "bleurt": 0.27984,
        "meteor": 0.30357606086071576,
        "bertscore": {
            "precision": 0.91058,
            "recall": 0.90863,
            "f1": 0.90723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 138,
        "mean_pred_length": 17.25,
        "std_pred_length": 4.322904116447646,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.6811594202898551,
        "vocab_size-1": 94,
        "unique-1": 81,
        "entropy-1": 6.125279235698079,
        "distinct-2": 0.9692307692307692,
        "vocab_size-2": 126,
        "unique-2": 123,
        "entropy-2": 6.955022524550275,
        "cond_entropy-2": 0.704328187061414,
        "distinct-3": 0.9918032786885246,
        "vocab_size-3": 121,
        "unique-3": 120,
        "entropy-3": 6.914343894939951,
        "cond_entropy-3": -0.03626254511996621,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.235268586524354,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7377049180327869,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.142392538343837,
        "distinct-2-nopunct": 0.9649122807017544,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 107,
        "entropy-2-nopunct": 6.756092755373845,
        "cond_entropy-2-nopunct": 0.6273131195878077,
        "distinct-3-nopunct": 0.9905660377358491,
        "vocab_size-3-nopunct": 105,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.709052530034882,
        "cond_entropy-3-nopunct": -0.05619668222944507,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19444444444444445,
            "2": 0.6666666666666666,
            "3": 0.821917808219178
        },
        "nist": 5.144655773862085,
        "rouge1": {
            "precision": 0.7291,
            "recall": 0.76956,
            "fmeasure": 0.74188
        },
        "rouge2": {
            "precision": 0.5124,
            "recall": 0.54949,
            "fmeasure": 0.52308
        },
        "rougeL": {
            "precision": 0.58961,
            "recall": 0.64137,
            "fmeasure": 0.60592
        },
        "rougeLsum": {
            "precision": 0.58961,
            "recall": 0.64137,
            "fmeasure": 0.60592
        },
        "bleu": 43.80124,
        "nubia": {
            "semantic_relation": 4.24321,
            "contradiction": 8.63645,
            "irrelevancy": 27.82451,
            "logical_agreement": 63.53904,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.48436,
            "nubia_score": 0.76729
        },
        "bleurt": 0.23254,
        "meteor": 0.40763967237651394,
        "bertscore": {
            "precision": 0.91307,
            "recall": 0.92911,
            "f1": 0.91892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.0,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.807009421281391,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.33185547416993433,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.707714802597437,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.9837880587523955,
        "cond_entropy-2-nopunct": 0.3016228449032888,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.02568167993932011,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "nist": 2.5947276449192223,
        "rouge1": {
            "precision": 0.56731,
            "recall": 0.48224,
            "fmeasure": 0.52069
        },
        "rouge2": {
            "precision": 0.28804,
            "recall": 0.23819,
            "fmeasure": 0.25993
        },
        "rougeL": {
            "precision": 0.43162,
            "recall": 0.3807,
            "fmeasure": 0.40267
        },
        "rougeLsum": {
            "precision": 0.43162,
            "recall": 0.3807,
            "fmeasure": 0.40267
        },
        "bleu": 20.73172,
        "nubia": {
            "semantic_relation": 3.44026,
            "contradiction": 2.2636,
            "irrelevancy": 25.24509,
            "logical_agreement": 72.49131,
            "grammar_ref": 4.82994,
            "grammar_hyp": 5.02545,
            "nubia_score": 0.47565
        },
        "bleurt": -0.3255,
        "meteor": 0.24655318908235574,
        "bertscore": {
            "precision": 0.8593,
            "recall": 0.84798,
            "f1": 0.85355
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 98,
        "mean_pred_length": 19.6,
        "std_pred_length": 6.681317235396026,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.6326530612244898,
        "vocab_size-1": 62,
        "unique-1": 48,
        "entropy-1": 5.529222125289242,
        "distinct-2": 0.9354838709677419,
        "vocab_size-2": 87,
        "unique-2": 81,
        "entropy-2": 6.41012655304352,
        "cond_entropy-2": 0.8881361599259581,
        "distinct-3": 0.9886363636363636,
        "vocab_size-3": 87,
        "unique-3": 86,
        "entropy-3": 6.436704345910033,
        "cond_entropy-3": 0.03390917116562971,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 5.932958789676531,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.604642371503493,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.196928094887357,
        "cond_entropy-2-nopunct": 0.6300825086735103,
        "distinct-3-nopunct": 0.9866666666666667,
        "vocab_size-3-nopunct": 74,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.202152023829224,
        "cond_entropy-3-nopunct": 0.013557262275185212,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3181818181818182,
            "2": 0.35714285714285715,
            "3": 0.7619047619047619
        },
        "nist": 5.04294662644574,
        "rouge1": {
            "precision": 0.76214,
            "recall": 0.7386,
            "fmeasure": 0.73932
        },
        "rouge2": {
            "precision": 0.5368,
            "recall": 0.52608,
            "fmeasure": 0.52346
        },
        "rougeL": {
            "precision": 0.71486,
            "recall": 0.68641,
            "fmeasure": 0.6901
        },
        "rougeLsum": {
            "precision": 0.71486,
            "recall": 0.68641,
            "fmeasure": 0.6901
        },
        "bleu": 51.57666,
        "nubia": {
            "semantic_relation": 4.0984,
            "contradiction": 5.65,
            "irrelevancy": 42.16002,
            "logical_agreement": 52.18997,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.18313,
            "nubia_score": 0.71649
        },
        "bleurt": 0.08849,
        "meteor": 0.40612437037602134,
        "bertscore": {
            "precision": 0.93024,
            "recall": 0.93049,
            "f1": 0.9283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.68,
        "total_length": 115,
        "mean_pred_length": 16.428571428571427,
        "std_pred_length": 4.271404682207444,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.6260869565217392,
        "vocab_size-1": 72,
        "unique-1": 54,
        "entropy-1": 5.803329429796869,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 100,
        "unique-2": 92,
        "entropy-2": 6.60673935401531,
        "cond_entropy-2": 0.7487851221154473,
        "distinct-3": 0.9405940594059405,
        "vocab_size-3": 95,
        "unique-3": 89,
        "entropy-3": 6.539399601563661,
        "cond_entropy-3": -0.05707205901563421,
        "total_length-nopunct": 104,
        "mean_pred_length-nopunct": 14.857142857142858,
        "std_pred_length-nopunct": 4.356557337707688,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6634615384615384,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.771312886572917,
        "distinct-2-nopunct": 0.9175257731958762,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.434964388578894,
        "cond_entropy-2-nopunct": 0.7143620723178863,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.3585197629963295,
        "cond_entropy-3-nopunct": -0.06361530141300877,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.42857142857142855,
            "3": 0.7
        },
        "nist": 5.087920354919375,
        "rouge1": {
            "precision": 0.76678,
            "recall": 0.67903,
            "fmeasure": 0.71671
        },
        "rouge2": {
            "precision": 0.58162,
            "recall": 0.54356,
            "fmeasure": 0.55652
        },
        "rougeL": {
            "precision": 0.68376,
            "recall": 0.62817,
            "fmeasure": 0.64703
        },
        "rougeLsum": {
            "precision": 0.68376,
            "recall": 0.62817,
            "fmeasure": 0.64703
        },
        "bleu": 46.51548,
        "nubia": {
            "semantic_relation": 4.15331,
            "contradiction": 14.17725,
            "irrelevancy": 42.87375,
            "logical_agreement": 42.949,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.85294,
            "nubia_score": 0.69131
        },
        "bleurt": 0.22012,
        "meteor": 0.4175072539824546,
        "bertscore": {
            "precision": 0.93752,
            "recall": 0.92738,
            "f1": 0.92829
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79,
        "total_length": 182,
        "mean_pred_length": 16.545454545454547,
        "std_pred_length": 6.315401611984875,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6208791208791209,
        "vocab_size-1": 113,
        "unique-1": 92,
        "entropy-1": 6.340476890934464,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 152,
        "unique-2": 136,
        "entropy-2": 7.182386652274837,
        "cond_entropy-2": 0.722735575919529,
        "distinct-3": 0.95,
        "vocab_size-3": 152,
        "unique-3": 144,
        "entropy-3": 7.2219280948873665,
        "cond_entropy-3": 0.05572972066702955,
        "total_length-nopunct": 161,
        "mean_pred_length-nopunct": 14.636363636363637,
        "std_pred_length-nopunct": 5.498309281831796,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6708074534161491,
        "vocab_size-1-nopunct": 108,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.36673955254182,
        "distinct-2-nopunct": 0.88,
        "vocab_size-2-nopunct": 132,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.973720940452598,
        "cond_entropy-2-nopunct": 0.6710210584527839,
        "distinct-3-nopunct": 0.9424460431654677,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 7.003833159054457,
        "cond_entropy-3-nopunct": 0.04310556572755757,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28125,
            "2": 0.5,
            "3": 0.926829268292683
        },
        "nist": 6.421133922529663,
        "rouge1": {
            "precision": 0.82869,
            "recall": 0.89107,
            "fmeasure": 0.85691
        },
        "rouge2": {
            "precision": 0.65733,
            "recall": 0.70672,
            "fmeasure": 0.67848
        },
        "rougeL": {
            "precision": 0.75454,
            "recall": 0.81815,
            "fmeasure": 0.78341
        },
        "rougeLsum": {
            "precision": 0.75454,
            "recall": 0.81815,
            "fmeasure": 0.78341
        },
        "bleu": 63.16596,
        "nubia": {
            "semantic_relation": 4.84586,
            "contradiction": 0.87267,
            "irrelevancy": 5.91242,
            "logical_agreement": 93.21491,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.14704,
            "nubia_score": 0.94776
        },
        "bleurt": 0.61227,
        "meteor": 0.497570484341808,
        "bertscore": {
            "precision": 0.96079,
            "recall": 0.96569,
            "f1": 0.96284
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 2.4944581430771797,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.44444,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "bleu": 27.37678,
        "nubia": {
            "semantic_relation": 4.0224,
            "contradiction": 3.76892,
            "irrelevancy": 1.17822,
            "logical_agreement": 95.05285,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.98587,
            "nubia_score": 0.57375
        },
        "bleurt": 0.64406,
        "meteor": 0.40853686369460246,
        "bertscore": {
            "precision": 0.94135,
            "recall": 0.93398,
            "f1": 0.93765
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 6.0,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.964904158123496,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.1651888075032675,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.923181998146335,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.0065763845768089385,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7931034482758621
        },
        "nist": 3.830653600806577,
        "rouge1": {
            "precision": 0.77715,
            "recall": 0.78099,
            "fmeasure": 0.77345
        },
        "rouge2": {
            "precision": 0.61087,
            "recall": 0.61915,
            "fmeasure": 0.60854
        },
        "rougeL": {
            "precision": 0.76326,
            "recall": 0.78607,
            "fmeasure": 0.76735
        },
        "rougeLsum": {
            "precision": 0.76326,
            "recall": 0.78607,
            "fmeasure": 0.76735
        },
        "bleu": 54.37934,
        "nubia": {
            "semantic_relation": 4.09061,
            "contradiction": 49.15458,
            "irrelevancy": 50.08538,
            "logical_agreement": 0.76004,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.4601,
            "nubia_score": 0.74323
        },
        "bleurt": 0.39738,
        "meteor": 0.4931036528691759,
        "bertscore": {
            "precision": 0.9468,
            "recall": 0.96026,
            "f1": 0.95321
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 18.25,
        "std_pred_length": 3.960744879438715,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.7123287671232876,
        "vocab_size-1": 52,
        "unique-1": 39,
        "entropy-1": 5.506614929004307,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 66,
        "unique-2": 63,
        "entropy-2": 6.021567935039034,
        "cond_entropy-2": 0.48564794831501784,
        "distinct-3": 0.9846153846153847,
        "vocab_size-3": 64,
        "unique-3": 63,
        "entropy-3": 5.991598582259227,
        "cond_entropy-3": -0.024618182211253073,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 16.25,
        "std_pred_length-nopunct": 3.344772040064913,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.506832812961889,
        "distinct-2-nopunct": 0.9508196721311475,
        "vocab_size-2-nopunct": 58,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.832376681825178,
        "cond_entropy-2-nopunct": 0.34295600001520143,
        "distinct-3-nopunct": 0.9824561403508771,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.797802294866491,
        "cond_entropy-3-nopunct": -0.027671884801653127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.9574468085106383
        },
        "nist": 5.743681583264472,
        "rouge1": {
            "precision": 0.82498,
            "recall": 0.89082,
            "fmeasure": 0.85112
        },
        "rouge2": {
            "precision": 0.71656,
            "recall": 0.79937,
            "fmeasure": 0.74722
        },
        "rougeL": {
            "precision": 0.76942,
            "recall": 0.86538,
            "fmeasure": 0.80521
        },
        "rougeLsum": {
            "precision": 0.76942,
            "recall": 0.86538,
            "fmeasure": 0.80521
        },
        "bleu": 71.77789,
        "nubia": {
            "semantic_relation": 4.63586,
            "contradiction": 8.78581,
            "irrelevancy": 28.11326,
            "logical_agreement": 63.10093,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.04398,
            "nubia_score": 0.88749
        },
        "bleurt": 0.61654,
        "meteor": 0.5484347591903083,
        "bertscore": {
            "precision": 0.96455,
            "recall": 0.97882,
            "f1": 0.96557
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.8,
        "total_length": 205,
        "mean_pred_length": 18.636363636363637,
        "std_pred_length": 4.354156369028381,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.6439024390243903,
        "vocab_size-1": 132,
        "unique-1": 108,
        "entropy-1": 6.526324412778538,
        "distinct-2": 0.979381443298969,
        "vocab_size-2": 190,
        "unique-2": 186,
        "entropy-2": 7.558675728785041,
        "cond_entropy-2": 0.9455234167334016,
        "distinct-3": 1.0,
        "vocab_size-3": 183,
        "unique-3": 183,
        "entropy-3": 7.5156998382840365,
        "cond_entropy-3": -0.05142611865718377,
        "total_length-nopunct": 183,
        "mean_pred_length-nopunct": 16.636363636363637,
        "std_pred_length-nopunct": 4.715019083596342,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6994535519125683,
        "vocab_size-1-nopunct": 128,
        "unique-1-nopunct": 108,
        "entropy-1-nopunct": 6.5575672385405825,
        "distinct-2-nopunct": 0.9825581395348837,
        "vocab_size-2-nopunct": 169,
        "unique-2-nopunct": 166,
        "entropy-2-nopunct": 7.391381033771834,
        "cond_entropy-2-nopunct": 0.87764785684278,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 161,
        "unique-3-nopunct": 161,
        "entropy-3-nopunct": 7.330916878114602,
        "cond_entropy-3-nopunct": -0.058080795842139245,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1388888888888889,
            "2": 0.56,
            "3": 0.7446808510638298
        },
        "nist": 5.62186363010458,
        "rouge1": {
            "precision": 0.70708,
            "recall": 0.7296,
            "fmeasure": 0.70787
        },
        "rouge2": {
            "precision": 0.49477,
            "recall": 0.48355,
            "fmeasure": 0.48274
        },
        "rougeL": {
            "precision": 0.60293,
            "recall": 0.59832,
            "fmeasure": 0.59246
        },
        "rougeLsum": {
            "precision": 0.60293,
            "recall": 0.59832,
            "fmeasure": 0.59246
        },
        "bleu": 43.66653,
        "nubia": {
            "semantic_relation": 4.2492,
            "contradiction": 2.74271,
            "irrelevancy": 42.43315,
            "logical_agreement": 54.82414,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.69872,
            "nubia_score": 0.73041
        },
        "bleurt": 0.11205,
        "meteor": 0.3828544745601578,
        "bertscore": {
            "precision": 0.91876,
            "recall": 0.92507,
            "f1": 0.92117
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 11.6,
        "std_pred_length": 5.351635264103861,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.7931034482758621,
        "vocab_size-1": 46,
        "unique-1": 40,
        "entropy-1": 5.334454650703428,
        "distinct-2": 0.9811320754716981,
        "vocab_size-2": 52,
        "unique-2": 51,
        "entropy-2": 5.690184605506591,
        "cond_entropy-2": 0.1860694123066361,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.10129128717537642,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 4.33589667773576,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.84,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.2687584397314575,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.447408651885229,
        "cond_entropy-2-nopunct": 0.22032773993636018,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.11992500144231243,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "nist": 4.976196591102064,
        "rouge1": {
            "precision": 0.8219,
            "recall": 0.79404,
            "fmeasure": 0.80202
        },
        "rouge2": {
            "precision": 0.62106,
            "recall": 0.5922,
            "fmeasure": 0.60133
        },
        "rougeL": {
            "precision": 0.76013,
            "recall": 0.73992,
            "fmeasure": 0.74531
        },
        "rougeLsum": {
            "precision": 0.76013,
            "recall": 0.73992,
            "fmeasure": 0.74531
        },
        "bleu": 51.78105,
        "nubia": {
            "semantic_relation": 4.25503,
            "contradiction": 6.78706,
            "irrelevancy": 32.90872,
            "logical_agreement": 60.30422,
            "grammar_ref": 5.12632,
            "grammar_hyp": 5.39777,
            "nubia_score": 0.71634
        },
        "bleurt": 0.45847,
        "meteor": 0.43673725720047313,
        "bertscore": {
            "precision": 0.95861,
            "recall": 0.95054,
            "f1": 0.95441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.7275,
        "msttr-100_nopunct": 0.795,
        "total_length": 489,
        "mean_pred_length": 15.774193548387096,
        "std_pred_length": 5.2714059911781925,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.5807770961145194,
        "vocab_size-1": 284,
        "unique-1": 228,
        "entropy-1": 7.374704521803476,
        "distinct-2": 0.9279475982532751,
        "vocab_size-2": 425,
        "unique-2": 398,
        "entropy-2": 8.682272995562185,
        "cond_entropy-2": 1.1131047913363779,
        "distinct-3": 0.9765807962529274,
        "vocab_size-3": 417,
        "unique-3": 407,
        "entropy-3": 8.691253852126346,
        "cond_entropy-3": 0.01569011784890282,
        "total_length-nopunct": 425,
        "mean_pred_length-nopunct": 13.709677419354838,
        "std_pred_length-nopunct": 4.813914967601377,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6564705882352941,
        "vocab_size-1-nopunct": 279,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.5947517451495035,
        "distinct-2-nopunct": 0.9441624365482234,
        "vocab_size-2-nopunct": 372,
        "unique-2-nopunct": 354,
        "entropy-2-nopunct": 8.499299210378755,
        "cond_entropy-2-nopunct": 0.9787443836610802,
        "distinct-3-nopunct": 0.9889807162534435,
        "vocab_size-3-nopunct": 359,
        "unique-3-nopunct": 355,
        "entropy-3-nopunct": 8.48178717050266,
        "cond_entropy-3-nopunct": -0.012538676566409952,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18666666666666668,
            "2": 0.569620253164557,
            "3": 0.775
        },
        "nist": 6.74875500644805,
        "rouge1": {
            "precision": 0.79414,
            "recall": 0.75423,
            "fmeasure": 0.75973
        },
        "rouge2": {
            "precision": 0.58762,
            "recall": 0.55036,
            "fmeasure": 0.55728
        },
        "rougeL": {
            "precision": 0.6681,
            "recall": 0.63507,
            "fmeasure": 0.6378
        },
        "rougeLsum": {
            "precision": 0.6681,
            "recall": 0.63507,
            "fmeasure": 0.6378
        },
        "bleu": 50.50018,
        "nubia": {
            "semantic_relation": 4.36362,
            "contradiction": 4.02267,
            "irrelevancy": 26.08186,
            "logical_agreement": 69.89546,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.70441,
            "nubia_score": 0.77055
        },
        "bleurt": 0.29809,
        "meteor": 0.4150900188390091,
        "bertscore": {
            "precision": 0.93373,
            "recall": 0.92658,
            "f1": 0.92856
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.81,
        "total_length": 127,
        "mean_pred_length": 15.875,
        "std_pred_length": 4.985917668794783,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.7244094488188977,
        "vocab_size-1": 92,
        "unique-1": 78,
        "entropy-1": 6.224625140003197,
        "distinct-2": 0.9663865546218487,
        "vocab_size-2": 115,
        "unique-2": 113,
        "entropy-2": 6.810784149862564,
        "cond_entropy-2": 0.48359889597504446,
        "distinct-3": 1.0,
        "vocab_size-3": 111,
        "unique-3": 111,
        "entropy-3": 6.794415866350121,
        "cond_entropy-3": -0.010311806867747396,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 4.322904116447646,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7909090909090909,
        "vocab_size-1-nopunct": 87,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.217577782333725,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.5743861262852255,
        "cond_entropy-2-nopunct": 0.37350344716199235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 6.554588851677623,
        "cond_entropy-3-nopunct": -0.011453511570453781,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.375,
            "3": 0.84375
        },
        "nist": 5.730541180452676,
        "rouge1": {
            "precision": 0.87016,
            "recall": 0.8138,
            "fmeasure": 0.83613
        },
        "rouge2": {
            "precision": 0.65478,
            "recall": 0.64435,
            "fmeasure": 0.64605
        },
        "rougeL": {
            "precision": 0.71733,
            "recall": 0.69048,
            "fmeasure": 0.69983
        },
        "rougeLsum": {
            "precision": 0.71733,
            "recall": 0.69048,
            "fmeasure": 0.69983
        },
        "bleu": 55.48959,
        "nubia": {
            "semantic_relation": 4.33998,
            "contradiction": 9.41171,
            "irrelevancy": 19.00866,
            "logical_agreement": 71.57963,
            "grammar_ref": 4.87577,
            "grammar_hyp": 5.10362,
            "nubia_score": 0.73379
        },
        "bleurt": 0.35959,
        "meteor": 0.4396313545631068,
        "bertscore": {
            "precision": 0.95472,
            "recall": 0.95003,
            "f1": 0.95187
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 90,
        "mean_pred_length": 12.857142857142858,
        "std_pred_length": 2.799416848895061,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.6888888888888889,
        "vocab_size-1": 62,
        "unique-1": 50,
        "entropy-1": 5.6370120188902515,
        "distinct-2": 0.891566265060241,
        "vocab_size-2": 74,
        "unique-2": 65,
        "entropy-2": 6.1581719614674135,
        "cond_entropy-2": 0.35649010025995204,
        "distinct-3": 0.9078947368421053,
        "vocab_size-3": 69,
        "unique-3": 62,
        "entropy-3": 6.063716987127802,
        "cond_entropy-3": -0.10079612842965495,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 11.428571428571429,
        "std_pred_length-nopunct": 3.063944369932459,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.665311532225099,
        "distinct-2-nopunct": 0.9041095890410958,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.998043736962218,
        "cond_entropy-2-nopunct": 0.3682981764992415,
        "distinct-3-nopunct": 0.9242424242424242,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.89287896784331,
        "cond_entropy-3-nopunct": -0.11512740921853373,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.46153846153846156,
            "3": 0.8571428571428571
        },
        "nist": 4.753790188373189,
        "rouge1": {
            "precision": 0.75929,
            "recall": 0.84542,
            "fmeasure": 0.79391
        },
        "rouge2": {
            "precision": 0.52644,
            "recall": 0.61447,
            "fmeasure": 0.56114
        },
        "rougeL": {
            "precision": 0.65146,
            "recall": 0.73866,
            "fmeasure": 0.68678
        },
        "rougeLsum": {
            "precision": 0.65146,
            "recall": 0.73866,
            "fmeasure": 0.68678
        },
        "bleu": 40.26419,
        "nubia": {
            "semantic_relation": 4.3511,
            "contradiction": 25.31398,
            "irrelevancy": 38.80967,
            "logical_agreement": 35.87636,
            "grammar_ref": 5.14386,
            "grammar_hyp": 4.88049,
            "nubia_score": 0.75845
        },
        "bleurt": 0.47987,
        "meteor": 0.4327147789652966,
        "bertscore": {
            "precision": 0.94281,
            "recall": 0.95557,
            "f1": 0.94888
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1986532337201607,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "bleurt": 0.99035,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 103,
        "mean_pred_length": 17.166666666666668,
        "std_pred_length": 4.844813951249544,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7281553398058253,
        "vocab_size-1": 75,
        "unique-1": 65,
        "entropy-1": 5.8837535535123475,
        "distinct-2": 0.979381443298969,
        "vocab_size-2": 95,
        "unique-2": 93,
        "entropy-2": 6.558675728785079,
        "cond_entropy-2": 0.6048896120519939,
        "distinct-3": 1.0,
        "vocab_size-3": 91,
        "unique-3": 91,
        "entropy-3": 6.507794640198703,
        "cond_entropy-3": -0.048162158032387686,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 3.8151743807531986,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7608695652173914,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.802709670062449,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 6.379753126795123,
        "cond_entropy-2-nopunct": 0.6157075697090456,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.05433665981473594,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5454545454545454,
            "3": 0.7391304347826086
        },
        "nist": 5.096176886447335,
        "rouge1": {
            "precision": 0.71869,
            "recall": 0.70267,
            "fmeasure": 0.6998
        },
        "rouge2": {
            "precision": 0.56249,
            "recall": 0.53732,
            "fmeasure": 0.54043
        },
        "rougeL": {
            "precision": 0.69319,
            "recall": 0.65919,
            "fmeasure": 0.66611
        },
        "rougeLsum": {
            "precision": 0.69319,
            "recall": 0.65919,
            "fmeasure": 0.66611
        },
        "bleu": 52.85704,
        "nubia": {
            "semantic_relation": 4.18262,
            "contradiction": 15.86854,
            "irrelevancy": 37.67923,
            "logical_agreement": 46.45222,
            "grammar_ref": 4.71157,
            "grammar_hyp": 5.02152,
            "nubia_score": 0.64865
        },
        "bleurt": 0.19401,
        "meteor": 0.40382742987983794,
        "bertscore": {
            "precision": 0.93039,
            "recall": 0.92112,
            "f1": 0.92516
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "total_length": 111,
        "mean_pred_length": 18.5,
        "std_pred_length": 6.701989754294367,
        "median_pred_length": 20.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.7207207207207207,
        "vocab_size-1": 80,
        "unique-1": 66,
        "entropy-1": 6.054425186283291,
        "distinct-2": 0.9809523809523809,
        "vocab_size-2": 103,
        "unique-2": 101,
        "entropy-2": 6.676150279570875,
        "cond_entropy-2": 0.5162981321073575,
        "distinct-3": 0.98989898989899,
        "vocab_size-3": 98,
        "unique-3": 97,
        "entropy-3": 6.609154599877599,
        "cond_entropy-3": -0.06468687738449273,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 16.166666666666668,
        "std_pred_length-nopunct": 5.639641438562877,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7835051546391752,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.036725311433624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.507794640198703,
        "cond_entropy-2-nopunct": 0.49721356156201535,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.409390936137707,
        "cond_entropy-3-nopunct": -0.09840370406099458,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1320754716981132,
            "2": 0.5405405405405406,
            "3": 0.6904761904761905
        },
        "nist": 4.2172084812694886,
        "rouge1": {
            "precision": 0.61811,
            "recall": 0.56057,
            "fmeasure": 0.57952
        },
        "rouge2": {
            "precision": 0.3814,
            "recall": 0.3143,
            "fmeasure": 0.33873
        },
        "rougeL": {
            "precision": 0.48172,
            "recall": 0.42663,
            "fmeasure": 0.44568
        },
        "rougeLsum": {
            "precision": 0.48172,
            "recall": 0.42663,
            "fmeasure": 0.44568
        },
        "bleu": 27.67215,
        "nubia": {
            "semantic_relation": 3.91925,
            "contradiction": 12.13991,
            "irrelevancy": 37.26054,
            "logical_agreement": 50.59954,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.93606,
            "nubia_score": 0.62841
        },
        "bleurt": -0.00932,
        "meteor": 0.329742342956411,
        "bertscore": {
            "precision": 0.90718,
            "recall": 0.90224,
            "f1": 0.90335
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "total_length": 171,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.811865258054231,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.672514619883041,
        "vocab_size-1": 115,
        "unique-1": 94,
        "entropy-1": 6.422851586228223,
        "distinct-2": 0.9382716049382716,
        "vocab_size-2": 152,
        "unique-2": 143,
        "entropy-2": 7.211733413365079,
        "cond_entropy-2": 0.7228541969116586,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 150,
        "unique-3": 147,
        "entropy-3": 7.218172156418123,
        "cond_entropy-3": 0.013975013024781768,
        "total_length-nopunct": 155,
        "mean_pred_length-nopunct": 17.22222222222222,
        "std_pred_length-nopunct": 5.513171657802345,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7161290322580646,
        "vocab_size-1-nopunct": 111,
        "unique-1-nopunct": 92,
        "entropy-1-nopunct": 6.431981244682925,
        "distinct-2-nopunct": 0.9315068493150684,
        "vocab_size-2-nopunct": 136,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 7.047667795166571,
        "cond_entropy-2-nopunct": 0.6677227727118882,
        "distinct-3-nopunct": 0.9781021897810219,
        "vocab_size-3-nopunct": 134,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.054236462522556,
        "cond_entropy-3-nopunct": 0.015907432855425282,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.42857142857142855,
            "3": 0.7746478873239436
        },
        "nist": 4.74056699755905,
        "rouge1": {
            "precision": 0.6132,
            "recall": 0.65672,
            "fmeasure": 0.62581
        },
        "rouge2": {
            "precision": 0.38228,
            "recall": 0.40848,
            "fmeasure": 0.38839
        },
        "rougeL": {
            "precision": 0.55258,
            "recall": 0.58864,
            "fmeasure": 0.56141
        },
        "rougeLsum": {
            "precision": 0.55258,
            "recall": 0.58864,
            "fmeasure": 0.56141
        },
        "bleu": 36.18558,
        "nubia": {
            "semantic_relation": 3.45707,
            "contradiction": 8.57499,
            "irrelevancy": 38.4934,
            "logical_agreement": 52.93161,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.75803,
            "nubia_score": 0.55782
        },
        "bleurt": -0.07163,
        "meteor": 0.3399431297350709,
        "bertscore": {
            "precision": 0.89655,
            "recall": 0.89762,
            "f1": 0.89492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.67,
        "total_length": 113,
        "mean_pred_length": 16.142857142857142,
        "std_pred_length": 4.085814184592883,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6371681415929203,
        "vocab_size-1": 72,
        "unique-1": 56,
        "entropy-1": 5.762798931836755,
        "distinct-2": 0.8962264150943396,
        "vocab_size-2": 95,
        "unique-2": 86,
        "entropy-2": 6.501505360223563,
        "cond_entropy-2": 0.6622147794219471,
        "distinct-3": 0.9595959595959596,
        "vocab_size-3": 95,
        "unique-3": 91,
        "entropy-3": 6.548548539271538,
        "cond_entropy-3": 0.04285030693055152,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 14.285714285714286,
        "std_pred_length-nopunct": 3.614031611621005,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.67,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.684114505264362,
        "distinct-2-nopunct": 0.8924731182795699,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.30259967132309,
        "cond_entropy-2-nopunct": 0.6477130347853178,
        "distinct-3-nopunct": 0.9651162790697675,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.3564973128416336,
        "cond_entropy-3-nopunct": 0.0266408273149969,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5882352941176471,
            "3": 0.7246376811594203
        },
        "nist": 4.450191153845043,
        "rouge1": {
            "precision": 0.66019,
            "recall": 0.71929,
            "fmeasure": 0.68306
        },
        "rouge2": {
            "precision": 0.37904,
            "recall": 0.47734,
            "fmeasure": 0.41324
        },
        "rougeL": {
            "precision": 0.50435,
            "recall": 0.55329,
            "fmeasure": 0.52286
        },
        "rougeLsum": {
            "precision": 0.50435,
            "recall": 0.55329,
            "fmeasure": 0.52286
        },
        "bleu": 30.50456,
        "nubia": {
            "semantic_relation": 3.86752,
            "contradiction": 18.67045,
            "irrelevancy": 66.75505,
            "logical_agreement": 14.57449,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.03759,
            "nubia_score": 0.63866
        },
        "bleurt": 0.08896,
        "meteor": 0.37758526223106914,
        "bertscore": {
            "precision": 0.90426,
            "recall": 0.91588,
            "f1": 0.9084
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 2.0,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 20,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 23,
        "entropy-1": 4.625212766041288,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.4354684419973452,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5695322390610205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.4628384235758111,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.6666666666666666,
            "3": 0.9473684210526315
        },
        "nist": 4.752145657556114,
        "rouge1": {
            "precision": 0.81658,
            "recall": 0.92623,
            "fmeasure": 0.86598
        },
        "rouge2": {
            "precision": 0.70909,
            "recall": 0.79717,
            "fmeasure": 0.74876
        },
        "rougeL": {
            "precision": 0.7731,
            "recall": 0.87165,
            "fmeasure": 0.81758
        },
        "rougeLsum": {
            "precision": 0.7731,
            "recall": 0.87165,
            "fmeasure": 0.81758
        },
        "bleu": 61.73667,
        "nubia": {
            "semantic_relation": 4.90703,
            "contradiction": 0.40654,
            "irrelevancy": 29.05396,
            "logical_agreement": 70.5395,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.60796,
            "nubia_score": 0.94327
        },
        "bleurt": 0.63179,
        "meteor": 0.5003930327483798,
        "bertscore": {
            "precision": 0.96095,
            "recall": 0.97721,
            "f1": 0.96894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 3.5,
        "median_pred_length": 11.5,
        "min_pred_length": 8,
        "max_pred_length": 15,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.036006438040157185,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393866,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9333333333333333
        },
        "nist": 3.2006176953459478,
        "rouge1": {
            "precision": 0.67308,
            "recall": 0.90278,
            "fmeasure": 0.76472
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.68788,
            "fmeasure": 0.57265
        },
        "rougeL": {
            "precision": 0.67308,
            "recall": 0.90278,
            "fmeasure": 0.76472
        },
        "rougeLsum": {
            "precision": 0.67308,
            "recall": 0.90278,
            "fmeasure": 0.76472
        },
        "bleu": 50.02172,
        "nubia": {
            "semantic_relation": 4.14393,
            "contradiction": 0.85415,
            "irrelevancy": 64.04009,
            "logical_agreement": 35.10576,
            "grammar_ref": 3.61093,
            "grammar_hyp": 3.63415,
            "nubia_score": 0.77149
        },
        "bleurt": 0.58315,
        "meteor": 0.5077765512130824,
        "bertscore": {
            "precision": 0.91967,
            "recall": 0.95897,
            "f1": 0.93887
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 3.4489501552193644,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.60606,
            "recall": 0.66667,
            "fmeasure": 0.63492
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.83939,
            "fmeasure": 0.79183
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.83939,
            "fmeasure": 0.79183
        },
        "bleu": 46.59538,
        "nubia": {
            "semantic_relation": 3.8457,
            "contradiction": 83.73137,
            "irrelevancy": 3.72436,
            "logical_agreement": 12.54427,
            "grammar_ref": 3.16175,
            "grammar_hyp": 3.02211,
            "nubia_score": 0.66751
        },
        "bleurt": 0.60872,
        "meteor": 0.4771782424635379,
        "bertscore": {
            "precision": 0.98535,
            "recall": 0.99283,
            "f1": 0.98908
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.62,
        "total_length": 125,
        "mean_pred_length": 17.857142857142858,
        "std_pred_length": 5.303060340934453,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.56,
        "vocab_size-1": 70,
        "unique-1": 47,
        "entropy-1": 5.728991602670137,
        "distinct-2": 0.8559322033898306,
        "vocab_size-2": 101,
        "unique-2": 85,
        "entropy-2": 6.588110104428245,
        "cond_entropy-2": 0.8010487879413147,
        "distinct-3": 0.918918918918919,
        "vocab_size-3": 102,
        "unique-3": 93,
        "entropy-3": 6.6322537041879555,
        "cond_entropy-3": 0.06271774944018785,
        "total_length-nopunct": 115,
        "mean_pred_length-nopunct": 16.428571428571427,
        "std_pred_length-nopunct": 5.627918743883488,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.591304347826087,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.705583005338574,
        "distinct-2-nopunct": 0.8425925925925926,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.43308298825454,
        "cond_entropy-2-nopunct": 0.7736050692052433,
        "distinct-3-nopunct": 0.9108910891089109,
        "vocab_size-3-nopunct": 92,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.479993660969605,
        "cond_entropy-3-nopunct": 0.04941197565925151,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.7142857142857143,
            "3": 0.7101449275362319
        },
        "nist": 4.903987887810604,
        "rouge1": {
            "precision": 0.73309,
            "recall": 0.6793,
            "fmeasure": 0.70167
        },
        "rouge2": {
            "precision": 0.45654,
            "recall": 0.42094,
            "fmeasure": 0.43564
        },
        "rougeL": {
            "precision": 0.60581,
            "recall": 0.57481,
            "fmeasure": 0.58641
        },
        "rougeLsum": {
            "precision": 0.60581,
            "recall": 0.57481,
            "fmeasure": 0.58641
        },
        "bleu": 41.05609,
        "nubia": {
            "semantic_relation": 4.11341,
            "contradiction": 25.19626,
            "irrelevancy": 29.18759,
            "logical_agreement": 45.61615,
            "grammar_ref": 5.20043,
            "grammar_hyp": 5.04905,
            "nubia_score": 0.66046
        },
        "bleurt": -0.1061,
        "meteor": 0.346040560911066,
        "bertscore": {
            "precision": 0.91119,
            "recall": 0.90313,
            "f1": 0.90613
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8333333333333334
        },
        "nist": 2.517679218911131,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.69444,
            "fmeasure": 0.64286
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.32727,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.51429
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.51429
        },
        "bleu": 21.20063,
        "nubia": {
            "semantic_relation": 3.59129,
            "contradiction": 0.53091,
            "irrelevancy": 33.20595,
            "logical_agreement": 66.26314,
            "grammar_ref": 6.47099,
            "grammar_hyp": 5.41165,
            "nubia_score": 0.6867
        },
        "bleurt": -0.5051,
        "meteor": 0.37929104676710707,
        "bertscore": {
            "precision": 0.89139,
            "recall": 0.90328,
            "f1": 0.89729
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "nist": 4.00193538757769,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "bleu": 81.96501,
        "nubia": {
            "semantic_relation": 4.91472,
            "contradiction": 0.30946,
            "irrelevancy": 2.79721,
            "logical_agreement": 96.89333,
            "grammar_ref": 3.61542,
            "grammar_hyp": 3.03745,
            "nubia_score": 1.0
        },
        "bleurt": 0.86304,
        "meteor": 0.5249299242820813,
        "bertscore": {
            "precision": 0.99614,
            "recall": 0.98503,
            "f1": 0.99055
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1850,
        "msttr-100": 0.69175,
        "msttr-100_nopunct": 0.73986,
        "total_length": 25166,
        "mean_pred_length": 13.603243243243243,
        "std_pred_length": 4.186127704340724,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.2542716363347373,
        "vocab_size-1": 6399,
        "unique-1": 4679,
        "entropy-1": 9.17970274876928,
        "distinct-2": 0.6177303139475039,
        "vocab_size-2": 14403,
        "unique-2": 12579,
        "entropy-2": 12.59321470328345,
        "cond_entropy-2": 2.9979856409693206,
        "distinct-3": 0.7878971396627225,
        "vocab_size-3": 16913,
        "unique-3": 15792,
        "entropy-3": 13.385180255438717,
        "cond_entropy-3": 0.833288496779142,
        "total_length-nopunct": 21916,
        "mean_pred_length-nopunct": 11.846486486486487,
        "std_pred_length-nopunct": 3.7094766996104074,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.29129403175762003,
        "vocab_size-1-nopunct": 6384,
        "unique-1-nopunct": 4676,
        "entropy-1-nopunct": 9.638863155794285,
        "distinct-2-nopunct": 0.6406857370676766,
        "vocab_size-2-nopunct": 12856,
        "unique-2-nopunct": 11442,
        "entropy-2-nopunct": 12.427303757660052,
        "cond_entropy-2-nopunct": 3.0265575576396326,
        "distinct-3-nopunct": 0.7975955204216074,
        "vocab_size-3-nopunct": 14529,
        "unique-3-nopunct": 13650,
        "entropy-3-nopunct": 13.176672578292422,
        "cond_entropy-3-nopunct": 0.8739555621216514,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22881040892193308,
            "2": 0.4919816723940435,
            "3": 0.7801795809777187
        },
        "nist": 9.476593446017628,
        "rouge1": {
            "precision": 0.7444,
            "recall": 0.73514,
            "fmeasure": 0.72685
        },
        "rouge2": {
            "precision": 0.54239,
            "recall": 0.53826,
            "fmeasure": 0.53066
        },
        "rougeL": {
            "precision": 0.67254,
            "recall": 0.66795,
            "fmeasure": 0.65855
        },
        "rougeLsum": {
            "precision": 0.67254,
            "recall": 0.66795,
            "fmeasure": 0.65855
        },
        "bleu": 50.69373,
        "nubia": {
            "semantic_relation": 4.16485,
            "contradiction": 7.97135,
            "irrelevancy": 31.52644,
            "logical_agreement": 60.50222,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.73204,
            "nubia_score": 0.72363
        },
        "bleurt": 0.30257,
        "meteor": 0.4059699229930126,
        "bertscore": {
            "precision": 0.92749,
            "recall": 0.92635,
            "f1": 0.92513
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 4.264680527307995,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.7017543859649122,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.076409040853093,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.5576609211298488,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.11321061044799063,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 4.031128874149275,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.03656563024272,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.5053484940187908,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.1312445332782525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8461538461538461,
            "3": 0.9583333333333334
        },
        "nist": 5.043379441954469,
        "rouge1": {
            "precision": 0.81407,
            "recall": 0.91219,
            "fmeasure": 0.85414
        },
        "rouge2": {
            "precision": 0.65253,
            "recall": 0.73383,
            "fmeasure": 0.68525
        },
        "rougeL": {
            "precision": 0.78629,
            "recall": 0.89251,
            "fmeasure": 0.83018
        },
        "rougeLsum": {
            "precision": 0.78629,
            "recall": 0.89251,
            "fmeasure": 0.83018
        },
        "bleu": 62.16624,
        "nubia": {
            "semantic_relation": 4.41365,
            "contradiction": 11.99853,
            "irrelevancy": 36.18866,
            "logical_agreement": 51.81281,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.16941,
            "nubia_score": 0.77236
        },
        "bleurt": 0.50229,
        "meteor": 0.4900984393717045,
        "bertscore": {
            "precision": 0.95934,
            "recall": 0.97306,
            "f1": 0.96594
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.7,
        "total_length": 121,
        "mean_pred_length": 15.125,
        "std_pred_length": 5.395310463726809,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.628099173553719,
        "vocab_size-1": 76,
        "unique-1": 60,
        "entropy-1": 5.877431266461831,
        "distinct-2": 0.8761061946902655,
        "vocab_size-2": 99,
        "unique-2": 92,
        "entropy-2": 6.52562840918384,
        "cond_entropy-2": 0.5095374592397135,
        "distinct-3": 0.8857142857142857,
        "vocab_size-3": 93,
        "unique-3": 87,
        "entropy-3": 6.442537660399631,
        "cond_entropy-3": -0.060648801871317964,
        "total_length-nopunct": 102,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 4.892596447695231,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.696078431372549,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.863567562912499,
        "distinct-2-nopunct": 0.8723404255319149,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.251085394092723,
        "cond_entropy-2-nopunct": 0.4457184932278131,
        "distinct-3-nopunct": 0.8837209302325582,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149817806901897,
        "cond_entropy-3-nopunct": -0.07303470741549921,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.125,
            "3": 0.7659574468085106
        },
        "nist": 5.554443494196939,
        "rouge1": {
            "precision": 0.883,
            "recall": 0.8462,
            "fmeasure": 0.86226
        },
        "rouge2": {
            "precision": 0.79324,
            "recall": 0.76552,
            "fmeasure": 0.77766
        },
        "rougeL": {
            "precision": 0.86514,
            "recall": 0.82804,
            "fmeasure": 0.84426
        },
        "rougeLsum": {
            "precision": 0.86514,
            "recall": 0.82804,
            "fmeasure": 0.84426
        },
        "bleu": 61.04717,
        "nubia": {
            "semantic_relation": 4.82519,
            "contradiction": 0.18446,
            "irrelevancy": 17.0149,
            "logical_agreement": 82.80064,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.52632,
            "nubia_score": 0.93776
        },
        "bleurt": 0.74591,
        "meteor": 0.4892287219135475,
        "bertscore": {
            "precision": 0.97381,
            "recall": 0.96584,
            "f1": 0.96956
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.746,
        "msttr-100_nopunct": 0.805,
        "total_length": 500,
        "mean_pred_length": 17.24137931034483,
        "std_pred_length": 4.86121293515839,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.558,
        "vocab_size-1": 279,
        "unique-1": 218,
        "entropy-1": 7.365844967352877,
        "distinct-2": 0.9044585987261147,
        "vocab_size-2": 426,
        "unique-2": 396,
        "entropy-2": 8.656666649910717,
        "cond_entropy-2": 1.145388899520672,
        "distinct-3": 0.9728506787330317,
        "vocab_size-3": 430,
        "unique-3": 420,
        "entropy-3": 8.730188136304692,
        "cond_entropy-3": 0.0836223492704217,
        "total_length-nopunct": 424,
        "mean_pred_length-nopunct": 14.620689655172415,
        "std_pred_length-nopunct": 3.6898163032814995,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6415094339622641,
        "vocab_size-1-nopunct": 272,
        "unique-1-nopunct": 216,
        "entropy-1-nopunct": 7.575751150870801,
        "distinct-2-nopunct": 0.9240506329113924,
        "vocab_size-2-nopunct": 365,
        "unique-2-nopunct": 343,
        "entropy-2-nopunct": 8.451711233056404,
        "cond_entropy-2-nopunct": 0.9413472905561524,
        "distinct-3-nopunct": 0.9808743169398907,
        "vocab_size-3-nopunct": 359,
        "unique-3-nopunct": 352,
        "entropy-3-nopunct": 8.47744847216377,
        "cond_entropy-3-nopunct": 0.03679169454526188,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.27631578947368424,
            "2": 0.44776119402985076,
            "3": 0.799410029498525
        },
        "nist": 6.897522584933714,
        "rouge1": {
            "precision": 0.79659,
            "recall": 0.78283,
            "fmeasure": 0.78425
        },
        "rouge2": {
            "precision": 0.64161,
            "recall": 0.62757,
            "fmeasure": 0.63009
        },
        "rougeL": {
            "precision": 0.74724,
            "recall": 0.73481,
            "fmeasure": 0.73581
        },
        "rougeLsum": {
            "precision": 0.74724,
            "recall": 0.73481,
            "fmeasure": 0.73581
        },
        "bleu": 58.37567,
        "nubia": {
            "semantic_relation": 4.21715,
            "contradiction": 11.04472,
            "irrelevancy": 27.76666,
            "logical_agreement": 61.18862,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.81042,
            "nubia_score": 0.73857
        },
        "bleurt": 0.37785,
        "meteor": 0.42963110977179847,
        "bertscore": {
            "precision": 0.94058,
            "recall": 0.94124,
            "f1": 0.94039
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.034621791174768206,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 3.6012231371527106,
        "rouge1": {
            "precision": 0.73485,
            "recall": 0.52033,
            "fmeasure": 0.60489
        },
        "rouge2": {
            "precision": 0.59848,
            "recall": 0.40873,
            "fmeasure": 0.48261
        },
        "rougeL": {
            "precision": 0.73485,
            "recall": 0.52033,
            "fmeasure": 0.60489
        },
        "rougeLsum": {
            "precision": 0.73485,
            "recall": 0.52033,
            "fmeasure": 0.60489
        },
        "bleu": 53.90595,
        "nubia": {
            "semantic_relation": 2.9714,
            "contradiction": 50.85642,
            "irrelevancy": 3.63178,
            "logical_agreement": 45.5118,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.52481,
            "nubia_score": 0.34991
        },
        "bleurt": -0.05285,
        "meteor": 0.30438018617566287,
        "bertscore": {
            "precision": 0.92563,
            "recall": 0.89111,
            "f1": 0.89836
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.9055199766139435,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.93333,
            "fmeasure": 0.87179
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.93333
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.93333
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.18583,
            "contradiction": 0.32484,
            "irrelevancy": 35.51392,
            "logical_agreement": 64.16124,
            "grammar_ref": 4.09688,
            "grammar_hyp": 3.75691,
            "nubia_score": 0.79418
        },
        "bleurt": 0.42629,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.675,
        "msttr-100_nopunct": 0.73,
        "total_length": 251,
        "mean_pred_length": 17.928571428571427,
        "std_pred_length": 5.457161555689731,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.5657370517928287,
        "vocab_size-1": 142,
        "unique-1": 116,
        "entropy-1": 6.432997795056815,
        "distinct-2": 0.8860759493670886,
        "vocab_size-2": 210,
        "unique-2": 191,
        "entropy-2": 7.629208333268229,
        "cond_entropy-2": 1.1100459906328752,
        "distinct-3": 0.9327354260089686,
        "vocab_size-3": 208,
        "unique-3": 197,
        "entropy-3": 7.650631850573557,
        "cond_entropy-3": 0.015295664474960174,
        "total_length-nopunct": 221,
        "mean_pred_length-nopunct": 15.785714285714286,
        "std_pred_length-nopunct": 4.631855096249565,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6244343891402715,
        "vocab_size-1-nopunct": 138,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.499382237033587,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 184,
        "unique-2-nopunct": 169,
        "entropy-2-nopunct": 7.434985628975982,
        "cond_entropy-2-nopunct": 0.9985951045656435,
        "distinct-3-nopunct": 0.9326424870466321,
        "vocab_size-3-nopunct": 180,
        "unique-3-nopunct": 171,
        "entropy-3-nopunct": 7.439556648644603,
        "cond_entropy-3-nopunct": 0.002597022773936517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2191780821917808,
            "2": 0.5846153846153846,
            "3": 0.7130434782608696
        },
        "nist": 5.166887795757459,
        "rouge1": {
            "precision": 0.64059,
            "recall": 0.66708,
            "fmeasure": 0.64001
        },
        "rouge2": {
            "precision": 0.39362,
            "recall": 0.40568,
            "fmeasure": 0.39125
        },
        "rougeL": {
            "precision": 0.53579,
            "recall": 0.573,
            "fmeasure": 0.54206
        },
        "rougeLsum": {
            "precision": 0.53579,
            "recall": 0.573,
            "fmeasure": 0.54206
        },
        "bleu": 33.8711,
        "nubia": {
            "semantic_relation": 3.72264,
            "contradiction": 6.34851,
            "irrelevancy": 66.57024,
            "logical_agreement": 27.08125,
            "grammar_ref": 4.00042,
            "grammar_hyp": 3.90846,
            "nubia_score": 0.64452
        },
        "bleurt": -0.02264,
        "meteor": 0.3524068765158399,
        "bertscore": {
            "precision": 0.90337,
            "recall": 0.90641,
            "f1": 0.90356
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 112,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 2.6874192494328497,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 23,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 72,
        "unique-1": 53,
        "entropy-1": 5.834196721524643,
        "distinct-2": 0.9245283018867925,
        "vocab_size-2": 98,
        "unique-2": 90,
        "entropy-2": 6.576977058336769,
        "cond_entropy-2": 0.6515461311411057,
        "distinct-3": 0.95,
        "vocab_size-3": 95,
        "unique-3": 90,
        "entropy-3": 6.543856189774739,
        "cond_entropy-3": -0.04406426478847467,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.140872096444188,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6868686868686869,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.802343458656111,
        "distinct-2-nopunct": 0.9247311827956989,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.388621176699437,
        "cond_entropy-2-nopunct": 0.6181280295330152,
        "distinct-3-nopunct": 0.9425287356321839,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 77,
        "entropy-3-nopunct": 6.3280009671130895,
        "cond_entropy-3-nopunct": -0.0502383037650501,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.5,
            "3": 0.8194444444444444
        },
        "nist": 5.425295466059664,
        "rouge1": {
            "precision": 0.72332,
            "recall": 0.78978,
            "fmeasure": 0.74889
        },
        "rouge2": {
            "precision": 0.55186,
            "recall": 0.60877,
            "fmeasure": 0.57287
        },
        "rougeL": {
            "precision": 0.64897,
            "recall": 0.71631,
            "fmeasure": 0.67573
        },
        "rougeLsum": {
            "precision": 0.64897,
            "recall": 0.71631,
            "fmeasure": 0.67573
        },
        "bleu": 53.98697,
        "nubia": {
            "semantic_relation": 4.13847,
            "contradiction": 31.97286,
            "irrelevancy": 21.42047,
            "logical_agreement": 46.60667,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.16557,
            "nubia_score": 0.75304
        },
        "bleurt": 0.36314,
        "meteor": 0.43390722465944115,
        "bertscore": {
            "precision": 0.92461,
            "recall": 0.94242,
            "f1": 0.93315
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5
        },
        "nist": 0.8888940541810273,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.35417,
            "fmeasure": 0.44505
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.13393,
            "fmeasure": 0.17424
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.35417,
            "fmeasure": 0.44505
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.35417,
            "fmeasure": 0.44505
        },
        "bleu": 11.709,
        "nubia": {
            "semantic_relation": 3.38471,
            "contradiction": 1.7235,
            "irrelevancy": 1.39459,
            "logical_agreement": 96.88191,
            "grammar_ref": 6.12307,
            "grammar_hyp": 6.80271,
            "nubia_score": 0.4553
        },
        "bleurt": -0.25876,
        "meteor": 0.19751594224285138,
        "bertscore": {
            "precision": 0.81475,
            "recall": 0.74824,
            "f1": 0.77892
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.715,
        "total_length": 298,
        "mean_pred_length": 17.529411764705884,
        "std_pred_length": 5.424537356893413,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6208053691275168,
        "vocab_size-1": 185,
        "unique-1": 150,
        "entropy-1": 6.901531138055869,
        "distinct-2": 0.9181494661921709,
        "vocab_size-2": 258,
        "unique-2": 239,
        "entropy-2": 7.9599795230371075,
        "cond_entropy-2": 0.9495510024221718,
        "distinct-3": 0.9659090909090909,
        "vocab_size-3": 255,
        "unique-3": 247,
        "entropy-3": 7.973352878819965,
        "cond_entropy-3": 0.02460667226817277,
        "total_length-nopunct": 265,
        "mean_pred_length-nopunct": 15.588235294117647,
        "std_pred_length-nopunct": 4.923638343021548,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6830188679245283,
        "vocab_size-1-nopunct": 181,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 7.006262799936431,
        "distinct-2-nopunct": 0.9153225806451613,
        "vocab_size-2-nopunct": 227,
        "unique-2-nopunct": 210,
        "entropy-2-nopunct": 7.772665866803615,
        "cond_entropy-2-nopunct": 0.8137456384064016,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 224,
        "unique-3-nopunct": 218,
        "entropy-3-nopunct": 7.787875069545191,
        "cond_entropy-3-nopunct": 0.015581573048621249,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4117647058823529,
            "3": 0.7103825136612022
        },
        "nist": 5.608153548240545,
        "rouge1": {
            "precision": 0.73537,
            "recall": 0.70581,
            "fmeasure": 0.70949
        },
        "rouge2": {
            "precision": 0.49078,
            "recall": 0.46756,
            "fmeasure": 0.47209
        },
        "rougeL": {
            "precision": 0.63836,
            "recall": 0.60678,
            "fmeasure": 0.61284
        },
        "rougeLsum": {
            "precision": 0.63836,
            "recall": 0.60678,
            "fmeasure": 0.61284
        },
        "bleu": 41.47017,
        "nubia": {
            "semantic_relation": 3.94246,
            "contradiction": 18.08673,
            "irrelevancy": 40.90764,
            "logical_agreement": 41.00563,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.52648,
            "nubia_score": 0.61606
        },
        "bleurt": 0.14586,
        "meteor": 0.36239925371954085,
        "bertscore": {
            "precision": 0.91701,
            "recall": 0.9141,
            "f1": 0.91218
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.775,
        "total_length": 319,
        "mean_pred_length": 15.95,
        "std_pred_length": 5.074199444247339,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.5736677115987461,
        "vocab_size-1": 183,
        "unique-1": 142,
        "entropy-1": 6.8719728593081255,
        "distinct-2": 0.9264214046822743,
        "vocab_size-2": 277,
        "unique-2": 259,
        "entropy-2": 8.06510610562172,
        "cond_entropy-2": 1.0340901019897648,
        "distinct-3": 0.989247311827957,
        "vocab_size-3": 276,
        "unique-3": 273,
        "entropy-3": 8.102615935485108,
        "cond_entropy-3": 0.03456327563942279,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 13.9,
        "std_pred_length-nopunct": 4.3920382511995495,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6402877697841727,
        "vocab_size-1-nopunct": 178,
        "unique-1-nopunct": 141,
        "entropy-1-nopunct": 7.014992185619055,
        "distinct-2-nopunct": 0.9302325581395349,
        "vocab_size-2-nopunct": 240,
        "unique-2-nopunct": 226,
        "entropy-2-nopunct": 7.858088592615754,
        "cond_entropy-2-nopunct": 0.8915228226609179,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 238,
        "unique-3-nopunct": 238,
        "entropy-3-nopunct": 7.894817763307991,
        "cond_entropy-3-nopunct": 0.04119460454152516,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25675675675675674,
            "2": 0.5692307692307692,
            "3": 0.8263157894736842
        },
        "nist": 6.687711827273689,
        "rouge1": {
            "precision": 0.82399,
            "recall": 0.81018,
            "fmeasure": 0.80375
        },
        "rouge2": {
            "precision": 0.6703,
            "recall": 0.65695,
            "fmeasure": 0.65445
        },
        "rougeL": {
            "precision": 0.76721,
            "recall": 0.74945,
            "fmeasure": 0.74679
        },
        "rougeLsum": {
            "precision": 0.76721,
            "recall": 0.74945,
            "fmeasure": 0.74679
        },
        "bleu": 60.58679,
        "nubia": {
            "semantic_relation": 4.24329,
            "contradiction": 7.7825,
            "irrelevancy": 14.09887,
            "logical_agreement": 78.11862,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.45896,
            "nubia_score": 0.73727
        },
        "bleurt": 0.42038,
        "meteor": 0.430478821566429,
        "bertscore": {
            "precision": 0.95207,
            "recall": 0.94363,
            "f1": 0.94659
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.81,
        "total_length": 149,
        "mean_pred_length": 18.625,
        "std_pred_length": 5.721396245672904,
        "median_pred_length": 19.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.7046979865771812,
        "vocab_size-1": 105,
        "unique-1": 85,
        "entropy-1": 6.383293772515965,
        "distinct-2": 0.9574468085106383,
        "vocab_size-2": 135,
        "unique-2": 129,
        "entropy-2": 7.05444496942005,
        "cond_entropy-2": 0.5909171400499957,
        "distinct-3": 0.9774436090225563,
        "vocab_size-3": 130,
        "unique-3": 127,
        "entropy-3": 7.010169653546311,
        "cond_entropy-3": -0.03915613494271676,
        "total_length-nopunct": 129,
        "mean_pred_length-nopunct": 16.125,
        "std_pred_length-nopunct": 4.512136411945011,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7596899224806202,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.352810999845353,
        "distinct-2-nopunct": 0.9669421487603306,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 6.852747534795264,
        "cond_entropy-2-nopunct": 0.5352037254013211,
        "distinct-3-nopunct": 0.9823008849557522,
        "vocab_size-3-nopunct": 111,
        "unique-3-nopunct": 109,
        "entropy-3-nopunct": 6.784780732326711,
        "cond_entropy-3-nopunct": -0.06328604477091117,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.28,
            "2": 0.2727272727272727,
            "3": 0.7872340425531915
        },
        "nist": 5.198490582121134,
        "rouge1": {
            "precision": 0.72258,
            "recall": 0.71107,
            "fmeasure": 0.71003
        },
        "rouge2": {
            "precision": 0.44978,
            "recall": 0.4421,
            "fmeasure": 0.44146
        },
        "rougeL": {
            "precision": 0.61936,
            "recall": 0.6061,
            "fmeasure": 0.60632
        },
        "rougeLsum": {
            "precision": 0.61936,
            "recall": 0.6061,
            "fmeasure": 0.60632
        },
        "bleu": 40.39106,
        "nubia": {
            "semantic_relation": 3.84273,
            "contradiction": 39.3329,
            "irrelevancy": 18.15616,
            "logical_agreement": 42.51093,
            "grammar_ref": 5.01189,
            "grammar_hyp": 5.17135,
            "nubia_score": 0.56832
        },
        "bleurt": 0.07606,
        "meteor": 0.37561211437004133,
        "bertscore": {
            "precision": 0.91938,
            "recall": 0.926,
            "f1": 0.92103
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "nist": 2.3747812124738807,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.65657,
            "fmeasure": 0.64623
        },
        "rouge2": {
            "precision": 0.4127,
            "recall": 0.41905,
            "fmeasure": 0.4158
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.51587,
            "fmeasure": 0.50775
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.51587,
            "fmeasure": 0.50775
        },
        "bleu": 15.82129,
        "nubia": {
            "semantic_relation": 2.9361,
            "contradiction": 82.68662,
            "irrelevancy": 16.83401,
            "logical_agreement": 0.47937,
            "grammar_ref": 3.42286,
            "grammar_hyp": 4.30718,
            "nubia_score": 0.34813
        },
        "bleurt": -0.04019,
        "meteor": 0.3642869796701903,
        "bertscore": {
            "precision": 0.90085,
            "recall": 0.89218,
            "f1": 0.89649
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.75,
        "total_length": 152,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.330127018922194,
        "median_pred_length": 20.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.6644736842105263,
        "vocab_size-1": 101,
        "unique-1": 83,
        "entropy-1": 6.26891435587466,
        "distinct-2": 0.9375,
        "vocab_size-2": 135,
        "unique-2": 128,
        "entropy-2": 7.0310361125534415,
        "cond_entropy-2": 0.649844709877023,
        "distinct-3": 0.9779411764705882,
        "vocab_size-3": 133,
        "unique-3": 130,
        "entropy-3": 7.043345194191504,
        "cond_entropy-3": 0.020479016278615262,
        "total_length-nopunct": 132,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 3.968626966596886,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.314995066801674,
        "distinct-2-nopunct": 0.9435483870967742,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.825164052322346,
        "cond_entropy-2-nopunct": 0.5572269889114376,
        "distinct-3-nopunct": 0.9913793103448276,
        "vocab_size-3-nopunct": 115,
        "unique-3-nopunct": 114,
        "entropy-3-nopunct": 6.840739615817211,
        "cond_entropy-3-nopunct": 0.024474339913110918,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.4,
            "3": 0.8514851485148515
        },
        "nist": 5.572957164457738,
        "rouge1": {
            "precision": 0.79359,
            "recall": 0.84215,
            "fmeasure": 0.79657
        },
        "rouge2": {
            "precision": 0.6263,
            "recall": 0.67898,
            "fmeasure": 0.63414
        },
        "rougeL": {
            "precision": 0.66475,
            "recall": 0.73789,
            "fmeasure": 0.68203
        },
        "rougeLsum": {
            "precision": 0.66475,
            "recall": 0.73789,
            "fmeasure": 0.68203
        },
        "bleu": 53.27555,
        "nubia": {
            "semantic_relation": 4.43577,
            "contradiction": 10.74718,
            "irrelevancy": 28.42391,
            "logical_agreement": 60.82891,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.4182,
            "nubia_score": 0.83773
        },
        "bleurt": 0.42375,
        "meteor": 0.4560613339828757,
        "bertscore": {
            "precision": 0.93218,
            "recall": 0.94372,
            "f1": 0.93558
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 72,
        "mean_pred_length": 18.0,
        "std_pred_length": 5.385164807134504,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 52,
        "unique-1": 41,
        "entropy-1": 5.4927737861344905,
        "distinct-2": 0.9852941176470589,
        "vocab_size-2": 67,
        "unique-2": 66,
        "entropy-2": 6.058051076544463,
        "cond_entropy-2": 0.4874626560163128,
        "distinct-3": 1.0,
        "vocab_size-3": 64,
        "unique-3": 64,
        "entropy-3": 6.0,
        "cond_entropy-3": -0.08746284125033935,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 4.205650960315181,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8545454545454545,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.454086986251929,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.24400680491742444,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.11783649029385802,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.4666666666666667,
            "3": 0.8205128205128205
        },
        "nist": 5.2971050585498745,
        "rouge1": {
            "precision": 0.73656,
            "recall": 0.77657,
            "fmeasure": 0.7481
        },
        "rouge2": {
            "precision": 0.41685,
            "recall": 0.43465,
            "fmeasure": 0.41897
        },
        "rougeL": {
            "precision": 0.57936,
            "recall": 0.6285,
            "fmeasure": 0.59605
        },
        "rougeLsum": {
            "precision": 0.57936,
            "recall": 0.6285,
            "fmeasure": 0.59605
        },
        "bleu": 40.79058,
        "nubia": {
            "semantic_relation": 4.11937,
            "contradiction": 5.84377,
            "irrelevancy": 40.24846,
            "logical_agreement": 53.90777,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.62338,
            "nubia_score": 0.68937
        },
        "bleurt": 0.26726,
        "meteor": 0.42609319099009474,
        "bertscore": {
            "precision": 0.92873,
            "recall": 0.94786,
            "f1": 0.93243
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 14.25,
        "std_pred_length": 1.0897247358851685,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.8245614035087719,
        "vocab_size-1": 47,
        "unique-1": 39,
        "entropy-1": 5.4469251018840374,
        "distinct-2": 0.9433962264150944,
        "vocab_size-2": 50,
        "unique-2": 47,
        "entropy-2": 5.614712907393384,
        "cond_entropy-2": 0.04597383662487266,
        "distinct-3": 0.9591836734693877,
        "vocab_size-3": 47,
        "unique-3": 45,
        "entropy-3": 5.533077191053984,
        "cond_entropy-3": -0.07239428391737843,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.7071067811865476,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8653846153846154,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.431208948910324,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.4599625007211605,
        "cond_entropy-2-nopunct": 0.05118944924673079,
        "distinct-3-nopunct": 0.9545454545454546,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.368522527728204,
        "cond_entropy-3-nopunct": -0.08007633662931374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8478260869565217
        },
        "nist": 5.614323845384203,
        "rouge1": {
            "precision": 0.83173,
            "recall": 0.81027,
            "fmeasure": 0.82023
        },
        "rouge2": {
            "precision": 0.66477,
            "recall": 0.64455,
            "fmeasure": 0.65404
        },
        "rougeL": {
            "precision": 0.78312,
            "recall": 0.76074,
            "fmeasure": 0.77125
        },
        "rougeLsum": {
            "precision": 0.78312,
            "recall": 0.76074,
            "fmeasure": 0.77125
        },
        "bleu": 71.97157,
        "nubia": {
            "semantic_relation": 4.81117,
            "contradiction": 0.39242,
            "irrelevancy": 12.0261,
            "logical_agreement": 87.58148,
            "grammar_ref": 4.9146,
            "grammar_hyp": 4.60021,
            "nubia_score": 0.93866
        },
        "bleurt": 0.58003,
        "meteor": 0.47052767354293357,
        "bertscore": {
            "precision": 0.96897,
            "recall": 0.95898,
            "f1": 0.96193
        }
    },
    "schema_guided_dialog_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.69281,
        "msttr-100_nopunct": 0.71842,
        "total_length": 6466,
        "mean_pred_length": 12.932,
        "std_pred_length": 6.594799162976838,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 32,
        "distinct-1": 0.1599133931333127,
        "vocab_size-1": 1034,
        "unique-1": 564,
        "entropy-1": 7.880131609458786,
        "distinct-2": 0.5050284948038887,
        "vocab_size-2": 3013,
        "unique-2": 2156,
        "entropy-2": 10.818462196347678,
        "cond_entropy-2": 2.718267551325671,
        "distinct-3": 0.7279546286132456,
        "vocab_size-3": 3979,
        "unique-3": 3318,
        "entropy-3": 11.6212734675676,
        "cond_entropy-3": 0.8293579526133575,
        "total_length-nopunct": 5709,
        "mean_pred_length-nopunct": 11.418,
        "std_pred_length-nopunct": 6.123338631824962,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.1791907514450867,
        "vocab_size-1-nopunct": 1023,
        "unique-1-nopunct": 562,
        "entropy-1-nopunct": 8.061959803625689,
        "distinct-2-nopunct": 0.5198694567095412,
        "vocab_size-2-nopunct": 2708,
        "unique-2-nopunct": 1972,
        "entropy-2-nopunct": 10.65849264333234,
        "cond_entropy-2-nopunct": 2.7271539257106188,
        "distinct-3-nopunct": 0.738004246284501,
        "vocab_size-3-nopunct": 3476,
        "unique-3-nopunct": 2930,
        "entropy-3-nopunct": 11.425116976900581,
        "cond_entropy-3-nopunct": 0.818751946104115,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5522285320943039
        },
        "nist": 5.994067109547731,
        "rouge1": {
            "precision": 0.5683,
            "recall": 0.53915,
            "fmeasure": 0.54275
        },
        "rouge2": {
            "precision": 0.35141,
            "recall": 0.33254,
            "fmeasure": 0.3344
        },
        "rougeL": {
            "precision": 0.50982,
            "recall": 0.48376,
            "fmeasure": 0.48684
        },
        "rougeLsum": {
            "precision": 0.50982,
            "recall": 0.48376,
            "fmeasure": 0.48684
        },
        "bleu": 30.50087,
        "nubia": {
            "semantic_relation": 3.54215,
            "contradiction": 6.74966,
            "irrelevancy": 24.17501,
            "logical_agreement": 69.07532,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.73913,
            "nubia_score": 0.61277
        },
        "bleurt": -0.14881,
        "meteor": 0.30344966164788145,
        "bertscore": {
            "precision": 0.86726,
            "recall": 0.86044,
            "f1": 0.86336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "total_length": 144,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.415880433163924,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.7083333333333334,
        "vocab_size-1": 102,
        "unique-1": 83,
        "entropy-1": 6.3849558178335934,
        "distinct-2": 0.9558823529411765,
        "vocab_size-2": 130,
        "unique-2": 124,
        "entropy-2": 6.999227547132685,
        "cond_entropy-2": 0.5159501779348954,
        "distinct-3": 0.96875,
        "vocab_size-3": 124,
        "unique-3": 120,
        "entropy-3": 6.9375,
        "cond_entropy-3": -0.0562128412503393,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 16.25,
        "std_pred_length-nopunct": 3.7332961307670196,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7615384615384615,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.423334713175169,
        "distinct-2-nopunct": 0.9508196721311475,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 110,
        "entropy-2-nopunct": 6.832376681825194,
        "cond_entropy-2-nopunct": 0.44832282765678555,
        "distinct-3-nopunct": 0.9649122807017544,
        "vocab_size-3-nopunct": 110,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.7627145755682605,
        "cond_entropy-3-nopunct": -0.06275960409989875,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2608695652173913,
            "2": 0.38461538461538464,
            "3": 0.7788461538461539
        },
        "nist": 5.200916771567881,
        "rouge1": {
            "precision": 0.78169,
            "recall": 0.76754,
            "fmeasure": 0.76875
        },
        "rouge2": {
            "precision": 0.52897,
            "recall": 0.51184,
            "fmeasure": 0.51679
        },
        "rougeL": {
            "precision": 0.59639,
            "recall": 0.57296,
            "fmeasure": 0.58016
        },
        "rougeLsum": {
            "precision": 0.59639,
            "recall": 0.57296,
            "fmeasure": 0.58016
        },
        "bleu": 39.36921,
        "nubia": {
            "semantic_relation": 4.39031,
            "contradiction": 1.11405,
            "irrelevancy": 33.17283,
            "logical_agreement": 65.71312,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.64474,
            "nubia_score": 0.76492
        },
        "bleurt": 0.23377,
        "meteor": 0.38632182530341597,
        "bertscore": {
            "precision": 0.9375,
            "recall": 0.93092,
            "f1": 0.93368
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.5,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.6717805845106355,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.096369598558668,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015323,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.048968687611256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.36363636363636365,
            "3": 0.6666666666666666
        },
        "nist": 2.8209207860620533,
        "rouge1": {
            "precision": 0.62573,
            "recall": 0.63862,
            "fmeasure": 0.59223
        },
        "rouge2": {
            "precision": 0.24306,
            "recall": 0.28043,
            "fmeasure": 0.24819
        },
        "rougeL": {
            "precision": 0.47076,
            "recall": 0.45345,
            "fmeasure": 0.43932
        },
        "rougeLsum": {
            "precision": 0.47076,
            "recall": 0.45345,
            "fmeasure": 0.43932
        },
        "bleu": 9.27977,
        "nubia": {
            "semantic_relation": 3.94536,
            "contradiction": 0.4094,
            "irrelevancy": 45.89654,
            "logical_agreement": 53.69406,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.51209,
            "nubia_score": 0.60285
        },
        "bleurt": -0.09246,
        "meteor": 0.3250286747445532,
        "bertscore": {
            "precision": 0.88897,
            "recall": 0.88785,
            "f1": 0.88277
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 5.656854249492381,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.7111111111111111,
        "vocab_size-1": 32,
        "unique-1": 24,
        "entropy-1": 4.789416641342189,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 39,
        "unique-2": 36,
        "entropy-2": 5.249460279921618,
        "cond_entropy-2": 0.46259862345948577,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": 0.046930949929642,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 5.185449728701348,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7317073170731707,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.6841461393879165,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.090032776601483,
        "cond_entropy-2-nopunct": 0.4327344686791022,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": 0.05278407492995249,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6764705882352942
        },
        "nist": 3.8896718486544217,
        "rouge1": {
            "precision": 0.75967,
            "recall": 0.70073,
            "fmeasure": 0.72809
        },
        "rouge2": {
            "precision": 0.44048,
            "recall": 0.39932,
            "fmeasure": 0.41836
        },
        "rougeL": {
            "precision": 0.58594,
            "recall": 0.55216,
            "fmeasure": 0.56821
        },
        "rougeLsum": {
            "precision": 0.58594,
            "recall": 0.55216,
            "fmeasure": 0.56821
        },
        "bleu": 28.99589,
        "nubia": {
            "semantic_relation": 4.60009,
            "contradiction": 0.69238,
            "irrelevancy": 1.18133,
            "logical_agreement": 98.1263,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.20259,
            "nubia_score": 0.92146
        },
        "bleurt": 0.45607,
        "meteor": 0.35001948375427944,
        "bertscore": {
            "precision": 0.92285,
            "recall": 0.91955,
            "f1": 0.92089
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 2.7726341266023544,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.8113207547169812,
        "vocab_size-1": 43,
        "unique-1": 37,
        "entropy-1": 5.284339794104197,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.20331541004847753,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.12285674778553377,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 2.384848003542364,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8723404255319149,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.267146830308981,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.18585671707857537,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.14086253583984967,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16,
            "2": 0.6875,
            "3": 0.8095238095238095
        },
        "nist": 4.149850329214002,
        "rouge1": {
            "precision": 0.67493,
            "recall": 0.79205,
            "fmeasure": 0.71705
        },
        "rouge2": {
            "precision": 0.45625,
            "recall": 0.53109,
            "fmeasure": 0.48009
        },
        "rougeL": {
            "precision": 0.64008,
            "recall": 0.74943,
            "fmeasure": 0.67877
        },
        "rougeLsum": {
            "precision": 0.64008,
            "recall": 0.74943,
            "fmeasure": 0.67877
        },
        "bleu": 37.14014,
        "nubia": {
            "semantic_relation": 3.83836,
            "contradiction": 23.91206,
            "irrelevancy": 26.82205,
            "logical_agreement": 49.26589,
            "grammar_ref": 4.75156,
            "grammar_hyp": 4.80054,
            "nubia_score": 0.59352
        },
        "bleurt": 0.21666,
        "meteor": 0.39319643314791985,
        "bertscore": {
            "precision": 0.90997,
            "recall": 0.93061,
            "f1": 0.91918
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.084183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.17625665551219521,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9057645846554525,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.19723710464117222,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "nist": 3.217653730066315,
        "rouge1": {
            "precision": 0.73684,
            "recall": 0.58333,
            "fmeasure": 0.65116
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.26087,
            "fmeasure": 0.29268
        },
        "rougeL": {
            "precision": 0.50877,
            "recall": 0.65278,
            "fmeasure": 0.55764
        },
        "rougeLsum": {
            "precision": 0.50877,
            "recall": 0.65278,
            "fmeasure": 0.55764
        },
        "bleu": 10.47524,
        "nubia": {
            "semantic_relation": 3.65024,
            "contradiction": 83.07504,
            "irrelevancy": 8.79015,
            "logical_agreement": 8.13481,
            "grammar_ref": 4.791,
            "grammar_hyp": 5.27573,
            "nubia_score": 0.45751
        },
        "bleurt": 0.06732,
        "meteor": 0.3412676485337015,
        "bertscore": {
            "precision": 0.9158,
            "recall": 0.93056,
            "f1": 0.90438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.765,
        "total_length": 284,
        "mean_pred_length": 15.777777777777779,
        "std_pred_length": 4.825344611246325,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6091549295774648,
        "vocab_size-1": 173,
        "unique-1": 145,
        "entropy-1": 6.712819305854051,
        "distinct-2": 0.9398496240601504,
        "vocab_size-2": 250,
        "unique-2": 244,
        "entropy-2": 7.879365189187439,
        "cond_entropy-2": 1.0025527718463505,
        "distinct-3": 0.9959677419354839,
        "vocab_size-3": 247,
        "unique-3": 246,
        "entropy-3": 7.946131794257869,
        "cond_entropy-3": 0.07147027617387638,
        "total_length-nopunct": 250,
        "mean_pred_length-nopunct": 13.88888888888889,
        "std_pred_length-nopunct": 4.483164667073781,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.672,
        "vocab_size-1-nopunct": 168,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 6.799459961594597,
        "distinct-2-nopunct": 0.9353448275862069,
        "vocab_size-2-nopunct": 217,
        "unique-2-nopunct": 212,
        "entropy-2-nopunct": 7.664903462716039,
        "cond_entropy-2-nopunct": 0.9395231687643927,
        "distinct-3-nopunct": 0.9953271028037384,
        "vocab_size-3-nopunct": 213,
        "unique-3-nopunct": 212,
        "entropy-3-nopunct": 7.732121192008589,
        "cond_entropy-3-nopunct": 0.08345789557016993,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.35714285714285715,
            "3": 0.7473684210526316
        },
        "nist": 5.581633546715506,
        "rouge1": {
            "precision": 0.66036,
            "recall": 0.69886,
            "fmeasure": 0.67234
        },
        "rouge2": {
            "precision": 0.40534,
            "recall": 0.43401,
            "fmeasure": 0.41485
        },
        "rougeL": {
            "precision": 0.57005,
            "recall": 0.61576,
            "fmeasure": 0.58593
        },
        "rougeLsum": {
            "precision": 0.57005,
            "recall": 0.61576,
            "fmeasure": 0.58593
        },
        "bleu": 40.1695,
        "nubia": {
            "semantic_relation": 4.15168,
            "contradiction": 1.78792,
            "irrelevancy": 41.24313,
            "logical_agreement": 56.96895,
            "grammar_ref": 5.08526,
            "grammar_hyp": 5.04752,
            "nubia_score": 0.70248
        },
        "bleurt": 0.22503,
        "meteor": 0.37804493777079345,
        "bertscore": {
            "precision": 0.90698,
            "recall": 0.91194,
            "f1": 0.90817
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 180,
        "mean_pred_length": 16.363636363636363,
        "std_pred_length": 5.448481477735163,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6222222222222222,
        "vocab_size-1": 112,
        "unique-1": 90,
        "entropy-1": 6.300012848324711,
        "distinct-2": 0.9112426035502958,
        "vocab_size-2": 154,
        "unique-2": 143,
        "entropy-2": 7.197539034053775,
        "cond_entropy-2": 0.7499314811316885,
        "distinct-3": 0.9810126582278481,
        "vocab_size-3": 155,
        "unique-3": 152,
        "entropy-3": 7.265806064632815,
        "cond_entropy-3": 0.08242364086074333,
        "total_length-nopunct": 162,
        "mean_pred_length-nopunct": 14.727272727272727,
        "std_pred_length-nopunct": 4.863423954580093,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6790123456790124,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.371788198060671,
        "distinct-2-nopunct": 0.9006622516556292,
        "vocab_size-2-nopunct": 136,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 7.010825083850888,
        "cond_entropy-2-nopunct": 0.7029354278634874,
        "distinct-3-nopunct": 0.9785714285714285,
        "vocab_size-3-nopunct": 137,
        "unique-3-nopunct": 134,
        "entropy-3-nopunct": 7.086425874087835,
        "cond_entropy-3-nopunct": 0.08633919173846102,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.5263157894736842,
            "3": 0.8467741935483871
        },
        "nist": 5.893176386740882,
        "rouge1": {
            "precision": 0.78954,
            "recall": 0.81242,
            "fmeasure": 0.78733
        },
        "rouge2": {
            "precision": 0.63452,
            "recall": 0.6704,
            "fmeasure": 0.63919
        },
        "rougeL": {
            "precision": 0.73317,
            "recall": 0.75018,
            "fmeasure": 0.7285
        },
        "rougeLsum": {
            "precision": 0.73317,
            "recall": 0.75018,
            "fmeasure": 0.7285
        },
        "bleu": 53.85359,
        "nubia": {
            "semantic_relation": 4.66027,
            "contradiction": 3.74011,
            "irrelevancy": 14.4396,
            "logical_agreement": 81.82029,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.40698,
            "nubia_score": 0.8713
        },
        "bleurt": 0.45833,
        "meteor": 0.43716395271848063,
        "bertscore": {
            "precision": 0.94866,
            "recall": 0.94095,
            "f1": 0.9439
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 3.344772040064913,
        "median_pred_length": 13.5,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.7358490566037735,
        "vocab_size-1": 39,
        "unique-1": 32,
        "entropy-1": 5.072167860182754,
        "distinct-2": 0.9183673469387755,
        "vocab_size-2": 45,
        "unique-2": 41,
        "entropy-2": 5.451444537992759,
        "cond_entropy-2": 0.2695421957186106,
        "distinct-3": 0.9555555555555556,
        "vocab_size-3": 43,
        "unique-3": 41,
        "entropy-3": 5.402964207440784,
        "cond_entropy-3": -0.03396785889664474,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 2.8613807855648994,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7872340425531915,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.027889117589055,
        "distinct-2-nopunct": 0.9069767441860465,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.240218243074191,
        "cond_entropy-2-nopunct": 0.26132444958640166,
        "distinct-3-nopunct": 0.9487179487179487,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.182838116298145,
        "cond_entropy-3-nopunct": -0.03829843327574718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.4166666666666667,
            "3": 0.55
        },
        "nist": 3.573135594712396,
        "rouge1": {
            "precision": 0.70754,
            "recall": 0.60304,
            "fmeasure": 0.63127
        },
        "rouge2": {
            "precision": 0.42772,
            "recall": 0.35602,
            "fmeasure": 0.37446
        },
        "rougeL": {
            "precision": 0.62697,
            "recall": 0.54451,
            "fmeasure": 0.56755
        },
        "rougeLsum": {
            "precision": 0.62697,
            "recall": 0.54451,
            "fmeasure": 0.56755
        },
        "bleu": 27.06453,
        "nubia": {
            "semantic_relation": 3.991,
            "contradiction": 7.62404,
            "irrelevancy": 20.44361,
            "logical_agreement": 71.93235,
            "grammar_ref": 4.84918,
            "grammar_hyp": 5.15712,
            "nubia_score": 0.60169
        },
        "bleurt": 0.1197,
        "meteor": 0.3020734550793683,
        "bertscore": {
            "precision": 0.92735,
            "recall": 0.90553,
            "f1": 0.91585
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 1.5,
        "median_pred_length": 12.5,
        "min_pred_length": 11,
        "max_pred_length": 14,
        "distinct-1": 0.76,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.103465189601645,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.38013076647041577,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.936260027531526,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.4379852264664117,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.9411764705882353
        },
        "nist": 5.318802960978226,
        "rouge1": {
            "precision": 0.9188,
            "recall": 0.797,
            "fmeasure": 0.85185
        },
        "rouge2": {
            "precision": 0.72917,
            "recall": 0.62308,
            "fmeasure": 0.67044
        },
        "rougeL": {
            "precision": 0.81339,
            "recall": 0.70808,
            "fmeasure": 0.75556
        },
        "rougeLsum": {
            "precision": 0.81339,
            "recall": 0.70808,
            "fmeasure": 0.75556
        },
        "bleu": 71.46705,
        "nubia": {
            "semantic_relation": 4.34864,
            "contradiction": 0.82063,
            "irrelevancy": 13.90884,
            "logical_agreement": 85.27053,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.27682,
            "nubia_score": 0.72077
        },
        "bleurt": 0.32745,
        "meteor": 0.4560162464622809,
        "bertscore": {
            "precision": 0.95117,
            "recall": 0.93224,
            "f1": 0.94137
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.74,
        "total_length": 188,
        "mean_pred_length": 14.461538461538462,
        "std_pred_length": 4.3785382986946795,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.648936170212766,
        "vocab_size-1": 122,
        "unique-1": 92,
        "entropy-1": 6.559978740976055,
        "distinct-2": 0.9542857142857143,
        "vocab_size-2": 167,
        "unique-2": 159,
        "entropy-2": 7.359782540403737,
        "cond_entropy-2": 0.6562391344797721,
        "distinct-3": 0.9814814814814815,
        "vocab_size-3": 159,
        "unique-3": 156,
        "entropy-3": 7.3028129658475684,
        "cond_entropy-3": -0.049632713885975684,
        "total_length-nopunct": 172,
        "mean_pred_length-nopunct": 13.23076923076923,
        "std_pred_length-nopunct": 4.370422372720552,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.686046511627907,
        "vocab_size-1-nopunct": 118,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.588020187814141,
        "distinct-2-nopunct": 0.949685534591195,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 143,
        "entropy-2-nopunct": 7.212254024466716,
        "cond_entropy-2-nopunct": 0.6739016314295878,
        "distinct-3-nopunct": 0.9794520547945206,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.148728668469062,
        "cond_entropy-3-nopunct": -0.06141456078789957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.37254901960784315,
            "3": 0.7073170731707317
        },
        "nist": 4.444145186986296,
        "rouge1": {
            "precision": 0.67571,
            "recall": 0.63219,
            "fmeasure": 0.64098
        },
        "rouge2": {
            "precision": 0.43892,
            "recall": 0.41557,
            "fmeasure": 0.41738
        },
        "rougeL": {
            "precision": 0.5823,
            "recall": 0.54749,
            "fmeasure": 0.55328
        },
        "rougeLsum": {
            "precision": 0.5823,
            "recall": 0.54749,
            "fmeasure": 0.55328
        },
        "bleu": 30.24506,
        "nubia": {
            "semantic_relation": 3.87459,
            "contradiction": 19.17463,
            "irrelevancy": 27.7856,
            "logical_agreement": 53.03976,
            "grammar_ref": 4.86507,
            "grammar_hyp": 5.13077,
            "nubia_score": 0.60039
        },
        "bleurt": 0.01298,
        "meteor": 0.35251646277723075,
        "bertscore": {
            "precision": 0.90033,
            "recall": 0.89339,
            "f1": 0.89604
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 1.0,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 17,
        "distinct-1": 0.96875,
        "vocab_size-1": 31,
        "unique-1": 30,
        "entropy-1": 4.9375,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.09310940439148141,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.754887502163471,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.11103131238874399,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.3,
            "3": 0.8571428571428571
        },
        "nist": 3.570760058086446,
        "rouge1": {
            "precision": 0.59444,
            "recall": 0.68148,
            "fmeasure": 0.62144
        },
        "rouge2": {
            "precision": 0.36538,
            "recall": 0.39815,
            "fmeasure": 0.37482
        },
        "rougeL": {
            "precision": 0.54921,
            "recall": 0.63502,
            "fmeasure": 0.57632
        },
        "rougeLsum": {
            "precision": 0.54921,
            "recall": 0.63502,
            "fmeasure": 0.57632
        },
        "bleu": 40.22196,
        "nubia": {
            "semantic_relation": 4.34876,
            "contradiction": 0.39613,
            "irrelevancy": 16.09128,
            "logical_agreement": 83.51259,
            "grammar_ref": 4.57807,
            "grammar_hyp": 4.02494,
            "nubia_score": 0.79673
        },
        "bleurt": 0.39648,
        "meteor": 0.40725750698920055,
        "bertscore": {
            "precision": 0.92151,
            "recall": 0.93839,
            "f1": 0.92764
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.041522986797286,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.75,
        "vocab_size-1": 51,
        "unique-1": 40,
        "entropy-1": 5.506436738245535,
        "distinct-2": 0.953125,
        "vocab_size-2": 61,
        "unique-2": 58,
        "entropy-2": 5.90625,
        "cond_entropy-2": 0.3111273931922692,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 58,
        "unique-3": 56,
        "entropy-3": 5.8402239289418505,
        "cond_entropy-3": -0.05977607105814807,
        "total_length-nopunct": 56,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.0990195135927845,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8392857142857143,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.458966082694626,
        "distinct-2-nopunct": 0.9423076923076923,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.58505510275648,
        "cond_entropy-2-nopunct": 0.15288816155131352,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.5016291673878275,
        "cond_entropy-3-nopunct": -0.0738105507532692,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.11764705882352941,
            "2": 0.4473684210526316,
            "3": 0.85
        },
        "nist": 4.102542707278784,
        "rouge1": {
            "precision": 0.55568,
            "recall": 0.5106,
            "fmeasure": 0.52206
        },
        "rouge2": {
            "precision": 0.30921,
            "recall": 0.33741,
            "fmeasure": 0.31739
        },
        "rougeL": {
            "precision": 0.48845,
            "recall": 0.50597,
            "fmeasure": 0.491
        },
        "rougeLsum": {
            "precision": 0.48845,
            "recall": 0.50597,
            "fmeasure": 0.491
        },
        "bleu": 41.40045,
        "nubia": {
            "semantic_relation": 3.23705,
            "contradiction": 38.84477,
            "irrelevancy": 39.05011,
            "logical_agreement": 22.10511,
            "grammar_ref": 4.83501,
            "grammar_hyp": 4.27397,
            "nubia_score": 0.46779
        },
        "bleurt": -0.21584,
        "meteor": 0.36961494575796566,
        "bertscore": {
            "precision": 0.85253,
            "recall": 0.85931,
            "f1": 0.84443
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 7.5,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6551724137931034,
        "vocab_size-1": 38,
        "unique-1": 28,
        "entropy-1": 4.963596460973654,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 51,
        "unique-2": 48,
        "entropy-2": 5.643776391052356,
        "cond_entropy-2": 0.5982824881641782,
        "distinct-3": 0.98,
        "vocab_size-3": 49,
        "unique-3": 48,
        "entropy-3": 5.603856189774728,
        "cond_entropy-3": -0.07103131238874397,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 6.7592529172978875,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.905377979642797,
        "distinct-2-nopunct": 0.9574468085106383,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.469482468698917,
        "cond_entropy-2-nopunct": 0.5868319241479238,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.08181246906856265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0,
            "3": 0.725
        },
        "nist": 4.5934162331999095,
        "rouge1": {
            "precision": 0.6911,
            "recall": 0.71815,
            "fmeasure": 0.69842
        },
        "rouge2": {
            "precision": 0.33953,
            "recall": 0.36833,
            "fmeasure": 0.35045
        },
        "rougeL": {
            "precision": 0.57481,
            "recall": 0.5854,
            "fmeasure": 0.57414
        },
        "rougeLsum": {
            "precision": 0.57481,
            "recall": 0.5854,
            "fmeasure": 0.57414
        },
        "bleu": 35.3204,
        "nubia": {
            "semantic_relation": 4.53053,
            "contradiction": 12.24791,
            "irrelevancy": 11.7558,
            "logical_agreement": 75.99629,
            "grammar_ref": 4.90076,
            "grammar_hyp": 4.95767,
            "nubia_score": 0.78811
        },
        "bleurt": 0.25926,
        "meteor": 0.39035418689887214,
        "bertscore": {
            "precision": 0.91938,
            "recall": 0.92597,
            "f1": 0.92192
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.6144838329894124,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.96078,
            "fmeasure": 0.94819
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.7619,
            "fmeasure": 0.769
        },
        "rougeL": {
            "precision": 0.89583,
            "recall": 0.87712,
            "fmeasure": 0.88563
        },
        "rougeLsum": {
            "precision": 0.89583,
            "recall": 0.87712,
            "fmeasure": 0.88563
        },
        "bleu": 78.93575,
        "nubia": {
            "semantic_relation": 4.80996,
            "contradiction": 0.22818,
            "irrelevancy": 0.49433,
            "logical_agreement": 99.27749,
            "grammar_ref": 4.24096,
            "grammar_hyp": 3.78167,
            "nubia_score": 0.97089
        },
        "bleurt": 0.73059,
        "meteor": 0.5305475968023703,
        "bertscore": {
            "precision": 0.97737,
            "recall": 0.97443,
            "f1": 0.97475
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.6451714496047405,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.96296,
            "fmeasure": 0.91228
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.79167,
            "fmeasure": 0.7451
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 0.85185,
            "fmeasure": 0.80702
        },
        "bleu": 55.83948,
        "nubia": {
            "semantic_relation": 4.99771,
            "contradiction": 0.25029,
            "irrelevancy": 0.44471,
            "logical_agreement": 99.30501,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.0976,
            "nubia_score": 0.99587
        },
        "bleurt": 0.67063,
        "meteor": 0.4336185492206869,
        "bertscore": {
            "precision": 0.94907,
            "recall": 0.93812,
            "f1": 0.94353
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 1.0,
            "3": 0.5714285714285714
        },
        "nist": 1.788192533264089,
        "rouge1": {
            "precision": 0.53333,
            "recall": 0.52422,
            "fmeasure": 0.52479
        },
        "rouge2": {
            "precision": 0.51852,
            "recall": 0.44444,
            "fmeasure": 0.47432
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.52422,
            "fmeasure": 0.52479
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.52422,
            "fmeasure": 0.52479
        },
        "bleu": 42.7287,
        "nubia": {
            "semantic_relation": 1.4738,
            "contradiction": 95.59341,
            "irrelevancy": 3.93932,
            "logical_agreement": 0.46727,
            "grammar_ref": 4.13721,
            "grammar_hyp": 4.32767,
            "nubia_score": 0.08649
        },
        "bleurt": -0.11977,
        "meteor": 0.2228979147001447,
        "bertscore": {
            "precision": 0.92759,
            "recall": 0.89609,
            "f1": 0.90638
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.0,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.8928571428571429,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.593069207771891,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.4838561897747224,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.05361880976054911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.8666666666666667
        },
        "nist": 2.8993933909694083,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.78357,
            "fmeasure": 0.74475
        },
        "rouge2": {
            "precision": 0.50139,
            "recall": 0.52778,
            "fmeasure": 0.50893
        },
        "rougeL": {
            "precision": 0.57639,
            "recall": 0.60874,
            "fmeasure": 0.58553
        },
        "rougeLsum": {
            "precision": 0.57639,
            "recall": 0.60874,
            "fmeasure": 0.58553
        },
        "bleu": 30.31644,
        "nubia": {
            "semantic_relation": 4.12901,
            "contradiction": 13.94382,
            "irrelevancy": 5.01325,
            "logical_agreement": 81.04293,
            "grammar_ref": 3.96214,
            "grammar_hyp": 4.10518,
            "nubia_score": 0.67194
        },
        "bleurt": 0.13025,
        "meteor": 0.42863224456971216,
        "bertscore": {
            "precision": 0.92097,
            "recall": 0.92503,
            "f1": 0.92292
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 22.666666666666668,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 23.0,
        "min_pred_length": 22,
        "max_pred_length": 23,
        "distinct-1": 0.7058823529411765,
        "vocab_size-1": 48,
        "unique-1": 32,
        "entropy-1": 5.43504331218269,
        "distinct-2": 0.8615384615384616,
        "vocab_size-2": 56,
        "unique-2": 47,
        "entropy-2": 5.745444736105381,
        "cond_entropy-2": 0.27402189303523666,
        "distinct-3": 0.9193548387096774,
        "vocab_size-3": 57,
        "unique-3": 52,
        "entropy-3": 5.792905987806228,
        "cond_entropy-3": 0.04473172316487237,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 19.666666666666668,
        "std_pred_length-nopunct": 0.9428090415820634,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7288135593220338,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.279089820981552,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.521640636343323,
        "cond_entropy-2-nopunct": 0.19770673661628857,
        "distinct-3-nopunct": 0.9056603773584906,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.539241209280177,
        "cond_entropy-3-nopunct": -0.022830693909499235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.45161290322580644,
            "3": 0.8
        },
        "nist": 4.116110215103091,
        "rouge1": {
            "precision": 0.67222,
            "recall": 0.62663,
            "fmeasure": 0.63982
        },
        "rouge2": {
            "precision": 0.53778,
            "recall": 0.50519,
            "fmeasure": 0.51579
        },
        "rougeL": {
            "precision": 0.60873,
            "recall": 0.58728,
            "fmeasure": 0.59127
        },
        "rougeLsum": {
            "precision": 0.60873,
            "recall": 0.58728,
            "fmeasure": 0.59127
        },
        "bleu": 38.85318,
        "nubia": {
            "semantic_relation": 3.82415,
            "contradiction": 12.01502,
            "irrelevancy": 33.7659,
            "logical_agreement": 54.21909,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.60011,
            "nubia_score": 0.64828
        },
        "bleurt": 0.17324,
        "meteor": 0.32694822833591675,
        "bertscore": {
            "precision": 0.92441,
            "recall": 0.90278,
            "f1": 0.9119
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.546060565661952,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.6851851851851852,
        "vocab_size-1": 37,
        "unique-1": 26,
        "entropy-1": 5.016474483998151,
        "distinct-2": 0.7647058823529411,
        "vocab_size-2": 39,
        "unique-2": 28,
        "entropy-2": 5.187035390948681,
        "cond_entropy-2": 0.12076387856489526,
        "distinct-3": 0.7916666666666666,
        "vocab_size-3": 38,
        "unique-3": 28,
        "entropy-3": 5.168295834054487,
        "cond_entropy-3": -0.030069351621933808,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.941467880199448,
        "distinct-2-nopunct": 0.7659574468085106,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 5.070442309078412,
        "cond_entropy-2-nopunct": 0.1312545337454719,
        "distinct-3-nopunct": 0.7954545454545454,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 5.050340709546388,
        "cond_entropy-3-nopunct": -0.032546153445716056,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.8,
            "3": 0.9310344827586207
        },
        "nist": 4.094828567885553,
        "rouge1": {
            "precision": 0.72255,
            "recall": 0.91497,
            "fmeasure": 0.80428
        },
        "rouge2": {
            "precision": 0.56938,
            "recall": 0.75571,
            "fmeasure": 0.64583
        },
        "rougeL": {
            "precision": 0.71144,
            "recall": 0.91375,
            "fmeasure": 0.79596
        },
        "rougeLsum": {
            "precision": 0.71144,
            "recall": 0.91375,
            "fmeasure": 0.79596
        },
        "bleu": 48.46702,
        "nubia": {
            "semantic_relation": 4.29292,
            "contradiction": 0.089,
            "irrelevancy": 56.14629,
            "logical_agreement": 43.76471,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.09364,
            "nubia_score": 0.82615
        },
        "bleurt": 0.41706,
        "meteor": 0.5023129945179833,
        "bertscore": {
            "precision": 0.92888,
            "recall": 0.97581,
            "f1": 0.94962
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.0,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7631578947368421,
        "vocab_size-1": 29,
        "unique-1": 22,
        "entropy-1": 4.721611723969901,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 34,
        "unique-2": 32,
        "entropy-2": 5.058813890331199,
        "cond_entropy-2": 0.3108863768876156,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 33,
        "unique-3": 32,
        "entropy-3": 5.028639311838573,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7878787878787878,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.559545634509969,
        "distinct-2-nopunct": 0.9354838709677419,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.825164052322361,
        "cond_entropy-2-nopunct": 0.2646409007058413,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.789015477886192,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.9583333333333334
        },
        "nist": 5.136842527877646,
        "rouge1": {
            "precision": 0.97619,
            "recall": 0.95455,
            "fmeasure": 0.964
        },
        "rouge2": {
            "precision": 0.89444,
            "recall": 0.87368,
            "fmeasure": 0.88259
        },
        "rougeL": {
            "precision": 0.97619,
            "recall": 0.95455,
            "fmeasure": 0.964
        },
        "rougeLsum": {
            "precision": 0.97619,
            "recall": 0.95455,
            "fmeasure": 0.964
        },
        "bleu": 88.68354,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.56047,
            "irrelevancy": 1.75292,
            "logical_agreement": 97.68661,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.57731,
            "nubia_score": 0.98274
        },
        "bleurt": 0.79929,
        "meteor": 0.6055123574117481,
        "bertscore": {
            "precision": 0.99242,
            "recall": 0.98939,
            "f1": 0.99089
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 5.312459150169742,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 44,
        "unique-1": 38,
        "entropy-1": 5.204975771318481,
        "distinct-2": 0.9636363636363636,
        "vocab_size-2": 53,
        "unique-2": 51,
        "entropy-2": 5.708632440797383,
        "cond_entropy-2": 0.5029114998684914,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.0039969184604905636,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 5.354126134736337,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.12758559510926,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.59399396942248,
        "cond_entropy-2-nopunct": 0.5033084864928742,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.004129507917006088,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.7692307692307693,
            "3": 0.7666666666666667
        },
        "nist": 4.925810541159249,
        "rouge1": {
            "precision": 0.6892,
            "recall": 0.73514,
            "fmeasure": 0.7085
        },
        "rouge2": {
            "precision": 0.49407,
            "recall": 0.55986,
            "fmeasure": 0.52109
        },
        "rougeL": {
            "precision": 0.62487,
            "recall": 0.67608,
            "fmeasure": 0.64687
        },
        "rougeLsum": {
            "precision": 0.62487,
            "recall": 0.67608,
            "fmeasure": 0.64687
        },
        "bleu": 57.28496,
        "nubia": {
            "semantic_relation": 4.47648,
            "contradiction": 0.41671,
            "irrelevancy": 74.70828,
            "logical_agreement": 24.87502,
            "grammar_ref": 4.38609,
            "grammar_hyp": 4.21052,
            "nubia_score": 0.77849
        },
        "bleurt": 0.16628,
        "meteor": 0.4696512965587964,
        "bertscore": {
            "precision": 0.9254,
            "recall": 0.94529,
            "f1": 0.93453
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 389,
        "msttr-100": 0.30776,
        "msttr-100_nopunct": 0.29758,
        "total_length": 6733,
        "mean_pred_length": 17.308483290488432,
        "std_pred_length": 4.631673121033737,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.030892618446457746,
        "vocab_size-1": 208,
        "unique-1": 22,
        "entropy-1": 6.113045909063821,
        "distinct-2": 0.09977931904161412,
        "vocab_size-2": 633,
        "unique-2": 139,
        "entropy-2": 7.981446077506575,
        "cond_entropy-2": 1.765997358641585,
        "distinct-3": 0.1632241813602015,
        "vocab_size-3": 972,
        "unique-3": 258,
        "entropy-3": 8.90826006541031,
        "cond_entropy-3": 0.9499539168311876,
        "total_length-nopunct": 6231,
        "mean_pred_length-nopunct": 16.017994858611825,
        "std_pred_length-nopunct": 4.411621144295619,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.03306050393195314,
        "vocab_size-1-nopunct": 206,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 6.163208889990149,
        "distinct-2-nopunct": 0.10184868195823348,
        "vocab_size-2-nopunct": 595,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.893857829924218,
        "cond_entropy-2-nopunct": 1.8154517443197555,
        "distinct-3-nopunct": 0.16944801026957637,
        "vocab_size-3-nopunct": 924,
        "unique-3-nopunct": 253,
        "entropy-3-nopunct": 8.878438627670485,
        "cond_entropy-3-nopunct": 0.9876454083929685,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6056269312083266
        },
        "nist": 4.341555298249099,
        "rouge1": {
            "precision": 0.65826,
            "recall": 0.62242,
            "fmeasure": 0.62361
        },
        "rouge2": {
            "precision": 0.38918,
            "recall": 0.36564,
            "fmeasure": 0.36648
        },
        "rougeL": {
            "precision": 0.51357,
            "recall": 0.48355,
            "fmeasure": 0.48538
        },
        "rougeLsum": {
            "precision": 0.51357,
            "recall": 0.48355,
            "fmeasure": 0.48538
        },
        "bleu": 25.18198,
        "nubia": {
            "semantic_relation": 3.92544,
            "contradiction": 6.16227,
            "irrelevancy": 40.15408,
            "logical_agreement": 53.68365,
            "grammar_ref": 5.31197,
            "grammar_hyp": 5.01718,
            "nubia_score": 0.66259
        },
        "bleurt": 0.00043,
        "meteor": 0.3149888345677902,
        "bertscore": {
            "precision": 0.90035,
            "recall": 0.88934,
            "f1": 0.89432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "nist": 2.728440861296354,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.39683,
            "fmeasure": 0.41071
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "bleu": 51.3345,
        "nubia": {
            "semantic_relation": 3.8356,
            "contradiction": 0.29358,
            "irrelevancy": 2.30585,
            "logical_agreement": 97.40056,
            "grammar_ref": 6.57359,
            "grammar_hyp": 6.42103,
            "nubia_score": 0.64627
        },
        "bleurt": 0.49581,
        "meteor": 0.4099828269763827,
        "bertscore": {
            "precision": 0.95461,
            "recall": 0.9542,
            "f1": 0.95441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 79,
        "mean_pred_length": 15.8,
        "std_pred_length": 7.547184905645283,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.6582278481012658,
        "vocab_size-1": 52,
        "unique-1": 41,
        "entropy-1": 5.362457609232797,
        "distinct-2": 0.8783783783783784,
        "vocab_size-2": 65,
        "unique-2": 58,
        "entropy-2": 5.939183095358685,
        "cond_entropy-2": 0.4781662387572563,
        "distinct-3": 0.8985507246376812,
        "vocab_size-3": 62,
        "unique-3": 55,
        "entropy-3": 5.905625906053528,
        "cond_entropy-3": -0.013972387111650155,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 5.678027826631356,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7205882352941176,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.376219782770928,
        "distinct-2-nopunct": 0.9047619047619048,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.78680373302373,
        "cond_entropy-2-nopunct": 0.46703181203688293,
        "distinct-3-nopunct": 0.9137931034482759,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.685567202024122,
        "cond_entropy-3-nopunct": -0.08481616975165487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.125,
            "3": 0.7678571428571429
        },
        "nist": 4.576798880337325,
        "rouge1": {
            "precision": 0.79028,
            "recall": 0.78268,
            "fmeasure": 0.78037
        },
        "rouge2": {
            "precision": 0.61436,
            "recall": 0.6087,
            "fmeasure": 0.60641
        },
        "rougeL": {
            "precision": 0.75833,
            "recall": 0.74983,
            "fmeasure": 0.7479
        },
        "rougeLsum": {
            "precision": 0.75833,
            "recall": 0.74983,
            "fmeasure": 0.7479
        },
        "bleu": 42.82632,
        "nubia": {
            "semantic_relation": 4.20609,
            "contradiction": 28.27587,
            "irrelevancy": 28.54454,
            "logical_agreement": 43.17959,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.4528,
            "nubia_score": 0.70406
        },
        "bleurt": 0.1418,
        "meteor": 0.4096545037710095,
        "bertscore": {
            "precision": 0.94527,
            "recall": 0.9392,
            "f1": 0.94151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.943920288775949,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 15,
        "distinct-1": 0.8611111111111112,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.871178126382214,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.05628729973432274,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.13750352374993471,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.90625,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.8125,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.030394788231020403,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.5,
            "3": 0.7727272727272727
        },
        "nist": 4.459033738443228,
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.7558,
            "fmeasure": 0.76039
        },
        "rouge2": {
            "precision": 0.45613,
            "recall": 0.47222,
            "fmeasure": 0.46045
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.62808,
            "fmeasure": 0.60628
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.62808,
            "fmeasure": 0.60628
        },
        "bleu": 40.67744,
        "nubia": {
            "semantic_relation": 4.28408,
            "contradiction": 0.26642,
            "irrelevancy": 47.73908,
            "logical_agreement": 51.99449,
            "grammar_ref": 5.1114,
            "grammar_hyp": 4.81965,
            "nubia_score": 0.71184
        },
        "bleurt": 0.00109,
        "meteor": 0.3926826716825394,
        "bertscore": {
            "precision": 0.91045,
            "recall": 0.90435,
            "f1": 0.8977
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.242640687119285,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.8541666666666666,
        "vocab_size-1": 41,
        "unique-1": 36,
        "entropy-1": 5.261842188131015,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.1458880956565952,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.2998316455372216,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8837209302325582,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.176151091861087,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.16453552773935098,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "nist": 5.033373045493408,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.78345,
            "fmeasure": 0.793
        },
        "rouge2": {
            "precision": 0.68535,
            "recall": 0.64837,
            "fmeasure": 0.66435
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.78345,
            "fmeasure": 0.793
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.78345,
            "fmeasure": 0.793
        },
        "bleu": 67.56413,
        "nubia": {
            "semantic_relation": 4.25681,
            "contradiction": 0.78507,
            "irrelevancy": 14.75657,
            "logical_agreement": 84.45836,
            "grammar_ref": 5.35172,
            "grammar_hyp": 4.861,
            "nubia_score": 0.77489
        },
        "bleurt": 0.40437,
        "meteor": 0.4737052226836079,
        "bertscore": {
            "precision": 0.95807,
            "recall": 0.95846,
            "f1": 0.95773
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.77,
        "total_length": 120,
        "mean_pred_length": 17.142857142857142,
        "std_pred_length": 4.882287854467161,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7083333333333334,
        "vocab_size-1": 85,
        "unique-1": 72,
        "entropy-1": 6.047236299807931,
        "distinct-2": 0.9911504424778761,
        "vocab_size-2": 112,
        "unique-2": 111,
        "entropy-2": 6.802479847370959,
        "cond_entropy-2": 0.6446931499194537,
        "distinct-3": 1.0,
        "vocab_size-3": 106,
        "unique-3": 106,
        "entropy-3": 6.727920454563184,
        "cond_entropy-3": -0.0733905833236864,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 15.285714285714286,
        "std_pred_length-nopunct": 4.772369453854305,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7570093457943925,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.030821191846862,
        "distinct-2-nopunct": 0.99,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.62385618977474,
        "cond_entropy-2-nopunct": 0.6027802035466547,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 93,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.539158811108037,
        "cond_entropy-3-nopunct": -0.08319200232260755,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.4,
            "3": 0.8311688311688312
        },
        "nist": 5.613079712192381,
        "rouge1": {
            "precision": 0.77899,
            "recall": 0.79681,
            "fmeasure": 0.78159
        },
        "rouge2": {
            "precision": 0.51061,
            "recall": 0.52753,
            "fmeasure": 0.51416
        },
        "rougeL": {
            "precision": 0.6062,
            "recall": 0.62735,
            "fmeasure": 0.61287
        },
        "rougeLsum": {
            "precision": 0.6062,
            "recall": 0.62735,
            "fmeasure": 0.61287
        },
        "bleu": 46.06811,
        "nubia": {
            "semantic_relation": 4.38329,
            "contradiction": 1.75104,
            "irrelevancy": 31.963,
            "logical_agreement": 66.28596,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.79032,
            "nubia_score": 0.79004
        },
        "bleurt": 0.3028,
        "meteor": 0.41163803571470725,
        "bertscore": {
            "precision": 0.93653,
            "recall": 0.93404,
            "f1": 0.93425
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.957444505957562,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.23948928337392253,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.1154772174199358,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.265986323710904,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.926733681937769,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.13976873919382182,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.7142857142857143,
            "3": 0.36363636363636365
        },
        "nist": 2.6601074617000458,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.49316,
            "fmeasure": 0.53129
        },
        "rouge2": {
            "precision": 0.26636,
            "recall": 0.19067,
            "fmeasure": 0.21805
        },
        "rougeL": {
            "precision": 0.50926,
            "recall": 0.41168,
            "fmeasure": 0.4433
        },
        "rougeLsum": {
            "precision": 0.50926,
            "recall": 0.41168,
            "fmeasure": 0.4433
        },
        "bleu": 15.3649,
        "nubia": {
            "semantic_relation": 3.81132,
            "contradiction": 21.95201,
            "irrelevancy": 33.57529,
            "logical_agreement": 44.4727,
            "grammar_ref": 3.54742,
            "grammar_hyp": 4.21976,
            "nubia_score": 0.58513
        },
        "bleurt": 0.24583,
        "meteor": 0.27026304061397555,
        "bertscore": {
            "precision": 0.88103,
            "recall": 0.86264,
            "f1": 0.87052
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": NaN,
        "total_length": 108,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.8078865529319543,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 78,
        "unique-1": 61,
        "entropy-1": 6.051035535209724,
        "distinct-2": 0.94,
        "vocab_size-2": 94,
        "unique-2": 88,
        "entropy-2": 6.523856189774739,
        "cond_entropy-2": 0.3093946864283854,
        "distinct-3": 0.967391304347826,
        "vocab_size-3": 89,
        "unique-3": 86,
        "entropy-3": 6.458344564752679,
        "cond_entropy-3": -0.05507684241336393,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 11.875,
        "std_pred_length-nopunct": 3.4437443284889775,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.098751529360807,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 81,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.305012461365965,
        "cond_entropy-2-nopunct": 0.24958084731276264,
        "distinct-3-nopunct": 0.9620253164556962,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.227831381088497,
        "cond_entropy-3-nopunct": -0.06321338058301788,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.8301886792452831
        },
        "nist": 5.555223742998629,
        "rouge1": {
            "precision": 0.93251,
            "recall": 0.82072,
            "fmeasure": 0.85795
        },
        "rouge2": {
            "precision": 0.81143,
            "recall": 0.72367,
            "fmeasure": 0.75186
        },
        "rougeL": {
            "precision": 0.8858,
            "recall": 0.78054,
            "fmeasure": 0.81605
        },
        "rougeLsum": {
            "precision": 0.8858,
            "recall": 0.78054,
            "fmeasure": 0.81605
        },
        "bleu": 64.42699,
        "nubia": {
            "semantic_relation": 4.40262,
            "contradiction": 0.79761,
            "irrelevancy": 4.20275,
            "logical_agreement": 94.99965,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.33821,
            "nubia_score": 0.75914
        },
        "bleurt": 0.52979,
        "meteor": 0.46552592414549665,
        "bertscore": {
            "precision": 0.97489,
            "recall": 0.9431,
            "f1": 0.95754
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.0,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 13,
        "distinct-1": 0.6041666666666666,
        "vocab_size-1": 29,
        "unique-1": 20,
        "entropy-1": 4.605388542207535,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 34,
        "unique-2": 27,
        "entropy-2": 4.953416561671604,
        "cond_entropy-2": 0.2552620156925835,
        "distinct-3": 0.825,
        "vocab_size-3": 33,
        "unique-3": 27,
        "entropy-3": 4.953055907333277,
        "cond_entropy-3": 0.050240851358238414,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.572623663895163,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.765311532225103,
        "cond_entropy-2-nopunct": 0.2813686638041517,
        "distinct-3-nopunct": 0.8055555555555556,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.760067015271104,
        "cond_entropy-3-nopunct": 0.056601767786254004,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.45454545454545453,
            "3": 0.8055555555555556
        },
        "nist": 4.186300359610363,
        "rouge1": {
            "precision": 0.78472,
            "recall": 0.76076,
            "fmeasure": 0.75571
        },
        "rouge2": {
            "precision": 0.58418,
            "recall": 0.51918,
            "fmeasure": 0.53472
        },
        "rougeL": {
            "precision": 0.68333,
            "recall": 0.64846,
            "fmeasure": 0.6504
        },
        "rougeLsum": {
            "precision": 0.68333,
            "recall": 0.64846,
            "fmeasure": 0.6504
        },
        "bleu": 37.62285,
        "nubia": {
            "semantic_relation": 4.11115,
            "contradiction": 0.55011,
            "irrelevancy": 26.99059,
            "logical_agreement": 72.4593,
            "grammar_ref": 5.27719,
            "grammar_hyp": 5.6333,
            "nubia_score": 0.63189
        },
        "bleurt": 0.10497,
        "meteor": 0.38166729900661395,
        "bertscore": {
            "precision": 0.91976,
            "recall": 0.91985,
            "f1": 0.91724
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 19.4,
        "std_pred_length": 8.593020423576334,
        "median_pred_length": 23.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.7422680412371134,
        "vocab_size-1": 72,
        "unique-1": 63,
        "entropy-1": 5.903172543986376,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 88,
        "unique-2": 85,
        "entropy-2": 6.428400135381336,
        "cond_entropy-2": 0.4761373902102164,
        "distinct-3": 1.0,
        "vocab_size-3": 87,
        "unique-3": 87,
        "entropy-3": 6.442943495848723,
        "cond_entropy-3": -0.002976075125945915,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 6.887670143089026,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.898416047492303,
        "distinct-2-nopunct": 0.9861111111111112,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.14214722366454,
        "cond_entropy-2-nopunct": 0.26931246042241513,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.066089190457767,
        "cond_entropy-3-nopunct": -0.07398506471588323,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.125,
            "3": 0.7792207792207793
        },
        "nist": 4.956091783813961,
        "rouge1": {
            "precision": 0.84683,
            "recall": 0.74549,
            "fmeasure": 0.78586
        },
        "rouge2": {
            "precision": 0.68984,
            "recall": 0.61275,
            "fmeasure": 0.64055
        },
        "rougeL": {
            "precision": 0.72291,
            "recall": 0.64253,
            "fmeasure": 0.67144
        },
        "rougeLsum": {
            "precision": 0.72291,
            "recall": 0.64253,
            "fmeasure": 0.67144
        },
        "bleu": 53.63873,
        "nubia": {
            "semantic_relation": 4.22438,
            "contradiction": 3.14653,
            "irrelevancy": 19.77397,
            "logical_agreement": 77.07949,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.94272,
            "nubia_score": 0.72029
        },
        "bleurt": 0.35828,
        "meteor": 0.4263306818006371,
        "bertscore": {
            "precision": 0.9475,
            "recall": 0.94569,
            "f1": 0.94595
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 114,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 2.9137254363387344,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.7105263157894737,
        "vocab_size-1": 81,
        "unique-1": 69,
        "entropy-1": 6.022167344098344,
        "distinct-2": 0.9626168224299065,
        "vocab_size-2": 103,
        "unique-2": 100,
        "entropy-2": 6.659645607876246,
        "cond_entropy-2": 0.5068574622457839,
        "distinct-3": 0.99,
        "vocab_size-3": 99,
        "unique-3": 98,
        "entropy-3": 6.623856189774739,
        "cond_entropy-3": -0.030061921604787562,
        "total_length-nopunct": 98,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.0701966780270626,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7755102040816326,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.011023523107764,
        "distinct-2-nopunct": 0.9560439560439561,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.411587085229871,
        "cond_entropy-2-nopunct": 0.44700097143037415,
        "distinct-3-nopunct": 0.9880952380952381,
        "vocab_size-3-nopunct": 83,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.368507898969236,
        "cond_entropy-3-nopunct": -0.035061890013227855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.8791208791208791
        },
        "nist": 5.841311774335659,
        "rouge1": {
            "precision": 0.87689,
            "recall": 0.86523,
            "fmeasure": 0.8682
        },
        "rouge2": {
            "precision": 0.69995,
            "recall": 0.68361,
            "fmeasure": 0.6897
        },
        "rougeL": {
            "precision": 0.81306,
            "recall": 0.79507,
            "fmeasure": 0.80162
        },
        "rougeLsum": {
            "precision": 0.81306,
            "recall": 0.79507,
            "fmeasure": 0.80162
        },
        "bleu": 64.61142,
        "nubia": {
            "semantic_relation": 4.80084,
            "contradiction": 0.23691,
            "irrelevancy": 1.63697,
            "logical_agreement": 98.12612,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.0897,
            "nubia_score": 0.91803
        },
        "bleurt": 0.64051,
        "meteor": 0.4784584243901193,
        "bertscore": {
            "precision": 0.97809,
            "recall": 0.978,
            "f1": 0.97779
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 79,
        "mean_pred_length": 19.75,
        "std_pred_length": 4.656984002549289,
        "median_pred_length": 20.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.6962025316455697,
        "vocab_size-1": 55,
        "unique-1": 41,
        "entropy-1": 5.556697836675156,
        "distinct-2": 0.9466666666666667,
        "vocab_size-2": 71,
        "unique-2": 67,
        "entropy-2": 6.122152023829224,
        "cond_entropy-2": 0.5419001090719834,
        "distinct-3": 0.9859154929577465,
        "vocab_size-3": 70,
        "unique-3": 69,
        "entropy-3": 6.12157810542017,
        "cond_entropy-3": 0.0054354712623223755,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 3.3541019662496847,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7285714285714285,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.468359266852249,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 58,
        "entropy-2-nopunct": 5.92318199814634,
        "cond_entropy-2-nopunct": 0.47972720099667465,
        "distinct-3-nopunct": 0.9838709677419355,
        "vocab_size-3-nopunct": 61,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.921938245870744,
        "cond_entropy-3-nopunct": -0.00955264768125559,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.12,
            "2": 0.7,
            "3": 0.8
        },
        "nist": 4.770158067757639,
        "rouge1": {
            "precision": 0.73056,
            "recall": 0.69868,
            "fmeasure": 0.71405
        },
        "rouge2": {
            "precision": 0.4996,
            "recall": 0.52222,
            "fmeasure": 0.50062
        },
        "rougeL": {
            "precision": 0.59365,
            "recall": 0.56614,
            "fmeasure": 0.57942
        },
        "rougeLsum": {
            "precision": 0.59365,
            "recall": 0.56614,
            "fmeasure": 0.57942
        },
        "bleu": 46.34129,
        "nubia": {
            "semantic_relation": 4.04804,
            "contradiction": 7.72779,
            "irrelevancy": 47.78358,
            "logical_agreement": 44.48863,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.36362,
            "nubia_score": 0.65529
        },
        "bleurt": 0.19676,
        "meteor": 0.4305214558394117,
        "bertscore": {
            "precision": 0.91864,
            "recall": 0.92374,
            "f1": 0.91496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.242640687119285,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.75,
        "vocab_size-1": 42,
        "unique-1": 33,
        "entropy-1": 5.231200234441707,
        "distinct-2": 0.9038461538461539,
        "vocab_size-2": 47,
        "unique-2": 43,
        "entropy-2": 5.493614958484105,
        "cond_entropy-2": 0.15288816155131352,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 46,
        "unique-3": 44,
        "entropy-3": 5.5016291673878275,
        "cond_entropy-3": 0.02524960554180305,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.9370039370059056,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.121115365169276,
        "distinct-2-nopunct": 0.8636363636363636,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.169547811769943,
        "cond_entropy-2-nopunct": 0.05457849299809049,
        "distinct-3-nopunct": 0.925,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.171928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9387755102040817
        },
        "nist": 5.446690713502556,
        "rouge1": {
            "precision": 0.97917,
            "recall": 0.96154,
            "fmeasure": 0.97
        },
        "rouge2": {
            "precision": 0.93182,
            "recall": 0.91667,
            "fmeasure": 0.92391
        },
        "rougeL": {
            "precision": 0.97917,
            "recall": 0.96154,
            "fmeasure": 0.97
        },
        "rougeLsum": {
            "precision": 0.97917,
            "recall": 0.96154,
            "fmeasure": 0.97
        },
        "bleu": 85.14771,
        "nubia": {
            "semantic_relation": 4.99725,
            "contradiction": 0.47987,
            "irrelevancy": 0.61025,
            "logical_agreement": 98.90987,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.00075,
            "nubia_score": 0.98868
        },
        "bleurt": 0.93951,
        "meteor": 0.6068240506653246,
        "bertscore": {
            "precision": 0.98504,
            "recall": 0.98808,
            "f1": 0.98651
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.61,
        "msttr-100_nopunct": 0.65,
        "total_length": 134,
        "mean_pred_length": 16.75,
        "std_pred_length": 5.2855936279664935,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.582089552238806,
        "vocab_size-1": 78,
        "unique-1": 49,
        "entropy-1": 5.900320538155053,
        "distinct-2": 0.8095238095238095,
        "vocab_size-2": 102,
        "unique-2": 79,
        "entropy-2": 6.590336371895455,
        "cond_entropy-2": 0.6204238632116126,
        "distinct-3": 0.847457627118644,
        "vocab_size-3": 100,
        "unique-3": 82,
        "entropy-3": 6.577558303599122,
        "cond_entropy-3": -0.0034937597129611458,
        "total_length-nopunct": 112,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.787918451395113,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6517857142857143,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.901248284063275,
        "distinct-2-nopunct": 0.8076923076923077,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.308565799851068,
        "cond_entropy-2-nopunct": 0.45216261774194455,
        "distinct-3-nopunct": 0.8541666666666666,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.2932958340544936,
        "cond_entropy-3-nopunct": -0.0034471392723997582,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4634146341463415,
            "2": 0.7142857142857143,
            "3": 0.8125
        },
        "nist": 5.015330285317105,
        "rouge1": {
            "precision": 0.69306,
            "recall": 0.73803,
            "fmeasure": 0.69882
        },
        "rouge2": {
            "precision": 0.50837,
            "recall": 0.58196,
            "fmeasure": 0.52626
        },
        "rougeL": {
            "precision": 0.62867,
            "recall": 0.67375,
            "fmeasure": 0.63555
        },
        "rougeLsum": {
            "precision": 0.62867,
            "recall": 0.67375,
            "fmeasure": 0.63555
        },
        "bleu": 50.80471,
        "nubia": {
            "semantic_relation": 3.94933,
            "contradiction": 25.89612,
            "irrelevancy": 27.3805,
            "logical_agreement": 46.72338,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.805,
            "nubia_score": 0.66275
        },
        "bleurt": 0.16898,
        "meteor": 0.42309022995282886,
        "bertscore": {
            "precision": 0.92313,
            "recall": 0.93619,
            "f1": 0.92757
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.08248290463863,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 45,
        "unique-1": 37,
        "entropy-1": 5.358862821030459,
        "distinct-2": 1.0,
        "vocab_size-2": 54,
        "unique-2": 54,
        "entropy-2": 5.7548875021634665,
        "cond_entropy-2": 0.33430605293373433,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.08246216019197294,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.82,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.238562939644919,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.55458885167764,
        "cond_entropy-2-nopunct": 0.3418956939559,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.09515723304034036,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.7,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 4.976187218996584,
        "rouge1": {
            "precision": 0.74173,
            "recall": 0.70624,
            "fmeasure": 0.72307
        },
        "rouge2": {
            "precision": 0.47877,
            "recall": 0.46406,
            "fmeasure": 0.47102
        },
        "rougeL": {
            "precision": 0.65179,
            "recall": 0.62264,
            "fmeasure": 0.63649
        },
        "rougeLsum": {
            "precision": 0.65179,
            "recall": 0.62264,
            "fmeasure": 0.63649
        },
        "bleu": 51.40637,
        "nubia": {
            "semantic_relation": 4.50759,
            "contradiction": 0.96484,
            "irrelevancy": 44.76753,
            "logical_agreement": 54.26763,
            "grammar_ref": 4.0888,
            "grammar_hyp": 3.79862,
            "nubia_score": 0.86005
        },
        "bleurt": 0.50126,
        "meteor": 0.4371423966791698,
        "bertscore": {
            "precision": 0.94296,
            "recall": 0.93261,
            "f1": 0.93774
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 85,
        "mean_pred_length": 21.25,
        "std_pred_length": 6.057020719792859,
        "median_pred_length": 22.5,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.788235294117647,
        "vocab_size-1": 67,
        "unique-1": 55,
        "entropy-1": 5.903278583094718,
        "distinct-2": 0.9753086419753086,
        "vocab_size-2": 79,
        "unique-2": 77,
        "entropy-2": 6.290467286835232,
        "cond_entropy-2": 0.37514486932289637,
        "distinct-3": 1.0,
        "vocab_size-3": 77,
        "unique-3": 77,
        "entropy-3": 6.266786540694905,
        "cond_entropy-3": -0.034102423228684384,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 18.25,
        "std_pred_length-nopunct": 5.539629951540085,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.863013698630137,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.895170106765958,
        "distinct-2-nopunct": 0.9855072463768116,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.079538949531787,
        "cond_entropy-2-nopunct": 0.18695750665651303,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.055387412980483844,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nist": 4.580984365867208,
        "rouge1": {
            "precision": 0.8817,
            "recall": 0.75439,
            "fmeasure": 0.80972
        },
        "rouge2": {
            "precision": 0.725,
            "recall": 0.62083,
            "fmeasure": 0.66557
        },
        "rougeL": {
            "precision": 0.80506,
            "recall": 0.6904,
            "fmeasure": 0.74001
        },
        "rougeLsum": {
            "precision": 0.80506,
            "recall": 0.6904,
            "fmeasure": 0.74001
        },
        "bleu": 49.57626,
        "nubia": {
            "semantic_relation": 4.25574,
            "contradiction": 25.50752,
            "irrelevancy": 4.321,
            "logical_agreement": 70.17148,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.64886,
            "nubia_score": 0.73311
        },
        "bleurt": 0.39064,
        "meteor": 0.37655914373199323,
        "bertscore": {
            "precision": 0.96049,
            "recall": 0.94123,
            "f1": 0.95068
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.5714285714285714
        },
        "nist": 2.1704260058381,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.55267,
            "fmeasure": 0.63632
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.30556,
            "fmeasure": 0.3545
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.46032,
            "fmeasure": 0.53011
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.46032,
            "fmeasure": 0.53011
        },
        "bleu": 20.40437,
        "nubia": {
            "semantic_relation": 3.91771,
            "contradiction": 4.74669,
            "irrelevancy": 61.99112,
            "logical_agreement": 33.26219,
            "grammar_ref": 4.70322,
            "grammar_hyp": 5.78495,
            "nubia_score": 0.45403
        },
        "bleurt": -0.25415,
        "meteor": 0.27251594628262255,
        "bertscore": {
            "precision": 0.89323,
            "recall": 0.85689,
            "f1": 0.87469
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.0803217005180272,
        "rouge1": {
            "precision": 0.78571,
            "recall": 1.0,
            "fmeasure": 0.88
        },
        "rouge2": {
            "precision": 0.61538,
            "recall": 0.8,
            "fmeasure": 0.69565
        },
        "rougeL": {
            "precision": 0.78571,
            "recall": 1.0,
            "fmeasure": 0.88
        },
        "rougeLsum": {
            "precision": 0.78571,
            "recall": 1.0,
            "fmeasure": 0.88
        },
        "bleu": 64.19752,
        "nubia": {
            "semantic_relation": 4.74815,
            "contradiction": 0.08698,
            "irrelevancy": 99.77042,
            "logical_agreement": 0.14259,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.8206,
            "nubia_score": 0.9516
        },
        "bleurt": 0.43735,
        "meteor": 0.5261965690756933,
        "bertscore": {
            "precision": 0.92464,
            "recall": 0.98785,
            "f1": 0.9552
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.03214388408660254,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.8181818181818182
        },
        "nist": 3.9996518530457728,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.78974,
            "fmeasure": 0.81593
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.46429,
            "fmeasure": 0.48077
        },
        "rougeL": {
            "precision": 0.42308,
            "recall": 0.39231,
            "fmeasure": 0.40659
        },
        "rougeLsum": {
            "precision": 0.42308,
            "recall": 0.39231,
            "fmeasure": 0.40659
        },
        "bleu": 28.79373,
        "nubia": {
            "semantic_relation": 4.04752,
            "contradiction": 0.34226,
            "irrelevancy": 0.50357,
            "logical_agreement": 99.15418,
            "grammar_ref": 4.56931,
            "grammar_hyp": 4.27399,
            "nubia_score": 0.7341
        },
        "bleurt": 0.03865,
        "meteor": 0.39155853034425203,
        "bertscore": {
            "precision": 0.91789,
            "recall": 0.87672,
            "f1": 0.89413
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 20.5,
        "std_pred_length": 6.5,
        "median_pred_length": 20.5,
        "min_pred_length": 14,
        "max_pred_length": 27,
        "distinct-1": 0.8536585365853658,
        "vocab_size-1": 35,
        "unique-1": 30,
        "entropy-1": 5.046457187492144,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.2548986117355359,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.07594885323329875,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.8711781263822145,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.2338580604598938,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7096774193548387
        },
        "nist": 4.182121332568939,
        "rouge1": {
            "precision": 0.7313,
            "recall": 0.69114,
            "fmeasure": 0.7094
        },
        "rouge2": {
            "precision": 0.55616,
            "recall": 0.52766,
            "fmeasure": 0.54046
        },
        "rougeL": {
            "precision": 0.7313,
            "recall": 0.69114,
            "fmeasure": 0.7094
        },
        "rougeLsum": {
            "precision": 0.7313,
            "recall": 0.69114,
            "fmeasure": 0.7094
        },
        "bleu": 55.77841,
        "nubia": {
            "semantic_relation": 3.36435,
            "contradiction": 33.23759,
            "irrelevancy": 21.52893,
            "logical_agreement": 45.23348,
            "grammar_ref": 5.38335,
            "grammar_hyp": 6.09912,
            "nubia_score": 0.42954
        },
        "bleurt": -0.13198,
        "meteor": 0.37786867757914755,
        "bertscore": {
            "precision": 0.88433,
            "recall": 0.90922,
            "f1": 0.89653
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 2.5,
        "median_pred_length": 23.5,
        "min_pred_length": 21,
        "max_pred_length": 26,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 35,
        "unique-1": 27,
        "entropy-1": 4.969274489883448,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.447408651885229,
        "cond_entropy-2": 0.4597036891926359,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.01907671372059983,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7948717948717948,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.83643362900771,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.155399311574899,
        "cond_entropy-2-nopunct": 0.30039743064793845,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.02302749154112622,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.6875
        },
        "nist": 2.516972018517153,
        "rouge1": {
            "precision": 0.44924,
            "recall": 0.74893,
            "fmeasure": 0.56129
        },
        "rouge2": {
            "precision": 0.27402,
            "recall": 0.46999,
            "fmeasure": 0.34471
        },
        "rougeL": {
            "precision": 0.37197,
            "recall": 0.66733,
            "fmeasure": 0.47395
        },
        "rougeLsum": {
            "precision": 0.37197,
            "recall": 0.66733,
            "fmeasure": 0.47395
        },
        "bleu": 21.09945,
        "nubia": {
            "semantic_relation": 3.62412,
            "contradiction": 18.5716,
            "irrelevancy": 37.59625,
            "logical_agreement": 43.83215,
            "grammar_ref": 4.76014,
            "grammar_hyp": 3.9552,
            "nubia_score": 0.58792
        },
        "bleurt": -0.17688,
        "meteor": 0.35248795707886166,
        "bertscore": {
            "precision": 0.84618,
            "recall": 0.92338,
            "f1": 0.88018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.7543859649122807,
        "vocab_size-1": 43,
        "unique-1": 34,
        "entropy-1": 5.266843303524555,
        "distinct-2": 0.9814814814814815,
        "vocab_size-2": 53,
        "unique-2": 52,
        "entropy-2": 5.717850465126429,
        "cond_entropy-2": 0.3944007288195959,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.04324647391746317,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 3.8586123009300755,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8163265306122449,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.2165511705575165,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.28949939464456387,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.05078557344793837,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9629629629629629
        },
        "nist": 4.761323041224142,
        "rouge1": {
            "precision": 0.86532,
            "recall": 0.91642,
            "fmeasure": 0.88964
        },
        "rouge2": {
            "precision": 0.67059,
            "recall": 0.70625,
            "fmeasure": 0.68748
        },
        "rougeL": {
            "precision": 0.80976,
            "recall": 0.85576,
            "fmeasure": 0.83165
        },
        "rougeLsum": {
            "precision": 0.80976,
            "recall": 0.85576,
            "fmeasure": 0.83165
        },
        "bleu": 66.75771,
        "nubia": {
            "semantic_relation": 4.80932,
            "contradiction": 31.13985,
            "irrelevancy": 10.2999,
            "logical_agreement": 58.56026,
            "grammar_ref": 4.97796,
            "grammar_hyp": 4.70627,
            "nubia_score": 0.93127
        },
        "bleurt": 0.55828,
        "meteor": 0.5225899904849781,
        "bertscore": {
            "precision": 0.94986,
            "recall": 0.96667,
            "f1": 0.95812
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 89,
        "mean_pred_length": 17.8,
        "std_pred_length": 5.844655678480984,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7078651685393258,
        "vocab_size-1": 63,
        "unique-1": 51,
        "entropy-1": 5.665183256950477,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 78,
        "unique-2": 73,
        "entropy-2": 6.24047352394348,
        "cond_entropy-2": 0.485327295512569,
        "distinct-3": 0.9746835443037974,
        "vocab_size-3": 77,
        "unique-3": 75,
        "entropy-3": 6.2531478367846995,
        "cond_entropy-3": 0.022284686185221815,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 5.782732917920384,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7349397590361446,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.645770455286921,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.1218780201165695,
        "cond_entropy-2-nopunct": 0.5100350632950327,
        "distinct-3-nopunct": 0.9726027397260274,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.135030038332081,
        "cond_entropy-3-nopunct": 0.010653675663843752,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.25,
            "3": 0.7857142857142857
        },
        "nist": 4.947317170040501,
        "rouge1": {
            "precision": 0.77272,
            "recall": 0.72486,
            "fmeasure": 0.74234
        },
        "rouge2": {
            "precision": 0.5443,
            "recall": 0.49977,
            "fmeasure": 0.51552
        },
        "rougeL": {
            "precision": 0.60049,
            "recall": 0.55113,
            "fmeasure": 0.56931
        },
        "rougeLsum": {
            "precision": 0.60049,
            "recall": 0.55113,
            "fmeasure": 0.56931
        },
        "bleu": 43.9592,
        "nubia": {
            "semantic_relation": 4.61201,
            "contradiction": 4.05115,
            "irrelevancy": 31.47777,
            "logical_agreement": 64.47108,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.95911,
            "nubia_score": 0.78358
        },
        "bleurt": 0.33403,
        "meteor": 0.3986311075458257,
        "bertscore": {
            "precision": 0.9272,
            "recall": 0.92136,
            "f1": 0.92317
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.616348566075163,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.5886641546653933,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.503258334775645,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.5645966633374387,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.875
        },
        "nist": 2.1605346539966486,
        "rouge1": {
            "precision": 0.60526,
            "recall": 0.85165,
            "fmeasure": 0.70739
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.59936,
            "fmeasure": 0.4914
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.74176,
            "fmeasure": 0.61553
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.74176,
            "fmeasure": 0.61553
        },
        "bleu": 22.32309,
        "nubia": {
            "semantic_relation": 3.00347,
            "contradiction": 88.29257,
            "irrelevancy": 9.91408,
            "logical_agreement": 1.79335,
            "grammar_ref": 3.57757,
            "grammar_hyp": 3.60355,
            "nubia_score": 0.44872
        },
        "bleurt": 0.02204,
        "meteor": 0.3785964169484644,
        "bertscore": {
            "precision": 0.89395,
            "recall": 0.93088,
            "f1": 0.91204
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.8,
        "total_length": 118,
        "mean_pred_length": 14.75,
        "std_pred_length": 5.043560250458004,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.711864406779661,
        "vocab_size-1": 84,
        "unique-1": 67,
        "entropy-1": 6.10700078296073,
        "distinct-2": 0.9454545454545454,
        "vocab_size-2": 104,
        "unique-2": 98,
        "entropy-2": 6.672268804433759,
        "cond_entropy-2": 0.4034965499385493,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 100,
        "unique-3": 98,
        "entropy-3": 6.63320965569699,
        "cond_entropy-3": -0.030502999004144396,
        "total_length-nopunct": 102,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 4.841229182759271,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7941176470588235,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 66,
        "entropy-1-nopunct": 6.20306943039378,
        "distinct-2-nopunct": 0.9574468085106383,
        "vocab_size-2-nopunct": 90,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.4694824686989,
        "cond_entropy-2-nopunct": 0.295719924396857,
        "distinct-3-nopunct": 0.9883720930232558,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.40300894074861,
        "cond_entropy-3-nopunct": -0.05855665511507434,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.8,
            "3": 0.8833333333333333
        },
        "nist": 5.761104301970057,
        "rouge1": {
            "precision": 0.84677,
            "recall": 0.7973,
            "fmeasure": 0.8148
        },
        "rouge2": {
            "precision": 0.56888,
            "recall": 0.54519,
            "fmeasure": 0.5516
        },
        "rougeL": {
            "precision": 0.68397,
            "recall": 0.65002,
            "fmeasure": 0.6617
        },
        "rougeLsum": {
            "precision": 0.68397,
            "recall": 0.65002,
            "fmeasure": 0.6617
        },
        "bleu": 44.06307,
        "nubia": {
            "semantic_relation": 4.46841,
            "contradiction": 1.13739,
            "irrelevancy": 26.5729,
            "logical_agreement": 72.28971,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.21032,
            "nubia_score": 0.83426
        },
        "bleurt": 0.36722,
        "meteor": 0.4252744768279358,
        "bertscore": {
            "precision": 0.94984,
            "recall": 0.9451,
            "f1": 0.94432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 14.0,
        "std_pred_length": 5.621387729022079,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6428571428571429,
        "vocab_size-1": 45,
        "unique-1": 33,
        "entropy-1": 5.222369539011196,
        "distinct-2": 0.8153846153846154,
        "vocab_size-2": 53,
        "unique-2": 45,
        "entropy-2": 5.599140505269581,
        "cond_entropy-2": 0.2679236880311845,
        "distinct-3": 0.8833333333333333,
        "vocab_size-3": 53,
        "unique-3": 47,
        "entropy-3": 5.660975803905792,
        "cond_entropy-3": 0.09710424094945533,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 4.923413450036469,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6825396825396826,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.185624320628057,
        "distinct-2-nopunct": 0.7931034482758621,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.3836745295357264,
        "cond_entropy-2-nopunct": 0.23181362294835015,
        "distinct-3-nopunct": 0.8679245283018868,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.4495263507487905,
        "cond_entropy-3-nopunct": 0.11059771419342837,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.864406779661017
        },
        "nist": 5.025455012970901,
        "rouge1": {
            "precision": 0.8621,
            "recall": 0.85965,
            "fmeasure": 0.85919
        },
        "rouge2": {
            "precision": 0.73413,
            "recall": 0.7314,
            "fmeasure": 0.73126
        },
        "rougeL": {
            "precision": 0.84877,
            "recall": 0.84854,
            "fmeasure": 0.84707
        },
        "rougeLsum": {
            "precision": 0.84877,
            "recall": 0.84854,
            "fmeasure": 0.84707
        },
        "bleu": 60.48234,
        "nubia": {
            "semantic_relation": 4.66602,
            "contradiction": 0.49717,
            "irrelevancy": 0.66911,
            "logical_agreement": 98.83372,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.92744,
            "nubia_score": 0.8594
        },
        "bleurt": 0.79098,
        "meteor": 0.46587944769143336,
        "bertscore": {
            "precision": 0.98047,
            "recall": 0.97451,
            "f1": 0.97739
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.0,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750188,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.16597642850354188,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.303508854797679,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.13605491346902576,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.9375
        },
        "nist": 4.1227613467575415,
        "rouge1": {
            "precision": 0.81002,
            "recall": 0.79903,
            "fmeasure": 0.80433
        },
        "rouge2": {
            "precision": 0.575,
            "recall": 0.56752,
            "fmeasure": 0.57111
        },
        "rougeL": {
            "precision": 0.75874,
            "recall": 0.74958,
            "fmeasure": 0.75399
        },
        "rougeLsum": {
            "precision": 0.75874,
            "recall": 0.74958,
            "fmeasure": 0.75399
        },
        "bleu": 45.61187,
        "nubia": {
            "semantic_relation": 4.11072,
            "contradiction": 39.46696,
            "irrelevancy": 43.04558,
            "logical_agreement": 17.48745,
            "grammar_ref": 5.19402,
            "grammar_hyp": 6.03756,
            "nubia_score": 0.50224
        },
        "bleurt": 0.17077,
        "meteor": 0.413209067848524,
        "bertscore": {
            "precision": 0.95011,
            "recall": 0.95007,
            "f1": 0.94332
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.07021912877717248,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.08609442102484588,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.2064508774674265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.55
        },
        "nist": 1.5561983201584288,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.49078,
            "fmeasure": 0.57444
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.25476,
            "fmeasure": 0.30105
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.40328,
            "fmeasure": 0.46444
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.40328,
            "fmeasure": 0.46444
        },
        "bleu": 11.52159,
        "nubia": {
            "semantic_relation": 4.00359,
            "contradiction": 0.38322,
            "irrelevancy": 1.00599,
            "logical_agreement": 98.6108,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.3455,
            "nubia_score": 0.79033
        },
        "bleurt": 0.22129,
        "meteor": 0.3048564741924019,
        "bertscore": {
            "precision": 0.92764,
            "recall": 0.87721,
            "f1": 0.90163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 16.5,
        "std_pred_length": 5.188127472091127,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6060606060606061,
        "vocab_size-1": 60,
        "unique-1": 44,
        "entropy-1": 5.508207948769605,
        "distinct-2": 0.8494623655913979,
        "vocab_size-2": 79,
        "unique-2": 69,
        "entropy-2": 6.200344026115272,
        "cond_entropy-2": 0.6784467443119054,
        "distinct-3": 0.9195402298850575,
        "vocab_size-3": 80,
        "unique-3": 74,
        "entropy-3": 6.2733470877778785,
        "cond_entropy-3": 0.0963695985586677,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 5.9907335852038095,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6304347826086957,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.455748576083896,
        "distinct-2-nopunct": 0.8372093023255814,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 6.059872022093646,
        "cond_entropy-2-nopunct": 0.6786220539148581,
        "distinct-3-nopunct": 0.9125,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.137492001110314,
        "cond_entropy-3-nopunct": 0.10509943396230753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 4.467860000470026,
        "rouge1": {
            "precision": 0.73148,
            "recall": 0.76674,
            "fmeasure": 0.74315
        },
        "rouge2": {
            "precision": 0.55542,
            "recall": 0.56611,
            "fmeasure": 0.55807
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.65507,
            "fmeasure": 0.63438
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.65507,
            "fmeasure": 0.63438
        },
        "bleu": 36.27949,
        "nubia": {
            "semantic_relation": 4.23349,
            "contradiction": 9.10836,
            "irrelevancy": 39.8698,
            "logical_agreement": 51.02183,
            "grammar_ref": 4.9652,
            "grammar_hyp": 4.86115,
            "nubia_score": 0.74837
        },
        "bleurt": 0.29511,
        "meteor": 0.3626835996144421,
        "bertscore": {
            "precision": 0.92061,
            "recall": 0.91754,
            "f1": 0.91854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.229871195093384,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.24291000358771486,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.229871195093384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.24291000358771486,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.08333333333333333,
            "3": 0.5769230769230769
        },
        "nist": 0.4912115799469222,
        "rouge1": {
            "precision": 0.78261,
            "recall": 0.42312,
            "fmeasure": 0.54891
        },
        "rouge2": {
            "precision": 0.34848,
            "recall": 0.17685,
            "fmeasure": 0.23447
        },
        "rougeL": {
            "precision": 0.63768,
            "recall": 0.32345,
            "fmeasure": 0.42916
        },
        "rougeLsum": {
            "precision": 0.63768,
            "recall": 0.32345,
            "fmeasure": 0.42916
        },
        "bleu": 7.7308,
        "nubia": {
            "semantic_relation": 3.56934,
            "contradiction": 1.0849,
            "irrelevancy": 92.17367,
            "logical_agreement": 6.74142,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.86498,
            "nubia_score": 0.37993
        },
        "bleurt": -0.64507,
        "meteor": 0.21050981653197398,
        "bertscore": {
            "precision": 0.88633,
            "recall": 0.83148,
            "f1": 0.85803
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.7142857142857143
        },
        "nist": 2.0859865299942584,
        "rouge1": {
            "precision": 0.55,
            "recall": 0.49206,
            "fmeasure": 0.51316
        },
        "rouge2": {
            "precision": 0.27778,
            "recall": 0.24038,
            "fmeasure": 0.25401
        },
        "rougeL": {
            "precision": 0.45,
            "recall": 0.40079,
            "fmeasure": 0.41886
        },
        "rougeLsum": {
            "precision": 0.45,
            "recall": 0.40079,
            "fmeasure": 0.41886
        },
        "bleu": 19.08165,
        "nubia": {
            "semantic_relation": 3.08137,
            "contradiction": 38.87506,
            "irrelevancy": 59.36062,
            "logical_agreement": 1.76432,
            "grammar_ref": 5.58883,
            "grammar_hyp": 5.3969,
            "nubia_score": 0.32736
        },
        "bleurt": -0.02021,
        "meteor": 0.21703736993245187,
        "bertscore": {
            "precision": 0.89084,
            "recall": 0.89774,
            "f1": 0.89428
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 4.642796092394707,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 5.003055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.1037414869578035,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 4.189935029992179,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9142857142857143,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.957854445516392,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.058216983055033616,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.14201900487242786,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.47058823529411764,
            "3": 0.75
        },
        "nist": 3.795389940866014,
        "rouge1": {
            "precision": 0.68269,
            "recall": 0.81217,
            "fmeasure": 0.69906
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.63169,
            "fmeasure": 0.5418
        },
        "rougeL": {
            "precision": 0.58654,
            "recall": 0.73016,
            "fmeasure": 0.61414
        },
        "rougeLsum": {
            "precision": 0.58654,
            "recall": 0.73016,
            "fmeasure": 0.61414
        },
        "bleu": 40.99637,
        "nubia": {
            "semantic_relation": 3.81238,
            "contradiction": 4.36532,
            "irrelevancy": 42.49782,
            "logical_agreement": 53.13685,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.79286,
            "nubia_score": 0.64377
        },
        "bleurt": 0.12292,
        "meteor": 0.3534091707256302,
        "bertscore": {
            "precision": 0.90359,
            "recall": 0.92656,
            "f1": 0.91183
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 75,
        "mean_pred_length": 18.75,
        "std_pred_length": 4.264680527307995,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.76,
        "vocab_size-1": 57,
        "unique-1": 49,
        "entropy-1": 5.60189135704717,
        "distinct-2": 1.0,
        "vocab_size-2": 71,
        "unique-2": 71,
        "entropy-2": 6.149747119504677,
        "cond_entropy-2": 0.47049955589125053,
        "distinct-3": 1.0,
        "vocab_size-3": 67,
        "unique-3": 67,
        "entropy-3": 6.066089190457767,
        "cond_entropy-3": -0.08365792904690947,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 4.06201920231798,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8088235294117647,
        "vocab_size-1-nopunct": 55,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.583570745566661,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 64,
        "entropy-2-nopunct": 6.0,
        "cond_entropy-2-nopunct": 0.44792251041357345,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": -0.09310940439148153,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.6,
            "3": 0.8181818181818182
        },
        "nist": 4.770065424187582,
        "rouge1": {
            "precision": 0.76486,
            "recall": 0.76561,
            "fmeasure": 0.76399
        },
        "rouge2": {
            "precision": 0.46972,
            "recall": 0.4598,
            "fmeasure": 0.46244
        },
        "rougeL": {
            "precision": 0.62296,
            "recall": 0.6258,
            "fmeasure": 0.62276
        },
        "rougeLsum": {
            "precision": 0.62296,
            "recall": 0.6258,
            "fmeasure": 0.62276
        },
        "bleu": 35.83929,
        "nubia": {
            "semantic_relation": 4.01359,
            "contradiction": 1.50521,
            "irrelevancy": 61.68311,
            "logical_agreement": 36.81168,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.37819,
            "nubia_score": 0.65104
        },
        "bleurt": 0.26268,
        "meteor": 0.36891719809019863,
        "bertscore": {
            "precision": 0.92113,
            "recall": 0.9241,
            "f1": 0.92163
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 3.9219280948873623,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.3470520501351705,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.826874881864636,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.3664419324431712,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.966484682517076,
        "rouge1": {
            "precision": 0.87719,
            "recall": 0.91022,
            "fmeasure": 0.89279
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.72685,
            "fmeasure": 0.7146
        },
        "rougeL": {
            "precision": 0.85965,
            "recall": 0.89061,
            "fmeasure": 0.87427
        },
        "rougeLsum": {
            "precision": 0.85965,
            "recall": 0.89061,
            "fmeasure": 0.87427
        },
        "bleu": 75.90995,
        "nubia": {
            "semantic_relation": 4.83068,
            "contradiction": 0.43259,
            "irrelevancy": 1.92909,
            "logical_agreement": 97.63831,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.90985,
            "nubia_score": 0.87766
        },
        "bleurt": 0.54795,
        "meteor": 0.5243374525842459,
        "bertscore": {
            "precision": 0.96238,
            "recall": 0.97177,
            "f1": 0.96705
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 35,
        "unique-1": 27,
        "entropy-1": 5.013858096233519,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 39,
        "unique-2": 36,
        "entropy-2": 5.249460279921618,
        "cond_entropy-2": 0.1565330765005968,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": 0.04693094992964198,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8048780487804879,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.948896211882388,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.0374011976541135,
        "cond_entropy-2-nopunct": 0.12076728519822492,
        "distinct-3-nopunct": 0.9714285714285714,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.072140159802107,
        "cond_entropy-3-nopunct": 0.05278407492995249,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9354838709677419
        },
        "nist": 5.020945219921343,
        "rouge1": {
            "precision": 0.86012,
            "recall": 0.90331,
            "fmeasure": 0.88047
        },
        "rouge2": {
            "precision": 0.79088,
            "recall": 0.86061,
            "fmeasure": 0.82096
        },
        "rougeL": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "rougeLsum": {
            "precision": 0.85218,
            "recall": 0.90246,
            "fmeasure": 0.87478
        },
        "bleu": 77.16836,
        "nubia": {
            "semantic_relation": 4.5356,
            "contradiction": 0.50583,
            "irrelevancy": 46.81276,
            "logical_agreement": 52.68141,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.822,
            "nubia_score": 0.83797
        },
        "bleurt": 0.65711,
        "meteor": 0.5769639229603134,
        "bertscore": {
            "precision": 0.96702,
            "recall": 0.97968,
            "f1": 0.97166
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.251647869033911,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.82933,
            "contradiction": 1.12257,
            "irrelevancy": 0.76148,
            "logical_agreement": 98.11595,
            "grammar_ref": 6.06085,
            "grammar_hyp": 6.23781,
            "nubia_score": 0.91231
        },
        "bleurt": 0.89857,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964168,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5294117647058824
        },
        "nist": 1.7693033130936888,
        "rouge1": {
            "precision": 0.68889,
            "recall": 0.5103,
            "fmeasure": 0.58514
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.22559,
            "fmeasure": 0.26852
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.29748,
            "fmeasure": 0.34056
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.29748,
            "fmeasure": 0.34056
        },
        "bleu": 11.96455,
        "nubia": {
            "semantic_relation": 3.80732,
            "contradiction": 7.26266,
            "irrelevancy": 2.56857,
            "logical_agreement": 90.16876,
            "grammar_ref": 4.86737,
            "grammar_hyp": 6.44861,
            "nubia_score": 0.42678
        },
        "bleurt": -0.12798,
        "meteor": 0.30333063390096976,
        "bertscore": {
            "precision": 0.89526,
            "recall": 0.8471,
            "f1": 0.87052
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.9184254167955828,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.58333,
            "fmeasure": 0.5676
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.13228,
            "fmeasure": 0.1281
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.46667,
            "fmeasure": 0.45408
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.46667,
            "fmeasure": 0.45408
        },
        "bleu": 18.57506,
        "nubia": {
            "semantic_relation": 4.20715,
            "contradiction": 0.50637,
            "irrelevancy": 3.50168,
            "logical_agreement": 95.99195,
            "grammar_ref": 5.68329,
            "grammar_hyp": 6.48912,
            "nubia_score": 0.63365
        },
        "bleurt": 0.29327,
        "meteor": 0.34940950708866647,
        "bertscore": {
            "precision": 0.92286,
            "recall": 0.92576,
            "f1": 0.92431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nist": 3.232383717502119,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.67235,
            "fmeasure": 0.67805
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.42963,
            "fmeasure": 0.39365
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.48485,
            "fmeasure": 0.44796
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.48485,
            "fmeasure": 0.44796
        },
        "bleu": 17.3958,
        "nubia": {
            "semantic_relation": 3.98784,
            "contradiction": 0.18169,
            "irrelevancy": 0.99873,
            "logical_agreement": 98.81957,
            "grammar_ref": 5.84412,
            "grammar_hyp": 6.32171,
            "nubia_score": 0.57155
        },
        "bleurt": -0.27582,
        "meteor": 0.3568330242611599,
        "bertscore": {
            "precision": 0.91678,
            "recall": 0.94418,
            "f1": 0.92553
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 144,
        "mean_pred_length": 14.4,
        "std_pred_length": 5.624944444170094,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.6944444444444444,
        "vocab_size-1": 100,
        "unique-1": 88,
        "entropy-1": 6.216921186044975,
        "distinct-2": 0.9626865671641791,
        "vocab_size-2": 129,
        "unique-2": 124,
        "entropy-2": 6.991462324786138,
        "cond_entropy-2": 0.5977557447493764,
        "distinct-3": 0.9919354838709677,
        "vocab_size-3": 123,
        "unique-3": 122,
        "entropy-3": 6.938067278128796,
        "cond_entropy-3": -0.04737675103863901,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 12.7,
        "std_pred_length-nopunct": 5.441507144165117,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7559055118110236,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.261097064772876,
        "distinct-2-nopunct": 0.9658119658119658,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 109,
        "entropy-2-nopunct": 6.801988651207317,
        "cond_entropy-2-nopunct": 0.5945315541266915,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 107,
        "unique-3-nopunct": 107,
        "entropy-3-nopunct": 6.741466986401138,
        "cond_entropy-3-nopunct": -0.06347717243459383,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.30434782608695654,
            "2": 0.6296296296296297,
            "3": 0.7263157894736842
        },
        "nist": 5.493036951992491,
        "rouge1": {
            "precision": 0.78952,
            "recall": 0.69454,
            "fmeasure": 0.70842
        },
        "rouge2": {
            "precision": 0.515,
            "recall": 0.4222,
            "fmeasure": 0.44524
        },
        "rougeL": {
            "precision": 0.67478,
            "recall": 0.57747,
            "fmeasure": 0.60057
        },
        "rougeLsum": {
            "precision": 0.67478,
            "recall": 0.57747,
            "fmeasure": 0.60057
        },
        "bleu": 44.71373,
        "nubia": {
            "semantic_relation": 4.17143,
            "contradiction": 4.28174,
            "irrelevancy": 22.20231,
            "logical_agreement": 73.51595,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.61103,
            "nubia_score": 0.65624
        },
        "bleurt": 0.22143,
        "meteor": 0.36671500851757766,
        "bertscore": {
            "precision": 0.92889,
            "recall": 0.90408,
            "f1": 0.91424
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.86,
        "total_length": 123,
        "mean_pred_length": 15.375,
        "std_pred_length": 4.580870550452174,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.7479674796747967,
        "vocab_size-1": 92,
        "unique-1": 81,
        "entropy-1": 6.20637355051009,
        "distinct-2": 1.0,
        "vocab_size-2": 115,
        "unique-2": 115,
        "entropy-2": 6.84549005094439,
        "cond_entropy-2": 0.469809784148143,
        "distinct-3": 1.0,
        "vocab_size-3": 107,
        "unique-3": 107,
        "entropy-3": 6.741466986401138,
        "cond_entropy-3": -0.10402306454322816,
        "total_length-nopunct": 107,
        "mean_pred_length-nopunct": 13.375,
        "std_pred_length-nopunct": 3.838538133196022,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8411214953271028,
        "vocab_size-1-nopunct": 90,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.345536818395529,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 99,
        "entropy-2-nopunct": 6.62935662007962,
        "cond_entropy-2-nopunct": 0.31581415869462726,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 91,
        "entropy-3-nopunct": 6.507794640198703,
        "cond_entropy-3-nopunct": -0.12156197988091334,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24390243902439024,
            "2": 0.28,
            "3": 0.8985507246376812
        },
        "nist": 5.549135862471933,
        "rouge1": {
            "precision": 0.70747,
            "recall": 0.73363,
            "fmeasure": 0.70332
        },
        "rouge2": {
            "precision": 0.46287,
            "recall": 0.44906,
            "fmeasure": 0.44559
        },
        "rougeL": {
            "precision": 0.58199,
            "recall": 0.56118,
            "fmeasure": 0.5607
        },
        "rougeLsum": {
            "precision": 0.58199,
            "recall": 0.56118,
            "fmeasure": 0.5607
        },
        "bleu": 42.10833,
        "nubia": {
            "semantic_relation": 3.84909,
            "contradiction": 1.56407,
            "irrelevancy": 45.02613,
            "logical_agreement": 53.4098,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.53744,
            "nubia_score": 0.62946
        },
        "bleurt": 0.09085,
        "meteor": 0.3923394371164446,
        "bertscore": {
            "precision": 0.9064,
            "recall": 0.91223,
            "f1": 0.90566
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 81,
        "mean_pred_length": 20.25,
        "std_pred_length": 4.380353866983808,
        "median_pred_length": 20.5,
        "min_pred_length": 14,
        "max_pred_length": 26,
        "distinct-1": 0.7160493827160493,
        "vocab_size-1": 58,
        "unique-1": 44,
        "entropy-1": 5.659363392035682,
        "distinct-2": 0.948051948051948,
        "vocab_size-2": 73,
        "unique-2": 69,
        "entropy-2": 6.162890436798801,
        "cond_entropy-2": 0.46413819984404625,
        "distinct-3": 0.9863013698630136,
        "vocab_size-3": 72,
        "unique-3": 71,
        "entropy-3": 6.162427298606055,
        "cond_entropy-3": -0.008468831129952347,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 19.25,
        "std_pred_length-nopunct": 4.205650960315181,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7272727272727273,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.612701761778017,
        "distinct-2-nopunct": 0.9452054794520548,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.080235517784137,
        "cond_entropy-2-nopunct": 0.4896753877275862,
        "distinct-3-nopunct": 0.9855072463768116,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.079538949531787,
        "cond_entropy-3-nopunct": -0.008836333985906233,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.6,
            "3": 0.7014925373134329
        },
        "nist": 4.189915728410966,
        "rouge1": {
            "precision": 0.72142,
            "recall": 0.72005,
            "fmeasure": 0.70465
        },
        "rouge2": {
            "precision": 0.45783,
            "recall": 0.45177,
            "fmeasure": 0.44147
        },
        "rougeL": {
            "precision": 0.63432,
            "recall": 0.62985,
            "fmeasure": 0.61806
        },
        "rougeLsum": {
            "precision": 0.63432,
            "recall": 0.62985,
            "fmeasure": 0.61806
        },
        "bleu": 31.73597,
        "nubia": {
            "semantic_relation": 4.18766,
            "contradiction": 18.86251,
            "irrelevancy": 20.57289,
            "logical_agreement": 60.5646,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.27268,
            "nubia_score": 0.69813
        },
        "bleurt": 0.10665,
        "meteor": 0.3311511648971298,
        "bertscore": {
            "precision": 0.91466,
            "recall": 0.89641,
            "f1": 0.90256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 17.4,
        "std_pred_length": 4.923413450036469,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6206896551724138,
        "vocab_size-1": 54,
        "unique-1": 38,
        "entropy-1": 5.418582398391673,
        "distinct-2": 0.7926829268292683,
        "vocab_size-2": 65,
        "unique-2": 51,
        "entropy-2": 5.9093216692258475,
        "cond_entropy-2": 0.4116193319664709,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 66,
        "unique-3": 55,
        "entropy-3": 5.981072254980618,
        "cond_entropy-3": 0.07488242571530407,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 15.2,
        "std_pred_length-nopunct": 4.354308211415448,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6710526315789473,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.359641000228761,
        "distinct-2-nopunct": 0.8028169014084507,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.716579689896742,
        "cond_entropy-2-nopunct": 0.3913250638380466,
        "distinct-3-nopunct": 0.8787878787878788,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.801969876934217,
        "cond_entropy-3-nopunct": 0.08790287109867252,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.890625
        },
        "nist": 5.739405505129024,
        "rouge1": {
            "precision": 0.84464,
            "recall": 0.83353,
            "fmeasure": 0.83712
        },
        "rouge2": {
            "precision": 0.72556,
            "recall": 0.69963,
            "fmeasure": 0.71158
        },
        "rougeL": {
            "precision": 0.81607,
            "recall": 0.80817,
            "fmeasure": 0.81025
        },
        "rougeLsum": {
            "precision": 0.81607,
            "recall": 0.80817,
            "fmeasure": 0.81025
        },
        "bleu": 75.33447,
        "nubia": {
            "semantic_relation": 4.56937,
            "contradiction": 0.1664,
            "irrelevancy": 20.4044,
            "logical_agreement": 79.4292,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.83647,
            "nubia_score": 0.87648
        },
        "bleurt": 0.60572,
        "meteor": 0.5270050236538251,
        "bertscore": {
            "precision": 0.95677,
            "recall": 0.96077,
            "f1": 0.95812
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.7307692307692307,
        "vocab_size-1": 19,
        "unique-1": 12,
        "entropy-1": 4.161978179679553,
        "distinct-2": 0.875,
        "vocab_size-2": 21,
        "unique-2": 18,
        "entropy-2": 4.334962500721156,
        "cond_entropy-2": 0.13452278258006406,
        "distinct-3": 0.9090909090909091,
        "vocab_size-3": 20,
        "unique-3": 18,
        "entropy-3": 4.277613436819113,
        "cond_entropy-3": -0.034621791174768206,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.001822825622231,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.106603137064473,
        "cond_entropy-2-nopunct": 0.15446975243603325,
        "distinct-3-nopunct": 0.8947368421052632,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.03740119765411,
        "cond_entropy-3-nopunct": -0.0391267514404381,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "nist": 4.693495074346837,
        "rouge1": {
            "precision": 0.90641,
            "recall": 0.91136,
            "fmeasure": 0.90746
        },
        "rouge2": {
            "precision": 0.65741,
            "recall": 0.65051,
            "fmeasure": 0.65268
        },
        "rougeL": {
            "precision": 0.86795,
            "recall": 0.8697,
            "fmeasure": 0.86746
        },
        "rougeLsum": {
            "precision": 0.86795,
            "recall": 0.8697,
            "fmeasure": 0.86746
        },
        "bleu": 62.34181,
        "nubia": {
            "semantic_relation": 4.97457,
            "contradiction": 0.29171,
            "irrelevancy": 0.8262,
            "logical_agreement": 98.88209,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.45138,
            "nubia_score": 0.93751
        },
        "bleurt": 0.78283,
        "meteor": 0.5024103736780707,
        "bertscore": {
            "precision": 0.96847,
            "recall": 0.96821,
            "f1": 0.96833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 4.08248290463863,
        "median_pred_length": 20.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.85,
        "vocab_size-1": 51,
        "unique-1": 46,
        "entropy-1": 5.540223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 57,
        "unique-2": 57,
        "entropy-2": 5.832890014164737,
        "cond_entropy-2": 0.2768766115386793,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.265986323710904,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9074074074074074,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.532665279941244,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.15283195745508582,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.08746284125033933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.6507936507936508
        },
        "nist": 3.7119225310635797,
        "rouge1": {
            "precision": 0.80987,
            "recall": 0.62918,
            "fmeasure": 0.70574
        },
        "rouge2": {
            "precision": 0.57144,
            "recall": 0.44421,
            "fmeasure": 0.49841
        },
        "rougeL": {
            "precision": 0.75834,
            "recall": 0.59212,
            "fmeasure": 0.66281
        },
        "rougeLsum": {
            "precision": 0.75834,
            "recall": 0.59212,
            "fmeasure": 0.66281
        },
        "bleu": 39.69886,
        "nubia": {
            "semantic_relation": 3.98092,
            "contradiction": 55.18338,
            "irrelevancy": 39.72479,
            "logical_agreement": 5.09183,
            "grammar_ref": 3.87101,
            "grammar_hyp": 4.15427,
            "nubia_score": 0.59222
        },
        "bleurt": 0.28916,
        "meteor": 0.3378377664048297,
        "bertscore": {
            "precision": 0.94031,
            "recall": 0.90181,
            "f1": 0.91953
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 13.857142857142858,
        "std_pred_length": 5.138887356744271,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5979381443298969,
        "vocab_size-1": 58,
        "unique-1": 41,
        "entropy-1": 5.479189806307083,
        "distinct-2": 0.8777777777777778,
        "vocab_size-2": 79,
        "unique-2": 70,
        "entropy-2": 6.225186429662998,
        "cond_entropy-2": 0.6148141433198989,
        "distinct-3": 0.927710843373494,
        "vocab_size-3": 77,
        "unique-3": 71,
        "entropy-3": 6.23046111809392,
        "cond_entropy-3": 0.02776464827026222,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 12.428571428571429,
        "std_pred_length-nopunct": 4.655477353371521,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6436781609195402,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.473934731207367,
        "distinct-2-nopunct": 0.8625,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 6.0219280948873575,
        "cond_entropy-2-nopunct": 0.6202816305861112,
        "distinct-3-nopunct": 0.9178082191780822,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 61,
        "entropy-3-nopunct": 6.02544099723619,
        "cond_entropy-3-nopunct": 0.0322800256364906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.75,
            "3": 0.717391304347826
        },
        "nist": 4.162900878906079,
        "rouge1": {
            "precision": 0.64158,
            "recall": 0.66502,
            "fmeasure": 0.63433
        },
        "rouge2": {
            "precision": 0.28095,
            "recall": 0.29673,
            "fmeasure": 0.27776
        },
        "rougeL": {
            "precision": 0.52775,
            "recall": 0.54493,
            "fmeasure": 0.5182
        },
        "rougeLsum": {
            "precision": 0.52775,
            "recall": 0.54493,
            "fmeasure": 0.5182
        },
        "bleu": 21.52879,
        "nubia": {
            "semantic_relation": 4.30421,
            "contradiction": 10.26708,
            "irrelevancy": 29.41687,
            "logical_agreement": 60.31605,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.39237,
            "nubia_score": 0.77481
        },
        "bleurt": 0.23103,
        "meteor": 0.34418423620868,
        "bertscore": {
            "precision": 0.90883,
            "recall": 0.90049,
            "f1": 0.90424
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.1365257343456969,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.15283195745508585,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 2.943051631204597,
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.63458,
            "fmeasure": 0.56486
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.34167,
            "fmeasure": 0.30079
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.57008,
            "fmeasure": 0.45909
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.57008,
            "fmeasure": 0.45909
        },
        "bleu": 20.76047,
        "nubia": {
            "semantic_relation": 4.29808,
            "contradiction": 0.24734,
            "irrelevancy": 70.02946,
            "logical_agreement": 29.7232,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.68691,
            "nubia_score": 0.69209
        },
        "bleurt": 0.0921,
        "meteor": 0.34693199151905174,
        "bertscore": {
            "precision": 0.88204,
            "recall": 0.90613,
            "f1": 0.88412
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.5,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 4.8625759375402735,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.03883444909293795,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9655172413793104,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.789015477886192,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": -0.029019418890029344,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9629629629629629
        },
        "nist": 4.982855333410896,
        "rouge1": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "rougeLsum": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "bleu": 91.53254,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31768,
            "irrelevancy": 0.57052,
            "logical_agreement": 99.11181,
            "grammar_ref": 5.04945,
            "grammar_hyp": 4.81437,
            "nubia_score": 1.0
        },
        "bleurt": 0.87023,
        "meteor": 0.6276979374374717,
        "bertscore": {
            "precision": 0.99594,
            "recall": 0.99594,
            "f1": 0.99594
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 8.0,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.784183719779189,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 36,
        "unique-2": 34,
        "entropy-2": 5.142664355548852,
        "cond_entropy-2": 0.33415139235430047,
        "distinct-3": 0.9722222222222222,
        "vocab_size-3": 35,
        "unique-3": 34,
        "entropy-3": 5.114369445886754,
        "cond_entropy-3": -0.022446956445717602,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8055555555555556,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.627986806877673,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.969815782426808,
        "cond_entropy-2-nopunct": 0.3737076928764665,
        "distinct-3-nopunct": 0.96875,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.9375,
        "cond_entropy-3-nopunct": -0.024962841250339415,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 0.8846153846153846
        },
        "nist": 5.064915173097376,
        "rouge1": {
            "precision": 0.78129,
            "recall": 0.78535,
            "fmeasure": 0.78218
        },
        "rouge2": {
            "precision": 0.6697,
            "recall": 0.68517,
            "fmeasure": 0.6765
        },
        "rougeL": {
            "precision": 0.78129,
            "recall": 0.78535,
            "fmeasure": 0.78218
        },
        "rougeLsum": {
            "precision": 0.78129,
            "recall": 0.78535,
            "fmeasure": 0.78218
        },
        "bleu": 81.41816,
        "nubia": {
            "semantic_relation": 4.64858,
            "contradiction": 0.30368,
            "irrelevancy": 1.88442,
            "logical_agreement": 97.8119,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.60166,
            "nubia_score": 0.90492
        },
        "bleurt": 0.68259,
        "meteor": 0.5410197639815344,
        "bertscore": {
            "precision": 0.96888,
            "recall": 0.96243,
            "f1": 0.96354
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.5,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.8220005168831515,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.2410167842972282,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.09019780897157811,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8709677419354839,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.671780584510635,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.17119459860840283,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.10309349296410335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5357142857142857
        },
        "nist": 2.6503079632595288,
        "rouge1": {
            "precision": 0.64719,
            "recall": 0.51437,
            "fmeasure": 0.57174
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.32917,
            "fmeasure": 0.37869
        },
        "rougeL": {
            "precision": 0.59957,
            "recall": 0.45973,
            "fmeasure": 0.51838
        },
        "rougeLsum": {
            "precision": 0.59957,
            "recall": 0.45973,
            "fmeasure": 0.51838
        },
        "bleu": 26.73956,
        "nubia": {
            "semantic_relation": 3.43739,
            "contradiction": 47.1051,
            "irrelevancy": 46.49446,
            "logical_agreement": 6.40044,
            "grammar_ref": 3.82725,
            "grammar_hyp": 4.48974,
            "nubia_score": 0.47042
        },
        "bleurt": 0.08135,
        "meteor": 0.25661041475238167,
        "bertscore": {
            "precision": 0.88554,
            "recall": 0.87796,
            "f1": 0.87924
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 5.5,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.8787878787878788,
        "vocab_size-1": 29,
        "unique-1": 25,
        "entropy-1": 4.801969876934213,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.10335057812519605,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9310344827586207,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.720049960644813,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.04505465518404472,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.375,
            "3": 1.0
        },
        "nist": 4.3876659814439956,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.86553,
            "fmeasure": 0.86176
        },
        "rouge2": {
            "precision": 0.65205,
            "recall": 0.65966,
            "fmeasure": 0.65095
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.73895,
            "fmeasure": 0.71777
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.73895,
            "fmeasure": 0.71777
        },
        "bleu": 49.1338,
        "nubia": {
            "semantic_relation": 4.76375,
            "contradiction": 0.47575,
            "irrelevancy": 16.7919,
            "logical_agreement": 82.73235,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.35593,
            "nubia_score": 0.93952
        },
        "bleurt": 0.4839,
        "meteor": 0.46162799748876326,
        "bertscore": {
            "precision": 0.93733,
            "recall": 0.9568,
            "f1": 0.94685
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 12.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.8611111111111112,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.871178126382214,
        "distinct-2": 1.0,
        "vocab_size-2": 33,
        "unique-2": 33,
        "entropy-2": 5.044394119358456,
        "cond_entropy-2": 0.056287299734322754,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.13750352374993471,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9032258064516129,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.760647923290102,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.06744432595644313,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.16349873228287956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.7
        },
        "nist": 3.5595970967109407,
        "rouge1": {
            "precision": 0.63333,
            "recall": 0.56025,
            "fmeasure": 0.57782
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.33518,
            "fmeasure": 0.34961
        },
        "rougeL": {
            "precision": 0.54444,
            "recall": 0.50288,
            "fmeasure": 0.50809
        },
        "rougeLsum": {
            "precision": 0.54444,
            "recall": 0.50288,
            "fmeasure": 0.50809
        },
        "bleu": 34.10531,
        "nubia": {
            "semantic_relation": 3.22271,
            "contradiction": 33.20497,
            "irrelevancy": 55.8312,
            "logical_agreement": 10.96384,
            "grammar_ref": 5.06451,
            "grammar_hyp": 5.30376,
            "nubia_score": 0.4567
        },
        "bleurt": -0.13558,
        "meteor": 0.3123727299113147,
        "bertscore": {
            "precision": 0.90813,
            "recall": 0.9085,
            "f1": 0.90587
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "nist": 2.9898332363522426,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "bleu": 61.0195,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "bleurt": 0.83294,
        "meteor": 0.5064321156600579,
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "nist": 2.6330370023236713,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "bleu": 42.95749,
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        },
        "bleurt": 0.45492,
        "meteor": 0.42350497485471644,
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        }
    },
    "wiki_auto_asset_turk_challenge_test_asset_nopunc": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_test_asset_nopunc",
        "N": 359,
        "msttr-100": 0.72685,
        "msttr-100_nopunct": 0.765,
        "total_length": 5424,
        "mean_pred_length": 15.108635097493035,
        "std_pred_length": 6.076293775641913,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.3821902654867257,
        "vocab_size-1": 2073,
        "unique-1": 1560,
        "entropy-1": 8.939936897025827,
        "distinct-2": 0.8416584402764067,
        "vocab_size-2": 4263,
        "unique-2": 3962,
        "entropy-2": 11.749232616574904,
        "cond_entropy-2": 2.555976065213123,
        "distinct-3": 0.9596260093497663,
        "vocab_size-3": 4516,
        "unique-3": 4446,
        "entropy-3": 12.047521651436847,
        "cond_entropy-3": 0.32727079509325613,
        "total_length-nopunct": 4853,
        "mean_pred_length-nopunct": 13.518105849582172,
        "std_pred_length-nopunct": 5.538327410590829,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4253039357098702,
        "vocab_size-1-nopunct": 2064,
        "unique-1-nopunct": 1559,
        "entropy-1-nopunct": 9.237041369842181,
        "distinct-2-nopunct": 0.8644859813084113,
        "vocab_size-2-nopunct": 3885,
        "unique-2-nopunct": 3625,
        "entropy-2-nopunct": 11.698943570065687,
        "cond_entropy-2-nopunct": 2.6421184313697386,
        "distinct-3-nopunct": 0.9816203143893591,
        "vocab_size-3-nopunct": 4059,
        "unique-3-nopunct": 4003,
        "entropy-3-nopunct": 11.972786813569828,
        "cond_entropy-3-nopunct": 0.30411725770763165,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_asset_nopunc.json",
        "local_recall": {
            "1": 0.04386473429951691,
            "2": 0.13598901098901098,
            "3": 0.23681125439624853,
            "4": 0.3413597733711048,
            "5": 0.4103585657370518,
            "6": 0.4827586206896552,
            "7": 0.5844748858447488,
            "8": 0.689484126984127,
            "9": 0.8129496402877698
        },
        "nist": 9.257094493681716,
        "rouge1": {
            "precision": 0.79279,
            "recall": 0.70364,
            "fmeasure": 0.72896
        },
        "rouge2": {
            "precision": 0.61544,
            "recall": 0.53522,
            "fmeasure": 0.55519
        },
        "rougeL": {
            "precision": 0.7486,
            "recall": 0.66954,
            "fmeasure": 0.69028
        },
        "rougeLsum": {
            "precision": 0.7486,
            "recall": 0.66954,
            "fmeasure": 0.69028
        },
        "bleu": 58.7796,
        "sari": 43.60607,
        "nubia": {
            "semantic_relation": 3.79786,
            "contradiction": 4.94528,
            "irrelevancy": 25.59709,
            "logical_agreement": 69.45763,
            "grammar_ref": 4.57404,
            "grammar_hyp": 5.12858,
            "nubia_score": 0.54529
        },
        "bleurt": -0.00403,
        "meteor": 0.3759682376413861,
        "bertscore": {
            "precision": 0.93939,
            "recall": 0.92292,
            "f1": 0.92656
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.625
        },
        "nist": 2.6460319154011556,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.49206,
            "fmeasure": 0.53865
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.30288,
            "fmeasure": 0.33036
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.49206,
            "fmeasure": 0.53865
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.49206,
            "fmeasure": 0.53865
        },
        "bleu": 41.72261,
        "nubia": {
            "semantic_relation": 3.37254,
            "contradiction": 57.6798,
            "irrelevancy": 8.53355,
            "logical_agreement": 33.78665,
            "grammar_ref": 5.77141,
            "grammar_hyp": 6.47673,
            "nubia_score": 0.31584
        },
        "bleurt": 0.27682,
        "meteor": 0.38383285656618293,
        "bertscore": {
            "precision": 0.94726,
            "recall": 0.94097,
            "f1": 0.94411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.8,
        "total_length": 172,
        "mean_pred_length": 17.2,
        "std_pred_length": 3.249615361854384,
        "median_pred_length": 17.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.6453488372093024,
        "vocab_size-1": 111,
        "unique-1": 89,
        "entropy-1": 6.350871023123273,
        "distinct-2": 0.9259259259259259,
        "vocab_size-2": 150,
        "unique-2": 138,
        "entropy-2": 7.191701854736459,
        "cond_entropy-2": 0.7249333766922421,
        "distinct-3": 0.9539473684210527,
        "vocab_size-3": 145,
        "unique-3": 138,
        "entropy-3": 7.155822250285672,
        "cond_entropy-3": -0.02613301575682892,
        "total_length-nopunct": 156,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 3.5832945734337835,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6987179487179487,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.408563037040652,
        "distinct-2-nopunct": 0.9246575342465754,
        "vocab_size-2-nopunct": 135,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 7.039139627373171,
        "cond_entropy-2-nopunct": 0.6729288459318061,
        "distinct-3-nopunct": 0.9485294117647058,
        "vocab_size-3-nopunct": 129,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 6.984521664779739,
        "cond_entropy-3-nopunct": -0.04353818821791298,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.4722222222222222,
            "3": 0.7692307692307693
        },
        "nist": 5.273875693200229,
        "rouge1": {
            "precision": 0.80007,
            "recall": 0.72671,
            "fmeasure": 0.75753
        },
        "rouge2": {
            "precision": 0.58709,
            "recall": 0.53326,
            "fmeasure": 0.55544
        },
        "rougeL": {
            "precision": 0.66243,
            "recall": 0.59219,
            "fmeasure": 0.62168
        },
        "rougeLsum": {
            "precision": 0.66243,
            "recall": 0.59219,
            "fmeasure": 0.62168
        },
        "bleu": 45.76624,
        "nubia": {
            "semantic_relation": 4.21576,
            "contradiction": 33.39063,
            "irrelevancy": 8.07529,
            "logical_agreement": 58.53408,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.22565,
            "nubia_score": 0.71657
        },
        "bleurt": 0.40789,
        "meteor": 0.3922609087620898,
        "bertscore": {
            "precision": 0.9493,
            "recall": 0.93786,
            "f1": 0.94319
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8292682926829268,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.979264809390595,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.17339886414559313,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.11864449649861893,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8648648648648649,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.918780730435346,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.16491793156737414,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.3333333333333333,
            "3": 0.6363636363636364
        },
        "nist": 3.527581261548812,
        "rouge1": {
            "precision": 0.62875,
            "recall": 0.51439,
            "fmeasure": 0.54379
        },
        "rouge2": {
            "precision": 0.27853,
            "recall": 0.24697,
            "fmeasure": 0.25931
        },
        "rougeL": {
            "precision": 0.56856,
            "recall": 0.4763,
            "fmeasure": 0.5006
        },
        "rougeLsum": {
            "precision": 0.56856,
            "recall": 0.4763,
            "fmeasure": 0.5006
        },
        "bleu": 30.65595,
        "nubia": {
            "semantic_relation": 4.12771,
            "contradiction": 12.70589,
            "irrelevancy": 15.10995,
            "logical_agreement": 72.18416,
            "grammar_ref": 4.68806,
            "grammar_hyp": 5.73905,
            "nubia_score": 0.59664
        },
        "bleurt": -0.04686,
        "meteor": 0.2582396579356121,
        "bertscore": {
            "precision": 0.87379,
            "recall": 0.84319,
            "f1": 0.8578
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 57,
        "mean_pred_length": 19.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 22,
        "distinct-1": 0.8596491228070176,
        "vocab_size-1": 49,
        "unique-1": 44,
        "entropy-1": 5.512457338612274,
        "distinct-2": 1.0,
        "vocab_size-2": 54,
        "unique-2": 54,
        "entropy-2": 5.7548875021634665,
        "cond_entropy-2": 0.17217850659737377,
        "distinct-3": 1.0,
        "vocab_size-3": 51,
        "unique-3": 51,
        "entropy-3": 5.6724253419715005,
        "cond_entropy-3": -0.08246216019197294,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.92,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.468758439731458,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.55458885167764,
        "cond_entropy-2-nopunct": 0.09700686407660356,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.09515723304034036,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.5,
            "3": 0.6792452830188679
        },
        "nist": 4.5096218495568134,
        "rouge1": {
            "precision": 0.82888,
            "recall": 0.76827,
            "fmeasure": 0.79172
        },
        "rouge2": {
            "precision": 0.69742,
            "recall": 0.70191,
            "fmeasure": 0.69471
        },
        "rougeL": {
            "precision": 0.76827,
            "recall": 0.72661,
            "fmeasure": 0.74233
        },
        "rougeLsum": {
            "precision": 0.76827,
            "recall": 0.72661,
            "fmeasure": 0.74233
        },
        "bleu": 54.6611,
        "nubia": {
            "semantic_relation": 4.47145,
            "contradiction": 0.34865,
            "irrelevancy": 30.54042,
            "logical_agreement": 69.11093,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.1431,
            "nubia_score": 0.82875
        },
        "bleurt": 0.51339,
        "meteor": 0.41172017517222004,
        "bertscore": {
            "precision": 0.95528,
            "recall": 0.93274,
            "f1": 0.943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.04505465518404472,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.2,
            "3": 0.9047619047619048
        },
        "nist": 4.5002024609082545,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.8072,
            "fmeasure": 0.82563
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.63782,
            "fmeasure": 0.65141
        },
        "rougeL": {
            "precision": 0.67949,
            "recall": 0.65641,
            "fmeasure": 0.66735
        },
        "rougeLsum": {
            "precision": 0.67949,
            "recall": 0.65641,
            "fmeasure": 0.66735
        },
        "bleu": 57.21955,
        "nubia": {
            "semantic_relation": 4.80562,
            "contradiction": 1.86798,
            "irrelevancy": 36.02852,
            "logical_agreement": 62.1035,
            "grammar_ref": 5.26806,
            "grammar_hyp": 4.86936,
            "nubia_score": 0.88865
        },
        "bleurt": 0.44025,
        "meteor": 0.4248155552074314,
        "bertscore": {
            "precision": 0.96398,
            "recall": 0.94306,
            "f1": 0.95336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 20.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.8392857142857143,
        "vocab_size-1": 47,
        "unique-1": 42,
        "entropy-1": 5.414497779200465,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.2979240230716325,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.08406426478847459,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8627450980392157,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.319484165500912,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.5849625007211605,
        "cond_entropy-2-nopunct": 0.2875371587496608,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.09310940439148176,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.8666666666666667,
            "3": 0.6060606060606061
        },
        "nist": 2.8328827111375325,
        "rouge1": {
            "precision": 0.69211,
            "recall": 0.57976,
            "fmeasure": 0.60596
        },
        "rouge2": {
            "precision": 0.37072,
            "recall": 0.29001,
            "fmeasure": 0.31174
        },
        "rougeL": {
            "precision": 0.4655,
            "recall": 0.36974,
            "fmeasure": 0.39822
        },
        "rougeLsum": {
            "precision": 0.4655,
            "recall": 0.36974,
            "fmeasure": 0.39822
        },
        "bleu": 16.56711,
        "nubia": {
            "semantic_relation": 3.46605,
            "contradiction": 61.92312,
            "irrelevancy": 4.95846,
            "logical_agreement": 33.11842,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.41212,
            "nubia_score": 0.47682
        },
        "bleurt": 0.01786,
        "meteor": 0.2744679203180102,
        "bertscore": {
            "precision": 0.89683,
            "recall": 0.88997,
            "f1": 0.8906
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8888888888888888
        },
        "nist": 2.2997963733835585,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.88889,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.5,
            "fmeasure": 0.42105
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.77778,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.77778,
            "fmeasure": 0.66667
        },
        "bleu": 25.45094,
        "nubia": {
            "semantic_relation": 4.9615,
            "contradiction": 0.13809,
            "irrelevancy": 0.73786,
            "logical_agreement": 99.12406,
            "grammar_ref": 6.68645,
            "grammar_hyp": 5.21536,
            "nubia_score": 1.0
        },
        "bleurt": 0.68493,
        "meteor": 0.45933486691439784,
        "bertscore": {
            "precision": 0.90595,
            "recall": 0.94971,
            "f1": 0.92732
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 10.333333333333334,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 9.0,
        "min_pred_length": 7,
        "max_pred_length": 15,
        "distinct-1": 0.9032258064516129,
        "vocab_size-1": 28,
        "unique-1": 26,
        "entropy-1": 4.7362967135428935,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": -0.07541281690069976,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.16349873228287956,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9642857142857143,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.735926350629034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.08349873228287957,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0625,
            "2": 0.8461538461538461,
            "3": 1.0
        },
        "nist": 4.223628960924441,
        "rouge1": {
            "precision": 0.88095,
            "recall": 0.84911,
            "fmeasure": 0.86376
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.6999,
            "fmeasure": 0.71009
        },
        "rougeL": {
            "precision": 0.86905,
            "recall": 0.838,
            "fmeasure": 0.85227
        },
        "rougeLsum": {
            "precision": 0.86905,
            "recall": 0.838,
            "fmeasure": 0.85227
        },
        "bleu": 52.09822,
        "nubia": {
            "semantic_relation": 4.7283,
            "contradiction": 0.4306,
            "irrelevancy": 0.4837,
            "logical_agreement": 99.0857,
            "grammar_ref": 5.27099,
            "grammar_hyp": 5.69786,
            "nubia_score": 0.87953
        },
        "bleurt": 0.69207,
        "meteor": 0.5412506044522375,
        "bertscore": {
            "precision": 0.98195,
            "recall": 0.97888,
            "f1": 0.97973
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "nist": 5.167285237000905,
        "rouge1": {
            "precision": 0.93939,
            "recall": 0.7381,
            "fmeasure": 0.82667
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5641,
            "fmeasure": 0.63768
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.61905,
            "fmeasure": 0.69333
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.61905,
            "fmeasure": 0.69333
        },
        "bleu": 86.17039,
        "nubia": {
            "semantic_relation": 4.47476,
            "contradiction": 0.21103,
            "irrelevancy": 0.50822,
            "logical_agreement": 99.28074,
            "grammar_ref": 5.70189,
            "grammar_hyp": 5.16131,
            "nubia_score": 0.88864
        },
        "bleurt": 0.39897,
        "meteor": 0.41350261431419155,
        "bertscore": {
            "precision": 0.95266,
            "recall": 0.92991,
            "f1": 0.94115
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 2.9137534064961805,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.4902,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "bleu": 25.38528,
        "nubia": {
            "semantic_relation": 4.98918,
            "contradiction": 0.125,
            "irrelevancy": 0.41772,
            "logical_agreement": 99.45728,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.50065,
            "nubia_score": 0.98365
        },
        "bleurt": 0.50787,
        "meteor": 0.41081248021664324,
        "bertscore": {
            "precision": 0.96297,
            "recall": 0.93529,
            "f1": 0.94893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.8284271247461903,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 38,
        "unique-1": 32,
        "entropy-1": 5.095175521464347,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 44,
        "unique-2": 43,
        "entropy-2": 5.44740865188523,
        "cond_entropy-2": 0.2792214289899287,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.05191662593186678,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 2.357022603955158,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.033184175406309,
        "distinct-2-nopunct": 0.975609756097561,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.308771516813203,
        "cond_entropy-2-nopunct": 0.3067761787164807,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.056992912227129496,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.25,
            "3": 0.75
        },
        "nist": 4.555431481175787,
        "rouge1": {
            "precision": 0.77407,
            "recall": 0.7185,
            "fmeasure": 0.74077
        },
        "rouge2": {
            "precision": 0.533,
            "recall": 0.46587,
            "fmeasure": 0.49225
        },
        "rougeL": {
            "precision": 0.63721,
            "recall": 0.58895,
            "fmeasure": 0.60666
        },
        "rougeLsum": {
            "precision": 0.63721,
            "recall": 0.58895,
            "fmeasure": 0.60666
        },
        "bleu": 48.61965,
        "nubia": {
            "semantic_relation": 4.4612,
            "contradiction": 24.54832,
            "irrelevancy": 35.14181,
            "logical_agreement": 40.30987,
            "grammar_ref": 4.10939,
            "grammar_hyp": 4.35592,
            "nubia_score": 0.7685
        },
        "bleurt": 0.18856,
        "meteor": 0.3722040270048508,
        "bertscore": {
            "precision": 0.92279,
            "recall": 0.92474,
            "f1": 0.92149
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.1523912776298655,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2545471137682951,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.273885809802417,
        "rouge1": {
            "precision": 0.94444,
            "recall": 1.0,
            "fmeasure": 0.97143
        },
        "rouge2": {
            "precision": 0.88235,
            "recall": 0.9375,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 1.0,
            "fmeasure": 0.97143
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 1.0,
            "fmeasure": 0.97143
        },
        "bleu": 83.1818,
        "nubia": {
            "semantic_relation": 4.01139,
            "contradiction": 16.14144,
            "irrelevancy": 81.9162,
            "logical_agreement": 1.94236,
            "grammar_ref": 5.25838,
            "grammar_hyp": 4.97196,
            "nubia_score": 0.60875
        },
        "bleurt": 0.75626,
        "meteor": 0.6134244054151646,
        "bertscore": {
            "precision": 0.98172,
            "recall": 0.99794,
            "f1": 0.98976
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.589898095464287,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219057,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "nist": 3.6349628618266467,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.81197,
            "fmeasure": 0.85749
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.5303,
            "fmeasure": 0.56277
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.73077,
            "fmeasure": 0.77174
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.73077,
            "fmeasure": 0.77174
        },
        "bleu": 54.10823,
        "nubia": {
            "semantic_relation": 4.94802,
            "contradiction": 0.30152,
            "irrelevancy": 1.00054,
            "logical_agreement": 98.69795,
            "grammar_ref": 5.03839,
            "grammar_hyp": 5.47268,
            "nubia_score": 0.88611
        },
        "bleurt": 0.45919,
        "meteor": 0.44981361328292224,
        "bertscore": {
            "precision": 0.97049,
            "recall": 0.94797,
            "f1": 0.95909
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.2864255422923785,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.2864255422923785,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6521739130434783
        },
        "nist": 1.5936468284111893,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.48571,
            "fmeasure": 0.57627
        },
        "rouge2": {
            "precision": 0.30435,
            "recall": 0.20588,
            "fmeasure": 0.24561
        },
        "rougeL": {
            "precision": 0.56944,
            "recall": 0.39048,
            "fmeasure": 0.46328
        },
        "rougeLsum": {
            "precision": 0.56944,
            "recall": 0.39048,
            "fmeasure": 0.46328
        },
        "bleu": 11.42734,
        "nubia": {
            "semantic_relation": 3.46284,
            "contradiction": 63.71297,
            "irrelevancy": 26.33756,
            "logical_agreement": 9.94947,
            "grammar_ref": 5.19058,
            "grammar_hyp": 5.39886,
            "nubia_score": 0.3858
        },
        "bleurt": -0.25404,
        "meteor": 0.2992443067455073,
        "bertscore": {
            "precision": 0.9276,
            "recall": 0.8824,
            "f1": 0.90424
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 2.3882580746443813,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.63636,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.13889,
            "recall": 0.22381,
            "fmeasure": 0.17065
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "bleu": 8.73717,
        "nubia": {
            "semantic_relation": 3.72063,
            "contradiction": 0.13102,
            "irrelevancy": 99.54598,
            "logical_agreement": 0.323,
            "grammar_ref": 4.68733,
            "grammar_hyp": 4.77237,
            "nubia_score": 0.56186
        },
        "bleurt": 0.0546,
        "meteor": 0.3571087401080447,
        "bertscore": {
            "precision": 0.82367,
            "recall": 0.89751,
            "f1": 0.85901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.812814895472355,
        "distinct-2": 0.9459459459459459,
        "vocab_size-2": 35,
        "unique-2": 33,
        "entropy-2": 5.101345257520845,
        "cond_entropy-2": 0.2012993376182578,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.004343465555080835,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8378378378378378,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.787571190644174,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.969815782426808,
        "cond_entropy-2-nopunct": 0.21946948957541362,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.004234272798947956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.38461538461538464,
            "3": 0.6
        },
        "nist": 3.206023020607198,
        "rouge1": {
            "precision": 0.63906,
            "recall": 0.54536,
            "fmeasure": 0.58627
        },
        "rouge2": {
            "precision": 0.3619,
            "recall": 0.30647,
            "fmeasure": 0.32991
        },
        "rougeL": {
            "precision": 0.61684,
            "recall": 0.52353,
            "fmeasure": 0.56427
        },
        "rougeLsum": {
            "precision": 0.61684,
            "recall": 0.52353,
            "fmeasure": 0.56427
        },
        "bleu": 13.94293,
        "nubia": {
            "semantic_relation": 2.86807,
            "contradiction": 51.86276,
            "irrelevancy": 14.97943,
            "logical_agreement": 33.15781,
            "grammar_ref": 4.28129,
            "grammar_hyp": 4.64391,
            "nubia_score": 0.36693
        },
        "bleurt": -0.11813,
        "meteor": 0.2686981308370916,
        "bertscore": {
            "precision": 0.89475,
            "recall": 0.87778,
            "f1": 0.88596
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.73,
        "total_length": 241,
        "mean_pred_length": 16.066666666666666,
        "std_pred_length": 4.753478258660237,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6348547717842323,
        "vocab_size-1": 153,
        "unique-1": 121,
        "entropy-1": 6.727065453782864,
        "distinct-2": 0.9380530973451328,
        "vocab_size-2": 212,
        "unique-2": 200,
        "entropy-2": 7.689604736732348,
        "cond_entropy-2": 0.8053905631614193,
        "distinct-3": 0.9715639810426541,
        "vocab_size-3": 205,
        "unique-3": 199,
        "entropy-3": 7.664227150792518,
        "cond_entropy-3": -0.025573731033467533,
        "total_length-nopunct": 217,
        "mean_pred_length-nopunct": 14.466666666666667,
        "std_pred_length-nopunct": 4.2874493842169406,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6866359447004609,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.800811201288045,
        "distinct-2-nopunct": 0.9356435643564357,
        "vocab_size-2-nopunct": 189,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.52202447777985,
        "cond_entropy-2-nopunct": 0.7727533778153362,
        "distinct-3-nopunct": 0.9732620320855615,
        "vocab_size-3-nopunct": 182,
        "unique-3-nopunct": 177,
        "entropy-3-nopunct": 7.493418524058743,
        "cond_entropy-3-nopunct": -0.028377049578987238,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2978723404255319,
            "2": 0.4444444444444444,
            "3": 0.8516129032258064
        },
        "nist": 6.275363634060759,
        "rouge1": {
            "precision": 0.7448,
            "recall": 0.80937,
            "fmeasure": 0.76769
        },
        "rouge2": {
            "precision": 0.57093,
            "recall": 0.60655,
            "fmeasure": 0.58043
        },
        "rougeL": {
            "precision": 0.67983,
            "recall": 0.74115,
            "fmeasure": 0.70153
        },
        "rougeLsum": {
            "precision": 0.67983,
            "recall": 0.74115,
            "fmeasure": 0.70153
        },
        "bleu": 52.26665,
        "nubia": {
            "semantic_relation": 4.48118,
            "contradiction": 5.67771,
            "irrelevancy": 32.30527,
            "logical_agreement": 62.01703,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.66487,
            "nubia_score": 0.80209
        },
        "bleurt": 0.32937,
        "meteor": 0.4594347200420639,
        "bertscore": {
            "precision": 0.94894,
            "recall": 0.95389,
            "f1": 0.94943
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.81,
        "msttr-100_nopunct": 0.83,
        "total_length": 113,
        "mean_pred_length": 16.142857142857142,
        "std_pred_length": 3.481730744843983,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7699115044247787,
        "vocab_size-1": 87,
        "unique-1": 75,
        "entropy-1": 6.187349095120274,
        "distinct-2": 0.9905660377358491,
        "vocab_size-2": 105,
        "unique-2": 104,
        "entropy-2": 6.7090525300348824,
        "cond_entropy-2": 0.40774149214801064,
        "distinct-3": 1.0,
        "vocab_size-3": 99,
        "unique-3": 99,
        "entropy-3": 6.62935662007962,
        "cond_entropy-3": -0.0783618142815695,
        "total_length-nopunct": 102,
        "mean_pred_length-nopunct": 14.571428571428571,
        "std_pred_length-nopunct": 3.5799897388976194,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.201837106677381,
        "distinct-2-nopunct": 0.9894736842105263,
        "vocab_size-2-nopunct": 94,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.548802976752,
        "cond_entropy-2-nopunct": 0.37111447688576826,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.459431618637305,
        "cond_entropy-3-nopunct": -0.08769671696637771,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6785714285714286,
            "3": 0.8405797101449275
        },
        "nist": 5.161800998059489,
        "rouge1": {
            "precision": 0.82411,
            "recall": 0.81644,
            "fmeasure": 0.80043
        },
        "rouge2": {
            "precision": 0.61274,
            "recall": 0.59584,
            "fmeasure": 0.59165
        },
        "rougeL": {
            "precision": 0.70318,
            "recall": 0.69742,
            "fmeasure": 0.68335
        },
        "rougeLsum": {
            "precision": 0.70318,
            "recall": 0.69742,
            "fmeasure": 0.68335
        },
        "bleu": 46.39837,
        "nubia": {
            "semantic_relation": 4.36371,
            "contradiction": 7.52402,
            "irrelevancy": 39.80976,
            "logical_agreement": 52.66621,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.42087,
            "nubia_score": 0.70222
        },
        "bleurt": 0.36195,
        "meteor": 0.42137421079097265,
        "bertscore": {
            "precision": 0.94052,
            "recall": 0.94137,
            "f1": 0.93866
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 62,
        "mean_pred_length": 20.666666666666668,
        "std_pred_length": 3.6817870057290873,
        "median_pred_length": 21.0,
        "min_pred_length": 16,
        "max_pred_length": 25,
        "distinct-1": 0.8387096774193549,
        "vocab_size-1": 52,
        "unique-1": 46,
        "entropy-1": 5.561220052699773,
        "distinct-2": 1.0,
        "vocab_size-2": 59,
        "unique-2": 59,
        "entropy-2": 5.882643049361836,
        "cond_entropy-2": 0.3075065351885298,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.07528812730423731,
        "total_length-nopunct": 55,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8545454545454545,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.4110955684955595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.700439718141095,
        "cond_entropy-2-nopunct": 0.31070554262797645,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.08572987402588379,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.625,
            "3": 0.8214285714285714
        },
        "nist": 4.472941122751499,
        "rouge1": {
            "precision": 0.71614,
            "recall": 0.7294,
            "fmeasure": 0.72001
        },
        "rouge2": {
            "precision": 0.54728,
            "recall": 0.57866,
            "fmeasure": 0.56105
        },
        "rougeL": {
            "precision": 0.6828,
            "recall": 0.69451,
            "fmeasure": 0.68597
        },
        "rougeLsum": {
            "precision": 0.6828,
            "recall": 0.69451,
            "fmeasure": 0.68597
        },
        "bleu": 44.25368,
        "nubia": {
            "semantic_relation": 3.71403,
            "contradiction": 15.10975,
            "irrelevancy": 9.39127,
            "logical_agreement": 75.49897,
            "grammar_ref": 4.44265,
            "grammar_hyp": 4.30777,
            "nubia_score": 0.63228
        },
        "bleurt": 0.23539,
        "meteor": 0.3847246420586103,
        "bertscore": {
            "precision": 0.91586,
            "recall": 0.92574,
            "f1": 0.91715
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 13.2,
        "std_pred_length": 5.418486873657627,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.7878787878787878,
        "vocab_size-1": 52,
        "unique-1": 42,
        "entropy-1": 5.554022483349365,
        "distinct-2": 1.0,
        "vocab_size-2": 61,
        "unique-2": 61,
        "entropy-2": 5.930737337562883,
        "cond_entropy-2": 0.22658727561694847,
        "distinct-3": 1.0,
        "vocab_size-3": 56,
        "unique-3": 56,
        "entropy-3": 5.807354922057609,
        "cond_entropy-3": -0.1233824155052819,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 11.8,
        "std_pred_length-nopunct": 5.192301994298868,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.847457627118644,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.5647636001726255,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.7548875021634665,
        "cond_entropy-2-nopunct": 0.18252014728613586,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.614709844115208,
        "cond_entropy-3-nopunct": -0.14017765804826005,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.7777777777777778
        },
        "nist": 4.491433598005378,
        "rouge1": {
            "precision": 0.77712,
            "recall": 0.79106,
            "fmeasure": 0.77327
        },
        "rouge2": {
            "precision": 0.525,
            "recall": 0.56614,
            "fmeasure": 0.5373
        },
        "rougeL": {
            "precision": 0.68267,
            "recall": 0.70329,
            "fmeasure": 0.68306
        },
        "rougeLsum": {
            "precision": 0.68267,
            "recall": 0.70329,
            "fmeasure": 0.68306
        },
        "bleu": 45.9927,
        "nubia": {
            "semantic_relation": 4.01624,
            "contradiction": 33.53222,
            "irrelevancy": 34.23221,
            "logical_agreement": 32.23558,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.22918,
            "nubia_score": 0.6814
        },
        "bleurt": 0.44749,
        "meteor": 0.44007847414535417,
        "bertscore": {
            "precision": 0.94586,
            "recall": 0.9516,
            "f1": 0.94534
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 3.9779155565930684,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.77244,
            "fmeasure": 0.82476
        },
        "rouge2": {
            "precision": 0.60606,
            "recall": 0.52222,
            "fmeasure": 0.55964
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.73077,
            "fmeasure": 0.77714
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.73077,
            "fmeasure": 0.77714
        },
        "bleu": 48.40463,
        "nubia": {
            "semantic_relation": 4.65592,
            "contradiction": 1.33699,
            "irrelevancy": 3.56667,
            "logical_agreement": 95.09634,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.9504,
            "nubia_score": 0.79543
        },
        "bleurt": 0.5181,
        "meteor": 0.4363167712366481,
        "bertscore": {
            "precision": 0.97152,
            "recall": 0.97157,
            "f1": 0.97154
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 3.5659084433001964,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.77576,
            "fmeasure": 0.82807
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.61111,
            "fmeasure": 0.65577
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.77576,
            "fmeasure": 0.82807
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.77576,
            "fmeasure": 0.82807
        },
        "bleu": 61.56287,
        "nubia": {
            "semantic_relation": 4.88529,
            "contradiction": 0.3305,
            "irrelevancy": 0.43801,
            "logical_agreement": 99.2315,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.61476,
            "nubia_score": 0.96634
        },
        "bleurt": 0.56133,
        "meteor": 0.46802752733401326,
        "bertscore": {
            "precision": 0.98534,
            "recall": 0.97315,
            "f1": 0.97921
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74,
        "total_length": 167,
        "mean_pred_length": 16.7,
        "std_pred_length": 4.73392015141785,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.6227544910179641,
        "vocab_size-1": 104,
        "unique-1": 83,
        "entropy-1": 6.246151840921914,
        "distinct-2": 0.9044585987261147,
        "vocab_size-2": 142,
        "unique-2": 130,
        "entropy-2": 7.089113344391685,
        "cond_entropy-2": 0.7902483828399403,
        "distinct-3": 0.9863945578231292,
        "vocab_size-3": 145,
        "unique-3": 143,
        "entropy-3": 7.172461460482613,
        "cond_entropy-3": 0.09732821163514875,
        "total_length-nopunct": 150,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.019960159204453,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6733333333333333,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 82,
        "entropy-1-nopunct": 6.283549024217065,
        "distinct-2-nopunct": 0.9071428571428571,
        "vocab_size-2-nopunct": 127,
        "unique-2-nopunct": 117,
        "entropy-2-nopunct": 6.927392570470044,
        "cond_entropy-2-nopunct": 0.7113628081300172,
        "distinct-3-nopunct": 0.9923076923076923,
        "vocab_size-3-nopunct": 129,
        "unique-3-nopunct": 128,
        "entropy-3-nopunct": 7.00698319764384,
        "cond_entropy-3-nopunct": 0.0951206615180294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.6538461538461539,
            "3": 0.8990825688073395
        },
        "nist": 6.483536468208762,
        "rouge1": {
            "precision": 0.84698,
            "recall": 0.86719,
            "fmeasure": 0.85326
        },
        "rouge2": {
            "precision": 0.66126,
            "recall": 0.67488,
            "fmeasure": 0.66499
        },
        "rougeL": {
            "precision": 0.70711,
            "recall": 0.74909,
            "fmeasure": 0.72567
        },
        "rougeLsum": {
            "precision": 0.70711,
            "recall": 0.74909,
            "fmeasure": 0.72567
        },
        "bleu": 62.83948,
        "nubia": {
            "semantic_relation": 4.49394,
            "contradiction": 11.09045,
            "irrelevancy": 34.33561,
            "logical_agreement": 54.57394,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.97444,
            "nubia_score": 0.79981
        },
        "bleurt": 0.45404,
        "meteor": 0.48143117310150896,
        "bertscore": {
            "precision": 0.95735,
            "recall": 0.95775,
            "f1": 0.95624
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.50789957099271,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "bleurt": 0.89367,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.7142857142857143
        },
        "nist": 1.6563910721497275,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.8125,
            "fmeasure": 0.61905
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.42857,
            "fmeasure": 0.31579
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.625,
            "fmeasure": 0.47619
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.625,
            "fmeasure": 0.47619
        },
        "bleu": 13.06511,
        "nubia": {
            "semantic_relation": 3.36539,
            "contradiction": 1.32294,
            "irrelevancy": 96.96805,
            "logical_agreement": 1.70901,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.31398,
            "nubia_score": 0.37042
        },
        "bleurt": -1.03465,
        "meteor": 0.39024782529772706,
        "bertscore": {
            "precision": 0.82519,
            "recall": 0.90328,
            "f1": 0.86247
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7
        },
        "nist": 2.4818971158838776,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.75,
            "fmeasure": 0.72
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.75,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.75,
            "fmeasure": 0.72
        },
        "bleu": 37.06866,
        "nubia": {
            "semantic_relation": 4.17286,
            "contradiction": 0.31345,
            "irrelevancy": 78.02059,
            "logical_agreement": 21.66595,
            "grammar_ref": 5.68739,
            "grammar_hyp": 4.26558,
            "nubia_score": 0.85035
        },
        "bleurt": 0.58257,
        "meteor": 0.39879105557888783,
        "bertscore": {
            "precision": 0.89748,
            "recall": 0.88532,
            "f1": 0.89136
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 17.0,
        "min_pred_length": 16,
        "max_pred_length": 21,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 44,
        "unique-1": 38,
        "entropy-1": 5.328599539040247,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.2756684771901917,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.08746284125033933,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.303508854797682,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.20710781792689456,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.0995356735509143,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.47058823529411764,
            "3": 0.8055555555555556
        },
        "nist": 4.275000230934241,
        "rouge1": {
            "precision": 0.81495,
            "recall": 0.7766,
            "fmeasure": 0.79133
        },
        "rouge2": {
            "precision": 0.50849,
            "recall": 0.48195,
            "fmeasure": 0.49233
        },
        "rougeL": {
            "precision": 0.59784,
            "recall": 0.538,
            "fmeasure": 0.55989
        },
        "rougeLsum": {
            "precision": 0.59784,
            "recall": 0.538,
            "fmeasure": 0.55989
        },
        "bleu": 38.37892,
        "nubia": {
            "semantic_relation": 4.29789,
            "contradiction": 4.72721,
            "irrelevancy": 22.90928,
            "logical_agreement": 72.36351,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.8591,
            "nubia_score": 0.66866
        },
        "bleurt": 0.22659,
        "meteor": 0.3909383321201444,
        "bertscore": {
            "precision": 0.93666,
            "recall": 0.92115,
            "f1": 0.92718
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 79,
        "mean_pred_length": 15.8,
        "std_pred_length": 3.8678159211627436,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.6962025316455697,
        "vocab_size-1": 55,
        "unique-1": 48,
        "entropy-1": 5.403534982623131,
        "distinct-2": 0.9459459459459459,
        "vocab_size-2": 70,
        "unique-2": 66,
        "entropy-2": 6.101345257520847,
        "cond_entropy-2": 0.6017506580508598,
        "distinct-3": 0.9710144927536232,
        "vocab_size-3": 67,
        "unique-3": 65,
        "entropy-3": 6.05055344228541,
        "cond_entropy-3": -0.04295789435802701,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.147288270665544,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7285714285714285,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.307714802597441,
        "distinct-2-nopunct": 0.9384615384615385,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.899290889951535,
        "cond_entropy-2-nopunct": 0.6547736423039023,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.84022392894185,
        "cond_entropy-3-nopunct": -0.04881055075326924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.875,
            "3": 0.9761904761904762
        },
        "nist": 5.852114010630501,
        "rouge1": {
            "precision": 0.87206,
            "recall": 0.90319,
            "fmeasure": 0.88288
        },
        "rouge2": {
            "precision": 0.68734,
            "recall": 0.7097,
            "fmeasure": 0.69328
        },
        "rougeL": {
            "precision": 0.8073,
            "recall": 0.84367,
            "fmeasure": 0.82059
        },
        "rougeLsum": {
            "precision": 0.8073,
            "recall": 0.84367,
            "fmeasure": 0.82059
        },
        "bleu": 68.42346,
        "nubia": {
            "semantic_relation": 4.35139,
            "contradiction": 24.50895,
            "irrelevancy": 24.64702,
            "logical_agreement": 50.84403,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.5613,
            "nubia_score": 0.78186
        },
        "bleurt": 0.50454,
        "meteor": 0.5131654827749575,
        "bertscore": {
            "precision": 0.95309,
            "recall": 0.97279,
            "f1": 0.96211
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.3735572622751855,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.5028145374500879,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.0506260730699678,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.392747410448783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.26341647163363247,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.058893689053568274,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "nist": 3.3869194545482744,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.74561,
            "fmeasure": 0.6716
        },
        "rouge2": {
            "precision": 0.36232,
            "recall": 0.44542,
            "fmeasure": 0.39954
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.45408,
            "fmeasure": 0.38419
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.45408,
            "fmeasure": 0.38419
        },
        "bleu": 36.96257,
        "nubia": {
            "semantic_relation": 3.90169,
            "contradiction": 0.62297,
            "irrelevancy": 9.8432,
            "logical_agreement": 89.53383,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.73412,
            "nubia_score": 0.68208
        },
        "bleurt": -0.22331,
        "meteor": 0.3789332289221943,
        "bertscore": {
            "precision": 0.85065,
            "recall": 0.87814,
            "f1": 0.86398
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "nist": 2.0052535157554314,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "bleu": 43.47209,
        "nubia": {
            "semantic_relation": 3.20888,
            "contradiction": 7.26046,
            "irrelevancy": 34.4265,
            "logical_agreement": 58.31305,
            "grammar_ref": 7.84225,
            "grammar_hyp": 6.05309,
            "nubia_score": 0.61047
        },
        "bleurt": -0.19772,
        "meteor": 0.329649630607643,
        "bertscore": {
            "precision": 0.91518,
            "recall": 0.90079,
            "f1": 0.90793
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.9090909090909091
        },
        "nist": 2.3754613970455307,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.86111,
            "fmeasure": 0.74817
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.6404,
            "fmeasure": 0.5456
        },
        "rougeL": {
            "precision": 0.64706,
            "recall": 0.84028,
            "fmeasure": 0.72797
        },
        "rougeLsum": {
            "precision": 0.64706,
            "recall": 0.84028,
            "fmeasure": 0.72797
        },
        "bleu": 20.46592,
        "nubia": {
            "semantic_relation": 4.35833,
            "contradiction": 2.96994,
            "irrelevancy": 50.21572,
            "logical_agreement": 46.81434,
            "grammar_ref": 4.67419,
            "grammar_hyp": 3.93163,
            "nubia_score": 0.80907
        },
        "bleurt": 0.65233,
        "meteor": 0.4265952285540264,
        "bertscore": {
            "precision": 0.89211,
            "recall": 0.96465,
            "f1": 0.91456
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.625
        },
        "nist": 2.555071304121285,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "bleu": 31.02016,
        "nubia": {
            "semantic_relation": 4.74617,
            "contradiction": 0.69551,
            "irrelevancy": 24.09977,
            "logical_agreement": 75.20471,
            "grammar_ref": 5.45224,
            "grammar_hyp": 5.0629,
            "nubia_score": 0.971
        },
        "bleurt": 0.55205,
        "meteor": 0.42773059020159415,
        "bertscore": {
            "precision": 0.96238,
            "recall": 0.92889,
            "f1": 0.94534
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.598076211353316,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 42,
        "unique-1": 33,
        "entropy-1": 5.1982454346708415,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 51,
        "unique-2": 49,
        "entropy-2": 5.629796992864144,
        "cond_entropy-2": 0.3322727108197291,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": 0.024066437654525513,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.0615528128088303,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.078562939644918,
        "distinct-2-nopunct": 0.9347826086956522,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.3767165755751956,
        "cond_entropy-2-nopunct": 0.34730957072417806,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": 0.029586121535163372,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.3888888888888889,
            "3": 0.95
        },
        "nist": 3.261819487992101,
        "rouge1": {
            "precision": 0.59444,
            "recall": 0.66927,
            "fmeasure": 0.61193
        },
        "rouge2": {
            "precision": 0.45536,
            "recall": 0.53162,
            "fmeasure": 0.47632
        },
        "rougeL": {
            "precision": 0.54722,
            "recall": 0.62723,
            "fmeasure": 0.56819
        },
        "rougeLsum": {
            "precision": 0.54722,
            "recall": 0.62723,
            "fmeasure": 0.56819
        },
        "bleu": 33.67674,
        "nubia": {
            "semantic_relation": 3.94106,
            "contradiction": 23.18968,
            "irrelevancy": 33.01223,
            "logical_agreement": 43.79808,
            "grammar_ref": 4.6519,
            "grammar_hyp": 5.07259,
            "nubia_score": 0.56027
        },
        "bleurt": 0.15674,
        "meteor": 0.36538172252903506,
        "bertscore": {
            "precision": 0.88633,
            "recall": 0.8983,
            "f1": 0.88927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.9,
        "vocab_size-1": 36,
        "unique-1": 33,
        "entropy-1": 5.103055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": -0.004366621150304511,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.058813890331199,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": -0.0043187608717378916,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1875,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 3.9505335810609066,
        "rouge1": {
            "precision": 0.7936,
            "recall": 0.67447,
            "fmeasure": 0.71715
        },
        "rouge2": {
            "precision": 0.55772,
            "recall": 0.45926,
            "fmeasure": 0.4976
        },
        "rougeL": {
            "precision": 0.70286,
            "recall": 0.60224,
            "fmeasure": 0.63894
        },
        "rougeLsum": {
            "precision": 0.70286,
            "recall": 0.60224,
            "fmeasure": 0.63894
        },
        "bleu": 47.11375,
        "nubia": {
            "semantic_relation": 3.96402,
            "contradiction": 0.22464,
            "irrelevancy": 55.56328,
            "logical_agreement": 44.21208,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.46024,
            "nubia_score": 0.72629
        },
        "bleurt": 0.15666,
        "meteor": 0.3915631138635693,
        "bertscore": {
            "precision": 0.93741,
            "recall": 0.90037,
            "f1": 0.91401
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.7142857142857143
        },
        "nist": 2.8715699480384034,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.57143,
            "fmeasure": 0.53257
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.28322,
            "fmeasure": 0.26519
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.46429,
            "fmeasure": 0.42912
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.46429,
            "fmeasure": 0.42912
        },
        "bleu": 26.01278,
        "nubia": {
            "semantic_relation": 4.39175,
            "contradiction": 0.50704,
            "irrelevancy": 29.8717,
            "logical_agreement": 69.62126,
            "grammar_ref": 5.74657,
            "grammar_hyp": 3.93125,
            "nubia_score": 0.93557
        },
        "bleurt": 0.2259,
        "meteor": 0.2847037720662867,
        "bertscore": {
            "precision": 0.86547,
            "recall": 0.89578,
            "f1": 0.87434
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 3.913977073182751,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.5043143755700347,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.10689059560851857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.875
        },
        "nist": 1.7878134178836338,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.9697,
            "fmeasure": 0.75973
        },
        "rouge2": {
            "precision": 0.51111,
            "recall": 0.82593,
            "fmeasure": 0.63111
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.9697,
            "fmeasure": 0.75973
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.9697,
            "fmeasure": 0.75973
        },
        "bleu": 22.37468,
        "nubia": {
            "semantic_relation": 3.70639,
            "contradiction": 4.76822,
            "irrelevancy": 93.69833,
            "logical_agreement": 1.53345,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.02289,
            "nubia_score": 0.54905
        },
        "bleurt": -0.02804,
        "meteor": 0.43393059825318553,
        "bertscore": {
            "precision": 0.88139,
            "recall": 0.97117,
            "f1": 0.92411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 3.6314597615834874,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7454545454545455,
        "vocab_size-1": 41,
        "unique-1": 31,
        "entropy-1": 5.2084547134459855,
        "distinct-2": 0.8627450980392157,
        "vocab_size-2": 44,
        "unique-2": 38,
        "entropy-2": 5.383113822321234,
        "cond_entropy-2": 0.06273008927357071,
        "distinct-3": 0.9361702127659575,
        "vocab_size-3": 44,
        "unique-3": 41,
        "entropy-3": 5.426929277209555,
        "cond_entropy-3": 0.06843771187983272,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.9154759474226504,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.095175521464346,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.078638720860853,
        "cond_entropy-2-nopunct": 0.027989288419856123,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.071928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8780487804878049
        },
        "nist": 5.127863262624373,
        "rouge1": {
            "precision": 0.95,
            "recall": 0.90143,
            "fmeasure": 0.92307
        },
        "rouge2": {
            "precision": 0.86647,
            "recall": 0.83813,
            "fmeasure": 0.85134
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.86339,
            "fmeasure": 0.88641
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.86339,
            "fmeasure": 0.88641
        },
        "bleu": 67.83839,
        "nubia": {
            "semantic_relation": 4.62965,
            "contradiction": 18.02633,
            "irrelevancy": 9.97219,
            "logical_agreement": 72.00149,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.05493,
            "nubia_score": 0.83314
        },
        "bleurt": 0.66689,
        "meteor": 0.5131708398434838,
        "bertscore": {
            "precision": 0.97504,
            "recall": 0.97683,
            "f1": 0.97459
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.969023783328203,
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.7381,
            "fmeasure": 0.72222
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.88426,
            "fmeasure": 0.8671
        },
        "bleu": 65.8037,
        "nubia": {
            "semantic_relation": 4.23369,
            "contradiction": 0.79699,
            "irrelevancy": 35.69325,
            "logical_agreement": 63.50976,
            "grammar_ref": 7.10682,
            "grammar_hyp": 6.76014,
            "nubia_score": 0.73725
        },
        "bleurt": 0.69484,
        "meteor": 0.5046339609688354,
        "bertscore": {
            "precision": 0.9703,
            "recall": 0.97351,
            "f1": 0.96978
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5454545454545454
        },
        "nist": 1.7540712657384554,
        "rouge1": {
            "precision": 0.41176,
            "recall": 0.53472,
            "fmeasure": 0.46325
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.08283,
            "fmeasure": 0.07089
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.38194,
            "fmeasure": 0.3309
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.38194,
            "fmeasure": 0.3309
        },
        "bleu": 9.62994,
        "nubia": {
            "semantic_relation": 3.75946,
            "contradiction": 4.31227,
            "irrelevancy": 44.7073,
            "logical_agreement": 50.98043,
            "grammar_ref": 5.53377,
            "grammar_hyp": 4.93889,
            "nubia_score": 0.61642
        },
        "bleurt": -0.30595,
        "meteor": 0.20471045211206826,
        "bertscore": {
            "precision": 0.82485,
            "recall": 0.84737,
            "f1": 0.83237
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.2516291673878226,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.23810548155250455,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "nist": 4.100909897353531,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.96296,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.91667,
            "fmeasure": 0.88889
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.96296,
            "fmeasure": 0.93333
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.96296,
            "fmeasure": 0.93333
        },
        "bleu": 73.48889,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.31665,
            "irrelevancy": 1.54603,
            "logical_agreement": 97.13731,
            "grammar_ref": 5.94246,
            "grammar_hyp": 5.18915,
            "nubia_score": 0.97387
        },
        "bleurt": 0.62323,
        "meteor": 0.9454545454545454,
        "bertscore": {
            "precision": 0.99189,
            "recall": 0.99189,
            "f1": 0.99189
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 6.0,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.836591668108977,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.15283195745508593,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.0249628412503394,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8387096774193549,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.631615665225586,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.17964675370621433,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.9230769230769231
        },
        "nist": 4.901918588047584,
        "rouge1": {
            "precision": 0.89855,
            "recall": 0.88582,
            "fmeasure": 0.89085
        },
        "rouge2": {
            "precision": 0.77273,
            "recall": 0.78139,
            "fmeasure": 0.77696
        },
        "rougeL": {
            "precision": 0.84058,
            "recall": 0.84552,
            "fmeasure": 0.843
        },
        "rougeLsum": {
            "precision": 0.84058,
            "recall": 0.84552,
            "fmeasure": 0.843
        },
        "bleu": 68.84744,
        "nubia": {
            "semantic_relation": 4.53578,
            "contradiction": 1.08364,
            "irrelevancy": 6.14832,
            "logical_agreement": 92.76804,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.29952,
            "nubia_score": 0.82921
        },
        "bleurt": 0.48693,
        "meteor": 0.4923832151834533,
        "bertscore": {
            "precision": 0.96332,
            "recall": 0.95628,
            "f1": 0.95671
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.03462179117476822,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 1.0,
            "3": 0.8947368421052632
        },
        "nist": 5.000017703148979,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.88384,
            "fmeasure": 0.89592
        },
        "rouge2": {
            "precision": 0.78333,
            "recall": 0.77121,
            "fmeasure": 0.77698
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.88384,
            "fmeasure": 0.89592
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.88384,
            "fmeasure": 0.89592
        },
        "bleu": 80.18569,
        "nubia": {
            "semantic_relation": 4.78058,
            "contradiction": 0.65198,
            "irrelevancy": 2.15089,
            "logical_agreement": 97.19713,
            "grammar_ref": 5.62679,
            "grammar_hyp": 5.10158,
            "nubia_score": 0.95179
        },
        "bleurt": 0.70762,
        "meteor": 0.489717712374343,
        "bertscore": {
            "precision": 0.98869,
            "recall": 0.97921,
            "f1": 0.98226
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 77,
        "mean_pred_length": 12.833333333333334,
        "std_pred_length": 4.9805175991613115,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.5454545454545454,
        "vocab_size-1": 42,
        "unique-1": 30,
        "entropy-1": 4.98115383342619,
        "distinct-2": 0.7464788732394366,
        "vocab_size-2": 53,
        "unique-2": 42,
        "entropy-2": 5.568279337601237,
        "cond_entropy-2": 0.532254458670483,
        "distinct-3": 0.7846153846153846,
        "vocab_size-3": 51,
        "unique-3": 43,
        "entropy-3": 5.521916658982599,
        "cond_entropy-3": -0.06584084493776625,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 11.833333333333334,
        "std_pred_length-nopunct": 5.273097339852125,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5633802816901409,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.918985457740538,
        "distinct-2-nopunct": 0.7538461538461538,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.460378197444138,
        "cond_entropy-2-nopunct": 0.5818493930639245,
        "distinct-3-nopunct": 0.7966101694915254,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.411889871212392,
        "cond_entropy-3-nopunct": -0.07192815349712162,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7692307692307693,
            "3": 0.9047619047619048
        },
        "nist": 5.9809588363161765,
        "rouge1": {
            "precision": 0.89998,
            "recall": 0.91932,
            "fmeasure": 0.90613
        },
        "rouge2": {
            "precision": 0.78966,
            "recall": 0.80669,
            "fmeasure": 0.79493
        },
        "rougeL": {
            "precision": 0.88065,
            "recall": 0.89723,
            "fmeasure": 0.88562
        },
        "rougeLsum": {
            "precision": 0.88065,
            "recall": 0.89723,
            "fmeasure": 0.88562
        },
        "bleu": 76.87787,
        "nubia": {
            "semantic_relation": 4.15624,
            "contradiction": 20.4294,
            "irrelevancy": 22.9511,
            "logical_agreement": 56.6195,
            "grammar_ref": 4.0718,
            "grammar_hyp": 4.11742,
            "nubia_score": 0.76437
        },
        "bleurt": 0.57363,
        "meteor": 0.5109458723955485,
        "bertscore": {
            "precision": 0.97628,
            "recall": 0.97883,
            "f1": 0.97755
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 2.7238054442553494,
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.74411,
            "fmeasure": 0.68599
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.5,
            "fmeasure": 0.42105
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.74411,
            "fmeasure": 0.68599
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.74411,
            "fmeasure": 0.68599
        },
        "bleu": 22.62944,
        "nubia": {
            "semantic_relation": 3.60057,
            "contradiction": 31.66071,
            "irrelevancy": 65.77646,
            "logical_agreement": 2.56282,
            "grammar_ref": 6.0554,
            "grammar_hyp": 6.90279,
            "nubia_score": 0.33112
        },
        "bleurt": -0.47914,
        "meteor": 0.3823953232246601,
        "bertscore": {
            "precision": 0.87574,
            "recall": 0.93482,
            "f1": 0.90432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 10,
        "unique-1": 6,
        "entropy-1": 3.2359263506290334,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.35462325762194935,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.918295834054489,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.277613436819116,
        "cond_entropy-2-nopunct": 0.3290145724615955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "nist": 3.16333702950726,
        "rouge1": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.69697,
            "fmeasure": 0.68116
        },
        "rougeL": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "rougeLsum": {
            "precision": 0.73077,
            "recall": 0.75962,
            "fmeasure": 0.74462
        },
        "bleu": 61.15381,
        "nubia": {
            "semantic_relation": 3.07117,
            "contradiction": 98.59532,
            "irrelevancy": 0.62762,
            "logical_agreement": 0.77706,
            "grammar_ref": 3.96979,
            "grammar_hyp": 3.40628,
            "nubia_score": 0.45471
        },
        "bleurt": 0.60179,
        "meteor": 0.451369116507126,
        "bertscore": {
            "precision": 0.97141,
            "recall": 0.94728,
            "f1": 0.95919
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 3.5,
        "median_pred_length": 23.5,
        "min_pred_length": 20,
        "max_pred_length": 27,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 29,
        "entropy-1": 5.001397362315937,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 42,
        "unique-2": 39,
        "entropy-2": 5.358519762996339,
        "cond_entropy-2": 0.38170868909648165,
        "distinct-3": 0.9534883720930233,
        "vocab_size-3": 41,
        "unique-3": 39,
        "entropy-3": 5.333241498888144,
        "cond_entropy-3": -0.019076713720599832,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.871928094887363,
        "distinct-2-nopunct": 0.9210526315789473,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.090032776601483,
        "cond_entropy-2-nopunct": 0.24178889224043365,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.058813890331199,
        "cond_entropy-3-nopunct": -0.0224469564457176,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 2.8196327444133127,
        "rouge1": {
            "precision": 0.64082,
            "recall": 0.58041,
            "fmeasure": 0.60393
        },
        "rouge2": {
            "precision": 0.36657,
            "recall": 0.34307,
            "fmeasure": 0.35156
        },
        "rougeL": {
            "precision": 0.54991,
            "recall": 0.51563,
            "fmeasure": 0.52893
        },
        "rougeLsum": {
            "precision": 0.54991,
            "recall": 0.51563,
            "fmeasure": 0.52893
        },
        "bleu": 30.6069,
        "nubia": {
            "semantic_relation": 3.4873,
            "contradiction": 8.68978,
            "irrelevancy": 81.81319,
            "logical_agreement": 9.49703,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.84026,
            "nubia_score": 0.49974
        },
        "bleurt": -0.22394,
        "meteor": 0.27477160166136344,
        "bertscore": {
            "precision": 0.83613,
            "recall": 0.84708,
            "f1": 0.84152
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.018549068142959,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rouge2": {
            "precision": 0.80952,
            "recall": 0.90476,
            "fmeasure": 0.85348
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.95833,
            "fmeasure": 0.91389
        },
        "bleu": 69.85342,
        "nubia": {
            "semantic_relation": 4.38462,
            "contradiction": 0.18156,
            "irrelevancy": 63.65703,
            "logical_agreement": 36.16141,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.57005,
            "nubia_score": 0.947
        },
        "bleurt": 0.6035,
        "meteor": 0.5255759325753065,
        "bertscore": {
            "precision": 0.95785,
            "recall": 0.97999,
            "f1": 0.96524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 18.0,
        "min_pred_length": 15,
        "max_pred_length": 25,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 42,
        "unique-1": 32,
        "entropy-1": 5.196523616220669,
        "distinct-2": 0.9636363636363636,
        "vocab_size-2": 53,
        "unique-2": 51,
        "entropy-2": 5.708632440797383,
        "cond_entropy-2": 0.4617358179323021,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.0039969184604905705,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8085106382978723,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.094809267115153,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.41397707318275,
        "cond_entropy-2-nopunct": 0.32778914137867804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.053099126214335574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.5333333333333333,
            "3": 0.7692307692307693
        },
        "nist": 2.9489170636843425,
        "rouge1": {
            "precision": 0.47677,
            "recall": 0.69921,
            "fmeasure": 0.56522
        },
        "rouge2": {
            "precision": 0.24535,
            "recall": 0.38759,
            "fmeasure": 0.29903
        },
        "rougeL": {
            "precision": 0.41293,
            "recall": 0.60509,
            "fmeasure": 0.48939
        },
        "rougeLsum": {
            "precision": 0.41293,
            "recall": 0.60509,
            "fmeasure": 0.48939
        },
        "bleu": 24.20491,
        "nubia": {
            "semantic_relation": 3.45948,
            "contradiction": 8.93087,
            "irrelevancy": 72.97326,
            "logical_agreement": 18.09587,
            "grammar_ref": 4.63208,
            "grammar_hyp": 4.00586,
            "nubia_score": 0.5682
        },
        "bleurt": -0.11544,
        "meteor": 0.33299640294164295,
        "bertscore": {
            "precision": 0.83377,
            "recall": 0.90294,
            "f1": 0.86555
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.944797625754069,
        "rouge1": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.90476,
            "recall": 0.94444,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.73925,
            "contradiction": 0.27952,
            "irrelevancy": 59.63412,
            "logical_agreement": 40.08636,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.19529,
            "nubia_score": 0.89159
        },
        "bleurt": 0.56963,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 4.109609335312651,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 5.003055907333276,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.10374148695780361,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": -0.0040879703896692515,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.4166666666666667,
            "3": 0.75
        },
        "nist": 4.587848681785715,
        "rouge1": {
            "precision": 0.75936,
            "recall": 0.62439,
            "fmeasure": 0.67077
        },
        "rouge2": {
            "precision": 0.47391,
            "recall": 0.42184,
            "fmeasure": 0.42751
        },
        "rougeL": {
            "precision": 0.56624,
            "recall": 0.52561,
            "fmeasure": 0.52922
        },
        "rougeLsum": {
            "precision": 0.56624,
            "recall": 0.52561,
            "fmeasure": 0.52922
        },
        "bleu": 39.04584,
        "nubia": {
            "semantic_relation": 3.79323,
            "contradiction": 42.62568,
            "irrelevancy": 1.7462,
            "logical_agreement": 55.62812,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.41727,
            "nubia_score": 0.60914
        },
        "bleurt": 0.21032,
        "meteor": 0.38421805869901055,
        "bertscore": {
            "precision": 0.91651,
            "recall": 0.8954,
            "f1": 0.90411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.0,
        "median_pred_length": 19.0,
        "min_pred_length": 15,
        "max_pred_length": 23,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 28,
        "unique-1": 21,
        "entropy-1": 4.626621185168934,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.4667097233997496,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.569657210485732,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838573,
        "cond_entropy-2-nopunct": 0.46488020670322766,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.05621284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.8666666666666667,
            "3": 1.0
        },
        "nist": 4.6066561435076565,
        "rouge1": {
            "precision": 0.74116,
            "recall": 0.89618,
            "fmeasure": 0.80838
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.75785,
            "fmeasure": 0.67846
        },
        "rougeL": {
            "precision": 0.73005,
            "recall": 0.8823,
            "fmeasure": 0.79603
        },
        "rougeLsum": {
            "precision": 0.73005,
            "recall": 0.8823,
            "fmeasure": 0.79603
        },
        "bleu": 61.60142,
        "nubia": {
            "semantic_relation": 3.75219,
            "contradiction": 50.2108,
            "irrelevancy": 1.20992,
            "logical_agreement": 48.57928,
            "grammar_ref": 4.13759,
            "grammar_hyp": 3.93589,
            "nubia_score": 0.65349
        },
        "bleurt": 0.57052,
        "meteor": 0.4779725421736991,
        "bertscore": {
            "precision": 0.95552,
            "recall": 0.96619,
            "f1": 0.95798
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 11.333333333333334,
        "std_pred_length": 4.027681991198191,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.7352941176470589,
        "vocab_size-1": 25,
        "unique-1": 19,
        "entropy-1": 4.477024973539649,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.3828625013946004,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.14684138832927116,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7666666666666667,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.3735572622751855,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.44058949914754264,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.7083333333333334
        },
        "nist": 3.2191284997466556,
        "rouge1": {
            "precision": 0.71131,
            "recall": 0.65033,
            "fmeasure": 0.65224
        },
        "rouge2": {
            "precision": 0.43175,
            "recall": 0.47083,
            "fmeasure": 0.44624
        },
        "rougeL": {
            "precision": 0.69544,
            "recall": 0.65449,
            "fmeasure": 0.65224
        },
        "rougeLsum": {
            "precision": 0.69544,
            "recall": 0.65449,
            "fmeasure": 0.65224
        },
        "bleu": 48.34821,
        "nubia": {
            "semantic_relation": 3.79105,
            "contradiction": 52.45195,
            "irrelevancy": 3.49933,
            "logical_agreement": 44.04872,
            "grammar_ref": 4.11451,
            "grammar_hyp": 4.8921,
            "nubia_score": 0.57134
        },
        "bleurt": 0.29857,
        "meteor": 0.32321139351600264,
        "bertscore": {
            "precision": 0.9316,
            "recall": 0.90169,
            "f1": 0.91085
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 3.5,
        "median_pred_length": 19.5,
        "min_pred_length": 16,
        "max_pred_length": 23,
        "distinct-1": 0.8205128205128205,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.907071770088825,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.32283189006841645,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.6578823768686535,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.32125017496917896,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.8
        },
        "nist": 3.689787955510904,
        "rouge1": {
            "precision": 0.73889,
            "recall": 0.85307,
            "fmeasure": 0.78988
        },
        "rouge2": {
            "precision": 0.48371,
            "recall": 0.60018,
            "fmeasure": 0.53365
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.78481,
            "fmeasure": 0.7444
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.78481,
            "fmeasure": 0.7444
        },
        "bleu": 39.82016,
        "nubia": {
            "semantic_relation": 4.90798,
            "contradiction": 2.18208,
            "irrelevancy": 7.56994,
            "logical_agreement": 90.24798,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.85968,
            "nubia_score": 0.93313
        },
        "bleurt": 0.31142,
        "meteor": 0.46976139664888433,
        "bertscore": {
            "precision": 0.92652,
            "recall": 0.95738,
            "f1": 0.9417
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "nist": 1.8866070611151255,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.52564,
            "fmeasure": 0.60024
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.40598,
            "fmeasure": 0.46898
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.52564,
            "fmeasure": 0.60024
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.52564,
            "fmeasure": 0.60024
        },
        "bleu": 31.6542,
        "nubia": {
            "semantic_relation": 3.34954,
            "contradiction": 3.5075,
            "irrelevancy": 10.64899,
            "logical_agreement": 85.84352,
            "grammar_ref": 5.35534,
            "grammar_hyp": 5.24221,
            "nubia_score": 0.43629
        },
        "bleurt": -0.06324,
        "meteor": 0.2947896646399671,
        "bertscore": {
            "precision": 0.92512,
            "recall": 0.87655,
            "f1": 0.90018
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 83,
        "mean_pred_length": 20.75,
        "std_pred_length": 6.299801584177076,
        "median_pred_length": 22.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.7228915662650602,
        "vocab_size-1": 60,
        "unique-1": 48,
        "entropy-1": 5.651954944226405,
        "distinct-2": 0.9746835443037974,
        "vocab_size-2": 77,
        "unique-2": 75,
        "entropy-2": 6.2531478367846995,
        "cond_entropy-2": 0.5924254931628661,
        "distinct-3": 1.0,
        "vocab_size-3": 75,
        "unique-3": 75,
        "entropy-3": 6.228818690495891,
        "cond_entropy-3": -0.021628724347888918,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 6.041522986797286,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7631578947368421,
        "vocab_size-1-nopunct": 58,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.637317356120344,
        "distinct-2-nopunct": 0.9722222222222222,
        "vocab_size-2-nopunct": 70,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.114369445886761,
        "cond_entropy-2-nopunct": 0.4889615082188035,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.087462841250345,
        "cond_entropy-3-nopunct": -0.023638630780208263,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.47368421052631576,
            "3": 0.6296296296296297
        },
        "nist": 3.655708164093579,
        "rouge1": {
            "precision": 0.56941,
            "recall": 0.55535,
            "fmeasure": 0.55369
        },
        "rouge2": {
            "precision": 0.28946,
            "recall": 0.2995,
            "fmeasure": 0.28753
        },
        "rougeL": {
            "precision": 0.45645,
            "recall": 0.43462,
            "fmeasure": 0.44061
        },
        "rougeLsum": {
            "precision": 0.45645,
            "recall": 0.43462,
            "fmeasure": 0.44061
        },
        "bleu": 20.76418,
        "nubia": {
            "semantic_relation": 3.4375,
            "contradiction": 17.69575,
            "irrelevancy": 67.9442,
            "logical_agreement": 14.36004,
            "grammar_ref": 4.54253,
            "grammar_hyp": 4.84751,
            "nubia_score": 0.44747
        },
        "bleurt": -0.33104,
        "meteor": 0.27234383000334633,
        "bertscore": {
            "precision": 0.86671,
            "recall": 0.85736,
            "f1": 0.85855
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 23,
        "unique-1": 16,
        "entropy-1": 4.413716068381603,
        "distinct-2": 0.9310344827586207,
        "vocab_size-2": 27,
        "unique-2": 25,
        "entropy-2": 4.720049960644813,
        "cond_entropy-2": 0.23430063304142654,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.6808134280893965,
        "cond_entropy-3": -0.029019418890029347,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.310443057719025,
        "distinct-2-nopunct": 0.92,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.483856189774723,
        "cond_entropy-2-nopunct": 0.168968687611256,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.436605434317882,
        "cond_entropy-3-nopunct": -0.07681597284814654,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.43478260869565216
        },
        "nist": 2.21560764480805,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.41818,
            "fmeasure": 0.40612
        },
        "rouge2": {
            "precision": 0.12662,
            "recall": 0.14444,
            "fmeasure": 0.13364
        },
        "rougeL": {
            "precision": 0.36667,
            "recall": 0.38693,
            "fmeasure": 0.37387
        },
        "rougeLsum": {
            "precision": 0.36667,
            "recall": 0.38693,
            "fmeasure": 0.37387
        },
        "bleu": 14.11737,
        "nubia": {
            "semantic_relation": 3.7241,
            "contradiction": 0.84371,
            "irrelevancy": 70.60505,
            "logical_agreement": 28.55124,
            "grammar_ref": 4.72797,
            "grammar_hyp": 5.03302,
            "nubia_score": 0.51361
        },
        "bleurt": -0.09819,
        "meteor": 0.1992341020340809,
        "bertscore": {
            "precision": 0.86493,
            "recall": 0.86207,
            "f1": 0.8634
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 10,
        "unique-1": 6,
        "entropy-1": 3.2359263506290334,
        "distinct-2": 0.8461538461538461,
        "vocab_size-2": 11,
        "unique-2": 9,
        "entropy-2": 3.3927474104487847,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 11,
        "unique-3": 10,
        "entropy-3": 3.418295834054489,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 3.0850551027564768,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.2516291673878226,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.2776134368191165,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nist": 1.9001483542818842,
        "rouge1": {
            "precision": 0.5641,
            "recall": 0.36522,
            "fmeasure": 0.43915
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.14646,
            "fmeasure": 0.1732
        },
        "rougeL": {
            "precision": 0.35897,
            "recall": 0.32479,
            "fmeasure": 0.34066
        },
        "rougeLsum": {
            "precision": 0.35897,
            "recall": 0.32479,
            "fmeasure": 0.34066
        },
        "bleu": 9.23843,
        "nubia": {
            "semantic_relation": 2.44537,
            "contradiction": 9.09773,
            "irrelevancy": 68.44906,
            "logical_agreement": 22.45321,
            "grammar_ref": 4.61776,
            "grammar_hyp": 4.93398,
            "nubia_score": 0.20468
        },
        "bleurt": -0.98497,
        "meteor": 0.15427673850158954,
        "bertscore": {
            "precision": 0.82263,
            "recall": 0.74529,
            "f1": 0.78205
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 23.0,
        "std_pred_length": 1.0,
        "median_pred_length": 23.0,
        "min_pred_length": 22,
        "max_pred_length": 24,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 5.17573586910049,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 42,
        "unique-2": 40,
        "entropy-2": 5.368522527728205,
        "cond_entropy-2": 0.1631423898530118,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": 0.028123899379558455,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 21.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8372093023255814,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.10068335935326,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.259991029008325,
        "cond_entropy-2-nopunct": 0.17518968894037604,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": 0.030414316808267502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.3333333333333333,
            "3": 0.8928571428571429
        },
        "nist": 4.557531016569825,
        "rouge1": {
            "precision": 0.73706,
            "recall": 0.7713,
            "fmeasure": 0.75236
        },
        "rouge2": {
            "precision": 0.49015,
            "recall": 0.49978,
            "fmeasure": 0.49418
        },
        "rougeL": {
            "precision": 0.47447,
            "recall": 0.65063,
            "fmeasure": 0.52804
        },
        "rougeLsum": {
            "precision": 0.47447,
            "recall": 0.65063,
            "fmeasure": 0.52804
        },
        "bleu": 46.64509,
        "nubia": {
            "semantic_relation": 4.34875,
            "contradiction": 0.50316,
            "irrelevancy": 0.86931,
            "logical_agreement": 98.62753,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.39486,
            "nubia_score": 0.70956
        },
        "bleurt": 0.23551,
        "meteor": 0.4537784315524942,
        "bertscore": {
            "precision": 0.91898,
            "recall": 0.93342,
            "f1": 0.91972
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 5.90668171555645,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.76,
        "vocab_size-1": 38,
        "unique-1": 31,
        "entropy-1": 5.078562939644918,
        "distinct-2": 1.0,
        "vocab_size-2": 47,
        "unique-2": 47,
        "entropy-2": 5.55458885167764,
        "cond_entropy-2": 0.44466324711670197,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.09515723304034036,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.656854249492381,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.01385809623352,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.41260182655210753,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.10691520391651191,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.6206896551724138
        },
        "nist": 2.5543837188423297,
        "rouge1": {
            "precision": 0.41417,
            "recall": 0.5639,
            "fmeasure": 0.46935
        },
        "rouge2": {
            "precision": 0.19697,
            "recall": 0.29563,
            "fmeasure": 0.2254
        },
        "rougeL": {
            "precision": 0.39036,
            "recall": 0.4943,
            "fmeasure": 0.41709
        },
        "rougeLsum": {
            "precision": 0.39036,
            "recall": 0.4943,
            "fmeasure": 0.41709
        },
        "bleu": 25.92023,
        "nubia": {
            "semantic_relation": 3.18693,
            "contradiction": 33.99369,
            "irrelevancy": 32.89284,
            "logical_agreement": 33.11346,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.51426,
            "nubia_score": 0.47517
        },
        "bleurt": -0.08608,
        "meteor": 0.25207747789165713,
        "bertscore": {
            "precision": 0.83953,
            "recall": 0.872,
            "f1": 0.85336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.8284271247461903,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 33,
        "unique-1": 29,
        "entropy-1": 4.938997731571813,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.12771410208460499,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9117647058823529,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.8887896794220005,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.08463306598051865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.78125
        },
        "nist": 4.077430266803843,
        "rouge1": {
            "precision": 0.80247,
            "recall": 0.81481,
            "fmeasure": 0.79434
        },
        "rouge2": {
            "precision": 0.6444,
            "recall": 0.6607,
            "fmeasure": 0.63903
        },
        "rougeL": {
            "precision": 0.78025,
            "recall": 0.79259,
            "fmeasure": 0.77212
        },
        "rougeLsum": {
            "precision": 0.78025,
            "recall": 0.79259,
            "fmeasure": 0.77212
        },
        "bleu": 59.78797,
        "nubia": {
            "semantic_relation": 4.00152,
            "contradiction": 15.09663,
            "irrelevancy": 11.63216,
            "logical_agreement": 73.2712,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.56282,
            "nubia_score": 0.67115
        },
        "bleurt": 0.31871,
        "meteor": 0.4280775082818627,
        "bertscore": {
            "precision": 0.95218,
            "recall": 0.93792,
            "f1": 0.93261
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 1.0
        },
        "nist": 3.5900183150183156,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.78333,
            "fmeasure": 0.76393
        },
        "rouge2": {
            "precision": 0.57692,
            "recall": 0.6039,
            "fmeasure": 0.58796
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.78333,
            "fmeasure": 0.76393
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.78333,
            "fmeasure": 0.76393
        },
        "bleu": 55.3341,
        "nubia": {
            "semantic_relation": 4.85751,
            "contradiction": 0.32016,
            "irrelevancy": 19.29058,
            "logical_agreement": 80.38926,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.55811,
            "nubia_score": 0.8529
        },
        "bleurt": 0.42758,
        "meteor": 0.5008032864424928,
        "bertscore": {
            "precision": 0.92627,
            "recall": 0.94786,
            "f1": 0.92805
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.7037037037037037,
        "vocab_size-1": 19,
        "unique-1": 14,
        "entropy-1": 4.078418520441603,
        "distinct-2": 0.8461538461538461,
        "vocab_size-2": 22,
        "unique-2": 18,
        "entropy-2": 4.392747410448783,
        "cond_entropy-2": 0.34034692776571607,
        "distinct-3": 0.88,
        "vocab_size-3": 22,
        "unique-3": 19,
        "entropy-3": 4.403856189774723,
        "cond_entropy-3": 0.023416471633632495,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8841837197791884,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.03740119765411,
        "cond_entropy-2-nopunct": 0.17625665551219527,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.058813890331201,
        "cond_entropy-3-nopunct": 0.03310859910983795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.4006141213626981,
        "rouge1": {
            "precision": 0.47619,
            "recall": 0.51754,
            "fmeasure": 0.49593
        },
        "rouge2": {
            "precision": 0.15,
            "recall": 0.16374,
            "fmeasure": 0.15655
        },
        "rougeL": {
            "precision": 0.19048,
            "recall": 0.20702,
            "fmeasure": 0.19837
        },
        "rougeLsum": {
            "precision": 0.19048,
            "recall": 0.20702,
            "fmeasure": 0.19837
        },
        "bleu": 5.11929,
        "nubia": {
            "semantic_relation": 3.61361,
            "contradiction": 0.96355,
            "irrelevancy": 95.48386,
            "logical_agreement": 3.55259,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.4508,
            "nubia_score": 0.53515
        },
        "bleurt": -0.22504,
        "meteor": 0.2343339390082976,
        "bertscore": {
            "precision": 0.78991,
            "recall": 0.82817,
            "f1": 0.80859
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 7.788880963698615,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 26,
        "distinct-1": 0.875,
        "vocab_size-1": 42,
        "unique-1": 37,
        "entropy-1": 5.319235677759421,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.0846683733862961,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 6.128258770283412,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.926829268292683,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.211210541203447,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.02195445619392314,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.11864449649861893,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.6086956521739131,
            "3": 0.5294117647058824
        },
        "nist": 3.715228565343708,
        "rouge1": {
            "precision": 0.64613,
            "recall": 0.62102,
            "fmeasure": 0.63175
        },
        "rouge2": {
            "precision": 0.42176,
            "recall": 0.39683,
            "fmeasure": 0.40778
        },
        "rougeL": {
            "precision": 0.55089,
            "recall": 0.52307,
            "fmeasure": 0.53545
        },
        "rougeLsum": {
            "precision": 0.55089,
            "recall": 0.52307,
            "fmeasure": 0.53545
        },
        "bleu": 32.68506,
        "nubia": {
            "semantic_relation": 4.31382,
            "contradiction": 0.62872,
            "irrelevancy": 29.07348,
            "logical_agreement": 70.2978,
            "grammar_ref": 4.61531,
            "grammar_hyp": 4.83964,
            "nubia_score": 0.73684
        },
        "bleurt": 0.34137,
        "meteor": 0.31929712762111284,
        "bertscore": {
            "precision": 0.91149,
            "recall": 0.91859,
            "f1": 0.91472
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 1.9336064017757768,
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.50095,
            "fmeasure": 0.5348
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.13287,
            "fmeasure": 0.14066
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.43478,
            "fmeasure": 0.45946
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.43478,
            "fmeasure": 0.45946
        },
        "bleu": 9.62581,
        "nubia": {
            "semantic_relation": 3.69508,
            "contradiction": 0.08991,
            "irrelevancy": 99.77936,
            "logical_agreement": 0.13073,
            "grammar_ref": 4.57081,
            "grammar_hyp": 4.99904,
            "nubia_score": 0.47629
        },
        "bleurt": -0.17039,
        "meteor": 0.2696894755763373,
        "bertscore": {
            "precision": 0.87208,
            "recall": 0.8738,
            "f1": 0.87294
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9285714285714286
        },
        "nist": 3.9449057454615866,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96552
        },
        "rouge2": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96552
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96552
        },
        "bleu": 81.96501,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.27316,
            "irrelevancy": 0.49108,
            "logical_agreement": 99.23576,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.48414,
            "nubia_score": 0.95923
        },
        "bleurt": 0.80322,
        "meteor": 0.5560383621160697,
        "bertscore": {
            "precision": 0.99479,
            "recall": 0.98655,
            "f1": 0.99065
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.7884615384615384,
        "vocab_size-1": 41,
        "unique-1": 35,
        "entropy-1": 5.19535005455474,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.3532451260624214,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.09114788805819536,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8478260869565217,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.15932527122737,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.426264754702098,
        "cond_entropy-2-nopunct": 0.2923513452070261,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.1043366598147359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35294117647058826,
            "2": 0.0,
            "3": 0.6944444444444444
        },
        "nist": 4.407816492909375,
        "rouge1": {
            "precision": 0.65783,
            "recall": 0.60652,
            "fmeasure": 0.62758
        },
        "rouge2": {
            "precision": 0.4348,
            "recall": 0.37497,
            "fmeasure": 0.40166
        },
        "rougeL": {
            "precision": 0.64549,
            "recall": 0.58535,
            "fmeasure": 0.61033
        },
        "rougeLsum": {
            "precision": 0.64549,
            "recall": 0.58535,
            "fmeasure": 0.61033
        },
        "bleu": 39.87903,
        "nubia": {
            "semantic_relation": 3.88981,
            "contradiction": 29.16345,
            "irrelevancy": 26.34697,
            "logical_agreement": 44.48957,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.36685,
            "nubia_score": 0.64194
        },
        "bleurt": -0.01334,
        "meteor": 0.4001072984845926,
        "bertscore": {
            "precision": 0.92743,
            "recall": 0.90891,
            "f1": 0.91806
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.373660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.2225599568699097,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.229871195093384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.24291000358771486,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6190476190476191
        },
        "nist": 1.5800908557147848,
        "rouge1": {
            "precision": 0.75362,
            "recall": 0.57778,
            "fmeasure": 0.64931
        },
        "rouge2": {
            "precision": 0.60606,
            "recall": 0.46154,
            "fmeasure": 0.52004
        },
        "rougeL": {
            "precision": 0.75362,
            "recall": 0.57778,
            "fmeasure": 0.64931
        },
        "rougeLsum": {
            "precision": 0.75362,
            "recall": 0.57778,
            "fmeasure": 0.64931
        },
        "bleu": 43.6127,
        "nubia": {
            "semantic_relation": 2.57786,
            "contradiction": 99.02412,
            "irrelevancy": 0.82642,
            "logical_agreement": 0.14946,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.64406,
            "nubia_score": 0.20555
        },
        "bleurt": -0.162,
        "meteor": 0.36540509741232674,
        "bertscore": {
            "precision": 0.95876,
            "recall": 0.90826,
            "f1": 0.93283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nist": 3.5579098675041347,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "bleu": 73.48889,
        "nubia": {
            "semantic_relation": 4.61305,
            "contradiction": 1.00975,
            "irrelevancy": 33.27064,
            "logical_agreement": 65.71961,
            "grammar_ref": 4.85143,
            "grammar_hyp": 4.81815,
            "nubia_score": 0.82757
        },
        "bleurt": 0.54425,
        "meteor": 0.9384615384615386,
        "bertscore": {
            "precision": 0.98143,
            "recall": 0.98247,
            "f1": 0.98195
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.19264507794239588,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.22239242133644807,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644807,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.5625
        },
        "nist": 2.0570549704916856,
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.67857,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.61538,
            "fmeasure": 0.65
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.66667,
            "fmeasure": 0.71212
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.66667,
            "fmeasure": 0.71212
        },
        "bleu": 47.70659,
        "nubia": {
            "semantic_relation": 4.15105,
            "contradiction": 1.87661,
            "irrelevancy": 26.93422,
            "logical_agreement": 71.18917,
            "grammar_ref": 4.81259,
            "grammar_hyp": 5.12838,
            "nubia_score": 0.69153
        },
        "bleurt": 0.52276,
        "meteor": 0.40737890910027114,
        "bertscore": {
            "precision": 0.95498,
            "recall": 0.92054,
            "f1": 0.93708
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.090634124990776,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "bleu": 76.11606,
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "bleurt": 0.48581,
        "meteor": 0.5715186082473627,
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8888888888888888
        },
        "nist": 3.5254014736774537,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.79356,
            "fmeasure": 0.794
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.53333,
            "fmeasure": 0.5348
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.73295,
            "fmeasure": 0.73602
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.73295,
            "fmeasure": 0.73602
        },
        "bleu": 64.66228,
        "nubia": {
            "semantic_relation": 4.41246,
            "contradiction": 0.38082,
            "irrelevancy": 0.44962,
            "logical_agreement": 99.16957,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.30528,
            "nubia_score": 0.842
        },
        "bleurt": 0.52909,
        "meteor": 0.5114172322734849,
        "bertscore": {
            "precision": 0.94796,
            "recall": 0.95801,
            "f1": 0.95296
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 71,
        "mean_pred_length": 17.75,
        "std_pred_length": 4.9180788932265,
        "median_pred_length": 19.5,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.49295774647887325,
        "vocab_size-1": 35,
        "unique-1": 21,
        "entropy-1": 4.6896993972589485,
        "distinct-2": 0.746268656716418,
        "vocab_size-2": 50,
        "unique-2": 34,
        "entropy-2": 5.547359526246376,
        "cond_entropy-2": 0.8254241721065773,
        "distinct-3": 0.8095238095238095,
        "vocab_size-3": 51,
        "unique-3": 39,
        "entropy-3": 5.596327542547536,
        "cond_entropy-3": 0.05015720133045305,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 4.9180788932265,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5074626865671642,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.63827742509289,
        "distinct-2-nopunct": 0.746031746031746,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.457361074259227,
        "cond_entropy-2-nopunct": 0.846246300935535,
        "distinct-3-nopunct": 0.8135593220338984,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.509761693429634,
        "cond_entropy-3-nopunct": 0.05375104962740725,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8823529411764706
        },
        "nist": 5.047695870490835,
        "rouge1": {
            "precision": 0.88963,
            "recall": 0.93045,
            "fmeasure": 0.90838
        },
        "rouge2": {
            "precision": 0.81458,
            "recall": 0.85888,
            "fmeasure": 0.83482
        },
        "rougeL": {
            "precision": 0.88963,
            "recall": 0.93045,
            "fmeasure": 0.90838
        },
        "rougeLsum": {
            "precision": 0.88963,
            "recall": 0.93045,
            "fmeasure": 0.90838
        },
        "bleu": 71.78369,
        "nubia": {
            "semantic_relation": 4.05113,
            "contradiction": 44.01511,
            "irrelevancy": 21.28119,
            "logical_agreement": 34.70369,
            "grammar_ref": 3.98368,
            "grammar_hyp": 3.93589,
            "nubia_score": 0.71416
        },
        "bleurt": 0.66236,
        "meteor": 0.5320148735439336,
        "bertscore": {
            "precision": 0.97285,
            "recall": 0.97606,
            "f1": 0.97438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 11.333333333333334,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.7352941176470589,
        "vocab_size-1": 25,
        "unique-1": 17,
        "entropy-1": 4.5358485029514135,
        "distinct-2": 0.8064516129032258,
        "vocab_size-2": 25,
        "unique-2": 19,
        "entropy-2": 4.567099536193328,
        "cond_entropy-2": -0.06875040183120606,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 18,
        "entropy-3": 4.450212064914748,
        "cond_entropy-3": -0.07541281690069972,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 10.333333333333334,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.50258340716107,
        "distinct-2-nopunct": 0.7857142857142857,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.378783493486177,
        "cond_entropy-2-nopunct": -0.0754128169006997,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.243856189774722,
        "cond_entropy-3-nopunct": -0.08349873228287957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.9523809523809523
        },
        "nist": 4.235522679317677,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.9,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.81481,
            "recall": 0.81481,
            "fmeasure": 0.81481
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "bleu": 74.08577,
        "nubia": {
            "semantic_relation": 4.53721,
            "contradiction": 23.85742,
            "irrelevancy": 18.37108,
            "logical_agreement": 57.77149,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.80124,
            "nubia_score": 0.75412
        },
        "bleurt": 0.70601,
        "meteor": 0.5057448171162038,
        "bertscore": {
            "precision": 0.97417,
            "recall": 0.9698,
            "f1": 0.97195
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 34,
        "unique-1": 30,
        "entropy-1": 4.971928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.24178889224043365,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8648648648648649,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.885129041304628,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.26268679417315943,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.08488889758651327,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.9523809523809523
        },
        "nist": 4.4648942784442305,
        "rouge1": {
            "precision": 0.80068,
            "recall": 0.89468,
            "fmeasure": 0.84385
        },
        "rouge2": {
            "precision": 0.62582,
            "recall": 0.72157,
            "fmeasure": 0.66967
        },
        "rougeL": {
            "precision": 0.74659,
            "recall": 0.83449,
            "fmeasure": 0.78696
        },
        "rougeLsum": {
            "precision": 0.74659,
            "recall": 0.83449,
            "fmeasure": 0.78696
        },
        "bleu": 60.19902,
        "nubia": {
            "semantic_relation": 4.20426,
            "contradiction": 47.53005,
            "irrelevancy": 18.71948,
            "logical_agreement": 33.75047,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.27116,
            "nubia_score": 0.81729
        },
        "bleurt": 0.5433,
        "meteor": 0.5078087562806939,
        "bertscore": {
            "precision": 0.94394,
            "recall": 0.96062,
            "f1": 0.94794
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.7918385093778593,
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.74411,
            "fmeasure": 0.71818
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.375,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.63636,
            "recall": 0.77778,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.63636,
            "recall": 0.77778,
            "fmeasure": 0.7
        },
        "bleu": 39.43168,
        "nubia": {
            "semantic_relation": 4.91525,
            "contradiction": 0.60271,
            "irrelevancy": 12.70572,
            "logical_agreement": 86.69157,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.81682,
            "nubia_score": 0.88965
        },
        "bleurt": 0.70191,
        "meteor": 0.42491665810423224,
        "bertscore": {
            "precision": 0.95741,
            "recall": 0.94496,
            "f1": 0.95115
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 0.05784726708778937,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.34119,
            "fmeasure": 0.49223
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.22283,
            "fmeasure": 0.32792
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.29854,
            "fmeasure": 0.4307
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.29854,
            "fmeasure": 0.4307
        },
        "bleu": 15.84584,
        "nubia": {
            "semantic_relation": 3.00313,
            "contradiction": 11.09423,
            "irrelevancy": 2.36107,
            "logical_agreement": 86.54471,
            "grammar_ref": 5.07625,
            "grammar_hyp": 6.20892,
            "nubia_score": 0.19742
        },
        "bleurt": -0.3862,
        "meteor": 0.20130815671219748,
        "bertscore": {
            "precision": 0.9061,
            "recall": 0.82782,
            "f1": 0.86519
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 4.348795462964455,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.85,
            "fmeasure": 0.91892
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.78947,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.65833,
            "fmeasure": 0.66066
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.65833,
            "fmeasure": 0.66066
        },
        "bleu": 70.66452,
        "nubia": {
            "semantic_relation": 4.64731,
            "contradiction": 0.29909,
            "irrelevancy": 23.73556,
            "logical_agreement": 75.96536,
            "grammar_ref": 3.95052,
            "grammar_hyp": 3.93061,
            "nubia_score": 0.93737
        },
        "bleurt": 0.55544,
        "meteor": 0.46578769191877023,
        "bertscore": {
            "precision": 0.96124,
            "recall": 0.95502,
            "f1": 0.94378
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 4.73920135143642,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24144,
            "irrelevancy": 0.5072,
            "logical_agreement": 99.25136,
            "grammar_ref": 5.3705,
            "grammar_hyp": 5.23692,
            "nubia_score": 1.0
        },
        "bleurt": 0.75827,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.636809247747852,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.050098279976059,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 51,
        "unique-2": 50,
        "entropy-2": 5.661978179679557,
        "cond_entropy-2": 0.5162842567866937,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.07381055075326926,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.636809247747852,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.038778718976349,
        "distinct-2-nopunct": 0.9791666666666666,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5432958340544936,
        "cond_entropy-2-nopunct": 0.5596555316752041,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.08007633662931371,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6,
            "3": 0.88
        },
        "nist": 3.740238887146531,
        "rouge1": {
            "precision": 0.66351,
            "recall": 0.83254,
            "fmeasure": 0.72325
        },
        "rouge2": {
            "precision": 0.46794,
            "recall": 0.59234,
            "fmeasure": 0.5081
        },
        "rougeL": {
            "precision": 0.64428,
            "recall": 0.8131,
            "fmeasure": 0.70349
        },
        "rougeLsum": {
            "precision": 0.64428,
            "recall": 0.8131,
            "fmeasure": 0.70349
        },
        "bleu": 45.17789,
        "nubia": {
            "semantic_relation": 4.13287,
            "contradiction": 0.2073,
            "irrelevancy": 74.4166,
            "logical_agreement": 25.3761,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.94851,
            "nubia_score": 0.64858
        },
        "bleurt": 0.51959,
        "meteor": 0.4758353307538239,
        "bertscore": {
            "precision": 0.93116,
            "recall": 0.96339,
            "f1": 0.94597
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.5,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 24,
        "unique-1": 17,
        "entropy-1": 4.4531888161970326,
        "distinct-2": 0.8709677419354839,
        "vocab_size-2": 27,
        "unique-2": 23,
        "entropy-2": 4.696131794257844,
        "cond_entropy-2": 0.21656912665187147,
        "distinct-3": 0.9310344827586207,
        "vocab_size-3": 27,
        "unique-3": 25,
        "entropy-3": 4.720049960644813,
        "cond_entropy-3": 0.04171571922345565,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7419354838709677,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.389364858634393,
        "distinct-2-nopunct": 0.8620689655172413,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.582118926162055,
        "cond_entropy-2-nopunct": 0.19722520213128106,
        "distinct-3-nopunct": 0.9259259259259259,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.606739354015323,
        "cond_entropy-3-nopunct": 0.008017618147007688,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.9047619047619048
        },
        "nist": 3.4950101745022755,
        "rouge1": {
            "precision": 0.72576,
            "recall": 0.89274,
            "fmeasure": 0.7974
        },
        "rouge2": {
            "precision": 0.57807,
            "recall": 0.70574,
            "fmeasure": 0.63357
        },
        "rougeL": {
            "precision": 0.72576,
            "recall": 0.88175,
            "fmeasure": 0.79384
        },
        "rougeLsum": {
            "precision": 0.72576,
            "recall": 0.88175,
            "fmeasure": 0.79384
        },
        "bleu": 50.2993,
        "nubia": {
            "semantic_relation": 4.82062,
            "contradiction": 0.28846,
            "irrelevancy": 21.63373,
            "logical_agreement": 78.0778,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.20499,
            "nubia_score": 0.91212
        },
        "bleurt": 0.60126,
        "meteor": 0.5136409518453566,
        "bertscore": {
            "precision": 0.92848,
            "recall": 0.95552,
            "f1": 0.94169
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 5.0,
        "median_pred_length": 19.0,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 31,
        "entropy-1": 4.912272579176128,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.27629991861437875,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9117647058823529,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.852168723603279,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.16253715874966074,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.5666666666666667
        },
        "nist": 3.5737440300583083,
        "rouge1": {
            "precision": 0.64662,
            "recall": 0.59715,
            "fmeasure": 0.62033
        },
        "rouge2": {
            "precision": 0.35826,
            "recall": 0.32407,
            "fmeasure": 0.33995
        },
        "rougeL": {
            "precision": 0.46241,
            "recall": 0.41776,
            "fmeasure": 0.4386
        },
        "rougeLsum": {
            "precision": 0.46241,
            "recall": 0.41776,
            "fmeasure": 0.4386
        },
        "bleu": 25.41445,
        "nubia": {
            "semantic_relation": 3.31708,
            "contradiction": 0.4938,
            "irrelevancy": 36.65017,
            "logical_agreement": 62.85603,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.74307,
            "nubia_score": 0.45673
        },
        "bleurt": -0.1909,
        "meteor": 0.3015533582155315,
        "bertscore": {
            "precision": 0.86887,
            "recall": 0.84548,
            "f1": 0.85691
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 16.75,
        "std_pred_length": 4.14578098794425,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6119402985074627,
        "vocab_size-1": 41,
        "unique-1": 26,
        "entropy-1": 5.131325153396715,
        "distinct-2": 0.9206349206349206,
        "vocab_size-2": 58,
        "unique-2": 53,
        "entropy-2": 5.818549764769761,
        "cond_entropy-2": 0.6195905819800918,
        "distinct-3": 0.9491525423728814,
        "vocab_size-3": 56,
        "unique-3": 53,
        "entropy-3": 5.780948134107599,
        "cond_entropy-3": -0.02684026396858376,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 4.14578098794425,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6349206349206349,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 5.110149915831811,
        "distinct-2-nopunct": 0.9152542372881356,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.713151523938108,
        "cond_entropy-2-nopunct": 0.6448409306600722,
        "distinct-3-nopunct": 0.9454545454545454,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.672268804433747,
        "cond_entropy-3-nopunct": -0.02855606310990897,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.6842105263157895
        },
        "nist": 3.6434980890504463,
        "rouge1": {
            "precision": 0.63552,
            "recall": 0.69322,
            "fmeasure": 0.6553
        },
        "rouge2": {
            "precision": 0.35888,
            "recall": 0.37002,
            "fmeasure": 0.36001
        },
        "rougeL": {
            "precision": 0.46964,
            "recall": 0.52916,
            "fmeasure": 0.49253
        },
        "rougeLsum": {
            "precision": 0.46964,
            "recall": 0.52916,
            "fmeasure": 0.49253
        },
        "bleu": 28.50684,
        "nubia": {
            "semantic_relation": 4.26319,
            "contradiction": 17.26475,
            "irrelevancy": 22.15749,
            "logical_agreement": 60.57775,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.44893,
            "nubia_score": 0.70274
        },
        "bleurt": 0.37796,
        "meteor": 0.3042519546535127,
        "bertscore": {
            "precision": 0.90664,
            "recall": 0.88891,
            "f1": 0.89741
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728204,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096008,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nist": 3.233146680717854,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.76441,
            "fmeasure": 0.75672
        },
        "rouge2": {
            "precision": 0.61404,
            "recall": 0.62778,
            "fmeasure": 0.62047
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.40769,
            "fmeasure": 0.40359
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.40769,
            "fmeasure": 0.40359
        },
        "bleu": 55.94283,
        "nubia": {
            "semantic_relation": 3.68269,
            "contradiction": 86.912,
            "irrelevancy": 8.25598,
            "logical_agreement": 4.83201,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.74573,
            "nubia_score": 0.53719
        },
        "bleurt": -0.30316,
        "meteor": 0.4582729619433606,
        "bertscore": {
            "precision": 0.91944,
            "recall": 0.93202,
            "f1": 0.92569
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750189,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.165976428503542,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.09175833038780654,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.7692307692307693,
            "3": 0.8888888888888888
        },
        "nist": 4.258182434300473,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.8096,
            "fmeasure": 0.85703
        },
        "rouge2": {
            "precision": 0.68452,
            "recall": 0.58712,
            "fmeasure": 0.6272
        },
        "rougeL": {
            "precision": 0.88462,
            "recall": 0.77071,
            "fmeasure": 0.81846
        },
        "rougeLsum": {
            "precision": 0.88462,
            "recall": 0.77071,
            "fmeasure": 0.81846
        },
        "bleu": 53.82218,
        "nubia": {
            "semantic_relation": 4.62706,
            "contradiction": 4.28402,
            "irrelevancy": 16.72492,
            "logical_agreement": 78.99106,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.53999,
            "nubia_score": 0.8842
        },
        "bleurt": 0.5973,
        "meteor": 0.45503434859954983,
        "bertscore": {
            "precision": 0.9804,
            "recall": 0.97058,
            "f1": 0.97528
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.418295834054489,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.025555977074987156,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.02677875348937534,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.02812389937955851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": 0.029610672108601997,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.8823529411764706
        },
        "nist": 4.092363771372742,
        "rouge1": {
            "precision": 0.79167,
            "recall": 0.85112,
            "fmeasure": 0.82023
        },
        "rouge2": {
            "precision": 0.52174,
            "recall": 0.55267,
            "fmeasure": 0.5367
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.6469,
            "fmeasure": 0.62843
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.6469,
            "fmeasure": 0.62843
        },
        "bleu": 44.04763,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.11583,
            "irrelevancy": 59.82661,
            "logical_agreement": 40.05756,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.91245,
            "nubia_score": 0.99335
        },
        "bleurt": 0.34844,
        "meteor": 0.4356795889802981,
        "bertscore": {
            "precision": 0.94439,
            "recall": 0.94979,
            "f1": 0.94708
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.27047901627861537,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.3068905956085185,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5714285714285714,
            "3": 0.8333333333333334
        },
        "nist": 3.1455265437887974,
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.67521,
            "fmeasure": 0.637
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.27381,
            "fmeasure": 0.24188
        },
        "rougeL": {
            "precision": 0.4375,
            "recall": 0.51453,
            "fmeasure": 0.47238
        },
        "rougeLsum": {
            "precision": 0.4375,
            "recall": 0.51453,
            "fmeasure": 0.47238
        },
        "bleu": 23.2879,
        "nubia": {
            "semantic_relation": 4.25272,
            "contradiction": 0.25858,
            "irrelevancy": 53.345,
            "logical_agreement": 46.39642,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.57443,
            "nubia_score": 0.67714
        },
        "bleurt": -0.03701,
        "meteor": 0.3126545513024239,
        "bertscore": {
            "precision": 0.90724,
            "recall": 0.89867,
            "f1": 0.89682
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.9302325581395349,
        "vocab_size-1": 40,
        "unique-1": 38,
        "entropy-1": 5.26917434767504,
        "distinct-2": 1.0,
        "vocab_size-2": 40,
        "unique-2": 40,
        "entropy-2": 5.3219280948873635,
        "cond_entropy-2": -0.05433665981473582,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.11247472925841272,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.247927513443589,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": -0.11864449649861893,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.12928301694496638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.8695652173913043
        },
        "nist": 4.406075289969193,
        "rouge1": {
            "precision": 0.89744,
            "recall": 0.79133,
            "fmeasure": 0.83525
        },
        "rouge2": {
            "precision": 0.65741,
            "recall": 0.57775,
            "fmeasure": 0.6108
        },
        "rougeL": {
            "precision": 0.79487,
            "recall": 0.692,
            "fmeasure": 0.73507
        },
        "rougeLsum": {
            "precision": 0.79487,
            "recall": 0.692,
            "fmeasure": 0.73507
        },
        "bleu": 50.18383,
        "nubia": {
            "semantic_relation": 4.18407,
            "contradiction": 6.22696,
            "irrelevancy": 60.42707,
            "logical_agreement": 33.34596,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.38426,
            "nubia_score": 0.6118
        },
        "bleurt": 0.33532,
        "meteor": 0.4432621446933424,
        "bertscore": {
            "precision": 0.93673,
            "recall": 0.94899,
            "f1": 0.94255
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.625,
        "vocab_size-1": 15,
        "unique-1": 8,
        "entropy-1": 3.751629167387823,
        "distinct-2": 0.7272727272727273,
        "vocab_size-2": 16,
        "unique-2": 10,
        "entropy-2": 3.9139770731827506,
        "cond_entropy-2": 0.14719639064341358,
        "distinct-3": 0.75,
        "vocab_size-3": 15,
        "unique-3": 10,
        "entropy-3": 3.8219280948873626,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.641249800455478,
        "distinct-2-nopunct": 0.7,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.7219280948873625,
        "cond_entropy-2-nopunct": 0.16249647625006497,
        "distinct-3-nopunct": 0.7222222222222222,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.6143694458867563,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 3.357046268735128,
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.64316,
            "fmeasure": 0.59797
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.35505,
            "fmeasure": 0.34228
        },
        "rougeL": {
            "precision": 0.4697,
            "recall": 0.53846,
            "fmeasure": 0.48565
        },
        "rougeLsum": {
            "precision": 0.4697,
            "recall": 0.53846,
            "fmeasure": 0.48565
        },
        "bleu": 27.09199,
        "nubia": {
            "semantic_relation": 3.64044,
            "contradiction": 0.19681,
            "irrelevancy": 65.91776,
            "logical_agreement": 33.88544,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.66319,
            "nubia_score": 0.61591
        },
        "bleurt": -0.26244,
        "meteor": 0.3788089831293786,
        "bertscore": {
            "precision": 0.86655,
            "recall": 0.89271,
            "f1": 0.87831
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.070656113151927,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.2673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9841837197791885,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.28151981340693205,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "nist": 3.3294792316743127,
        "rouge1": {
            "precision": 0.69697,
            "recall": 0.65657,
            "fmeasure": 0.67589
        },
        "rouge2": {
            "precision": 0.49206,
            "recall": 0.4617,
            "fmeasure": 0.47619
        },
        "rougeL": {
            "precision": 0.69697,
            "recall": 0.65657,
            "fmeasure": 0.67589
        },
        "rougeLsum": {
            "precision": 0.69697,
            "recall": 0.65657,
            "fmeasure": 0.67589
        },
        "bleu": 34.45779,
        "nubia": {
            "semantic_relation": 4.28592,
            "contradiction": 0.19806,
            "irrelevancy": 99.21941,
            "logical_agreement": 0.58253,
            "grammar_ref": 3.8277,
            "grammar_hyp": 4.02862,
            "nubia_score": 0.79664
        },
        "bleurt": -0.02575,
        "meteor": 0.3310876123059347,
        "bertscore": {
            "precision": 0.8812,
            "recall": 0.87461,
            "f1": 0.87789
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.4
        },
        "nist": 2.335907648982945,
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.53072,
            "fmeasure": 0.47671
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.20536,
            "fmeasure": 0.17835
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.51242,
            "fmeasure": 0.44891
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.51242,
            "fmeasure": 0.44891
        },
        "bleu": 11.12466,
        "nubia": {
            "semantic_relation": 3.73133,
            "contradiction": 97.55269,
            "irrelevancy": 1.38839,
            "logical_agreement": 1.05892,
            "grammar_ref": 4.69116,
            "grammar_hyp": 3.87067,
            "nubia_score": 0.64129
        },
        "bleurt": 0.0241,
        "meteor": 0.27481186182452966,
        "bertscore": {
            "precision": 0.86528,
            "recall": 0.87674,
            "f1": 0.87097
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 1.5,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 11,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.932138039759373,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.07482944545381268,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.18057224564182078,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.09306920777188989,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "nist": 3.489786383968293,
        "rouge1": {
            "precision": 0.80159,
            "recall": 0.76852,
            "fmeasure": 0.77696
        },
        "rouge2": {
            "precision": 0.51389,
            "recall": 0.53042,
            "fmeasure": 0.51746
        },
        "rougeL": {
            "precision": 0.80159,
            "recall": 0.76852,
            "fmeasure": 0.77696
        },
        "rougeLsum": {
            "precision": 0.80159,
            "recall": 0.76852,
            "fmeasure": 0.77696
        },
        "bleu": 47.14286,
        "nubia": {
            "semantic_relation": 4.76631,
            "contradiction": 0.53835,
            "irrelevancy": 39.52562,
            "logical_agreement": 59.93603,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.62563,
            "nubia_score": 0.82719
        },
        "bleurt": 0.50262,
        "meteor": 0.4298581917836034,
        "bertscore": {
            "precision": 0.94934,
            "recall": 0.94407,
            "f1": 0.94635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.0,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.78125,
        "vocab_size-1": 25,
        "unique-1": 19,
        "entropy-1": 4.538909765557392,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.2653868456806342,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.028107102122342922,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.418157288156418,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.2952356737826917,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.68
        },
        "nist": 3.6443573819874073,
        "rouge1": {
            "precision": 0.72281,
            "recall": 0.69815,
            "fmeasure": 0.70864
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.39253,
            "fmeasure": 0.39006
        },
        "rougeL": {
            "precision": 0.47281,
            "recall": 0.48677,
            "fmeasure": 0.47867
        },
        "rougeLsum": {
            "precision": 0.47281,
            "recall": 0.48677,
            "fmeasure": 0.47867
        },
        "bleu": 28.36331,
        "nubia": {
            "semantic_relation": 4.45081,
            "contradiction": 2.75027,
            "irrelevancy": 13.72821,
            "logical_agreement": 83.52152,
            "grammar_ref": 4.18803,
            "grammar_hyp": 4.05791,
            "nubia_score": 0.80002
        },
        "bleurt": 0.29425,
        "meteor": 0.3132660200118816,
        "bertscore": {
            "precision": 0.9097,
            "recall": 0.90033,
            "f1": 0.90159
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1699250014423126,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "bleurt": 0.99428,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.7224676484285957,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.81818,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.88889,
            "fmeasure": 0.92063
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.40157,
            "contradiction": 5.65972,
            "irrelevancy": 2.65283,
            "logical_agreement": 91.68745,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.81914,
            "nubia_score": 0.8297
        },
        "bleurt": 0.68577,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.6682958340544896,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 17,
        "unique-2": 12,
        "entropy-2": 4.004886164091841,
        "cond_entropy-2": 0.3290145724615955,
        "distinct-3": 0.8,
        "vocab_size-3": 16,
        "unique-3": 12,
        "entropy-3": 3.9219280948873623,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.5503407095463877,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.821928094887362,
        "cond_entropy-2-nopunct": 0.362496476250065,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.7254805569978675,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.232198344961961,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.8323,
            "fmeasure": 0.864
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.70694,
            "fmeasure": 0.73147
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.8127,
            "fmeasure": 0.84019
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.8127,
            "fmeasure": 0.84019
        },
        "bleu": 74.31012,
        "nubia": {
            "semantic_relation": 4.98476,
            "contradiction": 0.38618,
            "irrelevancy": 0.50592,
            "logical_agreement": 99.10789,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.96933,
            "nubia_score": 0.94361
        },
        "bleurt": 0.61954,
        "meteor": 0.9692307692307691,
        "bertscore": {
            "precision": 0.98829,
            "recall": 0.98829,
            "f1": 0.98829
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.456435556800404,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "bleu": 50.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        },
        "bleurt": 0.93658,
        "meteor": 0.5277006683854432,
        "bertscore": {
            "precision": 0.98601,
            "recall": 0.99497,
            "f1": 0.99047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5263157894736842
        },
        "nist": 1.0243282469011752,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.51449,
            "fmeasure": 0.61925
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.18759,
            "fmeasure": 0.22646
        },
        "rougeL": {
            "precision": 0.71111,
            "recall": 0.47036,
            "fmeasure": 0.56615
        },
        "rougeLsum": {
            "precision": 0.71111,
            "recall": 0.47036,
            "fmeasure": 0.56615
        },
        "bleu": 5.97272,
        "nubia": {
            "semantic_relation": 4.4538,
            "contradiction": 0.92656,
            "irrelevancy": 0.57186,
            "logical_agreement": 98.50158,
            "grammar_ref": 4.34096,
            "grammar_hyp": 5.77858,
            "nubia_score": 0.61183
        },
        "bleurt": 0.29018,
        "meteor": 0.3099706890521834,
        "bertscore": {
            "precision": 0.93295,
            "recall": 0.86415,
            "f1": 0.89723
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 15.25,
        "std_pred_length": 8.437268515343103,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.8524590163934426,
        "vocab_size-1": 52,
        "unique-1": 46,
        "entropy-1": 5.590493280150366,
        "distinct-2": 1.0,
        "vocab_size-2": 57,
        "unique-2": 57,
        "entropy-2": 5.832890014164737,
        "cond_entropy-2": 0.12592263278016208,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.10496955960154235,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 7.46240577829965,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9245283018867925,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.576977058336781,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.614709844115208,
        "cond_entropy-2-nopunct": 0.050054695674458236,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.12285674778553377,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.8,
            "3": 0.7777777777777778
        },
        "nist": 4.463545263500253,
        "rouge1": {
            "precision": 0.86875,
            "recall": 0.78091,
            "fmeasure": 0.81587
        },
        "rouge2": {
            "precision": 0.54464,
            "recall": 0.48807,
            "fmeasure": 0.51059
        },
        "rougeL": {
            "precision": 0.71534,
            "recall": 0.64812,
            "fmeasure": 0.67421
        },
        "rougeLsum": {
            "precision": 0.71534,
            "recall": 0.64812,
            "fmeasure": 0.67421
        },
        "bleu": 46.407,
        "nubia": {
            "semantic_relation": 4.29877,
            "contradiction": 3.67552,
            "irrelevancy": 14.40889,
            "logical_agreement": 81.91559,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.04934,
            "nubia_score": 0.70534
        },
        "bleurt": 0.38448,
        "meteor": 0.4230901754153735,
        "bertscore": {
            "precision": 0.94987,
            "recall": 0.91963,
            "f1": 0.93391
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 8.0,
        "median_pred_length": 18.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.683542362433229,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838574,
        "cond_entropy-2": 0.3148841634647017,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.0249628412503394,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8064516129032258,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.51839711669891,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.24601959865813777,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.14285714285714285,
            "3": 0.8571428571428571
        },
        "nist": 4.630427911448185,
        "rouge1": {
            "precision": 0.78704,
            "recall": 0.80694,
            "fmeasure": 0.79584
        },
        "rouge2": {
            "precision": 0.51838,
            "recall": 0.53414,
            "fmeasure": 0.52546
        },
        "rougeL": {
            "precision": 0.46296,
            "recall": 0.49491,
            "fmeasure": 0.47758
        },
        "rougeLsum": {
            "precision": 0.46296,
            "recall": 0.49491,
            "fmeasure": 0.47758
        },
        "bleu": 50.36366,
        "nubia": {
            "semantic_relation": 4.72891,
            "contradiction": 42.77993,
            "irrelevancy": 1.80896,
            "logical_agreement": 55.41111,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.24913,
            "nubia_score": 0.84062
        },
        "bleurt": 0.32809,
        "meteor": 0.46777396780882435,
        "bertscore": {
            "precision": 0.93514,
            "recall": 0.94218,
            "f1": 0.93864
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 4.027681991198191,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.75,
        "vocab_size-1": 39,
        "unique-1": 29,
        "entropy-1": 5.147461112330258,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.40406604434146326,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.09114788805819536,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.963745994207333,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.3546232576219498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.2857142857142857,
            "3": 0.7297297297297297
        },
        "nist": 4.041200473047874,
        "rouge1": {
            "precision": 0.81225,
            "recall": 0.74779,
            "fmeasure": 0.77354
        },
        "rouge2": {
            "precision": 0.5852,
            "recall": 0.55347,
            "fmeasure": 0.56386
        },
        "rougeL": {
            "precision": 0.71377,
            "recall": 0.6748,
            "fmeasure": 0.68903
        },
        "rougeLsum": {
            "precision": 0.71377,
            "recall": 0.6748,
            "fmeasure": 0.68903
        },
        "bleu": 37.04857,
        "nubia": {
            "semantic_relation": 4.26041,
            "contradiction": 0.58416,
            "irrelevancy": 43.88856,
            "logical_agreement": 55.52729,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.51467,
            "nubia_score": 0.75755
        },
        "bleurt": 0.12641,
        "meteor": 0.3913765864322042,
        "bertscore": {
            "precision": 0.9197,
            "recall": 0.91998,
            "f1": 0.91921
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 9,
        "unique-1": 7,
        "entropy-1": 3.0957952550009344,
        "distinct-2": 0.9,
        "vocab_size-2": 9,
        "unique-2": 8,
        "entropy-2": 3.121928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": 0.07021912877717243,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.9219280948873623,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.94770277922009,
        "cond_entropy-2-nopunct": 0.07021912877717243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": 0.08007499855768763,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5454545454545454
        },
        "nist": 2.093433395617397,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.33333,
            "fmeasure": 0.31579
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.33333,
            "fmeasure": 0.31579
        },
        "bleu": 10.16519,
        "nubia": {
            "semantic_relation": 4.76189,
            "contradiction": 0.81633,
            "irrelevancy": 13.42957,
            "logical_agreement": 85.7541,
            "grammar_ref": 4.80739,
            "grammar_hyp": 5.51482,
            "nubia_score": 0.71571
        },
        "bleurt": -0.19288,
        "meteor": 0.25143722317365347,
        "bertscore": {
            "precision": 0.81629,
            "recall": 0.77992,
            "f1": 0.79769
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 6.0,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.71875,
        "vocab_size-1": 23,
        "unique-1": 15,
        "entropy-1": 4.413909765557392,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 25,
        "unique-2": 20,
        "entropy-2": 4.573557262275185,
        "cond_entropy-2": 0.1320535123473008,
        "distinct-3": 0.8928571428571429,
        "vocab_size-3": 25,
        "unique-3": 22,
        "entropy-3": 4.593069207771891,
        "cond_entropy-3": -0.028107102122342915,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.310443057719025,
        "distinct-2-nopunct": 0.84,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.323856189774723,
        "cond_entropy-2-nopunct": -0.031031312388743956,
        "distinct-3-nopunct": 0.9130434782608695,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.349648912578752,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.7777777777777778
        },
        "nist": 3.5031982390796292,
        "rouge1": {
            "precision": 0.68519,
            "recall": 0.65723,
            "fmeasure": 0.66336
        },
        "rouge2": {
            "precision": 0.46569,
            "recall": 0.43906,
            "fmeasure": 0.44603
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.56512,
            "fmeasure": 0.54985
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.56512,
            "fmeasure": 0.54985
        },
        "bleu": 29.8401,
        "nubia": {
            "semantic_relation": 4.09423,
            "contradiction": 0.57727,
            "irrelevancy": 26.66591,
            "logical_agreement": 72.75682,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.75203,
            "nubia_score": 0.80523
        },
        "bleurt": 0.10374,
        "meteor": 0.39294960913097177,
        "bertscore": {
            "precision": 0.93303,
            "recall": 0.90737,
            "f1": 0.91928
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 4.5,
        "median_pred_length": 19.5,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.958353821370876,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.2147237819603084,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8857142857142857,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.879143374026008,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.1804107236911676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.5,
            "3": 0.92
        },
        "nist": 4.204374830018622,
        "rouge1": {
            "precision": 0.80769,
            "recall": 0.9044,
            "fmeasure": 0.85007
        },
        "rouge2": {
            "precision": 0.69667,
            "recall": 0.77895,
            "fmeasure": 0.73249
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.81078,
            "fmeasure": 0.77736
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.81078,
            "fmeasure": 0.77736
        },
        "bleu": 53.18274,
        "nubia": {
            "semantic_relation": 4.72235,
            "contradiction": 0.20563,
            "irrelevancy": 18.23044,
            "logical_agreement": 81.56394,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.48987,
            "nubia_score": 0.90596
        },
        "bleurt": 0.53272,
        "meteor": 0.4794293500895278,
        "bertscore": {
            "precision": 0.9529,
            "recall": 0.97193,
            "f1": 0.95707
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 2.4209568589429815,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.53846,
            "fmeasure": 0.6087
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.33333,
            "fmeasure": 0.38095
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.53846,
            "fmeasure": 0.6087
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.53846,
            "fmeasure": 0.6087
        },
        "bleu": 25.42762,
        "nubia": {
            "semantic_relation": 4.68401,
            "contradiction": 0.72988,
            "irrelevancy": 6.95348,
            "logical_agreement": 92.31664,
            "grammar_ref": 4.23153,
            "grammar_hyp": 5.30022,
            "nubia_score": 0.75432
        },
        "bleurt": 0.50596,
        "meteor": 0.34478741640586874,
        "bertscore": {
            "precision": 0.92492,
            "recall": 0.88851,
            "f1": 0.90635
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.1034164716336325,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.06711419585853673,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "nist": 3.637832324370452,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.87982,
            "fmeasure": 0.82269
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.63743,
            "fmeasure": 0.59359
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.82807,
            "fmeasure": 0.77429
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.82807,
            "fmeasure": 0.77429
        },
        "bleu": 48.44329,
        "nubia": {
            "semantic_relation": 3.98119,
            "contradiction": 64.86261,
            "irrelevancy": 33.44495,
            "logical_agreement": 1.69244,
            "grammar_ref": 3.98302,
            "grammar_hyp": 4.17383,
            "nubia_score": 0.60358
        },
        "bleurt": 0.06673,
        "meteor": 0.4483652749150881,
        "bertscore": {
            "precision": 0.92833,
            "recall": 0.96118,
            "f1": 0.94312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.262692390839622,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.20859693530755724,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.1365257343456969,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "nist": 2.8263512418816172,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rouge2": {
            "precision": 0.42105,
            "recall": 0.67917,
            "fmeasure": 0.50871
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.79514,
            "fmeasure": 0.60249
        },
        "bleu": 54.89939,
        "nubia": {
            "semantic_relation": 2.94238,
            "contradiction": 0.50941,
            "irrelevancy": 98.89877,
            "logical_agreement": 0.59183,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.5973,
            "nubia_score": 0.37674
        },
        "bleurt": -0.27345,
        "meteor": 0.5119636887618974,
        "bertscore": {
            "precision": 0.90138,
            "recall": 0.95069,
            "f1": 0.92538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.27630381192071,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.76923,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.63333,
            "fmeasure": 0.59091
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.75058,
            "fmeasure": 0.70513
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.75058,
            "fmeasure": 0.70513
        },
        "bleu": 64.00572,
        "nubia": {
            "semantic_relation": 4.80973,
            "contradiction": 0.62133,
            "irrelevancy": 38.0045,
            "logical_agreement": 61.37417,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.76683,
            "nubia_score": 0.85605
        },
        "bleurt": 0.21352,
        "meteor": 0.5205559484776897,
        "bertscore": {
            "precision": 0.928,
            "recall": 0.96387,
            "f1": 0.94559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.73215889136457,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.7777777777777778,
        "vocab_size-3": 14,
        "unique-3": 10,
        "entropy-3": 3.7254805569978675,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.490498678107601,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "bleurt": 0.92254,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.7871439606981383,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.2972690158966973,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.572469458770136,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.27221762763487745,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.026442737724814768,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4666666666666667
        },
        "nist": 1.492843630584539,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.52941,
            "fmeasure": 0.51429
        },
        "rouge2": {
            "precision": 0.29412,
            "recall": 0.3125,
            "fmeasure": 0.30303
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.41176,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.41176,
            "fmeasure": 0.4
        },
        "bleu": 19.22854,
        "nubia": {
            "semantic_relation": 3.02079,
            "contradiction": 95.30918,
            "irrelevancy": 3.92096,
            "logical_agreement": 0.76986,
            "grammar_ref": 3.58521,
            "grammar_hyp": 2.92357,
            "nubia_score": 0.50729
        },
        "bleurt": -0.24382,
        "meteor": 0.22823846709213128,
        "bertscore": {
            "precision": 0.85136,
            "recall": 0.83961,
            "f1": 0.84544
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5833333333333334
        },
        "nist": 2.5388526647472367,
        "rouge1": {
            "precision": 0.73077,
            "recall": 0.51739,
            "fmeasure": 0.59921
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.31494,
            "fmeasure": 0.36878
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.46232,
            "fmeasure": 0.53571
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.46232,
            "fmeasure": 0.53571
        },
        "bleu": 41.22478,
        "nubia": {
            "semantic_relation": 3.47904,
            "contradiction": 2.59208,
            "irrelevancy": 52.92243,
            "logical_agreement": 44.4855,
            "grammar_ref": 5.51157,
            "grammar_hyp": 6.36084,
            "nubia_score": 0.35261
        },
        "bleurt": -0.23902,
        "meteor": 0.3152134825528036,
        "bertscore": {
            "precision": 0.89853,
            "recall": 0.89853,
            "f1": 0.89853
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 15.0,
        "std_pred_length": 7.176350047203662,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.7666666666666667,
        "vocab_size-1": 46,
        "unique-1": 37,
        "entropy-1": 5.335812887167011,
        "distinct-2": 0.9821428571428571,
        "vocab_size-2": 55,
        "unique-2": 54,
        "entropy-2": 5.7716406363433235,
        "cond_entropy-2": 0.39171030866920925,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.06845366545497374,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 6.417748826496718,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7735849056603774,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.171132246934386,
        "distinct-2-nopunct": 0.9795918367346939,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.5738935175845965,
        "cond_entropy-2-nopunct": 0.4482133692321504,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.07841230334108922,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.55,
            "3": 0.7777777777777778
        },
        "nist": 4.406503176435939,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.67599,
            "fmeasure": 0.68285
        },
        "rouge2": {
            "precision": 0.56458,
            "recall": 0.47257,
            "fmeasure": 0.48416
        },
        "rougeL": {
            "precision": 0.7004,
            "recall": 0.5996,
            "fmeasure": 0.62343
        },
        "rougeLsum": {
            "precision": 0.7004,
            "recall": 0.5996,
            "fmeasure": 0.62343
        },
        "bleu": 43.89625,
        "nubia": {
            "semantic_relation": 3.28579,
            "contradiction": 37.17007,
            "irrelevancy": 35.39158,
            "logical_agreement": 27.43836,
            "grammar_ref": 4.43752,
            "grammar_hyp": 5.00601,
            "nubia_score": 0.44862
        },
        "bleurt": -0.1163,
        "meteor": 0.39452477819459486,
        "bertscore": {
            "precision": 0.92101,
            "recall": 0.91776,
            "f1": 0.91585
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "nist": 2.7109047337507373,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "bleu": 53.10725,
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "bleurt": 0.22576,
        "meteor": 0.5033950705050299,
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 8.339997335464536,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.8367346938775511,
        "vocab_size-1": 41,
        "unique-1": 34,
        "entropy-1": 5.272773364479219,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.2296105359018799,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.09729720135491506,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 7.408703590297622,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.169547811769944,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.2092152031067245,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4,
            "3": 0.9032258064516129
        },
        "nist": 4.353628021519031,
        "rouge1": {
            "precision": 0.72475,
            "recall": 0.85028,
            "fmeasure": 0.77879
        },
        "rouge2": {
            "precision": 0.50159,
            "recall": 0.60362,
            "fmeasure": 0.54468
        },
        "rougeL": {
            "precision": 0.66919,
            "recall": 0.7731,
            "fmeasure": 0.71386
        },
        "rougeLsum": {
            "precision": 0.66919,
            "recall": 0.7731,
            "fmeasure": 0.71386
        },
        "bleu": 46.77443,
        "nubia": {
            "semantic_relation": 4.21949,
            "contradiction": 0.89927,
            "irrelevancy": 64.7667,
            "logical_agreement": 34.33404,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.98769,
            "nubia_score": 0.72119
        },
        "bleurt": 0.00741,
        "meteor": 0.4603940145482887,
        "bertscore": {
            "precision": 0.93783,
            "recall": 0.94818,
            "f1": 0.94279
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.5178571428571429,
        "vocab_size-1": 29,
        "unique-1": 16,
        "entropy-1": 4.601125010956985,
        "distinct-2": 0.7169811320754716,
        "vocab_size-2": 38,
        "unique-2": 30,
        "entropy-2": 5.06218059578689,
        "cond_entropy-2": 0.43961789107780136,
        "distinct-3": 0.8,
        "vocab_size-3": 40,
        "unique-3": 35,
        "entropy-3": 5.16836743955838,
        "cond_entropy-3": 0.05103348525479493,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.5294117647058824,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.480386371001473,
        "distinct-2-nopunct": 0.7291666666666666,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.948934896284059,
        "cond_entropy-2-nopunct": 0.38149080467313856,
        "distinct-3-nopunct": 0.8222222222222222,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.069196429470699,
        "cond_entropy-3-nopunct": 0.0569992067677065,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.8,
            "2": 0.3333333333333333,
            "3": 0.8157894736842105
        },
        "nist": 5.09583013106166,
        "rouge1": {
            "precision": 0.80892,
            "recall": 0.77916,
            "fmeasure": 0.78229
        },
        "rouge2": {
            "precision": 0.57837,
            "recall": 0.54916,
            "fmeasure": 0.55503
        },
        "rougeL": {
            "precision": 0.72079,
            "recall": 0.68582,
            "fmeasure": 0.69364
        },
        "rougeLsum": {
            "precision": 0.72079,
            "recall": 0.68582,
            "fmeasure": 0.69364
        },
        "bleu": 53.10166,
        "nubia": {
            "semantic_relation": 4.34284,
            "contradiction": 0.24367,
            "irrelevancy": 46.28909,
            "logical_agreement": 53.46724,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.56879,
            "nubia_score": 0.72989
        },
        "bleurt": 0.02934,
        "meteor": 0.4405601075870003,
        "bertscore": {
            "precision": 0.93389,
            "recall": 0.92221,
            "f1": 0.92759
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.772581706041735,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 34,
        "unique-2": 32,
        "entropy-2": 5.058813890331199,
        "cond_entropy-2": 0.16230056035784188,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.004318760871737879,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.734521664779751,
        "distinct-2-nopunct": 0.9354838709677419,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.825164052322361,
        "cond_entropy-2-nopunct": 0.09253992074943912,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.039698531186414046,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6551724137931034
        },
        "nist": 2.885197900733174,
        "rouge1": {
            "precision": 0.58095,
            "recall": 0.61182,
            "fmeasure": 0.58851
        },
        "rouge2": {
            "precision": 0.24895,
            "recall": 0.25682,
            "fmeasure": 0.24894
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.50468,
            "fmeasure": 0.48381
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.50468,
            "fmeasure": 0.48381
        },
        "bleu": 13.58196,
        "nubia": {
            "semantic_relation": 4.07631,
            "contradiction": 26.16385,
            "irrelevancy": 40.69033,
            "logical_agreement": 33.14582,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.66258,
            "nubia_score": 0.64731
        },
        "bleurt": -0.16885,
        "meteor": 0.3168142580418377,
        "bertscore": {
            "precision": 0.90183,
            "recall": 0.88779,
            "f1": 0.89457
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 5.656854249492381,
        "median_pred_length": 24.0,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.5166666666666667,
        "vocab_size-1": 31,
        "unique-1": 19,
        "entropy-1": 4.585487053689447,
        "distinct-2": 0.7894736842105263,
        "vocab_size-2": 45,
        "unique-2": 37,
        "entropy-2": 5.315174663211633,
        "cond_entropy-2": 0.7816913047109134,
        "distinct-3": 0.8888888888888888,
        "vocab_size-3": 48,
        "unique-3": 42,
        "entropy-3": 5.532665279941245,
        "cond_entropy-3": 0.2277340621529292,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 5.557777333511022,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.5471698113207547,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.524629180774191,
        "distinct-2-nopunct": 0.76,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 5.053660689688188,
        "cond_entropy-2-nopunct": 0.5812289853413335,
        "distinct-3-nopunct": 0.8723404255319149,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.299269702741469,
        "cond_entropy-3-nopunct": 0.26200447050561354,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.5789473684210527
        },
        "nist": 2.9621305539877096,
        "rouge1": {
            "precision": 0.66304,
            "recall": 0.64354,
            "fmeasure": 0.62597
        },
        "rouge2": {
            "precision": 0.5496,
            "recall": 0.50929,
            "fmeasure": 0.50655
        },
        "rougeL": {
            "precision": 0.59058,
            "recall": 0.58063,
            "fmeasure": 0.55863
        },
        "rougeLsum": {
            "precision": 0.59058,
            "recall": 0.58063,
            "fmeasure": 0.55863
        },
        "bleu": 23.11319,
        "nubia": {
            "semantic_relation": 3.63198,
            "contradiction": 13.90738,
            "irrelevancy": 22.05278,
            "logical_agreement": 64.03983,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.27579,
            "nubia_score": 0.5146
        },
        "bleurt": -0.22668,
        "meteor": 0.3601137301736501,
        "bertscore": {
            "precision": 0.882,
            "recall": 0.86892,
            "f1": 0.87403
        }
    },
    "web_nlg_en_challenge_test_scramble": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.52085,
        "msttr-100_nopunct": 0.53357,
        "total_length": 9423,
        "mean_pred_length": 18.846,
        "std_pred_length": 6.542651144604915,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.13201740422370795,
        "vocab_size-1": 1244,
        "unique-1": 490,
        "entropy-1": 8.033755785533213,
        "distinct-2": 0.38731368373865294,
        "vocab_size-2": 3456,
        "unique-2": 2083,
        "entropy-2": 10.863304991325357,
        "cond_entropy-2": 2.766971916180401,
        "distinct-3": 0.5925442241481658,
        "vocab_size-3": 4991,
        "unique-3": 3681,
        "entropy-3": 11.787408146373044,
        "cond_entropy-3": 1.0038478389331156,
        "total_length-nopunct": 8494,
        "mean_pred_length-nopunct": 16.988,
        "std_pred_length-nopunct": 6.1530363236372985,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.14551448080998353,
        "vocab_size-1-nopunct": 1236,
        "unique-1-nopunct": 489,
        "entropy-1-nopunct": 8.230058803533082,
        "distinct-2-nopunct": 0.39604703527645735,
        "vocab_size-2-nopunct": 3166,
        "unique-2-nopunct": 1947,
        "entropy-2-nopunct": 10.746333996685829,
        "cond_entropy-2-nopunct": 2.6709877092303187,
        "distinct-3-nopunct": 0.5991459834534294,
        "vocab_size-3-nopunct": 4490,
        "unique-3-nopunct": 3369,
        "entropy-3-nopunct": 11.62697908394167,
        "cond_entropy-3-nopunct": 0.9538894981875957,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.18719114449495947,
            "2": 0.508992195453003,
            "3": 0.7384068810770381,
            "4": 0.4,
            "5": 0.7777777777777778
        },
        "nist": 6.7259663850962195,
        "rouge1": {
            "precision": 0.77467,
            "recall": 0.67205,
            "fmeasure": 0.70753
        },
        "rouge2": {
            "precision": 0.51988,
            "recall": 0.44865,
            "fmeasure": 0.47238
        },
        "rougeL": {
            "precision": 0.6444,
            "recall": 0.55965,
            "fmeasure": 0.5888
        },
        "rougeLsum": {
            "precision": 0.6444,
            "recall": 0.55965,
            "fmeasure": 0.5888
        },
        "bleu": 39.64056,
        "nubia": {
            "semantic_relation": 4.10867,
            "contradiction": 9.06014,
            "irrelevancy": 9.61439,
            "logical_agreement": 81.32547,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.85396,
            "nubia_score": 0.66371
        },
        "bleurt": 0.03689,
        "meteor": 0.32481083723461057,
        "bertscore": {
            "precision": 0.92015,
            "recall": 0.89868,
            "f1": 0.90778
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.8841837197791884,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548846,
        "cond_entropy-2": 0.281519813406932,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.6835423624332306,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.3148841634647016,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": 0.037537158749660585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.9090909090909091
        },
        "nist": 4.381495975445594,
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.74603,
            "fmeasure": 0.80342
        },
        "rouge2": {
            "precision": 0.54902,
            "recall": 0.62821,
            "fmeasure": 0.58018
        },
        "rougeL": {
            "precision": 0.64815,
            "recall": 0.55556,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.64815,
            "recall": 0.55556,
            "fmeasure": 0.59829
        },
        "bleu": 48.19625,
        "nubia": {
            "semantic_relation": 4.24676,
            "contradiction": 0.2576,
            "irrelevancy": 33.59835,
            "logical_agreement": 66.14405,
            "grammar_ref": 3.68983,
            "grammar_hyp": 4.33036,
            "nubia_score": 0.73508
        },
        "bleurt": 0.04146,
        "meteor": 0.4584754194144495,
        "bertscore": {
            "precision": 0.94249,
            "recall": 0.9541,
            "f1": 0.93093
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 1.3413739496895452,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.41751
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.09091,
            "fmeasure": 0.1
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.25,
            "fmeasure": 0.27273
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.25,
            "fmeasure": 0.27273
        },
        "bleu": 9.9801,
        "nubia": {
            "semantic_relation": 3.45742,
            "contradiction": 0.12426,
            "irrelevancy": 99.66738,
            "logical_agreement": 0.20836,
            "grammar_ref": 5.08958,
            "grammar_hyp": 4.87649,
            "nubia_score": 0.54041
        },
        "bleurt": -0.29531,
        "meteor": 0.18662887241015477,
        "bertscore": {
            "precision": 0.78812,
            "recall": 0.86002,
            "f1": 0.8225
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nist": 2.709332696076892,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.65556,
            "fmeasure": 0.62778
        },
        "rouge2": {
            "precision": 0.43137,
            "recall": 0.45455,
            "fmeasure": 0.43783
        },
        "rougeL": {
            "precision": 0.57407,
            "recall": 0.61111,
            "fmeasure": 0.58737
        },
        "rougeLsum": {
            "precision": 0.57407,
            "recall": 0.61111,
            "fmeasure": 0.58737
        },
        "bleu": 37.42032,
        "nubia": {
            "semantic_relation": 3.07327,
            "contradiction": 12.76266,
            "irrelevancy": 86.97515,
            "logical_agreement": 0.26219,
            "grammar_ref": 4.44297,
            "grammar_hyp": 4.59785,
            "nubia_score": 0.30182
        },
        "bleurt": -0.19537,
        "meteor": 0.3555288730365827,
        "bertscore": {
            "precision": 0.83986,
            "recall": 0.90754,
            "f1": 0.87239
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 2.0,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 12,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.04089198233393863,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.10742500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.42857142857142855
        },
        "nist": 1.4008414227119623,
        "rouge1": {
            "precision": 0.74675,
            "recall": 0.60778,
            "fmeasure": 0.61201
        },
        "rouge2": {
            "precision": 0.28889,
            "recall": 0.26521,
            "fmeasure": 0.25097
        },
        "rougeL": {
            "precision": 0.56061,
            "recall": 0.44563,
            "fmeasure": 0.45333
        },
        "rougeLsum": {
            "precision": 0.56061,
            "recall": 0.44563,
            "fmeasure": 0.45333
        },
        "bleu": 6.35145,
        "nubia": {
            "semantic_relation": 4.09147,
            "contradiction": 1.35593,
            "irrelevancy": 1.20229,
            "logical_agreement": 97.44179,
            "grammar_ref": 5.29605,
            "grammar_hyp": 5.25467,
            "nubia_score": 0.66655
        },
        "bleurt": -0.03979,
        "meteor": 0.25499924191020684,
        "bertscore": {
            "precision": 0.89353,
            "recall": 0.84001,
            "f1": 0.86478
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.098214829261011,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2797,
            "irrelevancy": 0.5863,
            "logical_agreement": 99.13399,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.67996,
            "nubia_score": 0.98883
        },
        "bleurt": 0.94053,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228495,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5333333333333333
        },
        "nist": 2.4563004050304786,
        "rouge1": {
            "precision": 0.76471,
            "recall": 0.59325,
            "fmeasure": 0.66752
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.33333,
            "fmeasure": 0.37037
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.31944,
            "fmeasure": 0.35944
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.31944,
            "fmeasure": 0.35944
        },
        "bleu": 25.773,
        "nubia": {
            "semantic_relation": 3.46492,
            "contradiction": 0.30895,
            "irrelevancy": 62.82113,
            "logical_agreement": 36.86992,
            "grammar_ref": 6.02354,
            "grammar_hyp": 6.01654,
            "nubia_score": 0.46249
        },
        "bleurt": -0.22039,
        "meteor": 0.33249146840880134,
        "bertscore": {
            "precision": 0.89482,
            "recall": 0.8661,
            "f1": 0.87647
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 18,
        "entropy-1": 4.3565583354166755,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 24,
        "unique-2": 22,
        "entropy-2": 4.546593564294937,
        "cond_entropy-2": 0.20535558144544921,
        "distinct-3": 0.96,
        "vocab_size-3": 24,
        "unique-3": 23,
        "entropy-3": 4.5638561897747225,
        "cond_entropy-3": 0.023416471633632502,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.220175521464345,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.23229021629948574,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": 0.026778753489375348,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5833333333333334,
            "3": 0.6
        },
        "nist": 3.7039493622731188,
        "rouge1": {
            "precision": 0.64,
            "recall": 0.60779,
            "fmeasure": 0.62343
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.35538,
            "fmeasure": 0.3649
        },
        "rougeL": {
            "precision": 0.52,
            "recall": 0.49383,
            "fmeasure": 0.50654
        },
        "rougeLsum": {
            "precision": 0.52,
            "recall": 0.49383,
            "fmeasure": 0.50654
        },
        "bleu": 34.98215,
        "nubia": {
            "semantic_relation": 3.47434,
            "contradiction": 12.09962,
            "irrelevancy": 31.84613,
            "logical_agreement": 56.05425,
            "grammar_ref": 4.65446,
            "grammar_hyp": 3.7,
            "nubia_score": 0.46635
        },
        "bleurt": -0.38915,
        "meteor": 0.3081275287800382,
        "bertscore": {
            "precision": 0.91944,
            "recall": 0.90845,
            "f1": 0.91392
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.021369002496408333,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.8
        },
        "nist": 2.8808871430394167,
        "rouge1": {
            "precision": 0.60526,
            "recall": 0.85165,
            "fmeasure": 0.70739
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.4391,
            "fmeasure": 0.36022
        },
        "rougeL": {
            "precision": 0.47368,
            "recall": 0.66758,
            "fmeasure": 0.55398
        },
        "rougeLsum": {
            "precision": 0.47368,
            "recall": 0.66758,
            "fmeasure": 0.55398
        },
        "bleu": 31.82085,
        "nubia": {
            "semantic_relation": 4.49796,
            "contradiction": 60.73793,
            "irrelevancy": 38.64614,
            "logical_agreement": 0.61593,
            "grammar_ref": 4.1674,
            "grammar_hyp": 4.2677,
            "nubia_score": 0.74385
        },
        "bleurt": 0.34519,
        "meteor": 0.3969471920061496,
        "bertscore": {
            "precision": 0.91582,
            "recall": 0.95622,
            "f1": 0.93559
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.46967048737186,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.25,
            "3": 0.7368421052631579
        },
        "nist": 3.613495755391166,
        "rouge1": {
            "precision": 0.76515,
            "recall": 0.69658,
            "fmeasure": 0.72911
        },
        "rouge2": {
            "precision": 0.51818,
            "recall": 0.46843,
            "fmeasure": 0.49194
        },
        "rougeL": {
            "precision": 0.59848,
            "recall": 0.54701,
            "fmeasure": 0.5715
        },
        "rougeLsum": {
            "precision": 0.59848,
            "recall": 0.54701,
            "fmeasure": 0.5715
        },
        "bleu": 40.92261,
        "nubia": {
            "semantic_relation": 4.02495,
            "contradiction": 0.2471,
            "irrelevancy": 31.74955,
            "logical_agreement": 68.00335,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.4666,
            "nubia_score": 0.73259
        },
        "bleurt": 0.22276,
        "meteor": 0.3822894587174407,
        "bertscore": {
            "precision": 0.91042,
            "recall": 0.89935,
            "f1": 0.90409
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.4182958340544896,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.03462179117476819,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 2.091228125420675,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.27273,
            "fmeasure": 0.3
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.41667,
            "fmeasure": 0.45455
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.41667,
            "fmeasure": 0.45455
        },
        "bleu": 17.24222,
        "nubia": {
            "semantic_relation": 4.07226,
            "contradiction": 1.54286,
            "irrelevancy": 96.21535,
            "logical_agreement": 2.24179,
            "grammar_ref": 5.64121,
            "grammar_hyp": 6.18235,
            "nubia_score": 0.53411
        },
        "bleurt": 0.01954,
        "meteor": 0.33948671213218107,
        "bertscore": {
            "precision": 0.8983,
            "recall": 0.87812,
            "f1": 0.8881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 3.6817870057290873,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.7454545454545455,
        "vocab_size-1": 41,
        "unique-1": 32,
        "entropy-1": 5.194729486133923,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 48,
        "unique-2": 44,
        "entropy-2": 5.546593564294942,
        "cond_entropy-2": 0.34724659127970986,
        "distinct-3": 0.9591836734693877,
        "vocab_size-3": 47,
        "unique-3": 45,
        "entropy-3": 5.533077191053984,
        "cond_entropy-3": -0.004097220964659235,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 5.312459150169742,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.74,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.038562939644918,
        "distinct-2-nopunct": 0.9148936170212766,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.384376085720193,
        "cond_entropy-2-nopunct": 0.3844488854452617,
        "distinct-3-nopunct": 0.9545454545454546,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.368522527728204,
        "cond_entropy-3-nopunct": -0.004248142131249438,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.5,
            "3": 0.5277777777777778
        },
        "nist": 3.4235601342630084,
        "rouge1": {
            "precision": 0.59382,
            "recall": 0.61667,
            "fmeasure": 0.60243
        },
        "rouge2": {
            "precision": 0.36932,
            "recall": 0.39235,
            "fmeasure": 0.37872
        },
        "rougeL": {
            "precision": 0.56484,
            "recall": 0.58333,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.56484,
            "recall": 0.58333,
            "fmeasure": 0.57143
        },
        "bleu": 30.32878,
        "nubia": {
            "semantic_relation": 3.7785,
            "contradiction": 26.72298,
            "irrelevancy": 16.4939,
            "logical_agreement": 56.78312,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.24151,
            "nubia_score": 0.62497
        },
        "bleurt": -0.00229,
        "meteor": 0.26619031479397093,
        "bertscore": {
            "precision": 0.89694,
            "recall": 0.87838,
            "f1": 0.88745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nist": 3.898626692302749,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.371,
            "irrelevancy": 0.46802,
            "logical_agreement": 99.16099,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.2666,
            "nubia_score": 1.0
        },
        "bleurt": 0.90186,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 6.0,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.506890595608519,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.2576071835919427,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.450212064914748,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.2777001806988724,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 1.0,
            "3": 0.76
        },
        "nist": 4.1195146499869955,
        "rouge1": {
            "precision": 0.8875,
            "recall": 0.81773,
            "fmeasure": 0.83399
        },
        "rouge2": {
            "precision": 0.81454,
            "recall": 0.76499,
            "fmeasure": 0.76876
        },
        "rougeL": {
            "precision": 0.8375,
            "recall": 0.78243,
            "fmeasure": 0.7926
        },
        "rougeLsum": {
            "precision": 0.8375,
            "recall": 0.78243,
            "fmeasure": 0.7926
        },
        "bleu": 57.34546,
        "nubia": {
            "semantic_relation": 4.25407,
            "contradiction": 0.11524,
            "irrelevancy": 75.11071,
            "logical_agreement": 24.77405,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.46368,
            "nubia_score": 0.83864
        },
        "bleurt": 0.3985,
        "meteor": 0.40242437641836204,
        "bertscore": {
            "precision": 0.98166,
            "recall": 0.94145,
            "f1": 0.96068
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.031262576450960096,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 3.4021133954141405,
        "rouge1": {
            "precision": 0.73684,
            "recall": 0.82895,
            "fmeasure": 0.77895
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.62963,
            "fmeasure": 0.58923
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.65132,
            "fmeasure": 0.61203
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.65132,
            "fmeasure": 0.61203
        },
        "bleu": 48.78595,
        "nubia": {
            "semantic_relation": 4.64486,
            "contradiction": 0.22923,
            "irrelevancy": 0.86813,
            "logical_agreement": 98.90263,
            "grammar_ref": 4.542,
            "grammar_hyp": 4.19153,
            "nubia_score": 0.92237
        },
        "bleurt": 0.36708,
        "meteor": 0.4809580877082117,
        "bertscore": {
            "precision": 0.94069,
            "recall": 0.93635,
            "f1": 0.93548
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "nist": 4.357019244978275,
        "rouge1": {
            "precision": 0.75556,
            "recall": 0.64327,
            "fmeasure": 0.69281
        },
        "rouge2": {
            "precision": 0.30952,
            "recall": 0.29365,
            "fmeasure": 0.3006
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.67778,
            "fmeasure": 0.63111
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.67778,
            "fmeasure": 0.63111
        },
        "bleu": 29.28298,
        "nubia": {
            "semantic_relation": 4.29077,
            "contradiction": 0.87219,
            "irrelevancy": 40.27834,
            "logical_agreement": 58.84946,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.85516,
            "nubia_score": 0.57276
        },
        "bleurt": 0.03514,
        "meteor": 0.35913292243528394,
        "bertscore": {
            "precision": 0.93442,
            "recall": 0.9308,
            "f1": 0.93261
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nist": 2.6903293061000233,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.71429,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.46154,
            "fmeasure": 0.48
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.42857,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.42857,
            "fmeasure": 0.44444
        },
        "bleu": 26.17221,
        "nubia": {
            "semantic_relation": 4.51418,
            "contradiction": 0.12864,
            "irrelevancy": 99.16354,
            "logical_agreement": 0.70782,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.69313,
            "nubia_score": 0.70899
        },
        "bleurt": 0.22278,
        "meteor": 0.4086744480648821,
        "bertscore": {
            "precision": 0.94101,
            "recall": 0.92102,
            "f1": 0.93091
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5
        },
        "nist": 1.7923412991989904,
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.56923,
            "fmeasure": 0.55273
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.29167,
            "fmeasure": 0.28043
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.38077,
            "fmeasure": 0.37636
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.38077,
            "fmeasure": 0.37636
        },
        "bleu": 9.00747,
        "nubia": {
            "semantic_relation": 2.46896,
            "contradiction": 97.62646,
            "irrelevancy": 1.80288,
            "logical_agreement": 0.57066,
            "grammar_ref": 4.19915,
            "grammar_hyp": 4.93347,
            "nubia_score": 0.19871
        },
        "bleurt": -0.73765,
        "meteor": 0.248679663759582,
        "bertscore": {
            "precision": 0.90017,
            "recall": 0.86279,
            "f1": 0.88108
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.04281761336971672,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.06666666666666667,
            "2": 0.0,
            "3": 0.6153846153846154
        },
        "nist": 1.1910889565224405,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.6869,
            "fmeasure": 0.74897
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.59487,
            "fmeasure": 0.62799
        },
        "rougeL": {
            "precision": 0.77273,
            "recall": 0.63571,
            "fmeasure": 0.68031
        },
        "rougeLsum": {
            "precision": 0.77273,
            "recall": 0.63571,
            "fmeasure": 0.68031
        },
        "bleu": 45.42774,
        "nubia": {
            "semantic_relation": 4.09391,
            "contradiction": 32.11984,
            "irrelevancy": 4.34575,
            "logical_agreement": 63.53441,
            "grammar_ref": 4.54027,
            "grammar_hyp": 4.54583,
            "nubia_score": 0.6551
        },
        "bleurt": 0.32622,
        "meteor": 0.3417132168375659,
        "bertscore": {
            "precision": 0.95571,
            "recall": 0.91545,
            "f1": 0.93386
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 86,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 5.467073155618908,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.7093023255813954,
        "vocab_size-1": 61,
        "unique-1": 47,
        "entropy-1": 5.702257051138257,
        "distinct-2": 0.9,
        "vocab_size-2": 72,
        "unique-2": 64,
        "entropy-2": 6.121928094887356,
        "cond_entropy-2": 0.28009943396230763,
        "distinct-3": 0.9324324324324325,
        "vocab_size-3": 69,
        "unique-3": 64,
        "entropy-3": 6.07431823049382,
        "cond_entropy-3": -0.03139364817733154,
        "total_length-nopunct": 74,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 4.346134936801766,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7702702702702703,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.685738669653772,
        "distinct-2-nopunct": 0.8970588235294118,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.881580488309169,
        "cond_entropy-2-nopunct": 0.2420519388884996,
        "distinct-3-nopunct": 0.9354838709677419,
        "vocab_size-3-nopunct": 58,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.825164052322357,
        "cond_entropy-3-nopunct": -0.036492337315077006,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35,
            "2": 0.3,
            "3": 0.6774193548387096
        },
        "nist": 4.5344688719504,
        "rouge1": {
            "precision": 0.79471,
            "recall": 0.6891,
            "fmeasure": 0.72113
        },
        "rouge2": {
            "precision": 0.55821,
            "recall": 0.46681,
            "fmeasure": 0.49789
        },
        "rougeL": {
            "precision": 0.69351,
            "recall": 0.60318,
            "fmeasure": 0.63165
        },
        "rougeLsum": {
            "precision": 0.69351,
            "recall": 0.60318,
            "fmeasure": 0.63165
        },
        "bleu": 43.59905,
        "nubia": {
            "semantic_relation": 4.3321,
            "contradiction": 3.82366,
            "irrelevancy": 26.59403,
            "logical_agreement": 69.58231,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.63564,
            "nubia_score": 0.78084
        },
        "bleurt": 0.35234,
        "meteor": 0.39870070854729367,
        "bertscore": {
            "precision": 0.93283,
            "recall": 0.91529,
            "f1": 0.92309
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 10.75,
        "std_pred_length": 3.344772040064913,
        "median_pred_length": 10.5,
        "min_pred_length": 7,
        "max_pred_length": 15,
        "distinct-1": 0.7906976744186046,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.9260374290200755,
        "distinct-2": 0.9743589743589743,
        "vocab_size-2": 38,
        "unique-2": 37,
        "entropy-2": 5.234120167580196,
        "cond_entropy-2": 0.15425990016853333,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.09897634477442474,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 9.75,
        "std_pred_length-nopunct": 3.344772040064913,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.9389977315718125,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.072140159802107,
        "cond_entropy-2-nopunct": 0.17273151249205912,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.11057057752583337,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.1111111111111111,
            "3": 0.8695652173913043
        },
        "nist": 2.4378686276452606,
        "rouge1": {
            "precision": 0.61859,
            "recall": 0.63682,
            "fmeasure": 0.58554
        },
        "rouge2": {
            "precision": 0.28739,
            "recall": 0.37302,
            "fmeasure": 0.31721
        },
        "rougeL": {
            "precision": 0.50252,
            "recall": 0.56275,
            "fmeasure": 0.50388
        },
        "rougeLsum": {
            "precision": 0.50252,
            "recall": 0.56275,
            "fmeasure": 0.50388
        },
        "bleu": 21.04742,
        "nubia": {
            "semantic_relation": 3.60375,
            "contradiction": 0.84851,
            "irrelevancy": 33.06112,
            "logical_agreement": 66.09037,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.40944,
            "nubia_score": 0.61043
        },
        "bleurt": 0.07628,
        "meteor": 0.23098390923101625,
        "bertscore": {
            "precision": 0.89146,
            "recall": 0.86306,
            "f1": 0.87088
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.8936441277848375,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rouge2": {
            "precision": 0.92593,
            "recall": 0.75926,
            "fmeasure": 0.83069
        },
        "rougeL": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "rougeLsum": {
            "precision": 0.93333,
            "recall": 0.85641,
            "fmeasure": 0.88986
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.57319,
            "contradiction": 0.20028,
            "irrelevancy": 0.43256,
            "logical_agreement": 99.36716,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.18715,
            "nubia_score": 0.88792
        },
        "bleurt": 0.55466,
        "meteor": 0.9652173913043478,
        "bertscore": {
            "precision": 0.98107,
            "recall": 0.98047,
            "f1": 0.98047
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.75
        },
        "nist": 3.368551600409571,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "rouge2": {
            "precision": 0.78571,
            "recall": 0.61111,
            "fmeasure": 0.6875
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.68421,
            "fmeasure": 0.76471
        },
        "bleu": 62.22142,
        "nubia": {
            "semantic_relation": 3.97227,
            "contradiction": 1.50172,
            "irrelevancy": 4.39492,
            "logical_agreement": 94.10337,
            "grammar_ref": 4.21408,
            "grammar_hyp": 5.60097,
            "nubia_score": 0.50716
        },
        "bleurt": 0.38877,
        "meteor": 0.3993500396692958,
        "bertscore": {
            "precision": 0.95507,
            "recall": 0.90862,
            "f1": 0.93127
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.17632144674685427,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.11251249881411754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7916666666666666
        },
        "nist": 3.9399051068477173,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.80769,
            "fmeasure": 0.84
        },
        "rouge2": {
            "precision": 0.69565,
            "recall": 0.64,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.79167,
            "recall": 0.73077,
            "fmeasure": 0.76
        },
        "rougeLsum": {
            "precision": 0.79167,
            "recall": 0.73077,
            "fmeasure": 0.76
        },
        "bleu": 55.10099,
        "nubia": {
            "semantic_relation": 3.98103,
            "contradiction": 22.03217,
            "irrelevancy": 2.83056,
            "logical_agreement": 75.13728,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.50438,
            "nubia_score": 0.62119
        },
        "bleurt": 0.45921,
        "meteor": 0.46014046071051723,
        "bertscore": {
            "precision": 0.96986,
            "recall": 0.94737,
            "f1": 0.95849
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.768492245572466,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.373,
            "irrelevancy": 0.51156,
            "logical_agreement": 99.11544,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.22425,
            "nubia_score": 0.9763
        },
        "bleurt": 0.97268,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 96,
        "mean_pred_length": 19.2,
        "std_pred_length": 8.588364221433556,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 35,
        "distinct-1": 0.6770833333333334,
        "vocab_size-1": 65,
        "unique-1": 48,
        "entropy-1": 5.780594990837059,
        "distinct-2": 0.9010989010989011,
        "vocab_size-2": 82,
        "unique-2": 74,
        "entropy-2": 6.301696975339762,
        "cond_entropy-2": 0.4663969026282009,
        "distinct-3": 0.9418604651162791,
        "vocab_size-3": 81,
        "unique-3": 76,
        "entropy-3": 6.309985684934658,
        "cond_entropy-3": 0.020271131970418885,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 4.841487374764082,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 48,
        "entropy-1-nopunct": 5.731308873363873,
        "distinct-2-nopunct": 0.9041095890410958,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 59,
        "entropy-2-nopunct": 5.998043736962218,
        "cond_entropy-2-nopunct": 0.2635905721941193,
        "distinct-3-nopunct": 0.9264705882352942,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 58,
        "entropy-3-nopunct": 5.940404017720932,
        "cond_entropy-3-nopunct": -0.05824407057085417,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.47058823529411764,
            "3": 0.8
        },
        "nist": 4.072458642091493,
        "rouge1": {
            "precision": 0.71185,
            "recall": 0.69676,
            "fmeasure": 0.68803
        },
        "rouge2": {
            "precision": 0.57673,
            "recall": 0.55847,
            "fmeasure": 0.55377
        },
        "rougeL": {
            "precision": 0.64296,
            "recall": 0.619,
            "fmeasure": 0.6162
        },
        "rougeLsum": {
            "precision": 0.64296,
            "recall": 0.619,
            "fmeasure": 0.6162
        },
        "bleu": 50.88848,
        "nubia": {
            "semantic_relation": 3.95405,
            "contradiction": 18.79536,
            "irrelevancy": 28.5379,
            "logical_agreement": 52.66674,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.84127,
            "nubia_score": 0.63947
        },
        "bleurt": 0.04503,
        "meteor": 0.3821643631650961,
        "bertscore": {
            "precision": 0.92066,
            "recall": 0.92225,
            "f1": 0.92078
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548847,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.7777777777777778
        },
        "nist": 2.045883536231242,
        "rouge1": {
            "precision": 0.45,
            "recall": 0.51084,
            "fmeasure": 0.47817
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.18056,
            "fmeasure": 0.16834
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.45408,
            "fmeasure": 0.42504
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.45408,
            "fmeasure": 0.42504
        },
        "bleu": 10.97576,
        "nubia": {
            "semantic_relation": 2.56188,
            "contradiction": 2.96447,
            "irrelevancy": 86.07168,
            "logical_agreement": 10.96386,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.75458,
            "nubia_score": 0.33576
        },
        "bleurt": -0.17571,
        "meteor": 0.25971332609944275,
        "bertscore": {
            "precision": 0.84502,
            "recall": 0.85229,
            "f1": 0.84551
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.1523912776298655,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.25454711376829503,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.070656113151927,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.2673550472167754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.9166666666666666
        },
        "nist": 3.8555915905626184,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.75,
            "fmeasure": 0.73171
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.5614,
            "fmeasure": 0.54701
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.62105,
            "fmeasure": 0.59512
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.62105,
            "fmeasure": 0.59512
        },
        "bleu": 45.73344,
        "nubia": {
            "semantic_relation": 3.38304,
            "contradiction": 1.5531,
            "irrelevancy": 92.91289,
            "logical_agreement": 5.53402,
            "grammar_ref": 5.26752,
            "grammar_hyp": 5.38355,
            "nubia_score": 0.47797
        },
        "bleurt": -0.36704,
        "meteor": 0.4202146397894553,
        "bertscore": {
            "precision": 0.88094,
            "recall": 0.90636,
            "f1": 0.89347
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 0.5,
        "median_pred_length": 10.5,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.14438990933517493,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.16992500144231232,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5294117647058824
        },
        "nist": 2.1689060048273294,
        "rouge1": {
            "precision": 0.59583,
            "recall": 0.42717,
            "fmeasure": 0.49537
        },
        "rouge2": {
            "precision": 0.29365,
            "recall": 0.17593,
            "fmeasure": 0.21855
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.37717,
            "fmeasure": 0.43981
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.37717,
            "fmeasure": 0.43981
        },
        "bleu": 16.38949,
        "nubia": {
            "semantic_relation": 4.01234,
            "contradiction": 36.09406,
            "irrelevancy": 4.78119,
            "logical_agreement": 59.12474,
            "grammar_ref": 4.56502,
            "grammar_hyp": 6.07998,
            "nubia_score": 0.58484
        },
        "bleurt": 0.26563,
        "meteor": 0.27129030241273716,
        "bertscore": {
            "precision": 0.89333,
            "recall": 0.88533,
            "f1": 0.88604
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.5454545454545454
        },
        "nist": 2.784037697631196,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.58333,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.27273,
            "fmeasure": 0.31579
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "bleu": 35.0844,
        "nubia": {
            "semantic_relation": 4.5296,
            "contradiction": 0.10688,
            "irrelevancy": 33.94207,
            "logical_agreement": 65.95105,
            "grammar_ref": 4.00353,
            "grammar_hyp": 5.42257,
            "nubia_score": 0.77031
        },
        "bleurt": 0.19217,
        "meteor": 0.3249792698434261,
        "bertscore": {
            "precision": 0.95406,
            "recall": 0.89606,
            "f1": 0.92415
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.4156844010247407,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.64096,
            "contradiction": 0.21793,
            "irrelevancy": 0.49368,
            "logical_agreement": 99.2884,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.3673,
            "nubia_score": 0.85584
        },
        "bleurt": 0.6432,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673076,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 3.4595216280661427,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.71429,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.4359,
            "fmeasure": 0.49275
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.66667,
            "fmeasure": 0.74667
        },
        "bleu": 38.14156,
        "nubia": {
            "semantic_relation": 4.61109,
            "contradiction": 3.09482,
            "irrelevancy": 8.3594,
            "logical_agreement": 88.54578,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.96442,
            "nubia_score": 0.74324
        },
        "bleurt": 0.44858,
        "meteor": 0.3918734238227112,
        "bertscore": {
            "precision": 0.96123,
            "recall": 0.92567,
            "f1": 0.94312
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 23.0,
        "std_pred_length": 3.0,
        "median_pred_length": 23.0,
        "min_pred_length": 20,
        "max_pred_length": 26,
        "distinct-1": 0.8478260869565217,
        "vocab_size-1": 39,
        "unique-1": 34,
        "entropy-1": 5.186392934223817,
        "distinct-2": 1.0,
        "vocab_size-2": 44,
        "unique-2": 44,
        "entropy-2": 5.4594316186372955,
        "cond_entropy-2": 0.24291000358771486,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0671141958585368,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.03418371977919,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.247927513443589,
        "cond_entropy-2-nopunct": 0.22888823445956363,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.0780025120012732,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0,
            "3": 0.5897435897435898
        },
        "nist": 3.5654200062210792,
        "rouge1": {
            "precision": 0.7197,
            "recall": 0.57926,
            "fmeasure": 0.64049
        },
        "rouge2": {
            "precision": 0.4239,
            "recall": 0.35278,
            "fmeasure": 0.38455
        },
        "rougeL": {
            "precision": 0.62121,
            "recall": 0.52621,
            "fmeasure": 0.56967
        },
        "rougeLsum": {
            "precision": 0.62121,
            "recall": 0.52621,
            "fmeasure": 0.56967
        },
        "bleu": 35.12334,
        "nubia": {
            "semantic_relation": 3.49262,
            "contradiction": 50.25854,
            "irrelevancy": 8.88579,
            "logical_agreement": 40.85567,
            "grammar_ref": 3.79147,
            "grammar_hyp": 4.09163,
            "nubia_score": 0.48538
        },
        "bleurt": 0.18587,
        "meteor": 0.2986442078494703,
        "bertscore": {
            "precision": 0.88965,
            "recall": 0.8675,
            "f1": 0.87795
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.5898980954642865,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219054,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.334679141051595,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.28076340776035325,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "nist": 3.3443085076254806,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.86667,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.57143,
            "fmeasure": 0.57143
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "bleu": 33.79021,
        "nubia": {
            "semantic_relation": 4.64796,
            "contradiction": 0.22408,
            "irrelevancy": 1.01192,
            "logical_agreement": 98.764,
            "grammar_ref": 4.08392,
            "grammar_hyp": 4.65223,
            "nubia_score": 0.85115
        },
        "bleurt": 0.40945,
        "meteor": 0.4057849261288186,
        "bertscore": {
            "precision": 0.94147,
            "recall": 0.9246,
            "f1": 0.93296
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 1.5,
        "median_pred_length": 16.5,
        "min_pred_length": 15,
        "max_pred_length": 18,
        "distinct-1": 0.6060606060606061,
        "vocab_size-1": 20,
        "unique-1": 9,
        "entropy-1": 4.195909270873606,
        "distinct-2": 0.7096774193548387,
        "vocab_size-2": 22,
        "unique-2": 13,
        "entropy-2": 4.373551149096553,
        "cond_entropy-2": 0.16786670715745414,
        "distinct-3": 0.7586206896551724,
        "vocab_size-3": 22,
        "unique-3": 15,
        "entropy-3": 4.375222374437916,
        "cond_entropy-3": 0.04171571922345565,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6129032258064516,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 4.11548663296752,
        "distinct-2-nopunct": 0.6896551724137931,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 4.237291339955158,
        "cond_entropy-2-nopunct": 0.17964675370621427,
        "distinct-3-nopunct": 0.7407407407407407,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 4.236368983644952,
        "cond_entropy-3-nopunct": 0.04505465518404472,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.47058823529411764,
            "2": 0.2857142857142857,
            "3": 0.5625
        },
        "nist": 3.6293775604437606,
        "rouge1": {
            "precision": 0.53399,
            "recall": 0.60555,
            "fmeasure": 0.55234
        },
        "rouge2": {
            "precision": 0.32222,
            "recall": 0.36694,
            "fmeasure": 0.33232
        },
        "rougeL": {
            "precision": 0.47643,
            "recall": 0.53962,
            "fmeasure": 0.49241
        },
        "rougeLsum": {
            "precision": 0.47643,
            "recall": 0.53962,
            "fmeasure": 0.49241
        },
        "bleu": 34.61308,
        "nubia": {
            "semantic_relation": 3.60534,
            "contradiction": 46.50636,
            "irrelevancy": 41.90555,
            "logical_agreement": 11.58808,
            "grammar_ref": 3.56015,
            "grammar_hyp": 3.99146,
            "nubia_score": 0.54139
        },
        "bleurt": -0.29166,
        "meteor": 0.361201442904607,
        "bertscore": {
            "precision": 0.8602,
            "recall": 0.91504,
            "f1": 0.88336
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6428571428571429
        },
        "nist": 2.3394631975644025,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.54581,
            "fmeasure": 0.61869
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.40414,
            "fmeasure": 0.46165
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.49123,
            "fmeasure": 0.55682
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.49123,
            "fmeasure": 0.55682
        },
        "bleu": 34.56548,
        "nubia": {
            "semantic_relation": 2.93621,
            "contradiction": 82.57872,
            "irrelevancy": 16.60773,
            "logical_agreement": 0.81354,
            "grammar_ref": 4.95426,
            "grammar_hyp": 5.78779,
            "nubia_score": 0.20383
        },
        "bleurt": -0.49787,
        "meteor": 0.3409441346034425,
        "bertscore": {
            "precision": 0.8907,
            "recall": 0.87709,
            "f1": 0.88384
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.0,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 14,
        "entropy-1": 4.23890125660263,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 20,
        "unique-2": 16,
        "entropy-2": 4.251629167387823,
        "cond_entropy-2": -0.032143884086602556,
        "distinct-3": 0.8636363636363636,
        "vocab_size-3": 19,
        "unique-3": 16,
        "entropy-3": 4.186704345910023,
        "cond_entropy-3": -0.0346217911747682,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.16829583405449,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.095795255000932,
        "cond_entropy-2-nopunct": -0.08007633662931364,
        "distinct-3-nopunct": 0.85,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.021928094887363,
        "cond_entropy-3-nopunct": -0.08750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.287165657505093,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 83.90527,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.36033,
            "irrelevancy": 0.57765,
            "logical_agreement": 99.06202,
            "grammar_ref": 6.12532,
            "grammar_hyp": 5.69755,
            "nubia_score": 1.0
        },
        "bleurt": 0.88717,
        "meteor": 0.6317139091272116,
        "bertscore": {
            "precision": 0.97954,
            "recall": 0.99788,
            "f1": 0.98854
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.251629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.2864255422923785,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.011365041826378,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.32961067210860195,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6428571428571429
        },
        "nist": 2.700454928899545,
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.6152,
            "fmeasure": 0.60058
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.21196,
            "fmeasure": 0.20413
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.40196,
            "fmeasure": 0.3883
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.40196,
            "fmeasure": 0.3883
        },
        "bleu": 6.4988,
        "nubia": {
            "semantic_relation": 4.02037,
            "contradiction": 51.59429,
            "irrelevancy": 6.98639,
            "logical_agreement": 41.41932,
            "grammar_ref": 4.95035,
            "grammar_hyp": 5.24263,
            "nubia_score": 0.58015
        },
        "bleurt": 0.16696,
        "meteor": 0.3125308355097275,
        "bertscore": {
            "precision": 0.88841,
            "recall": 0.88829,
            "f1": 0.87587
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.0,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.238901256602629,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.30118944924673063,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.088779347361362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.3449459429122239,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9473684210526315
        },
        "nist": 3.2759010858400464,
        "rouge1": {
            "precision": 0.85317,
            "recall": 0.84551,
            "fmeasure": 0.84166
        },
        "rouge2": {
            "precision": 0.67308,
            "recall": 0.65507,
            "fmeasure": 0.65656
        },
        "rougeL": {
            "precision": 0.85317,
            "recall": 0.84551,
            "fmeasure": 0.84166
        },
        "rougeLsum": {
            "precision": 0.85317,
            "recall": 0.84551,
            "fmeasure": 0.84166
        },
        "bleu": 63.1837,
        "nubia": {
            "semantic_relation": 3.66062,
            "contradiction": 49.87791,
            "irrelevancy": 1.00952,
            "logical_agreement": 49.11257,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.55217,
            "nubia_score": 0.5019
        },
        "bleurt": 0.31996,
        "meteor": 0.4834082979791966,
        "bertscore": {
            "precision": 0.97558,
            "recall": 0.97217,
            "f1": 0.97387
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "nist": 3.2414851729709646,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.74661,
            "fmeasure": 0.81931
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.58333,
            "fmeasure": 0.64412
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.50452,
            "fmeasure": 0.55586
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.50452,
            "fmeasure": 0.55586
        },
        "bleu": 54.08439,
        "nubia": {
            "semantic_relation": 4.23015,
            "contradiction": 0.30962,
            "irrelevancy": 0.87818,
            "logical_agreement": 98.81219,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.71423,
            "nubia_score": 0.7174
        },
        "bleurt": 0.49887,
        "meteor": 0.47058904521438194,
        "bertscore": {
            "precision": 0.96621,
            "recall": 0.95745,
            "f1": 0.96181
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.8653846153846154,
        "vocab_size-1": 45,
        "unique-1": 41,
        "entropy-1": 5.361792785940386,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.23283421728915335,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.09114788805819536,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 4.189935029992178,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8775510204081632,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.296145752800172,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.24819212225564813,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.09729720135491506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.07692307692307693,
            "3": 0.7804878048780488
        },
        "nist": 3.793183615714472,
        "rouge1": {
            "precision": 0.75758,
            "recall": 0.69254,
            "fmeasure": 0.71925
        },
        "rouge2": {
            "precision": 0.58211,
            "recall": 0.53494,
            "fmeasure": 0.55362
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.66434,
            "fmeasure": 0.69004
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.66434,
            "fmeasure": 0.69004
        },
        "bleu": 45.25834,
        "nubia": {
            "semantic_relation": 4.17308,
            "contradiction": 3.40838,
            "irrelevancy": 28.3785,
            "logical_agreement": 68.21312,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.5369,
            "nubia_score": 0.7075
        },
        "bleurt": 0.11476,
        "meteor": 0.3938454908866195,
        "bertscore": {
            "precision": 0.94024,
            "recall": 0.92496,
            "f1": 0.93216
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.42857142857142855
        },
        "nist": 0.6549594661666175,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.38462,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2037,
            "fmeasure": 0.25185
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.38462,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.38462,
            "fmeasure": 0.5
        },
        "bleu": 8.42356,
        "nubia": {
            "semantic_relation": 3.68354,
            "contradiction": 1.53338,
            "irrelevancy": 2.62782,
            "logical_agreement": 95.8388,
            "grammar_ref": 5.35395,
            "grammar_hyp": 5.40107,
            "nubia_score": 0.53927
        },
        "bleurt": -0.17263,
        "meteor": 0.28617795903169624,
        "bertscore": {
            "precision": 0.92814,
            "recall": 0.83417,
            "f1": 0.87865
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.07482944545381269,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.7779545389594613,
        "rouge1": {
            "precision": 0.67857,
            "recall": 0.9,
            "fmeasure": 0.77048
        },
        "rouge2": {
            "precision": 0.54701,
            "recall": 0.67083,
            "fmeasure": 0.58442
        },
        "rougeL": {
            "precision": 0.70238,
            "recall": 0.81667,
            "fmeasure": 0.73843
        },
        "rougeLsum": {
            "precision": 0.70238,
            "recall": 0.81667,
            "fmeasure": 0.73843
        },
        "bleu": 54.29936,
        "nubia": {
            "semantic_relation": 4.42709,
            "contradiction": 0.89129,
            "irrelevancy": 36.63372,
            "logical_agreement": 62.47499,
            "grammar_ref": 5.35128,
            "grammar_hyp": 5.2706,
            "nubia_score": 0.74104
        },
        "bleurt": 0.28337,
        "meteor": 0.43860703897900205,
        "bertscore": {
            "precision": 0.93654,
            "recall": 0.96593,
            "f1": 0.95051
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8
        },
        "nist": 1.292481250360578,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.8,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.6,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.6,
            "fmeasure": 0.5
        },
        "bleu": 17.74741,
        "nubia": {
            "semantic_relation": 4.28578,
            "contradiction": 0.1089,
            "irrelevancy": 99.7684,
            "logical_agreement": 0.12269,
            "grammar_ref": 6.34893,
            "grammar_hyp": 5.16849,
            "nubia_score": 0.91942
        },
        "bleurt": 0.33378,
        "meteor": 0.3919429262309219,
        "bertscore": {
            "precision": 0.87894,
            "recall": 0.93101,
            "f1": 0.90423
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.8708286933869707,
        "median_pred_length": 11.5,
        "min_pred_length": 8,
        "max_pred_length": 13,
        "distinct-1": 0.7045454545454546,
        "vocab_size-1": 31,
        "unique-1": 21,
        "entropy-1": 4.80591144813358,
        "distinct-2": 0.925,
        "vocab_size-2": 37,
        "unique-2": 34,
        "entropy-2": 5.171928094887363,
        "cond_entropy-2": 0.23136866380415166,
        "distinct-3": 0.9722222222222222,
        "vocab_size-3": 35,
        "unique-3": 34,
        "entropy-3": 5.114369445886754,
        "cond_entropy-3": -0.04089198233393863,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 9.75,
        "std_pred_length-nopunct": 1.6393596310755,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.7435897435897436,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.753225616242672,
        "distinct-2-nopunct": 0.9142857142857143,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.957854445516393,
        "cond_entropy-2-nopunct": 0.23687758385881713,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.889680181354619,
        "cond_entropy-3-nopunct": -0.07831251300970431,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.8611111111111112
        },
        "nist": 4.9969892104937035,
        "rouge1": {
            "precision": 0.84735,
            "recall": 0.83122,
            "fmeasure": 0.8222
        },
        "rouge2": {
            "precision": 0.76865,
            "recall": 0.73068,
            "fmeasure": 0.72177
        },
        "rougeL": {
            "precision": 0.84735,
            "recall": 0.80216,
            "fmeasure": 0.79569
        },
        "rougeLsum": {
            "precision": 0.84735,
            "recall": 0.80216,
            "fmeasure": 0.79569
        },
        "bleu": 70.82362,
        "nubia": {
            "semantic_relation": 4.72764,
            "contradiction": 3.74964,
            "irrelevancy": 21.34117,
            "logical_agreement": 74.90919,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.44928,
            "nubia_score": 0.89521
        },
        "bleurt": 0.56937,
        "meteor": 0.5031071796026749,
        "bertscore": {
            "precision": 0.97838,
            "recall": 0.96457,
            "f1": 0.97082
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "nist": 1.6363636363636365,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.85714,
            "fmeasure": 0.70588
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.85714,
            "fmeasure": 0.70588
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.85714,
            "fmeasure": 0.70588
        },
        "bleu": 11.73118,
        "nubia": {
            "semantic_relation": 4.63911,
            "contradiction": 0.15419,
            "irrelevancy": 34.47586,
            "logical_agreement": 65.36995,
            "grammar_ref": 5.74517,
            "grammar_hyp": 4.51844,
            "nubia_score": 0.9699
        },
        "bleurt": 0.43507,
        "meteor": 0.3691424994520742,
        "bertscore": {
            "precision": 0.86756,
            "recall": 0.90492,
            "f1": 0.88585
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4444444444444444
        },
        "nist": 1.6609640474436813,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "bleu": 12.54931,
        "nubia": {
            "semantic_relation": 4.59766,
            "contradiction": 0.24242,
            "irrelevancy": 90.95441,
            "logical_agreement": 8.80317,
            "grammar_ref": 3.99081,
            "grammar_hyp": 2.90139,
            "nubia_score": 1.0
        },
        "bleurt": 0.30052,
        "meteor": 0.29568923502227945,
        "bertscore": {
            "precision": 0.87901,
            "recall": 0.89984,
            "f1": 0.8893
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 72,
        "mean_pred_length": 14.4,
        "std_pred_length": 4.409081537009721,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7083333333333334,
        "vocab_size-1": 51,
        "unique-1": 35,
        "entropy-1": 5.51548867534837,
        "distinct-2": 0.8805970149253731,
        "vocab_size-2": 59,
        "unique-2": 51,
        "entropy-2": 5.827283220308516,
        "cond_entropy-2": 0.18735486072183233,
        "distinct-3": 0.9032258064516129,
        "vocab_size-3": 56,
        "unique-3": 50,
        "entropy-3": 5.760647923290104,
        "cond_entropy-3": -0.04737675103863914,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 4.363484845854286,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.489107106005257,
        "distinct-2-nopunct": 0.8793103448275862,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.616601684782744,
        "cond_entropy-2-nopunct": 0.16957844235461184,
        "distinct-3-nopunct": 0.9056603773584906,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.539241209280178,
        "cond_entropy-3-nopunct": -0.05458884245116534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.8260869565217391
        },
        "nist": 4.843180571066261,
        "rouge1": {
            "precision": 0.8368,
            "recall": 0.79939,
            "fmeasure": 0.81675
        },
        "rouge2": {
            "precision": 0.62338,
            "recall": 0.60129,
            "fmeasure": 0.61146
        },
        "rougeL": {
            "precision": 0.74993,
            "recall": 0.78175,
            "fmeasure": 0.75905
        },
        "rougeLsum": {
            "precision": 0.74993,
            "recall": 0.78175,
            "fmeasure": 0.75905
        },
        "bleu": 55.06176,
        "nubia": {
            "semantic_relation": 4.65859,
            "contradiction": 0.56683,
            "irrelevancy": 6.09818,
            "logical_agreement": 93.33499,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.81244,
            "nubia_score": 0.89849
        },
        "bleurt": 0.61658,
        "meteor": 0.44147368188378194,
        "bertscore": {
            "precision": 0.94858,
            "recall": 0.95124,
            "f1": 0.94899
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4,
            "3": 1.0
        },
        "nist": 3.0675674754291196,
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "rouge2": {
            "precision": 0.69444,
            "recall": 0.89744,
            "fmeasure": 0.77333
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.92857,
            "fmeasure": 0.81706
        },
        "bleu": 64.75445,
        "nubia": {
            "semantic_relation": 4.46855,
            "contradiction": 11.23993,
            "irrelevancy": 35.42151,
            "logical_agreement": 53.33856,
            "grammar_ref": 6.35753,
            "grammar_hyp": 7.2064,
            "nubia_score": 0.61247
        },
        "bleurt": 0.15531,
        "meteor": 0.5257043737612862,
        "bertscore": {
            "precision": 0.93681,
            "recall": 0.98888,
            "f1": 0.94109
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 6.0,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.7631578947368421,
        "vocab_size-1": 29,
        "unique-1": 23,
        "entropy-1": 4.701746263386654,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 33,
        "unique-2": 30,
        "entropy-2": 5.003258334775643,
        "cond_entropy-2": 0.28782873803879105,
        "distinct-3": 0.9705882352941176,
        "vocab_size-3": 33,
        "unique-3": 32,
        "entropy-3": 5.028639311838574,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.593400348604437,
        "distinct-2-nopunct": 0.9117647058823529,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.910992253015044,
        "cond_entropy-2-nopunct": 0.3048885751445657,
        "distinct-3-nopunct": 0.96875,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.9375,
        "cond_entropy-3-nopunct": 0.037537158749660605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.3333333333333333,
            "3": 0.88
        },
        "nist": 4.6377975323219385,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.89928,
            "fmeasure": 0.86296
        },
        "rouge2": {
            "precision": 0.71528,
            "recall": 0.76116,
            "fmeasure": 0.73576
        },
        "rougeL": {
            "precision": 0.74,
            "recall": 0.78,
            "fmeasure": 0.75778
        },
        "rougeLsum": {
            "precision": 0.74,
            "recall": 0.78,
            "fmeasure": 0.75778
        },
        "bleu": 62.11248,
        "nubia": {
            "semantic_relation": 4.39365,
            "contradiction": 10.58323,
            "irrelevancy": 14.13119,
            "logical_agreement": 75.28557,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.12634,
            "nubia_score": 0.82961
        },
        "bleurt": 0.42781,
        "meteor": 0.47294625422915265,
        "bertscore": {
            "precision": 0.94435,
            "recall": 0.94434,
            "f1": 0.94434
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.09306920777188987,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.16666666666666666
        },
        "nist": 0.11263728676709353,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.3619,
            "fmeasure": 0.46667
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.19286,
            "fmeasure": 0.25325
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.30159,
            "fmeasure": 0.38889
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.30159,
            "fmeasure": 0.38889
        },
        "bleu": 5.50858,
        "nubia": {
            "semantic_relation": 4.24209,
            "contradiction": 0.26024,
            "irrelevancy": 0.54912,
            "logical_agreement": 99.19064,
            "grammar_ref": 2.70093,
            "grammar_hyp": 3.65187,
            "nubia_score": 0.80852
        },
        "bleurt": -0.12081,
        "meteor": 0.2509364483138908,
        "bertscore": {
            "precision": 0.91196,
            "recall": 0.87746,
            "f1": 0.89438
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.4992275471326932,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.4125371587496608,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": 0.04022392894185188,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2402239289418517,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.471892897877657,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 4.230920381554628,
        "rouge1": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rouge2": {
            "precision": 0.88235,
            "recall": 0.97619,
            "fmeasure": 0.92603
        },
        "rougeL": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "rougeLsum": {
            "precision": 0.90741,
            "recall": 1.0,
            "fmeasure": 0.95065
        },
        "bleu": 76.24659,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.1682,
            "irrelevancy": 1.56747,
            "logical_agreement": 98.26433,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.14197,
            "nubia_score": 0.99701
        },
        "bleurt": 0.68837,
        "meteor": 0.6646020374343252,
        "bertscore": {
            "precision": 0.98562,
            "recall": 0.99506,
            "f1": 0.99032
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 18.25,
        "std_pred_length": 3.897114317029974,
        "median_pred_length": 19.5,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.6575342465753424,
        "vocab_size-1": 48,
        "unique-1": 37,
        "entropy-1": 5.241615230813261,
        "distinct-2": 0.8985507246376812,
        "vocab_size-2": 62,
        "unique-2": 56,
        "entropy-2": 5.894685507471448,
        "cond_entropy-2": 0.5920969043722117,
        "distinct-3": 0.9384615384615385,
        "vocab_size-3": 61,
        "unique-3": 57,
        "entropy-3": 5.899290889951534,
        "cond_entropy-3": 0.017764702437415687,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 16.25,
        "std_pred_length-nopunct": 3.2691742076555053,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6615384615384615,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.080532721507323,
        "distinct-2-nopunct": 0.8852459016393442,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.688853935888071,
        "cond_entropy-2-nopunct": 0.6700808925132866,
        "distinct-3-nopunct": 0.9298245614035088,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 49,
        "entropy-3-nopunct": 5.692539136971755,
        "cond_entropy-3-nopunct": 0.020659474885425258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6363636363636364,
            "3": 0.4864864864864865
        },
        "nist": 4.024458931386178,
        "rouge1": {
            "precision": 0.65033,
            "recall": 0.6135,
            "fmeasure": 0.62936
        },
        "rouge2": {
            "precision": 0.40095,
            "recall": 0.39233,
            "fmeasure": 0.39613
        },
        "rougeL": {
            "precision": 0.56746,
            "recall": 0.54867,
            "fmeasure": 0.55605
        },
        "rougeLsum": {
            "precision": 0.56746,
            "recall": 0.54867,
            "fmeasure": 0.55605
        },
        "bleu": 32.34354,
        "nubia": {
            "semantic_relation": 3.12425,
            "contradiction": 48.09389,
            "irrelevancy": 7.72698,
            "logical_agreement": 44.17913,
            "grammar_ref": 4.12218,
            "grammar_hyp": 3.8802,
            "nubia_score": 0.49301
        },
        "bleurt": 0.0184,
        "meteor": 0.2938295840410738,
        "bertscore": {
            "precision": 0.89417,
            "recall": 0.89004,
            "f1": 0.8913
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.1625371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.6875
        },
        "nist": 2.7815203706024314,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.60529,
            "fmeasure": 0.63137
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.39773,
            "fmeasure": 0.41447
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.60529,
            "fmeasure": 0.63137
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.60529,
            "fmeasure": 0.63137
        },
        "bleu": 27.67894,
        "nubia": {
            "semantic_relation": 4.11841,
            "contradiction": 0.56466,
            "irrelevancy": 27.32189,
            "logical_agreement": 72.11344,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.5101,
            "nubia_score": 0.67788
        },
        "bleurt": 0.44569,
        "meteor": 0.39175036158287463,
        "bertscore": {
            "precision": 0.9314,
            "recall": 0.94166,
            "f1": 0.9365
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 1.0,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 19,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 33,
        "unique-1": 30,
        "entropy-1": 5.003258334775643,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.09400842804332113,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9117647058823529,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.910992253015044,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.06878715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.6190476190476191
        },
        "nist": 4.422938581172478,
        "rouge1": {
            "precision": 0.58894,
            "recall": 0.58654,
            "fmeasure": 0.58333
        },
        "rouge2": {
            "precision": 0.36,
            "recall": 0.35831,
            "fmeasure": 0.35604
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.50894,
            "fmeasure": 0.50104
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.50894,
            "fmeasure": 0.50104
        },
        "bleu": 37.77894,
        "nubia": {
            "semantic_relation": 3.66243,
            "contradiction": 25.80256,
            "irrelevancy": 34.98125,
            "logical_agreement": 39.21619,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.75086,
            "nubia_score": 0.55405
        },
        "bleurt": -0.09797,
        "meteor": 0.32539076943921236,
        "bertscore": {
            "precision": 0.93091,
            "recall": 0.9171,
            "f1": 0.91995
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.9519701592632195,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.57143,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.16667,
            "fmeasure": 0.14286
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.42857,
            "fmeasure": 0.375
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.42857,
            "fmeasure": 0.375
        },
        "bleu": 7.12938,
        "nubia": {
            "semantic_relation": 4.32572,
            "contradiction": 0.10425,
            "irrelevancy": 0.98464,
            "logical_agreement": 98.91111,
            "grammar_ref": 4.92688,
            "grammar_hyp": 4.11301,
            "nubia_score": 0.84871
        },
        "bleurt": 0.45013,
        "meteor": 0.2693880923282191,
        "bertscore": {
            "precision": 0.85678,
            "recall": 0.88006,
            "f1": 0.86397
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.548645758111165,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.65439,
            "contradiction": 0.55881,
            "irrelevancy": 1.76619,
            "logical_agreement": 97.675,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.54703,
            "nubia_score": 0.85279
        },
        "bleurt": 0.7198,
        "meteor": 0.5161210442123606,
        "bertscore": {
            "precision": 0.98951,
            "recall": 0.9715,
            "f1": 0.98042
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.392755884942568,
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.72222,
            "fmeasure": 0.60131
        },
        "rouge2": {
            "precision": 0.20833,
            "recall": 0.31429,
            "fmeasure": 0.24957
        },
        "rougeL": {
            "precision": 0.40741,
            "recall": 0.52778,
            "fmeasure": 0.45079
        },
        "rougeLsum": {
            "precision": 0.40741,
            "recall": 0.52778,
            "fmeasure": 0.45079
        },
        "bleu": 14.53577,
        "nubia": {
            "semantic_relation": 4.37868,
            "contradiction": 5.14587,
            "irrelevancy": 78.5943,
            "logical_agreement": 16.25983,
            "grammar_ref": 5.75818,
            "grammar_hyp": 5.43269,
            "nubia_score": 0.72299
        },
        "bleurt": 0.04039,
        "meteor": 0.38252559899409705,
        "bertscore": {
            "precision": 0.83137,
            "recall": 0.88431,
            "f1": 0.85703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7142857142857143
        },
        "nist": 3.926592062147975,
        "rouge1": {
            "precision": 0.80392,
            "recall": 0.69758,
            "fmeasure": 0.74659
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32222,
            "fmeasure": 0.34641
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57978,
            "fmeasure": 0.61988
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57978,
            "fmeasure": 0.61988
        },
        "bleu": 24.50341,
        "nubia": {
            "semantic_relation": 4.18498,
            "contradiction": 0.21419,
            "irrelevancy": 33.28813,
            "logical_agreement": 66.49768,
            "grammar_ref": 4.42639,
            "grammar_hyp": 4.43353,
            "nubia_score": 0.74514
        },
        "bleurt": 0.26882,
        "meteor": 0.37423520854850306,
        "bertscore": {
            "precision": 0.93037,
            "recall": 0.92685,
            "f1": 0.92861
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 4.5,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.0559581516151235,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2856548715866746,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.9754180179138325,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.3163936434102709,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.1111111111111111,
            "3": 0.5294117647058824
        },
        "nist": 2.1249516173811114,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.51061,
            "fmeasure": 0.55505
        },
        "rouge2": {
            "precision": 0.36667,
            "recall": 0.29148,
            "fmeasure": 0.31952
        },
        "rougeL": {
            "precision": 0.61458,
            "recall": 0.50227,
            "fmeasure": 0.54579
        },
        "rougeLsum": {
            "precision": 0.61458,
            "recall": 0.50227,
            "fmeasure": 0.54579
        },
        "bleu": 21.90886,
        "nubia": {
            "semantic_relation": 3.23614,
            "contradiction": 47.30115,
            "irrelevancy": 3.68171,
            "logical_agreement": 49.01714,
            "grammar_ref": 4.30067,
            "grammar_hyp": 4.71731,
            "nubia_score": 0.42489
        },
        "bleurt": 0.01711,
        "meteor": 0.2668422836624087,
        "bertscore": {
            "precision": 0.89883,
            "recall": 0.86771,
            "f1": 0.88283
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.8094988549899862,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.26984,
            "fmeasure": 0.32727
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.50595,
            "fmeasure": 0.59829
        },
        "bleu": 24.59813,
        "nubia": {
            "semantic_relation": 4.18837,
            "contradiction": 0.38664,
            "irrelevancy": 0.58445,
            "logical_agreement": 99.02891,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.86986,
            "nubia_score": 0.75842
        },
        "bleurt": 0.30353,
        "meteor": 0.3010544205973617,
        "bertscore": {
            "precision": 0.97738,
            "recall": 0.94093,
            "f1": 0.95881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.175735869100492,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.2995060262166481,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.2417888922404337,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "nist": 3.646657919873787,
        "rouge1": {
            "precision": 0.85,
            "recall": 0.89474,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.63158,
            "recall": 0.66667,
            "fmeasure": 0.64865
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.73684,
            "fmeasure": 0.71795
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.73684,
            "fmeasure": 0.71795
        },
        "bleu": 47.82196,
        "nubia": {
            "semantic_relation": 4.26042,
            "contradiction": 0.09351,
            "irrelevancy": 2.43254,
            "logical_agreement": 97.47395,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.89706,
            "nubia_score": 0.79338
        },
        "bleurt": 0.38328,
        "meteor": 0.453804335281964,
        "bertscore": {
            "precision": 0.93883,
            "recall": 0.94188,
            "f1": 0.94036
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.2777777777777778
        },
        "nist": 0.2793273316827827,
        "rouge1": {
            "precision": 0.46154,
            "recall": 0.22222,
            "fmeasure": 0.3
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.07692,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.22222,
            "fmeasure": 0.3
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.22222,
            "fmeasure": 0.3
        },
        "bleu": 5.24147,
        "nubia": {
            "semantic_relation": 1.80936,
            "contradiction": 3.84502,
            "irrelevancy": 93.768,
            "logical_agreement": 2.38698,
            "grammar_ref": 4.95946,
            "grammar_hyp": 6.57661,
            "nubia_score": 0.07629
        },
        "bleurt": -0.50526,
        "meteor": 0.14219684632158625,
        "bertscore": {
            "precision": 0.86133,
            "recall": 0.82227,
            "f1": 0.84135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548846,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": 0.037537158749660585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2222222222222222,
            "3": 0.6111111111111112
        },
        "nist": 1.978351594134444,
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.59607,
            "fmeasure": 0.67619
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.2899,
            "fmeasure": 0.33056
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.3885,
            "fmeasure": 0.46286
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.3885,
            "fmeasure": 0.46286
        },
        "bleu": 19.40303,
        "nubia": {
            "semantic_relation": 4.24633,
            "contradiction": 16.99719,
            "irrelevancy": 27.8134,
            "logical_agreement": 55.18941,
            "grammar_ref": 3.59602,
            "grammar_hyp": 4.52749,
            "nubia_score": 0.61482
        },
        "bleurt": -0.10052,
        "meteor": 0.32098901507064637,
        "bertscore": {
            "precision": 0.92947,
            "recall": 0.90871,
            "f1": 0.91897
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.9024801311398734,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.94872,
            "fmeasure": 0.90667
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.7381,
            "fmeasure": 0.70692
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.76282,
            "fmeasure": 0.73333
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.76282,
            "fmeasure": 0.73333
        },
        "bleu": 58.51655,
        "nubia": {
            "semantic_relation": 4.16958,
            "contradiction": 0.28804,
            "irrelevancy": 50.15351,
            "logical_agreement": 49.55844,
            "grammar_ref": 4.62626,
            "grammar_hyp": 4.37029,
            "nubia_score": 0.72136
        },
        "bleurt": -0.00284,
        "meteor": 0.5319853951676884,
        "bertscore": {
            "precision": 0.98044,
            "recall": 0.97622,
            "f1": 0.97833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "nist": 1.353289509199005,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.41667,
            "fmeasure": 0.50794
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.5641,
            "fmeasure": 0.675
        },
        "bleu": 42.13953,
        "nubia": {
            "semantic_relation": 3.58413,
            "contradiction": 0.90915,
            "irrelevancy": 0.77982,
            "logical_agreement": 98.31103,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.04864,
            "nubia_score": 0.50694
        },
        "bleurt": 0.02674,
        "meteor": 0.2969362339094229,
        "bertscore": {
            "precision": 0.95405,
            "recall": 0.92629,
            "f1": 0.93996
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.5,
        "vocab_size-1": 12,
        "unique-1": 2,
        "entropy-1": 3.5016291673878226,
        "distinct-2": 0.5909090909090909,
        "vocab_size-2": 13,
        "unique-2": 4,
        "entropy-2": 3.6412498004554794,
        "cond_entropy-2": 0.14719639064341367,
        "distinct-3": 0.65,
        "vocab_size-3": 13,
        "unique-3": 6,
        "entropy-3": 3.6219280948873624,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 3.368522527728207,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": 0.162496476250065,
        "distinct-3-nopunct": 0.6666666666666666,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 3.503258334775645,
        "cond_entropy-3-nopunct": -0.04089198233393866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.631578947368421
        },
        "nist": 3.0753781696409983,
        "rouge1": {
            "precision": 0.89394,
            "recall": 0.73769,
            "fmeasure": 0.80135
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.66667,
            "fmeasure": 0.64857
        },
        "rougeL": {
            "precision": 0.84848,
            "recall": 0.70644,
            "fmeasure": 0.76431
        },
        "rougeLsum": {
            "precision": 0.84848,
            "recall": 0.70644,
            "fmeasure": 0.76431
        },
        "bleu": 33.51347,
        "nubia": {
            "semantic_relation": 4.02848,
            "contradiction": 0.21257,
            "irrelevancy": 17.70474,
            "logical_agreement": 82.08268,
            "grammar_ref": 4.70595,
            "grammar_hyp": 5.88377,
            "nubia_score": 0.53293
        },
        "bleurt": 0.30361,
        "meteor": 0.36452479981371805,
        "bertscore": {
            "precision": 0.96054,
            "recall": 0.88556,
            "f1": 0.92145
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "nist": 1.6209105484829365,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.21481,
            "fmeasure": 0.25714
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.57778,
            "fmeasure": 0.61111
        },
        "bleu": 43.47209,
        "nubia": {
            "semantic_relation": 3.06089,
            "contradiction": 82.7322,
            "irrelevancy": 16.29995,
            "logical_agreement": 0.96784,
            "grammar_ref": 7.45181,
            "grammar_hyp": 8.73391,
            "nubia_score": 0.17831
        },
        "bleurt": -0.8909,
        "meteor": 0.38938120775882434,
        "bertscore": {
            "precision": 0.89278,
            "recall": 0.88981,
            "f1": 0.89129
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.6835423624332306,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 15,
        "unique-2": 13,
        "entropy-2": 3.8521687236032816,
        "cond_entropy-2": 0.19723710464117222,
        "distinct-3": 0.9375,
        "vocab_size-3": 15,
        "unique-3": 14,
        "entropy-3": 3.875,
        "cond_entropy-3": 0.037537158749660585,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7647058823529411,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.5724694587701364,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.75,
        "cond_entropy-2-nopunct": 0.20971762763487736,
        "distinct-3-nopunct": 0.9333333333333333,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.773557262275185,
        "cond_entropy-3-nopunct": 0.04022392894185189,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.4945940961352653,
        "rouge1": {
            "precision": 0.61404,
            "recall": 0.72887,
            "fmeasure": 0.65614
        },
        "rouge2": {
            "precision": 0.40741,
            "recall": 0.4963,
            "fmeasure": 0.43915
        },
        "rougeL": {
            "precision": 0.47368,
            "recall": 0.81818,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.47368,
            "recall": 0.81818,
            "fmeasure": 0.6
        },
        "bleu": 13.15899,
        "nubia": {
            "semantic_relation": 4.85687,
            "contradiction": 0.27953,
            "irrelevancy": 83.30204,
            "logical_agreement": 16.41843,
            "grammar_ref": 3.90557,
            "grammar_hyp": 3.51049,
            "nubia_score": 0.81483
        },
        "bleurt": 0.44894,
        "meteor": 0.3228796465838358,
        "bertscore": {
            "precision": 0.94008,
            "recall": 0.93559,
            "f1": 0.93242
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.150824249374843,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.9697,
            "fmeasure": 0.92754
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.93333,
            "fmeasure": 0.88889
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.9697,
            "fmeasure": 0.92754
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.9697,
            "fmeasure": 0.92754
        },
        "bleu": 85.55262,
        "nubia": {
            "semantic_relation": 4.90595,
            "contradiction": 0.14926,
            "irrelevancy": 5.28966,
            "logical_agreement": 94.56107,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.0211,
            "nubia_score": 0.92067
        },
        "bleurt": 0.71148,
        "meteor": 0.5783876283840306,
        "bertscore": {
            "precision": 0.99136,
            "recall": 0.99724,
            "f1": 0.99429
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.5,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 15,
        "entropy-1": 4.243856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.22753185323880998,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.9219280948873623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.29244135099939467,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.45454545454545453,
            "3": 0.8181818181818182
        },
        "nist": 3.238499140738457,
        "rouge1": {
            "precision": 0.69088,
            "recall": 0.63049,
            "fmeasure": 0.65119
        },
        "rouge2": {
            "precision": 0.48611,
            "recall": 0.39322,
            "fmeasure": 0.41698
        },
        "rougeL": {
            "precision": 0.63818,
            "recall": 0.54563,
            "fmeasure": 0.57037
        },
        "rougeLsum": {
            "precision": 0.63818,
            "recall": 0.54563,
            "fmeasure": 0.57037
        },
        "bleu": 38.35544,
        "nubia": {
            "semantic_relation": 3.8967,
            "contradiction": 8.11551,
            "irrelevancy": 21.70702,
            "logical_agreement": 70.17748,
            "grammar_ref": 4.3679,
            "grammar_hyp": 4.24205,
            "nubia_score": 0.63957
        },
        "bleurt": -0.09125,
        "meteor": 0.3359090387002174,
        "bertscore": {
            "precision": 0.92635,
            "recall": 0.92041,
            "f1": 0.91752
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857
        },
        "nist": 0.8420353203410017,
        "rouge1": {
            "precision": 0.36364,
            "recall": 0.47222,
            "fmeasure": 0.41053
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.26786,
            "fmeasure": 0.22876
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.47222,
            "fmeasure": 0.41053
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.47222,
            "fmeasure": 0.41053
        },
        "bleu": 8.29519,
        "nubia": {
            "semantic_relation": 3.51137,
            "contradiction": 2.10079,
            "irrelevancy": 62.52146,
            "logical_agreement": 35.37775,
            "grammar_ref": 4.73918,
            "grammar_hyp": 3.8281,
            "nubia_score": 0.56679
        },
        "bleurt": 0.31149,
        "meteor": 0.27264101633287546,
        "bertscore": {
            "precision": 0.82287,
            "recall": 0.85985,
            "f1": 0.84095
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 3.1227989408526344,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.86667,
            "fmeasure": 0.8254
        },
        "rouge2": {
            "precision": 0.46667,
            "recall": 0.51852,
            "fmeasure": 0.49123
        },
        "rougeL": {
            "precision": 0.51515,
            "recall": 0.56667,
            "fmeasure": 0.53968
        },
        "rougeLsum": {
            "precision": 0.51515,
            "recall": 0.56667,
            "fmeasure": 0.53968
        },
        "bleu": 23.23342,
        "nubia": {
            "semantic_relation": 4.92746,
            "contradiction": 0.20361,
            "irrelevancy": 1.11157,
            "logical_agreement": 98.68482,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.26278,
            "nubia_score": 0.96929
        },
        "bleurt": 0.52526,
        "meteor": 0.44212044811612455,
        "bertscore": {
            "precision": 0.9415,
            "recall": 0.96357,
            "f1": 0.9524
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 3.0,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 13,
        "distinct-1": 0.75,
        "vocab_size-1": 15,
        "unique-1": 10,
        "entropy-1": 3.821928094887362,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 15,
        "unique-2": 12,
        "entropy-2": 3.8365916681089787,
        "cond_entropy-2": -0.04089198233393866,
        "distinct-3": 0.875,
        "vocab_size-3": 14,
        "unique-3": 12,
        "entropy-3": 3.75,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 0.8125,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.625,
        "cond_entropy-2-nopunct": -0.10742500144231237,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.12121650651382439,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9375
        },
        "nist": 3.980352302429953,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "rouge2": {
            "precision": 0.84167,
            "recall": 0.85354,
            "fmeasure": 0.84585
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.93452,
            "fmeasure": 0.92718
        },
        "bleu": 80.17494,
        "nubia": {
            "semantic_relation": 4.93787,
            "contradiction": 0.82427,
            "irrelevancy": 0.91292,
            "logical_agreement": 98.26281,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.10466,
            "nubia_score": 0.9183
        },
        "bleurt": 0.80221,
        "meteor": 0.5859552163896863,
        "bertscore": {
            "precision": 0.98723,
            "recall": 0.99228,
            "f1": 0.98974
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.6538461538461539,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 3.8692996998935216,
        "distinct-2": 0.84,
        "vocab_size-2": 21,
        "unique-2": 17,
        "entropy-2": 4.323856189774722,
        "cond_entropy-2": 0.48780209061110497,
        "distinct-3": 0.875,
        "vocab_size-3": 21,
        "unique-3": 18,
        "entropy-3": 4.334962500721156,
        "cond_entropy-3": 0.02443964427976503,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.826874881864636,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.94770277922009,
        "cond_entropy-2-nopunct": 0.14421971022094904,
        "distinct-3-nopunct": 0.9411764705882353,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.969815782426811,
        "cond_entropy-3-nopunct": 0.03518489863155644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.375,
            "3": 0.1875
        },
        "nist": 1.9875472621057255,
        "rouge1": {
            "precision": 0.35088,
            "recall": 0.32323,
            "fmeasure": 0.33575
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.11018,
            "fmeasure": 0.11038
        },
        "rougeL": {
            "precision": 0.21053,
            "recall": 0.20875,
            "fmeasure": 0.20918
        },
        "rougeLsum": {
            "precision": 0.21053,
            "recall": 0.20875,
            "fmeasure": 0.20918
        },
        "bleu": 17.92479,
        "nubia": {
            "semantic_relation": 2.76375,
            "contradiction": 92.83031,
            "irrelevancy": 4.65807,
            "logical_agreement": 2.51162,
            "grammar_ref": 4.78465,
            "grammar_hyp": 4.72013,
            "nubia_score": 0.30957
        },
        "bleurt": -0.41093,
        "meteor": 0.1760994145704426,
        "bertscore": {
            "precision": 0.86818,
            "recall": 0.80258,
            "f1": 0.83409
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.7735572622751845,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.043321469306228474,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.52164063634332,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.5465935642949384,
        "cond_entropy-2-nopunct": -0.029992126993435245,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.2,
            "3": 0.5833333333333334
        },
        "nist": 2.537573048196229,
        "rouge1": {
            "precision": 0.7381,
            "recall": 0.5098,
            "fmeasure": 0.60096
        },
        "rouge2": {
            "precision": 0.48718,
            "recall": 0.32639,
            "fmeasure": 0.38945
        },
        "rougeL": {
            "precision": 0.59524,
            "recall": 0.40998,
            "fmeasure": 0.48387
        },
        "rougeLsum": {
            "precision": 0.59524,
            "recall": 0.40998,
            "fmeasure": 0.48387
        },
        "bleu": 27.17107,
        "nubia": {
            "semantic_relation": 4.04877,
            "contradiction": 36.51117,
            "irrelevancy": 14.88282,
            "logical_agreement": 48.606,
            "grammar_ref": 3.28677,
            "grammar_hyp": 4.20748,
            "nubia_score": 0.62524
        },
        "bleurt": -0.09475,
        "meteor": 0.23362191289008588,
        "bertscore": {
            "precision": 0.9164,
            "recall": 0.89024,
            "f1": 0.89865
        }
    },
    "xsum_challenge_test_backtranslation_parent": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.72305,
        "msttr-100_nopunct": 0.7315,
        "total_length": 10542,
        "mean_pred_length": 21.084,
        "std_pred_length": 3.5503442086648445,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.26446594574084614,
        "vocab_size-1": 2788,
        "unique-1": 1732,
        "entropy-1": 9.084580123068042,
        "distinct-2": 0.7254530969926309,
        "vocab_size-2": 7285,
        "unique-2": 6261,
        "entropy-2": 12.330714997221992,
        "cond_entropy-2": 3.15836771052064,
        "distinct-3": 0.9274785160343744,
        "vocab_size-3": 8850,
        "unique-3": 8425,
        "entropy-3": 13.033020026997022,
        "cond_entropy-3": 0.7229059849826227,
        "total_length-nopunct": 10012,
        "mean_pred_length-nopunct": 20.024,
        "std_pred_length-nopunct": 3.6725228385947446,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.2775669196963644,
        "vocab_size-1-nopunct": 2779,
        "unique-1-nopunct": 1732,
        "entropy-1-nopunct": 9.177348062212289,
        "distinct-2-nopunct": 0.731286795626577,
        "vocab_size-2-nopunct": 6956,
        "unique-2-nopunct": 6008,
        "entropy-2-nopunct": 12.268007806445182,
        "cond_entropy-2-nopunct": 3.2028104684811507,
        "distinct-3-nopunct": 0.9315357301375943,
        "vocab_size-3-nopunct": 8395,
        "unique-3-nopunct": 8006,
        "entropy-3-nopunct": 12.966125606009326,
        "cond_entropy-3-nopunct": 0.7182474481120518,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.31153340745982006
        },
        "nist": 3.092967103176244,
        "rouge1": {
            "precision": 0.35532,
            "recall": 0.34192,
            "fmeasure": 0.34239
        },
        "rouge2": {
            "precision": 0.12145,
            "recall": 0.11934,
            "fmeasure": 0.11811
        },
        "rougeL": {
            "precision": 0.27212,
            "recall": 0.26332,
            "fmeasure": 0.26278
        },
        "rougeLsum": {
            "precision": 0.27212,
            "recall": 0.26332,
            "fmeasure": 0.26278
        },
        "bleu": 7.52723,
        "nubia": {
            "semantic_relation": 2.43963,
            "contradiction": 30.69412,
            "irrelevancy": 59.87086,
            "logical_agreement": 9.43502,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.34595,
            "nubia_score": 0.28381
        },
        "bleurt": -0.57558,
        "meteor": 0.14275842898018018,
        "bertscore": {
            "precision": 0.81219,
            "recall": 0.8042,
            "f1": 0.80789
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 4.0,
        "median_pred_length": 12.0,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.8636363636363636,
        "vocab_size-2": 19,
        "unique-2": 16,
        "entropy-2": 4.186704345910023,
        "cond_entropy-2": 0.0562872997343227,
        "distinct-3": 0.9,
        "vocab_size-3": 18,
        "unique-3": 16,
        "entropy-3": 4.1219280948873624,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 0.85,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.021928094887363,
        "cond_entropy-2-nopunct": 0.012496476250064989,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.7894736842105263
        },
        "nist": 2.9816150038761955,
        "rouge1": {
            "precision": 0.76825,
            "recall": 0.70265,
            "fmeasure": 0.72706
        },
        "rouge2": {
            "precision": 0.53571,
            "recall": 0.49178,
            "fmeasure": 0.50697
        },
        "rougeL": {
            "precision": 0.67937,
            "recall": 0.65536,
            "fmeasure": 0.66329
        },
        "rougeLsum": {
            "precision": 0.67937,
            "recall": 0.65536,
            "fmeasure": 0.66329
        },
        "bleu": 17.63383,
        "nubia": {
            "semantic_relation": 4.16366,
            "contradiction": 2.06371,
            "irrelevancy": 16.68432,
            "logical_agreement": 81.25196,
            "grammar_ref": 6.00658,
            "grammar_hyp": 6.24111,
            "nubia_score": 0.66392
        },
        "bleurt": 0.22044,
        "meteor": 0.39925368134367606,
        "bertscore": {
            "precision": 0.93254,
            "recall": 0.89714,
            "f1": 0.91326
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.625
        },
        "nist": 2.019949341578472,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.25,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.66667,
            "fmeasure": 0.6
        },
        "bleu": 17.24222,
        "nubia": {
            "semantic_relation": 3.30557,
            "contradiction": 12.3688,
            "irrelevancy": 86.36982,
            "logical_agreement": 1.26137,
            "grammar_ref": 5.49813,
            "grammar_hyp": 5.19143,
            "nubia_score": 0.34946
        },
        "bleurt": 0.22806,
        "meteor": 0.23176611180260565,
        "bertscore": {
            "precision": 0.91468,
            "recall": 0.91761,
            "f1": 0.91407
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 0.5,
        "median_pred_length": 10.5,
        "min_pred_length": 10,
        "max_pred_length": 11,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.0391267514404381,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.04281761336971671,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.8
        },
        "nist": 3.6066135650348863,
        "rouge1": {
            "precision": 0.68704,
            "recall": 0.73333,
            "fmeasure": 0.70686
        },
        "rouge2": {
            "precision": 0.52546,
            "recall": 0.56296,
            "fmeasure": 0.53989
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.73333,
            "fmeasure": 0.68333
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.73333,
            "fmeasure": 0.68333
        },
        "bleu": 59.40637,
        "nubia": {
            "semantic_relation": 4.06955,
            "contradiction": 0.27083,
            "irrelevancy": 49.93805,
            "logical_agreement": 49.79112,
            "grammar_ref": 5.47595,
            "grammar_hyp": 5.31876,
            "nubia_score": 0.7286
        },
        "bleurt": 0.18971,
        "meteor": 0.43115560515334744,
        "bertscore": {
            "precision": 0.92478,
            "recall": 0.92847,
            "f1": 0.92662
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6363636363636364
        },
        "nist": 2.6961870270923605,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.55238,
            "fmeasure": 0.65333
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.25824,
            "fmeasure": 0.31028
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.48333,
            "fmeasure": 0.57167
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.48333,
            "fmeasure": 0.57167
        },
        "bleu": 40.91928,
        "nubia": {
            "semantic_relation": 4.8272,
            "contradiction": 0.11918,
            "irrelevancy": 1.81029,
            "logical_agreement": 98.07052,
            "grammar_ref": 5.03823,
            "grammar_hyp": 5.54199,
            "nubia_score": 0.90515
        },
        "bleurt": 0.38871,
        "meteor": 0.4073528227256414,
        "bertscore": {
            "precision": 0.92027,
            "recall": 0.88562,
            "f1": 0.90261
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 2.120737673534145,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.20952,
            "fmeasure": 0.25589
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "bleu": 19.43406,
        "nubia": {
            "semantic_relation": 3.20935,
            "contradiction": 0.14596,
            "irrelevancy": 99.7425,
            "logical_agreement": 0.11154,
            "grammar_ref": 4.59968,
            "grammar_hyp": 5.14169,
            "nubia_score": 0.37802
        },
        "bleurt": -0.46065,
        "meteor": 0.2400764504728186,
        "bertscore": {
            "precision": 0.86847,
            "recall": 0.81945,
            "f1": 0.84325
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "nist": 0.31592321743697377,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.41176,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.25,
            "fmeasure": 0.34783
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.35294,
            "fmeasure": 0.48
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.35294,
            "fmeasure": 0.48
        },
        "bleu": 15.98205,
        "nubia": {
            "semantic_relation": 2.69293,
            "contradiction": 61.91548,
            "irrelevancy": 8.5993,
            "logical_agreement": 29.48523,
            "grammar_ref": 4.28272,
            "grammar_hyp": 5.32215,
            "nubia_score": 0.17607
        },
        "bleurt": 0.02689,
        "meteor": 0.22923407173743382,
        "bertscore": {
            "precision": 0.94721,
            "recall": 0.82881,
            "f1": 0.88407
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 1.5,
        "median_pred_length": 14.5,
        "min_pred_length": 13,
        "max_pred_length": 16,
        "distinct-1": 0.8620689655172413,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.582118926162054,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.6808134280893965,
        "cond_entropy-2": 0.04505465518404472,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.031031312388743976,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.532665279941248,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.008968687611256045,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.6,
            "3": 1.0
        },
        "nist": 3.6807133726957,
        "rouge1": {
            "precision": 0.59444,
            "recall": 0.68337,
            "fmeasure": 0.62514
        },
        "rouge2": {
            "precision": 0.30952,
            "recall": 0.41021,
            "fmeasure": 0.34298
        },
        "rougeL": {
            "precision": 0.54444,
            "recall": 0.63823,
            "fmeasure": 0.57773
        },
        "rougeLsum": {
            "precision": 0.54444,
            "recall": 0.63823,
            "fmeasure": 0.57773
        },
        "bleu": 21.02632,
        "nubia": {
            "semantic_relation": 3.9887,
            "contradiction": 2.09627,
            "irrelevancy": 77.87755,
            "logical_agreement": 20.02618,
            "grammar_ref": 4.46901,
            "grammar_hyp": 4.60681,
            "nubia_score": 0.60712
        },
        "bleurt": 0.35599,
        "meteor": 0.37748382366030664,
        "bertscore": {
            "precision": 0.93111,
            "recall": 0.94455,
            "f1": 0.93763
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.334962500721156,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.11251249881411754,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.02677875348937534,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.262692390839622,
        "distinct-2-nopunct": 0.9545454545454546,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.368522527728204,
        "cond_entropy-2-nopunct": 0.1176878443984663,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": 0.02812389937955851,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "nist": 2.973857497380672,
        "rouge1": {
            "precision": 0.86957,
            "recall": 0.74074,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "rougeLsum": {
            "precision": 0.78261,
            "recall": 0.66667,
            "fmeasure": 0.72
        },
        "bleu": 45.46584,
        "nubia": {
            "semantic_relation": 4.20923,
            "contradiction": 0.14488,
            "irrelevancy": 5.9228,
            "logical_agreement": 93.93232,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.6766,
            "nubia_score": 0.66233
        },
        "bleurt": 0.25231,
        "meteor": 0.4126722315475949,
        "bertscore": {
            "precision": 0.96134,
            "recall": 0.92946,
            "f1": 0.94399
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 3.5,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.4838561897747224,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728205,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.037503523749935014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6,
            "2": 0.3684210526315789,
            "3": 0.8333333333333334
        },
        "nist": 3.391002465072617,
        "rouge1": {
            "precision": 0.60846,
            "recall": 0.5947,
            "fmeasure": 0.58939
        },
        "rouge2": {
            "precision": 0.40625,
            "recall": 0.39456,
            "fmeasure": 0.38985
        },
        "rougeL": {
            "precision": 0.54963,
            "recall": 0.45581,
            "fmeasure": 0.49678
        },
        "rougeLsum": {
            "precision": 0.54963,
            "recall": 0.45581,
            "fmeasure": 0.49678
        },
        "bleu": 19.5715,
        "nubia": {
            "semantic_relation": 4.05424,
            "contradiction": 0.23554,
            "irrelevancy": 50.16612,
            "logical_agreement": 49.59834,
            "grammar_ref": 5.11675,
            "grammar_hyp": 4.89455,
            "nubia_score": 0.72777
        },
        "bleurt": 0.19263,
        "meteor": 0.3200116116209175,
        "bertscore": {
            "precision": 0.89825,
            "recall": 0.90297,
            "f1": 0.89987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.794653473544342,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.3148841634647017,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6901165175936654,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.3347176276348775,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666
        },
        "nist": 1.3446318632258687,
        "rouge1": {
            "precision": 0.29412,
            "recall": 0.63492,
            "fmeasure": 0.40064
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.45833,
            "fmeasure": 0.26515
        },
        "rougeL": {
            "precision": 0.26471,
            "recall": 0.57937,
            "fmeasure": 0.36218
        },
        "rougeLsum": {
            "precision": 0.26471,
            "recall": 0.57937,
            "fmeasure": 0.36218
        },
        "bleu": 21.86977,
        "nubia": {
            "semantic_relation": 3.36963,
            "contradiction": 0.10682,
            "irrelevancy": 97.80351,
            "logical_agreement": 2.08967,
            "grammar_ref": 4.8549,
            "grammar_hyp": 3.68756,
            "nubia_score": 0.43759
        },
        "bleurt": 0.11121,
        "meteor": 0.33191424076171827,
        "bertscore": {
            "precision": 0.82499,
            "recall": 0.88813,
            "f1": 0.84877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "nist": 3.2627065518090133,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.44444,
            "fmeasure": 0.44444
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.7,
            "fmeasure": 0.7
        },
        "bleu": 53.48259,
        "nubia": {
            "semantic_relation": 4.20574,
            "contradiction": 5.694,
            "irrelevancy": 75.89227,
            "logical_agreement": 18.41373,
            "grammar_ref": 5.6957,
            "grammar_hyp": 5.10116,
            "nubia_score": 0.6222
        },
        "bleurt": 0.11932,
        "meteor": 0.4671869666017637,
        "bertscore": {
            "precision": 0.95378,
            "recall": 0.95364,
            "f1": 0.95371
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.66,
        "total_length": 123,
        "mean_pred_length": 15.375,
        "std_pred_length": 3.838538133196022,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.6016260162601627,
        "vocab_size-1": 74,
        "unique-1": 52,
        "entropy-1": 5.807158891585212,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 100,
        "unique-2": 87,
        "entropy-2": 6.571492007428502,
        "cond_entropy-2": 0.6346187237565929,
        "distinct-3": 0.9065420560747663,
        "vocab_size-3": 97,
        "unique-3": 88,
        "entropy-3": 6.5474960751659665,
        "cond_entropy-3": -0.022201686018336098,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 13.875,
        "std_pred_length-nopunct": 3.295356581616017,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6396396396396397,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.7953721457232605,
        "distinct-2-nopunct": 0.8640776699029126,
        "vocab_size-2-nopunct": 89,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.399997857238312,
        "cond_entropy-2-nopunct": 0.6279984034013942,
        "distinct-3-nopunct": 0.8947368421052632,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.351383108308174,
        "cond_entropy-3-nopunct": -0.03501452409265513,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3076923076923077,
            "2": 0.5405405405405406,
            "3": 0.684931506849315
        },
        "nist": 4.322905304509236,
        "rouge1": {
            "precision": 0.70376,
            "recall": 0.63966,
            "fmeasure": 0.656
        },
        "rouge2": {
            "precision": 0.51084,
            "recall": 0.48177,
            "fmeasure": 0.4862
        },
        "rougeL": {
            "precision": 0.67273,
            "recall": 0.59845,
            "fmeasure": 0.61909
        },
        "rougeLsum": {
            "precision": 0.67273,
            "recall": 0.59845,
            "fmeasure": 0.61909
        },
        "bleu": 43.96385,
        "nubia": {
            "semantic_relation": 3.66292,
            "contradiction": 16.05061,
            "irrelevancy": 51.05786,
            "logical_agreement": 32.89153,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.65069,
            "nubia_score": 0.51694
        },
        "bleurt": 0.03355,
        "meteor": 0.33791525016516144,
        "bertscore": {
            "precision": 0.89336,
            "recall": 0.89623,
            "f1": 0.89318
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 18,
        "unique-1": 14,
        "entropy-1": 4.095795255000932,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.16249647625006503,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.021928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.1813302398882836,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.9473684210526315
        },
        "nist": 4.551092599346497,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.94302,
            "fmeasure": 0.94187
        },
        "rouge2": {
            "precision": 0.82955,
            "recall": 0.82738,
            "fmeasure": 0.82645
        },
        "rougeL": {
            "precision": 0.86111,
            "recall": 0.8661,
            "fmeasure": 0.86187
        },
        "rougeLsum": {
            "precision": 0.86111,
            "recall": 0.8661,
            "fmeasure": 0.86187
        },
        "bleu": 71.86396,
        "nubia": {
            "semantic_relation": 4.32003,
            "contradiction": 0.83699,
            "irrelevancy": 33.64486,
            "logical_agreement": 65.51815,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.45233,
            "nubia_score": 0.76298
        },
        "bleurt": 0.45879,
        "meteor": 0.5142718038025831,
        "bertscore": {
            "precision": 0.96381,
            "recall": 0.96066,
            "f1": 0.95958
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.9
        },
        "nist": 3.0672195651947667,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.75524,
            "fmeasure": 0.7513
        },
        "rouge2": {
            "precision": 0.45455,
            "recall": 0.45833,
            "fmeasure": 0.45549
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.75524,
            "fmeasure": 0.7513
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.75524,
            "fmeasure": 0.7513
        },
        "bleu": 32.00286,
        "nubia": {
            "semantic_relation": 4.4298,
            "contradiction": 0.39833,
            "irrelevancy": 97.5067,
            "logical_agreement": 2.09498,
            "grammar_ref": 4.75081,
            "grammar_hyp": 4.66009,
            "nubia_score": 0.77698
        },
        "bleurt": 0.45819,
        "meteor": 0.4882741674837447,
        "bertscore": {
            "precision": 0.93177,
            "recall": 0.9456,
            "f1": 0.93801
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.8387096774193549,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.607264455478377,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.13671183998771325,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.02901941889002935,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.494680368408909,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.15288816155131352,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5238095238095238
        },
        "nist": 1.720716130457608,
        "rouge1": {
            "precision": 0.4359,
            "recall": 0.5406,
            "fmeasure": 0.47424
        },
        "rouge2": {
            "precision": 0.20238,
            "recall": 0.22489,
            "fmeasure": 0.2099
        },
        "rougeL": {
            "precision": 0.39744,
            "recall": 0.50305,
            "fmeasure": 0.43625
        },
        "rougeLsum": {
            "precision": 0.39744,
            "recall": 0.50305,
            "fmeasure": 0.43625
        },
        "bleu": 12.09818,
        "nubia": {
            "semantic_relation": 3.6343,
            "contradiction": 0.61121,
            "irrelevancy": 36.30957,
            "logical_agreement": 63.07922,
            "grammar_ref": 5.01983,
            "grammar_hyp": 4.63217,
            "nubia_score": 0.4903
        },
        "bleurt": 0.06749,
        "meteor": 0.2696204081971998,
        "bertscore": {
            "precision": 0.86837,
            "recall": 0.89117,
            "f1": 0.87955
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 20,
        "distinct-1": 0.46551724137931033,
        "vocab_size-1": 27,
        "unique-1": 12,
        "entropy-1": 4.486448667168353,
        "distinct-2": 0.7090909090909091,
        "vocab_size-2": 39,
        "unique-2": 28,
        "entropy-2": 5.13091539514616,
        "cond_entropy-2": 0.6328250821907946,
        "distinct-3": 0.75,
        "vocab_size-3": 39,
        "unique-3": 30,
        "entropy-3": 5.142371448743904,
        "cond_entropy-3": 0.048981687350345374,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.5102040816326531,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.404827956051039,
        "distinct-2-nopunct": 0.6956521739130435,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.849223912390624,
        "cond_entropy-2-nopunct": 0.5015621664307263,
        "distinct-3-nopunct": 0.7441860465116279,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.8619702778069716,
        "cond_entropy-3-nopunct": 0.03653739171865395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.8666666666666667
        },
        "nist": 5.02866849448459,
        "rouge1": {
            "precision": 0.89951,
            "recall": 0.84577,
            "fmeasure": 0.86812
        },
        "rouge2": {
            "precision": 0.70046,
            "recall": 0.68004,
            "fmeasure": 0.68788
        },
        "rougeL": {
            "precision": 0.73284,
            "recall": 0.69274,
            "fmeasure": 0.70928
        },
        "rougeLsum": {
            "precision": 0.73284,
            "recall": 0.69274,
            "fmeasure": 0.70928
        },
        "bleu": 68.96422,
        "nubia": {
            "semantic_relation": 3.97742,
            "contradiction": 32.01404,
            "irrelevancy": 29.86972,
            "logical_agreement": 38.11624,
            "grammar_ref": 4.73012,
            "grammar_hyp": 5.11993,
            "nubia_score": 0.59669
        },
        "bleurt": 0.2838,
        "meteor": 0.4766932518035744,
        "bertscore": {
            "precision": 0.9594,
            "recall": 0.94847,
            "f1": 0.94816
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75
        },
        "nist": 1.9481518726417577,
        "rouge1": {
            "precision": 0.53125,
            "recall": 0.74242,
            "fmeasure": 0.61905
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.47727,
            "fmeasure": 0.39231
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.52273,
            "fmeasure": 0.43651
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.52273,
            "fmeasure": 0.43651
        },
        "bleu": 19.56475,
        "nubia": {
            "semantic_relation": 4.08725,
            "contradiction": 0.07178,
            "irrelevancy": 97.71184,
            "logical_agreement": 2.21638,
            "grammar_ref": 5.10481,
            "grammar_hyp": 4.92933,
            "nubia_score": 0.65281
        },
        "bleurt": 0.17158,
        "meteor": 0.3999094844838074,
        "bertscore": {
            "precision": 0.87385,
            "recall": 0.92622,
            "f1": 0.89927
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.6
        },
        "nist": 2.052319092186461,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.52083,
            "fmeasure": 0.50769
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.1,
            "fmeasure": 0.09091
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.45833,
            "fmeasure": 0.44103
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.45833,
            "fmeasure": 0.44103
        },
        "bleu": 16.51582,
        "nubia": {
            "semantic_relation": 4.61687,
            "contradiction": 1.0095,
            "irrelevancy": 0.94988,
            "logical_agreement": 98.04062,
            "grammar_ref": 7.18676,
            "grammar_hyp": 7.70787,
            "nubia_score": 0.80911
        },
        "bleurt": 0.08663,
        "meteor": 0.3860617816344823,
        "bertscore": {
            "precision": 0.91561,
            "recall": 0.89761,
            "f1": 0.90652
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 4.423065265165703,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "bleurt": 0.94038,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.6666666666666666,
            "3": 0.375
        },
        "nist": 1.6197310645472072,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.75,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.20875,
            "fmeasure": 0.15018
        },
        "rougeL": {
            "precision": 0.27778,
            "recall": 0.47222,
            "fmeasure": 0.34921
        },
        "rougeLsum": {
            "precision": 0.27778,
            "recall": 0.47222,
            "fmeasure": 0.34921
        },
        "bleu": 5.726,
        "nubia": {
            "semantic_relation": 3.11165,
            "contradiction": 22.036,
            "irrelevancy": 76.06225,
            "logical_agreement": 1.90174,
            "grammar_ref": 4.40566,
            "grammar_hyp": 4.60156,
            "nubia_score": 0.35106
        },
        "bleurt": -0.09485,
        "meteor": 0.2583597606745811,
        "bertscore": {
            "precision": 0.76886,
            "recall": 0.82113,
            "f1": 0.79194
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.2857142857142857
        },
        "nist": 1.5306625155282125,
        "rouge1": {
            "precision": 0.23077,
            "recall": 0.23077,
            "fmeasure": 0.23077
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.08333,
            "fmeasure": 0.08333
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.23077,
            "fmeasure": 0.23077
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.23077,
            "fmeasure": 0.23077
        },
        "bleu": 8.4931,
        "nubia": {
            "semantic_relation": 1.46451,
            "contradiction": 4.39456,
            "irrelevancy": 85.38399,
            "logical_agreement": 10.22145,
            "grammar_ref": 4.12033,
            "grammar_hyp": 4.96045,
            "nubia_score": 0.09994
        },
        "bleurt": -0.83706,
        "meteor": 0.09423415101120709,
        "bertscore": {
            "precision": 0.74073,
            "recall": 0.69739,
            "f1": 0.7184
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.6363636363636364
        },
        "nist": 2.7441487405552323,
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.61667,
            "fmeasure": 0.53565
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.29121,
            "fmeasure": 0.25202
        },
        "rougeL": {
            "precision": 0.42105,
            "recall": 0.54762,
            "fmeasure": 0.47594
        },
        "rougeLsum": {
            "precision": 0.42105,
            "recall": 0.54762,
            "fmeasure": 0.47594
        },
        "bleu": 31.22226,
        "nubia": {
            "semantic_relation": 3.89633,
            "contradiction": 80.11743,
            "irrelevancy": 14.52354,
            "logical_agreement": 5.35903,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.43626,
            "nubia_score": 0.62816
        },
        "bleurt": 0.22982,
        "meteor": 0.35948083682742965,
        "bertscore": {
            "precision": 0.89165,
            "recall": 0.93249,
            "f1": 0.91161
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 2.5,
        "median_pred_length": 12.5,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.453660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.051382820642878885,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.8947368421052632
        },
        "nist": 3.941506593645461,
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.82593,
            "fmeasure": 0.84259
        },
        "rouge2": {
            "precision": 0.72917,
            "recall": 0.70238,
            "fmeasure": 0.71212
        },
        "rougeL": {
            "precision": 0.75926,
            "recall": 0.72963,
            "fmeasure": 0.74074
        },
        "rougeLsum": {
            "precision": 0.75926,
            "recall": 0.72963,
            "fmeasure": 0.74074
        },
        "bleu": 71.29276,
        "nubia": {
            "semantic_relation": 4.36634,
            "contradiction": 0.37159,
            "irrelevancy": 0.59003,
            "logical_agreement": 99.03839,
            "grammar_ref": 4.70186,
            "grammar_hyp": 5.14226,
            "nubia_score": 0.74643
        },
        "bleurt": 0.52796,
        "meteor": 0.494331701675106,
        "bertscore": {
            "precision": 0.96812,
            "recall": 0.94619,
            "f1": 0.95344
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.42857142857142855
        },
        "nist": 1.3672678641955807,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.35714,
            "fmeasure": 0.41667
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.07692,
            "fmeasure": 0.09091
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.27937,
            "fmeasure": 0.32889
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.27937,
            "fmeasure": 0.32889
        },
        "bleu": 6.85739,
        "nubia": {
            "semantic_relation": 3.04547,
            "contradiction": 0.2656,
            "irrelevancy": 99.4872,
            "logical_agreement": 0.2472,
            "grammar_ref": 3.90604,
            "grammar_hyp": 4.69627,
            "nubia_score": 0.31304
        },
        "bleurt": -0.46966,
        "meteor": 0.1873721662384854,
        "bertscore": {
            "precision": 0.7632,
            "recall": 0.77408,
            "f1": 0.7686
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 6.182412330330469,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.6938775510204082,
        "vocab_size-1": 34,
        "unique-1": 24,
        "entropy-1": 4.88798248749405,
        "distinct-2": 0.9347826086956522,
        "vocab_size-2": 43,
        "unique-2": 40,
        "entropy-2": 5.393127173448314,
        "cond_entropy-2": 0.5090616874730393,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 42,
        "unique-3": 41,
        "entropy-3": 5.379753126795121,
        "cond_entropy-3": -0.0042739455409616465,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 6.182412330330469,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.79291759791708,
        "distinct-2-nopunct": 0.9302325581395349,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.286729870981167,
        "cond_entropy-2-nopunct": 0.49827583293431293,
        "distinct-3-nopunct": 0.975,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.271928094887364,
        "cond_entropy-3-nopunct": -0.029336659814735815,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7741935483870968
        },
        "nist": 3.184927115121055,
        "rouge1": {
            "precision": 0.71556,
            "recall": 0.8165,
            "fmeasure": 0.74094
        },
        "rouge2": {
            "precision": 0.62037,
            "recall": 0.67273,
            "fmeasure": 0.62999
        },
        "rougeL": {
            "precision": 0.68889,
            "recall": 0.75926,
            "fmeasure": 0.70457
        },
        "rougeLsum": {
            "precision": 0.68889,
            "recall": 0.75926,
            "fmeasure": 0.70457
        },
        "bleu": 43.73623,
        "nubia": {
            "semantic_relation": 4.41713,
            "contradiction": 0.49506,
            "irrelevancy": 33.14802,
            "logical_agreement": 66.35692,
            "grammar_ref": 3.77014,
            "grammar_hyp": 4.18627,
            "nubia_score": 0.67598
        },
        "bleurt": 0.34418,
        "meteor": 0.42492630078393456,
        "bertscore": {
            "precision": 0.92065,
            "recall": 0.93753,
            "f1": 0.92821
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.0
        },
        "nist": 0.4404554792394883,
        "rouge1": {
            "precision": 0.27778,
            "recall": 0.11364,
            "fmeasure": 0.16129
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.02381,
            "fmeasure": 0.03448
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.09091,
            "fmeasure": 0.12903
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.09091,
            "fmeasure": 0.12903
        },
        "bleu": 5.89152,
        "nubia": {
            "semantic_relation": 1.6254,
            "contradiction": 78.63427,
            "irrelevancy": 18.26297,
            "logical_agreement": 3.10276,
            "grammar_ref": 3.66593,
            "grammar_hyp": 6.38876,
            "nubia_score": 0.09139
        },
        "bleurt": -1.08598,
        "meteor": 0.11695952799266258,
        "bertscore": {
            "precision": 0.82284,
            "recall": 0.7635,
            "f1": 0.79206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 16.0,
        "min_pred_length": 15,
        "max_pred_length": 21,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.180832987205442,
        "distinct-2": 0.9795918367346939,
        "vocab_size-2": 48,
        "unique-2": 47,
        "entropy-2": 5.5738935175845965,
        "cond_entropy-2": 0.32783466692290014,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.04766962718863017,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 1.8856180831641267,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.039547553742002,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.379753126795121,
        "cond_entropy-2-nopunct": 0.3739740197262572,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 40,
        "entropy-3-nopunct": 5.3219280948873635,
        "cond_entropy-3-nopunct": -0.0543366598147358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.55,
            "2": 0.7222222222222222,
            "3": 0.7222222222222222
        },
        "nist": 4.4421532128999495,
        "rouge1": {
            "precision": 0.74478,
            "recall": 0.72671,
            "fmeasure": 0.7263
        },
        "rouge2": {
            "precision": 0.5169,
            "recall": 0.5085,
            "fmeasure": 0.50463
        },
        "rougeL": {
            "precision": 0.63988,
            "recall": 0.629,
            "fmeasure": 0.6259
        },
        "rougeLsum": {
            "precision": 0.63988,
            "recall": 0.629,
            "fmeasure": 0.6259
        },
        "bleu": 46.59422,
        "nubia": {
            "semantic_relation": 4.05497,
            "contradiction": 7.19309,
            "irrelevancy": 74.8339,
            "logical_agreement": 17.97301,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.72289,
            "nubia_score": 0.61883
        },
        "bleurt": -0.07865,
        "meteor": 0.37228267580551766,
        "bertscore": {
            "precision": 0.92139,
            "recall": 0.91295,
            "f1": 0.91411
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "nist": 2.344871875614832,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.93333,
            "fmeasure": 0.81212
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.92593,
            "fmeasure": 0.75185
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.93333,
            "fmeasure": 0.81212
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.93333,
            "fmeasure": 0.81212
        },
        "bleu": 26.13023,
        "nubia": {
            "semantic_relation": 4.31277,
            "contradiction": 0.16629,
            "irrelevancy": 33.60335,
            "logical_agreement": 66.23036,
            "grammar_ref": 3.90726,
            "grammar_hyp": 3.13333,
            "nubia_score": 0.90556
        },
        "bleurt": 0.39992,
        "meteor": 0.5450030037868164,
        "bertscore": {
            "precision": 0.93015,
            "recall": 0.9654,
            "f1": 0.94076
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.0,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.7941176470588235,
        "vocab_size-1": 27,
        "unique-1": 20,
        "entropy-1": 4.675698135367986,
        "distinct-2": 0.96875,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.9375,
        "cond_entropy-2": 0.2562871587496607,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.02644273772481478,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.78125,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.5625,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.27355726227518523,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.02810710212234293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.4
        },
        "nist": 1.9346076906600387,
        "rouge1": {
            "precision": 0.48007,
            "recall": 0.67873,
            "fmeasure": 0.56123
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.4212,
            "fmeasure": 0.33091
        },
        "rougeL": {
            "precision": 0.4221,
            "recall": 0.61806,
            "fmeasure": 0.50134
        },
        "rougeLsum": {
            "precision": 0.4221,
            "recall": 0.61806,
            "fmeasure": 0.50134
        },
        "bleu": 12.88615,
        "nubia": {
            "semantic_relation": 3.70906,
            "contradiction": 1.25682,
            "irrelevancy": 70.42428,
            "logical_agreement": 28.31891,
            "grammar_ref": 4.27476,
            "grammar_hyp": 4.14502,
            "nubia_score": 0.59391
        },
        "bleurt": -0.03166,
        "meteor": 0.2879930875903859,
        "bertscore": {
            "precision": 0.86842,
            "recall": 0.90253,
            "f1": 0.88496
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.6086956521739131,
        "vocab_size-1": 14,
        "unique-1": 5,
        "entropy-1": 3.7409532604048397,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 17,
        "unique-2": 12,
        "entropy-2": 4.004886164091841,
        "cond_entropy-2": 0.2540514807621027,
        "distinct-3": 0.8095238095238095,
        "vocab_size-3": 17,
        "unique-3": 13,
        "entropy-3": 4.011365041826378,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.5219280948873624,
        "distinct-2-nopunct": 0.7368421052631579,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.7216117239699003,
        "cond_entropy-2-nopunct": 0.18915731329306532,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.7254805569978675,
        "cond_entropy-3-nopunct": 0.03310859910983795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.1
        },
        "nist": 0.6335579050160076,
        "rouge1": {
            "precision": 0.05,
            "recall": 0.08838,
            "fmeasure": 0.06384
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.05,
            "recall": 0.08838,
            "fmeasure": 0.06384
        },
        "rougeLsum": {
            "precision": 0.05,
            "recall": 0.08838,
            "fmeasure": 0.06384
        },
        "bleu": 3.91645,
        "nubia": {
            "semantic_relation": 2.75994,
            "contradiction": 28.47583,
            "irrelevancy": 9.61522,
            "logical_agreement": 61.90895,
            "grammar_ref": 5.20931,
            "grammar_hyp": 4.11829,
            "nubia_score": 0.44355
        },
        "bleurt": -0.88431,
        "meteor": 0.07967252921724187,
        "bertscore": {
            "precision": 0.68063,
            "recall": 0.66388,
            "f1": 0.6686
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 72,
        "mean_pred_length": 18.0,
        "std_pred_length": 7.0710678118654755,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 48,
        "unique-1": 33,
        "entropy-1": 5.376599786459485,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 64,
        "unique-2": 60,
        "entropy-2": 5.969815782426816,
        "cond_entropy-2": 0.5369410086133759,
        "distinct-3": 0.984375,
        "vocab_size-3": 63,
        "unique-3": 62,
        "entropy-3": 5.96875,
        "cond_entropy-3": 0.00628715874966059,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 6.456585785072479,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6825396825396826,
        "vocab_size-1-nopunct": 43,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.229352693678271,
        "distinct-2-nopunct": 0.9322033898305084,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.7470498290228536,
        "cond_entropy-2-nopunct": 0.5345057610952088,
        "distinct-3-nopunct": 0.9818181818181818,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.744996077161019,
        "cond_entropy-3-nopunct": -0.010374244928090796,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.25925925925925924,
            "3": 0.4827586206896552
        },
        "nist": 3.0571892330227914,
        "rouge1": {
            "precision": 0.54594,
            "recall": 0.40115,
            "fmeasure": 0.4322
        },
        "rouge2": {
            "precision": 0.24321,
            "recall": 0.20128,
            "fmeasure": 0.20627
        },
        "rougeL": {
            "precision": 0.34604,
            "recall": 0.33296,
            "fmeasure": 0.3351
        },
        "rougeLsum": {
            "precision": 0.34604,
            "recall": 0.33296,
            "fmeasure": 0.3351
        },
        "bleu": 22.49062,
        "nubia": {
            "semantic_relation": 3.90392,
            "contradiction": 2.00353,
            "irrelevancy": 68.22642,
            "logical_agreement": 29.77004,
            "grammar_ref": 5.44243,
            "grammar_hyp": 5.8742,
            "nubia_score": 0.56045
        },
        "bleurt": -0.33696,
        "meteor": 0.20145477318823451,
        "bertscore": {
            "precision": 0.86239,
            "recall": 0.837,
            "f1": 0.84206
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6153846153846154
        },
        "nist": 2.0002547821687853,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.56667,
            "fmeasure": 0.64444
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.27381,
            "fmeasure": 0.3121
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.45359,
            "fmeasure": 0.51
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.45359,
            "fmeasure": 0.51
        },
        "bleu": 26.73141,
        "nubia": {
            "semantic_relation": 4.25158,
            "contradiction": 0.19944,
            "irrelevancy": 30.21846,
            "logical_agreement": 69.58211,
            "grammar_ref": 4.4151,
            "grammar_hyp": 5.84129,
            "nubia_score": 0.55865
        },
        "bleurt": -0.02023,
        "meteor": 0.3097565583127413,
        "bertscore": {
            "precision": 0.91426,
            "recall": 0.89295,
            "f1": 0.90348
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.42857142857142855
        },
        "nist": 1.7352722232246318,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.12037,
            "fmeasure": 0.11547
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.4,
            "fmeasure": 0.4
        },
        "bleu": 6.27466,
        "nubia": {
            "semantic_relation": 4.6046,
            "contradiction": 0.28771,
            "irrelevancy": 0.46039,
            "logical_agreement": 99.25189,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.7947,
            "nubia_score": 0.9374
        },
        "bleurt": 0.5085,
        "meteor": 0.2494115916069732,
        "bertscore": {
            "precision": 0.90651,
            "recall": 0.89766,
            "f1": 0.90207
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.4375
        },
        "nist": 1.5832107567081308,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.42892,
            "fmeasure": 0.49425
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.19583,
            "fmeasure": 0.22792
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.30637,
            "fmeasure": 0.35304
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.30637,
            "fmeasure": 0.35304
        },
        "bleu": 13.76604,
        "nubia": {
            "semantic_relation": 3.50089,
            "contradiction": 23.92183,
            "irrelevancy": 15.12011,
            "logical_agreement": 60.95806,
            "grammar_ref": 4.86284,
            "grammar_hyp": 6.73573,
            "nubia_score": 0.30414
        },
        "bleurt": -0.35238,
        "meteor": 0.24898276606694492,
        "bertscore": {
            "precision": 0.84632,
            "recall": 0.84624,
            "f1": 0.8462
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 4.766329012715601,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.83419,
            "fmeasure": 0.87546
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6627,
            "fmeasure": 0.70299
        },
        "rougeL": {
            "precision": 0.87179,
            "recall": 0.78291,
            "fmeasure": 0.82418
        },
        "rougeLsum": {
            "precision": 0.87179,
            "recall": 0.78291,
            "fmeasure": 0.82418
        },
        "bleu": 81.42442,
        "nubia": {
            "semantic_relation": 4.94744,
            "contradiction": 0.308,
            "irrelevancy": 0.49541,
            "logical_agreement": 99.1966,
            "grammar_ref": 4.20051,
            "grammar_hyp": 4.4586,
            "nubia_score": 0.95267
        },
        "bleurt": 0.59254,
        "meteor": 0.4894845842304888,
        "bertscore": {
            "precision": 0.98573,
            "recall": 0.95537,
            "f1": 0.96627
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 28,
        "unique-1": 22,
        "entropy-1": 4.6067557245856845,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.5432343762376237,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.433153646184957,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.9837880587523955,
        "cond_entropy-2-nopunct": 0.5928240714013739,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.025681679939320114,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.6333333333333333
        },
        "nist": 3.429128651912793,
        "rouge1": {
            "precision": 0.78595,
            "recall": 0.67778,
            "fmeasure": 0.7118
        },
        "rouge2": {
            "precision": 0.5576,
            "recall": 0.51743,
            "fmeasure": 0.52685
        },
        "rougeL": {
            "precision": 0.63998,
            "recall": 0.61561,
            "fmeasure": 0.62124
        },
        "rougeLsum": {
            "precision": 0.63998,
            "recall": 0.61561,
            "fmeasure": 0.62124
        },
        "bleu": 41.28211,
        "nubia": {
            "semantic_relation": 4.20372,
            "contradiction": 1.8052,
            "irrelevancy": 48.07116,
            "logical_agreement": 50.12365,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.30587,
            "nubia_score": 0.6997
        },
        "bleurt": -0.21739,
        "meteor": 0.283905174703537,
        "bertscore": {
            "precision": 0.88864,
            "recall": 0.85669,
            "f1": 0.86693
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9565217391304348,
        "vocab_size-1": 22,
        "unique-1": 21,
        "entropy-1": 4.436605434317882,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.026778753489375348,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.026778753489375348,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.5,
            "3": 0.75
        },
        "nist": 1.0760229597015292,
        "rouge1": {
            "precision": 0.26389,
            "recall": 0.58889,
            "fmeasure": 0.35043
        },
        "rouge2": {
            "precision": 0.11594,
            "recall": 0.27619,
            "fmeasure": 0.15573
        },
        "rougeL": {
            "precision": 0.19444,
            "recall": 0.82222,
            "fmeasure": 0.31418
        },
        "rougeLsum": {
            "precision": 0.19444,
            "recall": 0.82222,
            "fmeasure": 0.31418
        },
        "bleu": 4.69944,
        "nubia": {
            "semantic_relation": 3.73597,
            "contradiction": 0.08168,
            "irrelevancy": 99.75537,
            "logical_agreement": 0.16295,
            "grammar_ref": 5.27628,
            "grammar_hyp": 3.99904,
            "nubia_score": 0.39954
        },
        "bleurt": -0.38744,
        "meteor": 0.2690351444652819,
        "bertscore": {
            "precision": 0.78871,
            "recall": 0.9429,
            "f1": 0.83431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.6666666666666666,
            "3": 0.6428571428571429
        },
        "nist": 4.31313668368312,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.67677,
            "fmeasure": 0.70383
        },
        "rouge2": {
            "precision": 0.5614,
            "recall": 0.5254,
            "fmeasure": 0.54274
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.58153,
            "fmeasure": 0.60627
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.58153,
            "fmeasure": 0.60627
        },
        "bleu": 53.06728,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.19981,
            "irrelevancy": 0.77725,
            "logical_agreement": 99.02295,
            "grammar_ref": 3.4928,
            "grammar_hyp": 3.51366,
            "nubia_score": 0.99625
        },
        "bleurt": 0.60312,
        "meteor": 0.5583075251357223,
        "bertscore": {
            "precision": 0.97322,
            "recall": 0.96544,
            "f1": 0.96931
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "nist": 4.507537764567106,
        "rouge1": {
            "precision": 0.89583,
            "recall": 0.82143,
            "fmeasure": 0.8536
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.73333,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.75794,
            "fmeasure": 0.78153
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.75794,
            "fmeasure": 0.78153
        },
        "bleu": 78.25423,
        "nubia": {
            "semantic_relation": 4.09191,
            "contradiction": 0.50894,
            "irrelevancy": 46.14429,
            "logical_agreement": 53.34677,
            "grammar_ref": 3.89472,
            "grammar_hyp": 3.99105,
            "nubia_score": 0.7335
        },
        "bleurt": 0.14151,
        "meteor": 0.5511445391114351,
        "bertscore": {
            "precision": 0.96642,
            "recall": 0.96589,
            "f1": 0.96615
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.7,
        "vocab_size-1": 14,
        "unique-1": 8,
        "entropy-1": 3.721928094887362,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.29244135099939467,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.7222222222222222,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.6143694458867563,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.26757499855768774,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5
        },
        "nist": 1.6330477591954435,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.57407,
            "fmeasure": 0.664
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.32335,
            "fmeasure": 0.37179
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.54398,
            "fmeasure": 0.62646
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.54398,
            "fmeasure": 0.62646
        },
        "bleu": 11.13513,
        "nubia": {
            "semantic_relation": 4.2325,
            "contradiction": 0.44456,
            "irrelevancy": 1.46299,
            "logical_agreement": 98.09244,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.39552,
            "nubia_score": 0.77977
        },
        "bleurt": 0.43157,
        "meteor": 0.335157039206657,
        "bertscore": {
            "precision": 0.921,
            "recall": 0.87602,
            "f1": 0.89756
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 2.8483609718589222,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21732,
            "irrelevancy": 0.45505,
            "logical_agreement": 99.32763,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.46881,
            "nubia_score": 0.9943
        },
        "bleurt": 0.96931,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 4.065799943973496,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.94444,
            "fmeasure": 0.91546
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.90909,
            "fmeasure": 0.87734
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 0.94444,
            "fmeasure": 0.91546
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 0.94444,
            "fmeasure": 0.91546
        },
        "bleu": 80.70557,
        "nubia": {
            "semantic_relation": 4.7231,
            "contradiction": 0.31115,
            "irrelevancy": 18.74911,
            "logical_agreement": 80.93974,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.4859,
            "nubia_score": 0.79728
        },
        "bleurt": 0.4329,
        "meteor": 0.5538043848309318,
        "bertscore": {
            "precision": 0.97728,
            "recall": 0.99134,
            "f1": 0.98426
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.7142857142857143
        },
        "nist": 1.0922883679202227,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.62092,
            "fmeasure": 0.71059
        },
        "rouge2": {
            "precision": 0.64286,
            "recall": 0.46875,
            "fmeasure": 0.53043
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.5915,
            "fmeasure": 0.67059
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.5915,
            "fmeasure": 0.67059
        },
        "bleu": 42.50084,
        "nubia": {
            "semantic_relation": 3.62021,
            "contradiction": 2.98151,
            "irrelevancy": 2.35298,
            "logical_agreement": 94.66551,
            "grammar_ref": 5.6106,
            "grammar_hyp": 5.26749,
            "nubia_score": 0.53996
        },
        "bleurt": -0.00889,
        "meteor": 0.4305278436099791,
        "bertscore": {
            "precision": 0.94405,
            "recall": 0.9129,
            "f1": 0.92821
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.18181818181818182,
            "3": 0.3333333333333333
        },
        "nist": 0.12486065344110399,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.29623,
            "fmeasure": 0.41616
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.13258,
            "fmeasure": 0.18964
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.21159,
            "fmeasure": 0.29726
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.21159,
            "fmeasure": 0.29726
        },
        "bleu": 5.02178,
        "nubia": {
            "semantic_relation": 0.82665,
            "contradiction": 27.71673,
            "irrelevancy": 71.38742,
            "logical_agreement": 0.89585,
            "grammar_ref": 3.96534,
            "grammar_hyp": 3.65931,
            "nubia_score": 0.06263
        },
        "bleurt": -0.93953,
        "meteor": 0.12970441077325173,
        "bertscore": {
            "precision": 0.87773,
            "recall": 0.78945,
            "f1": 0.83125
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.6129032258064516,
        "vocab_size-1": 19,
        "unique-1": 10,
        "entropy-1": 4.106949132758152,
        "distinct-2": 0.896551724137931,
        "vocab_size-2": 26,
        "unique-2": 23,
        "entropy-2": 4.651084443403434,
        "cond_entropy-2": 0.5336006332403662,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.6808134280893965,
        "cond_entropy-3": 0.045054655184044744,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6071428571428571,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.940759832540089,
        "distinct-2-nopunct": 0.8846153846153846,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.46967048737186,
        "cond_entropy-2-nopunct": 0.5571102771023495,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.501629167387823,
        "cond_entropy-3-nopunct": 0.05118944924673078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.25,
            "3": 0.9333333333333333
        },
        "nist": 3.2747582306338696,
        "rouge1": {
            "precision": 0.64426,
            "recall": 0.78431,
            "fmeasure": 0.6921
        },
        "rouge2": {
            "precision": 0.48157,
            "recall": 0.57802,
            "fmeasure": 0.51385
        },
        "rougeL": {
            "precision": 0.61485,
            "recall": 0.82003,
            "fmeasure": 0.67866
        },
        "rougeLsum": {
            "precision": 0.61485,
            "recall": 0.82003,
            "fmeasure": 0.67866
        },
        "bleu": 36.76609,
        "nubia": {
            "semantic_relation": 3.87267,
            "contradiction": 12.76427,
            "irrelevancy": 38.47306,
            "logical_agreement": 48.76266,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.40127,
            "nubia_score": 0.54401
        },
        "bleurt": 0.16979,
        "meteor": 0.4623483800617731,
        "bertscore": {
            "precision": 0.87018,
            "recall": 0.95906,
            "f1": 0.90017
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 23,
        "entropy-1": 4.696131794257844,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.11068123646483499,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9259259259259259,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.606739354015323,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.04896868761125604,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "nist": 2.9259547715771306,
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.63187,
            "fmeasure": 0.61287
        },
        "rouge2": {
            "precision": 0.34615,
            "recall": 0.36752,
            "fmeasure": 0.35641
        },
        "rougeL": {
            "precision": 0.55952,
            "recall": 0.59341,
            "fmeasure": 0.57584
        },
        "rougeLsum": {
            "precision": 0.55952,
            "recall": 0.59341,
            "fmeasure": 0.57584
        },
        "bleu": 32.35486,
        "nubia": {
            "semantic_relation": 4.04907,
            "contradiction": 0.76435,
            "irrelevancy": 97.93046,
            "logical_agreement": 1.30519,
            "grammar_ref": 4.47266,
            "grammar_hyp": 4.42281,
            "nubia_score": 0.70455
        },
        "bleurt": -0.10605,
        "meteor": 0.33938680988132247,
        "bertscore": {
            "precision": 0.88679,
            "recall": 0.902,
            "f1": 0.89432
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 0.9782567700931432,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.81481,
            "fmeasure": 0.8642
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.76471,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.81481,
            "fmeasure": 0.8642
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.81481,
            "fmeasure": 0.8642
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.42127,
            "contradiction": 0.1348,
            "irrelevancy": 0.45863,
            "logical_agreement": 99.40657,
            "grammar_ref": 4.62828,
            "grammar_hyp": 6.42175,
            "nubia_score": 0.6405
        },
        "bleurt": 0.384,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 6.0,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.548394345536403,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.2845674515263524,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8275862068965517,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.487122805397797,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.29523567378269167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.35294117647058826,
            "3": 0.6071428571428571
        },
        "nist": 1.825560357197096,
        "rouge1": {
            "precision": 0.97826,
            "recall": 0.59023,
            "fmeasure": 0.67681
        },
        "rouge2": {
            "precision": 0.66883,
            "recall": 0.48593,
            "fmeasure": 0.52703
        },
        "rougeL": {
            "precision": 0.76993,
            "recall": 0.5701,
            "fmeasure": 0.62738
        },
        "rougeLsum": {
            "precision": 0.76993,
            "recall": 0.5701,
            "fmeasure": 0.62738
        },
        "bleu": 52.86382,
        "nubia": {
            "semantic_relation": 3.74372,
            "contradiction": 48.96782,
            "irrelevancy": 1.59824,
            "logical_agreement": 49.43394,
            "grammar_ref": 3.63495,
            "grammar_hyp": 4.5689,
            "nubia_score": 0.48968
        },
        "bleurt": 0.21997,
        "meteor": 0.3782746503795795,
        "bertscore": {
            "precision": 0.9393,
            "recall": 0.88925,
            "f1": 0.90602
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.02961067210860201,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.7857142857142857
        },
        "nist": 4.188113662565427,
        "rouge1": {
            "precision": 0.85965,
            "recall": 0.76944,
            "fmeasure": 0.81057
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.55789,
            "fmeasure": 0.5258
        },
        "rougeL": {
            "precision": 0.5614,
            "recall": 0.625,
            "fmeasure": 0.58999
        },
        "rougeLsum": {
            "precision": 0.5614,
            "recall": 0.625,
            "fmeasure": 0.58999
        },
        "bleu": 48.35897,
        "nubia": {
            "semantic_relation": 4.03256,
            "contradiction": 48.45772,
            "irrelevancy": 37.26386,
            "logical_agreement": 14.27842,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.5366,
            "nubia_score": 0.65176
        },
        "bleurt": -0.16368,
        "meteor": 0.39162424523101574,
        "bertscore": {
            "precision": 0.91233,
            "recall": 0.90362,
            "f1": 0.90661
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.5217391304347826,
        "vocab_size-1": 12,
        "unique-1": 3,
        "entropy-1": 3.4800836951874485,
        "distinct-2": 0.5714285714285714,
        "vocab_size-2": 12,
        "unique-2": 3,
        "entropy-2": 3.5351745656359035,
        "cond_entropy-2": 0.05923165719793805,
        "distinct-3": 0.5789473684210527,
        "vocab_size-3": 11,
        "unique-3": 3,
        "entropy-3": 3.405822250285691,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5238095238095238,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 3.344698375159713,
        "distinct-2-nopunct": 0.5789473684210527,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 3.405822250285691,
        "cond_entropy-2-nopunct": 0.06613640645429873,
        "distinct-3-nopunct": 0.5882352941176471,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 3.2639334294856344,
        "cond_entropy-3-nopunct": -0.16046467219324612,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "nist": 4.375333324538663,
        "rouge1": {
            "precision": 0.91818,
            "recall": 0.94815,
            "fmeasure": 0.93241
        },
        "rouge2": {
            "precision": 0.81852,
            "recall": 0.84491,
            "fmeasure": 0.83098
        },
        "rougeL": {
            "precision": 0.91818,
            "recall": 0.94815,
            "fmeasure": 0.93241
        },
        "rougeLsum": {
            "precision": 0.91818,
            "recall": 0.94815,
            "fmeasure": 0.93241
        },
        "bleu": 86.40174,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.68979,
            "irrelevancy": 0.61255,
            "logical_agreement": 98.69766,
            "grammar_ref": 4.85767,
            "grammar_hyp": 4.90849,
            "nubia_score": 0.93819
        },
        "bleurt": 0.82312,
        "meteor": 0.9836734693877551,
        "bertscore": {
            "precision": 0.98734,
            "recall": 0.98734,
            "f1": 0.98734
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.188721875540867,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.3067316181128199,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.027169118440619,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.3379852264664119,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.625
        },
        "nist": 2.9575049575636045,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.60268,
            "fmeasure": 0.66758
        },
        "rouge2": {
            "precision": 0.59091,
            "recall": 0.46923,
            "fmeasure": 0.52244
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.60268,
            "fmeasure": 0.66758
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.60268,
            "fmeasure": 0.66758
        },
        "bleu": 54.264,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.25728,
            "irrelevancy": 0.43005,
            "logical_agreement": 99.31267,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.42097,
            "nubia_score": 0.99751
        },
        "bleurt": 0.52166,
        "meteor": 0.4006101177585838,
        "bertscore": {
            "precision": 0.97771,
            "recall": 0.94099,
            "f1": 0.959
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 2.3333681836077096,
        "rouge1": {
            "precision": 0.64103,
            "recall": 0.89167,
            "fmeasure": 0.74396
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.68519,
            "fmeasure": 0.55556
        },
        "rougeL": {
            "precision": 0.61538,
            "recall": 0.88571,
            "fmeasure": 0.72174
        },
        "rougeLsum": {
            "precision": 0.61538,
            "recall": 0.88571,
            "fmeasure": 0.72174
        },
        "bleu": 26.58484,
        "nubia": {
            "semantic_relation": 4.79219,
            "contradiction": 0.7683,
            "irrelevancy": 43.40062,
            "logical_agreement": 55.83108,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.57543,
            "nubia_score": 0.96593
        },
        "bleurt": 0.43701,
        "meteor": 0.4120491874241176,
        "bertscore": {
            "precision": 0.96306,
            "recall": 0.94052,
            "f1": 0.95166
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 14,
        "unique-1": 10,
        "entropy-1": 3.681880802803402,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.5194912381189195,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.4548223999466066,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.5222176276348774,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.6666666666666666
        },
        "nist": 3.5801301903663414,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.73789,
            "fmeasure": 0.71746
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.25163,
            "fmeasure": 0.24964
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.5584,
            "fmeasure": 0.50794
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.5584,
            "fmeasure": 0.50794
        },
        "bleu": 9.94905,
        "nubia": {
            "semantic_relation": 4.41748,
            "contradiction": 6.93467,
            "irrelevancy": 40.44028,
            "logical_agreement": 52.62505,
            "grammar_ref": 5.3293,
            "grammar_hyp": 4.86764,
            "nubia_score": 0.74547
        },
        "bleurt": 0.06073,
        "meteor": 0.327568200764044,
        "bertscore": {
            "precision": 0.9423,
            "recall": 0.94019,
            "f1": 0.93925
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2221,
        "msttr-100": 0.72933,
        "msttr-100_nopunct": 0.78604,
        "total_length": 34266,
        "mean_pred_length": 15.428185502026114,
        "std_pred_length": 4.132965374394055,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.25021887585361585,
        "vocab_size-1": 8574,
        "unique-1": 6116,
        "entropy-1": 9.686847390346692,
        "distinct-2": 0.661975347168045,
        "vocab_size-2": 21213,
        "unique-2": 18460,
        "entropy-2": 13.554506298504553,
        "cond_entropy-2": 3.4933015826553158,
        "distinct-3": 0.8672210300429185,
        "vocab_size-3": 25864,
        "unique-3": 24228,
        "entropy-3": 14.441245910992299,
        "cond_entropy-3": 0.8803985508686784,
        "total_length-nopunct": 29819,
        "mean_pred_length-nopunct": 13.425934263845114,
        "std_pred_length-nopunct": 3.801885014725852,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.28696468694456556,
        "vocab_size-1-nopunct": 8557,
        "unique-1-nopunct": 6116,
        "entropy-1-nopunct": 10.211906533171344,
        "distinct-2-nopunct": 0.7025146749764476,
        "vocab_size-2-nopunct": 19388,
        "unique-2-nopunct": 17234,
        "entropy-2-nopunct": 13.485700763951519,
        "cond_entropy-2-nopunct": 3.4482439223571353,
        "distinct-3-nopunct": 0.8926193009417976,
        "vocab_size-3-nopunct": 22652,
        "unique-3-nopunct": 21435,
        "entropy-3-nopunct": 14.301392167918923,
        "cond_entropy-3-nopunct": 0.8731196551708374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.21846973094170405,
            "2": 0.4664804469273743,
            "3": 0.7954749910039582
        },
        "nist": 10.235438765349707,
        "rouge1": {
            "precision": 0.77028,
            "recall": 0.75739,
            "fmeasure": 0.75368
        },
        "rouge2": {
            "precision": 0.54,
            "recall": 0.53112,
            "fmeasure": 0.5281
        },
        "rougeL": {
            "precision": 0.66557,
            "recall": 0.65715,
            "fmeasure": 0.65239
        },
        "rougeLsum": {
            "precision": 0.66557,
            "recall": 0.65715,
            "fmeasure": 0.65239
        },
        "bleu": 48.43237,
        "nubia": {
            "semantic_relation": 4.31487,
            "contradiction": 7.14077,
            "irrelevancy": 27.03674,
            "logical_agreement": 65.82248,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.78861,
            "nubia_score": 0.75463
        },
        "bleurt": 0.30958,
        "meteor": 0.4075468310968897,
        "bertscore": {
            "precision": 0.93341,
            "recall": 0.93157,
            "f1": 0.9309
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9841837197791885,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.28151981340693205,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8924071185928746,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.2972690158966972,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 0.5555555555555556
        },
        "nist": 3.0334939103126475,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.64198,
            "fmeasure": 0.68146
        },
        "rouge2": {
            "precision": 0.46032,
            "recall": 0.38685,
            "fmeasure": 0.42005
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.44192,
            "fmeasure": 0.44796
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.44192,
            "fmeasure": 0.44796
        },
        "bleu": 20.28996,
        "nubia": {
            "semantic_relation": 4.31709,
            "contradiction": 0.17699,
            "irrelevancy": 33.79864,
            "logical_agreement": 66.02437,
            "grammar_ref": 3.86337,
            "grammar_hyp": 4.32481,
            "nubia_score": 0.74257
        },
        "bleurt": 0.06552,
        "meteor": 0.3620047800024769,
        "bertscore": {
            "precision": 0.93824,
            "recall": 0.90761,
            "f1": 0.92112
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 2.1663918604766343,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.84259,
            "fmeasure": 0.72456
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.27381,
            "fmeasure": 0.23094
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.48148,
            "fmeasure": 0.41404
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.48148,
            "fmeasure": 0.41404
        },
        "bleu": 18.20705,
        "nubia": {
            "semantic_relation": 3.92468,
            "contradiction": 7.85324,
            "irrelevancy": 42.67587,
            "logical_agreement": 49.4709,
            "grammar_ref": 5.1757,
            "grammar_hyp": 5.30761,
            "nubia_score": 0.47337
        },
        "bleurt": -0.34612,
        "meteor": 0.4211106550162908,
        "bertscore": {
            "precision": 0.82565,
            "recall": 0.9154,
            "f1": 0.86821
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 23.5,
        "std_pred_length": 2.5,
        "median_pred_length": 23.5,
        "min_pred_length": 21,
        "max_pred_length": 26,
        "distinct-1": 0.7659574468085106,
        "vocab_size-1": 36,
        "unique-1": 29,
        "entropy-1": 4.9936414479201865,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 42,
        "unique-2": 39,
        "entropy-2": 5.358519762996339,
        "cond_entropy-2": 0.38980931079871006,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 42,
        "unique-3": 41,
        "entropy-3": 5.379753126795121,
        "cond_entropy-3": 0.027434914186376908,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.812814895472355,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.142664355548852,
        "cond_entropy-2-nopunct": 0.3566448916246516,
        "distinct-3-nopunct": 0.9722222222222222,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.114369445886754,
        "cond_entropy-3-nopunct": -0.0224469564457176,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.8,
            "3": 0.6086956521739131
        },
        "nist": 3.7089625137165125,
        "rouge1": {
            "precision": 0.57149,
            "recall": 0.64338,
            "fmeasure": 0.58746
        },
        "rouge2": {
            "precision": 0.30752,
            "recall": 0.39156,
            "fmeasure": 0.33364
        },
        "rougeL": {
            "precision": 0.40033,
            "recall": 0.51398,
            "fmeasure": 0.43342
        },
        "rougeLsum": {
            "precision": 0.40033,
            "recall": 0.51398,
            "fmeasure": 0.43342
        },
        "bleu": 26.30603,
        "nubia": {
            "semantic_relation": 4.18976,
            "contradiction": 0.54234,
            "irrelevancy": 53.31164,
            "logical_agreement": 46.14603,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.88339,
            "nubia_score": 0.75016
        },
        "bleurt": 0.20393,
        "meteor": 0.34357787141474955,
        "bertscore": {
            "precision": 0.87019,
            "recall": 0.93205,
            "f1": 0.89703
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.2857142857142857
        },
        "nist": 1.2393895733558837,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.42803,
            "fmeasure": 0.37302
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.14286,
            "fmeasure": 0.10526
        },
        "rougeL": {
            "precision": 0.28205,
            "recall": 0.36742,
            "fmeasure": 0.31746
        },
        "rougeLsum": {
            "precision": 0.28205,
            "recall": 0.36742,
            "fmeasure": 0.31746
        },
        "bleu": 4.78923,
        "nubia": {
            "semantic_relation": 2.52235,
            "contradiction": 0.3858,
            "irrelevancy": 98.39154,
            "logical_agreement": 1.22266,
            "grammar_ref": 5.51883,
            "grammar_hyp": 4.2974,
            "nubia_score": 0.31583
        },
        "bleurt": -0.43412,
        "meteor": 0.166351606805293,
        "bertscore": {
            "precision": 0.78682,
            "recall": 0.76254,
            "f1": 0.77449
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750188,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.2536119717201712,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.07223329894392083,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7037037037037037
        },
        "nist": 2.6785626098934334,
        "rouge1": {
            "precision": 0.98551,
            "recall": 0.70121,
            "fmeasure": 0.81922
        },
        "rouge2": {
            "precision": 0.9697,
            "recall": 0.68056,
            "fmeasure": 0.79962
        },
        "rougeL": {
            "precision": 0.98551,
            "recall": 0.70121,
            "fmeasure": 0.81922
        },
        "rougeLsum": {
            "precision": 0.98551,
            "recall": 0.70121,
            "fmeasure": 0.81922
        },
        "bleu": 54.77195,
        "nubia": {
            "semantic_relation": 3.31335,
            "contradiction": 4.42979,
            "irrelevancy": 2.12914,
            "logical_agreement": 93.44106,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.61483,
            "nubia_score": 0.49216
        },
        "bleurt": 0.08085,
        "meteor": 0.40311419717249247,
        "bertscore": {
            "precision": 0.97334,
            "recall": 0.87059,
            "f1": 0.9191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.0,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 26,
        "unique-1": 24,
        "entropy-1": 4.664497779200462,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": -0.029992126993435266,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.03600643804015718,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8461538461538461
        },
        "nist": 4.5879545509504105,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.8303,
            "fmeasure": 0.88276
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.56429,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.64848,
            "fmeasure": 0.68276
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.64848,
            "fmeasure": 0.68276
        },
        "bleu": 67.38385,
        "nubia": {
            "semantic_relation": 4.81454,
            "contradiction": 0.15777,
            "irrelevancy": 1.31703,
            "logical_agreement": 98.52521,
            "grammar_ref": 3.76682,
            "grammar_hyp": 4.24877,
            "nubia_score": 0.9378
        },
        "bleurt": 0.60065,
        "meteor": 0.4698116464815166,
        "bertscore": {
            "precision": 0.96956,
            "recall": 0.95188,
            "f1": 0.96063
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 2.5,
        "median_pred_length": 16.5,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 22,
        "unique-1": 13,
        "entropy-1": 4.317121392085727,
        "distinct-2": 0.7741935483870968,
        "vocab_size-2": 24,
        "unique-2": 17,
        "entropy-2": 4.50258340716107,
        "cond_entropy-2": 0.16786670715745416,
        "distinct-3": 0.8275862068965517,
        "vocab_size-3": 24,
        "unique-3": 19,
        "entropy-3": 4.513153408920675,
        "cond_entropy-3": 0.04171571922345565,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.173557262275185,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 4.307354922057605,
        "cond_entropy-2-nopunct": 0.1861786121633713,
        "distinct-3-nopunct": 0.8076923076923077,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.315824333525706,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.75,
            "3": 0.8260869565217391
        },
        "nist": 4.310597822875767,
        "rouge1": {
            "precision": 0.90278,
            "recall": 0.90165,
            "fmeasure": 0.90135
        },
        "rouge2": {
            "precision": 0.82175,
            "recall": 0.82039,
            "fmeasure": 0.82016
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.72536,
            "fmeasure": 0.71635
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.72536,
            "fmeasure": 0.71635
        },
        "bleu": 70.31217,
        "nubia": {
            "semantic_relation": 4.33045,
            "contradiction": 0.43376,
            "irrelevancy": 30.1858,
            "logical_agreement": 69.38043,
            "grammar_ref": 4.08754,
            "grammar_hyp": 3.81835,
            "nubia_score": 0.8321
        },
        "bleurt": 0.34223,
        "meteor": 0.5035559672891159,
        "bertscore": {
            "precision": 0.96557,
            "recall": 0.93683,
            "f1": 0.95098
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.4182958340544896,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 0.8888888888888888
        },
        "nist": 2.939775049781529,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.56667,
            "recall": 0.65278,
            "fmeasure": 0.60624
        },
        "rougeL": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeLsum": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "bleu": 54.52469,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.88498,
            "irrelevancy": 0.70138,
            "logical_agreement": 98.41364,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.81168,
            "nubia_score": 0.89358
        },
        "bleurt": 0.73737,
        "meteor": 0.5451275220838824,
        "bertscore": {
            "precision": 0.98134,
            "recall": 0.98383,
            "f1": 0.98258
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.875
        },
        "nist": 2.3182087693745026,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.57955,
            "fmeasure": 0.63971
        },
        "rouge2": {
            "precision": 0.40909,
            "recall": 0.32251,
            "fmeasure": 0.35227
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.4697,
            "fmeasure": 0.5098
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.4697,
            "fmeasure": 0.5098
        },
        "bleu": 40.01602,
        "nubia": {
            "semantic_relation": 3.81664,
            "contradiction": 0.73268,
            "irrelevancy": 43.7144,
            "logical_agreement": 55.55291,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.75581,
            "nubia_score": 0.45617
        },
        "bleurt": 0.08563,
        "meteor": 0.47181544428945915,
        "bertscore": {
            "precision": 0.93599,
            "recall": 0.93641,
            "f1": 0.9362
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.026986833359286,
        "distinct-2": 0.88,
        "vocab_size-2": 22,
        "unique-2": 19,
        "entropy-2": 4.403856189774723,
        "cond_entropy-2": 0.4038074718067099,
        "distinct-3": 0.9166666666666666,
        "vocab_size-3": 22,
        "unique-3": 20,
        "entropy-3": 4.418295834054489,
        "cond_entropy-3": 0.024439644279765037,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.9690016298759936,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.277613436819114,
        "cond_entropy-2-nopunct": 0.3338190944968058,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.297079327540665,
        "cond_entropy-3-nopunct": 0.02812389937955851,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3,
            "2": 0.4,
            "3": 0.25
        },
        "nist": 2.6069064879070467,
        "rouge1": {
            "precision": 0.47436,
            "recall": 0.38704,
            "fmeasure": 0.4255
        },
        "rouge2": {
            "precision": 0.14667,
            "recall": 0.12381,
            "fmeasure": 0.13396
        },
        "rougeL": {
            "precision": 0.30769,
            "recall": 0.25798,
            "fmeasure": 0.27996
        },
        "rougeLsum": {
            "precision": 0.30769,
            "recall": 0.25798,
            "fmeasure": 0.27996
        },
        "bleu": 9.04357,
        "nubia": {
            "semantic_relation": 2.40251,
            "contradiction": 7.90355,
            "irrelevancy": 78.3676,
            "logical_agreement": 13.72885,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.85487,
            "nubia_score": 0.27094
        },
        "bleurt": -0.80175,
        "meteor": 0.15667021988919255,
        "bertscore": {
            "precision": 0.83656,
            "recall": 0.79528,
            "f1": 0.8154
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.5
        },
        "nist": 1.0122418461244853,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.425,
            "fmeasure": 0.54839
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.23684,
            "fmeasure": 0.31034
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.225,
            "fmeasure": 0.29032
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.225,
            "fmeasure": 0.29032
        },
        "bleu": 12.54711,
        "nubia": {
            "semantic_relation": 3.54277,
            "contradiction": 0.26576,
            "irrelevancy": 0.49148,
            "logical_agreement": 99.24276,
            "grammar_ref": 4.55046,
            "grammar_hyp": 5.76251,
            "nubia_score": 0.4295
        },
        "bleurt": 0.11356,
        "meteor": 0.24755553744384362,
        "bertscore": {
            "precision": 0.89116,
            "recall": 0.83321,
            "f1": 0.86121
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2727272727272727,
            "3": 0.3333333333333333
        },
        "nist": 0.6246840849426293,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.29048,
            "fmeasure": 0.37162
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.08625,
            "fmeasure": 0.11352
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.29048,
            "fmeasure": 0.37162
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.29048,
            "fmeasure": 0.37162
        },
        "bleu": 7.43376,
        "nubia": {
            "semantic_relation": 2.85021,
            "contradiction": 2.38487,
            "irrelevancy": 21.83144,
            "logical_agreement": 75.78369,
            "grammar_ref": 4.72922,
            "grammar_hyp": 4.95683,
            "nubia_score": 0.30362
        },
        "bleurt": -0.21136,
        "meteor": 0.1861482410930178,
        "bertscore": {
            "precision": 0.8816,
            "recall": 0.81153,
            "f1": 0.84
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601983,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "nist": 3.301008637650573,
        "rouge1": {
            "precision": 0.64815,
            "recall": 0.65022,
            "fmeasure": 0.64812
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.27407,
            "fmeasure": 0.27381
        },
        "rougeL": {
            "precision": 0.42593,
            "recall": 0.42654,
            "fmeasure": 0.42554
        },
        "rougeLsum": {
            "precision": 0.42593,
            "recall": 0.42654,
            "fmeasure": 0.42554
        },
        "bleu": 20.82198,
        "nubia": {
            "semantic_relation": 3.91782,
            "contradiction": 0.1058,
            "irrelevancy": 98.31554,
            "logical_agreement": 1.57866,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.58629,
            "nubia_score": 0.72223
        },
        "bleurt": 0.07921,
        "meteor": 0.3491369672803874,
        "bertscore": {
            "precision": 0.86845,
            "recall": 0.86917,
            "f1": 0.86881
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5833333333333334
        },
        "nist": 1.7786774610288023,
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.69231,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.53846,
            "fmeasure": 0.46667
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.53846,
            "fmeasure": 0.46667
        },
        "bleu": 8.22596,
        "nubia": {
            "semantic_relation": 3.80513,
            "contradiction": 0.21069,
            "irrelevancy": 99.18904,
            "logical_agreement": 0.60026,
            "grammar_ref": 3.76485,
            "grammar_hyp": 4.65042,
            "nubia_score": 0.57416
        },
        "bleurt": -0.61817,
        "meteor": 0.36124362335742055,
        "bertscore": {
            "precision": 0.84599,
            "recall": 0.89288,
            "f1": 0.8688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 1.0545733173664176,
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.425,
            "fmeasure": 0.54
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.20952,
            "fmeasure": 0.26877
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.38431,
            "fmeasure": 0.48718
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.38431,
            "fmeasure": 0.48718
        },
        "bleu": 8.89896,
        "nubia": {
            "semantic_relation": 2.66084,
            "contradiction": 98.7718,
            "irrelevancy": 0.90169,
            "logical_agreement": 0.3265,
            "grammar_ref": 4.68072,
            "grammar_hyp": 5.02104,
            "nubia_score": 0.19971
        },
        "bleurt": -0.46112,
        "meteor": 0.18531240129047372,
        "bertscore": {
            "precision": 0.88086,
            "recall": 0.79858,
            "f1": 0.83563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "nist": 4.23331430181648,
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.88462,
            "fmeasure": 0.9
        },
        "rougeL": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 3.77055,
            "contradiction": 48.79365,
            "irrelevancy": 1.17603,
            "logical_agreement": 50.03032,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.40036,
            "nubia_score": 0.71443
        },
        "bleurt": 0.56405,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.72,
        "vocab_size-1": 18,
        "unique-1": 11,
        "entropy-1": 4.083856189774724,
        "distinct-2": 0.875,
        "vocab_size-2": 21,
        "unique-2": 18,
        "entropy-2": 4.334962500721156,
        "cond_entropy-2": 0.2744396442797651,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 22,
        "unique-3": 21,
        "entropy-3": 4.436605434317882,
        "cond_entropy-3": 0.1125124988141176,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.001822825622231,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.277613436819113,
        "cond_entropy-2-nopunct": 0.2995060262166482,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.297079327540665,
        "cond_entropy-3-nopunct": 0.02812389937955851,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.2,
            "3": 0.6
        },
        "nist": 1.7606673935669237,
        "rouge1": {
            "precision": 0.44048,
            "recall": 0.73968,
            "fmeasure": 0.54896
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.51429,
            "fmeasure": 0.37364
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.60317,
            "fmeasure": 0.44613
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.60317,
            "fmeasure": 0.44613
        },
        "bleu": 10.97205,
        "nubia": {
            "semantic_relation": 3.35674,
            "contradiction": 3.57263,
            "irrelevancy": 48.20552,
            "logical_agreement": 48.22186,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.56497,
            "nubia_score": 0.46855
        },
        "bleurt": -0.15405,
        "meteor": 0.34166193157030156,
        "bertscore": {
            "precision": 0.78686,
            "recall": 0.91111,
            "f1": 0.83538
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 11,
        "unique-2": 10,
        "entropy-2": 3.418295834054489,
        "cond_entropy-2": 0.051189449246730766,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": 0.056287299734322706,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.277613436819116,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 2.0917125877356595,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.57071,
            "fmeasure": 0.5628
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.09697,
            "fmeasure": 0.0938
        },
        "rougeL": {
            "precision": 0.47222,
            "recall": 0.41818,
            "fmeasure": 0.44122
        },
        "rougeLsum": {
            "precision": 0.47222,
            "recall": 0.41818,
            "fmeasure": 0.44122
        },
        "bleu": 15.58011,
        "nubia": {
            "semantic_relation": 4.67843,
            "contradiction": 1.11213,
            "irrelevancy": 40.54644,
            "logical_agreement": 58.34143,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.51397,
            "nubia_score": 0.842
        },
        "bleurt": 0.29827,
        "meteor": 0.32351486405730756,
        "bertscore": {
            "precision": 0.90014,
            "recall": 0.90872,
            "f1": 0.90441
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.6296296296296297,
        "vocab_size-1": 17,
        "unique-1": 7,
        "entropy-1": 4.014146761422729,
        "distinct-2": 0.64,
        "vocab_size-2": 16,
        "unique-2": 7,
        "entropy-2": 3.9238561897747237,
        "cond_entropy-2": -0.11103131238874397,
        "distinct-3": 0.6521739130434783,
        "vocab_size-3": 15,
        "unique-3": 7,
        "entropy-3": 3.82790978214397,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.64,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.9238561897747237,
        "distinct-2-nopunct": 0.6521739130434783,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 3.82790978214397,
        "cond_entropy-2-nopunct": -0.12029423371771175,
        "distinct-3-nopunct": 0.6666666666666666,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 3.7256507561120933,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "nist": 2.8475452949098377,
        "rouge1": {
            "precision": 0.80128,
            "recall": 0.90909,
            "fmeasure": 0.85145
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.8,
            "fmeasure": 0.74459
        },
        "rougeL": {
            "precision": 0.80128,
            "recall": 0.90909,
            "fmeasure": 0.85145
        },
        "rougeLsum": {
            "precision": 0.80128,
            "recall": 0.90909,
            "fmeasure": 0.85145
        },
        "bleu": 69.57523,
        "nubia": {
            "semantic_relation": 4.38318,
            "contradiction": 0.37013,
            "irrelevancy": 90.68137,
            "logical_agreement": 8.94849,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.47503,
            "nubia_score": 0.86502
        },
        "bleurt": 0.47978,
        "meteor": 0.5613039889129741,
        "bertscore": {
            "precision": 0.92686,
            "recall": 0.96782,
            "f1": 0.94688
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 3.644214806381584,
        "rouge1": {
            "precision": 0.85417,
            "recall": 0.80392,
            "fmeasure": 0.82828
        },
        "rouge2": {
            "precision": 0.42222,
            "recall": 0.39583,
            "fmeasure": 0.4086
        },
        "rougeL": {
            "precision": 0.72917,
            "recall": 0.68627,
            "fmeasure": 0.70707
        },
        "rougeLsum": {
            "precision": 0.72917,
            "recall": 0.68627,
            "fmeasure": 0.70707
        },
        "bleu": 22.63405,
        "nubia": {
            "semantic_relation": 3.78901,
            "contradiction": 0.97455,
            "irrelevancy": 8.13054,
            "logical_agreement": 90.89491,
            "grammar_ref": 4.8802,
            "grammar_hyp": 6.03269,
            "nubia_score": 0.49081
        },
        "bleurt": 0.30208,
        "meteor": 0.37734221865582834,
        "bertscore": {
            "precision": 0.93752,
            "recall": 0.91099,
            "f1": 0.92406
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "nist": 3.0881978509745025,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "bleu": 68.94026,
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "bleurt": 0.64449,
        "meteor": 0.81809314801268,
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97492
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.875
        },
        "nist": 3.985781358787686,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.77273,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.85417,
            "recall": 0.65079,
            "fmeasure": 0.73874
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.72727,
            "fmeasure": 0.82051
        },
        "bleu": 59.05699,
        "nubia": {
            "semantic_relation": 4.31394,
            "contradiction": 0.42833,
            "irrelevancy": 33.02252,
            "logical_agreement": 66.54915,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.88278,
            "nubia_score": 0.77769
        },
        "bleurt": -0.00072,
        "meteor": 0.45532127755528956,
        "bertscore": {
            "precision": 0.96043,
            "recall": 0.92448,
            "f1": 0.93897
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "nist": 3.5309320563607085,
        "rouge1": {
            "precision": 0.79487,
            "recall": 0.69188,
            "fmeasure": 0.73827
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.51282,
            "fmeasure": 0.56762
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.60644,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.60644,
            "fmeasure": 0.66667
        },
        "bleu": 39.36932,
        "nubia": {
            "semantic_relation": 3.92964,
            "contradiction": 27.11727,
            "irrelevancy": 67.18535,
            "logical_agreement": 5.69738,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.35502,
            "nubia_score": 0.63536
        },
        "bleurt": -0.00492,
        "meteor": 0.3925374844963381,
        "bertscore": {
            "precision": 0.94298,
            "recall": 0.91149,
            "f1": 0.91237
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.42857142857142855
        },
        "nist": 1.9303644234652384,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.2,
            "fmeasure": 0.19048
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.45455,
            "fmeasure": 0.43478
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.45455,
            "fmeasure": 0.43478
        },
        "bleu": 15.7278,
        "nubia": {
            "semantic_relation": 3.23504,
            "contradiction": 0.08555,
            "irrelevancy": 99.38565,
            "logical_agreement": 0.52879,
            "grammar_ref": 4.25346,
            "grammar_hyp": 4.14837,
            "nubia_score": 0.50772
        },
        "bleurt": -0.10149,
        "meteor": 0.3111639316731902,
        "bertscore": {
            "precision": 0.87201,
            "recall": 0.8861,
            "f1": 0.879
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.7931034482758621,
        "vocab_size-1": 23,
        "unique-1": 17,
        "entropy-1": 4.444187891679296,
        "distinct-2": 0.9629629629629629,
        "vocab_size-2": 26,
        "unique-2": 25,
        "entropy-2": 4.6808134280893965,
        "cond_entropy-2": 0.19320280333219275,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.03103131238874396,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.243856189774722,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.22753185323880998,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.03600643804015717,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "nist": 3.331549424745896,
        "rouge1": {
            "precision": 0.7963,
            "recall": 0.57179,
            "fmeasure": 0.65481
        },
        "rouge2": {
            "precision": 0.5119,
            "recall": 0.31407,
            "fmeasure": 0.38612
        },
        "rougeL": {
            "precision": 0.47037,
            "recall": 0.34968,
            "fmeasure": 0.3943
        },
        "rougeLsum": {
            "precision": 0.47037,
            "recall": 0.34968,
            "fmeasure": 0.3943
        },
        "bleu": 34.55567,
        "nubia": {
            "semantic_relation": 3.96963,
            "contradiction": 3.10358,
            "irrelevancy": 3.92313,
            "logical_agreement": 92.97329,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.78826,
            "nubia_score": 0.58636
        },
        "bleurt": -0.03433,
        "meteor": 0.3143966115690376,
        "bertscore": {
            "precision": 0.9216,
            "recall": 0.87049,
            "f1": 0.894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.925938214656137,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.67194,
            "irrelevancy": 0.62656,
            "logical_agreement": 98.70151,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.94537,
            "nubia_score": 1.0
        },
        "bleurt": 0.92236,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.7323318183660923,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.47059,
            "fmeasure": 0.51613
        },
        "rouge2": {
            "precision": 0.38462,
            "recall": 0.3125,
            "fmeasure": 0.34483
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.47059,
            "fmeasure": 0.51613
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.47059,
            "fmeasure": 0.51613
        },
        "bleu": 12.84611,
        "nubia": {
            "semantic_relation": 2.73624,
            "contradiction": 97.42133,
            "irrelevancy": 2.21348,
            "logical_agreement": 0.36519,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.47633,
            "nubia_score": 0.33616
        },
        "bleurt": -0.32394,
        "meteor": 0.23615129358407105,
        "bertscore": {
            "precision": 0.9173,
            "recall": 0.86228,
            "f1": 0.88894
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "nist": 3.2961675827628523,
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.62709,
            "fmeasure": 0.69841
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.37939,
            "fmeasure": 0.42403
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.41806,
            "fmeasure": 0.46561
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.41806,
            "fmeasure": 0.46561
        },
        "bleu": 33.05096,
        "nubia": {
            "semantic_relation": 4.87196,
            "contradiction": 0.21673,
            "irrelevancy": 0.46491,
            "logical_agreement": 99.31836,
            "grammar_ref": 3.26294,
            "grammar_hyp": 2.87427,
            "nubia_score": 0.99583
        },
        "bleurt": 0.48675,
        "meteor": 0.3606501865871374,
        "bertscore": {
            "precision": 0.92875,
            "recall": 0.88404,
            "f1": 0.90533
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.027169118440619,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.3379852264664118,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.8464393446710154,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.3763177401286689,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "nist": 1.466697361167835,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.66138,
            "fmeasure": 0.79365
        },
        "rouge2": {
            "precision": 0.7037,
            "recall": 0.44495,
            "fmeasure": 0.54312
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.5,
            "fmeasure": 0.62302
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.5,
            "fmeasure": 0.62302
        },
        "bleu": 61.91567,
        "nubia": {
            "semantic_relation": 3.15575,
            "contradiction": 34.20923,
            "irrelevancy": 5.2919,
            "logical_agreement": 60.49886,
            "grammar_ref": 3.09217,
            "grammar_hyp": 3.70605,
            "nubia_score": 0.41449
        },
        "bleurt": -0.51566,
        "meteor": 0.34705670966624447,
        "bertscore": {
            "precision": 0.94387,
            "recall": 0.86471,
            "f1": 0.90256
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "nist": 2.425622163887878,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.83333,
            "fmeasure": 0.90909
        },
        "bleu": 51.15078,
        "nubia": {
            "semantic_relation": 4.03933,
            "contradiction": 14.76512,
            "irrelevancy": 1.30136,
            "logical_agreement": 83.93352,
            "grammar_ref": 6.21263,
            "grammar_hyp": 7.12865,
            "nubia_score": 0.54196
        },
        "bleurt": 0.50807,
        "meteor": 0.42750933026297866,
        "bertscore": {
            "precision": 0.99151,
            "recall": 0.95959,
            "f1": 0.97529
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.734521664779752,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.28753715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.506890595608519,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.25760718359194273,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.7777777777777778
        },
        "nist": 3.4155128429508075,
        "rouge1": {
            "precision": 0.84127,
            "recall": 0.79183,
            "fmeasure": 0.81572
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.50072,
            "fmeasure": 0.51645
        },
        "rougeL": {
            "precision": 0.60317,
            "recall": 0.56785,
            "fmeasure": 0.58492
        },
        "rougeLsum": {
            "precision": 0.60317,
            "recall": 0.56785,
            "fmeasure": 0.58492
        },
        "bleu": 37.55294,
        "nubia": {
            "semantic_relation": 4.57973,
            "contradiction": 0.57189,
            "irrelevancy": 17.15631,
            "logical_agreement": 82.2718,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.47604,
            "nubia_score": 0.90517
        },
        "bleurt": 0.18859,
        "meteor": 0.44184733782343,
        "bertscore": {
            "precision": 0.92771,
            "recall": 0.91539,
            "f1": 0.92151
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.2222222222222222,
            "3": 0.5555555555555556
        },
        "nist": 2.671327430758783,
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.4697,
            "fmeasure": 0.47067
        },
        "rouge2": {
            "precision": 0.31481,
            "recall": 0.29464,
            "fmeasure": 0.30317
        },
        "rougeL": {
            "precision": 0.31579,
            "recall": 0.34641,
            "fmeasure": 0.33033
        },
        "rougeLsum": {
            "precision": 0.31579,
            "recall": 0.34641,
            "fmeasure": 0.33033
        },
        "bleu": 29.35974,
        "nubia": {
            "semantic_relation": 2.94911,
            "contradiction": 61.68282,
            "irrelevancy": 36.92681,
            "logical_agreement": 1.39037,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.59767,
            "nubia_score": 0.3015
        },
        "bleurt": -0.82493,
        "meteor": 0.2275841544219835,
        "bertscore": {
            "precision": 0.84289,
            "recall": 0.88323,
            "f1": 0.86259
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "nist": 1.3422354203643907,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.44192,
            "fmeasure": 0.49206
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.19394,
            "fmeasure": 0.21832
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.44192,
            "fmeasure": 0.49206
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.44192,
            "fmeasure": 0.49206
        },
        "bleu": 9.9801,
        "nubia": {
            "semantic_relation": 2.48686,
            "contradiction": 1.21267,
            "irrelevancy": 90.60797,
            "logical_agreement": 8.17935,
            "grammar_ref": 4.79209,
            "grammar_hyp": 5.25507,
            "nubia_score": 0.19995
        },
        "bleurt": -0.95623,
        "meteor": 0.24623202927375937,
        "bertscore": {
            "precision": 0.78986,
            "recall": 0.74127,
            "f1": 0.76479
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "nist": 2.2201412514011016,
        "rouge1": {
            "precision": 0.775,
            "recall": 0.60216,
            "fmeasure": 0.66638
        },
        "rouge2": {
            "precision": 0.46825,
            "recall": 0.37108,
            "fmeasure": 0.40624
        },
        "rougeL": {
            "precision": 0.775,
            "recall": 0.60216,
            "fmeasure": 0.66638
        },
        "rougeLsum": {
            "precision": 0.775,
            "recall": 0.60216,
            "fmeasure": 0.66638
        },
        "bleu": 35.32204,
        "nubia": {
            "semantic_relation": 4.26879,
            "contradiction": 16.7471,
            "irrelevancy": 22.15317,
            "logical_agreement": 61.09973,
            "grammar_ref": 3.80999,
            "grammar_hyp": 5.19579,
            "nubia_score": 0.61774
        },
        "bleurt": 0.30059,
        "meteor": 0.28526922927111836,
        "bertscore": {
            "precision": 0.94993,
            "recall": 0.90308,
            "f1": 0.92352
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": -0.031031312388743945,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": -0.03600643804015717,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.039126751440438104,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2727272727272727,
            "2": 0.0,
            "3": 0.47058823529411764
        },
        "nist": 0.08605233040528769,
        "rouge1": {
            "precision": 0.82857,
            "recall": 0.37817,
            "fmeasure": 0.5166
        },
        "rouge2": {
            "precision": 0.30342,
            "recall": 0.11723,
            "fmeasure": 0.16742
        },
        "rougeL": {
            "precision": 0.51429,
            "recall": 0.24172,
            "fmeasure": 0.32727
        },
        "rougeLsum": {
            "precision": 0.51429,
            "recall": 0.24172,
            "fmeasure": 0.32727
        },
        "bleu": 3.3884,
        "nubia": {
            "semantic_relation": 2.47052,
            "contradiction": 52.03079,
            "irrelevancy": 6.01645,
            "logical_agreement": 41.95276,
            "grammar_ref": 3.44707,
            "grammar_hyp": 5.17657,
            "nubia_score": 0.11666
        },
        "bleurt": -0.31184,
        "meteor": 0.18068735476924444,
        "bertscore": {
            "precision": 0.91889,
            "recall": 0.8423,
            "f1": 0.8788
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7
        },
        "nist": 2.242373039861369,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.60985,
            "fmeasure": 0.65152
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.47727,
            "fmeasure": 0.51316
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.60985,
            "fmeasure": 0.65152
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.60985,
            "fmeasure": 0.65152
        },
        "bleu": 28.91785,
        "nubia": {
            "semantic_relation": 4.50155,
            "contradiction": 0.34291,
            "irrelevancy": 5.3429,
            "logical_agreement": 94.31419,
            "grammar_ref": 4.19853,
            "grammar_hyp": 4.25328,
            "nubia_score": 0.88316
        },
        "bleurt": 0.55298,
        "meteor": 0.3832699063476993,
        "bertscore": {
            "precision": 0.90473,
            "recall": 0.91727,
            "f1": 0.91083
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 737,
        "msttr-100": 0.29273,
        "msttr-100_nopunct": 0.29049,
        "total_length": 15466,
        "mean_pred_length": 20.98507462686567,
        "std_pred_length": 3.7613394040523604,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.01681106944264839,
        "vocab_size-1": 260,
        "unique-1": 61,
        "entropy-1": 5.966726779067638,
        "distinct-2": 0.061443410957974065,
        "vocab_size-2": 905,
        "unique-2": 260,
        "entropy-2": 7.904211479734659,
        "cond_entropy-2": 1.8788574448649231,
        "distinct-3": 0.11606632361349342,
        "vocab_size-3": 1624,
        "unique-3": 546,
        "entropy-3": 9.01615579464048,
        "cond_entropy-3": 1.1572016760432686,
        "total_length-nopunct": 14223,
        "mean_pred_length-nopunct": 19.29850746268657,
        "std_pred_length-nopunct": 3.436638799625223,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.018069324333825493,
        "vocab_size-1-nopunct": 257,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.987733362533853,
        "distinct-2-nopunct": 0.06376983538484354,
        "vocab_size-2-nopunct": 860,
        "unique-2-nopunct": 259,
        "entropy-2-nopunct": 7.818911972584585,
        "cond_entropy-2-nopunct": 1.9092166103039332,
        "distinct-3-nopunct": 0.12110753784610558,
        "vocab_size-3-nopunct": 1544,
        "unique-3-nopunct": 529,
        "entropy-3-nopunct": 8.989485751521912,
        "cond_entropy-3-nopunct": 1.1798555873721805,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.688366805608185
        },
        "nist": 4.907793861472827,
        "rouge1": {
            "precision": 0.71185,
            "recall": 0.70496,
            "fmeasure": 0.69782
        },
        "rouge2": {
            "precision": 0.4364,
            "recall": 0.43048,
            "fmeasure": 0.42676
        },
        "rougeL": {
            "precision": 0.53726,
            "recall": 0.53161,
            "fmeasure": 0.52664
        },
        "rougeLsum": {
            "precision": 0.53726,
            "recall": 0.53161,
            "fmeasure": 0.52664
        },
        "bleu": 30.50409,
        "nubia": {
            "semantic_relation": 4.21134,
            "contradiction": 3.53984,
            "irrelevancy": 28.04664,
            "logical_agreement": 68.41352,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.72555,
            "nubia_score": 0.7428
        },
        "bleurt": 0.14105,
        "meteor": 0.35633299988333345,
        "bertscore": {
            "precision": 0.91286,
            "recall": 0.90724,
            "f1": 0.90963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.14285714285714285,
            "3": 0.7
        },
        "nist": 1.140204368901255,
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.61481,
            "fmeasure": 0.68876
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.37473,
            "fmeasure": 0.42039
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.52963,
            "fmeasure": 0.59389
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.52963,
            "fmeasure": 0.59389
        },
        "bleu": 37.25177,
        "nubia": {
            "semantic_relation": 3.90425,
            "contradiction": 0.23632,
            "irrelevancy": 2.91639,
            "logical_agreement": 96.84729,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.79136,
            "nubia_score": 0.72975
        },
        "bleurt": 0.33005,
        "meteor": 0.32661173471612,
        "bertscore": {
            "precision": 0.95956,
            "recall": 0.90472,
            "f1": 0.93133
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337128,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.4444444444444444
        },
        "nist": 1.375770958405131,
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.33929,
            "fmeasure": 0.36969
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.11396,
            "fmeasure": 0.12285
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.32143,
            "fmeasure": 0.34643
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.32143,
            "fmeasure": 0.34643
        },
        "bleu": 12.09034,
        "nubia": {
            "semantic_relation": 3.07078,
            "contradiction": 0.43015,
            "irrelevancy": 84.59474,
            "logical_agreement": 14.97512,
            "grammar_ref": 3.10421,
            "grammar_hyp": 2.62896,
            "nubia_score": 0.51501
        },
        "bleurt": -0.15748,
        "meteor": 0.21784584182988367,
        "bertscore": {
            "precision": 0.82841,
            "recall": 0.82115,
            "f1": 0.82292
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.02961067210860197,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.42105263157894735
        },
        "nist": 1.5011175269536792,
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.30725,
            "fmeasure": 0.37021
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.11442,
            "fmeasure": 0.14152
        },
        "rougeL": {
            "precision": 0.23529,
            "recall": 0.15362,
            "fmeasure": 0.18511
        },
        "rougeLsum": {
            "precision": 0.23529,
            "recall": 0.15362,
            "fmeasure": 0.18511
        },
        "bleu": 14.35473,
        "nubia": {
            "semantic_relation": 3.09584,
            "contradiction": 0.50609,
            "irrelevancy": 8.39431,
            "logical_agreement": 91.0996,
            "grammar_ref": 4.294,
            "grammar_hyp": 6.10204,
            "nubia_score": 0.2698
        },
        "bleurt": -0.45829,
        "meteor": 0.16301368475784772,
        "bertscore": {
            "precision": 0.80628,
            "recall": 0.81519,
            "f1": 0.81071
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.238703514944046,
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.81818,
            "fmeasure": 0.78261
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.83333,
            "fmeasure": 0.8
        },
        "bleu": 54.10823,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21631,
            "irrelevancy": 9.48924,
            "logical_agreement": 90.29445,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.28863,
            "nubia_score": 1.0
        },
        "bleurt": 0.6871,
        "meteor": 0.5145692356432209,
        "bertscore": {
            "precision": 0.96002,
            "recall": 0.96374,
            "f1": 0.96188
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "nist": 2.32249814589546,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "bleu": 41.10546,
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "bleurt": 0.65075,
        "meteor": 0.8569614896318238,
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "nist": 1.9185943965476828,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.53333
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.25,
            "fmeasure": 0.30769
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.53333
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.44444,
            "fmeasure": 0.53333
        },
        "bleu": 34.78701,
        "nubia": {
            "semantic_relation": 4.28212,
            "contradiction": 0.40636,
            "irrelevancy": 0.54932,
            "logical_agreement": 99.04432,
            "grammar_ref": 4.6877,
            "grammar_hyp": 5.34073,
            "nubia_score": 0.7623
        },
        "bleurt": 0.40225,
        "meteor": 0.2173170392095533,
        "bertscore": {
            "precision": 0.88684,
            "recall": 0.84195,
            "f1": 0.86381
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 4.5,
        "median_pred_length": 22.5,
        "min_pred_length": 18,
        "max_pred_length": 27,
        "distinct-1": 0.6888888888888889,
        "vocab_size-1": 31,
        "unique-1": 20,
        "entropy-1": 4.819305040629888,
        "distinct-2": 0.7906976744186046,
        "vocab_size-2": 34,
        "unique-2": 27,
        "entropy-2": 4.972549056927052,
        "cond_entropy-2": 0.13801369330645757,
        "distinct-3": 0.8292682926829268,
        "vocab_size-3": 34,
        "unique-3": 28,
        "entropy-3": 4.997676699687266,
        "cond_entropy-3": 0.04726011582241173,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.6119493340804425,
        "distinct-2-nopunct": 0.7837837837837838,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.736216203349846,
        "cond_entropy-2-nopunct": 0.1606697279062545,
        "distinct-3-nopunct": 0.8285714285714286,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.764857659740294,
        "cond_entropy-3-nopunct": 0.05568357994925863,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.0,
            "3": 0.9473684210526315
        },
        "nist": 2.7216567813851484,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.82323,
            "fmeasure": 0.6483
        },
        "rouge2": {
            "precision": 0.38963,
            "recall": 0.55673,
            "fmeasure": 0.44971
        },
        "rougeL": {
            "precision": 0.51786,
            "recall": 0.80833,
            "fmeasure": 0.61439
        },
        "rougeLsum": {
            "precision": 0.51786,
            "recall": 0.80833,
            "fmeasure": 0.61439
        },
        "bleu": 34.72728,
        "nubia": {
            "semantic_relation": 4.35923,
            "contradiction": 4.60422,
            "irrelevancy": 48.36622,
            "logical_agreement": 47.02956,
            "grammar_ref": 6.17452,
            "grammar_hyp": 5.14291,
            "nubia_score": 0.53078
        },
        "bleurt": 0.12709,
        "meteor": 0.4078124077818703,
        "bertscore": {
            "precision": 0.88768,
            "recall": 0.92715,
            "f1": 0.90657
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 1.0,
        "vocab_size-1": 26,
        "unique-1": 26,
        "entropy-1": 4.70043971814109,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.05658352836636749,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.061400544664143256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.375,
            "2": 0.2,
            "3": 0.5454545454545454
        },
        "nist": 2.511692831551889,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.47619,
            "fmeasure": 0.43478
        },
        "rouge2": {
            "precision": 0.18056,
            "recall": 0.21667,
            "fmeasure": 0.19697
        },
        "rougeL": {
            "precision": 0.25333,
            "recall": 0.30159,
            "fmeasure": 0.27536
        },
        "rougeLsum": {
            "precision": 0.25333,
            "recall": 0.30159,
            "fmeasure": 0.27536
        },
        "bleu": 8.54325,
        "nubia": {
            "semantic_relation": 3.8648,
            "contradiction": 0.10413,
            "irrelevancy": 99.08802,
            "logical_agreement": 0.80785,
            "grammar_ref": 3.9898,
            "grammar_hyp": 4.91227,
            "nubia_score": 0.55543
        },
        "bleurt": 0.14157,
        "meteor": 0.27581932367324263,
        "bertscore": {
            "precision": 0.8362,
            "recall": 0.8774,
            "f1": 0.8563
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 9.666666666666666,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.5517241379310345,
        "vocab_size-1": 16,
        "unique-1": 8,
        "entropy-1": 3.83127625337525,
        "distinct-2": 0.6923076923076923,
        "vocab_size-2": 18,
        "unique-2": 12,
        "entropy-2": 4.026986833359286,
        "cond_entropy-2": 0.13129622317994066,
        "distinct-3": 0.8260869565217391,
        "vocab_size-3": 19,
        "unique-3": 15,
        "entropy-3": 4.1757358691004915,
        "cond_entropy-3": 0.029856477140419467,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.625814583693912,
        "distinct-2-nopunct": 0.7619047619047619,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.8801799226757367,
        "cond_entropy-2-nopunct": 0.16496325559698213,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": 0.04176799545041137,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "nist": 2.8762294518498766,
        "rouge1": {
            "precision": 0.85859,
            "recall": 0.74151,
            "fmeasure": 0.78513
        },
        "rouge2": {
            "precision": 0.69877,
            "recall": 0.61049,
            "fmeasure": 0.64259
        },
        "rougeL": {
            "precision": 0.85859,
            "recall": 0.74151,
            "fmeasure": 0.78513
        },
        "rougeLsum": {
            "precision": 0.85859,
            "recall": 0.74151,
            "fmeasure": 0.78513
        },
        "bleu": 45.99639,
        "nubia": {
            "semantic_relation": 3.67506,
            "contradiction": 83.52352,
            "irrelevancy": 12.30461,
            "logical_agreement": 4.17187,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.39988,
            "nubia_score": 0.52497
        },
        "bleurt": 0.39145,
        "meteor": 0.4610937085594191,
        "bertscore": {
            "precision": 0.96614,
            "recall": 0.9223,
            "f1": 0.94245
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9841837197791885,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.28151981340693205,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.9230769230769231
        },
        "nist": 4.717357853740129,
        "rouge1": {
            "precision": 0.88333,
            "recall": 0.91481,
            "fmeasure": 0.89825
        },
        "rouge2": {
            "precision": 0.7193,
            "recall": 0.742,
            "fmeasure": 0.73002
        },
        "rougeL": {
            "precision": 0.86667,
            "recall": 0.8963,
            "fmeasure": 0.8807
        },
        "rougeLsum": {
            "precision": 0.86667,
            "recall": 0.8963,
            "fmeasure": 0.8807
        },
        "bleu": 58.80963,
        "nubia": {
            "semantic_relation": 4.65184,
            "contradiction": 0.51113,
            "irrelevancy": 96.53996,
            "logical_agreement": 2.94891,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.79879,
            "nubia_score": 0.81023
        },
        "bleurt": 0.17705,
        "meteor": 0.47408357446123234,
        "bertscore": {
            "precision": 0.94968,
            "recall": 0.97287,
            "f1": 0.96113
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "nist": 2.728800539613452,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.8,
            "recall": 0.72727,
            "fmeasure": 0.7619
        },
        "rougeL": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeLsum": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "bleu": 34.17233,
        "nubia": {
            "semantic_relation": 4.7425,
            "contradiction": 0.28276,
            "irrelevancy": 33.55957,
            "logical_agreement": 66.15766,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.55658,
            "nubia_score": 0.80226
        },
        "bleurt": 0.64704,
        "meteor": 0.6101497202045876,
        "bertscore": {
            "precision": 0.97767,
            "recall": 0.95159,
            "f1": 0.96445
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 3.858612300930075,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 23,
        "distinct-1": 0.41509433962264153,
        "vocab_size-1": 22,
        "unique-1": 7,
        "entropy-1": 4.293220454236637,
        "distinct-2": 0.64,
        "vocab_size-2": 32,
        "unique-2": 23,
        "entropy-2": 4.768367439558379,
        "cond_entropy-2": 0.46613123529806444,
        "distinct-3": 0.7659574468085106,
        "vocab_size-3": 36,
        "unique-3": 29,
        "entropy-3": 5.022258000429685,
        "cond_entropy-3": 0.30977282152341207,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 3.858612300930075,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.43902439024390244,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.9668312726996966,
        "distinct-2-nopunct": 0.6842105263157895,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.47135448701393,
        "cond_entropy-2-nopunct": 0.5090537984130529,
        "distinct-3-nopunct": 0.8,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.686146588249908,
        "cond_entropy-3-nopunct": 0.16706978921566662,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.7142857142857143,
            "3": 0.8888888888888888
        },
        "nist": 3.719042019438758,
        "rouge1": {
            "precision": 0.76111,
            "recall": 0.74343,
            "fmeasure": 0.75082
        },
        "rouge2": {
            "precision": 0.60695,
            "recall": 0.60192,
            "fmeasure": 0.60309
        },
        "rougeL": {
            "precision": 0.65,
            "recall": 0.64646,
            "fmeasure": 0.64711
        },
        "rougeLsum": {
            "precision": 0.65,
            "recall": 0.64646,
            "fmeasure": 0.64711
        },
        "bleu": 52.45562,
        "nubia": {
            "semantic_relation": 4.52421,
            "contradiction": 1.36158,
            "irrelevancy": 32.50375,
            "logical_agreement": 66.13466,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.12444,
            "nubia_score": 0.84048
        },
        "bleurt": 0.47544,
        "meteor": 0.43969791363921523,
        "bertscore": {
            "precision": 0.93538,
            "recall": 0.9413,
            "f1": 0.93833
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322706,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.277613436819116,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.4,
            "2": 1.0
        },
        "nist": 2.6658843184093173,
        "rouge1": {
            "precision": 0.45455,
            "recall": 0.625,
            "fmeasure": 0.52632
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.5,
            "fmeasure": 0.41176
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.625,
            "fmeasure": 0.52632
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.625,
            "fmeasure": 0.52632
        },
        "bleu": 53.31675,
        "nubia": {
            "semantic_relation": 3.46219,
            "contradiction": 49.97195,
            "irrelevancy": 49.9222,
            "logical_agreement": 0.10584,
            "grammar_ref": 5.57872,
            "grammar_hyp": 4.91137,
            "nubia_score": 0.5378
        },
        "bleurt": 0.02437,
        "meteor": 0.44174989775949813,
        "bertscore": {
            "precision": 0.88071,
            "recall": 0.91324,
            "f1": 0.89668
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": 0.029610672108601983,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": 0.031262576450960096,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": 0.03310859910983795,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": 0.03518489863155644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.625
        },
        "nist": 1.290049191559112,
        "rouge1": {
            "precision": 0.40351,
            "recall": 0.67778,
            "fmeasure": 0.50501
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.22222,
            "fmeasure": 0.14815
        },
        "rougeL": {
            "precision": 0.21053,
            "recall": 0.4,
            "fmeasure": 0.27586
        },
        "rougeLsum": {
            "precision": 0.21053,
            "recall": 0.4,
            "fmeasure": 0.27586
        },
        "bleu": 5.23752,
        "nubia": {
            "semantic_relation": 4.15253,
            "contradiction": 39.95625,
            "irrelevancy": 24.12106,
            "logical_agreement": 35.92269,
            "grammar_ref": 5.64952,
            "grammar_hyp": 4.206,
            "nubia_score": 0.55564
        },
        "bleurt": -0.07379,
        "meteor": 0.2589297860246834,
        "bertscore": {
            "precision": 0.81811,
            "recall": 0.87963,
            "f1": 0.84431
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8235294117647058,
        "vocab_size-1": 14,
        "unique-1": 11,
        "entropy-1": 3.734521664779752,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.28753715874966057,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.625,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.3068905956085186,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 1.4761610297087115,
        "rouge1": {
            "precision": 0.375,
            "recall": 0.54545,
            "fmeasure": 0.44444
        },
        "rouge2": {
            "precision": 0.06667,
            "recall": 0.1,
            "fmeasure": 0.08
        },
        "rougeL": {
            "precision": 0.3125,
            "recall": 0.45455,
            "fmeasure": 0.37037
        },
        "rougeLsum": {
            "precision": 0.3125,
            "recall": 0.45455,
            "fmeasure": 0.37037
        },
        "bleu": 6.25612,
        "nubia": {
            "semantic_relation": 3.78043,
            "contradiction": 0.0845,
            "irrelevancy": 99.57992,
            "logical_agreement": 0.33558,
            "grammar_ref": 5.42176,
            "grammar_hyp": 3.87301,
            "nubia_score": 0.71938
        },
        "bleurt": -0.09929,
        "meteor": 0.23120875726260467,
        "bertscore": {
            "precision": 0.78935,
            "recall": 0.82256,
            "f1": 0.80561
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.867976246918685,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "bleurt": 0.73788,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518528,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.23810548155250458,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 3.6309927067289793,
        "rouge1": {
            "precision": 0.59524,
            "recall": 0.54739,
            "fmeasure": 0.56658
        },
        "rouge2": {
            "precision": 0.28205,
            "recall": 0.25758,
            "fmeasure": 0.26724
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.48039,
            "fmeasure": 0.49793
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.48039,
            "fmeasure": 0.49793
        },
        "bleu": 22.89416,
        "nubia": {
            "semantic_relation": 4.2213,
            "contradiction": 2.38946,
            "irrelevancy": 19.07447,
            "logical_agreement": 78.53607,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.53878,
            "nubia_score": 0.70347
        },
        "bleurt": 0.18718,
        "meteor": 0.2849192433560646,
        "bertscore": {
            "precision": 0.93652,
            "recall": 0.91459,
            "f1": 0.92502
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.6896551724137931,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.073329701949522,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 24,
        "unique-2": 22,
        "entropy-2": 4.450212064914748,
        "cond_entropy-2": 0.4049056234358702,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.6808134280893965,
        "cond_entropy-3": 0.24382887640216078,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 25.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 25.0,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.72,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.9238561897747233,
        "distinct-2-nopunct": 0.8333333333333334,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.16829583405449,
        "cond_entropy-2-nopunct": 0.23277297761309837,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.436605434317882,
        "cond_entropy-3-nopunct": 0.24294728142281322,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.4444444444444444
        },
        "nist": 4.02055520564225,
        "rouge1": {
            "precision": 0.76,
            "recall": 0.6129,
            "fmeasure": 0.67857
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.46667,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.76,
            "recall": 0.6129,
            "fmeasure": 0.67857
        },
        "rougeLsum": {
            "precision": 0.76,
            "recall": 0.6129,
            "fmeasure": 0.67857
        },
        "bleu": 37.50618,
        "nubia": {
            "semantic_relation": 2.69315,
            "contradiction": 88.22961,
            "irrelevancy": 5.58621,
            "logical_agreement": 6.18418,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.89347,
            "nubia_score": 0.27858
        },
        "bleurt": -0.23734,
        "meteor": 0.3018269986761726,
        "bertscore": {
            "precision": 0.97161,
            "recall": 0.94842,
            "f1": 0.95987
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "nist": 3.1566687205209765,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.7,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "bleu": 59.2065,
        "nubia": {
            "semantic_relation": 4.26096,
            "contradiction": 0.80225,
            "irrelevancy": 0.51437,
            "logical_agreement": 98.68338,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.89549,
            "nubia_score": 0.76313
        },
        "bleurt": 0.46434,
        "meteor": 0.4603105469113841,
        "bertscore": {
            "precision": 0.96496,
            "recall": 0.93489,
            "f1": 0.94969
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 2.5,
        "median_pred_length": 11.5,
        "min_pred_length": 9,
        "max_pred_length": 14,
        "distinct-1": 0.6086956521739131,
        "vocab_size-1": 14,
        "unique-1": 7,
        "entropy-1": 3.675310868912364,
        "distinct-2": 0.6666666666666666,
        "vocab_size-2": 14,
        "unique-2": 8,
        "entropy-2": 3.689703732199547,
        "cond_entropy-2": -5.9414127611068235e-05,
        "distinct-3": 0.7368421052631579,
        "vocab_size-3": 14,
        "unique-3": 9,
        "entropy-3": 3.7216117239699007,
        "cond_entropy-3": 0.0006041697260603099,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6190476190476191,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.5585186130489053,
        "distinct-2-nopunct": 0.6842105263157895,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.5766176449086653,
        "cond_entropy-2-nopunct": 0.0006041697260603064,
        "distinct-3-nopunct": 0.7647058823529411,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.6168746059562227,
        "cond_entropy-3-nopunct": 0.001587533816369658,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "nist": 3.8730980767647254,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.94444,
            "fmeasure": 0.92892
        },
        "rouge2": {
            "precision": 0.80357,
            "recall": 0.85833,
            "fmeasure": 0.82208
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 0.94444,
            "fmeasure": 0.92892
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 0.94444,
            "fmeasure": 0.92892
        },
        "bleu": 73.85255,
        "nubia": {
            "semantic_relation": 4.92218,
            "contradiction": 0.47325,
            "irrelevancy": 13.63589,
            "logical_agreement": 85.89086,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.46355,
            "nubia_score": 0.95975
        },
        "bleurt": 0.84843,
        "meteor": 0.5363057668264603,
        "bertscore": {
            "precision": 0.98874,
            "recall": 0.99049,
            "f1": 0.98745
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "nist": 1.6042028126043453,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2,
            "fmeasure": 0.2
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "bleu": 15.6197,
        "nubia": {
            "semantic_relation": 4.65359,
            "contradiction": 0.40568,
            "irrelevancy": 0.58566,
            "logical_agreement": 99.00866,
            "grammar_ref": 5.72796,
            "grammar_hyp": 6.23219,
            "nubia_score": 0.79923
        },
        "bleurt": 0.48449,
        "meteor": 0.29493026749867945,
        "bertscore": {
            "precision": 0.87845,
            "recall": 0.88539,
            "f1": 0.88191
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.165894208390023,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.16735504721677538,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5882352941176471
        },
        "nist": 2.493268172743635,
        "rouge1": {
            "precision": 0.68627,
            "recall": 0.66013,
            "fmeasure": 0.67283
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.30637,
            "fmeasure": 0.30934
        },
        "rougeL": {
            "precision": 0.37255,
            "recall": 0.27753,
            "fmeasure": 0.31509
        },
        "rougeLsum": {
            "precision": 0.37255,
            "recall": 0.27753,
            "fmeasure": 0.31509
        },
        "bleu": 12.02158,
        "nubia": {
            "semantic_relation": 3.91582,
            "contradiction": 0.29207,
            "irrelevancy": 97.6818,
            "logical_agreement": 2.02613,
            "grammar_ref": 4.84215,
            "grammar_hyp": 4.86559,
            "nubia_score": 0.58047
        },
        "bleurt": -0.03315,
        "meteor": 0.30060648660403116,
        "bertscore": {
            "precision": 0.85925,
            "recall": 0.87634,
            "f1": 0.86771
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.040223928941851894,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5833333333333334
        },
        "nist": 1.8684827970831035,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.45455,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.5,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.5,
            "fmeasure": 0.44444
        },
        "bleu": 18.20705,
        "nubia": {
            "semantic_relation": 3.96522,
            "contradiction": 0.43035,
            "irrelevancy": 94.7493,
            "logical_agreement": 4.82035,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.69571,
            "nubia_score": 0.61497
        },
        "bleurt": -0.22832,
        "meteor": 0.3678311835893843,
        "bertscore": {
            "precision": 0.86586,
            "recall": 0.88786,
            "f1": 0.8735
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.75,
        "vocab_size-1": 24,
        "unique-1": 17,
        "entropy-1": 4.476409765557392,
        "distinct-2": 0.9,
        "vocab_size-2": 27,
        "unique-2": 24,
        "entropy-2": 4.706890595608519,
        "cond_entropy-2": 0.19872017901396744,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 26,
        "unique-3": 24,
        "entropy-3": 4.664497779200462,
        "cond_entropy-3": -0.028107102122342933,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8076923076923077,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.286790198827111,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.418295834054489,
        "cond_entropy-2-nopunct": 0.16597642850354194,
        "distinct-3-nopunct": 0.9545454545454546,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.368522527728205,
        "cond_entropy-3-nopunct": -0.034621791174768206,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.125,
            "2": 0.75,
            "3": 0.8
        },
        "nist": 3.2438403261632938,
        "rouge1": {
            "precision": 0.66993,
            "recall": 0.82593,
            "fmeasure": 0.71592
        },
        "rouge2": {
            "precision": 0.39583,
            "recall": 0.44444,
            "fmeasure": 0.40523
        },
        "rougeL": {
            "precision": 0.63072,
            "recall": 0.62985,
            "fmeasure": 0.62241
        },
        "rougeLsum": {
            "precision": 0.63072,
            "recall": 0.62985,
            "fmeasure": 0.62241
        },
        "bleu": 27.11891,
        "nubia": {
            "semantic_relation": 4.35149,
            "contradiction": 45.78152,
            "irrelevancy": 30.47207,
            "logical_agreement": 23.74641,
            "grammar_ref": 5.12311,
            "grammar_hyp": 4.44334,
            "nubia_score": 0.66949
        },
        "bleurt": 0.43004,
        "meteor": 0.39726390885463486,
        "bertscore": {
            "precision": 0.90433,
            "recall": 0.93643,
            "f1": 0.91963
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 3.1161477829600597,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.77778,
            "fmeasure": 0.875
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.625,
            "fmeasure": 0.71429
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.77778,
            "fmeasure": 0.875
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.77778,
            "fmeasure": 0.875
        },
        "bleu": 64.32189,
        "nubia": {
            "semantic_relation": 4.85063,
            "contradiction": 1.10088,
            "irrelevancy": 0.68835,
            "logical_agreement": 98.21077,
            "grammar_ref": 5.69157,
            "grammar_hyp": 6.24095,
            "nubia_score": 0.82275
        },
        "bleurt": 0.65056,
        "meteor": 0.48301897589178006,
        "bertscore": {
            "precision": 0.97264,
            "recall": 0.93947,
            "f1": 0.95576
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094898,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.16253715874966057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.5555555555555556
        },
        "nist": 1.9290939644570329,
        "rouge1": {
            "precision": 0.53704,
            "recall": 0.69444,
            "fmeasure": 0.60404
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.35931,
            "fmeasure": 0.31029
        },
        "rougeL": {
            "precision": 0.37037,
            "recall": 0.52222,
            "fmeasure": 0.43232
        },
        "rougeLsum": {
            "precision": 0.37037,
            "recall": 0.52222,
            "fmeasure": 0.43232
        },
        "bleu": 14.87964,
        "nubia": {
            "semantic_relation": 4.9372,
            "contradiction": 0.18877,
            "irrelevancy": 23.70595,
            "logical_agreement": 76.10528,
            "grammar_ref": 4.47457,
            "grammar_hyp": 3.45678,
            "nubia_score": 0.99611
        },
        "bleurt": 0.52349,
        "meteor": 0.3703060603169643,
        "bertscore": {
            "precision": 0.8815,
            "recall": 0.91842,
            "f1": 0.89958
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.0562872997343227,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.04978793508525298,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "nist": 2.0146757378612445,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.92857,
            "fmeasure": 0.82857
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.55,
            "fmeasure": 0.48077
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.70238,
            "fmeasure": 0.62381
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.70238,
            "fmeasure": 0.62381
        },
        "bleu": 16.10899,
        "nubia": {
            "semantic_relation": 4.95715,
            "contradiction": 0.38296,
            "irrelevancy": 35.53863,
            "logical_agreement": 64.07841,
            "grammar_ref": 7.77345,
            "grammar_hyp": 5.40271,
            "nubia_score": 1.0
        },
        "bleurt": 0.38729,
        "meteor": 0.41032530309431586,
        "bertscore": {
            "precision": 0.87914,
            "recall": 0.9173,
            "f1": 0.89782
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.142914673354254,
        "distinct-2": 0.9545454545454546,
        "vocab_size-2": 21,
        "unique-2": 20,
        "entropy-2": 4.368522527728205,
        "cond_entropy-2": 0.24291000358771486,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": 0.02812389937955851,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.975418017913833,
        "distinct-2-nopunct": 0.95,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.221928094887362,
        "cond_entropy-2-nopunct": 0.2673550472167754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": 0.03126257645096008,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.0,
            "3": 0.8
        },
        "nist": 2.912664908775253,
        "rouge1": {
            "precision": 0.52381,
            "recall": 0.74762,
            "fmeasure": 0.61587
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.34127,
            "fmeasure": 0.27696
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.48376,
            "fmeasure": 0.39434
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.48376,
            "fmeasure": 0.39434
        },
        "bleu": 16.02072,
        "nubia": {
            "semantic_relation": 3.63249,
            "contradiction": 15.38582,
            "irrelevancy": 79.25989,
            "logical_agreement": 5.35429,
            "grammar_ref": 4.11472,
            "grammar_hyp": 2.84552,
            "nubia_score": 0.67919
        },
        "bleurt": -0.00287,
        "meteor": 0.37082577888416896,
        "bertscore": {
            "precision": 0.90235,
            "recall": 0.90248,
            "f1": 0.90242
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "nist": 1.639353622444082,
        "rouge1": {
            "precision": 0.31667,
            "recall": 0.65556,
            "fmeasure": 0.41905
        },
        "rouge2": {
            "precision": 0.15789,
            "recall": 0.35714,
            "fmeasure": 0.21445
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.55,
            "fmeasure": 0.35238
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.55,
            "fmeasure": 0.35238
        },
        "bleu": 13.52046,
        "nubia": {
            "semantic_relation": 3.65266,
            "contradiction": 0.10274,
            "irrelevancy": 99.77721,
            "logical_agreement": 0.12006,
            "grammar_ref": 4.70243,
            "grammar_hyp": 4.97731,
            "nubia_score": 0.4418
        },
        "bleurt": -0.32316,
        "meteor": 0.28264159975927516,
        "bertscore": {
            "precision": 0.83681,
            "recall": 0.92182,
            "f1": 0.85784
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "bleurt": 0.97683,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_backtranslation": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_test_turk_backtranslation",
        "N": 359,
        "msttr-100": 0.73052,
        "msttr-100_nopunct": 0.76365,
        "total_length": 5863,
        "mean_pred_length": 16.331476323119777,
        "std_pred_length": 6.027687814008299,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.37932798908408666,
        "vocab_size-1": 2224,
        "unique-1": 1655,
        "entropy-1": 9.009756055289097,
        "distinct-2": 0.8475654069767442,
        "vocab_size-2": 4665,
        "unique-2": 4347,
        "entropy-2": 11.905243141428835,
        "cond_entropy-2": 2.673015757197713,
        "distinct-3": 0.9710398445092323,
        "vocab_size-3": 4996,
        "unique-3": 4917,
        "entropy-3": 12.24107267955308,
        "cond_entropy-3": 0.35626338972034893,
        "total_length-nopunct": 5291,
        "mean_pred_length-nopunct": 14.73816155988858,
        "std_pred_length-nopunct": 5.670474570695715,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.41806841806841805,
        "vocab_size-1-nopunct": 2212,
        "unique-1-nopunct": 1651,
        "entropy-1-nopunct": 9.266498006327321,
        "distinct-2-nopunct": 0.8641524736415247,
        "vocab_size-2-nopunct": 4262,
        "unique-2-nopunct": 3995,
        "entropy-2-nopunct": 11.811168906971563,
        "cond_entropy-2-nopunct": 2.7026694828644335,
        "distinct-3-nopunct": 0.9842554122020556,
        "vocab_size-3-nopunct": 4501,
        "unique-3-nopunct": 4442,
        "entropy-3-nopunct": 12.124638305158143,
        "cond_entropy-3-nopunct": 0.3373291219935455,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_backtranslation.json",
        "local_recall": {
            "1": 0.05475382003395586,
            "2": 0.1532567049808429,
            "3": 0.25820568927789933,
            "4": 0.2931854199683043,
            "5": 0.3530633437175493,
            "6": 0.48007246376811596,
            "7": 0.6422298587247041
        },
        "nist": 6.243096764020989,
        "rouge1": {
            "precision": 0.69481,
            "recall": 0.58012,
            "fmeasure": 0.61667
        },
        "rouge2": {
            "precision": 0.45431,
            "recall": 0.37241,
            "fmeasure": 0.39681
        },
        "rougeL": {
            "precision": 0.64024,
            "recall": 0.53364,
            "fmeasure": 0.56757
        },
        "rougeLsum": {
            "precision": 0.64024,
            "recall": 0.53364,
            "fmeasure": 0.56757
        },
        "bleu": 36.45556,
        "sari": 41.48471,
        "nubia": {
            "semantic_relation": 3.49194,
            "contradiction": 13.54457,
            "irrelevancy": 24.98521,
            "logical_agreement": 61.47022,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.24487,
            "nubia_score": 0.48414
        },
        "bleurt": -0.18639,
        "meteor": 0.29959347056512886,
        "bertscore": {
            "precision": 0.90448,
            "recall": 0.88179,
            "f1": 0.88985
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 1.5,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 12,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.916126946588283,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.2766627222437725,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.1604646721932461,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.7254805569978675,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.26757499855768774,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.19264507794239588,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.6428571428571429,
            "3": 1.0
        },
        "nist": 5.185134525204288,
        "rouge1": {
            "precision": 0.86667,
            "recall": 0.88889,
            "fmeasure": 0.8725
        },
        "rouge2": {
            "precision": 0.74206,
            "recall": 0.76867,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.86616,
            "fmeasure": 0.84508
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.86616,
            "fmeasure": 0.84508
        },
        "bleu": 82.70342,
        "nubia": {
            "semantic_relation": 4.13539,
            "contradiction": 16.38626,
            "irrelevancy": 17.76298,
            "logical_agreement": 65.85076,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.38469,
            "nubia_score": 0.73526
        },
        "bleurt": 0.46111,
        "meteor": 0.6086153722946831,
        "bertscore": {
            "precision": 0.9715,
            "recall": 0.98384,
            "f1": 0.97759
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.9583333333333334,
        "vocab_size-1": 23,
        "unique-1": 22,
        "entropy-1": 4.501629167387823,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.025555977074987173,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9545454545454546,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.368522527728204,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.02812389937955851,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9444444444444444
        },
        "nist": 3.909692097447547,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.87982,
            "fmeasure": 0.82269
        },
        "rouge2": {
            "precision": 0.50794,
            "recall": 0.58285,
            "fmeasure": 0.54274
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.82807,
            "fmeasure": 0.77429
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.82807,
            "fmeasure": 0.77429
        },
        "bleu": 46.43434,
        "nubia": {
            "semantic_relation": 4.76762,
            "contradiction": 0.51179,
            "irrelevancy": 1.47431,
            "logical_agreement": 98.0139,
            "grammar_ref": 4.62058,
            "grammar_hyp": 4.25363,
            "nubia_score": 0.93459
        },
        "bleurt": 0.65166,
        "meteor": 0.47227601889630144,
        "bertscore": {
            "precision": 0.94918,
            "recall": 0.96783,
            "f1": 0.95841
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 3.3108073765504,
        "rouge1": {
            "precision": 0.5,
            "recall": 1.0,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.24242,
            "recall": 0.33333,
            "fmeasure": 0.27381
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 1.0,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 1.0,
            "fmeasure": 0.66667
        },
        "bleu": 42.61083,
        "nubia": {
            "semantic_relation": 4.37867,
            "contradiction": 0.37201,
            "irrelevancy": 62.13208,
            "logical_agreement": 37.49591,
            "grammar_ref": 5.78237,
            "grammar_hyp": 5.10906,
            "nubia_score": 0.7252
        },
        "bleurt": 0.34625,
        "meteor": 0.4360469943772266,
        "bertscore": {
            "precision": 0.88959,
            "recall": 0.92476,
            "f1": 0.89877
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7272727272727273
        },
        "nist": 2.6996390168973416,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.54545,
            "fmeasure": 0.6
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.66667,
            "fmeasure": 0.72727
        },
        "bleu": 52.6561,
        "nubia": {
            "semantic_relation": 4.13086,
            "contradiction": 0.63106,
            "irrelevancy": 21.16836,
            "logical_agreement": 78.20058,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.4501,
            "nubia_score": 0.86642
        },
        "bleurt": 0.54722,
        "meteor": 0.4000589570944282,
        "bertscore": {
            "precision": 0.96234,
            "recall": 0.94385,
            "f1": 0.95301
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.462425934400558,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 4.21715,
            "contradiction": 0.42269,
            "irrelevancy": 0.62596,
            "logical_agreement": 98.95136,
            "grammar_ref": 6.37596,
            "grammar_hyp": 6.07415,
            "nubia_score": 0.84205
        },
        "bleurt": 0.45919,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.373660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.22255995686990962,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.02961067210860201,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.7142857142857143
        },
        "nist": 2.9716280008111067,
        "rouge1": {
            "precision": 0.56522,
            "recall": 0.66579,
            "fmeasure": 0.6113
        },
        "rouge2": {
            "precision": 0.34091,
            "recall": 0.40497,
            "fmeasure": 0.37012
        },
        "rougeL": {
            "precision": 0.54348,
            "recall": 0.64079,
            "fmeasure": 0.58804
        },
        "rougeLsum": {
            "precision": 0.54348,
            "recall": 0.64079,
            "fmeasure": 0.58804
        },
        "bleu": 21.4274,
        "nubia": {
            "semantic_relation": 3.57968,
            "contradiction": 0.66017,
            "irrelevancy": 99.08478,
            "logical_agreement": 0.25506,
            "grammar_ref": 4.38153,
            "grammar_hyp": 4.49068,
            "nubia_score": 0.54311
        },
        "bleurt": -0.17821,
        "meteor": 0.32920391092607243,
        "bertscore": {
            "precision": 0.89125,
            "recall": 0.89939,
            "f1": 0.8953
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "nist": 4.502060569538222,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.51453,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.34226,
            "fmeasure": 0.34921
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.34226,
            "fmeasure": 0.34921
        },
        "bleu": 49.35579,
        "nubia": {
            "semantic_relation": 4.76119,
            "contradiction": 0.26908,
            "irrelevancy": 33.53051,
            "logical_agreement": 66.20041,
            "grammar_ref": 4.41465,
            "grammar_hyp": 4.7223,
            "nubia_score": 0.88644
        },
        "bleurt": 0.29739,
        "meteor": 0.4452980347402408,
        "bertscore": {
            "precision": 0.95538,
            "recall": 0.92773,
            "f1": 0.94135
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.1699250014423126,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.45873,
            "irrelevancy": 0.46812,
            "logical_agreement": 99.07315,
            "grammar_ref": 5.85687,
            "grammar_hyp": 5.85687,
            "nubia_score": 1.0
        },
        "bleurt": 0.95702,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666
        },
        "nist": 0.7054392373313632,
        "rouge1": {
            "precision": 0.16667,
            "recall": 0.13333,
            "fmeasure": 0.14815
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.08333,
            "recall": 0.06667,
            "fmeasure": 0.07407
        },
        "rougeLsum": {
            "precision": 0.08333,
            "recall": 0.06667,
            "fmeasure": 0.07407
        },
        "bleu": 3.1935,
        "nubia": {
            "semantic_relation": 1.7099,
            "contradiction": 1.44669,
            "irrelevancy": 97.99002,
            "logical_agreement": 0.56328,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.99597,
            "nubia_score": 0.11341
        },
        "bleurt": -0.6843,
        "meteor": 0.07766990291262137,
        "bertscore": {
            "precision": 0.77193,
            "recall": 0.75004,
            "f1": 0.76016
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "nist": 3.31524196457992,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.41071,
            "fmeasure": 0.48718
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "bleu": 55.31346,
        "nubia": {
            "semantic_relation": 4.60143,
            "contradiction": 1.74221,
            "irrelevancy": 1.04658,
            "logical_agreement": 97.21121,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.09601,
            "nubia_score": 0.77855
        },
        "bleurt": 0.52933,
        "meteor": 0.45766768780018025,
        "bertscore": {
            "precision": 0.98405,
            "recall": 0.95755,
            "f1": 0.97062
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.854285871987245,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "bleurt": 0.94692,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "nist": 3.1439774686768684,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "bleu": 39.28147,
        "nubia": {
            "semantic_relation": 3.02474,
            "contradiction": 0.99781,
            "irrelevancy": 95.74615,
            "logical_agreement": 3.25604,
            "grammar_ref": 3.66596,
            "grammar_hyp": 2.72226,
            "nubia_score": 0.61815
        },
        "bleurt": 0.3091,
        "meteor": 0.49043387317825937,
        "bertscore": {
            "precision": 0.92527,
            "recall": 0.9304,
            "f1": 0.92783
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.10341647163363249,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.025555977074987163,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.47368421052631576
        },
        "nist": 1.9020552939522295,
        "rouge1": {
            "precision": 0.42308,
            "recall": 0.48,
            "fmeasure": 0.44935
        },
        "rouge2": {
            "precision": 0.16,
            "recall": 0.18254,
            "fmeasure": 0.17036
        },
        "rougeL": {
            "precision": 0.34615,
            "recall": 0.39273,
            "fmeasure": 0.36765
        },
        "rougeLsum": {
            "precision": 0.34615,
            "recall": 0.39273,
            "fmeasure": 0.36765
        },
        "bleu": 7.61224,
        "nubia": {
            "semantic_relation": 3.54034,
            "contradiction": 5.3727,
            "irrelevancy": 91.33012,
            "logical_agreement": 3.29717,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.80125,
            "nubia_score": 0.51766
        },
        "bleurt": -0.44882,
        "meteor": 0.21119077362504357,
        "bertscore": {
            "precision": 0.81146,
            "recall": 0.82012,
            "f1": 0.81286
        }
    },
    "web_nlg_en_challenge_test_numbers": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_challenge_test_numbers",
        "N": 500,
        "msttr-100": 0.66062,
        "msttr-100_nopunct": 0.68908,
        "total_length": 9683,
        "mean_pred_length": 19.366,
        "std_pred_length": 6.3343542685896566,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.13508210265413612,
        "vocab_size-1": 1308,
        "unique-1": 586,
        "entropy-1": 8.033887830394637,
        "distinct-2": 0.378416639442448,
        "vocab_size-2": 3475,
        "unique-2": 2129,
        "entropy-2": 10.842164838339675,
        "cond_entropy-2": 2.7533441548309843,
        "distinct-3": 0.5751468386502361,
        "vocab_size-3": 4994,
        "unique-3": 3632,
        "entropy-3": 11.76471431835195,
        "cond_entropy-3": 1.007169286967528,
        "total_length-nopunct": 8735,
        "mean_pred_length-nopunct": 17.47,
        "std_pred_length-nopunct": 6.012079507125633,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.14882655981682885,
        "vocab_size-1-nopunct": 1300,
        "unique-1-nopunct": 585,
        "entropy-1-nopunct": 8.217539580316906,
        "distinct-2-nopunct": 0.38688524590163936,
        "vocab_size-2-nopunct": 3186,
        "unique-2-nopunct": 1997,
        "entropy-2-nopunct": 10.71824662073193,
        "cond_entropy-2-nopunct": 2.667522812918124,
        "distinct-3-nopunct": 0.5824175824175825,
        "vocab_size-3-nopunct": 4505,
        "unique-3-nopunct": 3346,
        "entropy-3-nopunct": 11.60356580553456,
        "cond_entropy-3-nopunct": 0.9663111445549367,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_challenge_test_numbers.json",
        "local_recall": {
            "1": 0.1887936441563872,
            "2": 0.5012039903680771,
            "3": 0.7374081376590786,
            "4": 0.8888888888888888,
            "5": 0.8181818181818182
        },
        "nist": 6.607086994115869,
        "rouge1": {
            "precision": 0.76983,
            "recall": 0.66611,
            "fmeasure": 0.70121
        },
        "rouge2": {
            "precision": 0.51963,
            "recall": 0.44843,
            "fmeasure": 0.4714
        },
        "rougeL": {
            "precision": 0.63688,
            "recall": 0.55105,
            "fmeasure": 0.57994
        },
        "rougeLsum": {
            "precision": 0.63688,
            "recall": 0.55105,
            "fmeasure": 0.57994
        },
        "bleu": 39.73625,
        "nubia": {
            "semantic_relation": 3.96922,
            "contradiction": 20.68626,
            "irrelevancy": 8.16616,
            "logical_agreement": 71.14758,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.77732,
            "nubia_score": 0.62092
        },
        "bleurt": 0.01714,
        "meteor": 0.32482187356105907,
        "bertscore": {
            "precision": 0.91968,
            "recall": 0.89906,
            "f1": 0.90764
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "nist": 1.7904735309681654,
        "rouge1": {
            "precision": 0.4359,
            "recall": 0.84921,
            "fmeasure": 0.57544
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.46667,
            "fmeasure": 0.30065
        },
        "rougeL": {
            "precision": 0.35897,
            "recall": 0.69841,
            "fmeasure": 0.47368
        },
        "rougeLsum": {
            "precision": 0.35897,
            "recall": 0.69841,
            "fmeasure": 0.47368
        },
        "bleu": 8.60156,
        "nubia": {
            "semantic_relation": 3.44353,
            "contradiction": 5.30952,
            "irrelevancy": 94.21428,
            "logical_agreement": 0.4762,
            "grammar_ref": 6.44614,
            "grammar_hyp": 5.91257,
            "nubia_score": 0.40486
        },
        "bleurt": -0.83526,
        "meteor": 0.33535086024415484,
        "bertscore": {
            "precision": 0.82777,
            "recall": 0.90124,
            "f1": 0.86294
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 11,
        "unique-2": 10,
        "entropy-2": 3.418295834054489,
        "cond_entropy-2": 0.05118944924673079,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": 0.056287299734322706,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.2776134368191165,
        "cond_entropy-2-nopunct": 0.05628729973432269,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": 0.06249647625006499,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2,
            "2": 0.5555555555555556
        },
        "nist": 2.155559687509084,
        "rouge1": {
            "precision": 0.54167,
            "recall": 0.43333,
            "fmeasure": 0.48148
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.14286,
            "fmeasure": 0.16
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.4,
            "fmeasure": 0.44444
        },
        "bleu": 12.91053,
        "nubia": {
            "semantic_relation": 3.06272,
            "contradiction": 42.00632,
            "irrelevancy": 49.66542,
            "logical_agreement": 8.32825,
            "grammar_ref": 5.62728,
            "grammar_hyp": 4.86609,
            "nubia_score": 0.38729
        },
        "bleurt": -0.70796,
        "meteor": 0.2203145156124437,
        "bertscore": {
            "precision": 0.88616,
            "recall": 0.84269,
            "f1": 0.86388
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "nist": 3.042602225169786,
        "rouge1": {
            "precision": 0.72549,
            "recall": 0.82633,
            "fmeasure": 0.77103
        },
        "rouge2": {
            "precision": 0.4375,
            "recall": 0.50481,
            "fmeasure": 0.46767
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.7591,
            "fmeasure": 0.70841
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.7591,
            "fmeasure": 0.70841
        },
        "bleu": 36.65883,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18191,
            "irrelevancy": 0.45762,
            "logical_agreement": 99.36048,
            "grammar_ref": 5.90677,
            "grammar_hyp": 5.4846,
            "nubia_score": 0.99755
        },
        "bleurt": 0.53218,
        "meteor": 0.4391622125012075,
        "bertscore": {
            "precision": 0.94155,
            "recall": 0.97214,
            "f1": 0.95578
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.6875,
        "vocab_size-1": 11,
        "unique-1": 7,
        "entropy-1": 3.327819531114783,
        "distinct-2": 0.8,
        "vocab_size-2": 12,
        "unique-2": 9,
        "entropy-2": 3.5068905956085183,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 13,
        "unique-3": 12,
        "entropy-3": 3.6644977792004623,
        "cond_entropy-3": 0.18617861216337128,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6153846153846154,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.873140679513133,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.084962500721156,
        "cond_entropy-2-nopunct": 0.2807634077603532,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.2776134368191165,
        "cond_entropy-3-nopunct": 0.23810548155250458,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "nist": 2.335875509205763,
        "rouge1": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "bleu": 48.41525,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.80225,
            "irrelevancy": 2.20481,
            "logical_agreement": 94.99294,
            "grammar_ref": 7.00423,
            "grammar_hyp": 4.8462,
            "nubia_score": 1.0
        },
        "bleurt": 0.72955,
        "meteor": 0.5158883169898099,
        "bertscore": {
            "precision": 0.94806,
            "recall": 0.97904,
            "f1": 0.9633
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.8,
        "vocab_size-1": 8,
        "unique-1": 6,
        "entropy-1": 2.9219280948873623,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 8,
        "unique-2": 7,
        "entropy-2": 2.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": 0.08007499855768763,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.75,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "nist": 3.47872969366552,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "bleurt": 0.9148,
        "meteor": 1.0,
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.02961067210860201,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.6
        },
        "nist": 3.393974939457842,
        "rouge1": {
            "precision": 0.49123,
            "recall": 0.46685,
            "fmeasure": 0.47778
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.20833,
            "fmeasure": 0.21465
        },
        "rougeL": {
            "precision": 0.2807,
            "recall": 0.26891,
            "fmeasure": 0.27407
        },
        "rougeLsum": {
            "precision": 0.2807,
            "recall": 0.26891,
            "fmeasure": 0.27407
        },
        "bleu": 12.4939,
        "nubia": {
            "semantic_relation": 3.36778,
            "contradiction": 49.66611,
            "irrelevancy": 41.38624,
            "logical_agreement": 8.94764,
            "grammar_ref": 5.50536,
            "grammar_hyp": 5.11424,
            "nubia_score": 0.45666
        },
        "bleurt": -0.15465,
        "meteor": 0.2805660541637625,
        "bertscore": {
            "precision": 0.86019,
            "recall": 0.86484,
            "f1": 0.86251
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.59375,
        "vocab_size-1": 19,
        "unique-1": 8,
        "entropy-1": 4.125,
        "distinct-2": 0.7333333333333333,
        "vocab_size-2": 22,
        "unique-2": 14,
        "entropy-2": 4.3735572622751855,
        "cond_entropy-2": 0.2402239289418519,
        "distinct-3": 0.8214285714285714,
        "vocab_size-3": 23,
        "unique-3": 18,
        "entropy-3": 4.450212064914749,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.8349625007211565,
        "distinct-2-nopunct": 0.7727272727272727,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 4.004886164091841,
        "cond_entropy-2-nopunct": 0.1471963906434136,
        "distinct-3-nopunct": 0.85,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.021928094887363,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9565217391304348
        },
        "nist": 4.657835095962392,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 85.40367,
        "nubia": {
            "semantic_relation": 4.6462,
            "contradiction": 0.30413,
            "irrelevancy": 1.00416,
            "logical_agreement": 98.6917,
            "grammar_ref": 4.1188,
            "grammar_hyp": 3.78084,
            "nubia_score": 0.92152
        },
        "bleurt": 0.51045,
        "meteor": 0.4961626845121834,
        "bertscore": {
            "precision": 0.98441,
            "recall": 0.94461,
            "f1": 0.96342
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.7,
        "vocab_size-1": 14,
        "unique-1": 9,
        "entropy-1": 3.684183719779189,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 17,
        "unique-2": 15,
        "entropy-2": 4.03740119765411,
        "cond_entropy-2": 0.3867829713016689,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": 0.14421971022094895,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.576617644908665,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.94770277922009,
        "cond_entropy-2-nopunct": 0.3203266547455219,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": 0.15283195745508582,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.6666666666666666
        },
        "nist": 1.7332279758905071,
        "rouge1": {
            "precision": 0.34211,
            "recall": 0.58547,
            "fmeasure": 0.42857
        },
        "rouge2": {
            "precision": 0.19444,
            "recall": 0.33333,
            "fmeasure": 0.24359
        },
        "rougeL": {
            "precision": 0.34211,
            "recall": 0.58547,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.34211,
            "recall": 0.58547,
            "fmeasure": 0.42857
        },
        "bleu": 14.02578,
        "nubia": {
            "semantic_relation": 3.6823,
            "contradiction": 1.10305,
            "irrelevancy": 85.94281,
            "logical_agreement": 12.95414,
            "grammar_ref": 4.60771,
            "grammar_hyp": 4.92979,
            "nubia_score": 0.32877
        },
        "bleurt": -0.40635,
        "meteor": 0.31218313185867547,
        "bertscore": {
            "precision": 0.83266,
            "recall": 0.86568,
            "f1": 0.84395
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "nist": 2.385203785131205,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.71429,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.71429,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.71429,
            "fmeasure": 0.76923
        },
        "bleu": 35.64026,
        "nubia": {
            "semantic_relation": 4.06247,
            "contradiction": 1.60617,
            "irrelevancy": 0.77383,
            "logical_agreement": 97.61999,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.98753,
            "nubia_score": 0.68315
        },
        "bleurt": 0.73794,
        "meteor": 0.4312411957825655,
        "bertscore": {
            "precision": 0.98318,
            "recall": 0.94715,
            "f1": 0.96483
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333
        },
        "nist": 1.4900999659910577,
        "rouge1": {
            "precision": 0.26923,
            "recall": 0.33636,
            "fmeasure": 0.29891
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.16111,
            "fmeasure": 0.14069
        },
        "rougeL": {
            "precision": 0.26923,
            "recall": 0.33636,
            "fmeasure": 0.29891
        },
        "rougeLsum": {
            "precision": 0.26923,
            "recall": 0.33636,
            "fmeasure": 0.29891
        },
        "bleu": 12.01106,
        "nubia": {
            "semantic_relation": 4.36447,
            "contradiction": 0.13325,
            "irrelevancy": 45.72803,
            "logical_agreement": 54.13872,
            "grammar_ref": 4.7527,
            "grammar_hyp": 4.78515,
            "nubia_score": 0.69975
        },
        "bleurt": 0.24646,
        "meteor": 0.23521620399555637,
        "bertscore": {
            "precision": 0.83287,
            "recall": 0.86036,
            "f1": 0.84639
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 1.0,
        "median_pred_length": 20.0,
        "min_pred_length": 19,
        "max_pred_length": 21,
        "distinct-1": 0.8,
        "vocab_size-1": 32,
        "unique-1": 28,
        "entropy-1": 4.812814895472355,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.40927647057202,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.740436146246769,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.327524450123693,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "nist": 5.136999078256792,
        "rouge1": {
            "precision": 0.94281,
            "recall": 0.89181,
            "fmeasure": 0.9166
        },
        "rouge2": {
            "precision": 0.87868,
            "recall": 0.82843,
            "fmeasure": 0.85281
        },
        "rougeL": {
            "precision": 0.94281,
            "recall": 0.89181,
            "fmeasure": 0.9166
        },
        "rougeLsum": {
            "precision": 0.94281,
            "recall": 0.89181,
            "fmeasure": 0.9166
        },
        "bleu": 80.31547,
        "nubia": {
            "semantic_relation": 4.8319,
            "contradiction": 1.64142,
            "irrelevancy": 1.65284,
            "logical_agreement": 96.70574,
            "grammar_ref": 4.13564,
            "grammar_hyp": 4.42572,
            "nubia_score": 0.88185
        },
        "bleurt": 0.79017,
        "meteor": 0.5926469183591522,
        "bertscore": {
            "precision": 0.98622,
            "recall": 0.98109,
            "f1": 0.9814
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819113,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096008,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.5384615384615384
        },
        "nist": 2.4832697565278243,
        "rouge1": {
            "precision": 0.48333,
            "recall": 0.57966,
            "fmeasure": 0.52703
        },
        "rouge2": {
            "precision": 0.19298,
            "recall": 0.23333,
            "fmeasure": 0.2112
        },
        "rougeL": {
            "precision": 0.3,
            "recall": 0.36765,
            "fmeasure": 0.33033
        },
        "rougeLsum": {
            "precision": 0.3,
            "recall": 0.36765,
            "fmeasure": 0.33033
        },
        "bleu": 15.82129,
        "nubia": {
            "semantic_relation": 4.03548,
            "contradiction": 0.92984,
            "irrelevancy": 24.12545,
            "logical_agreement": 74.94471,
            "grammar_ref": 5.85115,
            "grammar_hyp": 5.07608,
            "nubia_score": 0.72802
        },
        "bleurt": 0.04925,
        "meteor": 0.25486420334347126,
        "bertscore": {
            "precision": 0.87097,
            "recall": 0.87665,
            "f1": 0.87222
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.5898980954642865,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.24009914803219054,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "nist": 2.2151921043978793,
        "rouge1": {
            "precision": 0.78571,
            "recall": 0.64706,
            "fmeasure": 0.70968
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.25,
            "fmeasure": 0.27586
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "bleu": 12.32985,
        "nubia": {
            "semantic_relation": 4.74791,
            "contradiction": 0.17485,
            "irrelevancy": 0.43597,
            "logical_agreement": 99.38919,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.72977,
            "nubia_score": 0.89946
        },
        "bleurt": 0.3972,
        "meteor": 0.2918706185479792,
        "bertscore": {
            "precision": 0.92129,
            "recall": 0.90559,
            "f1": 0.91338
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 2.0,
        "median_pred_length": 17.0,
        "min_pred_length": 15,
        "max_pred_length": 19,
        "distinct-1": 0.6764705882352942,
        "vocab_size-1": 23,
        "unique-1": 16,
        "entropy-1": 4.278351811711311,
        "distinct-2": 0.90625,
        "vocab_size-2": 29,
        "unique-2": 26,
        "entropy-2": 4.8125,
        "cond_entropy-2": 0.5222176276348776,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 29,
        "unique-3": 28,
        "entropy-3": 4.840223928941852,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.243856189774723,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.22753185323880998,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.03600643804015718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9545454545454546
        },
        "nist": 3.798859951013103,
        "rouge1": {
            "precision": 0.88141,
            "recall": 0.95833,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.82576,
            "recall": 0.90909,
            "fmeasure": 0.86364
        },
        "rougeL": {
            "precision": 0.88141,
            "recall": 0.95833,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.88141,
            "recall": 0.95833,
            "fmeasure": 0.91667
        },
        "bleu": 59.37272,
        "nubia": {
            "semantic_relation": 4.43234,
            "contradiction": 6.19265,
            "irrelevancy": 41.59277,
            "logical_agreement": 52.21458,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.5873,
            "nubia_score": 0.70507
        },
        "bleurt": 0.051,
        "meteor": 0.5263326628684739,
        "bertscore": {
            "precision": 0.90231,
            "recall": 0.9791,
            "f1": 0.93732
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "nist": 2.355710589176038,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.64133,
            "fmeasure": 0.57008
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.2037,
            "fmeasure": 0.17778
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.54971,
            "fmeasure": 0.48864
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.54971,
            "fmeasure": 0.48864
        },
        "bleu": 10.07471,
        "nubia": {
            "semantic_relation": 4.41641,
            "contradiction": 0.08277,
            "irrelevancy": 5.98007,
            "logical_agreement": 93.93716,
            "grammar_ref": 3.44041,
            "grammar_hyp": 3.51199,
            "nubia_score": 0.85963
        },
        "bleurt": 0.44036,
        "meteor": 0.400724566671953,
        "bertscore": {
            "precision": 0.91479,
            "recall": 0.93784,
            "f1": 0.92617
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 1.5,
        "median_pred_length": 19.5,
        "min_pred_length": 18,
        "max_pred_length": 21,
        "distinct-1": 0.5897435897435898,
        "vocab_size-1": 23,
        "unique-1": 11,
        "entropy-1": 4.387465039153175,
        "distinct-2": 0.7027027027027027,
        "vocab_size-2": 26,
        "unique-2": 16,
        "entropy-2": 4.5944564061110205,
        "cond_entropy-2": 0.2555285118069825,
        "distinct-3": 0.7428571428571429,
        "vocab_size-3": 26,
        "unique-3": 17,
        "entropy-3": 4.6149973026592495,
        "cond_entropy-3": 0.05568357994925863,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 4.2527152789797045,
        "distinct-2-nopunct": 0.6764705882352942,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.4182014441278845,
        "cond_entropy-2-nopunct": 0.21943967823421542,
        "distinct-3-nopunct": 0.71875,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 4.4375,
        "cond_entropy-3-nopunct": 0.06112739319226901,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.8
        },
        "nist": 3.562196332317535,
        "rouge1": {
            "precision": 0.95614,
            "recall": 0.77712,
            "fmeasure": 0.8445
        },
        "rouge2": {
            "precision": 0.89815,
            "recall": 0.72623,
            "fmeasure": 0.78828
        },
        "rougeL": {
            "precision": 0.90351,
            "recall": 0.73464,
            "fmeasure": 0.7965
        },
        "rougeLsum": {
            "precision": 0.90351,
            "recall": 0.73464,
            "fmeasure": 0.7965
        },
        "bleu": 64.98196,
        "nubia": {
            "semantic_relation": 4.25325,
            "contradiction": 1.03896,
            "irrelevancy": 1.23521,
            "logical_agreement": 97.72584,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.74801,
            "nubia_score": 0.70838
        },
        "bleurt": 0.18288,
        "meteor": 0.40153273094782005,
        "bertscore": {
            "precision": 0.95716,
            "recall": 0.91181,
            "f1": 0.9333
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5714285714285714
        },
        "nist": 1.8343758442311895,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.61616,
            "fmeasure": 0.71528
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.2375,
            "fmeasure": 0.27679
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.4596,
            "fmeasure": 0.53472
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.4596,
            "fmeasure": 0.53472
        },
        "bleu": 21.06976,
        "nubia": {
            "semantic_relation": 4.25265,
            "contradiction": 8.40382,
            "irrelevancy": 5.19354,
            "logical_agreement": 86.40264,
            "grammar_ref": 5.60099,
            "grammar_hyp": 7.87017,
            "nubia_score": 0.41217
        },
        "bleurt": -1.0658,
        "meteor": 0.29891330307251945,
        "bertscore": {
            "precision": 0.85672,
            "recall": 0.87707,
            "f1": 0.86677
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "nist": 4.373609831586596,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.86667,
            "fmeasure": 0.89655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "bleu": 85.22457,
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35488,
            "irrelevancy": 10.42506,
            "logical_agreement": 89.22006,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.15345,
            "nubia_score": 0.98846
        },
        "bleurt": 0.78906,
        "meteor": 0.5747920211718521,
        "bertscore": {
            "precision": 0.99784,
            "recall": 0.98969,
            "f1": 0.99375
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.72,
        "total_length": 2250,
        "mean_pred_length": 21.22641509433962,
        "std_pred_length": 3.3794133097717904,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 30,
        "distinct-1": 0.4071111111111111,
        "vocab_size-1": 916,
        "unique-1": 646,
        "entropy-1": 8.32948631624853,
        "distinct-2": 0.8278917910447762,
        "vocab_size-2": 1775,
        "unique-2": 1594,
        "entropy-2": 10.57055933082657,
        "cond_entropy-2": 2.160415160954926,
        "distinct-3": 0.9607458292443573,
        "vocab_size-3": 1958,
        "unique-3": 1892,
        "entropy-3": 10.906860847468408,
        "cond_entropy-3": 0.35256753308195404,
        "total_length-nopunct": 2135,
        "mean_pred_length-nopunct": 20.141509433962263,
        "std_pred_length-nopunct": 3.5112720891257148,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.42576112412177985,
        "vocab_size-1-nopunct": 909,
        "unique-1-nopunct": 646,
        "entropy-1-nopunct": 8.382971614460129,
        "distinct-2-nopunct": 0.8299655002464268,
        "vocab_size-2-nopunct": 1684,
        "unique-2-nopunct": 1513,
        "entropy-2-nopunct": 10.495604236936785,
        "cond_entropy-2-nopunct": 2.193977400017274,
        "distinct-3-nopunct": 0.9620384815392615,
        "vocab_size-3-nopunct": 1850,
        "unique-3-nopunct": 1786,
        "entropy-3-nopunct": 10.829177141198116,
        "cond_entropy-3-nopunct": 0.3449272912319038,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.26497695852534564
        },
        "nist": 2.383174379051339,
        "rouge1": {
            "precision": 0.31639,
            "recall": 0.30095,
            "fmeasure": 0.30419
        },
        "rouge2": {
            "precision": 0.08937,
            "recall": 0.08686,
            "fmeasure": 0.08685
        },
        "rougeL": {
            "precision": 0.23835,
            "recall": 0.22822,
            "fmeasure": 0.22999
        },
        "rougeLsum": {
            "precision": 0.23835,
            "recall": 0.22822,
            "fmeasure": 0.22999
        },
        "bleu": 5.45227,
        "nubia": {
            "semantic_relation": 2.28,
            "contradiction": 33.1106,
            "irrelevancy": 58.49373,
            "logical_agreement": 8.39567,
            "grammar_ref": 3.78639,
            "grammar_hyp": 4.25223,
            "nubia_score": 0.25691
        },
        "bleurt": -0.62098,
        "meteor": 0.12221350072260717,
        "bertscore": {
            "precision": 0.80241,
            "recall": 0.79369,
            "f1": 0.79783
        }
    },
    "xsum_challenge_test_bfp_02_parent": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.72321,
        "msttr-100_nopunct": 0.72921,
        "total_length": 10656,
        "mean_pred_length": 21.312,
        "std_pred_length": 3.441897151281543,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.26191816816816815,
        "vocab_size-1": 2791,
        "unique-1": 1749,
        "entropy-1": 9.053537248924087,
        "distinct-2": 0.7148483654982276,
        "vocab_size-2": 7260,
        "unique-2": 6228,
        "entropy-2": 12.298532272939571,
        "cond_entropy-2": 3.1599366886480116,
        "distinct-3": 0.9169428334714167,
        "vocab_size-3": 8854,
        "unique-3": 8402,
        "entropy-3": 13.015517004547494,
        "cond_entropy-3": 0.7417155288109373,
        "total_length-nopunct": 10133,
        "mean_pred_length-nopunct": 20.266,
        "std_pred_length-nopunct": 3.6137576011680697,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.2744498174282049,
        "vocab_size-1-nopunct": 2781,
        "unique-1-nopunct": 1747,
        "entropy-1-nopunct": 9.141345284233376,
        "distinct-2-nopunct": 0.7195058652548532,
        "vocab_size-2-nopunct": 6931,
        "unique-2-nopunct": 5960,
        "entropy-2-nopunct": 12.236477030869791,
        "cond_entropy-2-nopunct": 3.2088826897477283,
        "distinct-3-nopunct": 0.9216029782108837,
        "vocab_size-3-nopunct": 8417,
        "unique-3-nopunct": 8007,
        "entropy-3-nopunct": 12.952695939163949,
        "cond_entropy-3-nopunct": 0.7378794194741374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.30695324881141045
        },
        "nist": 3.0216560414677005,
        "rouge1": {
            "precision": 0.34803,
            "recall": 0.33687,
            "fmeasure": 0.33695
        },
        "rouge2": {
            "precision": 0.11567,
            "recall": 0.11343,
            "fmeasure": 0.11229
        },
        "rougeL": {
            "precision": 0.26636,
            "recall": 0.25905,
            "fmeasure": 0.25834
        },
        "rougeLsum": {
            "precision": 0.26636,
            "recall": 0.25905,
            "fmeasure": 0.25834
        },
        "bleu": 6.83238,
        "nubia": {
            "semantic_relation": 2.38492,
            "contradiction": 29.78383,
            "irrelevancy": 60.76834,
            "logical_agreement": 9.44783,
            "grammar_ref": 3.74155,
            "grammar_hyp": 4.27789,
            "nubia_score": 0.28011
        },
        "bleurt": -0.59014,
        "meteor": 0.14084396375640154,
        "bertscore": {
            "precision": 0.8115,
            "recall": 0.80185,
            "f1": 0.80638
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1369,
        "msttr-100": 0.72399,
        "msttr-100_nopunct": 0.77468,
        "total_length": 25370,
        "mean_pred_length": 18.531775018261506,
        "std_pred_length": 4.631242379757569,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.252463539613717,
        "vocab_size-1": 6405,
        "unique-1": 4500,
        "entropy-1": 9.550993235523041,
        "distinct-2": 0.6651806174742719,
        "vocab_size-2": 15965,
        "unique-2": 13772,
        "entropy-2": 13.23717364471932,
        "cond_entropy-2": 3.435196765171675,
        "distinct-3": 0.8665606221279604,
        "vocab_size-3": 19612,
        "unique-3": 18306,
        "entropy-3": 14.053916718690658,
        "cond_entropy-3": 0.8254763506494511,
        "total_length-nopunct": 22210,
        "mean_pred_length-nopunct": 16.223520818115414,
        "std_pred_length-nopunct": 4.107894965101626,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.28766321476812245,
        "vocab_size-1-nopunct": 6389,
        "unique-1-nopunct": 4497,
        "entropy-1-nopunct": 10.010394974686406,
        "distinct-2-nopunct": 0.7035171057051005,
        "vocab_size-2-nopunct": 14662,
        "unique-2-nopunct": 12909,
        "entropy-2-nopunct": 13.16826317458291,
        "cond_entropy-2-nopunct": 3.2972957131339644,
        "distinct-3-nopunct": 0.88753081347576,
        "vocab_size-3-nopunct": 17282,
        "unique-3-nopunct": 16299,
        "entropy-3-nopunct": 13.906541166011698,
        "cond_entropy-3-nopunct": 0.7826217167080374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22502673796791445,
            "2": 0.4563889567554361,
            "3": 0.7778180281349997
        },
        "nist": 9.853487111245986,
        "rouge1": {
            "precision": 0.75673,
            "recall": 0.73813,
            "fmeasure": 0.73828
        },
        "rouge2": {
            "precision": 0.51862,
            "recall": 0.50877,
            "fmeasure": 0.50708
        },
        "rougeL": {
            "precision": 0.63704,
            "recall": 0.62596,
            "fmeasure": 0.62344
        },
        "rougeLsum": {
            "precision": 0.63704,
            "recall": 0.62596,
            "fmeasure": 0.62344
        },
        "bleu": 47.18107,
        "nubia": {
            "semantic_relation": 4.21271,
            "contradiction": 8.99349,
            "irrelevancy": 30.44316,
            "logical_agreement": 60.56335,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.50483,
            "nubia_score": 0.73026
        },
        "bleurt": 0.24253,
        "meteor": 0.3977467890211521,
        "bertscore": {
            "precision": 0.92852,
            "recall": 0.92608,
            "f1": 0.9258
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 483,
        "msttr-100": 0.72238,
        "msttr-100_nopunct": 0.76618,
        "total_length": 10161,
        "mean_pred_length": 21.03726708074534,
        "std_pred_length": 4.323207437985863,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 38,
        "distinct-1": 0.3142407243381557,
        "vocab_size-1": 3193,
        "unique-1": 2346,
        "entropy-1": 9.171165555313635,
        "distinct-2": 0.7383756974581525,
        "vocab_size-2": 7146,
        "unique-2": 6281,
        "entropy-2": 12.31521777005613,
        "cond_entropy-2": 2.992968266808913,
        "distinct-3": 0.9172376291462752,
        "vocab_size-3": 8434,
        "unique-3": 8007,
        "entropy-3": 12.951133059300078,
        "cond_entropy-3": 0.6429435707859866,
        "total_length-nopunct": 8986,
        "mean_pred_length-nopunct": 18.60455486542443,
        "std_pred_length-nopunct": 3.9671189903289648,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.35377253505452927,
        "vocab_size-1-nopunct": 3179,
        "unique-1-nopunct": 2342,
        "entropy-1-nopunct": 9.523764113083761,
        "distinct-2-nopunct": 0.7662001646477714,
        "vocab_size-2-nopunct": 6515,
        "unique-2-nopunct": 5817,
        "entropy-2-nopunct": 12.219657541696307,
        "cond_entropy-2-nopunct": 2.8041612365718387,
        "distinct-3-nopunct": 0.9268079800498753,
        "vocab_size-3-nopunct": 7433,
        "unique-3-nopunct": 7108,
        "entropy-3-nopunct": 12.777062091780712,
        "cond_entropy-3-nopunct": 0.5802023509021779,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.222803955788249,
            "2": 0.39419354838709675,
            "3": 0.7494162288382954
        },
        "nist": 8.665174059171546,
        "rouge1": {
            "precision": 0.73433,
            "recall": 0.71633,
            "fmeasure": 0.71679
        },
        "rouge2": {
            "precision": 0.4835,
            "recall": 0.47213,
            "fmeasure": 0.47179
        },
        "rougeL": {
            "precision": 0.59645,
            "recall": 0.58249,
            "fmeasure": 0.58228
        },
        "rougeLsum": {
            "precision": 0.59645,
            "recall": 0.58249,
            "fmeasure": 0.58228
        },
        "bleu": 41.22285,
        "nubia": {
            "semantic_relation": 4.08643,
            "contradiction": 10.27221,
            "irrelevancy": 33.04312,
            "logical_agreement": 56.68467,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.37185,
            "nubia_score": 0.69827
        },
        "bleurt": 0.14223,
        "meteor": 0.3746758357123401,
        "bertscore": {
            "precision": 0.91855,
            "recall": 0.91542,
            "f1": 0.91517
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.75
        },
        "nist": 2.8273350018471963,
        "rouge1": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.41751,
            "fmeasure": 0.38788
        },
        "rougeL": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "rougeLsum": {
            "precision": 0.63889,
            "recall": 0.79259,
            "fmeasure": 0.70707
        },
        "bleu": 35.41699,
        "nubia": {
            "semantic_relation": 4.217,
            "contradiction": 0.3805,
            "irrelevancy": 94.54951,
            "logical_agreement": 5.06999,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.45315,
            "nubia_score": 0.57521
        },
        "bleurt": 0.12552,
        "meteor": 0.40753581218515467,
        "bertscore": {
            "precision": 0.89404,
            "recall": 0.89885,
            "f1": 0.89644
        }
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.2178561159133974,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0957952550009344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.262496476250065,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "nist": 2.073374652101981,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.81667,
            "fmeasure": 0.67879
        },
        "rouge2": {
            "precision": 0.36364,
            "recall": 0.5291,
            "fmeasure": 0.42963
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.81667,
            "fmeasure": 0.67879
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.81667,
            "fmeasure": 0.67879
        },
        "bleu": 34.38931,
        "nubia": {
            "semantic_relation": 4.0657,
            "contradiction": 1.53134,
            "irrelevancy": 75.03025,
            "logical_agreement": 23.43842,
            "grammar_ref": 4.01433,
            "grammar_hyp": 3.88981,
            "nubia_score": 0.6912
        },
        "bleurt": 0.23582,
        "meteor": 0.47121535899770933,
        "bertscore": {
            "precision": 0.88092,
            "recall": 0.93531,
            "f1": 0.90692
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72095,
        "msttr-100_nopunct": 0.7345,
        "total_length": 2172,
        "mean_pred_length": 20.49056603773585,
        "std_pred_length": 3.647809585757034,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.4129834254143646,
        "vocab_size-1": 897,
        "unique-1": 652,
        "entropy-1": 8.331631530467545,
        "distinct-2": 0.8286544046466602,
        "vocab_size-2": 1712,
        "unique-2": 1542,
        "entropy-2": 10.522483885485016,
        "cond_entropy-2": 2.0962647471562743,
        "distinct-3": 0.9530612244897959,
        "vocab_size-3": 1868,
        "unique-3": 1801,
        "entropy-3": 10.831008949983588,
        "cond_entropy-3": 0.3230945367264089,
        "total_length-nopunct": 2060,
        "mean_pred_length-nopunct": 19.433962264150942,
        "std_pred_length-nopunct": 3.7417049587822935,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4320388349514563,
        "vocab_size-1-nopunct": 890,
        "unique-1-nopunct": 651,
        "entropy-1-nopunct": 8.396081891534141,
        "distinct-2-nopunct": 0.8275332650972365,
        "vocab_size-2-nopunct": 1617,
        "unique-2-nopunct": 1458,
        "entropy-2-nopunct": 10.434200005356933,
        "cond_entropy-2-nopunct": 2.13556332201766,
        "distinct-3-nopunct": 0.9534632034632035,
        "vocab_size-3-nopunct": 1762,
        "unique-3-nopunct": 1699,
        "entropy-3-nopunct": 10.747294053062896,
        "cond_entropy-3-nopunct": 0.3301723726248092,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2812206572769953
        },
        "nist": 2.5852660527799336,
        "rouge1": {
            "precision": 0.34198,
            "recall": 0.31816,
            "fmeasure": 0.32266
        },
        "rouge2": {
            "precision": 0.11913,
            "recall": 0.11259,
            "fmeasure": 0.11319
        },
        "rougeL": {
            "precision": 0.26301,
            "recall": 0.24733,
            "fmeasure": 0.24931
        },
        "rougeLsum": {
            "precision": 0.26301,
            "recall": 0.24733,
            "fmeasure": 0.24931
        },
        "bleu": 6.62764,
        "nubia": {
            "semantic_relation": 2.22446,
            "contradiction": 36.22895,
            "irrelevancy": 53.96473,
            "logical_agreement": 9.80631,
            "grammar_ref": 3.81724,
            "grammar_hyp": 4.30389,
            "nubia_score": 0.24226
        },
        "bleurt": -0.58317,
        "meteor": 0.12977786690740378,
        "bertscore": {
            "precision": 0.80881,
            "recall": 0.79715,
            "f1": 0.80266
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 335,
        "msttr-100": 0.66642,
        "msttr-100_nopunct": 0.66851,
        "total_length": 8158,
        "mean_pred_length": 24.35223880597015,
        "std_pred_length": 3.4270372831334406,
        "median_pred_length": 25.0,
        "min_pred_length": 15,
        "max_pred_length": 33,
        "distinct-1": 0.11461142436871782,
        "vocab_size-1": 935,
        "unique-1": 451,
        "entropy-1": 7.5797454981462735,
        "distinct-2": 0.33312028633516555,
        "vocab_size-2": 2606,
        "unique-2": 1590,
        "entropy-2": 10.213442836919608,
        "cond_entropy-2": 2.596175999292617,
        "distinct-3": 0.5443376068376068,
        "vocab_size-3": 4076,
        "unique-3": 2987,
        "entropy-3": 11.380237285148795,
        "cond_entropy-3": 1.1673115948474457,
        "total_length-nopunct": 7473,
        "mean_pred_length-nopunct": 22.307462686567163,
        "std_pred_length-nopunct": 3.172329688350941,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.12337749230563362,
        "vocab_size-1-nopunct": 922,
        "unique-1-nopunct": 449,
        "entropy-1-nopunct": 7.618483365125775,
        "distinct-2-nopunct": 0.3530400672457271,
        "vocab_size-2-nopunct": 2520,
        "unique-2-nopunct": 1596,
        "entropy-2-nopunct": 10.176118047133558,
        "cond_entropy-2-nopunct": 2.5869531728653463,
        "distinct-3-nopunct": 0.5626929295898868,
        "vocab_size-3-nopunct": 3828,
        "unique-3-nopunct": 2876,
        "entropy-3-nopunct": 11.284828409783536,
        "cond_entropy-3-nopunct": 1.1255920726435764,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6365605095541401
        },
        "nist": 6.601249332558499,
        "rouge1": {
            "precision": 0.74076,
            "recall": 0.65462,
            "fmeasure": 0.688
        },
        "rouge2": {
            "precision": 0.51823,
            "recall": 0.45737,
            "fmeasure": 0.48084
        },
        "rougeL": {
            "precision": 0.63452,
            "recall": 0.5603,
            "fmeasure": 0.589
        },
        "rougeLsum": {
            "precision": 0.63452,
            "recall": 0.5603,
            "fmeasure": 0.589
        },
        "bleu": 37.3709,
        "nubia": {
            "semantic_relation": 4.25303,
            "contradiction": 5.13495,
            "irrelevancy": 11.37255,
            "logical_agreement": 83.49251,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.57419,
            "nubia_score": 0.7257
        },
        "bleurt": -0.03638,
        "meteor": 0.3540515822733101,
        "bertscore": {
            "precision": 0.90692,
            "recall": 0.88771,
            "f1": 0.89695
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.70524,
        "msttr-100_nopunct": 0.71579,
        "total_length": 2116,
        "mean_pred_length": 19.962264150943398,
        "std_pred_length": 4.148026419335742,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 28,
        "distinct-1": 0.41351606805293006,
        "vocab_size-1": 875,
        "unique-1": 624,
        "entropy-1": 8.283862550171113,
        "distinct-2": 0.844776119402985,
        "vocab_size-2": 1698,
        "unique-2": 1557,
        "entropy-2": 10.50777029344452,
        "cond_entropy-2": 2.1026877180284425,
        "distinct-3": 0.9648109243697479,
        "vocab_size-3": 1837,
        "unique-3": 1789,
        "entropy-3": 10.81517031557068,
        "cond_entropy-3": 0.320380572741933,
        "total_length-nopunct": 1996,
        "mean_pred_length-nopunct": 18.830188679245282,
        "std_pred_length-nopunct": 4.205727671571117,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4348697394789579,
        "vocab_size-1-nopunct": 868,
        "unique-1-nopunct": 624,
        "entropy-1-nopunct": 8.360267355801641,
        "distinct-2-nopunct": 0.846031746031746,
        "vocab_size-2-nopunct": 1599,
        "unique-2-nopunct": 1470,
        "entropy-2-nopunct": 10.416817798124828,
        "cond_entropy-2-nopunct": 2.148053674140497,
        "distinct-3-nopunct": 0.9646860986547086,
        "vocab_size-3-nopunct": 1721,
        "unique-3-nopunct": 1675,
        "entropy-3-nopunct": 10.721500381707358,
        "cond_entropy-3-nopunct": 0.32244998161000443,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.24221789883268482
        },
        "nist": 2.163370888782558,
        "rouge1": {
            "precision": 0.29341,
            "recall": 0.2757,
            "fmeasure": 0.27746
        },
        "rouge2": {
            "precision": 0.08682,
            "recall": 0.08443,
            "fmeasure": 0.08316
        },
        "rougeL": {
            "precision": 0.23004,
            "recall": 0.21819,
            "fmeasure": 0.21851
        },
        "rougeLsum": {
            "precision": 0.23004,
            "recall": 0.21819,
            "fmeasure": 0.21851
        },
        "bleu": 5.20903,
        "nubia": {
            "semantic_relation": 2.05654,
            "contradiction": 32.45126,
            "irrelevancy": 60.78983,
            "logical_agreement": 6.75891,
            "grammar_ref": 3.93729,
            "grammar_hyp": 4.47533,
            "nubia_score": 0.22125
        },
        "bleurt": -0.6946,
        "meteor": 0.10881961659437978,
        "bertscore": {
            "precision": 0.79787,
            "recall": 0.78358,
            "f1": 0.79034
        }
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 379,
        "msttr-100": 0.71976,
        "msttr-100_nopunct": 0.76123,
        "total_length": 8334,
        "mean_pred_length": 21.989445910290236,
        "std_pred_length": 3.85281920001074,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.3449724022078234,
        "vocab_size-1": 2875,
        "unique-1": 2098,
        "entropy-1": 9.217777043976767,
        "distinct-2": 0.7783783783783784,
        "vocab_size-2": 6192,
        "unique-2": 5454,
        "entropy-2": 12.226036912963494,
        "cond_entropy-2": 2.9060218498503434,
        "distinct-3": 0.9361140443505808,
        "vocab_size-3": 7092,
        "unique-3": 6758,
        "entropy-3": 12.738433375541334,
        "cond_entropy-3": 0.5133277475093172,
        "total_length-nopunct": 7351,
        "mean_pred_length-nopunct": 19.395778364116094,
        "std_pred_length-nopunct": 3.7748764139138973,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.3890627125561148,
        "vocab_size-1-nopunct": 2860,
        "unique-1-nopunct": 2096,
        "entropy-1-nopunct": 9.558404796219612,
        "distinct-2-nopunct": 0.811675272518646,
        "vocab_size-2-nopunct": 5659,
        "unique-2-nopunct": 5093,
        "entropy-2-nopunct": 12.144795131350163,
        "cond_entropy-2-nopunct": 2.6738016066292998,
        "distinct-3-nopunct": 0.9460033368724404,
        "vocab_size-3-nopunct": 6237,
        "unique-3-nopunct": 5982,
        "entropy-3-nopunct": 12.562087978307758,
        "cond_entropy-3-nopunct": 0.4327397812823234,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.2425595238095238,
            "2": 0.41444600280504906,
            "3": 0.7239507959479016
        },
        "nist": 8.197737584589134,
        "rouge1": {
            "precision": 0.73627,
            "recall": 0.68863,
            "fmeasure": 0.7031
        },
        "rouge2": {
            "precision": 0.48051,
            "recall": 0.44702,
            "fmeasure": 0.457
        },
        "rougeL": {
            "precision": 0.59966,
            "recall": 0.56322,
            "fmeasure": 0.57321
        },
        "rougeLsum": {
            "precision": 0.59966,
            "recall": 0.56322,
            "fmeasure": 0.57321
        },
        "bleu": 38.29713,
        "nubia": {
            "semantic_relation": 3.9501,
            "contradiction": 11.43565,
            "irrelevancy": 30.52519,
            "logical_agreement": 58.03915,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.41678,
            "nubia_score": 0.64729
        },
        "bleurt": 0.08978,
        "meteor": 0.3544102219112866,
        "bertscore": {
            "precision": 0.91754,
            "recall": 0.90961,
            "f1": 0.9121
        }
    },
    "xsum_challenge_test_bfp_05_parent": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.71819,
        "msttr-100_nopunct": 0.7266,
        "total_length": 10592,
        "mean_pred_length": 21.184,
        "std_pred_length": 3.6086207891658555,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.26510574018126887,
        "vocab_size-1": 2808,
        "unique-1": 1736,
        "entropy-1": 9.088699875893692,
        "distinct-2": 0.7281014665081252,
        "vocab_size-2": 7348,
        "unique-2": 6322,
        "entropy-2": 12.345006666108903,
        "cond_entropy-2": 3.1602262435322372,
        "distinct-3": 0.9222268557130943,
        "vocab_size-3": 8846,
        "unique-3": 8396,
        "entropy-3": 13.027001566802682,
        "cond_entropy-3": 0.7037729154100404,
        "total_length-nopunct": 10060,
        "mean_pred_length-nopunct": 20.12,
        "std_pred_length-nopunct": 3.711818961102494,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.27813121272365804,
        "vocab_size-1-nopunct": 2798,
        "unique-1-nopunct": 1736,
        "entropy-1-nopunct": 9.180050904310717,
        "distinct-2-nopunct": 0.7319037656903765,
        "vocab_size-2-nopunct": 6997,
        "unique-2-nopunct": 6040,
        "entropy-2-nopunct": 12.276194599981842,
        "cond_entropy-2-nopunct": 3.2115721074210533,
        "distinct-3-nopunct": 0.9240618101545254,
        "vocab_size-3-nopunct": 8372,
        "unique-3-nopunct": 7953,
        "entropy-3-nopunct": 12.95126109233742,
        "cond_entropy-3-nopunct": 0.697469357142709,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.30824372759856633
        },
        "nist": 3.082907833641763,
        "rouge1": {
            "precision": 0.34827,
            "recall": 0.33424,
            "fmeasure": 0.33575
        },
        "rouge2": {
            "precision": 0.11616,
            "recall": 0.11254,
            "fmeasure": 0.11227
        },
        "rougeL": {
            "precision": 0.26633,
            "recall": 0.25686,
            "fmeasure": 0.25718
        },
        "rougeLsum": {
            "precision": 0.26633,
            "recall": 0.25686,
            "fmeasure": 0.25718
        },
        "bleu": 7.14954,
        "nubia": {
            "semantic_relation": 2.36258,
            "contradiction": 33.69969,
            "irrelevancy": 56.68659,
            "logical_agreement": 9.61372,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.37409,
            "nubia_score": 0.26816
        },
        "bleurt": -0.599,
        "meteor": 0.1421396499245526,
        "bertscore": {
            "precision": 0.81329,
            "recall": 0.80207,
            "f1": 0.80738
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 256,
        "msttr-100": 0.64077,
        "msttr-100_nopunct": 0.64067,
        "total_length": 6505,
        "mean_pred_length": 25.41015625,
        "std_pred_length": 3.359881411684933,
        "median_pred_length": 26.0,
        "min_pred_length": 15,
        "max_pred_length": 33,
        "distinct-1": 0.09254419677171406,
        "vocab_size-1": 602,
        "unique-1": 270,
        "entropy-1": 7.202633423215325,
        "distinct-2": 0.29332693230916945,
        "vocab_size-2": 1833,
        "unique-2": 1021,
        "entropy-2": 9.752265616321045,
        "cond_entropy-2": 2.5683094265507385,
        "distinct-3": 0.5132654763891207,
        "vocab_size-3": 3076,
        "unique-3": 2145,
        "entropy-3": 10.96725081108965,
        "cond_entropy-3": 1.2620163173779289,
        "total_length-nopunct": 6047,
        "mean_pred_length-nopunct": 23.62109375,
        "std_pred_length-nopunct": 3.151293195453406,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.09839589879278982,
        "vocab_size-1-nopunct": 595,
        "unique-1-nopunct": 270,
        "entropy-1-nopunct": 7.205558516134498,
        "distinct-2-nopunct": 0.3037471939216025,
        "vocab_size-2-nopunct": 1759,
        "unique-2-nopunct": 997,
        "entropy-2-nopunct": 9.688074134543978,
        "cond_entropy-2-nopunct": 2.5516700112946067,
        "distinct-3-nopunct": 0.5192411924119241,
        "vocab_size-3-nopunct": 2874,
        "unique-3-nopunct": 2033,
        "entropy-3-nopunct": 10.855164634013958,
        "cond_entropy-3-nopunct": 1.2244139999900503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5725304064075942
        },
        "nist": 5.22832904936949,
        "rouge1": {
            "precision": 0.70593,
            "recall": 0.58031,
            "fmeasure": 0.62807
        },
        "rouge2": {
            "precision": 0.46589,
            "recall": 0.38306,
            "fmeasure": 0.41416
        },
        "rougeL": {
            "precision": 0.58909,
            "recall": 0.48357,
            "fmeasure": 0.52365
        },
        "rougeLsum": {
            "precision": 0.58909,
            "recall": 0.48357,
            "fmeasure": 0.52365
        },
        "bleu": 29.88531,
        "nubia": {
            "semantic_relation": 3.74494,
            "contradiction": 5.16322,
            "irrelevancy": 16.31008,
            "logical_agreement": 78.5267,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.35699,
            "nubia_score": 0.57544
        },
        "bleurt": -0.20052,
        "meteor": 0.3086809669693563,
        "bertscore": {
            "precision": 0.89573,
            "recall": 0.86965,
            "f1": 0.88217
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 46,
        "msttr-100": 0.57636,
        "msttr-100_nopunct": 0.573,
        "total_length": 1103,
        "mean_pred_length": 23.97826086956522,
        "std_pred_length": 3.485929047363331,
        "median_pred_length": 24.0,
        "min_pred_length": 15,
        "max_pred_length": 32,
        "distinct-1": 0.18766999093381687,
        "vocab_size-1": 207,
        "unique-1": 96,
        "entropy-1": 6.493286229765425,
        "distinct-2": 0.4749290444654683,
        "vocab_size-2": 502,
        "unique-2": 309,
        "entropy-2": 8.351395180266195,
        "cond_entropy-2": 1.879337073334142,
        "distinct-3": 0.685459940652819,
        "vocab_size-3": 693,
        "unique-3": 542,
        "entropy-3": 9.113074110257028,
        "cond_entropy-3": 0.7837216436951624,
        "total_length-nopunct": 1037,
        "mean_pred_length-nopunct": 22.543478260869566,
        "std_pred_length-nopunct": 3.3602958056845713,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.19575699132111862,
        "vocab_size-1-nopunct": 203,
        "unique-1-nopunct": 96,
        "entropy-1-nopunct": 6.450413882608518,
        "distinct-2-nopunct": 0.4783047426841574,
        "vocab_size-2-nopunct": 474,
        "unique-2-nopunct": 293,
        "entropy-2-nopunct": 8.259159110348893,
        "cond_entropy-2-nopunct": 1.8486188155799874,
        "distinct-3-nopunct": 0.6761904761904762,
        "vocab_size-3-nopunct": 639,
        "unique-3-nopunct": 493,
        "entropy-3-nopunct": 8.990111961356753,
        "cond_entropy-3-nopunct": 0.76772301490226,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5136251032204789
        },
        "nist": 3.7507777433586758,
        "rouge1": {
            "precision": 0.64613,
            "recall": 0.5284,
            "fmeasure": 0.56793
        },
        "rouge2": {
            "precision": 0.37842,
            "recall": 0.31625,
            "fmeasure": 0.33639
        },
        "rougeL": {
            "precision": 0.51459,
            "recall": 0.43107,
            "fmeasure": 0.45879
        },
        "rougeLsum": {
            "precision": 0.51459,
            "recall": 0.43107,
            "fmeasure": 0.45879
        },
        "bleu": 24.1543,
        "nubia": {
            "semantic_relation": 3.67377,
            "contradiction": 11.67467,
            "irrelevancy": 16.54326,
            "logical_agreement": 71.78207,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.83504,
            "nubia_score": 0.53489
        },
        "bleurt": -0.33901,
        "meteor": 0.26116265050424425,
        "bertscore": {
            "precision": 0.8731,
            "recall": 0.84822,
            "f1": 0.86003
        }
    },
    "xsum_challenge_test_nopunc_parent": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 500,
        "msttr-100": 0.72708,
        "msttr-100_nopunct": 0.73525,
        "total_length": 10653,
        "mean_pred_length": 21.306,
        "std_pred_length": 3.685154542213936,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.2653712569229325,
        "vocab_size-1": 2827,
        "unique-1": 1734,
        "entropy-1": 9.107244545289921,
        "distinct-2": 0.726484782822811,
        "vocab_size-2": 7376,
        "unique-2": 6346,
        "entropy-2": 12.355064540148343,
        "cond_entropy-2": 3.1694549999908688,
        "distinct-3": 0.9254117890811147,
        "vocab_size-3": 8933,
        "unique-3": 8499,
        "entropy-3": 13.044994727066966,
        "cond_entropy-3": 0.7106903282375454,
        "total_length-nopunct": 10141,
        "mean_pred_length-nopunct": 20.282,
        "std_pred_length-nopunct": 3.818177051945077,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.27778325608914306,
        "vocab_size-1-nopunct": 2817,
        "unique-1-nopunct": 1732,
        "entropy-1-nopunct": 9.197659164860353,
        "distinct-2-nopunct": 0.7319780105798154,
        "vocab_size-2-nopunct": 7057,
        "unique-2-nopunct": 6088,
        "entropy-2-nopunct": 12.300365803079726,
        "cond_entropy-2-nopunct": 3.217720386587602,
        "distinct-3-nopunct": 0.9288918061481238,
        "vocab_size-3-nopunct": 8491,
        "unique-3-nopunct": 8088,
        "entropy-3-nopunct": 12.980059168515396,
        "cond_entropy-3-nopunct": 0.7026547813552039,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3172961028525512
        },
        "nist": 3.1656751832858943,
        "rouge1": {
            "precision": 0.35331,
            "recall": 0.34178,
            "fmeasure": 0.3418
        },
        "rouge2": {
            "precision": 0.12712,
            "recall": 0.12247,
            "fmeasure": 0.12256
        },
        "rougeL": {
            "precision": 0.27423,
            "recall": 0.26655,
            "fmeasure": 0.26586
        },
        "rougeLsum": {
            "precision": 0.27423,
            "recall": 0.26655,
            "fmeasure": 0.26586
        },
        "bleu": 8.0888,
        "nubia": {
            "semantic_relation": 2.39745,
            "contradiction": 32.42255,
            "irrelevancy": 58.26305,
            "logical_agreement": 9.3144,
            "grammar_ref": 3.78318,
            "grammar_hyp": 4.35788,
            "nubia_score": 0.2755
        },
        "bleurt": -0.59737,
        "meteor": 0.14503011751325492,
        "bertscore": {
            "precision": 0.81339,
            "recall": 0.80472,
            "f1": 0.80877
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.76741,
        "msttr-100_nopunct": 0.83682,
        "total_length": 2701,
        "mean_pred_length": 12.621495327102803,
        "std_pred_length": 2.6087031919013146,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.3731951129211403,
        "vocab_size-1": 1008,
        "unique-1": 666,
        "entropy-1": 8.494466238086726,
        "distinct-2": 0.6919983916365099,
        "vocab_size-2": 1721,
        "unique-2": 1348,
        "entropy-2": 10.43775635073302,
        "cond_entropy-2": 2.1053718133077104,
        "distinct-3": 0.8526176858776947,
        "vocab_size-3": 1938,
        "unique-3": 1696,
        "entropy-3": 10.816561895138706,
        "cond_entropy-3": 0.442454613448837,
        "total_length-nopunct": 2283,
        "mean_pred_length-nopunct": 10.66822429906542,
        "std_pred_length-nopunct": 2.1129815994015555,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.4384581690757775,
        "vocab_size-1-nopunct": 1001,
        "unique-1-nopunct": 665,
        "entropy-1-nopunct": 8.969549985310229,
        "distinct-2-nopunct": 0.7472208796520058,
        "vocab_size-2-nopunct": 1546,
        "unique-2-nopunct": 1263,
        "entropy-2-nopunct": 10.358237956676076,
        "cond_entropy-2-nopunct": 1.546206791757275,
        "distinct-3-nopunct": 0.8727762803234501,
        "vocab_size-3-nopunct": 1619,
        "unique-3-nopunct": 1445,
        "entropy-3-nopunct": 10.57097194054131,
        "cond_entropy-3-nopunct": 0.2738334498146257,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.13160854893138357,
            "2": 0.3125,
            "3": 0.41904761904761906
        },
        "nist": 0.5488449655084678,
        "rouge1": {
            "precision": 0.25642,
            "recall": 0.18735,
            "fmeasure": 0.20635
        },
        "rouge2": {
            "precision": 0.10241,
            "recall": 0.06014,
            "fmeasure": 0.06983
        },
        "rougeL": {
            "precision": 0.24641,
            "recall": 0.17872,
            "fmeasure": 0.19714
        },
        "rougeLsum": {
            "precision": 0.24641,
            "recall": 0.17872,
            "fmeasure": 0.19714
        },
        "bleu": 14.64937,
        "nubia": {
            "semantic_relation": 3.35574,
            "contradiction": 22.89491,
            "irrelevancy": 22.2378,
            "logical_agreement": 54.86729,
            "grammar_ref": 2.5317,
            "grammar_hyp": 2.67335,
            "nubia_score": 0.62646
        },
        "bleurt": -0.03026,
        "meteor": 0.3215038083328951,
        "bertscore": {
            "precision": 0.94126,
            "recall": 0.88612,
            "f1": 0.91213
        }
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.77192,
        "msttr-100_nopunct": 0.83773,
        "total_length": 2664,
        "mean_pred_length": 12.448598130841122,
        "std_pred_length": 2.4389121401326097,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 20,
        "distinct-1": 0.39376876876876876,
        "vocab_size-1": 1049,
        "unique-1": 695,
        "entropy-1": 8.582671360252961,
        "distinct-2": 0.7285714285714285,
        "vocab_size-2": 1785,
        "unique-2": 1429,
        "entropy-2": 10.515504277162165,
        "cond_entropy-2": 2.0523457090947703,
        "distinct-3": 0.8792486583184258,
        "vocab_size-3": 1966,
        "unique-3": 1749,
        "entropy-3": 10.864514729757524,
        "cond_entropy-3": 0.40365638775194657,
        "total_length-nopunct": 2276,
        "mean_pred_length-nopunct": 10.63551401869159,
        "std_pred_length-nopunct": 2.075187294168467,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.45782073813708263,
        "vocab_size-1-nopunct": 1042,
        "unique-1-nopunct": 693,
        "entropy-1-nopunct": 9.046354012998748,
        "distinct-2-nopunct": 0.7793404461687682,
        "vocab_size-2-nopunct": 1607,
        "unique-2-nopunct": 1338,
        "entropy-2-nopunct": 10.443781031628108,
        "cond_entropy-2-nopunct": 1.51884512401895,
        "distinct-3-nopunct": 0.8939393939393939,
        "vocab_size-3-nopunct": 1652,
        "unique-3-nopunct": 1498,
        "entropy-3-nopunct": 10.619621307095766,
        "cond_entropy-3-nopunct": 0.23038266364107918,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.15847801994828223,
            "2": 0.38741470811220624,
            "3": 0.5512367491166078,
            "4": 0.36363636363636365
        },
        "nist": 2.87975590706315,
        "rouge1": {
            "precision": 0.27826,
            "recall": 0.22284,
            "fmeasure": 0.24011
        },
        "rouge2": {
            "precision": 0.10507,
            "recall": 0.07395,
            "fmeasure": 0.08232
        },
        "rougeL": {
            "precision": 0.27237,
            "recall": 0.21852,
            "fmeasure": 0.23516
        },
        "rougeLsum": {
            "precision": 0.27237,
            "recall": 0.21852,
            "fmeasure": 0.23516
        },
        "bleu": 25.69799,
        "nubia": {
            "semantic_relation": 3.45228,
            "contradiction": 21.63464,
            "irrelevancy": 23.73738,
            "logical_agreement": 54.62798,
            "grammar_ref": 2.61878,
            "grammar_hyp": 2.65065,
            "nubia_score": 0.67353
        },
        "bleurt": -0.01064,
        "meteor": 0.41474099155620886,
        "bertscore": {
            "precision": 0.94599,
            "recall": 0.90707,
            "f1": 0.92547
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp02": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp02",
        "N": 359,
        "msttr-100": 0.755,
        "msttr-100_nopunct": 0.78833,
        "total_length": 6046,
        "mean_pred_length": 16.841225626740947,
        "std_pred_length": 6.0046291011756825,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.4181276877274231,
        "vocab_size-1": 2528,
        "unique-1": 2004,
        "entropy-1": 9.276491433323084,
        "distinct-2": 0.8646034816247582,
        "vocab_size-2": 4917,
        "unique-2": 4636,
        "entropy-2": 12.004830795135868,
        "cond_entropy-2": 2.51492571764243,
        "distinct-3": 0.972972972972973,
        "vocab_size-3": 5184,
        "unique-3": 5119,
        "entropy-3": 12.285734484045424,
        "cond_entropy-3": 0.30211543546913183,
        "total_length-nopunct": 5455,
        "mean_pred_length-nopunct": 15.194986072423399,
        "std_pred_length-nopunct": 5.6317719310507846,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4612282309807516,
        "vocab_size-1-nopunct": 2516,
        "unique-1-nopunct": 2001,
        "entropy-1-nopunct": 9.557585797729487,
        "distinct-2-nopunct": 0.8855965463108321,
        "vocab_size-2-nopunct": 4513,
        "unique-2-nopunct": 4276,
        "entropy-2-nopunct": 11.939690253742295,
        "cond_entropy-2-nopunct": 2.531198430764028,
        "distinct-3-nopunct": 0.987333755541482,
        "vocab_size-3-nopunct": 4677,
        "unique-3-nopunct": 4627,
        "entropy-3-nopunct": 12.182521403908684,
        "cond_entropy-3-nopunct": 0.2653855941773774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp02.json",
        "local_recall": {
            "1": 0.03671477079796265,
            "2": 0.140485312899106,
            "3": 0.29321663019693656,
            "4": 0.393026941362916,
            "5": 0.4652128764278297,
            "6": 0.5960144927536232,
            "7": 0.7109583810614738
        },
        "nist": 7.610287820682057,
        "rouge1": {
            "precision": 0.75453,
            "recall": 0.64978,
            "fmeasure": 0.68411
        },
        "rouge2": {
            "precision": 0.56296,
            "recall": 0.47751,
            "fmeasure": 0.5049
        },
        "rougeL": {
            "precision": 0.726,
            "recall": 0.62409,
            "fmeasure": 0.65721
        },
        "rougeLsum": {
            "precision": 0.726,
            "recall": 0.62409,
            "fmeasure": 0.65721
        },
        "bleu": 47.55921,
        "sari": 43.27159,
        "nubia": {
            "semantic_relation": 3.81889,
            "contradiction": 8.29028,
            "irrelevancy": 17.11843,
            "logical_agreement": 74.59129,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.92362,
            "nubia_score": 0.4909
        },
        "bleurt": -0.44889,
        "meteor": 0.33794812535398266,
        "bertscore": {
            "precision": 0.89963,
            "recall": 0.89793,
            "f1": 0.89528
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_bfp05": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_test_turk_bfp05",
        "N": 359,
        "msttr-100": 0.76852,
        "msttr-100_nopunct": 0.80527,
        "total_length": 6136,
        "mean_pred_length": 17.091922005571032,
        "std_pred_length": 5.914894700182847,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.46104954367666234,
        "vocab_size-1": 2829,
        "unique-1": 2354,
        "entropy-1": 9.515879702630063,
        "distinct-2": 0.8871386532802492,
        "vocab_size-2": 5125,
        "unique-2": 4885,
        "entropy-2": 12.113920294495664,
        "cond_entropy-2": 2.389328264586537,
        "distinct-3": 0.9815430047988187,
        "vocab_size-3": 5318,
        "unique-3": 5271,
        "entropy-3": 12.344656170769596,
        "cond_entropy-3": 0.24955416521114446,
        "total_length-nopunct": 5565,
        "mean_pred_length-nopunct": 15.501392757660167,
        "std_pred_length-nopunct": 5.65137331489866,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5061994609164421,
        "vocab_size-1-nopunct": 2817,
        "unique-1-nopunct": 2352,
        "entropy-1-nopunct": 9.798374522303233,
        "distinct-2-nopunct": 0.9024202842873608,
        "vocab_size-2-nopunct": 4698,
        "unique-2-nopunct": 4497,
        "entropy-2-nopunct": 12.021093446044317,
        "cond_entropy-2-nopunct": 2.360441363647189,
        "distinct-3-nopunct": 0.9915411594800908,
        "vocab_size-3-nopunct": 4806,
        "unique-3-nopunct": 4771,
        "entropy-3-nopunct": 12.224510460417438,
        "cond_entropy-3-nopunct": 0.22455524894607326,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_bfp05.json",
        "local_recall": {
            "1": 0.0350169779286927,
            "2": 0.12005108556832694,
            "3": 0.2735229759299781,
            "4": 0.3676703645007924,
            "5": 0.4195223260643821,
            "6": 0.5332125603864735,
            "7": 0.6533027873234059
        },
        "nist": 6.835523072699757,
        "rouge1": {
            "precision": 0.68344,
            "recall": 0.59533,
            "fmeasure": 0.62427
        },
        "rouge2": {
            "precision": 0.46298,
            "recall": 0.40234,
            "fmeasure": 0.42041
        },
        "rougeL": {
            "precision": 0.65908,
            "recall": 0.57499,
            "fmeasure": 0.60157
        },
        "rougeLsum": {
            "precision": 0.65908,
            "recall": 0.57499,
            "fmeasure": 0.60157
        },
        "bleu": 37.44153,
        "sari": 43.1557,
        "nubia": {
            "semantic_relation": 3.6855,
            "contradiction": 9.19856,
            "irrelevancy": 18.67149,
            "logical_agreement": 72.12995,
            "grammar_ref": 4.55265,
            "grammar_hyp": 6.5326,
            "nubia_score": 0.41914
        },
        "bleurt": -0.7929,
        "meteor": 0.29551351745391746,
        "bertscore": {
            "precision": 0.86238,
            "recall": 0.87906,
            "f1": 0.86741
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 1187,
        "msttr-100": 0.28664,
        "msttr-100_nopunct": 0.28086,
        "total_length": 26201,
        "mean_pred_length": 22.07329401853412,
        "std_pred_length": 3.267957764896713,
        "median_pred_length": 23.0,
        "min_pred_length": 13,
        "max_pred_length": 29,
        "distinct-1": 0.010877447425670777,
        "vocab_size-1": 285,
        "unique-1": 56,
        "entropy-1": 6.0137893829381595,
        "distinct-2": 0.04377548572799232,
        "vocab_size-2": 1095,
        "unique-2": 310,
        "entropy-2": 8.01338484232387,
        "cond_entropy-2": 2.0215253091541805,
        "distinct-3": 0.08863893901876023,
        "vocab_size-3": 2112,
        "unique-3": 712,
        "entropy-3": 9.19558482355668,
        "cond_entropy-3": 1.2405465813471375,
        "total_length-nopunct": 24538,
        "mean_pred_length-nopunct": 20.67228306655434,
        "std_pred_length-nopunct": 3.165408831255252,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.011492379167006276,
        "vocab_size-1-nopunct": 282,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 6.010585312092457,
        "distinct-2-nopunct": 0.04547985096997987,
        "vocab_size-2-nopunct": 1062,
        "unique-2-nopunct": 303,
        "entropy-2-nopunct": 7.956943798729231,
        "cond_entropy-2-nopunct": 2.028301722270122,
        "distinct-3-nopunct": 0.09113878361306624,
        "vocab_size-3-nopunct": 2020,
        "unique-3-nopunct": 681,
        "entropy-3-nopunct": 9.156093821416938,
        "cond_entropy-3-nopunct": 1.2443812039772078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.680886006653472
        },
        "nist": 4.870457533195306,
        "rouge1": {
            "precision": 0.73131,
            "recall": 0.69348,
            "fmeasure": 0.70247
        },
        "rouge2": {
            "precision": 0.41787,
            "recall": 0.3968,
            "fmeasure": 0.40149
        },
        "rougeL": {
            "precision": 0.50878,
            "recall": 0.48264,
            "fmeasure": 0.48877
        },
        "rougeLsum": {
            "precision": 0.50878,
            "recall": 0.48264,
            "fmeasure": 0.48877
        },
        "bleu": 28.08952,
        "nubia": {
            "semantic_relation": 4.15485,
            "contradiction": 2.13586,
            "irrelevancy": 31.81888,
            "logical_agreement": 66.04527,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.89062,
            "nubia_score": 0.70571
        },
        "bleurt": 0.0207,
        "meteor": 0.34641704078203805,
        "bertscore": {
            "precision": 0.90701,
            "recall": 0.89959,
            "f1": 0.90294
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 1397,
        "msttr-100": 0.63989,
        "msttr-100_nopunct": 0.64238,
        "total_length": 26989,
        "mean_pred_length": 19.319255547602005,
        "std_pred_length": 5.580388762827139,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.06691615102449146,
        "vocab_size-1": 1806,
        "unique-1": 861,
        "entropy-1": 7.584849756597219,
        "distinct-2": 0.2283526101906846,
        "vocab_size-2": 5844,
        "unique-2": 3551,
        "entropy-2": 10.49152883381142,
        "cond_entropy-2": 2.8306639559811875,
        "distinct-3": 0.4223599917338293,
        "vocab_size-3": 10219,
        "unique-3": 7464,
        "entropy-3": 12.016834429504376,
        "cond_entropy-3": 1.547133548133646,
        "total_length-nopunct": 24486,
        "mean_pred_length-nopunct": 17.52755905511811,
        "std_pred_length-nopunct": 5.396397760327913,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.07322551662174304,
        "vocab_size-1-nopunct": 1793,
        "unique-1-nopunct": 859,
        "entropy-1-nopunct": 7.643613978127817,
        "distinct-2-nopunct": 0.24409892156438132,
        "vocab_size-2-nopunct": 5636,
        "unique-2-nopunct": 3511,
        "entropy-2-nopunct": 10.453873311484264,
        "cond_entropy-2-nopunct": 2.8858581790281264,
        "distinct-3-nopunct": 0.4417757698690762,
        "vocab_size-3-nopunct": 9583,
        "unique-3-nopunct": 7065,
        "entropy-3-nopunct": 11.968950541471767,
        "cond_entropy-3-nopunct": 1.5509990585115006,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6263521756811712
        },
        "nist": 6.759496385697498,
        "rouge1": {
            "precision": 0.67259,
            "recall": 0.64178,
            "fmeasure": 0.64502
        },
        "rouge2": {
            "precision": 0.45166,
            "recall": 0.43215,
            "fmeasure": 0.4335
        },
        "rougeL": {
            "precision": 0.58095,
            "recall": 0.55567,
            "fmeasure": 0.55797
        },
        "rougeLsum": {
            "precision": 0.58095,
            "recall": 0.55567,
            "fmeasure": 0.55797
        },
        "bleu": 35.14396,
        "nubia": {
            "semantic_relation": 4.09992,
            "contradiction": 3.51828,
            "irrelevancy": 19.4891,
            "logical_agreement": 76.99262,
            "grammar_ref": 4.97201,
            "grammar_hyp": 5.00832,
            "nubia_score": 0.68291
        },
        "bleurt": -0.10051,
        "meteor": 0.33772855594018725,
        "bertscore": {
            "precision": 0.88419,
            "recall": 0.87835,
            "f1": 0.88082
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 983,
        "msttr-100": 0.26073,
        "msttr-100_nopunct": 0.2625,
        "total_length": 5565,
        "mean_pred_length": 5.661241098677518,
        "std_pred_length": 1.7394335222979953,
        "median_pred_length": 5.0,
        "min_pred_length": 2,
        "max_pred_length": 14,
        "distinct-1": 0.02336028751123091,
        "vocab_size-1": 130,
        "unique-1": 36,
        "entropy-1": 4.321673652864537,
        "distinct-2": 0.06460061108686163,
        "vocab_size-2": 296,
        "unique-2": 120,
        "entropy-2": 5.369539222018763,
        "cond_entropy-2": 0.8738296102610984,
        "distinct-3": 0.11003056404556821,
        "vocab_size-3": 396,
        "unique-3": 182,
        "entropy-3": 6.243203169159844,
        "cond_entropy-3": 0.7189403615645548,
        "total_length-nopunct": 4462,
        "mean_pred_length-nopunct": 4.539165818921668,
        "std_pred_length-nopunct": 1.4314595401292256,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.028014343343792023,
        "vocab_size-1-nopunct": 125,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 4.172295532226908,
        "distinct-2-nopunct": 0.0672607070997413,
        "vocab_size-2-nopunct": 234,
        "unique-2-nopunct": 95,
        "entropy-2-nopunct": 5.0507687233994565,
        "cond_entropy-2-nopunct": 0.728817729763534,
        "distinct-3-nopunct": 0.10893071686023229,
        "vocab_size-3-nopunct": 272,
        "unique-3-nopunct": 128,
        "entropy-3-nopunct": 5.5467022823019665,
        "cond_entropy-3-nopunct": 0.6334854709712573,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.48319417683579535
        },
        "nist": 2.7628941845844146,
        "rouge1": {
            "precision": 0.51723,
            "recall": 0.49978,
            "fmeasure": 0.49988
        },
        "rouge2": {
            "precision": 0.34674,
            "recall": 0.33244,
            "fmeasure": 0.33313
        },
        "rougeL": {
            "precision": 0.51589,
            "recall": 0.49828,
            "fmeasure": 0.49852
        },
        "rougeLsum": {
            "precision": 0.51589,
            "recall": 0.49828,
            "fmeasure": 0.49852
        },
        "bleu": 29.14187,
        "nubia": {
            "semantic_relation": 3.03781,
            "contradiction": 3.82246,
            "irrelevancy": 25.10799,
            "logical_agreement": 71.06955,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.62324,
            "nubia_score": 0.57282
        },
        "bleurt": 0.10536,
        "meteor": 0.2676852834980751,
        "bertscore": {
            "precision": 0.85449,
            "recall": 0.85112,
            "f1": 0.85234
        }
    },
    "wiki_auto_asset_turk_challenge_test_turk_nopunc": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_challenge_test_turk_nopunc",
        "N": 359,
        "msttr-100": 0.74328,
        "msttr-100_nopunct": 0.77226,
        "total_length": 5882,
        "mean_pred_length": 16.384401114206128,
        "std_pred_length": 6.080003446670963,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3830329819789187,
        "vocab_size-1": 2253,
        "unique-1": 1694,
        "entropy-1": 9.082660382811703,
        "distinct-2": 0.8460981350715191,
        "vocab_size-2": 4673,
        "unique-2": 4353,
        "entropy-2": 11.904476861760767,
        "cond_entropy-2": 2.6255205482158748,
        "distinct-3": 0.9686289697908598,
        "vocab_size-3": 5002,
        "unique-3": 4925,
        "entropy-3": 12.231504917621853,
        "cond_entropy-3": 0.3519432586054663,
        "total_length-nopunct": 5313,
        "mean_pred_length-nopunct": 14.799442896935933,
        "std_pred_length-nopunct": 5.67837119349243,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.42179559570863917,
        "vocab_size-1-nopunct": 2241,
        "unique-1-nopunct": 1691,
        "entropy-1-nopunct": 9.336232144880858,
        "distinct-2-nopunct": 0.863948324586193,
        "vocab_size-2-nopunct": 4280,
        "unique-2-nopunct": 4002,
        "entropy-2-nopunct": 11.827817976702498,
        "cond_entropy-2-nopunct": 2.6497259187196343,
        "distinct-3-nopunct": 0.9817192600652883,
        "vocab_size-3-nopunct": 4511,
        "unique-3-nopunct": 4445,
        "entropy-3-nopunct": 12.125175837582402,
        "cond_entropy-3-nopunct": 0.3237867619465287,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_challenge_test_turk_nopunc.json",
        "local_recall": {
            "1": 0.03968590831918506,
            "2": 0.14559386973180077,
            "3": 0.29978118161925604,
            "4": 0.4215530903328051,
            "5": 0.49428868120456904,
            "6": 0.626207729468599,
            "7": 0.764413898434517
        },
        "nist": 8.137746964441757,
        "rouge1": {
            "precision": 0.82336,
            "recall": 0.69691,
            "fmeasure": 0.73748
        },
        "rouge2": {
            "precision": 0.66625,
            "recall": 0.55842,
            "fmeasure": 0.59155
        },
        "rougeL": {
            "precision": 0.79059,
            "recall": 0.66963,
            "fmeasure": 0.70753
        },
        "rougeLsum": {
            "precision": 0.79059,
            "recall": 0.66963,
            "fmeasure": 0.70753
        },
        "bleu": 58.39456,
        "sari": 42.83291,
        "nubia": {
            "semantic_relation": 3.98812,
            "contradiction": 5.4017,
            "irrelevancy": 17.93045,
            "logical_agreement": 76.66785,
            "grammar_ref": 4.55265,
            "grammar_hyp": 5.09067,
            "nubia_score": 0.60899
        },
        "bleurt": 0.03824,
        "meteor": 0.3862352548181347,
        "bertscore": {
            "precision": 0.94289,
            "recall": 0.91502,
            "f1": 0.92529
        }
    },
    "cs_restaurants_validation": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_validation",
        "N": 781,
        "msttr-100": 0.615,
        "msttr-100_nopunct": 0.6471,
        "total_length": 8056,
        "mean_pred_length": 10.314980793854033,
        "std_pred_length": 3.8982767663918385,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 22,
        "distinct-1": 0.057224428997020856,
        "vocab_size-1": 461,
        "unique-1": 139,
        "entropy-1": 6.979375768533514,
        "distinct-2": 0.1997250859106529,
        "vocab_size-2": 1453,
        "unique-2": 634,
        "entropy-2": 9.329424836365432,
        "cond_entropy-2": 2.054305577070688,
        "distinct-3": 0.34755158607945796,
        "vocab_size-3": 2257,
        "unique-3": 1271,
        "entropy-3": 10.239102243743705,
        "cond_entropy-3": 0.829416084717051,
        "total_length-nopunct": 6974,
        "mean_pred_length-nopunct": 8.929577464788732,
        "std_pred_length-nopunct": 3.5741866477259996,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.06552910811585891,
        "vocab_size-1-nopunct": 457,
        "unique-1-nopunct": 139,
        "entropy-1-nopunct": 7.1809731021071235,
        "distinct-2-nopunct": 0.21362829000484418,
        "vocab_size-2-nopunct": 1323,
        "unique-2-nopunct": 597,
        "entropy-2-nopunct": 9.24515866020675,
        "cond_entropy-2-nopunct": 2.072913735383534,
        "distinct-3-nopunct": 0.37028824833702884,
        "vocab_size-3-nopunct": 2004,
        "unique-3-nopunct": 1159,
        "entropy-3-nopunct": 10.144335906934137,
        "cond_entropy-3-nopunct": 0.8375069557369575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_validation.json",
        "local_recall": {
            "1": 0.40458579881656803
        },
        "nist": 3.478444806415684,
        "rouge1": {
            "precision": 0.43815,
            "recall": 0.4518,
            "fmeasure": 0.42942
        },
        "rouge2": {
            "precision": 0.25005,
            "recall": 0.26346,
            "fmeasure": 0.24584
        },
        "rougeL": {
            "precision": 0.3959,
            "recall": 0.41004,
            "fmeasure": 0.38862
        },
        "rougeLsum": {
            "precision": 0.3959,
            "recall": 0.41004,
            "fmeasure": 0.38862
        },
        "bleu": 14.70281,
        "nubia": {
            "semantic_relation": 3.04013,
            "contradiction": 21.96781,
            "irrelevancy": 31.73356,
            "logical_agreement": 46.29863,
            "grammar_ref": 6.54085,
            "grammar_hyp": 6.46707,
            "nubia_score": 0.41115
        },
        "bleurt": -0.24193,
        "meteor": 0.20860591336905024,
        "bertscore": {
            "precision": 0.88927,
            "recall": 0.88611,
            "f1": 0.88743
        }
    },
    "cs_restaurants_test": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_test",
        "N": 842,
        "msttr-100": 0.60277,
        "msttr-100_nopunct": 0.64474,
        "total_length": 9452,
        "mean_pred_length": 11.225653206650831,
        "std_pred_length": 3.5925374439120525,
        "median_pred_length": 12.0,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.07247143461701228,
        "vocab_size-1": 685,
        "unique-1": 241,
        "entropy-1": 7.005780658267288,
        "distinct-2": 0.22566782810685249,
        "vocab_size-2": 1943,
        "unique-2": 1000,
        "entropy-2": 9.130897125643294,
        "cond_entropy-2": 1.9256250704393336,
        "distinct-3": 0.368048403707518,
        "vocab_size-3": 2859,
        "unique-3": 1932,
        "entropy-3": 9.82653011779877,
        "cond_entropy-3": 0.7733206927222411,
        "total_length-nopunct": 7898,
        "mean_pred_length-nopunct": 9.380047505938242,
        "std_pred_length-nopunct": 3.307729520693345,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.08622436059761965,
        "vocab_size-1-nopunct": 681,
        "unique-1-nopunct": 241,
        "entropy-1-nopunct": 7.309915650466452,
        "distinct-2-nopunct": 0.24036281179138322,
        "vocab_size-2-nopunct": 1696,
        "unique-2-nopunct": 906,
        "entropy-2-nopunct": 9.030547102282556,
        "cond_entropy-2-nopunct": 1.9171278203542854,
        "distinct-3-nopunct": 0.39909880914065016,
        "vocab_size-3-nopunct": 2480,
        "unique-3-nopunct": 1722,
        "entropy-3-nopunct": 9.782893313526294,
        "cond_entropy-3-nopunct": 0.8757657501259197,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "local_recall": {
            "1": 0.4495705181490718
        },
        "nist": 3.7450819894739893,
        "rouge1": {
            "precision": 0.48407,
            "recall": 0.51615,
            "fmeasure": 0.48257
        },
        "rouge2": {
            "precision": 0.26499,
            "recall": 0.27703,
            "fmeasure": 0.26178
        },
        "rougeL": {
            "precision": 0.43505,
            "recall": 0.46618,
            "fmeasure": 0.43488
        },
        "rougeLsum": {
            "precision": 0.43505,
            "recall": 0.46618,
            "fmeasure": 0.43488
        },
        "bleu": 15.88537,
        "nubia": {
            "semantic_relation": 3.28103,
            "contradiction": 23.20643,
            "irrelevancy": 34.84354,
            "logical_agreement": 41.95003,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.72449,
            "nubia_score": 0.47486
        },
        "bleurt": -0.27447,
        "meteor": 0.22550969788131578,
        "bertscore": {
            "precision": 0.88457,
            "recall": 0.89483,
            "f1": 0.88925
        }
    },
    "cs_restaurants_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_challenge_train_sample",
        "N": 500
    },
    "cs_restaurants_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 1027,
        "msttr-100": 0.62819,
        "msttr-100_nopunct": 0.66593,
        "total_length": 10575,
        "mean_pred_length": 10.296981499513144,
        "std_pred_length": 4.395760177613535,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 26,
        "distinct-1": 0.11309692671394798,
        "vocab_size-1": 1196,
        "unique-1": 633,
        "entropy-1": 7.43718211802644,
        "distinct-2": 0.33294930875576034,
        "vocab_size-2": 3179,
        "unique-2": 2012,
        "entropy-2": 10.401637100283319,
        "cond_entropy-2": 2.60741308915394,
        "distinct-3": 0.5430113836404178,
        "vocab_size-3": 4627,
        "unique-3": 3397,
        "entropy-3": 11.510924085508847,
        "cond_entropy-3": 1.1551306377473771,
        "total_length-nopunct": 9137,
        "mean_pred_length-nopunct": 8.896786757546252,
        "std_pred_length-nopunct": 4.122167895183988,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.1299113494582467,
        "vocab_size-1-nopunct": 1187,
        "unique-1-nopunct": 633,
        "entropy-1-nopunct": 7.7208705399413615,
        "distinct-2-nopunct": 0.34648581997533906,
        "vocab_size-2-nopunct": 2810,
        "unique-2-nopunct": 1795,
        "entropy-2-nopunct": 10.246911346179356,
        "cond_entropy-2-nopunct": 2.773350475051137,
        "distinct-3-nopunct": 0.5622178329571106,
        "vocab_size-3-nopunct": 3985,
        "unique-3-nopunct": 2999,
        "entropy-3-nopunct": 11.301474087251203,
        "cond_entropy-3-nopunct": 1.1834334281101748,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6329728536746855
        },
        "nist": 7.400970202348356,
        "rouge1": {
            "precision": 0.6821,
            "recall": 0.65654,
            "fmeasure": 0.65698
        },
        "rouge2": {
            "precision": 0.47602,
            "recall": 0.45869,
            "fmeasure": 0.45646
        },
        "rougeL": {
            "precision": 0.6239,
            "recall": 0.60039,
            "fmeasure": 0.60056
        },
        "rougeLsum": {
            "precision": 0.6239,
            "recall": 0.60039,
            "fmeasure": 0.60056
        },
        "bleu": 45.0292,
        "nubia": {
            "semantic_relation": 4.15103,
            "contradiction": 3.49466,
            "irrelevancy": 14.96717,
            "logical_agreement": 81.53816,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.87953,
            "nubia_score": 0.75985
        },
        "bleurt": 0.19948,
        "meteor": 0.37752970116516715,
        "bertscore": {
            "precision": 0.90477,
            "recall": 0.89944,
            "f1": 0.90168
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 1406,
        "msttr-100": 0.3097,
        "msttr-100_nopunct": 0.29975,
        "total_length": 33723,
        "mean_pred_length": 23.9850640113798,
        "std_pred_length": 2.464064104103536,
        "median_pred_length": 24.0,
        "min_pred_length": 17,
        "max_pred_length": 31,
        "distinct-1": 0.009696646205853572,
        "vocab_size-1": 327,
        "unique-1": 61,
        "entropy-1": 5.946416986065128,
        "distinct-2": 0.038122350465699166,
        "vocab_size-2": 1232,
        "unique-2": 275,
        "entropy-2": 8.008103212284654,
        "cond_entropy-2": 2.142236155243319,
        "distinct-3": 0.07987447834104364,
        "vocab_size-3": 2469,
        "unique-3": 622,
        "entropy-3": 9.366091253603082,
        "cond_entropy-3": 1.4563560433580356,
        "total_length-nopunct": 31755,
        "mean_pred_length-nopunct": 22.58534850640114,
        "std_pred_length-nopunct": 2.5067842768273816,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.010234608723035742,
        "vocab_size-1-nopunct": 325,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.93141994281181,
        "distinct-2-nopunct": 0.04026491811921316,
        "vocab_size-2-nopunct": 1222,
        "unique-2-nopunct": 286,
        "entropy-2-nopunct": 7.981796333539151,
        "cond_entropy-2-nopunct": 2.1677307158617025,
        "distinct-3-nopunct": 0.0833707632242684,
        "vocab_size-3-nopunct": 2413,
        "unique-3-nopunct": 624,
        "entropy-3-nopunct": 9.36599584876969,
        "cond_entropy-3-nopunct": 1.4764799952246888,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6417874176007776
        },
        "nist": 4.592711961998347,
        "rouge1": {
            "precision": 0.76801,
            "recall": 0.66003,
            "fmeasure": 0.70306
        },
        "rouge2": {
            "precision": 0.45954,
            "recall": 0.39446,
            "fmeasure": 0.42036
        },
        "rougeL": {
            "precision": 0.53457,
            "recall": 0.46105,
            "fmeasure": 0.49036
        },
        "rougeLsum": {
            "precision": 0.53457,
            "recall": 0.46105,
            "fmeasure": 0.49036
        },
        "bleu": 27.07281,
        "nubia": {
            "semantic_relation": 4.16315,
            "contradiction": 3.13962,
            "irrelevancy": 12.20459,
            "logical_agreement": 84.65578,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.72227,
            "nubia_score": 0.69931
        },
        "bleurt": 0.01941,
        "meteor": 0.3307147739131949,
        "bertscore": {
            "precision": 0.91436,
            "recall": 0.89108,
            "f1": 0.90236
        }
    },
    "cs_restaurants_challenge_test_scramble": {
        "predictions_file": "ByT5-small (Baseline)/cs_restaurants_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.60643,
        "msttr-100_nopunct": 0.64383,
        "total_length": 5670,
        "mean_pred_length": 11.34,
        "std_pred_length": 3.7762944800425715,
        "median_pred_length": 12.0,
        "min_pred_length": 4,
        "max_pred_length": 24,
        "distinct-1": 0.0962962962962963,
        "vocab_size-1": 546,
        "unique-1": 227,
        "entropy-1": 6.944241866983336,
        "distinct-2": 0.2831721470019342,
        "vocab_size-2": 1464,
        "unique-2": 876,
        "entropy-2": 8.95634981345118,
        "cond_entropy-2": 1.8094711379878996,
        "distinct-3": 0.43383297644539615,
        "vocab_size-3": 2026,
        "unique-3": 1504,
        "entropy-3": 9.55987492369149,
        "cond_entropy-3": 0.6620970493677005,
        "total_length-nopunct": 4722,
        "mean_pred_length-nopunct": 9.444,
        "std_pred_length-nopunct": 3.439020790864748,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.11478187208809826,
        "vocab_size-1-nopunct": 542,
        "unique-1-nopunct": 227,
        "entropy-1-nopunct": 7.249526413418352,
        "distinct-2-nopunct": 0.30175272382756985,
        "vocab_size-2-nopunct": 1274,
        "unique-2-nopunct": 777,
        "entropy-2-nopunct": 8.846851141526926,
        "cond_entropy-2-nopunct": 1.754115738607831,
        "distinct-3-nopunct": 0.46856528747984955,
        "vocab_size-3-nopunct": 1744,
        "unique-3-nopunct": 1327,
        "entropy-3-nopunct": 9.487495754456917,
        "cond_entropy-3-nopunct": 0.7414573319577804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.44980200326112274
        },
        "nist": 3.6002724880543506,
        "rouge1": {
            "precision": 0.47466,
            "recall": 0.50847,
            "fmeasure": 0.47312
        },
        "rouge2": {
            "precision": 0.25628,
            "recall": 0.27107,
            "fmeasure": 0.25391
        },
        "rougeL": {
            "precision": 0.42187,
            "recall": 0.45454,
            "fmeasure": 0.42198
        },
        "rougeLsum": {
            "precision": 0.42187,
            "recall": 0.45454,
            "fmeasure": 0.42198
        },
        "bleu": 15.15607,
        "nubia": {
            "semantic_relation": 3.24915,
            "contradiction": 24.59489,
            "irrelevancy": 33.47117,
            "logical_agreement": 41.93394,
            "grammar_ref": 6.87434,
            "grammar_hyp": 6.70741,
            "nubia_score": 0.47018
        },
        "bleurt": -0.3025,
        "meteor": 0.22577665254077947,
        "bertscore": {
            "precision": 0.882,
            "recall": 0.89184,
            "f1": 0.88644
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 5049,
        "msttr-100": 0.58457,
        "msttr-100_nopunct": 0.61113,
        "total_length": 38528,
        "mean_pred_length": 7.63081798375916,
        "std_pred_length": 2.7631765285575396,
        "median_pred_length": 7.0,
        "min_pred_length": 2,
        "max_pred_length": 27,
        "distinct-1": 0.033170681063122924,
        "vocab_size-1": 1278,
        "unique-1": 530,
        "entropy-1": 6.993568989156209,
        "distinct-2": 0.1455240598584187,
        "vocab_size-2": 4872,
        "unique-2": 2526,
        "entropy-2": 9.923423733750674,
        "cond_entropy-2": 2.5400087523773625,
        "distinct-3": 0.2774533943017939,
        "vocab_size-3": 7888,
        "unique-3": 4934,
        "entropy-3": 11.08045396083941,
        "cond_entropy-3": 1.1678270081696256,
        "total_length-nopunct": 32829,
        "mean_pred_length-nopunct": 6.502079619726678,
        "std_pred_length-nopunct": 2.580156007602566,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.03856346522891346,
        "vocab_size-1-nopunct": 1266,
        "unique-1-nopunct": 529,
        "entropy-1-nopunct": 7.191385384515745,
        "distinct-2-nopunct": 0.15269978401727863,
        "vocab_size-2-nopunct": 4242,
        "unique-2-nopunct": 2283,
        "entropy-2-nopunct": 9.648068846395272,
        "cond_entropy-2-nopunct": 2.665686754652604,
        "distinct-3-nopunct": 0.28390501319261213,
        "vocab_size-3-nopunct": 6456,
        "unique-3-nopunct": 4158,
        "entropy-3-nopunct": 10.707901167616793,
        "cond_entropy-3-nopunct": 1.1905572174411265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.45619839550272295
        },
        "nist": 4.646109586292269,
        "rouge1": {
            "precision": 0.49292,
            "recall": 0.47524,
            "fmeasure": 0.47106
        },
        "rouge2": {
            "precision": 0.2886,
            "recall": 0.27844,
            "fmeasure": 0.27467
        },
        "rougeL": {
            "precision": 0.46955,
            "recall": 0.45192,
            "fmeasure": 0.4485
        },
        "rougeLsum": {
            "precision": 0.46955,
            "recall": 0.45192,
            "fmeasure": 0.4485
        },
        "bleu": 25.63295,
        "nubia": {
            "semantic_relation": 3.07609,
            "contradiction": 8.23597,
            "irrelevancy": 28.19775,
            "logical_agreement": 63.56628,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.66892,
            "nubia_score": 0.54947
        },
        "bleurt": -0.15516,
        "meteor": 0.2579400288411185,
        "bertscore": {
            "precision": 0.85203,
            "recall": 0.8477,
            "f1": 0.84924
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 774,
        "msttr-100": 0.31762,
        "msttr-100_nopunct": 0.30912,
        "total_length": 19347,
        "mean_pred_length": 24.996124031007753,
        "std_pred_length": 1.69624466359559,
        "median_pred_length": 25.0,
        "min_pred_length": 21,
        "max_pred_length": 29,
        "distinct-1": 0.012870212436036595,
        "vocab_size-1": 249,
        "unique-1": 28,
        "entropy-1": 6.05891227642059,
        "distinct-2": 0.04974963656921338,
        "vocab_size-2": 924,
        "unique-2": 159,
        "entropy-2": 8.052001551035154,
        "cond_entropy-2": 2.1089577664405783,
        "distinct-3": 0.098263947412776,
        "vocab_size-3": 1749,
        "unique-3": 352,
        "entropy-3": 9.30288526072659,
        "cond_entropy-3": 1.3564725707534693,
        "total_length-nopunct": 18279,
        "mean_pred_length-nopunct": 23.61627906976744,
        "std_pred_length-nopunct": 1.581153082217812,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.013403359045899666,
        "vocab_size-1-nopunct": 245,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 6.03616498272488,
        "distinct-2-nopunct": 0.05215652670665524,
        "vocab_size-2-nopunct": 913,
        "unique-2-nopunct": 162,
        "entropy-2-nopunct": 8.052126718763017,
        "cond_entropy-2-nopunct": 2.1387102231304036,
        "distinct-3-nopunct": 0.10190664036817883,
        "vocab_size-3-nopunct": 1705,
        "unique-3-nopunct": 352,
        "entropy-3-nopunct": 9.317673122358293,
        "cond_entropy-3-nopunct": 1.3733660954514197,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.5809306441846384
        },
        "nist": 3.604434677783105,
        "rouge1": {
            "precision": 0.78729,
            "recall": 0.59049,
            "fmeasure": 0.67101
        },
        "rouge2": {
            "precision": 0.46158,
            "recall": 0.34371,
            "fmeasure": 0.39171
        },
        "rougeL": {
            "precision": 0.54304,
            "recall": 0.40877,
            "fmeasure": 0.4638
        },
        "rougeLsum": {
            "precision": 0.54304,
            "recall": 0.40877,
            "fmeasure": 0.4638
        },
        "bleu": 23.29098,
        "nubia": {
            "semantic_relation": 3.71053,
            "contradiction": 4.08652,
            "irrelevancy": 10.34255,
            "logical_agreement": 85.57092,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.723,
            "nubia_score": 0.55608
        },
        "bleurt": -0.12012,
        "meteor": 0.2980779416134345,
        "bertscore": {
            "precision": 0.91329,
            "recall": 0.87138,
            "f1": 0.89168
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 73,
        "msttr-100": 0.42389,
        "msttr-100_nopunct": 0.42588,
        "total_length": 1817,
        "mean_pred_length": 24.89041095890411,
        "std_pred_length": 2.290909036752534,
        "median_pred_length": 25.0,
        "min_pred_length": 20,
        "max_pred_length": 30,
        "distinct-1": 0.089157952669235,
        "vocab_size-1": 162,
        "unique-1": 54,
        "entropy-1": 6.0430430196261415,
        "distinct-2": 0.25344036697247707,
        "vocab_size-2": 442,
        "unique-2": 192,
        "entropy-2": 7.8746978971956025,
        "cond_entropy-2": 1.9206861992687376,
        "distinct-3": 0.4248952722920407,
        "vocab_size-3": 710,
        "unique-3": 380,
        "entropy-3": 8.872485934091161,
        "cond_entropy-3": 1.0690993160688316,
        "total_length-nopunct": 1723,
        "mean_pred_length-nopunct": 23.602739726027398,
        "std_pred_length-nopunct": 1.9982165063451112,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.09286128845037725,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 6.0114815918003375,
        "distinct-2-nopunct": 0.2587878787878788,
        "vocab_size-2-nopunct": 427,
        "unique-2-nopunct": 186,
        "entropy-2-nopunct": 7.832687271609453,
        "cond_entropy-2-nopunct": 1.918212121451977,
        "distinct-3-nopunct": 0.43056436271401394,
        "vocab_size-3-nopunct": 679,
        "unique-3-nopunct": 360,
        "entropy-3-nopunct": 8.832863006944077,
        "cond_entropy-3-nopunct": 1.07741080459471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6229674796747967
        },
        "nist": 4.2216064355733405,
        "rouge1": {
            "precision": 0.80117,
            "recall": 0.62383,
            "fmeasure": 0.69828
        },
        "rouge2": {
            "precision": 0.54432,
            "recall": 0.42085,
            "fmeasure": 0.47225
        },
        "rougeL": {
            "precision": 0.59768,
            "recall": 0.46455,
            "fmeasure": 0.52034
        },
        "rougeLsum": {
            "precision": 0.59768,
            "recall": 0.46455,
            "fmeasure": 0.52034
        },
        "bleu": 31.4766,
        "nubia": {
            "semantic_relation": 3.71879,
            "contradiction": 5.22485,
            "irrelevancy": 13.88972,
            "logical_agreement": 80.88542,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.83565,
            "nubia_score": 0.56477
        },
        "bleurt": -0.17333,
        "meteor": 0.3223549228447746,
        "bertscore": {
            "precision": 0.9176,
            "recall": 0.88084,
            "f1": 0.89869
        }
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.4375,
        "vocab_size-1": 21,
        "unique-1": 0,
        "entropy-1": 4.334962500721156,
        "distinct-2": 0.5,
        "vocab_size-2": 23,
        "unique-2": 0,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.19946902055324794,
        "distinct-3": 0.5,
        "vocab_size-3": 22,
        "unique-3": 0,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4375,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.334962500721156,
        "distinct-2-nopunct": 0.5,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.19946902055324794,
        "distinct-3-nopunct": 0.5,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.5285714285714286
        },
        "nist": 1.2506207368759865,
        "rouge1": {
            "precision": 0.85417,
            "recall": 0.51316,
            "fmeasure": 0.64076
        },
        "rouge2": {
            "precision": 0.52174,
            "recall": 0.30587,
            "fmeasure": 0.38542
        },
        "rougeL": {
            "precision": 0.60417,
            "recall": 0.36278,
            "fmeasure": 0.45308
        },
        "rougeLsum": {
            "precision": 0.60417,
            "recall": 0.36278,
            "fmeasure": 0.45308
        },
        "bleu": 15.49398,
        "nubia": {
            "semantic_relation": 3.62886,
            "contradiction": 1.61165,
            "irrelevancy": 2.31479,
            "logical_agreement": 96.07356,
            "grammar_ref": 4.16331,
            "grammar_hyp": 5.20915,
            "nubia_score": 0.41027
        },
        "bleurt": -0.35515,
        "meteor": 0.2710174409751563,
        "bertscore": {
            "precision": 0.90612,
            "recall": 0.84616,
            "f1": 0.87511
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 958,
        "msttr-100": 0.67352,
        "msttr-100_nopunct": 0.69798,
        "total_length": 19627,
        "mean_pred_length": 20.487473903966595,
        "std_pred_length": 4.801416554073202,
        "median_pred_length": 21.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.08676822744178937,
        "vocab_size-1": 1703,
        "unique-1": 797,
        "entropy-1": 7.811615561653424,
        "distinct-2": 0.2833038727301944,
        "vocab_size-2": 5289,
        "unique-2": 3216,
        "entropy-2": 10.783123309210119,
        "cond_entropy-2": 2.851415141360239,
        "distinct-3": 0.48512224041556096,
        "vocab_size-3": 8592,
        "unique-3": 6191,
        "entropy-3": 12.152557036458065,
        "cond_entropy-3": 1.446522150620357,
        "total_length-nopunct": 17364,
        "mean_pred_length-nopunct": 18.12526096033403,
        "std_pred_length-nopunct": 4.451193066211914,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.09732780465330569,
        "vocab_size-1-nopunct": 1690,
        "unique-1-nopunct": 796,
        "entropy-1-nopunct": 8.017962316690676,
        "distinct-2-nopunct": 0.3042179690357186,
        "vocab_size-2-nopunct": 4991,
        "unique-2-nopunct": 3123,
        "entropy-2-nopunct": 10.764070927177949,
        "cond_entropy-2-nopunct": 2.8890722140592144,
        "distinct-3-nopunct": 0.5154712584153288,
        "vocab_size-3-nopunct": 7963,
        "unique-3-nopunct": 5863,
        "entropy-3-nopunct": 12.159120132870264,
        "cond_entropy-3-nopunct": 1.4772726437937438,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5987531878719183
        },
        "nist": 6.6449770155119685,
        "rouge1": {
            "precision": 0.65365,
            "recall": 0.61314,
            "fmeasure": 0.62326
        },
        "rouge2": {
            "precision": 0.41685,
            "recall": 0.39027,
            "fmeasure": 0.39667
        },
        "rougeL": {
            "precision": 0.56934,
            "recall": 0.5347,
            "fmeasure": 0.54327
        },
        "rougeLsum": {
            "precision": 0.56934,
            "recall": 0.5347,
            "fmeasure": 0.54327
        },
        "bleu": 31.85539,
        "nubia": {
            "semantic_relation": 4.33605,
            "contradiction": 3.06197,
            "irrelevancy": 16.78425,
            "logical_agreement": 80.15377,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.87423,
            "nubia_score": 0.74767
        },
        "bleurt": -0.04828,
        "meteor": 0.33383130168221603,
        "bertscore": {
            "precision": 0.88765,
            "recall": 0.87869,
            "f1": 0.88279
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 72,
        "msttr-100": 0.64556,
        "msttr-100_nopunct": 0.66,
        "total_length": 1852,
        "mean_pred_length": 25.72222222222222,
        "std_pred_length": 2.9022128636908837,
        "median_pred_length": 26.0,
        "min_pred_length": 17,
        "max_pred_length": 33,
        "distinct-1": 0.21544276457883368,
        "vocab_size-1": 399,
        "unique-1": 234,
        "entropy-1": 7.094065194109704,
        "distinct-2": 0.48707865168539327,
        "vocab_size-2": 867,
        "unique-2": 592,
        "entropy-2": 9.089829390798021,
        "cond_entropy-2": 2.017505749144039,
        "distinct-3": 0.6768149882903981,
        "vocab_size-3": 1156,
        "unique-3": 931,
        "entropy-3": 9.793013805455208,
        "cond_entropy-3": 0.7427063386891735,
        "total_length-nopunct": 1656,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 2.8819360776317637,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.23671497584541062,
        "vocab_size-1-nopunct": 392,
        "unique-1-nopunct": 233,
        "entropy-1-nopunct": 7.188356596124379,
        "distinct-2-nopunct": 0.523989898989899,
        "vocab_size-2-nopunct": 830,
        "unique-2-nopunct": 581,
        "entropy-2-nopunct": 9.090318579838442,
        "cond_entropy-2-nopunct": 1.957605328051415,
        "distinct-3-nopunct": 0.705026455026455,
        "vocab_size-3-nopunct": 1066,
        "unique-3-nopunct": 868,
        "entropy-3-nopunct": 9.721089702339569,
        "cond_entropy-3-nopunct": 0.6711388285794564,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4952712792434047
        },
        "nist": 3.774804174398904,
        "rouge1": {
            "precision": 0.64569,
            "recall": 0.49842,
            "fmeasure": 0.55424
        },
        "rouge2": {
            "precision": 0.39029,
            "recall": 0.3045,
            "fmeasure": 0.33659
        },
        "rougeL": {
            "precision": 0.5325,
            "recall": 0.41317,
            "fmeasure": 0.45809
        },
        "rougeLsum": {
            "precision": 0.5325,
            "recall": 0.41317,
            "fmeasure": 0.45809
        },
        "bleu": 24.67001,
        "nubia": {
            "semantic_relation": 3.53148,
            "contradiction": 6.26601,
            "irrelevancy": 17.36912,
            "logical_agreement": 76.36487,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.4432,
            "nubia_score": 0.50025
        },
        "bleurt": -0.30538,
        "meteor": 0.26577460171805345,
        "bertscore": {
            "precision": 0.8863,
            "recall": 0.8457,
            "f1": 0.8652
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 1024,
        "msttr-100": 0.52863,
        "msttr-100_nopunct": 0.55425,
        "total_length": 10244,
        "mean_pred_length": 10.00390625,
        "std_pred_length": 5.5461473444374825,
        "median_pred_length": 7.0,
        "min_pred_length": 2,
        "max_pred_length": 28,
        "distinct-1": 0.07819211245607184,
        "vocab_size-1": 801,
        "unique-1": 441,
        "entropy-1": 6.564749914967896,
        "distinct-2": 0.23904555314533624,
        "vocab_size-2": 2204,
        "unique-2": 1355,
        "entropy-2": 9.383400804099614,
        "cond_entropy-2": 2.5178813563982754,
        "distinct-3": 0.41874084919472915,
        "vocab_size-3": 3432,
        "unique-3": 2426,
        "entropy-3": 10.61459153990447,
        "cond_entropy-3": 1.2088848149904794,
        "total_length-nopunct": 8712,
        "mean_pred_length-nopunct": 8.5078125,
        "std_pred_length-nopunct": 4.945201420553439,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.09079430670339761,
        "vocab_size-1-nopunct": 791,
        "unique-1-nopunct": 439,
        "entropy-1-nopunct": 6.7953500331507675,
        "distinct-2-nopunct": 0.2678199791883455,
        "vocab_size-2-nopunct": 2059,
        "unique-2-nopunct": 1312,
        "entropy-2-nopunct": 9.300673120334018,
        "cond_entropy-2-nopunct": 2.675601091246363,
        "distinct-3-nopunct": 0.4645161290322581,
        "vocab_size-3-nopunct": 3096,
        "unique-3-nopunct": 2302,
        "entropy-3-nopunct": 10.508123931504805,
        "cond_entropy-3-nopunct": 1.2107807995583215,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.41969082337463
        },
        "nist": 4.3543950657656145,
        "rouge1": {
            "precision": 0.40849,
            "recall": 0.38728,
            "fmeasure": 0.38725
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.19186,
            "fmeasure": 0.19144
        },
        "rougeL": {
            "precision": 0.36525,
            "recall": 0.34676,
            "fmeasure": 0.34616
        },
        "rougeLsum": {
            "precision": 0.36525,
            "recall": 0.34676,
            "fmeasure": 0.34616
        },
        "bleu": 23.77711,
        "nubia": {
            "semantic_relation": 2.37914,
            "contradiction": 13.59605,
            "irrelevancy": 32.96473,
            "logical_agreement": 53.43921,
            "grammar_ref": 5.2128,
            "grammar_hyp": 5.12386,
            "nubia_score": 0.38847
        },
        "bleurt": -0.60946,
        "meteor": 0.23661746753889137,
        "bertscore": {
            "precision": 0.83782,
            "recall": 0.83123,
            "f1": 0.83406
        }
    },
    "e2e_nlg_validation": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_validation",
        "N": 4299,
        "msttr-100": 0.31407,
        "msttr-100_nopunct": 0.30851,
        "total_length": 97703,
        "mean_pred_length": 22.726913235636193,
        "std_pred_length": 4.383866150272202,
        "median_pred_length": 24.0,
        "min_pred_length": 8,
        "max_pred_length": 33,
        "distinct-1": 0.006222940953706641,
        "vocab_size-1": 608,
        "unique-1": 92,
        "entropy-1": 6.262080928347529,
        "distinct-2": 0.030159307952550212,
        "vocab_size-2": 2817,
        "unique-2": 634,
        "entropy-2": 8.539069439425292,
        "cond_entropy-2": 2.321505237263361,
        "distinct-3": 0.06352056562482465,
        "vocab_size-3": 5660,
        "unique-3": 1598,
        "entropy-3": 10.019723702322354,
        "cond_entropy-3": 1.5820040887337097,
        "total_length-nopunct": 90693,
        "mean_pred_length-nopunct": 21.09630146545708,
        "std_pred_length-nopunct": 4.256329009236569,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.006659830416900973,
        "vocab_size-1-nopunct": 604,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.293267099032055,
        "distinct-2-nopunct": 0.032814778804083615,
        "vocab_size-2-nopunct": 2835,
        "unique-2-nopunct": 655,
        "entropy-2-nopunct": 8.527175825776608,
        "cond_entropy-2-nopunct": 2.3620472392901943,
        "distinct-3-nopunct": 0.06744625129423229,
        "vocab_size-3-nopunct": 5537,
        "unique-3-nopunct": 1571,
        "entropy-3-nopunct": 10.036244184538289,
        "cond_entropy-3-nopunct": 1.6074590498185999,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_validation.json",
        "local_recall": {
            "1": 0.6196479351592812
        },
        "nist": 4.657984809859502,
        "rouge1": {
            "precision": 0.66605,
            "recall": 0.63945,
            "fmeasure": 0.64263
        },
        "rouge2": {
            "precision": 0.38686,
            "recall": 0.36795,
            "fmeasure": 0.3715
        },
        "rougeL": {
            "precision": 0.49042,
            "recall": 0.47249,
            "fmeasure": 0.47405
        },
        "rougeLsum": {
            "precision": 0.49042,
            "recall": 0.47249,
            "fmeasure": 0.47405
        },
        "bleu": 26.47513,
        "nubia": {
            "semantic_relation": 3.9128,
            "contradiction": 5.17213,
            "irrelevancy": 29.40181,
            "logical_agreement": 65.42606,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.72316,
            "nubia_score": 0.64347
        },
        "bleurt": -0.06554,
        "meteor": 0.3217760535102475,
        "bertscore": {
            "precision": 0.89384,
            "recall": 0.88371,
            "f1": 0.88843
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 1246,
        "msttr-100": 0.68946,
        "msttr-100_nopunct": 0.71,
        "total_length": 18515,
        "mean_pred_length": 14.859550561797754,
        "std_pred_length": 4.782963794045295,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.10207939508506617,
        "vocab_size-1": 1890,
        "unique-1": 866,
        "entropy-1": 8.06770914328047,
        "distinct-2": 0.3128727778099485,
        "vocab_size-2": 5403,
        "unique-2": 3288,
        "entropy-2": 10.969417465460955,
        "cond_entropy-2": 2.6962655922117333,
        "distinct-3": 0.5171940335767334,
        "vocab_size-3": 8287,
        "unique-3": 5984,
        "entropy-3": 12.232867555421917,
        "cond_entropy-3": 1.3054385469333187,
        "total_length-nopunct": 16542,
        "mean_pred_length-nopunct": 13.276083467094702,
        "std_pred_length-nopunct": 4.3960279831168325,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.11334784185709104,
        "vocab_size-1-nopunct": 1875,
        "unique-1-nopunct": 864,
        "entropy-1-nopunct": 8.235926064597031,
        "distinct-2-nopunct": 0.3253791841004184,
        "vocab_size-2-nopunct": 4977,
        "unique-2-nopunct": 3125,
        "entropy-2-nopunct": 10.833283175641728,
        "cond_entropy-2-nopunct": 2.7286475923109217,
        "distinct-3-nopunct": 0.5320996441281138,
        "vocab_size-3-nopunct": 7476,
        "unique-3-nopunct": 5510,
        "entropy-3-nopunct": 12.0864243399719,
        "cond_entropy-3-nopunct": 1.310122684251403,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6353060493974466
        },
        "nist": 7.323921407031654,
        "rouge1": {
            "precision": 0.69957,
            "recall": 0.66164,
            "fmeasure": 0.66956
        },
        "rouge2": {
            "precision": 0.49087,
            "recall": 0.46379,
            "fmeasure": 0.46887
        },
        "rougeL": {
            "precision": 0.61384,
            "recall": 0.57981,
            "fmeasure": 0.58733
        },
        "rougeLsum": {
            "precision": 0.61384,
            "recall": 0.57981,
            "fmeasure": 0.58733
        },
        "bleu": 38.54785,
        "nubia": {
            "semantic_relation": 4.33748,
            "contradiction": 3.09206,
            "irrelevancy": 18.81433,
            "logical_agreement": 78.09361,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.91288,
            "nubia_score": 0.76949
        },
        "bleurt": -0.00838,
        "meteor": 0.36658929843985893,
        "bertscore": {
            "precision": 0.90127,
            "recall": 0.89245,
            "f1": 0.89643
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.3693,
        "msttr-100_nopunct": 0.37946,
        "total_length": 4300,
        "mean_pred_length": 8.6,
        "std_pred_length": 2.041568024827975,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 27,
        "distinct-1": 0.031162790697674417,
        "vocab_size-1": 134,
        "unique-1": 31,
        "entropy-1": 5.203749537880319,
        "distinct-2": 0.115,
        "vocab_size-2": 437,
        "unique-2": 184,
        "entropy-2": 7.070488623211741,
        "cond_entropy-2": 1.605294286373716,
        "distinct-3": 0.22393939393939394,
        "vocab_size-3": 739,
        "unique-3": 371,
        "entropy-3": 8.087687236452291,
        "cond_entropy-3": 1.0561287615509276,
        "total_length-nopunct": 3791,
        "mean_pred_length-nopunct": 7.582,
        "std_pred_length-nopunct": 1.9766830803140902,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.034291743603270905,
        "vocab_size-1-nopunct": 130,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.27335374558354,
        "distinct-2-nopunct": 0.11789729565481616,
        "vocab_size-2-nopunct": 388,
        "unique-2-nopunct": 164,
        "entropy-2-nopunct": 6.813166610680761,
        "cond_entropy-2-nopunct": 1.7016770090658206,
        "distinct-3-nopunct": 0.223217484772483,
        "vocab_size-3-nopunct": 623,
        "unique-3-nopunct": 316,
        "entropy-3-nopunct": 7.757288321257019,
        "cond_entropy-3-nopunct": 1.1542615746967095,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5171223785505707
        },
        "nist": 3.614456147316652,
        "rouge1": {
            "precision": 0.53927,
            "recall": 0.5345,
            "fmeasure": 0.52613
        },
        "rouge2": {
            "precision": 0.31134,
            "recall": 0.30931,
            "fmeasure": 0.30295
        },
        "rougeL": {
            "precision": 0.51709,
            "recall": 0.51428,
            "fmeasure": 0.50542
        },
        "rougeLsum": {
            "precision": 0.51709,
            "recall": 0.51428,
            "fmeasure": 0.50542
        },
        "bleu": 26.48884,
        "nubia": {
            "semantic_relation": 3.68067,
            "contradiction": 3.9183,
            "irrelevancy": 29.75516,
            "logical_agreement": 66.32654,
            "grammar_ref": 4.43492,
            "grammar_hyp": 4.2786,
            "nubia_score": 0.68028
        },
        "bleurt": 0.04249,
        "meteor": 0.28258169082600065,
        "bertscore": {
            "precision": 0.88387,
            "recall": 0.88402,
            "f1": 0.88358
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 2517,
        "msttr-100": 0.69748,
        "msttr-100_nopunct": 0.72234,
        "total_length": 36913,
        "mean_pred_length": 14.665474771553436,
        "std_pred_length": 4.342613901062587,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.06916262563324574,
        "vocab_size-1": 2553,
        "unique-1": 1184,
        "entropy-1": 8.179727577409324,
        "distinct-2": 0.2744214443539946,
        "vocab_size-2": 9439,
        "unique-2": 5628,
        "entropy-2": 11.711104324429067,
        "cond_entropy-2": 3.307217209679066,
        "distinct-3": 0.49628281941089747,
        "vocab_size-3": 15821,
        "unique-3": 11467,
        "entropy-3": 13.095182300682042,
        "cond_entropy-3": 1.4236662368862103,
        "total_length-nopunct": 32598,
        "mean_pred_length-nopunct": 12.95113230035757,
        "std_pred_length-nopunct": 3.9369781671953143,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07788821400085895,
        "vocab_size-1-nopunct": 2539,
        "unique-1-nopunct": 1182,
        "entropy-1-nopunct": 8.392029169925824,
        "distinct-2-nopunct": 0.2941059140321133,
        "vocab_size-2-nopunct": 8847,
        "unique-2-nopunct": 5493,
        "entropy-2-nopunct": 11.60480547508513,
        "cond_entropy-2-nopunct": 3.370331312221548,
        "distinct-3-nopunct": 0.5186112320417936,
        "vocab_size-3-nopunct": 14295,
        "unique-3-nopunct": 10635,
        "entropy-3-nopunct": 12.958713055532249,
        "cond_entropy-3-nopunct": 1.4169443599737712,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5876433638551205
        },
        "nist": 6.86405342740519,
        "rouge1": {
            "precision": 0.631,
            "recall": 0.61013,
            "fmeasure": 0.60969
        },
        "rouge2": {
            "precision": 0.39907,
            "recall": 0.38732,
            "fmeasure": 0.38602
        },
        "rougeL": {
            "precision": 0.54863,
            "recall": 0.53067,
            "fmeasure": 0.53029
        },
        "rougeLsum": {
            "precision": 0.54863,
            "recall": 0.53067,
            "fmeasure": 0.53029
        },
        "bleu": 32.99866,
        "nubia": {
            "semantic_relation": 4.02515,
            "contradiction": 4.48006,
            "irrelevancy": 20.81723,
            "logical_agreement": 74.70271,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.76836,
            "nubia_score": 0.69847
        },
        "bleurt": -0.06511,
        "meteor": 0.32734120431436475,
        "bertscore": {
            "precision": 0.88285,
            "recall": 0.87812,
            "f1": 0.88008
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 2078,
        "msttr-100": 0.51668,
        "msttr-100_nopunct": 0.5388,
        "total_length": 22009,
        "mean_pred_length": 10.591434071222329,
        "std_pred_length": 5.383472351147238,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 33,
        "distinct-1": 0.024944340951428962,
        "vocab_size-1": 549,
        "unique-1": 181,
        "entropy-1": 6.353062738247432,
        "distinct-2": 0.1352666700115398,
        "vocab_size-2": 2696,
        "unique-2": 1292,
        "entropy-2": 9.345184856043808,
        "cond_entropy-2": 2.7024749039230382,
        "distinct-3": 0.29496443174816556,
        "vocab_size-3": 5266,
        "unique-3": 3264,
        "entropy-3": 10.797695100883786,
        "cond_entropy-3": 1.5123294553593312,
        "total_length-nopunct": 19295,
        "mean_pred_length-nopunct": 9.285370548604428,
        "std_pred_length-nopunct": 4.960177085573566,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.02809017880279865,
        "vocab_size-1-nopunct": 542,
        "unique-1-nopunct": 179,
        "entropy-1-nopunct": 6.518910285092584,
        "distinct-2-nopunct": 0.14677353778242436,
        "vocab_size-2-nopunct": 2527,
        "unique-2-nopunct": 1298,
        "entropy-2-nopunct": 9.109151070729883,
        "cond_entropy-2-nopunct": 2.7869702794637274,
        "distinct-3-nopunct": 0.3089624199194241,
        "vocab_size-3-nopunct": 4678,
        "unique-3-nopunct": 3050,
        "entropy-3-nopunct": 10.534904983831291,
        "cond_entropy-3-nopunct": 1.5464879569227687,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.4290370983598075
        },
        "nist": 3.615077918180356,
        "rouge1": {
            "precision": 0.45832,
            "recall": 0.43305,
            "fmeasure": 0.43034
        },
        "rouge2": {
            "precision": 0.22564,
            "recall": 0.21466,
            "fmeasure": 0.2109
        },
        "rougeL": {
            "precision": 0.41925,
            "recall": 0.39624,
            "fmeasure": 0.39394
        },
        "rougeLsum": {
            "precision": 0.41925,
            "recall": 0.39624,
            "fmeasure": 0.39394
        },
        "bleu": 16.9288,
        "nubia": {
            "semantic_relation": 3.00317,
            "contradiction": 11.7898,
            "irrelevancy": 28.83404,
            "logical_agreement": 59.37616,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.48098,
            "nubia_score": 0.49412
        },
        "bleurt": -0.32583,
        "meteor": 0.2306784481486773,
        "bertscore": {
            "precision": 0.84011,
            "recall": 0.83306,
            "f1": 0.83582
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 1328,
        "msttr-100": 0.69909,
        "msttr-100_nopunct": 0.72371,
        "total_length": 25291,
        "mean_pred_length": 19.044427710843372,
        "std_pred_length": 4.642358240585372,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.08342888774662924,
        "vocab_size-1": 2110,
        "unique-1": 1020,
        "entropy-1": 8.115133832516076,
        "distinct-2": 0.29908609105704625,
        "vocab_size-2": 7167,
        "unique-2": 4419,
        "entropy-2": 11.388444181704545,
        "cond_entropy-2": 3.122929895175194,
        "distinct-3": 0.5165009940357853,
        "vocab_size-3": 11691,
        "unique-3": 8597,
        "entropy-3": 12.72664115035398,
        "cond_entropy-3": 1.3944280347706137,
        "total_length-nopunct": 22437,
        "mean_pred_length-nopunct": 16.895331325301203,
        "std_pred_length-nopunct": 4.193767881851599,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.09341712350135936,
        "vocab_size-1-nopunct": 2096,
        "unique-1-nopunct": 1017,
        "entropy-1-nopunct": 8.318792670830877,
        "distinct-2-nopunct": 0.32156899900516367,
        "vocab_size-2-nopunct": 6788,
        "unique-2-nopunct": 4326,
        "entropy-2-nopunct": 11.330088414526998,
        "cond_entropy-2-nopunct": 3.150019851260422,
        "distinct-3-nopunct": 0.5443607502148526,
        "vocab_size-3-nopunct": 10768,
        "unique-3-nopunct": 8134,
        "entropy-3-nopunct": 12.649884960429748,
        "cond_entropy-3-nopunct": 1.3866874851938944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6064004376367614
        },
        "nist": 6.8505057768426445,
        "rouge1": {
            "precision": 0.64781,
            "recall": 0.6261,
            "fmeasure": 0.62647
        },
        "rouge2": {
            "precision": 0.4138,
            "recall": 0.40172,
            "fmeasure": 0.40088
        },
        "rougeL": {
            "precision": 0.54609,
            "recall": 0.52911,
            "fmeasure": 0.52891
        },
        "rougeLsum": {
            "precision": 0.54609,
            "recall": 0.52911,
            "fmeasure": 0.52891
        },
        "bleu": 32.34003,
        "nubia": {
            "semantic_relation": 4.24629,
            "contradiction": 2.95712,
            "irrelevancy": 17.60113,
            "logical_agreement": 79.44176,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.76303,
            "nubia_score": 0.73777
        },
        "bleurt": -0.03995,
        "meteor": 0.3326590880757734,
        "bertscore": {
            "precision": 0.88905,
            "recall": 0.88233,
            "f1": 0.88531
        }
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 469,
        "msttr-100": 0.69979,
        "msttr-100_nopunct": 0.71802,
        "total_length": 9586,
        "mean_pred_length": 20.439232409381663,
        "std_pred_length": 4.311812041147207,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.12674733987064468,
        "vocab_size-1": 1215,
        "unique-1": 602,
        "entropy-1": 7.923338654315286,
        "distinct-2": 0.37128441373258747,
        "vocab_size-2": 3385,
        "unique-2": 2186,
        "entropy-2": 10.644240194888788,
        "cond_entropy-2": 2.602255592439983,
        "distinct-3": 0.5876503237742831,
        "vocab_size-3": 5082,
        "unique-3": 3848,
        "entropy-3": 11.77227540956583,
        "cond_entropy-3": 1.1505627965144232,
        "total_length-nopunct": 8617,
        "mean_pred_length-nopunct": 18.37313432835821,
        "std_pred_length-nopunct": 3.9494949860797264,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.1399559011256818,
        "vocab_size-1-nopunct": 1206,
        "unique-1-nopunct": 602,
        "entropy-1-nopunct": 8.070859754598311,
        "distinct-2-nopunct": 0.3904025527736868,
        "vocab_size-2-nopunct": 3181,
        "unique-2-nopunct": 2106,
        "entropy-2-nopunct": 10.572492621866541,
        "cond_entropy-2-nopunct": 2.5868606239580454,
        "distinct-3-nopunct": 0.6120588618309676,
        "vocab_size-3-nopunct": 4700,
        "unique-3-nopunct": 3634,
        "entropy-3-nopunct": 11.695572873619962,
        "cond_entropy-3-nopunct": 1.1399509741712985,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.6355529820497974
        },
        "nist": 6.827106327759669,
        "rouge1": {
            "precision": 0.68861,
            "recall": 0.65428,
            "fmeasure": 0.66087
        },
        "rouge2": {
            "precision": 0.46561,
            "recall": 0.4413,
            "fmeasure": 0.44623
        },
        "rougeL": {
            "precision": 0.59841,
            "recall": 0.56892,
            "fmeasure": 0.57474
        },
        "rougeLsum": {
            "precision": 0.59841,
            "recall": 0.56892,
            "fmeasure": 0.57474
        },
        "bleu": 34.81749,
        "nubia": {
            "semantic_relation": 4.29753,
            "contradiction": 2.41067,
            "irrelevancy": 17.64685,
            "logical_agreement": 79.94248,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.87013,
            "nubia_score": 0.7412
        },
        "bleurt": -0.05006,
        "meteor": 0.3477757771052919,
        "bertscore": {
            "precision": 0.89497,
            "recall": 0.88762,
            "f1": 0.89091
        }
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 715,
        "msttr-100": 0.27844,
        "msttr-100_nopunct": 0.276,
        "total_length": 6408,
        "mean_pred_length": 8.962237762237763,
        "std_pred_length": 2.916550414632241,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 25,
        "distinct-1": 0.02215980024968789,
        "vocab_size-1": 142,
        "unique-1": 41,
        "entropy-1": 4.669003859491208,
        "distinct-2": 0.07324784823467416,
        "vocab_size-2": 417,
        "unique-2": 190,
        "entropy-2": 6.074908702198648,
        "cond_entropy-2": 1.2281183712723824,
        "distinct-3": 0.12274005624748895,
        "vocab_size-3": 611,
        "unique-3": 346,
        "entropy-3": 6.6826462014108845,
        "cond_entropy-3": 0.5887804786426469,
        "total_length-nopunct": 5593,
        "mean_pred_length-nopunct": 7.822377622377623,
        "std_pred_length-nopunct": 2.6002802318163263,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.02467369926694082,
        "vocab_size-1-nopunct": 138,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 4.610600421002886,
        "distinct-2-nopunct": 0.07851578515785158,
        "vocab_size-2-nopunct": 383,
        "unique-2-nopunct": 195,
        "entropy-2-nopunct": 5.810384585839828,
        "cond_entropy-2-nopunct": 1.1753093940976034,
        "distinct-3-nopunct": 0.127792457362479,
        "vocab_size-3-nopunct": 532,
        "unique-3-nopunct": 312,
        "entropy-3-nopunct": 6.378597081130941,
        "cond_entropy-3-nopunct": 0.534320397683245,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5350798492732819
        },
        "nist": 3.033947232254401,
        "rouge1": {
            "precision": 0.5393,
            "recall": 0.54846,
            "fmeasure": 0.53137
        },
        "rouge2": {
            "precision": 0.29461,
            "recall": 0.30009,
            "fmeasure": 0.28895
        },
        "rougeL": {
            "precision": 0.46542,
            "recall": 0.46921,
            "fmeasure": 0.45641
        },
        "rougeLsum": {
            "precision": 0.46542,
            "recall": 0.46921,
            "fmeasure": 0.45641
        },
        "bleu": 26.25228,
        "nubia": {
            "semantic_relation": 3.5844,
            "contradiction": 2.26142,
            "irrelevancy": 25.96139,
            "logical_agreement": 71.77719,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.76764,
            "nubia_score": 0.70138
        },
        "bleurt": 0.12263,
        "meteor": 0.28048676843377535,
        "bertscore": {
            "precision": 0.85393,
            "recall": 0.85444,
            "f1": 0.85359
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72636,
        "msttr-100_nopunct": 0.73667,
        "total_length": 2277,
        "mean_pred_length": 21.4811320754717,
        "std_pred_length": 3.4236445660482255,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.41106719367588934,
        "vocab_size-1": 936,
        "unique-1": 694,
        "entropy-1": 8.369533842624632,
        "distinct-2": 0.844311377245509,
        "vocab_size-2": 1833,
        "unique-2": 1670,
        "entropy-2": 10.646726318916423,
        "cond_entropy-2": 2.1899982699240783,
        "distinct-3": 0.9753026634382567,
        "vocab_size-3": 2014,
        "unique-3": 1969,
        "entropy-3": 10.960100618360935,
        "cond_entropy-3": 0.322789051413498,
        "total_length-nopunct": 2163,
        "mean_pred_length-nopunct": 20.40566037735849,
        "std_pred_length-nopunct": 3.530936862921721,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.42903374942209893,
        "vocab_size-1-nopunct": 928,
        "unique-1-nopunct": 690,
        "entropy-1-nopunct": 8.431220194485311,
        "distinct-2-nopunct": 0.8492950899368011,
        "vocab_size-2-nopunct": 1747,
        "unique-2-nopunct": 1596,
        "entropy-2-nopunct": 10.583645962233879,
        "cond_entropy-2-nopunct": 2.225476759491174,
        "distinct-3-nopunct": 0.9774474628395694,
        "vocab_size-3-nopunct": 1907,
        "unique-3-nopunct": 1868,
        "entropy-3-nopunct": 10.882958371419651,
        "cond_entropy-3-nopunct": 0.30503513307351854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.39533705017739484
        },
        "nist": 3.5405568548248807,
        "rouge1": {
            "precision": 0.39801,
            "recall": 0.41361,
            "fmeasure": 0.39844
        },
        "rouge2": {
            "precision": 0.17862,
            "recall": 0.18569,
            "fmeasure": 0.17908
        },
        "rougeL": {
            "precision": 0.31957,
            "recall": 0.33327,
            "fmeasure": 0.32033
        },
        "rougeLsum": {
            "precision": 0.31957,
            "recall": 0.33327,
            "fmeasure": 0.32033
        },
        "bleu": 13.9701,
        "nubia": {
            "semantic_relation": 2.71358,
            "contradiction": 26.46087,
            "irrelevancy": 62.78316,
            "logical_agreement": 10.75597,
            "grammar_ref": 3.74062,
            "grammar_hyp": 4.20741,
            "nubia_score": 0.34743
        },
        "bleurt": -0.45765,
        "meteor": 0.18943392849664492,
        "bertscore": {
            "precision": 0.82976,
            "recall": 0.82864,
            "f1": 0.8289
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72682,
        "msttr-100_nopunct": 0.73238,
        "total_length": 2249,
        "mean_pred_length": 21.21698113207547,
        "std_pred_length": 3.4340270572365443,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.40862605602489993,
        "vocab_size-1": 919,
        "unique-1": 663,
        "entropy-1": 8.356748513407807,
        "distinct-2": 0.8334111059262715,
        "vocab_size-2": 1786,
        "unique-2": 1606,
        "entropy-2": 10.58220624611184,
        "cond_entropy-2": 2.145528712648202,
        "distinct-3": 0.9626902307314679,
        "vocab_size-3": 1961,
        "unique-3": 1894,
        "entropy-3": 10.914034775267762,
        "cond_entropy-3": 0.3479701090209196,
        "total_length-nopunct": 2139,
        "mean_pred_length-nopunct": 20.17924528301887,
        "std_pred_length-nopunct": 3.589284812903279,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4268349696119682,
        "vocab_size-1-nopunct": 913,
        "unique-1-nopunct": 661,
        "entropy-1-nopunct": 8.421071767658841,
        "distinct-2-nopunct": 0.8342351205115592,
        "vocab_size-2-nopunct": 1696,
        "unique-2-nopunct": 1528,
        "entropy-2-nopunct": 10.503408756514798,
        "cond_entropy-2-nopunct": 2.1683739713327963,
        "distinct-3-nopunct": 0.964193046185781,
        "vocab_size-3-nopunct": 1858,
        "unique-3-nopunct": 1795,
        "entropy-3-nopunct": 10.838176494587083,
        "cond_entropy-3-nopunct": 0.34435356521862753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3604926575082899
        },
        "nist": 3.3219733007682093,
        "rouge1": {
            "precision": 0.40384,
            "recall": 0.38578,
            "fmeasure": 0.38881
        },
        "rouge2": {
            "precision": 0.16859,
            "recall": 0.15777,
            "fmeasure": 0.16021
        },
        "rougeL": {
            "precision": 0.31301,
            "recall": 0.29847,
            "fmeasure": 0.30112
        },
        "rougeLsum": {
            "precision": 0.31301,
            "recall": 0.29847,
            "fmeasure": 0.30112
        },
        "bleu": 10.82218,
        "nubia": {
            "semantic_relation": 2.68355,
            "contradiction": 28.57967,
            "irrelevancy": 59.64196,
            "logical_agreement": 11.77837,
            "grammar_ref": 3.75111,
            "grammar_hyp": 4.27221,
            "nubia_score": 0.32972
        },
        "bleurt": -0.49678,
        "meteor": 0.16782619516710257,
        "bertscore": {
            "precision": 0.82803,
            "recall": 0.8176,
            "f1": 0.82246
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74217,
        "msttr-100_nopunct": 0.75286,
        "total_length": 2310,
        "mean_pred_length": 21.79245283018868,
        "std_pred_length": 3.476923876647492,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.40606060606060607,
        "vocab_size-1": 938,
        "unique-1": 673,
        "entropy-1": 8.42050134504067,
        "distinct-2": 0.8434664246823956,
        "vocab_size-2": 1859,
        "unique-2": 1677,
        "entropy-2": 10.662664207975967,
        "cond_entropy-2": 2.1852406652078353,
        "distinct-3": 0.9742612011439467,
        "vocab_size-3": 2044,
        "unique-3": 1998,
        "entropy-3": 10.978594888716161,
        "cond_entropy-3": 0.3282706036940344,
        "total_length-nopunct": 2198,
        "mean_pred_length-nopunct": 20.735849056603772,
        "std_pred_length-nopunct": 3.5800861347086426,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.42356687898089174,
        "vocab_size-1-nopunct": 931,
        "unique-1-nopunct": 670,
        "entropy-1-nopunct": 8.481322524326158,
        "distinct-2-nopunct": 0.8513384321223709,
        "vocab_size-2-nopunct": 1781,
        "unique-2-nopunct": 1609,
        "entropy-2-nopunct": 10.614280478238916,
        "cond_entropy-2-nopunct": 2.216188698548982,
        "distinct-3-nopunct": 0.9793554884189325,
        "vocab_size-3-nopunct": 1945,
        "unique-3-nopunct": 1907,
        "entropy-3-nopunct": 10.91322057091886,
        "cond_entropy-3-nopunct": 0.30636116118759094,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.32211981566820275
        },
        "nist": 2.9012404610865787,
        "rouge1": {
            "precision": 0.35477,
            "recall": 0.34403,
            "fmeasure": 0.34479
        },
        "rouge2": {
            "precision": 0.12008,
            "recall": 0.11803,
            "fmeasure": 0.11712
        },
        "rougeL": {
            "precision": 0.27499,
            "recall": 0.267,
            "fmeasure": 0.2672
        },
        "rougeLsum": {
            "precision": 0.27499,
            "recall": 0.267,
            "fmeasure": 0.2672
        },
        "bleu": 6.74152,
        "nubia": {
            "semantic_relation": 2.43442,
            "contradiction": 31.42173,
            "irrelevancy": 57.59178,
            "logical_agreement": 10.98649,
            "grammar_ref": 3.66018,
            "grammar_hyp": 4.38987,
            "nubia_score": 0.26737
        },
        "bleurt": -0.59806,
        "meteor": 0.15099514970778274,
        "bertscore": {
            "precision": 0.81025,
            "recall": 0.80445,
            "f1": 0.80709
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72364,
        "msttr-100_nopunct": 0.73905,
        "total_length": 2254,
        "mean_pred_length": 21.264150943396228,
        "std_pred_length": 3.213479530695228,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.4125998225377107,
        "vocab_size-1": 930,
        "unique-1": 680,
        "entropy-1": 8.37718748083595,
        "distinct-2": 0.845437616387337,
        "vocab_size-2": 1816,
        "unique-2": 1645,
        "entropy-2": 10.625501906586475,
        "cond_entropy-2": 2.1277891721765565,
        "distinct-3": 0.9618021547502449,
        "vocab_size-3": 1964,
        "unique-3": 1904,
        "entropy-3": 10.908510507633425,
        "cond_entropy-3": 0.29798830314158004,
        "total_length-nopunct": 2137,
        "mean_pred_length-nopunct": 20.160377358490567,
        "std_pred_length-nopunct": 3.2276423793999673,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4319138979878334,
        "vocab_size-1-nopunct": 923,
        "unique-1-nopunct": 679,
        "entropy-1-nopunct": 8.452515848544246,
        "distinct-2-nopunct": 0.843426883308715,
        "vocab_size-2-nopunct": 1713,
        "unique-2-nopunct": 1549,
        "entropy-2-nopunct": 10.536453977626282,
        "cond_entropy-2-nopunct": 2.1665514442035887,
        "distinct-3-nopunct": 0.9631168831168831,
        "vocab_size-3-nopunct": 1854,
        "unique-3-nopunct": 1797,
        "entropy-3-nopunct": 10.82762271097484,
        "cond_entropy-3-nopunct": 0.29599601088269667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.32412177985948476
        },
        "nist": 2.969484513201218,
        "rouge1": {
            "precision": 0.36685,
            "recall": 0.35101,
            "fmeasure": 0.35444
        },
        "rouge2": {
            "precision": 0.13036,
            "recall": 0.12562,
            "fmeasure": 0.12603
        },
        "rougeL": {
            "precision": 0.27831,
            "recall": 0.26653,
            "fmeasure": 0.26889
        },
        "rougeLsum": {
            "precision": 0.27831,
            "recall": 0.26653,
            "fmeasure": 0.26889
        },
        "bleu": 7.55632,
        "nubia": {
            "semantic_relation": 2.47664,
            "contradiction": 28.80914,
            "irrelevancy": 61.98166,
            "logical_agreement": 9.2092,
            "grammar_ref": 3.68583,
            "grammar_hyp": 4.25552,
            "nubia_score": 0.29393
        },
        "bleurt": -0.53196,
        "meteor": 0.1517321820607556,
        "bertscore": {
            "precision": 0.81498,
            "recall": 0.80267,
            "f1": 0.80856
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73455,
        "msttr-100_nopunct": 0.73857,
        "total_length": 2293,
        "mean_pred_length": 21.632075471698112,
        "std_pred_length": 3.8370720748393,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.420409943305713,
        "vocab_size-1": 964,
        "unique-1": 699,
        "entropy-1": 8.427627211614677,
        "distinct-2": 0.8559670781893004,
        "vocab_size-2": 1872,
        "unique-2": 1724,
        "entropy-2": 10.671963267816755,
        "cond_entropy-2": 2.1735870633404417,
        "distinct-3": 0.9759730898606439,
        "vocab_size-3": 2031,
        "unique-3": 1995,
        "entropy-3": 10.967183943182153,
        "cond_entropy-3": 0.30988423189031783,
        "total_length-nopunct": 2176,
        "mean_pred_length-nopunct": 20.528301886792452,
        "std_pred_length-nopunct": 3.8318613319579993,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4397977941176471,
        "vocab_size-1-nopunct": 957,
        "unique-1-nopunct": 699,
        "entropy-1-nopunct": 8.481127849167335,
        "distinct-2-nopunct": 0.8594202898550725,
        "vocab_size-2-nopunct": 1779,
        "unique-2-nopunct": 1643,
        "entropy-2-nopunct": 10.600292207982159,
        "cond_entropy-2-nopunct": 2.2060082398980487,
        "distinct-3-nopunct": 0.9786150712830958,
        "vocab_size-3-nopunct": 1922,
        "unique-3-nopunct": 1889,
        "entropy-3-nopunct": 10.89241567537243,
        "cond_entropy-3-nopunct": 0.30555619926013117,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.318781264211005
        },
        "nist": 2.8284085165764434,
        "rouge1": {
            "precision": 0.36635,
            "recall": 0.34868,
            "fmeasure": 0.35304
        },
        "rouge2": {
            "precision": 0.10812,
            "recall": 0.10392,
            "fmeasure": 0.10486
        },
        "rougeL": {
            "precision": 0.26607,
            "recall": 0.25345,
            "fmeasure": 0.25658
        },
        "rougeLsum": {
            "precision": 0.26607,
            "recall": 0.25345,
            "fmeasure": 0.25658
        },
        "bleu": 5.65973,
        "nubia": {
            "semantic_relation": 2.56699,
            "contradiction": 24.45531,
            "irrelevancy": 65.44054,
            "logical_agreement": 10.10415,
            "grammar_ref": 3.83852,
            "grammar_hyp": 4.369,
            "nubia_score": 0.30481
        },
        "bleurt": -0.5777,
        "meteor": 0.1457883237191153,
        "bertscore": {
            "precision": 0.8134,
            "recall": 0.80281,
            "f1": 0.80783
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.70957,
        "msttr-100_nopunct": 0.71636,
        "total_length": 2314,
        "mean_pred_length": 21.830188679245282,
        "std_pred_length": 3.1125785528109984,
        "median_pred_length": 22.0,
        "min_pred_length": 14,
        "max_pred_length": 30,
        "distinct-1": 0.40233362143474505,
        "vocab_size-1": 931,
        "unique-1": 654,
        "entropy-1": 8.370788286696142,
        "distinct-2": 0.822463768115942,
        "vocab_size-2": 1816,
        "unique-2": 1619,
        "entropy-2": 10.60324304564606,
        "cond_entropy-2": 2.1728708580600524,
        "distinct-3": 0.950523311132255,
        "vocab_size-3": 1998,
        "unique-3": 1914,
        "entropy-3": 10.930537937308626,
        "cond_entropy-3": 0.3394095881772465,
        "total_length-nopunct": 2204,
        "mean_pred_length-nopunct": 20.79245283018868,
        "std_pred_length-nopunct": 3.2958435262709007,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.4192377495462795,
        "vocab_size-1-nopunct": 924,
        "unique-1-nopunct": 653,
        "entropy-1-nopunct": 8.414027918834003,
        "distinct-2-nopunct": 0.8231649189704481,
        "vocab_size-2-nopunct": 1727,
        "unique-2-nopunct": 1540,
        "entropy-2-nopunct": 10.528518022479913,
        "cond_entropy-2-nopunct": 2.196537183692698,
        "distinct-3-nopunct": 0.9503012048192772,
        "vocab_size-3-nopunct": 1893,
        "unique-3-nopunct": 1811,
        "entropy-3-nopunct": 10.853915931800733,
        "cond_entropy-3-nopunct": 0.33836682325220924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.31209899175068745
        },
        "nist": 2.794504231858999,
        "rouge1": {
            "precision": 0.35483,
            "recall": 0.33592,
            "fmeasure": 0.34033
        },
        "rouge2": {
            "precision": 0.11938,
            "recall": 0.11268,
            "fmeasure": 0.11434
        },
        "rougeL": {
            "precision": 0.27555,
            "recall": 0.26148,
            "fmeasure": 0.26443
        },
        "rougeLsum": {
            "precision": 0.27555,
            "recall": 0.26148,
            "fmeasure": 0.26443
        },
        "bleu": 7.08489,
        "nubia": {
            "semantic_relation": 2.44671,
            "contradiction": 38.24013,
            "irrelevancy": 52.23146,
            "logical_agreement": 9.52841,
            "grammar_ref": 3.63886,
            "grammar_hyp": 4.24443,
            "nubia_score": 0.28169
        },
        "bleurt": -0.58643,
        "meteor": 0.1406863547311167,
        "bertscore": {
            "precision": 0.81919,
            "recall": 0.80824,
            "f1": 0.81344
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.70864,
        "msttr-100_nopunct": 0.72333,
        "total_length": 2254,
        "mean_pred_length": 21.264150943396228,
        "std_pred_length": 3.2630055793973685,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.3930789707187223,
        "vocab_size-1": 886,
        "unique-1": 624,
        "entropy-1": 8.290411941658158,
        "distinct-2": 0.8184357541899442,
        "vocab_size-2": 1758,
        "unique-2": 1586,
        "entropy-2": 10.516300436039423,
        "cond_entropy-2": 2.1440998033299032,
        "distinct-3": 0.955435847208619,
        "vocab_size-3": 1951,
        "unique-3": 1892,
        "entropy-3": 10.885873111703367,
        "cond_entropy-3": 0.3843356461082162,
        "total_length-nopunct": 2149,
        "mean_pred_length-nopunct": 20.27358490566038,
        "std_pred_length-nopunct": 3.4272300792879276,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4085621219171708,
        "vocab_size-1-nopunct": 878,
        "unique-1-nopunct": 621,
        "entropy-1-nopunct": 8.33714649967144,
        "distinct-2-nopunct": 0.8188937836514929,
        "vocab_size-2-nopunct": 1673,
        "unique-2-nopunct": 1510,
        "entropy-2-nopunct": 10.443381214137421,
        "cond_entropy-2-nopunct": 2.1945888190250042,
        "distinct-3-nopunct": 0.9571502323180175,
        "vocab_size-3-nopunct": 1854,
        "unique-3-nopunct": 1797,
        "entropy-3-nopunct": 10.817179932978842,
        "cond_entropy-3-nopunct": 0.39297059700900433,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3109360518999073
        },
        "nist": 2.807506398584791,
        "rouge1": {
            "precision": 0.36129,
            "recall": 0.3463,
            "fmeasure": 0.34659
        },
        "rouge2": {
            "precision": 0.12222,
            "recall": 0.11772,
            "fmeasure": 0.11651
        },
        "rougeL": {
            "precision": 0.27885,
            "recall": 0.27087,
            "fmeasure": 0.26882
        },
        "rougeLsum": {
            "precision": 0.27885,
            "recall": 0.27087,
            "fmeasure": 0.26882
        },
        "bleu": 6.87469,
        "nubia": {
            "semantic_relation": 2.34962,
            "contradiction": 35.57516,
            "irrelevancy": 54.27354,
            "logical_agreement": 10.15131,
            "grammar_ref": 3.80483,
            "grammar_hyp": 4.30098,
            "nubia_score": 0.2737
        },
        "bleurt": -0.58471,
        "meteor": 0.14189763151243226,
        "bertscore": {
            "precision": 0.81982,
            "recall": 0.80933,
            "f1": 0.81421
        }
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74182,
        "msttr-100_nopunct": 0.74714,
        "total_length": 2273,
        "mean_pred_length": 21.443396226415093,
        "std_pred_length": 3.6292319180100274,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.4104707435107787,
        "vocab_size-1": 933,
        "unique-1": 672,
        "entropy-1": 8.435256343959368,
        "distinct-2": 0.8514074757729581,
        "vocab_size-2": 1845,
        "unique-2": 1680,
        "entropy-2": 10.680671558037549,
        "cond_entropy-2": 2.1992670500247984,
        "distinct-3": 0.9689471130519165,
        "vocab_size-3": 1997,
        "unique-3": 1952,
        "entropy-3": 10.937965135730193,
        "cond_entropy-3": 0.26909179908278996,
        "total_length-nopunct": 2165,
        "mean_pred_length-nopunct": 20.42452830188679,
        "std_pred_length-nopunct": 3.9284835837848333,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.42725173210161665,
        "vocab_size-1-nopunct": 925,
        "unique-1-nopunct": 671,
        "entropy-1-nopunct": 8.48293751143512,
        "distinct-2-nopunct": 0.8576979116075765,
        "vocab_size-2-nopunct": 1766,
        "unique-2-nopunct": 1618,
        "entropy-2-nopunct": 10.621553553137861,
        "cond_entropy-2-nopunct": 2.2268701572780074,
        "distinct-3-nopunct": 0.9713261648745519,
        "vocab_size-3-nopunct": 1897,
        "unique-3-nopunct": 1855,
        "entropy-3-nopunct": 10.867777499635192,
        "cond_entropy-3-nopunct": 0.259329247836254,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.2804479701353243
        },
        "nist": 2.483295787803581,
        "rouge1": {
            "precision": 0.31049,
            "recall": 0.30426,
            "fmeasure": 0.30226
        },
        "rouge2": {
            "precision": 0.09206,
            "recall": 0.09044,
            "fmeasure": 0.08984
        },
        "rougeL": {
            "precision": 0.23909,
            "recall": 0.23442,
            "fmeasure": 0.23266
        },
        "rougeLsum": {
            "precision": 0.23909,
            "recall": 0.23442,
            "fmeasure": 0.23266
        },
        "bleu": 5.22955,
        "nubia": {
            "semantic_relation": 2.10805,
            "contradiction": 34.21982,
            "irrelevancy": 58.97777,
            "logical_agreement": 6.8024,
            "grammar_ref": 3.75874,
            "grammar_hyp": 4.46078,
            "nubia_score": 0.22163
        },
        "bleurt": -0.68041,
        "meteor": 0.12436682352636637,
        "bertscore": {
            "precision": 0.79908,
            "recall": 0.7915,
            "f1": 0.79505
        }
    },
    "e2e_nlg_test": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_test",
        "N": 4693,
        "msttr-100": 0.3144,
        "msttr-100_nopunct": 0.3054,
        "total_length": 105463,
        "mean_pred_length": 22.472405710632856,
        "std_pred_length": 3.866614647216839,
        "median_pred_length": 24.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.0052435451295715085,
        "vocab_size-1": 553,
        "unique-1": 80,
        "entropy-1": 6.181008336650967,
        "distinct-2": 0.026009725116602163,
        "vocab_size-2": 2621,
        "unique-2": 632,
        "entropy-2": 8.435562211078278,
        "cond_entropy-2": 2.3046998386625543,
        "distinct-3": 0.05801596636031516,
        "vocab_size-3": 5574,
        "unique-3": 1560,
        "entropy-3": 9.939488169734515,
        "cond_entropy-3": 1.6071916030684408,
        "total_length-nopunct": 98753,
        "mean_pred_length-nopunct": 21.04261666311528,
        "std_pred_length-nopunct": 3.7739638930846455,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.005549198505361863,
        "vocab_size-1-nopunct": 548,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.187656586136021,
        "distinct-2-nopunct": 0.02764193068254306,
        "vocab_size-2-nopunct": 2600,
        "unique-2-nopunct": 636,
        "entropy-2-nopunct": 8.407091264262126,
        "cond_entropy-2-nopunct": 2.340587434538625,
        "distinct-3-nopunct": 0.06054807703067128,
        "vocab_size-3-nopunct": 5411,
        "unique-3-nopunct": 1518,
        "entropy-3-nopunct": 9.95004207252001,
        "cond_entropy-3-nopunct": 1.6333258944154252,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "local_recall": {
            "1": 0.6407384688446089
        },
        "nist": 4.871959794895731,
        "rouge1": {
            "precision": 0.73801,
            "recall": 0.65944,
            "fmeasure": 0.68592
        },
        "rouge2": {
            "precision": 0.43696,
            "recall": 0.38944,
            "fmeasure": 0.40528
        },
        "rougeL": {
            "precision": 0.52593,
            "recall": 0.47183,
            "fmeasure": 0.48974
        },
        "rougeLsum": {
            "precision": 0.52593,
            "recall": 0.47183,
            "fmeasure": 0.48974
        },
        "bleu": 27.05434,
        "nubia": {
            "semantic_relation": 4.04739,
            "contradiction": 3.46279,
            "irrelevancy": 23.3805,
            "logical_agreement": 73.15672,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.79951,
            "nubia_score": 0.67347
        },
        "bleurt": 0.00104,
        "meteor": 0.32912250081020744,
        "bertscore": {
            "precision": 0.90953,
            "recall": 0.89183,
            "f1": 0.90023
        }
    },
    "e2e_nlg_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_challenge_train_sample",
        "N": 500
    },
    "e2e_nlg_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_challenge_validation_sample",
        "N": 500
    },
    "e2e_nlg_challenge_test_scramble": {
        "predictions_file": "ByT5-small (Baseline)/e2e_nlg_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.51027,
        "msttr-100_nopunct": 0.51114,
        "total_length": 11230,
        "mean_pred_length": 22.46,
        "std_pred_length": 3.9593433799053095,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.02920747996438112,
        "vocab_size-1": 328,
        "unique-1": 117,
        "entropy-1": 6.120092260899675,
        "distinct-2": 0.11416589002795899,
        "vocab_size-2": 1225,
        "unique-2": 632,
        "entropy-2": 8.279942896901641,
        "cond_entropy-2": 2.191450371200642,
        "distinct-3": 0.2295210166177908,
        "vocab_size-3": 2348,
        "unique-3": 1382,
        "entropy-3": 9.676593071309359,
        "cond_entropy-3": 1.4799907156256156,
        "total_length-nopunct": 10536,
        "mean_pred_length-nopunct": 21.072,
        "std_pred_length-nopunct": 3.931770084834565,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.030846621108580108,
        "vocab_size-1-nopunct": 325,
        "unique-1-nopunct": 117,
        "entropy-1-nopunct": 6.130358486121692,
        "distinct-2-nopunct": 0.118772419290554,
        "vocab_size-2-nopunct": 1192,
        "unique-2-nopunct": 626,
        "entropy-2-nopunct": 8.267169396884906,
        "cond_entropy-2-nopunct": 2.2456797970098994,
        "distinct-3-nopunct": 0.2386744966442953,
        "vocab_size-3-nopunct": 2276,
        "unique-3-nopunct": 1341,
        "entropy-3-nopunct": 9.70920988755441,
        "cond_entropy-3-nopunct": 1.5147898405353708,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.6150841625592858
        },
        "nist": 4.526207446974157,
        "rouge1": {
            "precision": 0.71159,
            "recall": 0.63425,
            "fmeasure": 0.65992
        },
        "rouge2": {
            "precision": 0.40223,
            "recall": 0.3573,
            "fmeasure": 0.37211
        },
        "rougeL": {
            "precision": 0.49362,
            "recall": 0.43992,
            "fmeasure": 0.45767
        },
        "rougeLsum": {
            "precision": 0.49362,
            "recall": 0.43992,
            "fmeasure": 0.45767
        },
        "bleu": 23.88481,
        "nubia": {
            "semantic_relation": 3.96401,
            "contradiction": 4.53665,
            "irrelevancy": 23.4689,
            "logical_agreement": 71.99445,
            "grammar_ref": 4.84664,
            "grammar_hyp": 4.67315,
            "nubia_score": 0.66379
        },
        "bleurt": -0.0245,
        "meteor": 0.3129293806041812,
        "bertscore": {
            "precision": 0.90384,
            "recall": 0.88494,
            "f1": 0.89396
        }
    },
    "schema_guided_dialog_validation": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_validation",
        "N": 10000,
        "msttr-100": 0.70157,
        "msttr-100_nopunct": 0.73025,
        "total_length": 122572,
        "mean_pred_length": 12.2572,
        "std_pred_length": 6.709563932179199,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 34,
        "distinct-1": 0.035676989850863164,
        "vocab_size-1": 4373,
        "unique-1": 1860,
        "entropy-1": 8.196686901305625,
        "distinct-2": 0.1618164374800128,
        "vocab_size-2": 18216,
        "unique-2": 9869,
        "entropy-2": 11.913942682394028,
        "cond_entropy-2": 3.477844338718623,
        "distinct-3": 0.3447136241774311,
        "vocab_size-3": 35359,
        "unique-3": 23681,
        "entropy-3": 13.61370712234933,
        "cond_entropy-3": 1.7201211249877824,
        "total_length-nopunct": 107870,
        "mean_pred_length-nopunct": 10.787,
        "std_pred_length-nopunct": 6.229191841643664,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.040372670807453416,
        "vocab_size-1-nopunct": 4355,
        "unique-1-nopunct": 1857,
        "entropy-1-nopunct": 8.426886478184686,
        "distinct-2-nopunct": 0.17868601205681006,
        "vocab_size-2-nopunct": 17488,
        "unique-2-nopunct": 9937,
        "entropy-2-nopunct": 11.831506635271682,
        "cond_entropy-2-nopunct": 3.552720593155488,
        "distinct-3-nopunct": 0.3695575503145727,
        "vocab_size-3-nopunct": 32483,
        "unique-3-nopunct": 22486,
        "entropy-3-nopunct": 13.509286290323177,
        "cond_entropy-3-nopunct": 1.715851028579777,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_validation.json",
        "local_recall": {
            "1": 0.6039790907061537
        },
        "nist": 7.42056881084268,
        "rouge1": {
            "precision": 0.61262,
            "recall": 0.60214,
            "fmeasure": 0.5942
        },
        "rouge2": {
            "precision": 0.39672,
            "recall": 0.39129,
            "fmeasure": 0.38482
        },
        "rougeL": {
            "precision": 0.55276,
            "recall": 0.54403,
            "fmeasure": 0.53653
        },
        "rougeLsum": {
            "precision": 0.55276,
            "recall": 0.54403,
            "fmeasure": 0.53653
        },
        "bleu": 34.91111,
        "nubia": {
            "semantic_relation": 3.79185,
            "contradiction": 4.67367,
            "irrelevancy": 20.5759,
            "logical_agreement": 74.75043,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.78801,
            "nubia_score": 0.68184
        },
        "bleurt": -0.01554,
        "meteor": 0.3354699484212075,
        "bertscore": {
            "precision": 0.8797,
            "recall": 0.87634,
            "f1": 0.87745
        }
    },
    "common_gen_validation": {
        "predictions_file": "ByT5-small (Baseline)/common_gen_validation",
        "N": 993,
        "msttr-100": 0.61746,
        "msttr-100_nopunct": 0.64142,
        "total_length": 11475,
        "mean_pred_length": 11.555891238670695,
        "std_pred_length": 3.1837243507319983,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.13786492374727669,
        "vocab_size-1": 1582,
        "unique-1": 778,
        "entropy-1": 7.628778378088544,
        "distinct-2": 0.508967754245373,
        "vocab_size-2": 5335,
        "unique-2": 4020,
        "entropy-2": 11.387091788805563,
        "cond_entropy-2": 3.5554401618763882,
        "distinct-3": 0.7974496785751923,
        "vocab_size-3": 7567,
        "unique-3": 6698,
        "entropy-3": 12.607789614867087,
        "cond_entropy-3": 1.2766492581758342,
        "total_length-nopunct": 10684,
        "mean_pred_length-nopunct": 10.759315206445116,
        "std_pred_length-nopunct": 3.029142828968024,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.14779108947959566,
        "vocab_size-1-nopunct": 1579,
        "unique-1-nopunct": 777,
        "entropy-1-nopunct": 7.788385055985168,
        "distinct-2-nopunct": 0.5066556598906201,
        "vocab_size-2-nopunct": 4910,
        "unique-2-nopunct": 3738,
        "entropy-2-nopunct": 11.228027910317126,
        "cond_entropy-2-nopunct": 3.7270467644282563,
        "distinct-3-nopunct": 0.8005288572085537,
        "vocab_size-3-nopunct": 6963,
        "unique-3-nopunct": 6196,
        "entropy-3-nopunct": 12.48352117025594,
        "cond_entropy-3-nopunct": 1.3328677549494699,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_validation.json",
        "local_recall": {
            "1": 0.10242469691288589,
            "2": 0.29627659574468085,
            "3": 0.4903283850652272,
            "4": 0.7588721438988819,
            "5": 0.7317596566523605,
            "6": 0.7976190476190477,
            "7": 1.0,
            "8": 0.8
        },
        "nist": 5.9977309788440225,
        "rouge1": {
            "precision": 0.58398,
            "recall": 0.60463,
            "fmeasure": 0.57999
        },
        "rouge2": {
            "precision": 0.24653,
            "recall": 0.25132,
            "fmeasure": 0.24077
        },
        "rougeL": {
            "precision": 0.48024,
            "recall": 0.49544,
            "fmeasure": 0.47591
        },
        "rougeLsum": {
            "precision": 0.48024,
            "recall": 0.49544,
            "fmeasure": 0.47591
        },
        "bleu": 16.96362,
        "nubia": {
            "semantic_relation": 2.93949,
            "contradiction": 30.8948,
            "irrelevancy": 40.12263,
            "logical_agreement": 28.98257,
            "grammar_ref": 4.64808,
            "grammar_hyp": 5.16064,
            "nubia_score": 0.34601
        },
        "bleurt": -0.66888,
        "meteor": 0.2391662126776944,
        "bertscore": {
            "precision": 0.86385,
            "recall": 0.86785,
            "f1": 0.86436
        }
    },
    "common_gen_test": {
        "predictions_file": "ByT5-small (Baseline)/common_gen_test",
        "N": 1497
    },
    "common_gen_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/common_gen_challenge_train_sample",
        "N": 500
    },
    "common_gen_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/common_gen_challenge_validation_sample",
        "N": 500
    },
    "common_gen_challenge_test_scramble": {
        "predictions_file": "ByT5-small (Baseline)/common_gen_challenge_test_scramble",
        "N": 500
    },
    "mlsum_de_validation": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_de_validation",
        "N": 11392,
        "msttr-100": 0.73481,
        "msttr-100_nopunct": 0.76453,
        "total_length": 225563,
        "mean_pred_length": 19.800122893258425,
        "std_pred_length": 2.7298785031939823,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 36,
        "distinct-1": 0.13805899017126036,
        "vocab_size-1": 31141,
        "unique-1": 19145,
        "entropy-1": 10.423985138132021,
        "distinct-2": 0.5352872237604531,
        "vocab_size-2": 114643,
        "unique-2": 92677,
        "entropy-2": 15.434507224331686,
        "cond_entropy-2": 5.084225235236575,
        "distinct-3": 0.8250755748869459,
        "vocab_size-3": 167308,
        "unique-3": 152457,
        "entropy-3": 17.02949552813416,
        "cond_entropy-3": 1.657497846189133,
        "total_length-nopunct": 206249,
        "mean_pred_length-nopunct": 18.104722612359552,
        "std_pred_length-nopunct": 2.480543423216089,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.15092436811814844,
        "vocab_size-1-nopunct": 31128,
        "unique-1-nopunct": 19144,
        "entropy-1-nopunct": 10.791745194138803,
        "distinct-2-nopunct": 0.5857115731023264,
        "vocab_size-2-nopunct": 114130,
        "unique-2-nopunct": 93760,
        "entropy-2-nopunct": 15.766666119738671,
        "cond_entropy-2-nopunct": 5.141729771987666,
        "distinct-3-nopunct": 0.864884310358924,
        "vocab_size-3-nopunct": 158676,
        "unique-3-nopunct": 146930,
        "entropy-3-nopunct": 17.056317027845676,
        "cond_entropy-3-nopunct": 1.3578265750273282,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_validation.json",
        "local_recall": {
            "1": 0.3443570396532349
        },
        "nist": 5.091613824142143,
        "rouge1": {
            "precision": 0.44569,
            "recall": 0.34467,
            "fmeasure": 0.38288
        },
        "rouge2": {
            "precision": 0.33054,
            "recall": 0.2456,
            "fmeasure": 0.27806
        },
        "rougeL": {
            "precision": 0.41324,
            "recall": 0.31807,
            "fmeasure": 0.35418
        },
        "rougeLsum": {
            "precision": 0.41324,
            "recall": 0.31807,
            "fmeasure": 0.35418
        },
        "bleu": 25.15876,
        "nubia": {
            "semantic_relation": 2.41822,
            "contradiction": 26.54273,
            "irrelevancy": 39.01679,
            "logical_agreement": 34.44048,
            "grammar_ref": 5.04919,
            "grammar_hyp": 4.95872,
            "nubia_score": 0.29518
        },
        "bleurt": -0.47314,
        "meteor": 0.3005457204756146,
        "bertscore": {
            "precision": 0.8873,
            "recall": 0.86708,
            "f1": 0.87687
        }
    },
    "schema_guided_dialog_test": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_test",
        "N": 10000,
        "msttr-100": 0.69137,
        "msttr-100_nopunct": 0.71975,
        "total_length": 126084,
        "mean_pred_length": 12.6084,
        "std_pred_length": 6.666022010164683,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 33,
        "distinct-1": 0.035000475873227375,
        "vocab_size-1": 4413,
        "unique-1": 1909,
        "entropy-1": 8.148611756209183,
        "distinct-2": 0.16362289376658282,
        "vocab_size-2": 18994,
        "unique-2": 10512,
        "entropy-2": 11.922827036868552,
        "cond_entropy-2": 3.527571157381585,
        "distinct-3": 0.3493269484559406,
        "vocab_size-3": 37058,
        "unique-3": 25016,
        "entropy-3": 13.661213724351208,
        "cond_entropy-3": 1.7586198951579999,
        "total_length-nopunct": 111038,
        "mean_pred_length-nopunct": 11.1038,
        "std_pred_length-nopunct": 6.18663281276657,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.039581044327167275,
        "vocab_size-1-nopunct": 4395,
        "unique-1-nopunct": 1906,
        "entropy-1-nopunct": 8.37054189777242,
        "distinct-2-nopunct": 0.18128822819137355,
        "vocab_size-2-nopunct": 18317,
        "unique-2-nopunct": 10570,
        "entropy-2-nopunct": 11.84593412735413,
        "cond_entropy-2-nopunct": 3.623712516424097,
        "distinct-3-nopunct": 0.3756741023866794,
        "vocab_size-3-nopunct": 34204,
        "unique-3-nopunct": 23841,
        "entropy-3-nopunct": 13.56141922999989,
        "cond_entropy-3-nopunct": 1.7661717584313874,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "local_recall": {
            "1": 0.5567908146489287
        },
        "nist": 6.849198572200314,
        "rouge1": {
            "precision": 0.57188,
            "recall": 0.54656,
            "fmeasure": 0.54722
        },
        "rouge2": {
            "precision": 0.35398,
            "recall": 0.3387,
            "fmeasure": 0.33827
        },
        "rougeL": {
            "precision": 0.51446,
            "recall": 0.49182,
            "fmeasure": 0.49237
        },
        "rougeLsum": {
            "precision": 0.51446,
            "recall": 0.49182,
            "fmeasure": 0.49237
        },
        "bleu": 31.20217,
        "nubia": {
            "semantic_relation": 3.58696,
            "contradiction": 6.14964,
            "irrelevancy": 23.51643,
            "logical_agreement": 70.33393,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.70549,
            "nubia_score": 0.62748
        },
        "bleurt": -0.11029,
        "meteor": 0.30968358118274103,
        "bertscore": {
            "precision": 0.86977,
            "recall": 0.86373,
            "f1": 0.86624
        }
    },
    "schema_guided_dialog_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_challenge_train_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_challenge_validation_sample",
        "N": 500
    },
    "schema_guided_dialog_challenge_test_backtranslation": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.6871,
        "msttr-100_nopunct": 0.72167,
        "total_length": 6295,
        "mean_pred_length": 12.59,
        "std_pred_length": 6.694019719122434,
        "median_pred_length": 11.0,
        "min_pred_length": 3,
        "max_pred_length": 32,
        "distinct-1": 0.1625099285146942,
        "vocab_size-1": 1023,
        "unique-1": 581,
        "entropy-1": 7.84015763296212,
        "distinct-2": 0.5066436583261432,
        "vocab_size-2": 2936,
        "unique-2": 2062,
        "entropy-2": 10.798927382970385,
        "cond_entropy-2": 2.708218161091321,
        "distinct-3": 0.7333333333333333,
        "vocab_size-3": 3883,
        "unique-3": 3249,
        "entropy-3": 11.591343208400128,
        "cond_entropy-3": 0.8090271165893695,
        "total_length-nopunct": 5499,
        "mean_pred_length-nopunct": 10.998,
        "std_pred_length-nopunct": 6.172357410260686,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.18366975813784325,
        "vocab_size-1-nopunct": 1010,
        "unique-1-nopunct": 577,
        "entropy-1-nopunct": 8.048185934245328,
        "distinct-2-nopunct": 0.5267053410682137,
        "vocab_size-2-nopunct": 2633,
        "unique-2-nopunct": 1910,
        "entropy-2-nopunct": 10.632594715630294,
        "cond_entropy-2-nopunct": 2.7144683847069087,
        "distinct-3-nopunct": 0.7508888888888889,
        "vocab_size-3-nopunct": 3379,
        "unique-3-nopunct": 2885,
        "entropy-3-nopunct": 11.39198627578544,
        "cond_entropy-3-nopunct": 0.788278712541596,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.5402448071216617
        },
        "nist": 5.679148590367201,
        "rouge1": {
            "precision": 0.53878,
            "recall": 0.52203,
            "fmeasure": 0.51685
        },
        "rouge2": {
            "precision": 0.32033,
            "recall": 0.31121,
            "fmeasure": 0.30661
        },
        "rougeL": {
            "precision": 0.48235,
            "recall": 0.46823,
            "fmeasure": 0.46314
        },
        "rougeLsum": {
            "precision": 0.48235,
            "recall": 0.46823,
            "fmeasure": 0.46314
        },
        "bleu": 29.31869,
        "nubia": {
            "semantic_relation": 3.5172,
            "contradiction": 6.20679,
            "irrelevancy": 25.30981,
            "logical_agreement": 68.4834,
            "grammar_ref": 4.7403,
            "grammar_hyp": 4.6527,
            "nubia_score": 0.61706
        },
        "bleurt": -0.14965,
        "meteor": 0.302230813323597,
        "bertscore": {
            "precision": 0.86135,
            "recall": 0.85618,
            "f1": 0.85816
        }
    },
    "schema_guided_dialog_challenge_test_bfp02": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_challenge_test_bfp02",
        "N": 500,
        "msttr-100": 0.6919,
        "msttr-100_nopunct": 0.71018,
        "total_length": 6384,
        "mean_pred_length": 12.768,
        "std_pred_length": 6.85493807411854,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 31,
        "distinct-1": 0.16024436090225563,
        "vocab_size-1": 1023,
        "unique-1": 577,
        "entropy-1": 7.8847741166266,
        "distinct-2": 0.5011896668932699,
        "vocab_size-2": 2949,
        "unique-2": 2085,
        "entropy-2": 10.786584288152962,
        "cond_entropy-2": 2.6931191273546364,
        "distinct-3": 0.7241827637444279,
        "vocab_size-3": 3899,
        "unique-3": 3225,
        "entropy-3": 11.602867335309082,
        "cond_entropy-3": 0.8437955516359963,
        "total_length-nopunct": 5645,
        "mean_pred_length-nopunct": 11.29,
        "std_pred_length-nopunct": 6.388888792270531,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.1787422497785651,
        "vocab_size-1-nopunct": 1009,
        "unique-1-nopunct": 573,
        "entropy-1-nopunct": 8.051608955152663,
        "distinct-2-nopunct": 0.5179786200194364,
        "vocab_size-2-nopunct": 2665,
        "unique-2-nopunct": 1918,
        "entropy-2-nopunct": 10.636790390903641,
        "cond_entropy-2-nopunct": 2.7139592598371243,
        "distinct-3-nopunct": 0.7359018510546707,
        "vocab_size-3-nopunct": 3419,
        "unique-3-nopunct": 2871,
        "entropy-3-nopunct": 11.411460623217566,
        "cond_entropy-3-nopunct": 0.8184354518801962,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp02.json",
        "local_recall": {
            "1": 0.5577828133170647
        },
        "nist": 6.109474814761678,
        "rouge1": {
            "precision": 0.58266,
            "recall": 0.55376,
            "fmeasure": 0.55748
        },
        "rouge2": {
            "precision": 0.36251,
            "recall": 0.34296,
            "fmeasure": 0.34537
        },
        "rougeL": {
            "precision": 0.52308,
            "recall": 0.49631,
            "fmeasure": 0.5001
        },
        "rougeLsum": {
            "precision": 0.52308,
            "recall": 0.49631,
            "fmeasure": 0.5001
        },
        "bleu": 31.61313,
        "nubia": {
            "semantic_relation": 3.61346,
            "contradiction": 6.19486,
            "irrelevancy": 21.73351,
            "logical_agreement": 72.07163,
            "grammar_ref": 4.79054,
            "grammar_hyp": 4.76738,
            "nubia_score": 0.62967
        },
        "bleurt": -0.10926,
        "meteor": 0.3126968644468495,
        "bertscore": {
            "precision": 0.87236,
            "recall": 0.86439,
            "f1": 0.86791
        }
    },
    "schema_guided_dialog_challenge_test_bfp05": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_challenge_test_bfp05",
        "N": 500,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.72604,
        "total_length": 6076,
        "mean_pred_length": 12.152,
        "std_pred_length": 6.519884661556521,
        "median_pred_length": 10.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.16869651086240947,
        "vocab_size-1": 1025,
        "unique-1": 579,
        "entropy-1": 7.891163404987655,
        "distinct-2": 0.5222381635581061,
        "vocab_size-2": 2912,
        "unique-2": 2096,
        "entropy-2": 10.788902122607036,
        "cond_entropy-2": 2.647250045453679,
        "distinct-3": 0.7427107959022853,
        "vocab_size-3": 3770,
        "unique-3": 3199,
        "entropy-3": 11.55027207065136,
        "cond_entropy-3": 0.782089138914399,
        "total_length-nopunct": 5339,
        "mean_pred_length-nopunct": 10.678,
        "std_pred_length-nopunct": 6.029454038302307,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.18973590560029968,
        "vocab_size-1-nopunct": 1013,
        "unique-1-nopunct": 576,
        "entropy-1-nopunct": 8.087767024246766,
        "distinct-2-nopunct": 0.5344079355238686,
        "vocab_size-2-nopunct": 2586,
        "unique-2-nopunct": 1906,
        "entropy-2-nopunct": 10.598480113310186,
        "cond_entropy-2-nopunct": 2.6449942171403986,
        "distinct-3-nopunct": 0.7517861258354459,
        "vocab_size-3-nopunct": 3262,
        "unique-3-nopunct": 2810,
        "entropy-3-nopunct": 11.334242945193182,
        "cond_entropy-3-nopunct": 0.7615636769865587,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_bfp05.json",
        "local_recall": {
            "1": 0.543788933675339
        },
        "nist": 5.913688866469197,
        "rouge1": {
            "precision": 0.55997,
            "recall": 0.5307,
            "fmeasure": 0.53396
        },
        "rouge2": {
            "precision": 0.34344,
            "recall": 0.32271,
            "fmeasure": 0.32608
        },
        "rougeL": {
            "precision": 0.50273,
            "recall": 0.47531,
            "fmeasure": 0.47877
        },
        "rougeLsum": {
            "precision": 0.50273,
            "recall": 0.47531,
            "fmeasure": 0.47877
        },
        "bleu": 31.02045,
        "nubia": {
            "semantic_relation": 3.51906,
            "contradiction": 6.98357,
            "irrelevancy": 23.85159,
            "logical_agreement": 69.16484,
            "grammar_ref": 4.77092,
            "grammar_hyp": 4.77317,
            "nubia_score": 0.60231
        },
        "bleurt": -0.15192,
        "meteor": 0.30421277153227233,
        "bertscore": {
            "precision": 0.86541,
            "recall": 0.85928,
            "f1": 0.86191
        }
    },
    "schema_guided_dialog_challenge_test_nopunc": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.719,
        "msttr-100_nopunct": 0.72927,
        "total_length": 6082,
        "mean_pred_length": 12.164,
        "std_pred_length": 6.587040610167817,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 30,
        "distinct-1": 0.17625780993094378,
        "vocab_size-1": 1072,
        "unique-1": 599,
        "entropy-1": 8.073676874508728,
        "distinct-2": 0.5249014690075242,
        "vocab_size-2": 2930,
        "unique-2": 2107,
        "entropy-2": 10.815980082748517,
        "cond_entropy-2": 2.70050564111368,
        "distinct-3": 0.7473435655253837,
        "vocab_size-3": 3798,
        "unique-3": 3210,
        "entropy-3": 11.585109381615531,
        "cond_entropy-3": 0.8075779736663568,
        "total_length-nopunct": 5502,
        "mean_pred_length-nopunct": 11.004,
        "std_pred_length-nopunct": 6.058711414154002,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.19229371137768084,
        "vocab_size-1-nopunct": 1058,
        "unique-1-nopunct": 596,
        "entropy-1-nopunct": 8.170956366193654,
        "distinct-2-nopunct": 0.5417832866853258,
        "vocab_size-2-nopunct": 2710,
        "unique-2-nopunct": 2001,
        "entropy-2-nopunct": 10.691384809918064,
        "cond_entropy-2-nopunct": 2.651560021222217,
        "distinct-3-nopunct": 0.7625499777876499,
        "vocab_size-3-nopunct": 3433,
        "unique-3-nopunct": 2949,
        "entropy-3-nopunct": 11.447324476500551,
        "cond_entropy-3-nopunct": 0.7910340269736951,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.5203761755485894
        },
        "nist": 5.56164145352326,
        "rouge1": {
            "precision": 0.57029,
            "recall": 0.50015,
            "fmeasure": 0.52042
        },
        "rouge2": {
            "precision": 0.3427,
            "recall": 0.29653,
            "fmeasure": 0.30944
        },
        "rougeL": {
            "precision": 0.50357,
            "recall": 0.44216,
            "fmeasure": 0.45996
        },
        "rougeLsum": {
            "precision": 0.50357,
            "recall": 0.44216,
            "fmeasure": 0.45996
        },
        "bleu": 27.15694,
        "nubia": {
            "semantic_relation": 3.55652,
            "contradiction": 6.31833,
            "irrelevancy": 19.92999,
            "logical_agreement": 73.75168,
            "grammar_ref": 4.79983,
            "grammar_hyp": 5.02033,
            "nubia_score": 0.59102
        },
        "bleurt": -0.17584,
        "meteor": 0.28971367859993746,
        "bertscore": {
            "precision": 0.86359,
            "recall": 0.84379,
            "f1": 0.8531
        }
    },
    "schema_guided_dialog_challenge_test_scramble": {
        "predictions_file": "ByT5-small (Baseline)/schema_guided_dialog_challenge_test_scramble",
        "N": 500,
        "msttr-100": 0.68516,
        "msttr-100_nopunct": 0.71035,
        "total_length": 6470,
        "mean_pred_length": 12.94,
        "std_pred_length": 6.701671433306768,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 32,
        "distinct-1": 0.15857805255023183,
        "vocab_size-1": 1026,
        "unique-1": 566,
        "entropy-1": 7.847125489058373,
        "distinct-2": 0.5063651591289782,
        "vocab_size-2": 3023,
        "unique-2": 2168,
        "entropy-2": 10.827209758606548,
        "cond_entropy-2": 2.763565999414288,
        "distinct-3": 0.7387568555758683,
        "vocab_size-3": 4041,
        "unique-3": 3400,
        "entropy-3": 11.660426500156746,
        "cond_entropy-3": 0.8600967475197074,
        "total_length-nopunct": 5708,
        "mean_pred_length-nopunct": 11.416,
        "std_pred_length-nopunct": 6.216666630920465,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.17782060266292923,
        "vocab_size-1-nopunct": 1015,
        "unique-1-nopunct": 564,
        "entropy-1-nopunct": 8.02761876965497,
        "distinct-2-nopunct": 0.5232334869431644,
        "vocab_size-2-nopunct": 2725,
        "unique-2-nopunct": 1997,
        "entropy-2-nopunct": 10.676609899671607,
        "cond_entropy-2-nopunct": 2.7827333283507425,
        "distinct-3-nopunct": 0.7500530898279889,
        "vocab_size-3-nopunct": 3532,
        "unique-3-nopunct": 3011,
        "entropy-3-nopunct": 11.465417901514344,
        "cond_entropy-3-nopunct": 0.8359057263223434,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_challenge_test_scramble.json",
        "local_recall": {
            "1": 0.5429358113921873
        },
        "nist": 5.876916553993763,
        "rouge1": {
            "precision": 0.56552,
            "recall": 0.53462,
            "fmeasure": 0.53864
        },
        "rouge2": {
            "precision": 0.34086,
            "recall": 0.3219,
            "fmeasure": 0.32388
        },
        "rougeL": {
            "precision": 0.49891,
            "recall": 0.47172,
            "fmeasure": 0.47533
        },
        "rougeLsum": {
            "precision": 0.49891,
            "recall": 0.47172,
            "fmeasure": 0.47533
        },
        "bleu": 28.91791,
        "nubia": {
            "semantic_relation": 3.51872,
            "contradiction": 7.54961,
            "irrelevancy": 23.09211,
            "logical_agreement": 69.35828,
            "grammar_ref": 4.7801,
            "grammar_hyp": 4.75585,
            "nubia_score": 0.60258
        },
        "bleurt": -0.15889,
        "meteor": 0.2966526497394671,
        "bertscore": {
            "precision": 0.86584,
            "recall": 0.85893,
            "f1": 0.86188
        }
    },
    "xsum_validation": {
        "predictions_file": "ByT5-small (Baseline)/xsum_validation",
        "N": 1117,
        "msttr-100": 0.71962,
        "msttr-100_nopunct": 0.72809,
        "total_length": 23725,
        "mean_pred_length": 21.239928379588182,
        "std_pred_length": 3.664255368773189,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.1951949420442571,
        "vocab_size-1": 4631,
        "unique-1": 2660,
        "entropy-1": 9.302910659275918,
        "distinct-2": 0.6390215852795471,
        "vocab_size-2": 14447,
        "unique-2": 11889,
        "entropy-2": 13.085232738981253,
        "cond_entropy-2": 3.6882596352441706,
        "distinct-3": 0.8804615885719603,
        "vocab_size-3": 18922,
        "unique-3": 17634,
        "entropy-3": 14.051321619510842,
        "cond_entropy-3": 0.988989319010626,
        "total_length-nopunct": 22517,
        "mean_pred_length-nopunct": 20.158460161145925,
        "std_pred_length-nopunct": 3.7522840017264825,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.20517830972154372,
        "vocab_size-1-nopunct": 4620,
        "unique-1-nopunct": 2660,
        "entropy-1-nopunct": 9.407951718078678,
        "distinct-2-nopunct": 0.6462149532710281,
        "vocab_size-2-nopunct": 13829,
        "unique-2-nopunct": 11444,
        "entropy-2-nopunct": 13.029315372637639,
        "cond_entropy-2-nopunct": 3.7461458798627763,
        "distinct-3-nopunct": 0.8871468717645319,
        "vocab_size-3-nopunct": 17994,
        "unique-3-nopunct": 16815,
        "entropy-3-nopunct": 13.993776022095156,
        "cond_entropy-3-nopunct": 0.9908084951680598,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_validation.json",
        "local_recall": {
            "1": 0.31464582580412
        },
        "nist": 3.252294427721193,
        "rouge1": {
            "precision": 0.35207,
            "recall": 0.3381,
            "fmeasure": 0.33901
        },
        "rouge2": {
            "precision": 0.11916,
            "recall": 0.1144,
            "fmeasure": 0.11469
        },
        "rougeL": {
            "precision": 0.27099,
            "recall": 0.26111,
            "fmeasure": 0.26132
        },
        "rougeLsum": {
            "precision": 0.27099,
            "recall": 0.26111,
            "fmeasure": 0.26132
        },
        "bleu": 7.4303,
        "nubia": {
            "semantic_relation": 2.45538,
            "contradiction": 30.47114,
            "irrelevancy": 59.56795,
            "logical_agreement": 9.96091,
            "grammar_ref": 3.8151,
            "grammar_hyp": 4.34963,
            "nubia_score": 0.28307
        },
        "bleurt": -0.55811,
        "meteor": 0.145671613809317,
        "bertscore": {
            "precision": 0.81477,
            "recall": 0.80526,
            "f1": 0.80973
        }
    },
    "xsum_test": {
        "predictions_file": "ByT5-small (Baseline)/xsum_test",
        "N": 1166,
        "msttr-100": 0.72267,
        "msttr-100_nopunct": 0.73119,
        "total_length": 24762,
        "mean_pred_length": 21.236706689536877,
        "std_pred_length": 3.55725877773028,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.19505694208868427,
        "vocab_size-1": 4830,
        "unique-1": 2797,
        "entropy-1": 9.33729788031049,
        "distinct-2": 0.641549415155111,
        "vocab_size-2": 15138,
        "unique-2": 12499,
        "entropy-2": 13.133071289125148,
        "cond_entropy-2": 3.7015287689972594,
        "distinct-3": 0.8818546589389211,
        "vocab_size-3": 19780,
        "unique-3": 18447,
        "entropy-3": 14.112814750086917,
        "cond_entropy-3": 1.00594030464397,
        "total_length-nopunct": 23522,
        "mean_pred_length-nopunct": 20.173241852487134,
        "std_pred_length-nopunct": 3.675868778162375,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.20491454808264603,
        "vocab_size-1-nopunct": 4820,
        "unique-1-nopunct": 2797,
        "entropy-1-nopunct": 9.443658058563464,
        "distinct-2-nopunct": 0.6485954553587404,
        "vocab_size-2-nopunct": 14500,
        "unique-2-nopunct": 12045,
        "entropy-2-nopunct": 13.080529202585655,
        "cond_entropy-2-nopunct": 3.760191882293372,
        "distinct-3-nopunct": 0.8882019820670127,
        "vocab_size-3-nopunct": 18821,
        "unique-3-nopunct": 17616,
        "entropy-3-nopunct": 14.054906158691633,
        "cond_entropy-3-nopunct": 1.0038338202360857,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "local_recall": {
            "1": 0.3098134630981346
        },
        "nist": 3.223658900130153,
        "rouge1": {
            "precision": 0.35166,
            "recall": 0.33858,
            "fmeasure": 0.33936
        },
        "rouge2": {
            "precision": 0.12134,
            "recall": 0.1178,
            "fmeasure": 0.11738
        },
        "rougeL": {
            "precision": 0.27062,
            "recall": 0.26175,
            "fmeasure": 0.26162
        },
        "rougeLsum": {
            "precision": 0.27062,
            "recall": 0.26175,
            "fmeasure": 0.26162
        },
        "bleu": 7.43828,
        "nubia": {
            "semantic_relation": 2.3946,
            "contradiction": 31.77751,
            "irrelevancy": 58.74274,
            "logical_agreement": 9.47975,
            "grammar_ref": 3.76542,
            "grammar_hyp": 4.32106,
            "nubia_score": 0.27643
        },
        "bleurt": -0.58295,
        "meteor": 0.14264502574881024,
        "bertscore": {
            "precision": 0.81305,
            "recall": 0.8036,
            "f1": 0.80803
        }
    },
    "xsum_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/xsum_challenge_train_sample",
        "N": 500
    },
    "xsum_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/xsum_challenge_validation_sample",
        "N": 500
    },
    "totto_validation": {
        "predictions_file": "ByT5-small (Baseline)/totto_validation",
        "N": 7700,
        "msttr-100": 0.72524,
        "msttr-100_nopunct": 0.77658,
        "total_length": 125354,
        "mean_pred_length": 16.279740259740258,
        "std_pred_length": 5.421643009231425,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 39,
        "distinct-1": 0.17198493865373263,
        "vocab_size-1": 21559,
        "unique-1": 14710,
        "entropy-1": 10.078640580924823,
        "distinct-2": 0.5536743332143403,
        "vocab_size-2": 65142,
        "unique-2": 54610,
        "entropy-2": 14.650506642812237,
        "cond_entropy-2": 4.244573298018255,
        "distinct-3": 0.7929952525601616,
        "vocab_size-3": 87193,
        "unique-3": 79818,
        "entropy-3": 15.953810839449325,
        "cond_entropy-3": 1.303033254914926,
        "total_length-nopunct": 109549,
        "mean_pred_length-nopunct": 14.227142857142857,
        "std_pred_length-nopunct": 4.842851568781989,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.19661521328355347,
        "vocab_size-1-nopunct": 21539,
        "unique-1-nopunct": 14707,
        "entropy-1-nopunct": 10.616477592553855,
        "distinct-2-nopunct": 0.5983563903425659,
        "vocab_size-2-nopunct": 60942,
        "unique-2-nopunct": 52205,
        "entropy-2-nopunct": 14.654961230832775,
        "cond_entropy-2-nopunct": 4.221454347887475,
        "distinct-3-nopunct": 0.8197750374406526,
        "vocab_size-3-nopunct": 77181,
        "unique-3-nopunct": 71598,
        "entropy-3-nopunct": 15.832808718163575,
        "cond_entropy-3-nopunct": 1.2545476265305266,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_validation.json",
        "local_recall": {
            "1": 0.22296132052229614,
            "2": 0.45844295880957514,
            "3": 0.7604094878895336
        },
        "nist": 10.645717601696507,
        "rouge1": {
            "precision": 0.74474,
            "recall": 0.72717,
            "fmeasure": 0.72466
        },
        "rouge2": {
            "precision": 0.5215,
            "recall": 0.51165,
            "fmeasure": 0.50846
        },
        "rougeL": {
            "precision": 0.64867,
            "recall": 0.63656,
            "fmeasure": 0.63257
        },
        "rougeLsum": {
            "precision": 0.64867,
            "recall": 0.63656,
            "fmeasure": 0.63257
        },
        "bleu": 45.83064,
        "nubia": {
            "semantic_relation": 4.14045,
            "contradiction": 9.16163,
            "irrelevancy": 30.4527,
            "logical_agreement": 60.38567,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.68421,
            "nubia_score": 0.7102
        },
        "bleurt": 0.23941,
        "meteor": 0.3868153726280523,
        "bertscore": {
            "precision": 0.92581,
            "recall": 0.92305,
            "f1": 0.92282
        }
    },
    "xsum_challenge_test_backtranslation": {
        "predictions_file": "ByT5-small (Baseline)/xsum_challenge_test_backtranslation",
        "N": 500,
        "msttr-100": 0.72123,
        "msttr-100_nopunct": 0.7282,
        "total_length": 10644,
        "mean_pred_length": 21.288,
        "std_pred_length": 3.5694615840487764,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.2624953025178504,
        "vocab_size-1": 2794,
        "unique-1": 1731,
        "entropy-1": 9.016924550702416,
        "distinct-2": 0.7160883280757098,
        "vocab_size-2": 7264,
        "unique-2": 6240,
        "entropy-2": 12.291306237787161,
        "cond_entropy-2": 3.201737314092521,
        "distinct-3": 0.9170468685192866,
        "vocab_size-3": 8844,
        "unique-3": 8401,
        "entropy-3": 13.007754811433406,
        "cond_entropy-3": 0.7418135908591942,
        "total_length-nopunct": 10080,
        "mean_pred_length-nopunct": 20.16,
        "std_pred_length-nopunct": 3.665296713773661,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.27609126984126986,
        "vocab_size-1-nopunct": 2783,
        "unique-1-nopunct": 1730,
        "entropy-1-nopunct": 9.099890361475918,
        "distinct-2-nopunct": 0.7220250521920668,
        "vocab_size-2-nopunct": 6917,
        "unique-2-nopunct": 5979,
        "entropy-2-nopunct": 12.22300430454163,
        "cond_entropy-2-nopunct": 3.2362994546409802,
        "distinct-3-nopunct": 0.9220264317180616,
        "vocab_size-3-nopunct": 8372,
        "unique-3-nopunct": 7968,
        "entropy-3-nopunct": 12.941288282540343,
        "cond_entropy-3-nopunct": 0.742766063756495,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_backtranslation.json",
        "local_recall": {
            "1": 0.2670575154149399
        },
        "nist": 2.478575972311937,
        "rouge1": {
            "precision": 0.30785,
            "recall": 0.29586,
            "fmeasure": 0.2964
        },
        "rouge2": {
            "precision": 0.08054,
            "recall": 0.07909,
            "fmeasure": 0.07835
        },
        "rougeL": {
            "precision": 0.2327,
            "recall": 0.22487,
            "fmeasure": 0.22443
        },
        "rougeLsum": {
            "precision": 0.2327,
            "recall": 0.22487,
            "fmeasure": 0.22443
        },
        "bleu": 4.33896,
        "nubia": {
            "semantic_relation": 2.0188,
            "contradiction": 33.20366,
            "irrelevancy": 61.47215,
            "logical_agreement": 5.32419,
            "grammar_ref": 3.78538,
            "grammar_hyp": 4.52607,
            "nubia_score": 0.20517
        },
        "bleurt": -0.69158,
        "meteor": 0.12064610529777137,
        "bertscore": {
            "precision": 0.79449,
            "recall": 0.78937,
            "f1": 0.79167
        }
    },
    "xsum_challenge_test_bfp_02": {
        "predictions_file": "ByT5-small (Baseline)/xsum_challenge_test_bfp_02",
        "N": 500,
        "msttr-100": 0.7228,
        "msttr-100_nopunct": 0.73137,
        "total_length": 10776,
        "mean_pred_length": 21.552,
        "std_pred_length": 3.208628367386912,
        "median_pred_length": 22.0,
        "min_pred_length": 11,
        "max_pred_length": 29,
        "distinct-1": 0.2762620638455828,
        "vocab_size-1": 2977,
        "unique-1": 1952,
        "entropy-1": 9.103685494694599,
        "distinct-2": 0.721292331646555,
        "vocab_size-2": 7412,
        "unique-2": 6422,
        "entropy-2": 12.318122131156192,
        "cond_entropy-2": 3.149201591856792,
        "distinct-3": 0.9193944353518821,
        "vocab_size-3": 8988,
        "unique-3": 8555,
        "entropy-3": 13.034507978097912,
        "cond_entropy-3": 0.7453496257562847,
        "total_length-nopunct": 10285,
        "mean_pred_length-nopunct": 20.57,
        "std_pred_length-nopunct": 3.342020347035607,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.2883811375789985,
        "vocab_size-1-nopunct": 2966,
        "unique-1-nopunct": 1950,
        "entropy-1-nopunct": 9.181319904465813,
        "distinct-2-nopunct": 0.7253960143076137,
        "vocab_size-2-nopunct": 7098,
        "unique-2-nopunct": 6174,
        "entropy-2-nopunct": 12.255569437635451,
        "cond_entropy-2-nopunct": 3.194446941596801,
        "distinct-3-nopunct": 0.9220247711362413,
        "vocab_size-3-nopunct": 8561,
        "unique-3-nopunct": 8158,
        "entropy-3-nopunct": 12.972053624192553,
        "cond_entropy-3-nopunct": 0.7466310129003976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_02.json",
        "local_recall": {
            "1": 0.2931854199683043
        },
        "nist": 2.7873886793082776,
        "rouge1": {
            "precision": 0.3291,
            "recall": 0.32075,
            "fmeasure": 0.31968
        },
        "rouge2": {
            "precision": 0.09871,
            "recall": 0.09691,
            "fmeasure": 0.09589
        },
        "rougeL": {
            "precision": 0.24727,
            "recall": 0.2432,
            "fmeasure": 0.24112
        },
        "rougeLsum": {
            "precision": 0.24727,
            "recall": 0.2432,
            "fmeasure": 0.24112
        },
        "bleu": 5.77608,
        "nubia": {
            "semantic_relation": 2.25295,
            "contradiction": 31.91855,
            "irrelevancy": 60.32913,
            "logical_agreement": 7.75232,
            "grammar_ref": 3.74155,
            "grammar_hyp": 4.65142,
            "nubia_score": 0.23273
        },
        "bleurt": -0.72155,
        "meteor": 0.13211319338293068,
        "bertscore": {
            "precision": 0.8005,
            "recall": 0.79684,
            "f1": 0.79838
        }
    },
    "xsum_challenge_test_bfp_05": {
        "predictions_file": "ByT5-small (Baseline)/xsum_challenge_test_bfp_05",
        "N": 500,
        "msttr-100": 0.72607,
        "msttr-100_nopunct": 0.73294,
        "total_length": 10747,
        "mean_pred_length": 21.494,
        "std_pred_length": 3.5707091732595644,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.2864985577370429,
        "vocab_size-1": 3079,
        "unique-1": 2047,
        "entropy-1": 9.172888855497359,
        "distinct-2": 0.7352395823167757,
        "vocab_size-2": 7534,
        "unique-2": 6584,
        "entropy-2": 12.369398091861415,
        "cond_entropy-2": 3.126286677199991,
        "distinct-3": 0.9243869908689853,
        "vocab_size-3": 9010,
        "unique-3": 8608,
        "entropy-3": 13.04373345250106,
        "cond_entropy-3": 0.7035058794921448,
        "total_length-nopunct": 10273,
        "mean_pred_length-nopunct": 20.546,
        "std_pred_length-nopunct": 3.7223492581970326,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.29864693857685193,
        "vocab_size-1-nopunct": 3068,
        "unique-1-nopunct": 2046,
        "entropy-1-nopunct": 9.244510970788793,
        "distinct-2-nopunct": 0.7372352399467922,
        "vocab_size-2-nopunct": 7205,
        "unique-2-nopunct": 6310,
        "entropy-2-nopunct": 12.303601174458242,
        "cond_entropy-2-nopunct": 3.183832273625681,
        "distinct-3-nopunct": 0.9269923433624502,
        "vocab_size-3-nopunct": 8596,
        "unique-3-nopunct": 8222,
        "entropy-3-nopunct": 12.981622821643237,
        "cond_entropy-3-nopunct": 0.7071425185530661,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_bfp_05.json",
        "local_recall": {
            "1": 0.2899243329350856
        },
        "nist": 2.7837929209193164,
        "rouge1": {
            "precision": 0.32012,
            "recall": 0.31492,
            "fmeasure": 0.31237
        },
        "rouge2": {
            "precision": 0.09442,
            "recall": 0.09449,
            "fmeasure": 0.09272
        },
        "rougeL": {
            "precision": 0.24565,
            "recall": 0.24269,
            "fmeasure": 0.24003
        },
        "rougeLsum": {
            "precision": 0.24565,
            "recall": 0.24269,
            "fmeasure": 0.24003
        },
        "bleu": 5.65006,
        "nubia": {
            "semantic_relation": 2.2061,
            "contradiction": 37.04799,
            "irrelevancy": 54.63475,
            "logical_agreement": 8.31726,
            "grammar_ref": 3.79385,
            "grammar_hyp": 4.89716,
            "nubia_score": 0.22118
        },
        "bleurt": -0.79083,
        "meteor": 0.12820421951466737,
        "bertscore": {
            "precision": 0.79539,
            "recall": 0.79457,
            "f1": 0.7947
        }
    },
    "xsum_challenge_test_nopunc": {
        "predictions_file": "ByT5-small (Baseline)/xsum_challenge_test_nopunc",
        "N": 500,
        "msttr-100": 0.72755,
        "msttr-100_nopunct": 0.73436,
        "total_length": 10681,
        "mean_pred_length": 21.362,
        "std_pred_length": 3.522918676325072,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.26589270667540493,
        "vocab_size-1": 2840,
        "unique-1": 1748,
        "entropy-1": 9.114870456992003,
        "distinct-2": 0.7260583439740693,
        "vocab_size-2": 7392,
        "unique-2": 6343,
        "entropy-2": 12.362730525259956,
        "cond_entropy-2": 3.1709682606300262,
        "distinct-3": 0.9239747959921496,
        "vocab_size-3": 8945,
        "unique-3": 8510,
        "entropy-3": 13.042298893233859,
        "cond_entropy-3": 0.7012225531292662,
        "total_length-nopunct": 10171,
        "mean_pred_length-nopunct": 20.342,
        "std_pred_length-nopunct": 3.6612888441094076,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.2782420607609871,
        "vocab_size-1-nopunct": 2830,
        "unique-1-nopunct": 1745,
        "entropy-1-nopunct": 9.206036327345098,
        "distinct-2-nopunct": 0.7315686071760935,
        "vocab_size-2-nopunct": 7075,
        "unique-2-nopunct": 6092,
        "entropy-2-nopunct": 12.307216322667404,
        "cond_entropy-2-nopunct": 3.2151383729053777,
        "distinct-3-nopunct": 0.927488823465271,
        "vocab_size-3-nopunct": 8506,
        "unique-3-nopunct": 8104,
        "entropy-3-nopunct": 12.977799710867638,
        "cond_entropy-3-nopunct": 0.693175589430554,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_nopunc.json",
        "local_recall": {
            "1": 0.3150863800723182
        },
        "nist": 3.147613695804975,
        "rouge1": {
            "precision": 0.35082,
            "recall": 0.34226,
            "fmeasure": 0.34115
        },
        "rouge2": {
            "precision": 0.12423,
            "recall": 0.12055,
            "fmeasure": 0.12035
        },
        "rougeL": {
            "precision": 0.27009,
            "recall": 0.26439,
            "fmeasure": 0.26297
        },
        "rougeLsum": {
            "precision": 0.27009,
            "recall": 0.26439,
            "fmeasure": 0.26297
        },
        "bleu": 7.97306,
        "nubia": {
            "semantic_relation": 2.39675,
            "contradiction": 33.07009,
            "irrelevancy": 58.3073,
            "logical_agreement": 8.6226,
            "grammar_ref": 3.78318,
            "grammar_hyp": 4.3628,
            "nubia_score": 0.27462
        },
        "bleurt": -0.60588,
        "meteor": 0.14398262858088498,
        "bertscore": {
            "precision": 0.81242,
            "recall": 0.80449,
            "f1": 0.80818
        }
    },
    "xsum_challenge_test_covid": {
        "predictions_file": "ByT5-small (Baseline)/xsum_challenge_test_covid",
        "N": 401,
        "msttr-100": 0.70506,
        "msttr-100_nopunct": 0.71639,
        "total_length": 8799,
        "mean_pred_length": 21.942643391521198,
        "std_pred_length": 3.342345555218109,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.21695647232640072,
        "vocab_size-1": 1909,
        "unique-1": 1144,
        "entropy-1": 8.53975952356419,
        "distinct-2": 0.6451536080019052,
        "vocab_size-2": 5418,
        "unique-2": 4441,
        "entropy-2": 11.777955046277027,
        "cond_entropy-2": 3.2105802817958717,
        "distinct-3": 0.8758284356633738,
        "vocab_size-3": 7004,
        "unique-3": 6490,
        "entropy-3": 12.621470199642385,
        "cond_entropy-3": 0.8675943526239747,
        "total_length-nopunct": 8337,
        "mean_pred_length-nopunct": 20.790523690773068,
        "std_pred_length-nopunct": 3.4829130432577706,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.22801967134460838,
        "vocab_size-1-nopunct": 1901,
        "unique-1-nopunct": 1143,
        "entropy-1-nopunct": 8.605991809191234,
        "distinct-2-nopunct": 0.6586441532258065,
        "vocab_size-2-nopunct": 5227,
        "unique-2-nopunct": 4334,
        "entropy-2-nopunct": 11.738193058534376,
        "cond_entropy-2-nopunct": 3.22283479232723,
        "distinct-3-nopunct": 0.8859986728599867,
        "vocab_size-3-nopunct": 6676,
        "unique-3-nopunct": 6233,
        "entropy-3-nopunct": 12.563122786195093,
        "cond_entropy-3-nopunct": 0.8408388079772905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_challenge_test_covid.json",
        "local_recall": {
            "1": 0.24843825084094184
        },
        "nist": 2.204467604688442,
        "rouge1": {
            "precision": 0.28144,
            "recall": 0.26791,
            "fmeasure": 0.26905
        },
        "rouge2": {
            "precision": 0.07925,
            "recall": 0.07562,
            "fmeasure": 0.0758
        },
        "rougeL": {
            "precision": 0.21499,
            "recall": 0.2058,
            "fmeasure": 0.20588
        },
        "rougeLsum": {
            "precision": 0.21499,
            "recall": 0.2058,
            "fmeasure": 0.20588
        },
        "bleu": 4.52931,
        "nubia": {
            "semantic_relation": 1.92103,
            "contradiction": 28.16495,
            "irrelevancy": 65.31767,
            "logical_agreement": 6.51738,
            "grammar_ref": 4.04957,
            "grammar_hyp": 4.70754,
            "nubia_score": 0.18969
        },
        "bleurt": -0.77198,
        "meteor": 0.11290834881103042,
        "bertscore": {
            "precision": 0.78353,
            "recall": 0.77402,
            "f1": 0.77846
        }
    },
    "totto_test": {
        "predictions_file": "ByT5-small (Baseline)/totto_test",
        "N": 7700,
        "msttr-100": 0.7242,
        "msttr-100_nopunct": 0.7764,
        "total_length": 124967,
        "mean_pred_length": 16.229480519480518,
        "std_pred_length": 5.462261411735985,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 38,
        "distinct-1": 0.17211743900389703,
        "vocab_size-1": 21509,
        "unique-1": 14815,
        "entropy-1": 10.0635650873593,
        "distinct-2": 0.5541627226756035,
        "vocab_size-2": 64985,
        "unique-2": 54466,
        "entropy-2": 14.649653688868723,
        "cond_entropy-2": 4.256207282253366,
        "distinct-3": 0.7924831381711647,
        "vocab_size-3": 86830,
        "unique-3": 79373,
        "entropy-3": 15.953165078348047,
        "cond_entropy-3": 1.3001251224342667,
        "total_length-nopunct": 109178,
        "mean_pred_length-nopunct": 14.178961038961038,
        "std_pred_length-nopunct": 4.895205601565569,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.1968436864569785,
        "vocab_size-1-nopunct": 21491,
        "unique-1-nopunct": 14815,
        "entropy-1-nopunct": 10.604636892285436,
        "distinct-2-nopunct": 0.5973708587082914,
        "vocab_size-2-nopunct": 60620,
        "unique-2-nopunct": 51864,
        "entropy-2-nopunct": 14.649309895655257,
        "cond_entropy-2-nopunct": 4.229434171665665,
        "distinct-3-nopunct": 0.8185608564908614,
        "vocab_size-3-nopunct": 76763,
        "unique-3-nopunct": 71016,
        "entropy-3-nopunct": 15.831004218331815,
        "cond_entropy-3-nopunct": 1.2579654985487216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "local_recall": {
            "1": 0.22631642952693665,
            "2": 0.46336375488917864,
            "3": 0.7615351769522518
        },
        "nist": 10.64780336925338,
        "rouge1": {
            "precision": 0.749,
            "recall": 0.72819,
            "fmeasure": 0.72711
        },
        "rouge2": {
            "precision": 0.52354,
            "recall": 0.51123,
            "fmeasure": 0.50887
        },
        "rougeL": {
            "precision": 0.65128,
            "recall": 0.63723,
            "fmeasure": 0.63399
        },
        "rougeLsum": {
            "precision": 0.65128,
            "recall": 0.63723,
            "fmeasure": 0.63399
        },
        "bleu": 45.67402,
        "nubia": {
            "semantic_relation": 4.1511,
            "contradiction": 9.18873,
            "irrelevancy": 30.20167,
            "logical_agreement": 60.6096,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.69411,
            "nubia_score": 0.71169
        },
        "bleurt": 0.24814,
        "meteor": 0.38670358227886614,
        "bertscore": {
            "precision": 0.92707,
            "recall": 0.92376,
            "f1": 0.92376
        }
    },
    "totto_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/totto_challenge_train_sample",
        "N": 500
    },
    "totto_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/totto_challenge_validation_sample",
        "N": 500
    },
    "totto_challenge_test_scramble": {
        "predictions_file": "ByT5-small (Baseline)/totto_challenge_test_scramble",
        "N": 378
    },
    "web_nlg_ru_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 500,
        "msttr-100": 0.67582,
        "msttr-100_nopunct": 0.7283,
        "total_length": 5589,
        "mean_pred_length": 11.178,
        "std_pred_length": 3.0043827985128657,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.2986222937913759,
        "vocab_size-1": 1669,
        "unique-1": 988,
        "entropy-1": 8.91145261432965,
        "distinct-2": 0.6187856160345844,
        "vocab_size-2": 3149,
        "unique-2": 2338,
        "entropy-2": 11.175091464480246,
        "cond_entropy-2": 2.279799719222669,
        "distinct-3": 0.7999564175201569,
        "vocab_size-3": 3671,
        "unique-3": 3088,
        "entropy-3": 11.687009147423748,
        "cond_entropy-3": 0.5880869655125609,
        "total_length-nopunct": 4740,
        "mean_pred_length-nopunct": 9.48,
        "std_pred_length-nopunct": 2.6430285658690864,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.35063291139240504,
        "vocab_size-1-nopunct": 1662,
        "unique-1-nopunct": 988,
        "entropy-1-nopunct": 9.428357341992708,
        "distinct-2-nopunct": 0.6620283018867924,
        "vocab_size-2-nopunct": 2807,
        "unique-2-nopunct": 2176,
        "entropy-2-nopunct": 11.069325367976635,
        "cond_entropy-2-nopunct": 1.8277488373182667,
        "distinct-3-nopunct": 0.81951871657754,
        "vocab_size-3-nopunct": 3065,
        "unique-3-nopunct": 2637,
        "entropy-3-nopunct": 11.437785859032289,
        "cond_entropy-3-nopunct": 0.45702717943786675,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.17829204693611472,
            "2": 0.3481818181818182,
            "3": 0.4885883347421809,
            "4": 0.6444444444444445,
            "5": 0.4,
            "6": 1.0
        },
        "nist": 1.6028834483815446,
        "rouge1": {
            "precision": 0.26065,
            "recall": 0.21531,
            "fmeasure": 0.2275
        },
        "rouge2": {
            "precision": 0.12611,
            "recall": 0.09849,
            "fmeasure": 0.10441
        },
        "rougeL": {
            "precision": 0.25553,
            "recall": 0.2113,
            "fmeasure": 0.22304
        },
        "rougeLsum": {
            "precision": 0.25553,
            "recall": 0.2113,
            "fmeasure": 0.22304
        },
        "bleu": 22.14571,
        "nubia": {
            "semantic_relation": 3.60226,
            "contradiction": 21.78134,
            "irrelevancy": 22.55205,
            "logical_agreement": 55.66661,
            "grammar_ref": 2.66667,
            "grammar_hyp": 2.72966,
            "nubia_score": 0.7041
        },
        "bleurt": 0.11897,
        "meteor": 0.39841044420738453,
        "bertscore": {
            "precision": 0.9519,
            "recall": 0.91448,
            "f1": 0.93198
        }
    },
    "web_nlg_en_challenge_test_scramble_parent": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.51979,
        "msttr-100_nopunct": 0.52588,
        "total_length": 9466,
        "mean_pred_length": 18.932,
        "std_pred_length": 6.695026213540915,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.13289668286499048,
        "vocab_size-1": 1258,
        "unique-1": 500,
        "entropy-1": 8.024614507366282,
        "distinct-2": 0.3802141423154138,
        "vocab_size-2": 3409,
        "unique-2": 2017,
        "entropy-2": 10.838423887568448,
        "cond_entropy-2": 2.761666541263309,
        "distinct-3": 0.5812662414363335,
        "vocab_size-3": 4921,
        "unique-3": 3563,
        "entropy-3": 11.762156256771389,
        "cond_entropy-3": 1.0054766943826234,
        "total_length-nopunct": 8530,
        "mean_pred_length-nopunct": 17.06,
        "std_pred_length-nopunct": 6.294791497738427,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.14642438452520515,
        "vocab_size-1-nopunct": 1249,
        "unique-1-nopunct": 499,
        "entropy-1-nopunct": 8.21658289570274,
        "distinct-2-nopunct": 0.3884184308841843,
        "vocab_size-2-nopunct": 3119,
        "unique-2-nopunct": 1917,
        "entropy-2-nopunct": 10.711268152467134,
        "cond_entropy-2-nopunct": 2.659581786813591,
        "distinct-3-nopunct": 0.5868525896414343,
        "vocab_size-3-nopunct": 4419,
        "unique-3-nopunct": 3270,
        "entropy-3-nopunct": 11.591874515864204,
        "cond_entropy-3-nopunct": 0.9618885244674303,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.18719114449495947,
            "2": 0.49338310145911096,
            "3": 0.7356020942408377,
            "4": 0.4,
            "5": 0.6111111111111112
        },
        "nist": 6.771696855233094,
        "rouge1": {
            "precision": 0.77232,
            "recall": 0.67194,
            "fmeasure": 0.70655
        },
        "rouge2": {
            "precision": 0.52136,
            "recall": 0.45139,
            "fmeasure": 0.47441
        },
        "rougeL": {
            "precision": 0.64282,
            "recall": 0.55949,
            "fmeasure": 0.5878
        },
        "rougeLsum": {
            "precision": 0.64282,
            "recall": 0.55949,
            "fmeasure": 0.5878
        },
        "bleu": 39.67006,
        "nubia": {
            "semantic_relation": 4.11092,
            "contradiction": 9.1752,
            "irrelevancy": 9.59514,
            "logical_agreement": 81.22966,
            "grammar_ref": 4.57064,
            "grammar_hyp": 4.82969,
            "nubia_score": 0.66714
        },
        "bleurt": 0.02578,
        "meteor": 0.32449063311770604,
        "bertscore": {
            "precision": 0.91965,
            "recall": 0.89811,
            "f1": 0.90718
        }
    },
    "web_nlg_en_challenge_test_numbers_parent": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_en_test",
        "N": 500,
        "msttr-100": 0.65979,
        "msttr-100_nopunct": 0.68759,
        "total_length": 9692,
        "mean_pred_length": 19.384,
        "std_pred_length": 6.344804488713581,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.1284564589352043,
        "vocab_size-1": 1245,
        "unique-1": 499,
        "entropy-1": 8.008988694907279,
        "distinct-2": 0.36825500435161007,
        "vocab_size-2": 3385,
        "unique-2": 1981,
        "entropy-2": 10.813678254845593,
        "cond_entropy-2": 2.74080616625941,
        "distinct-3": 0.563046479521399,
        "vocab_size-3": 4894,
        "unique-3": 3486,
        "entropy-3": 11.729458669620492,
        "cond_entropy-3": 0.99534032415519,
        "total_length-nopunct": 8730,
        "mean_pred_length-nopunct": 17.46,
        "std_pred_length-nopunct": 6.003032566961469,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.14169530355097365,
        "vocab_size-1-nopunct": 1237,
        "unique-1-nopunct": 498,
        "entropy-1-nopunct": 8.195995632617846,
        "distinct-2-nopunct": 0.37654921020656135,
        "vocab_size-2-nopunct": 3099,
        "unique-2-nopunct": 1868,
        "entropy-2-nopunct": 10.68419515049796,
        "cond_entropy-2-nopunct": 2.645676847344703,
        "distinct-3-nopunct": 0.5684346701164295,
        "vocab_size-3-nopunct": 4394,
        "unique-3-nopunct": 3194,
        "entropy-3-nopunct": 11.557490660120779,
        "cond_entropy-3-nopunct": 0.9510574409856394,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "local_recall": {
            "1": 0.19234789880827932,
            "2": 0.5094599243206054,
            "3": 0.7409930094999104,
            "4": 0.8888888888888888,
            "5": 0.8181818181818182
        },
        "nist": 6.747038446460922,
        "rouge1": {
            "precision": 0.78453,
            "recall": 0.67762,
            "fmeasure": 0.71353
        },
        "rouge2": {
            "precision": 0.53263,
            "recall": 0.45854,
            "fmeasure": 0.48226
        },
        "rougeL": {
            "precision": 0.64797,
            "recall": 0.56028,
            "fmeasure": 0.58944
        },
        "rougeLsum": {
            "precision": 0.64797,
            "recall": 0.56028,
            "fmeasure": 0.58944
        },
        "bleu": 40.43002,
        "nubia": {
            "semantic_relation": 4.11455,
            "contradiction": 7.64306,
            "irrelevancy": 9.85516,
            "logical_agreement": 82.50179,
            "grammar_ref": 4.51016,
            "grammar_hyp": 4.76138,
            "nubia_score": 0.66659
        },
        "bleurt": 0.02478,
        "meteor": 0.33047765087811276,
        "bertscore": {
            "precision": 0.9228,
            "recall": 0.90045,
            "f1": 0.90985
        }
    },
    "mlsum_de_test": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_de_test",
        "N": 10695,
        "msttr-100": 0.73531,
        "msttr-100_nopunct": 0.76541,
        "total_length": 212333,
        "mean_pred_length": 19.85348293595138,
        "std_pred_length": 2.7091417581917163,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.1423518718239746,
        "vocab_size-1": 30226,
        "unique-1": 18682,
        "entropy-1": 10.422630311141603,
        "distinct-2": 0.5434293139190034,
        "vocab_size-2": 109576,
        "unique-2": 89042,
        "entropy-2": 15.39448850282259,
        "cond_entropy-2": 5.042977135987238,
        "distinct-3": 0.8303577507423682,
        "vocab_size-3": 158551,
        "unique-3": 144911,
        "entropy-3": 16.960967347363475,
        "cond_entropy-3": 1.627061771177205,
        "total_length-nopunct": 194380,
        "mean_pred_length-nopunct": 18.174848059841047,
        "std_pred_length-nopunct": 2.471549835781676,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.15543265768083137,
        "vocab_size-1-nopunct": 30213,
        "unique-1-nopunct": 18682,
        "entropy-1-nopunct": 10.784827766530967,
        "distinct-2-nopunct": 0.5932275362713341,
        "vocab_size-2-nopunct": 108967,
        "unique-2-nopunct": 89975,
        "entropy-2-nopunct": 15.721852076630984,
        "cond_entropy-2-nopunct": 5.09876782892565,
        "distinct-3-nopunct": 0.8699288976241402,
        "vocab_size-3-nopunct": 150489,
        "unique-3-nopunct": 139765,
        "entropy-3-nopunct": 16.98706031218657,
        "cond_entropy-3-nopunct": 1.3321802215412641,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "local_recall": {
            "1": 0.3530642585760696
        },
        "nist": 5.1832826630361515,
        "rouge1": {
            "precision": 0.45994,
            "recall": 0.35296,
            "fmeasure": 0.39377
        },
        "rouge2": {
            "precision": 0.34695,
            "recall": 0.25636,
            "fmeasure": 0.29117
        },
        "rougeL": {
            "precision": 0.42751,
            "recall": 0.32656,
            "fmeasure": 0.36518
        },
        "rougeLsum": {
            "precision": 0.42751,
            "recall": 0.32656,
            "fmeasure": 0.36518
        },
        "bleu": 26.12234,
        "nubia": {
            "semantic_relation": 2.44749,
            "contradiction": 26.06158,
            "irrelevancy": 38.22208,
            "logical_agreement": 35.71634,
            "grammar_ref": 5.03454,
            "grammar_hyp": 4.95297,
            "nubia_score": 0.30044
        },
        "bleurt": -0.46534,
        "meteor": 0.3092718163952006,
        "bertscore": {
            "precision": 0.88891,
            "recall": 0.86788,
            "f1": 0.87806
        }
    },
    "mlsum_de_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_de_challenge_train_sample",
        "N": 500
    },
    "mlsum_de_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_de_challenge_validation_sample",
        "N": 500
    },
    "mlsum_de_challenge_test_covid": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_de_challenge_test_covid",
        "N": 5058,
        "msttr-100": 0.68719,
        "msttr-100_nopunct": 0.71096,
        "total_length": 103955,
        "mean_pred_length": 20.552589956504548,
        "std_pred_length": 3.0437858790614856,
        "median_pred_length": 21.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.12374585157039103,
        "vocab_size-1": 12864,
        "unique-1": 8230,
        "entropy-1": 9.214219725158486,
        "distinct-2": 0.43634286176527093,
        "vocab_size-2": 43153,
        "unique-2": 35750,
        "entropy-2": 12.705528271907184,
        "cond_entropy-2": 3.5711106600223217,
        "distinct-3": 0.6229499461844222,
        "vocab_size-3": 58457,
        "unique-3": 54346,
        "entropy-3": 13.561767534702383,
        "cond_entropy-3": 0.9087774315582385,
        "total_length-nopunct": 93956,
        "mean_pred_length-nopunct": 18.57572162910241,
        "std_pred_length-nopunct": 2.389077335135256,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.13677678913533994,
        "vocab_size-1-nopunct": 12851,
        "unique-1-nopunct": 8230,
        "entropy-1-nopunct": 9.518707448410646,
        "distinct-2-nopunct": 0.4783572183851155,
        "vocab_size-2-nopunct": 42525,
        "unique-2-nopunct": 35886,
        "entropy-2-nopunct": 12.878270499767849,
        "cond_entropy-2-nopunct": 3.487915157843463,
        "distinct-3-nopunct": 0.6490100190839695,
        "vocab_size-3-nopunct": 54413,
        "unique-3-nopunct": 51197,
        "entropy-3-nopunct": 13.533342926482483,
        "cond_entropy-3-nopunct": 0.7093308430808951,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_challenge_test_covid.json",
        "local_recall": {
            "1": 0.2938589740770871
        },
        "nist": 4.1777727656677595,
        "rouge1": {
            "precision": 0.31524,
            "recall": 0.29689,
            "fmeasure": 0.29951
        },
        "rouge2": {
            "precision": 0.22123,
            "recall": 0.19913,
            "fmeasure": 0.20565
        },
        "rougeL": {
            "precision": 0.29214,
            "recall": 0.27386,
            "fmeasure": 0.27691
        },
        "rougeLsum": {
            "precision": 0.29214,
            "recall": 0.27386,
            "fmeasure": 0.27691
        },
        "bleu": 20.10633,
        "nubia": {
            "semantic_relation": 1.96098,
            "contradiction": 25.60034,
            "irrelevancy": 55.24045,
            "logical_agreement": 19.15921,
            "grammar_ref": 5.17449,
            "grammar_hyp": 5.03679,
            "nubia_score": 0.25253
        },
        "bleurt": -0.54586,
        "meteor": 0.25066746225869474,
        "bertscore": {
            "precision": 0.86795,
            "recall": 0.86,
            "f1": 0.86378
        }
    },
    "mlsum_es_validation": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_es_validation",
        "N": 9977,
        "msttr-100": 0.69453,
        "msttr-100_nopunct": 0.69629,
        "total_length": 194145,
        "mean_pred_length": 19.45925628946577,
        "std_pred_length": 3.9402891122644434,
        "median_pred_length": 20.0,
        "min_pred_length": 7,
        "max_pred_length": 39,
        "distinct-1": 0.12569471271472354,
        "vocab_size-1": 24403,
        "unique-1": 13575,
        "entropy-1": 10.003006103835078,
        "distinct-2": 0.5056958863646236,
        "vocab_size-2": 93133,
        "unique-2": 72979,
        "entropy-2": 15.130460289787774,
        "cond_entropy-2": 5.322732075543261,
        "distinct-3": 0.8184119730640503,
        "vocab_size-3": 142560,
        "unique-3": 129088,
        "entropy-3": 16.830383182293588,
        "cond_entropy-3": 1.7559917016859898,
        "total_length-nopunct": 187998,
        "mean_pred_length-nopunct": 18.843139220206474,
        "std_pred_length-nopunct": 3.583585926215615,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.12971946510069257,
        "vocab_size-1-nopunct": 24387,
        "unique-1-nopunct": 13574,
        "entropy-1-nopunct": 10.05852370234989,
        "distinct-2-nopunct": 0.5148606063329607,
        "vocab_size-2-nopunct": 91656,
        "unique-2-nopunct": 72255,
        "entropy-2-nopunct": 15.139308830331464,
        "cond_entropy-2-nopunct": 5.286231041531145,
        "distinct-3-nopunct": 0.8239211158982171,
        "vocab_size-3-nopunct": 138455,
        "unique-3-nopunct": 125746,
        "entropy-3-nopunct": 16.799281443018458,
        "cond_entropy-3-nopunct": 1.7159139628676352,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_validation.json",
        "local_recall": {
            "1": 0.26404072307998955
        },
        "nist": 2.9278641380826906,
        "rouge1": {
            "precision": 0.32442,
            "recall": 0.28518,
            "fmeasure": 0.29538
        },
        "rouge2": {
            "precision": 0.13071,
            "recall": 0.11607,
            "fmeasure": 0.11958
        },
        "rougeL": {
            "precision": 0.26377,
            "recall": 0.2336,
            "fmeasure": 0.24113
        },
        "rougeLsum": {
            "precision": 0.26377,
            "recall": 0.2336,
            "fmeasure": 0.24113
        },
        "bleu": 8.84391,
        "nubia": {
            "semantic_relation": 1.75289,
            "contradiction": 28.98462,
            "irrelevancy": 57.2458,
            "logical_agreement": 13.76958,
            "grammar_ref": 5.2776,
            "grammar_hyp": 5.20169,
            "nubia_score": 0.19832
        },
        "bleurt": -0.43397,
        "meteor": 0.21232023565960567,
        "bertscore": {
            "precision": 0.84297,
            "recall": 0.8348,
            "f1": 0.83867
        }
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_validation",
        "N": 20000,
        "msttr-100": 0.23304,
        "msttr-100_nopunct": 0.22048,
        "total_length": 339370,
        "mean_pred_length": 16.9685,
        "std_pred_length": 5.916122695651266,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.0234846922238265,
        "vocab_size-1": 7970,
        "unique-1": 0,
        "entropy-1": 9.755035470143003,
        "distinct-2": 0.0719103234492908,
        "vocab_size-2": 22966,
        "unique-2": 0,
        "entropy-2": 13.804032522426327,
        "cond_entropy-2": 3.8220947690656804,
        "distinct-3": 0.09172261749674317,
        "vocab_size-3": 27459,
        "unique-3": 0,
        "entropy-3": 14.585578830311334,
        "cond_entropy-3": 0.8139298851842395,
        "total_length-nopunct": 302620,
        "mean_pred_length-nopunct": 15.131,
        "std_pred_length-nopunct": 5.410437967484702,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.026273874826515102,
        "vocab_size-1-nopunct": 7951,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.113693035044767,
        "distinct-2-nopunct": 0.07451701931922723,
        "vocab_size-2-nopunct": 21060,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 13.76848898639728,
        "cond_entropy-2-nopunct": 3.8519098625608077,
        "distinct-3-nopunct": 0.09362957885918818,
        "vocab_size-3-nopunct": 24589,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.510130610814567,
        "cond_entropy-3-nopunct": 0.7940949947184306,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_validation.json",
        "local_recall": {
            "1": 0.6499510963255185
        },
        "nist": 9.245428360327141,
        "rouge1": {
            "precision": 0.7365,
            "recall": 0.67787,
            "fmeasure": 0.68589
        },
        "rouge2": {
            "precision": 0.54619,
            "recall": 0.49907,
            "fmeasure": 0.50554
        },
        "rougeL": {
            "precision": 0.68899,
            "recall": 0.63484,
            "fmeasure": 0.64231
        },
        "rougeLsum": {
            "precision": 0.68899,
            "recall": 0.63484,
            "fmeasure": 0.64231
        },
        "bleu": 40.46725,
        "sari": 44.06254,
        "nubia": {
            "semantic_relation": 4.12856,
            "contradiction": 3.59349,
            "irrelevancy": 24.61059,
            "logical_agreement": 71.79593,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.87635,
            "nubia_score": 0.65322
        },
        "bleurt": 0.17423,
        "meteor": 0.35242630272348874,
        "bertscore": {
            "precision": 0.91816,
            "recall": 0.90567,
            "f1": 0.91091
        }
    },
    "wiki_auto_asset_turk_test_asset": {
        "predictions_file": "ByT5-small (Baseline)/wiki_auto_asset_turk_test_asset",
        "N": 359,
        "msttr-100": 0.73574,
        "msttr-100_nopunct": 0.77073,
        "total_length": 6195,
        "mean_pred_length": 17.25626740947075,
        "std_pred_length": 6.102746858210674,
        "median_pred_length": 18.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.3861178369652946,
        "vocab_size-1": 2392,
        "unique-1": 1804,
        "entropy-1": 9.128919406069475,
        "distinct-2": 0.8415010281014393,
        "vocab_size-2": 4911,
        "unique-2": 4579,
        "entropy-2": 11.951184855882673,
        "cond_entropy-2": 2.645463000586634,
        "distinct-3": 0.9667701296330108,
        "vocab_size-3": 5295,
        "unique-3": 5209,
        "entropy-3": 12.306699863458707,
        "cond_entropy-3": 0.38003923522366023,
        "total_length-nopunct": 5551,
        "mean_pred_length-nopunct": 15.462395543175488,
        "std_pred_length-nopunct": 5.597761774116267,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.42857142857142855,
        "vocab_size-1-nopunct": 2379,
        "unique-1-nopunct": 1801,
        "entropy-1-nopunct": 9.397022590121578,
        "distinct-2-nopunct": 0.863251155624037,
        "vocab_size-2-nopunct": 4482,
        "unique-2-nopunct": 4202,
        "entropy-2-nopunct": 11.879929657724336,
        "cond_entropy-2-nopunct": 2.629561991939067,
        "distinct-3-nopunct": 0.9836540451065591,
        "vocab_size-3-nopunct": 4754,
        "unique-3-nopunct": 4692,
        "entropy-3-nopunct": 12.20277347589048,
        "cond_entropy-3-nopunct": 0.3485169726431887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_test_asset.json",
        "local_recall": {
            "1": 0.02627710400588019,
            "2": 0.1307277628032345,
            "3": 0.29397590361445786,
            "4": 0.4908256880733945,
            "5": 0.5614567526555387,
            "6": 0.6394366197183099,
            "7": 0.6939890710382514,
            "8": 0.7478890229191797,
            "9": 0.8084656084656084,
            "10": 0.9031007751937985
        },
        "nist": 12.671020892791919,
        "rouge1": {
            "precision": 0.8717,
            "recall": 0.81549,
            "fmeasure": 0.83041
        },
        "rouge2": {
            "precision": 0.76832,
            "recall": 0.71155,
            "fmeasure": 0.72475
        },
        "rougeL": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "rougeLsum": {
            "precision": 0.85666,
            "recall": 0.79961,
            "fmeasure": 0.81562
        },
        "bleu": 81.93645,
        "sari": 43.31772,
        "nubia": {
            "semantic_relation": 4.06169,
            "contradiction": 3.80336,
            "irrelevancy": 30.13173,
            "logical_agreement": 66.06491,
            "grammar_ref": 4.5697,
            "grammar_hyp": 4.90619,
            "nubia_score": 0.62654
        },
        "bleurt": 0.1314,
        "meteor": 0.4679813155989895,
        "bertscore": {
            "precision": 0.96224,
            "recall": 0.95179,
            "f1": 0.95293
        }
    },
    "mlsum_es_test": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_es_test",
        "N": 13366,
        "msttr-100": 0.69532,
        "msttr-100_nopunct": 0.69597,
        "total_length": 259482,
        "mean_pred_length": 19.413586712554242,
        "std_pred_length": 3.891019643487206,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 41,
        "distinct-1": 0.11235076036102697,
        "vocab_size-1": 29153,
        "unique-1": 15899,
        "entropy-1": 10.060098628778048,
        "distinct-2": 0.4763851192120789,
        "vocab_size-2": 117246,
        "unique-2": 90696,
        "entropy-2": 15.320036313981745,
        "cond_entropy-2": 5.4599741223167735,
        "distinct-3": 0.7957164339419979,
        "vocab_size-3": 185203,
        "unique-3": 166100,
        "entropy-3": 17.144325482352407,
        "cond_entropy-3": 1.8830557316731042,
        "total_length-nopunct": 251670,
        "mean_pred_length-nopunct": 18.829118659284752,
        "std_pred_length-nopunct": 3.556324196968033,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.11577065204434378,
        "vocab_size-1-nopunct": 29136,
        "unique-1-nopunct": 15896,
        "entropy-1-nopunct": 10.110973067109677,
        "distinct-2-nopunct": 0.4846582516449577,
        "vocab_size-2-nopunct": 115496,
        "unique-2-nopunct": 89934,
        "entropy-2-nopunct": 15.326151000158793,
        "cond_entropy-2-nopunct": 5.426017007081334,
        "distinct-3-nopunct": 0.801398607616321,
        "vocab_size-3-nopunct": 180265,
        "unique-3-nopunct": 162222,
        "entropy-3-nopunct": 17.116224334693598,
        "cond_entropy-3-nopunct": 1.8482520649816045,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "local_recall": {
            "1": 0.2594185264398915
        },
        "nist": 2.8440820277737635,
        "rouge1": {
            "precision": 0.32328,
            "recall": 0.28248,
            "fmeasure": 0.29345
        },
        "rouge2": {
            "precision": 0.1279,
            "recall": 0.11239,
            "fmeasure": 0.11654
        },
        "rougeL": {
            "precision": 0.26307,
            "recall": 0.2312,
            "fmeasure": 0.23959
        },
        "rougeLsum": {
            "precision": 0.26307,
            "recall": 0.2312,
            "fmeasure": 0.23959
        },
        "bleu": 8.34992,
        "nubia": {
            "semantic_relation": 1.73385,
            "contradiction": 29.84786,
            "irrelevancy": 56.40144,
            "logical_agreement": 13.75071,
            "grammar_ref": 5.26998,
            "grammar_hyp": 5.19412,
            "nubia_score": 0.19619
        },
        "bleurt": -0.44008,
        "meteor": 0.20820058364237026,
        "bertscore": {
            "precision": 0.84258,
            "recall": 0.83367,
            "f1": 0.83791
        }
    },
    "mlsum_es_challenge_train_sample": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_es_challenge_train_sample",
        "N": 500
    },
    "mlsum_es_challenge_validation_sample": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_es_challenge_validation_sample",
        "N": 500
    },
    "mlsum_es_challenge_test_covid": {
        "predictions_file": "ByT5-small (Baseline)/mlsum_es_challenge_test_covid",
        "N": 1938,
        "msttr-100": 0.69844,
        "msttr-100_nopunct": 0.69753,
        "total_length": 37728,
        "mean_pred_length": 19.46749226006192,
        "std_pred_length": 3.4626454220846146,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.19860581000848176,
        "vocab_size-1": 7493,
        "unique-1": 4663,
        "entropy-1": 9.336196182988603,
        "distinct-2": 0.6055322715842414,
        "vocab_size-2": 21672,
        "unique-2": 17736,
        "entropy-2": 13.512229720745419,
        "cond_entropy-2": 4.329800668790557,
        "distinct-3": 0.869756587498523,
        "vocab_size-3": 29443,
        "unique-3": 27243,
        "entropy-3": 14.676857533874719,
        "cond_entropy-3": 1.1856658018883435,
        "total_length-nopunct": 36811,
        "mean_pred_length-nopunct": 18.994324045407637,
        "std_pred_length-nopunct": 3.2373384037511763,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.20325446198147293,
        "vocab_size-1-nopunct": 7482,
        "unique-1-nopunct": 4661,
        "entropy-1-nopunct": 9.35507749017031,
        "distinct-2-nopunct": 0.6116193043328649,
        "vocab_size-2-nopunct": 21329,
        "unique-2-nopunct": 17552,
        "entropy-2-nopunct": 13.492620115377502,
        "cond_entropy-2-nopunct": 4.296087226348325,
        "distinct-3-nopunct": 0.8722939122514043,
        "vocab_size-3-nopunct": 28729,
        "unique-3-nopunct": 26646,
        "entropy-3-nopunct": 14.643474958576585,
        "cond_entropy-3-nopunct": 1.1721542559249423,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_challenge_test_covid.json",
        "local_recall": {
            "1": 0.24111357287351892
        },
        "nist": 2.1179629809453604,
        "rouge1": {
            "precision": 0.32542,
            "recall": 0.2618,
            "fmeasure": 0.28132
        },
        "rouge2": {
            "precision": 0.11506,
            "recall": 0.09131,
            "fmeasure": 0.0989
        },
        "rougeL": {
            "precision": 0.25739,
            "recall": 0.20841,
            "fmeasure": 0.22324
        },
        "rougeLsum": {
            "precision": 0.25739,
            "recall": 0.20841,
            "fmeasure": 0.22324
        },
        "bleu": 6.29398,
        "nubia": {
            "semantic_relation": 1.62496,
            "contradiction": 27.61606,
            "irrelevancy": 60.70829,
            "logical_agreement": 11.67565,
            "grammar_ref": 5.23427,
            "grammar_hyp": 5.22792,
            "nubia_score": 0.17244
        },
        "bleurt": -0.47838,
        "meteor": 0.1933649007450059,
        "bertscore": {
            "precision": 0.84322,
            "recall": 0.83095,
            "f1": 0.83686
        }
    },
    "wiki_lingua_spanish_es_validation": {
        "predictions_file": "ByT5-small (Baseline)/wiki_lingua_spanish_es_validation",
        "N": 11316,
        "msttr-100": 0.58955,
        "msttr-100_nopunct": 0.65759,
        "total_length": 269470,
        "mean_pred_length": 23.813184870979146,
        "std_pred_length": 5.418252938058731,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 51,
        "distinct-1": 0.04819831521134078,
        "vocab_size-1": 12988,
        "unique-1": 5178,
        "entropy-1": 8.99055240109103,
        "distinct-2": 0.281824027518458,
        "vocab_size-2": 72754,
        "unique-2": 48391,
        "entropy-2": 14.043906950489848,
        "cond_entropy-2": 5.047897704609259,
        "distinct-3": 0.6144677885900874,
        "vocab_size-3": 151674,
        "unique-3": 124077,
        "entropy-3": 16.384225432567344,
        "cond_entropy-3": 2.3984672160468765,
        "total_length-nopunct": 231509,
        "mean_pred_length-nopunct": 20.45855425945564,
        "std_pred_length-nopunct": 5.147742643676826,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.056002142465303724,
        "vocab_size-1-nopunct": 12965,
        "unique-1-nopunct": 5174,
        "entropy-1-nopunct": 9.728061915233129,
        "distinct-2-nopunct": 0.4030918330737126,
        "vocab_size-2-nopunct": 88758,
        "unique-2-nopunct": 65466,
        "entropy-2-nopunct": 14.742508678673143,
        "cond_entropy-2-nopunct": 5.162670212493101,
        "distinct-3-nopunct": 0.738185630777922,
        "vocab_size-3-nopunct": 154190,
        "unique-3-nopunct": 133478,
        "entropy-3-nopunct": 16.781370473083495,
        "cond_entropy-3-nopunct": 2.1145346119464308,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_validation.json",
        "local_recall": {
            "1": 0.26409442902168695
        },
        "nist": 1.8047096031951062,
        "rouge1": {
            "precision": 0.45302,
            "recall": 0.31242,
            "fmeasure": 0.35036
        },
        "rouge2": {
            "precision": 0.17131,
            "recall": 0.11755,
            "fmeasure": 0.13189
        },
        "rougeL": {
            "precision": 0.37342,
            "recall": 0.26172,
            "fmeasure": 0.29135
        },
        "rougeLsum": {
            "precision": 0.37342,
            "recall": 0.26172,
            "fmeasure": 0.29135
        },
        "bleu": 7.72465,
        "sari": 67.48269,
        "nubia": {
            "semantic_relation": 2.85091,
            "contradiction": 16.6631,
            "irrelevancy": 42.4964,
            "logical_agreement": 40.8405,
            "grammar_ref": 3.95671,
            "grammar_hyp": 4.05691,
            "nubia_score": 0.36371
        },
        "bleurt": -0.47486,
        "meteor": 0.1408425706771069,
        "bertscore": {
            "precision": 0.85802,
            "recall": 0.82883,
            "f1": 0.84264
        }
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "ByT5-small (Baseline)/wiki_lingua_spanish_es_test",
        "N": 22632,
        "msttr-100": 0.58832,
        "msttr-100_nopunct": 0.65587,
        "total_length": 536128,
        "mean_pred_length": 23.68893601979498,
        "std_pred_length": 5.454348400252734,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 45,
        "distinct-1": 0.03317864390593291,
        "vocab_size-1": 17788,
        "unique-1": 6830,
        "entropy-1": 9.037852336238807,
        "distinct-2": 0.23094629753688442,
        "vocab_size-2": 118590,
        "unique-2": 76904,
        "entropy-2": 14.309331415611675,
        "cond_entropy-2": 5.266069101521349,
        "distinct-3": 0.5538071645099254,
        "vocab_size-3": 271844,
        "unique-3": 216184,
        "entropy-3": 16.978745064242194,
        "cond_entropy-3": 2.7340806003712257,
        "total_length-nopunct": 460774,
        "mean_pred_length-nopunct": 20.359402615765287,
        "std_pred_length-nopunct": 5.176910131728223,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.03854601171073021,
        "vocab_size-1-nopunct": 17761,
        "unique-1-nopunct": 6826,
        "entropy-1-nopunct": 9.778171135352734,
        "distinct-2-nopunct": 0.3442217363320567,
        "vocab_size-2-nopunct": 150818,
        "unique-2-nopunct": 107784,
        "entropy-2-nopunct": 15.114426014907853,
        "cond_entropy-2-nopunct": 5.488963421136218,
        "distinct-3-nopunct": 0.6850496979615412,
        "vocab_size-3-nopunct": 284645,
        "unique-3-nopunct": 240807,
        "entropy-3-nopunct": 17.50281787004621,
        "cond_entropy-3-nopunct": 2.4763121229878697,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "local_recall": {
            "1": 0.26015709502071677
        },
        "nist": 1.7200870484937527,
        "rouge1": {
            "precision": 0.45307,
            "recall": 0.30949,
            "fmeasure": 0.34812
        },
        "rouge2": {
            "precision": 0.16981,
            "recall": 0.11564,
            "fmeasure": 0.13003
        },
        "rougeL": {
            "precision": 0.37288,
            "recall": 0.25912,
            "fmeasure": 0.2892
        },
        "rougeLsum": {
            "precision": 0.37288,
            "recall": 0.25912,
            "fmeasure": 0.2892
        },
        "bleu": 7.47784,
        "sari": 67.37369,
        "nubia": {
            "semantic_relation": 2.84059,
            "contradiction": 16.71927,
            "irrelevancy": 42.53029,
            "logical_agreement": 40.75044,
            "grammar_ref": 3.9494,
            "grammar_hyp": 4.05453,
            "nubia_score": 0.36103
        },
        "bleurt": -0.48508,
        "meteor": 0.13842784113838497,
        "bertscore": {
            "precision": 0.85732,
            "recall": 0.82744,
            "f1": 0.84158
        }
    },
    "wiki_lingua_turkish_tr_validation": {
        "predictions_file": "ByT5-small (Baseline)/wiki_lingua_turkish_tr_validation",
        "N": 449,
        "msttr-100": 0.59874,
        "msttr-100_nopunct": 0.66448,
        "total_length": 11168,
        "mean_pred_length": 24.87305122494432,
        "std_pred_length": 4.647427604638981,
        "median_pred_length": 26.0,
        "min_pred_length": 3,
        "max_pred_length": 36,
        "distinct-1": 0.18257521489971346,
        "vocab_size-1": 2039,
        "unique-1": 1051,
        "entropy-1": 8.246335245536887,
        "distinct-2": 0.5501446030413285,
        "vocab_size-2": 5897,
        "unique-2": 4414,
        "entropy-2": 11.730559618295747,
        "cond_entropy-2": 3.5142300004021187,
        "distinct-3": 0.8089581304771178,
        "vocab_size-3": 8308,
        "unique-3": 7295,
        "entropy-3": 12.786145369889574,
        "cond_entropy-3": 1.0914249921979984,
        "total_length-nopunct": 9609,
        "mean_pred_length-nopunct": 21.400890868596882,
        "std_pred_length-nopunct": 4.304614927500387,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.2106358622125091,
        "vocab_size-1-nopunct": 2024,
        "unique-1-nopunct": 1045,
        "entropy-1-nopunct": 8.844025809542615,
        "distinct-2-nopunct": 0.6516375545851528,
        "vocab_size-2-nopunct": 5969,
        "unique-2-nopunct": 4765,
        "entropy-2-nopunct": 12.022141965763971,
        "cond_entropy-2-nopunct": 3.281173840423935,
        "distinct-3-nopunct": 0.8879577545631959,
        "vocab_size-3-nopunct": 7735,
        "unique-3-nopunct": 7105,
        "entropy-3-nopunct": 12.803667605624794,
        "cond_entropy-3-nopunct": 0.8159622147802088,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_validation.json",
        "local_recall": {
            "1": 0.27101370851370854
        },
        "nist": 1.7023123843212695,
        "rouge1": {
            "precision": 0.432,
            "recall": 0.30457,
            "fmeasure": 0.33612
        },
        "rouge2": {
            "precision": 0.18025,
            "recall": 0.12242,
            "fmeasure": 0.13624
        },
        "rougeL": {
            "precision": 0.35295,
            "recall": 0.25124,
            "fmeasure": 0.27575
        },
        "rougeLsum": {
            "precision": 0.35295,
            "recall": 0.25124,
            "fmeasure": 0.27575
        },
        "bleu": 10.35027,
        "sari": 67.66908,
        "nubia": {
            "semantic_relation": 2.54677,
            "contradiction": 25.47484,
            "irrelevancy": 44.08809,
            "logical_agreement": 30.43707,
            "grammar_ref": 3.85457,
            "grammar_hyp": 4.41632,
            "nubia_score": 0.26811
        },
        "bleurt": -0.60084,
        "meteor": 0.13987394404856793,
        "bertscore": {
            "precision": 0.84867,
            "recall": 0.82644,
            "f1": 0.83692
        }
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "ByT5-small (Baseline)/wiki_lingua_turkish_tr_test",
        "N": 900,
        "msttr-100": 0.59747,
        "msttr-100_nopunct": 0.66119,
        "total_length": 22542,
        "mean_pred_length": 25.046666666666667,
        "std_pred_length": 4.799773142787295,
        "median_pred_length": 26.0,
        "min_pred_length": 4,
        "max_pred_length": 36,
        "distinct-1": 0.12922544583444237,
        "vocab_size-1": 2913,
        "unique-1": 1360,
        "entropy-1": 8.372119502631158,
        "distinct-2": 0.4662230847426301,
        "vocab_size-2": 10090,
        "unique-2": 7145,
        "entropy-2": 12.209541600098458,
        "cond_entropy-2": 3.86892140259245,
        "distinct-3": 0.7517597145887571,
        "vocab_size-3": 15593,
        "unique-3": 13401,
        "entropy-3": 13.546753871420831,
        "cond_entropy-3": 1.384132490553992,
        "total_length-nopunct": 19426,
        "mean_pred_length-nopunct": 21.584444444444443,
        "std_pred_length-nopunct": 4.361521424434652,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.14923298671883042,
        "vocab_size-1-nopunct": 2899,
        "unique-1-nopunct": 1356,
        "entropy-1-nopunct": 8.972902446222506,
        "distinct-2-nopunct": 0.5709273453524776,
        "vocab_size-2-nopunct": 10577,
        "unique-2-nopunct": 8113,
        "entropy-2-nopunct": 12.606878110648589,
        "cond_entropy-2-nopunct": 3.7485661546398665,
        "distinct-3-nopunct": 0.8414841711108589,
        "vocab_size-3-nopunct": 14832,
        "unique-3-nopunct": 13311,
        "entropy-3-nopunct": 13.667299861767177,
        "cond_entropy-3-nopunct": 1.1095066971278433,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "local_recall": {
            "1": 0.2745973744755718
        },
        "nist": 1.7911018977064137,
        "rouge1": {
            "precision": 0.4271,
            "recall": 0.30479,
            "fmeasure": 0.33338
        },
        "rouge2": {
            "precision": 0.18158,
            "recall": 0.12311,
            "fmeasure": 0.13765
        },
        "rougeL": {
            "precision": 0.34961,
            "recall": 0.25226,
            "fmeasure": 0.27454
        },
        "rougeLsum": {
            "precision": 0.34961,
            "recall": 0.25226,
            "fmeasure": 0.27454
        },
        "bleu": 10.29052,
        "sari": 67.1368,
        "nubia": {
            "semantic_relation": 2.48458,
            "contradiction": 27.06723,
            "irrelevancy": 43.67046,
            "logical_agreement": 29.26232,
            "grammar_ref": 3.87672,
            "grammar_hyp": 4.37825,
            "nubia_score": 0.26467
        },
        "bleurt": -0.60413,
        "meteor": 0.13853925904474174,
        "bertscore": {
            "precision": 0.84718,
            "recall": 0.82639,
            "f1": 0.83617
        }
    },
    "wiki_lingua_vietnamese_vi_validation": {
        "predictions_file": "ByT5-small (Baseline)/wiki_lingua_vietnamese_vi_validation",
        "N": 1957,
        "msttr-100": 0.62667,
        "msttr-100_nopunct": 0.69951,
        "total_length": 47440,
        "mean_pred_length": 24.241185487991824,
        "std_pred_length": 4.730021344140907,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 36,
        "distinct-1": 0.10330944350758853,
        "vocab_size-1": 4901,
        "unique-1": 2255,
        "entropy-1": 8.744995437697153,
        "distinct-2": 0.433612558538355,
        "vocab_size-2": 19722,
        "unique-2": 14050,
        "entropy-2": 13.098341004014882,
        "cond_entropy-2": 4.3687790228201155,
        "distinct-3": 0.7640490741166199,
        "vocab_size-3": 33256,
        "unique-3": 29015,
        "entropy-3": 14.66646843212523,
        "cond_entropy-3": 1.6129038064489756,
        "total_length-nopunct": 40752,
        "mean_pred_length-nopunct": 20.823709759836483,
        "std_pred_length-nopunct": 4.478426106569113,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.11994503337259521,
        "vocab_size-1-nopunct": 4888,
        "unique-1-nopunct": 2252,
        "entropy-1-nopunct": 9.446209134536769,
        "distinct-2-nopunct": 0.5631911328779482,
        "vocab_size-2-nopunct": 21849,
        "unique-2-nopunct": 17251,
        "entropy-2-nopunct": 13.54713545738246,
        "cond_entropy-2-nopunct": 4.225929423509408,
        "distinct-3-nopunct": 0.8625875454693523,
        "vocab_size-3-nopunct": 31776,
        "unique-3-nopunct": 29205,
        "entropy-3-nopunct": 14.776536776318014,
        "cond_entropy-3-nopunct": 1.2780563825986593,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_validation.json",
        "local_recall": {
            "1": 0.24736388626759118
        },
        "nist": 1.7802908549674223,
        "rouge1": {
            "precision": 0.39349,
            "recall": 0.28214,
            "fmeasure": 0.31179
        },
        "rouge2": {
            "precision": 0.13176,
            "recall": 0.09384,
            "fmeasure": 0.10359
        },
        "rougeL": {
            "precision": 0.31265,
            "recall": 0.22809,
            "fmeasure": 0.24995
        },
        "rougeLsum": {
            "precision": 0.31265,
            "recall": 0.22809,
            "fmeasure": 0.24995
        },
        "bleu": 7.19626,
        "sari": 66.3716,
        "nubia": {
            "semantic_relation": 2.48809,
            "contradiction": 21.76391,
            "irrelevancy": 44.10186,
            "logical_agreement": 34.13423,
            "grammar_ref": 3.90718,
            "grammar_hyp": 4.38176,
            "nubia_score": 0.26785
        },
        "bleurt": -0.55092,
        "meteor": 0.13065387164533462,
        "bertscore": {
            "precision": 0.84359,
            "recall": 0.82294,
            "f1": 0.8327
        }
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "ByT5-small (Baseline)/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "msttr-100": 0.62478,
        "msttr-100_nopunct": 0.69647,
        "total_length": 94174,
        "mean_pred_length": 24.042379371968345,
        "std_pred_length": 4.906763189701471,
        "median_pred_length": 25.0,
        "min_pred_length": 2,
        "max_pred_length": 38,
        "distinct-1": 0.07181387644148067,
        "vocab_size-1": 6763,
        "unique-1": 2835,
        "entropy-1": 8.809348924992833,
        "distinct-2": 0.36208825908239806,
        "vocab_size-2": 32681,
        "unique-2": 22720,
        "entropy-2": 13.452110923652631,
        "cond_entropy-2": 4.6519188693534765,
        "distinct-3": 0.701331943479268,
        "vocab_size-3": 60553,
        "unique-3": 51718,
        "entropy-3": 15.347239131533552,
        "cond_entropy-3": 1.9467413775281435,
        "total_length-nopunct": 80873,
        "mean_pred_length-nopunct": 20.646668368649475,
        "std_pred_length-nopunct": 4.618589963452115,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.08342710175212988,
        "vocab_size-1-nopunct": 6747,
        "unique-1-nopunct": 2831,
        "entropy-1-nopunct": 9.530620536700692,
        "distinct-2-nopunct": 0.490773948749935,
        "vocab_size-2-nopunct": 37768,
        "unique-2-nopunct": 28982,
        "entropy-2-nopunct": 14.041642927470267,
        "cond_entropy-2-nopunct": 4.642313072655291,
        "distinct-3-nopunct": 0.818222891566265,
        "vocab_size-3-nopunct": 59763,
        "unique-3-nopunct": 53991,
        "entropy-3-nopunct": 15.587426102615893,
        "cond_entropy-3-nopunct": 1.6047390426625059,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "local_recall": {
            "1": 0.24978840346495856
        },
        "nist": 1.8344649717040222,
        "rouge1": {
            "precision": 0.39455,
            "recall": 0.2844,
            "fmeasure": 0.31301
        },
        "rouge2": {
            "precision": 0.1342,
            "recall": 0.09479,
            "fmeasure": 0.10509
        },
        "rougeL": {
            "precision": 0.31353,
            "recall": 0.22968,
            "fmeasure": 0.25075
        },
        "rougeLsum": {
            "precision": 0.31353,
            "recall": 0.22968,
            "fmeasure": 0.25075
        },
        "bleu": 7.27963,
        "sari": 66.20486,
        "nubia": {
            "semantic_relation": 2.5089,
            "contradiction": 21.44634,
            "irrelevancy": 43.78278,
            "logical_agreement": 34.77088,
            "grammar_ref": 3.92068,
            "grammar_hyp": 4.36339,
            "nubia_score": 0.27501
        },
        "bleurt": -0.54698,
        "meteor": 0.13103404030056184,
        "bertscore": {
            "precision": 0.84487,
            "recall": 0.82351,
            "f1": 0.8336
        }
    },
    "wiki_lingua_russian_ru_validation": {
        "predictions_file": "ByT5-small (Baseline)/wiki_lingua_russian_ru_validation",
        "N": 5288,
        "msttr-100": 0.57658,
        "msttr-100_nopunct": 0.64415,
        "total_length": 126447,
        "mean_pred_length": 23.912065052950076,
        "std_pred_length": 5.6354204244552335,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 42,
        "distinct-1": 0.0637974803672685,
        "vocab_size-1": 8067,
        "unique-1": 3188,
        "entropy-1": 8.820377512341974,
        "distinct-2": 0.32244406110978135,
        "vocab_size-2": 39067,
        "unique-2": 25724,
        "entropy-2": 13.54810795719729,
        "cond_entropy-2": 4.723554797691043,
        "distinct-3": 0.6477634610903504,
        "vocab_size-3": 75057,
        "unique-3": 61441,
        "entropy-3": 15.540458578764074,
        "cond_entropy-3": 2.043654327054996,
        "total_length-nopunct": 108460,
        "mean_pred_length-nopunct": 20.510590015128592,
        "std_pred_length-nopunct": 5.251168859133342,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 35,
        "distinct-1-nopunct": 0.07420247095703485,
        "vocab_size-1-nopunct": 8048,
        "unique-1-nopunct": 3187,
        "entropy-1-nopunct": 9.54660014595818,
        "distinct-2-nopunct": 0.44493661070833174,
        "vocab_size-2-nopunct": 45905,
        "unique-2-nopunct": 33796,
        "entropy-2-nopunct": 14.14313043692287,
        "cond_entropy-2-nopunct": 4.73398831135266,
        "distinct-3-nopunct": 0.7658555024314495,
        "vocab_size-3-nopunct": 74965,
        "unique-3-nopunct": 65051,
        "entropy-3-nopunct": 15.84010193942625,
        "cond_entropy-3-nopunct": 1.760753810548278,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_validation.json",
        "local_recall": {
            "1": 0.23065797378785519
        },
        "nist": 1.491269075627518,
        "rouge1": {
            "precision": 0.40353,
            "recall": 0.27746,
            "fmeasure": 0.30845
        },
        "rouge2": {
            "precision": 0.13728,
            "recall": 0.09323,
            "fmeasure": 0.1039
        },
        "rougeL": {
            "precision": 0.32896,
            "recall": 0.22991,
            "fmeasure": 0.2536
        },
        "rougeLsum": {
            "precision": 0.32896,
            "recall": 0.22991,
            "fmeasure": 0.2536
        },
        "bleu": 6.28348,
        "sari": 67.78202,
        "nubia": {
            "semantic_relation": 2.64764,
            "contradiction": 19.24677,
            "irrelevancy": 43.66927,
            "logical_agreement": 37.08395,
            "grammar_ref": 3.95099,
            "grammar_hyp": 4.079,
            "nubia_score": 0.32658
        },
        "bleurt": -0.55613,
        "meteor": 0.12442060951655001,
        "bertscore": {
            "precision": 0.84538,
            "recall": 0.81745,
            "f1": 0.83062
        }
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "ByT5-small (Baseline)/wiki_lingua_russian_ru_test",
        "N": 10580,
        "msttr-100": 0.57417,
        "msttr-100_nopunct": 0.64099,
        "total_length": 252177,
        "mean_pred_length": 23.83525519848771,
        "std_pred_length": 5.736180482060814,
        "median_pred_length": 25.0,
        "min_pred_length": 2,
        "max_pred_length": 56,
        "distinct-1": 0.043953255054981225,
        "vocab_size-1": 11084,
        "unique-1": 4253,
        "entropy-1": 8.869803936145475,
        "distinct-2": 0.2617623563206497,
        "vocab_size-2": 63241,
        "unique-2": 40655,
        "entropy-2": 13.816005655564194,
        "cond_entropy-2": 4.941566182027243,
        "distinct-3": 0.5809053013414597,
        "vocab_size-3": 134199,
        "unique-3": 107089,
        "entropy-3": 16.12728192334694,
        "cond_entropy-3": 2.3678499327232316,
        "total_length-nopunct": 216150,
        "mean_pred_length-nopunct": 20.430056710775048,
        "std_pred_length-nopunct": 5.333749961765069,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 41,
        "distinct-1-nopunct": 0.05116354383529956,
        "vocab_size-1-nopunct": 11059,
        "unique-1-nopunct": 4249,
        "entropy-1-nopunct": 9.608706151436508,
        "distinct-2-nopunct": 0.377822639490198,
        "vocab_size-2-nopunct": 77669,
        "unique-2-nopunct": 55556,
        "entropy-2-nopunct": 14.527167993448067,
        "cond_entropy-2-nopunct": 5.063141436420516,
        "distinct-3-nopunct": 0.7089089920715509,
        "vocab_size-3-nopunct": 138233,
        "unique-3-nopunct": 117322,
        "entropy-3-nopunct": 16.560088433436594,
        "cond_entropy-3-nopunct": 2.1060198549087916,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "local_recall": {
            "1": 0.23155160895641144
        },
        "nist": 1.588121480967212,
        "rouge1": {
            "precision": 0.40232,
            "recall": 0.27878,
            "fmeasure": 0.3095
        },
        "rouge2": {
            "precision": 0.13635,
            "recall": 0.09325,
            "fmeasure": 0.10384
        },
        "rougeL": {
            "precision": 0.3272,
            "recall": 0.23009,
            "fmeasure": 0.25358
        },
        "rougeLsum": {
            "precision": 0.3272,
            "recall": 0.23009,
            "fmeasure": 0.25358
        },
        "bleu": 6.3877,
        "sari": 67.6574,
        "nubia": {
            "semantic_relation": 2.65443,
            "contradiction": 20.2715,
            "irrelevancy": 43.36349,
            "logical_agreement": 36.36501,
            "grammar_ref": 3.95647,
            "grammar_hyp": 4.05084,
            "nubia_score": 0.32838
        },
        "bleurt": -0.54887,
        "meteor": 0.12514480002225634,
        "bertscore": {
            "precision": 0.84601,
            "recall": 0.81758,
            "f1": 0.831
        }
    },
    "dart_validation": {
        "predictions_file": "ByT5-small (Baseline)/dart_validation",
        "N": 2768,
        "msttr-100": 0.47121,
        "msttr-100_nopunct": 0.47701,
        "total_length": 55270,
        "mean_pred_length": 19.96748554913295,
        "std_pred_length": 6.142723081559804,
        "median_pred_length": 22.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.06696218563415958,
        "vocab_size-1": 3701,
        "unique-1": 1741,
        "entropy-1": 7.839907404863033,
        "distinct-2": 0.22279151270427794,
        "vocab_size-2": 11697,
        "unique-2": 7365,
        "entropy-2": 10.896804730500664,
        "cond_entropy-2": 3.013636483627371,
        "distinct-3": 0.36212651304942295,
        "vocab_size-3": 18010,
        "unique-3": 13040,
        "entropy-3": 12.296773304739254,
        "cond_entropy-3": 1.5112416455811366,
        "total_length-nopunct": 50599,
        "mean_pred_length-nopunct": 18.27998554913295,
        "std_pred_length-nopunct": 5.942888449329876,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07284728947212396,
        "vocab_size-1-nopunct": 3686,
        "unique-1-nopunct": 1738,
        "entropy-1-nopunct": 7.983578804736285,
        "distinct-2-nopunct": 0.22717484476594677,
        "vocab_size-2-nopunct": 10866,
        "unique-2-nopunct": 6943,
        "entropy-2-nopunct": 10.786236157464291,
        "cond_entropy-2-nopunct": 2.982155330030267,
        "distinct-3-nopunct": 0.36491134633734995,
        "vocab_size-3-nopunct": 16444,
        "unique-3-nopunct": 11935,
        "entropy-3-nopunct": 12.191734188914024,
        "cond_entropy-3-nopunct": 1.5204855275475073,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/dart_validation.json",
        "local_recall": {
            "1": 0.01882165409846116,
            "2": 0.014925373134328358,
            "3": 0.013154172560113154,
            "4": 0.028771670970121725,
            "5": 0.048327137546468404,
            "6": 0.0628775398132894,
            "7": 0.08154362416107383,
            "8": 0.09516129032258064,
            "9": 0.1020293122886133,
            "10": 0.11600587371512482,
            "11": 0.1163556531284303,
            "12": 0.12012480499219969,
            "13": 0.09846827133479212,
            "14": 0.04927536231884058,
            "15": 0.0660377358490566,
            "16": 0.09722222222222222,
            "17": 0.01282051282051282,
            "18": 0.06666666666666667,
            "19": 0.041666666666666664,
            "20": 0.08823529411764706,
            "21": 0.13043478260869565,
            "22": 0.0,
            "23": 0.13333333333333333,
            "24": 0.0,
            "25": 0.3333333333333333,
            "26": 0.0,
            "27": 0,
            "28": 0.0,
            "29": 0.0,
            "30": 0.0,
            "31": 0.0,
            "32": 0,
            "33": 0,
            "34": 0,
            "35": 0,
            "36": 0,
            "37": 0.0,
            "38": 0,
            "39": 0,
            "40": 0,
            "41": 0,
            "42": 0,
            "43": 0,
            "44": 0,
            "45": 0,
            "46": 0,
            "47": 0,
            "48": 0,
            "49": 0,
            "50": 0,
            "51": 0,
            "52": 0,
            "53": 0,
            "54": 0,
            "55": 0,
            "56": 0,
            "57": 0,
            "58": 0,
            "59": 0,
            "60": 0,
            "61": 0,
            "62": 0,
            "63": 0,
            "64": 0,
            "65": 0,
            "66": 0,
            "67": 0,
            "68": 0,
            "69": 0,
            "70": 0,
            "71": 0,
            "72": 0
        },
        "nist": 0.6018072419512449,
        "rouge1": {
            "precision": 0.03934,
            "recall": 0.72793,
            "fmeasure": 0.07408
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.03934,
            "recall": 0.72793,
            "fmeasure": 0.07408
        },
        "rougeLsum": {
            "precision": 0.03934,
            "recall": 0.72793,
            "fmeasure": 0.07408
        },
        "bleu": 0.00593,
        "nubia": {
            "semantic_relation": 4.06808,
            "contradiction": 7.03376,
            "irrelevancy": 20.63699,
            "logical_agreement": 72.32924,
            "grammar_ref": 4.89251,
            "grammar_hyp": 4.85019,
            "nubia_score": 0.67816
        },
        "bleurt": 0.05192,
        "meteor": 0.08231735349421943,
        "bertscore": {
            "precision": 0.90386,
            "recall": 0.89039,
            "f1": 0.89671
        }
    },
    "web_nlg_ru_validation": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_validation",
        "N": 790,
        "msttr-100": 0.51724,
        "msttr-100_nopunct": 0.55068,
        "total_length": 8709,
        "mean_pred_length": 11.024050632911392,
        "std_pred_length": 3.1543706945203773,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.1748765644735331,
        "vocab_size-1": 1523,
        "unique-1": 748,
        "entropy-1": 8.5507076195346,
        "distinct-2": 0.3979037757292587,
        "vocab_size-2": 3151,
        "unique-2": 2004,
        "entropy-2": 10.708491635045803,
        "cond_entropy-2": 2.2215282891918355,
        "distinct-3": 0.5403282367793519,
        "vocab_size-3": 3852,
        "unique-3": 2740,
        "entropy-3": 11.340257976360142,
        "cond_entropy-3": 0.7764410685931642,
        "total_length-nopunct": 7404,
        "mean_pred_length-nopunct": 9.372151898734177,
        "std_pred_length-nopunct": 2.756026157252217,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.20475418692598596,
        "vocab_size-1-nopunct": 1516,
        "unique-1-nopunct": 747,
        "entropy-1-nopunct": 8.997088297973978,
        "distinct-2-nopunct": 0.43317205926821895,
        "vocab_size-2-nopunct": 2865,
        "unique-2-nopunct": 1882,
        "entropy-2-nopunct": 10.664020429471199,
        "cond_entropy-2-nopunct": 1.8847139240818696,
        "distinct-3-nopunct": 0.5673076923076923,
        "vocab_size-3-nopunct": 3304,
        "unique-3-nopunct": 2396,
        "entropy-3-nopunct": 11.149776097915185,
        "cond_entropy-3-nopunct": 0.6491630769897319,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_validation.json",
        "local_recall": {
            "1": 0.14659907055344318,
            "2": 0.37307152875175315,
            "3": 0.5231130843562288,
            "4": 0.7878787878787878,
            "5": 0.7692307692307693,
            "6": 0.9,
            "7": 0.875,
            "8": 0,
            "9": 1.0
        },
        "nist": 1.9220528040375504,
        "rouge1": {
            "precision": 0.22516,
            "recall": 0.17136,
            "fmeasure": 0.18606
        },
        "rouge2": {
            "precision": 0.09303,
            "recall": 0.06024,
            "fmeasure": 0.06848
        },
        "rougeL": {
            "precision": 0.2175,
            "recall": 0.16523,
            "fmeasure": 0.17942
        },
        "rougeLsum": {
            "precision": 0.2175,
            "recall": 0.16523,
            "fmeasure": 0.17942
        },
        "bleu": 23.26756,
        "nubia": {
            "semantic_relation": 3.64475,
            "contradiction": 22.17838,
            "irrelevancy": 21.72792,
            "logical_agreement": 56.0937,
            "grammar_ref": 2.60252,
            "grammar_hyp": 2.69376,
            "nubia_score": 0.7092
        },
        "bleurt": 0.10135,
        "meteor": 0.402827508747248,
        "bertscore": {
            "precision": 0.95101,
            "recall": 0.91622,
            "f1": 0.93235
        }
    },
    "web_nlg_ru_test": {
        "predictions_file": "ByT5-small (Baseline)/web_nlg_ru_test",
        "N": 1102,
        "msttr-100": 0.77573,
        "msttr-100_nopunct": 0.85257,
        "total_length": 12459,
        "mean_pred_length": 11.305807622504537,
        "std_pred_length": 2.8934406749400328,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 21,
        "distinct-1": 0.20571474436150575,
        "vocab_size-1": 2563,
        "unique-1": 1300,
        "entropy-1": 9.143715939072797,
        "distinct-2": 0.49106278066390774,
        "vocab_size-2": 5577,
        "unique-2": 3746,
        "entropy-2": 11.754730779349128,
        "cond_entropy-2": 2.6634551293295337,
        "distinct-3": 0.6862993661628474,
        "vocab_size-3": 7038,
        "unique-3": 5486,
        "entropy-3": 12.476242464390518,
        "cond_entropy-3": 0.8350144853297948,
        "total_length-nopunct": 10514,
        "mean_pred_length-nopunct": 9.540834845735027,
        "std_pred_length-nopunct": 2.5260282864129913,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.24300932090545938,
        "vocab_size-1-nopunct": 2555,
        "unique-1-nopunct": 1299,
        "entropy-1-nopunct": 9.723863927932445,
        "distinct-2-nopunct": 0.5432426689332767,
        "vocab_size-2-nopunct": 5113,
        "unique-2-nopunct": 3640,
        "entropy-2-nopunct": 11.717720076303157,
        "cond_entropy-2-nopunct": 2.2079031057139815,
        "distinct-3-nopunct": 0.7215403128760529,
        "vocab_size-3-nopunct": 5996,
        "unique-3-nopunct": 4854,
        "entropy-3-nopunct": 12.267150436744583,
        "cond_entropy-3-nopunct": 0.6797312874061529,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "local_recall": {
            "1": 0.1662265362929127,
            "2": 0.3546167606990505,
            "3": 0.4836723269266654,
            "4": 0.6493506493506493,
            "5": 0.6486486486486487,
            "6": 0.9230769230769231,
            "7": 1.0
        },
        "nist": 1.7165794939087418,
        "rouge1": {
            "precision": 0.27504,
            "recall": 0.22551,
            "fmeasure": 0.23884
        },
        "rouge2": {
            "precision": 0.12678,
            "recall": 0.09985,
            "fmeasure": 0.10624
        },
        "rougeL": {
            "precision": 0.26954,
            "recall": 0.22087,
            "fmeasure": 0.23383
        },
        "rougeLsum": {
            "precision": 0.26954,
            "recall": 0.22087,
            "fmeasure": 0.23383
        },
        "bleu": 22.30663,
        "nubia": {
            "semantic_relation": 3.59829,
            "contradiction": 21.55323,
            "irrelevancy": 22.36571,
            "logical_agreement": 56.08106,
            "grammar_ref": 2.65213,
            "grammar_hyp": 2.73191,
            "nubia_score": 0.69837
        },
        "bleurt": 0.10188,
        "meteor": 0.3996410441399222,
        "bertscore": {
            "precision": 0.95095,
            "recall": 0.91355,
            "f1": 0.93101
        }
    }
}
