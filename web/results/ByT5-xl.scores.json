{
    "submission_name": "ByT5-xl (Baseline)",
    "param_count": 0,
    "web_nlg_ru_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 4,
        "mean_pred_length": 4.0,
        "std_pred_length": 0.0,
        "median_pred_length": 4.0,
        "min_pred_length": 4,
        "max_pred_length": 4,
        "distinct-1": 0.75,
        "vocab_size-1": 3,
        "unique-1": 2,
        "entropy-1": 1.5,
        "distinct-2": 1.0,
        "vocab_size-2": 3,
        "unique-2": 3,
        "entropy-2": 1.584962500721156,
        "cond_entropy-2": 0.2516291673878229,
        "distinct-3": 1.0,
        "vocab_size-3": 2,
        "unique-3": 2,
        "entropy-3": 1.0,
        "cond_entropy-3": -0.5849625007211562,
        "total_length-nopunct": 2,
        "mean_pred_length-nopunct": 2.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 2.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 2,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 2,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 1.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 1,
        "unique-2-nopunct": 1,
        "entropy-2-nopunct": -0.0,
        "cond_entropy-2-nopunct": -1.0,
        "distinct-3-nopunct": 0,
        "vocab_size-3-nopunct": 0,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 0,
        "cond_entropy-3-nopunct": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.0,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "bleu": 2.28825,
        "local_recall": {
            "1": 0.0,
            "2": 0.0
        },
        "bertscore": {
            "precision": 0.56595,
            "recall": 0.52192,
            "f1": 0.54305
        },
        "nubia": {
            "semantic_relation": 1.44725,
            "contradiction": 43.58248,
            "irrelevancy": 50.23958,
            "logical_agreement": 6.17794,
            "grammar_ref": 2.53664,
            "grammar_hyp": 7.50768,
            "nubia_score": 0.04787
        },
        "meteor": 0.0,
        "bleurt": -1.49026
    },
    "totto_test_contrast_challenge_input_size-input_length_18": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.74,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 20.8,
        "std_pred_length": 2.7129319932501073,
        "median_pred_length": 20.0,
        "min_pred_length": 18,
        "max_pred_length": 24,
        "distinct-1": 0.7307692307692307,
        "vocab_size-1": 76,
        "unique-1": 62,
        "entropy-1": 5.99721444977795,
        "distinct-2": 0.9797979797979798,
        "vocab_size-2": 97,
        "unique-2": 95,
        "entropy-2": 6.588952579675579,
        "cond_entropy-2": 0.579225390904212,
        "distinct-3": 1.0,
        "vocab_size-3": 94,
        "unique-3": 94,
        "entropy-3": 6.554588851677623,
        "cond_entropy-3": -0.03221457691261054,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 17.6,
        "std_pred_length-nopunct": 1.2,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8068181818181818,
        "vocab_size-1-nopunct": 71,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 5.982452431693699,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.375039431346932,
        "cond_entropy-2-nopunct": 0.4092724928426041,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.285402218862257,
        "cond_entropy-3-nopunct": -0.08963721248467645,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2085384505539034,
        "rouge1": {
            "precision": 0.67553,
            "recall": 0.53008,
            "fmeasure": 0.56727
        },
        "rouge2": {
            "precision": 0.42961,
            "recall": 0.35678,
            "fmeasure": 0.3687
        },
        "rougeL": {
            "precision": 0.61834,
            "recall": 0.49281,
            "fmeasure": 0.52396
        },
        "rougeLsum": {
            "precision": 0.61834,
            "recall": 0.49281,
            "fmeasure": 0.52396
        },
        "bleu": 21.49159,
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.5238095238095238,
            "3": 0.5333333333333333
        },
        "bertscore": {
            "precision": 0.88002,
            "recall": 0.88153,
            "f1": 0.87982
        },
        "nubia": {
            "semantic_relation": 2.97466,
            "contradiction": 23.2132,
            "irrelevancy": 44.65544,
            "logical_agreement": 32.13137,
            "grammar_ref": 3.87874,
            "grammar_hyp": 4.05474,
            "nubia_score": 0.37512
        },
        "meteor": 0.24910324898283792,
        "bleurt": -0.22699
    },
    "totto_test_contrast_challenge_input_size-input_length_60": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.0,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 20,
        "unique-1": 14,
        "entropy-1": 4.182005814760214,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 24,
        "unique-2": 22,
        "entropy-2": 4.546593564294937,
        "cond_entropy-2": 0.33576845009606227,
        "distinct-3": 0.9583333333333334,
        "vocab_size-3": 23,
        "unique-3": 22,
        "entropy-3": 4.501629167387823,
        "cond_entropy-3": -0.03214388408660257,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7307692307692307,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.103909910282363,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.418295834054489,
        "cond_entropy-2-nopunct": 0.36409674109368645,
        "distinct-3-nopunct": 0.9545454545454546,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.368522527728205,
        "cond_entropy-3-nopunct": -0.03462179117476818,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4438169777820913,
        "rouge1": {
            "precision": 0.73958,
            "recall": 0.66138,
            "fmeasure": 0.69661
        },
        "rouge2": {
            "precision": 0.58889,
            "recall": 0.53651,
            "fmeasure": 0.55974
        },
        "rougeL": {
            "precision": 0.67708,
            "recall": 0.63517,
            "fmeasure": 0.65415
        },
        "rougeLsum": {
            "precision": 0.67708,
            "recall": 0.63517,
            "fmeasure": 0.65415
        },
        "bleu": 49.10327,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.8921,
            "recall": 0.88821,
            "f1": 0.88741
        },
        "nubia": {
            "semantic_relation": 3.51706,
            "contradiction": 27.87283,
            "irrelevancy": 16.4026,
            "logical_agreement": 55.72458,
            "grammar_ref": 4.80653,
            "grammar_hyp": 4.74528,
            "nubia_score": 0.45996
        },
        "meteor": 0.31572930911809194,
        "bleurt": -0.00878
    },
    "totto_test_contrast_challenge_input_size-input_length_75": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.3030582957845047,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.17708,
            "fmeasure": 0.23111
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.17708,
            "fmeasure": 0.23111
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.17708,
            "fmeasure": 0.23111
        },
        "bleu": 4.95597,
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "bertscore": {
            "precision": 0.85009,
            "recall": 0.80794,
            "f1": 0.82848
        },
        "nubia": {
            "semantic_relation": 2.19992,
            "contradiction": 7.93984,
            "irrelevancy": 10.48028,
            "logical_agreement": 81.57989,
            "grammar_ref": 4.60656,
            "grammar_hyp": 5.51374,
            "nubia_score": 0.16638
        },
        "meteor": 0.1347049328308017,
        "bleurt": 0.07417
    },
    "totto_test_contrast_challenge_table_size-table_size_32": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 49,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "total_length": 837,
        "mean_pred_length": 17.081632653061224,
        "std_pred_length": 5.442976131784768,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.5412186379928315,
        "vocab_size-1": 453,
        "unique-1": 382,
        "entropy-1": 7.677334872887023,
        "distinct-2": 0.9213197969543148,
        "vocab_size-2": 726,
        "unique-2": 690,
        "entropy-2": 9.41361948211732,
        "cond_entropy-2": 1.5295110819581788,
        "distinct-3": 0.9810554803788903,
        "vocab_size-3": 725,
        "unique-3": 714,
        "entropy-3": 9.488477018954514,
        "cond_entropy-3": 0.07243965392761208,
        "total_length-nopunct": 713,
        "mean_pred_length-nopunct": 14.551020408163266,
        "std_pred_length-nopunct": 4.806718191770109,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6227208976157083,
        "vocab_size-1-nopunct": 444,
        "unique-1-nopunct": 379,
        "entropy-1-nopunct": 7.913413359897104,
        "distinct-2-nopunct": 0.9427710843373494,
        "vocab_size-2-nopunct": 626,
        "unique-2-nopunct": 605,
        "entropy-2-nopunct": 9.213706198900494,
        "cond_entropy-2-nopunct": 1.3874886415916479,
        "distinct-3-nopunct": 0.9902439024390244,
        "vocab_size-3-nopunct": 609,
        "unique-3-nopunct": 604,
        "entropy-3-nopunct": 9.243702945751561,
        "cond_entropy-3-nopunct": 0.03254224016331955,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.14707114361393,
        "rouge1": {
            "precision": 0.78113,
            "recall": 0.715,
            "fmeasure": 0.73457
        },
        "rouge2": {
            "precision": 0.55432,
            "recall": 0.5063,
            "fmeasure": 0.51943
        },
        "rougeL": {
            "precision": 0.68437,
            "recall": 0.62502,
            "fmeasure": 0.6425
        },
        "rougeLsum": {
            "precision": 0.68437,
            "recall": 0.62502,
            "fmeasure": 0.6425
        },
        "bleu": 48.35024,
        "local_recall": {
            "1": 0.21649484536082475,
            "2": 0.3930635838150289,
            "3": 0.7836812144212524
        },
        "bertscore": {
            "precision": 0.94161,
            "recall": 0.92503,
            "f1": 0.9309
        },
        "nubia": {
            "semantic_relation": 4.27468,
            "contradiction": 5.3461,
            "irrelevancy": 26.55613,
            "logical_agreement": 68.09777,
            "grammar_ref": 4.75318,
            "grammar_hyp": 4.80496,
            "nubia_score": 0.74938
        },
        "meteor": 0.39354563923082614,
        "bleurt": 0.29219
    },
    "totto_test_contrast_challenge_input_size-input_length_100": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.046930949929641655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.68420062859993,
        "rouge1": {
            "precision": 0.60714,
            "recall": 0.6,
            "fmeasure": 0.58578
        },
        "rouge2": {
            "precision": 0.34615,
            "recall": 0.3538,
            "fmeasure": 0.33807
        },
        "rougeL": {
            "precision": 0.39286,
            "recall": 0.375,
            "fmeasure": 0.37255
        },
        "rougeLsum": {
            "precision": 0.39286,
            "recall": 0.375,
            "fmeasure": 0.37255
        },
        "bleu": 30.21375,
        "local_recall": {
            "1": 0.4,
            "2": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.87291,
            "recall": 0.86852,
            "f1": 0.87071
        },
        "nubia": {
            "semantic_relation": 3.13905,
            "contradiction": 71.70672,
            "irrelevancy": 23.18222,
            "logical_agreement": 5.11106,
            "grammar_ref": 5.69136,
            "grammar_hyp": 5.20472,
            "nubia_score": 0.35398
        },
        "meteor": 0.3555524229843264,
        "bleurt": 0.10605
    },
    "totto_test_contrast_challenge_table_size-table_size_13": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.572,
        "msttr-100_nopunct": 0.61,
        "total_length": 520,
        "mean_pred_length": 14.857142857142858,
        "std_pred_length": 4.4666565133400695,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.3730769230769231,
        "vocab_size-1": 194,
        "unique-1": 152,
        "entropy-1": 6.433037259502879,
        "distinct-2": 0.7030927835051546,
        "vocab_size-2": 341,
        "unique-2": 295,
        "entropy-2": 8.056608546614404,
        "cond_entropy-2": 1.4537833134432108,
        "distinct-3": 0.8244444444444444,
        "vocab_size-3": 371,
        "unique-3": 343,
        "entropy-3": 8.31311598431953,
        "cond_entropy-3": 0.2623555470645177,
        "total_length-nopunct": 441,
        "mean_pred_length-nopunct": 12.6,
        "std_pred_length-nopunct": 3.8855041960011905,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.42857142857142855,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 152,
        "entropy-1-nopunct": 6.503954912999967,
        "distinct-2-nopunct": 0.7315270935960592,
        "vocab_size-2-nopunct": 297,
        "unique-2-nopunct": 260,
        "entropy-2-nopunct": 7.893114250802752,
        "cond_entropy-2-nopunct": 1.4783645772928133,
        "distinct-3-nopunct": 0.8221024258760108,
        "vocab_size-3-nopunct": 305,
        "unique-3-nopunct": 281,
        "entropy-3-nopunct": 8.030468555400024,
        "cond_entropy-3-nopunct": 0.1887342885291352,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.4241825132516235,
        "rouge1": {
            "precision": 0.78856,
            "recall": 0.73266,
            "fmeasure": 0.75246
        },
        "rouge2": {
            "precision": 0.58246,
            "recall": 0.53534,
            "fmeasure": 0.55291
        },
        "rougeL": {
            "precision": 0.69991,
            "recall": 0.65216,
            "fmeasure": 0.66921
        },
        "rougeLsum": {
            "precision": 0.69991,
            "recall": 0.65216,
            "fmeasure": 0.66921
        },
        "bleu": 53.08911,
        "local_recall": {
            "1": 0.13793103448275862,
            "2": 0.4326923076923077,
            "3": 0.7579250720461095
        },
        "bertscore": {
            "precision": 0.94019,
            "recall": 0.92688,
            "f1": 0.93216
        },
        "nubia": {
            "semantic_relation": 4.06487,
            "contradiction": 2.55293,
            "irrelevancy": 21.56152,
            "logical_agreement": 75.88555,
            "grammar_ref": 4.23324,
            "grammar_hyp": 4.06693,
            "nubia_score": 0.75697
        },
        "meteor": 0.4210614400039269,
        "bleurt": 0.42901
    },
    "totto_test_contrast_challenge_table_size-table_size_51": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.81,
        "total_length": 175,
        "mean_pred_length": 15.909090909090908,
        "std_pred_length": 3.629539050486751,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.6685714285714286,
        "vocab_size-1": 117,
        "unique-1": 99,
        "entropy-1": 6.3615037653184245,
        "distinct-2": 0.9573170731707317,
        "vocab_size-2": 157,
        "unique-2": 151,
        "entropy-2": 7.267583178385399,
        "cond_entropy-2": 0.747134492375738,
        "distinct-3": 1.0,
        "vocab_size-3": 153,
        "unique-3": 153,
        "entropy-3": 7.257387842692632,
        "cond_entropy-3": -0.003726988708677181,
        "total_length-nopunct": 153,
        "mean_pred_length-nopunct": 13.909090909090908,
        "std_pred_length-nopunct": 2.937362622073366,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7320261437908496,
        "vocab_size-1-nopunct": 112,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.401220827133701,
        "distinct-2-nopunct": 0.9577464788732394,
        "vocab_size-2-nopunct": 136,
        "unique-2-nopunct": 131,
        "entropy-2-nopunct": 7.0599239680810015,
        "cond_entropy-2-nopunct": 0.7250259379271995,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 131,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.03342300153745,
        "cond_entropy-3-nopunct": -0.018958564515602266,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.919176809951546,
        "rouge1": {
            "precision": 0.73013,
            "recall": 0.77963,
            "fmeasure": 0.7445
        },
        "rouge2": {
            "precision": 0.521,
            "recall": 0.57002,
            "fmeasure": 0.53666
        },
        "rougeL": {
            "precision": 0.63049,
            "recall": 0.68452,
            "fmeasure": 0.64632
        },
        "rougeLsum": {
            "precision": 0.63049,
            "recall": 0.68452,
            "fmeasure": 0.64632
        },
        "bleu": 52.33074,
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.5806451612903226,
            "3": 0.8478260869565217
        },
        "bertscore": {
            "precision": 0.92823,
            "recall": 0.94067,
            "f1": 0.9305
        },
        "nubia": {
            "semantic_relation": 4.07534,
            "contradiction": 10.59058,
            "irrelevancy": 50.59484,
            "logical_agreement": 38.81458,
            "grammar_ref": 4.58752,
            "grammar_hyp": 4.43442,
            "nubia_score": 0.70004
        },
        "meteor": 0.43500187074422925,
        "bleurt": 0.20668
    },
    "totto_test_contrast_challenge_input_size-input_length_123": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846627,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.0838941553983285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8824942985331738,
        "rouge1": {
            "precision": 0.56818,
            "recall": 0.31061,
            "fmeasure": 0.39336
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.10856,
            "fmeasure": 0.14667
        },
        "rougeL": {
            "precision": 0.47727,
            "recall": 0.24394,
            "fmeasure": 0.31643
        },
        "rougeLsum": {
            "precision": 0.47727,
            "recall": 0.24394,
            "fmeasure": 0.31643
        },
        "bleu": 31.03865,
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.36363636363636365
        },
        "bertscore": {
            "precision": 0.92161,
            "recall": 0.83997,
            "f1": 0.8686
        },
        "nubia": {
            "semantic_relation": 2.35965,
            "contradiction": 96.9334,
            "irrelevancy": 1.80309,
            "logical_agreement": 1.26351,
            "grammar_ref": 4.34131,
            "grammar_hyp": 4.7089,
            "nubia_score": 0.1317
        },
        "meteor": 0.14085002463506155,
        "bleurt": -0.12412
    },
    "totto_test_contrast_challenge_input_size-input_length_125": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.7871439606981383,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.40838012700780835,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.452819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.4905497624194164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0492695860968664,
        "rouge1": {
            "precision": 0.25,
            "recall": 0.28356,
            "fmeasure": 0.26472
        },
        "rouge2": {
            "precision": 0.06667,
            "recall": 0.07639,
            "fmeasure": 0.07089
        },
        "rougeL": {
            "precision": 0.22917,
            "recall": 0.23379,
            "fmeasure": 0.23058
        },
        "rougeLsum": {
            "precision": 0.22917,
            "recall": 0.23379,
            "fmeasure": 0.23058
        },
        "bleu": 5.09121,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.64186,
            "recall": 0.62649,
            "f1": 0.63408
        },
        "nubia": {
            "semantic_relation": 0.94354,
            "contradiction": 44.5465,
            "irrelevancy": 50.01547,
            "logical_agreement": 5.43804,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.54688,
            "nubia_score": 0.09829
        },
        "meteor": 0.11015333541717581,
        "bleurt": -0.93364
    },
    "totto_test_contrast_challenge_input_size-input_length_127": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.98168498643785,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "rouge2": {
            "precision": 0.64103,
            "recall": 0.65598,
            "fmeasure": 0.64821
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.85348,
            "fmeasure": 0.84303
        },
        "bleu": 68.92147,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.9
        },
        "bertscore": {
            "precision": 0.9623,
            "recall": 0.97357,
            "f1": 0.9679
        },
        "nubia": {
            "semantic_relation": 2.69446,
            "contradiction": 69.7633,
            "irrelevancy": 26.34867,
            "logical_agreement": 3.88803,
            "grammar_ref": 4.48671,
            "grammar_hyp": 4.14011,
            "nubia_score": 0.31661
        },
        "meteor": 0.47142184089545913,
        "bleurt": 0.32071
    },
    "totto_test_contrast_challenge_input_size-input_length_133": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4393391687433206,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.25,
            "fmeasure": 0.27586
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "bleu": 20.23303,
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "bertscore": {
            "precision": 0.83042,
            "recall": 0.80138,
            "f1": 0.81564
        },
        "nubia": {
            "semantic_relation": 2.2186,
            "contradiction": 83.60095,
            "irrelevancy": 15.37269,
            "logical_agreement": 1.02636,
            "grammar_ref": 4.28272,
            "grammar_hyp": 5.02915,
            "nubia_score": 0.13573
        },
        "meteor": 0.21934554315268176,
        "bleurt": -0.35456
    },
    "totto_test_contrast_challenge_input_size-input_length_19": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "total_length": 102,
        "mean_pred_length": 20.4,
        "std_pred_length": 4.923413450036469,
        "median_pred_length": 23.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 78,
        "unique-1": 66,
        "entropy-1": 6.061830489643127,
        "distinct-2": 1.0,
        "vocab_size-2": 97,
        "unique-2": 97,
        "entropy-2": 6.599912842187142,
        "cond_entropy-2": 0.5489377573031982,
        "distinct-3": 1.0,
        "vocab_size-3": 92,
        "unique-3": 92,
        "entropy-3": 6.523561956057027,
        "cond_entropy-3": -0.07635088613011487,
        "total_length-nopunct": 91,
        "mean_pred_length-nopunct": 18.2,
        "std_pred_length-nopunct": 4.534313619501853,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8131868131868132,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 6.061320019505395,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.426264754702099,
        "cond_entropy-2-nopunct": 0.39090256198120066,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.339850002884614,
        "cond_entropy-3-nopunct": -0.08641475181747339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9024159560182197,
        "rouge1": {
            "precision": 0.5221,
            "recall": 0.54816,
            "fmeasure": 0.52942
        },
        "rouge2": {
            "precision": 0.30588,
            "recall": 0.30637,
            "fmeasure": 0.30305
        },
        "rougeL": {
            "precision": 0.44208,
            "recall": 0.46193,
            "fmeasure": 0.44725
        },
        "rougeLsum": {
            "precision": 0.44208,
            "recall": 0.46193,
            "fmeasure": 0.44725
        },
        "bleu": 22.76933,
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.48484848484848486,
            "3": 0.6571428571428571
        },
        "bertscore": {
            "precision": 0.88096,
            "recall": 0.88209,
            "f1": 0.87824
        },
        "nubia": {
            "semantic_relation": 3.1184,
            "contradiction": 57.92509,
            "irrelevancy": 28.79625,
            "logical_agreement": 13.27866,
            "grammar_ref": 5.00025,
            "grammar_hyp": 4.63765,
            "nubia_score": 0.43324
        },
        "meteor": 0.28713276974593177,
        "bleurt": -0.08915
    },
    "totto_test_contrast_challenge_input_size-input_length_496": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 3.9318384571684564,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.554489684145594,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6461961952602273,
        "rouge1": {
            "precision": 0.29412,
            "recall": 0.16129,
            "fmeasure": 0.20833
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.13725,
            "recall": 0.16559,
            "fmeasure": 0.14043
        },
        "rougeLsum": {
            "precision": 0.13725,
            "recall": 0.16559,
            "fmeasure": 0.14043
        },
        "bleu": 4.79665,
        "local_recall": {
            "1": 0.0,
            "2": 0.21428571428571427,
            "3": 0.2222222222222222
        },
        "bertscore": {
            "precision": 0.82205,
            "recall": 0.78916,
            "f1": 0.78715
        },
        "nubia": {
            "semantic_relation": 1.75534,
            "contradiction": 64.96058,
            "irrelevancy": 32.06776,
            "logical_agreement": 2.97166,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.11132,
            "nubia_score": 0.15494
        },
        "meteor": 0.10346366664144258,
        "bleurt": -0.73841
    },
    "totto_test_contrast_challenge_continent-oceania": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.71467,
        "msttr-100_nopunct": 0.77692,
        "total_length": 1595,
        "mean_pred_length": 15.19047619047619,
        "std_pred_length": 4.93596179288917,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.4664576802507837,
        "vocab_size-1": 744,
        "unique-1": 596,
        "entropy-1": 7.987356474962343,
        "distinct-2": 0.8557046979865772,
        "vocab_size-2": 1275,
        "unique-2": 1182,
        "entropy-2": 10.113574674198206,
        "cond_entropy-2": 1.8690962097608452,
        "distinct-3": 0.9574007220216606,
        "vocab_size-3": 1326,
        "unique-3": 1295,
        "entropy-3": 10.32846617291119,
        "cond_entropy-3": 0.22888429930281923,
        "total_length-nopunct": 1395,
        "mean_pred_length-nopunct": 13.285714285714286,
        "std_pred_length-nopunct": 4.710099151143789,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5283154121863799,
        "vocab_size-1-nopunct": 737,
        "unique-1-nopunct": 595,
        "entropy-1-nopunct": 8.290885388949835,
        "distinct-2-nopunct": 0.875968992248062,
        "vocab_size-2-nopunct": 1130,
        "unique-2-nopunct": 1062,
        "entropy-2-nopunct": 9.950841356176609,
        "cond_entropy-2-nopunct": 1.7879929726665889,
        "distinct-3-nopunct": 0.980590717299578,
        "vocab_size-3-nopunct": 1162,
        "unique-3-nopunct": 1144,
        "entropy-3-nopunct": 10.1682539070713,
        "cond_entropy-3-nopunct": 0.241512134762386,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.714701153941435,
        "rouge1": {
            "precision": 0.8092,
            "recall": 0.75368,
            "fmeasure": 0.77027
        },
        "rouge2": {
            "precision": 0.56555,
            "recall": 0.52574,
            "fmeasure": 0.53691
        },
        "rougeL": {
            "precision": 0.70514,
            "recall": 0.65695,
            "fmeasure": 0.67061
        },
        "rougeLsum": {
            "precision": 0.70514,
            "recall": 0.65695,
            "fmeasure": 0.67061
        },
        "bleu": 46.11386,
        "local_recall": {
            "1": 0.189873417721519,
            "2": 0.2966101694915254,
            "3": 0.7865072587532024
        },
        "bertscore": {
            "precision": 0.93916,
            "recall": 0.93539,
            "f1": 0.93643
        },
        "nubia": {
            "semantic_relation": 4.43094,
            "contradiction": 7.95788,
            "irrelevancy": 25.60229,
            "logical_agreement": 66.43982,
            "grammar_ref": 5.02637,
            "grammar_hyp": 5.11874,
            "nubia_score": 0.77528
        },
        "meteor": 0.39961247875923567,
        "bleurt": 0.35057
    },
    "totto_test_contrast_challenge_input_size-input_length_20": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 20.8,
        "std_pred_length": 5.418486873657627,
        "median_pred_length": 24.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.7019230769230769,
        "vocab_size-1": 73,
        "unique-1": 59,
        "entropy-1": 5.868675357910156,
        "distinct-2": 0.9191919191919192,
        "vocab_size-2": 91,
        "unique-2": 85,
        "entropy-2": 6.452490205894497,
        "cond_entropy-2": 0.6056211288040823,
        "distinct-3": 0.9787234042553191,
        "vocab_size-3": 92,
        "unique-3": 90,
        "entropy-3": 6.512035660188264,
        "cond_entropy-3": 0.06895324228235698,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 4.898979485566356,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.843605940334201,
        "distinct-2-nopunct": 0.9222222222222223,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.319522262948253,
        "cond_entropy-2-nopunct": 0.5162635263916605,
        "distinct-3-nopunct": 0.9882352941176471,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.385861524373001,
        "cond_entropy-3-nopunct": 0.07647636927069687,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.87549891549971,
        "rouge1": {
            "precision": 0.50606,
            "recall": 0.3548,
            "fmeasure": 0.41113
        },
        "rouge2": {
            "precision": 0.2801,
            "recall": 0.21244,
            "fmeasure": 0.23762
        },
        "rougeL": {
            "precision": 0.42905,
            "recall": 0.3058,
            "fmeasure": 0.3516
        },
        "rougeLsum": {
            "precision": 0.42905,
            "recall": 0.3058,
            "fmeasure": 0.3516
        },
        "bleu": 8.52978,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.125,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.85143,
            "recall": 0.78007,
            "f1": 0.81326
        },
        "nubia": {
            "semantic_relation": 2.68679,
            "contradiction": 11.78941,
            "irrelevancy": 48.0592,
            "logical_agreement": 40.15138,
            "grammar_ref": 4.13756,
            "grammar_hyp": 4.354,
            "nubia_score": 0.30497
        },
        "meteor": 0.16361074422115507,
        "bleurt": -0.42371
    },
    "totto_test_contrast_challenge_input_size-input_length_21": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 21.0,
        "std_pred_length": 5.385164807134504,
        "median_pred_length": 23.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.7738095238095238,
        "vocab_size-1": 65,
        "unique-1": 53,
        "entropy-1": 5.841547631034827,
        "distinct-2": 0.9625,
        "vocab_size-2": 77,
        "unique-2": 75,
        "entropy-2": 6.237492001110313,
        "cond_entropy-2": 0.41098285966268877,
        "distinct-3": 1.0,
        "vocab_size-3": 76,
        "unique-3": 76,
        "entropy-3": 6.247927513443591,
        "cond_entropy-3": 0.014879517268900399,
        "total_length-nopunct": 77,
        "mean_pred_length-nopunct": 19.25,
        "std_pred_length-nopunct": 5.11737237261468,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7922077922077922,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.7536725795997485,
        "distinct-2-nopunct": 0.9726027397260274,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.124689113644912,
        "cond_entropy-2-nopunct": 0.38543373739283526,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 69,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.108524456778164,
        "cond_entropy-3-nopunct": -0.012388689027015374,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0591929029359695,
        "rouge1": {
            "precision": 0.611,
            "recall": 0.4788,
            "fmeasure": 0.51189
        },
        "rouge2": {
            "precision": 0.38869,
            "recall": 0.31077,
            "fmeasure": 0.32402
        },
        "rougeL": {
            "precision": 0.53637,
            "recall": 0.42387,
            "fmeasure": 0.44947
        },
        "rougeLsum": {
            "precision": 0.53637,
            "recall": 0.42387,
            "fmeasure": 0.44947
        },
        "bleu": 14.41651,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.47619047619047616
        },
        "bertscore": {
            "precision": 0.8576,
            "recall": 0.83362,
            "f1": 0.8444
        },
        "nubia": {
            "semantic_relation": 2.90624,
            "contradiction": 1.16095,
            "irrelevancy": 74.26242,
            "logical_agreement": 24.57663,
            "grammar_ref": 3.12827,
            "grammar_hyp": 3.7629,
            "nubia_score": 0.34372
        },
        "meteor": 0.19428074241283735,
        "bleurt": -0.33189
    },
    "totto_test_contrast_challenge_input_size-input_length_22": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.3198117763586169,
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.23387,
            "fmeasure": 0.32122
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.06883,
            "fmeasure": 0.07778
        },
        "rougeL": {
            "precision": 0.30556,
            "recall": 0.20476,
            "fmeasure": 0.24359
        },
        "rougeLsum": {
            "precision": 0.30556,
            "recall": 0.20476,
            "fmeasure": 0.24359
        },
        "bleu": 6.94205,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.0,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.89777,
            "recall": 0.88033,
            "f1": 0.8766
        },
        "nubia": {
            "semantic_relation": 3.97116,
            "contradiction": 40.93076,
            "irrelevancy": 29.61273,
            "logical_agreement": 29.45651,
            "grammar_ref": 4.03834,
            "grammar_hyp": 4.16624,
            "nubia_score": 0.60349
        },
        "meteor": 0.15476118719658413,
        "bleurt": 0.09092
    },
    "totto_test_contrast_challenge_input_size-input_length_23": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 27.0,
        "std_pred_length": 2.0,
        "median_pred_length": 27.0,
        "min_pred_length": 25,
        "max_pred_length": 29,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 42,
        "unique-1": 38,
        "entropy-1": 5.088220835496801,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 51,
        "unique-2": 50,
        "entropy-2": 5.661978179679556,
        "cond_entropy-2": 0.5993983698237771,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.016583528366367516,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8913043478260869,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.262692390839619,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.20859693530755724,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.0671141958585368,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6206297521541,
        "rouge1": {
            "precision": 0.445,
            "recall": 0.42091,
            "fmeasure": 0.43172
        },
        "rouge2": {
            "precision": 0.2193,
            "recall": 0.18537,
            "fmeasure": 0.19962
        },
        "rougeL": {
            "precision": 0.32,
            "recall": 0.31863,
            "fmeasure": 0.31884
        },
        "rougeLsum": {
            "precision": 0.32,
            "recall": 0.31863,
            "fmeasure": 0.31884
        },
        "bleu": 18.59883,
        "local_recall": {
            "1": 0.0,
            "2": 0.2857142857142857,
            "3": 0.631578947368421
        },
        "bertscore": {
            "precision": 0.84956,
            "recall": 0.86978,
            "f1": 0.85778
        },
        "nubia": {
            "semantic_relation": 2.66499,
            "contradiction": 78.32513,
            "irrelevancy": 16.91215,
            "logical_agreement": 4.76272,
            "grammar_ref": 4.17,
            "grammar_hyp": 3.70694,
            "nubia_score": 0.3447
        },
        "meteor": 0.2184816728909852,
        "bleurt": -0.21267
    },
    "totto_test_contrast_challenge_input_size-input_length_24": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": 0.68,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 27.25,
        "std_pred_length": 2.947456530637899,
        "median_pred_length": 26.5,
        "min_pred_length": 24,
        "max_pred_length": 32,
        "distinct-1": 0.6605504587155964,
        "vocab_size-1": 72,
        "unique-1": 58,
        "entropy-1": 5.764897660223792,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 95,
        "unique-2": 89,
        "entropy-2": 6.482202394079445,
        "cond_entropy-2": 0.7213826782127191,
        "distinct-3": 0.9702970297029703,
        "vocab_size-3": 98,
        "unique-3": 95,
        "entropy-3": 6.59880554215772,
        "cond_entropy-3": 0.1028035876768895,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 21.5,
        "std_pred_length-nopunct": 2.598076211353316,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7906976744186046,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.924876202623451,
        "distinct-2-nopunct": 0.975609756097561,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.3087715168132075,
        "cond_entropy-2-nopunct": 0.4083532923399341,
        "distinct-3-nopunct": 0.9871794871794872,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.25976119322123,
        "cond_entropy-3-nopunct": -0.04650876011480937,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.66269963519704,
        "rouge1": {
            "precision": 0.66858,
            "recall": 0.54952,
            "fmeasure": 0.5824
        },
        "rouge2": {
            "precision": 0.46638,
            "recall": 0.37905,
            "fmeasure": 0.40317
        },
        "rougeL": {
            "precision": 0.55136,
            "recall": 0.44637,
            "fmeasure": 0.4775
        },
        "rougeLsum": {
            "precision": 0.55136,
            "recall": 0.44637,
            "fmeasure": 0.4775
        },
        "bleu": 40.63555,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.4318181818181818,
            "3": 0.543859649122807
        },
        "bertscore": {
            "precision": 0.87876,
            "recall": 0.88547,
            "f1": 0.8801
        },
        "nubia": {
            "semantic_relation": 3.18603,
            "contradiction": 9.74097,
            "irrelevancy": 58.91575,
            "logical_agreement": 31.34328,
            "grammar_ref": 4.25341,
            "grammar_hyp": 4.64695,
            "nubia_score": 0.38565
        },
        "meteor": 0.2997907883043283,
        "bleurt": -0.38311
    },
    "totto_test_contrast_challenge_input_size-input_length_25": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728204,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.02812389937955851,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.033108599109837954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1547733329846315,
        "rouge1": {
            "precision": 0.42105,
            "recall": 0.5,
            "fmeasure": 0.45714
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.2,
            "fmeasure": 0.18182
        },
        "rougeL": {
            "precision": 0.36842,
            "recall": 0.4375,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.36842,
            "recall": 0.4375,
            "fmeasure": 0.4
        },
        "bleu": 9.61427,
        "local_recall": {
            "1": 0.2,
            "2": 0.5714285714285714,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.78278,
            "recall": 0.83693,
            "f1": 0.80895
        },
        "nubia": {
            "semantic_relation": 2.63683,
            "contradiction": 41.86527,
            "irrelevancy": 39.9062,
            "logical_agreement": 18.22854,
            "grammar_ref": 3.92881,
            "grammar_hyp": 2.78828,
            "nubia_score": 0.43876
        },
        "meteor": 0.18214527487356877,
        "bleurt": -0.21631
    },
    "totto_test_contrast_challenge_table_size-table_size_14": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.71083,
        "msttr-100_nopunct": 0.76,
        "total_length": 1295,
        "mean_pred_length": 16.39240506329114,
        "std_pred_length": 5.563028319996968,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.42625482625482625,
        "vocab_size-1": 552,
        "unique-1": 425,
        "entropy-1": 7.775376766300043,
        "distinct-2": 0.7738486842105263,
        "vocab_size-2": 941,
        "unique-2": 845,
        "entropy-2": 9.565220967508344,
        "cond_entropy-2": 1.5790636391368906,
        "distinct-3": 0.8759894459102903,
        "vocab_size-3": 996,
        "unique-3": 942,
        "entropy-3": 9.78305877519218,
        "cond_entropy-3": 0.23910335704773863,
        "total_length-nopunct": 1134,
        "mean_pred_length-nopunct": 14.354430379746836,
        "std_pred_length-nopunct": 5.014000587427432,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.48059964726631393,
        "vocab_size-1-nopunct": 545,
        "unique-1-nopunct": 424,
        "entropy-1-nopunct": 7.978773282905453,
        "distinct-2-nopunct": 0.7829383886255924,
        "vocab_size-2-nopunct": 826,
        "unique-2-nopunct": 748,
        "entropy-2-nopunct": 9.380896240073788,
        "cond_entropy-2-nopunct": 1.504254996360066,
        "distinct-3-nopunct": 0.8801229508196722,
        "vocab_size-3-nopunct": 859,
        "unique-3-nopunct": 816,
        "entropy-3-nopunct": 9.571727287485047,
        "cond_entropy-3-nopunct": 0.22759978478022339,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.06233834920323,
        "rouge1": {
            "precision": 0.79497,
            "recall": 0.73176,
            "fmeasure": 0.74979
        },
        "rouge2": {
            "precision": 0.59009,
            "recall": 0.54421,
            "fmeasure": 0.55732
        },
        "rougeL": {
            "precision": 0.69451,
            "recall": 0.64384,
            "fmeasure": 0.65716
        },
        "rougeLsum": {
            "precision": 0.69451,
            "recall": 0.64384,
            "fmeasure": 0.65716
        },
        "bleu": 49.22369,
        "local_recall": {
            "1": 0.17813765182186234,
            "2": 0.47101449275362317,
            "3": 0.7747440273037542
        },
        "bertscore": {
            "precision": 0.93522,
            "recall": 0.92423,
            "f1": 0.9276
        },
        "nubia": {
            "semantic_relation": 4.08922,
            "contradiction": 10.43688,
            "irrelevancy": 28.38766,
            "logical_agreement": 61.17546,
            "grammar_ref": 4.4104,
            "grammar_hyp": 4.35035,
            "nubia_score": 0.7138
        },
        "meteor": 0.3816592840206908,
        "bleurt": 0.29249
    },
    "totto_test_contrast_challenge_input_size-input_length_27": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.875,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.334962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.05628729973432273,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.52704064675181,
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.53175,
            "fmeasure": 0.52278
        },
        "rouge2": {
            "precision": 0.21212,
            "recall": 0.22222,
            "fmeasure": 0.21388
        },
        "rougeL": {
            "precision": 0.40278,
            "recall": 0.43352,
            "fmeasure": 0.41552
        },
        "rougeLsum": {
            "precision": 0.40278,
            "recall": 0.43352,
            "fmeasure": 0.41552
        },
        "bleu": 7.24946,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.3333333333333333,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.87756,
            "recall": 0.86951,
            "f1": 0.87307
        },
        "nubia": {
            "semantic_relation": 4.13613,
            "contradiction": 0.41251,
            "irrelevancy": 58.27787,
            "logical_agreement": 41.30962,
            "grammar_ref": 5.41182,
            "grammar_hyp": 5.33276,
            "nubia_score": 0.66722
        },
        "meteor": 0.2735890630577406,
        "bleurt": 0.23767
    },
    "totto_test_contrast_challenge_table_size-table_size_52": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.71833,
        "msttr-100_nopunct": 0.778,
        "total_length": 674,
        "mean_pred_length": 15.674418604651162,
        "std_pred_length": 5.161219119695882,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.5296735905044511,
        "vocab_size-1": 357,
        "unique-1": 288,
        "entropy-1": 7.45119458375641,
        "distinct-2": 0.8969889064976229,
        "vocab_size-2": 566,
        "unique-2": 522,
        "entropy-2": 9.057679283045958,
        "cond_entropy-2": 1.389357926389343,
        "distinct-3": 0.9574829931972789,
        "vocab_size-3": 563,
        "unique-3": 543,
        "entropy-3": 9.105098126342426,
        "cond_entropy-3": 0.04210334455294926,
        "total_length-nopunct": 583,
        "mean_pred_length-nopunct": 13.55813953488372,
        "std_pred_length-nopunct": 4.7067607267280485,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5986277873070326,
        "vocab_size-1-nopunct": 349,
        "unique-1-nopunct": 285,
        "entropy-1-nopunct": 7.643128631354625,
        "distinct-2-nopunct": 0.9111111111111111,
        "vocab_size-2-nopunct": 492,
        "unique-2-nopunct": 460,
        "entropy-2-nopunct": 8.864354382322622,
        "cond_entropy-2-nopunct": 1.295868103735394,
        "distinct-3-nopunct": 0.9698189134808853,
        "vocab_size-3-nopunct": 482,
        "unique-3-nopunct": 469,
        "entropy-3-nopunct": 8.892715723654868,
        "cond_entropy-3-nopunct": 0.0167134937058109,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.208069021200038,
        "rouge1": {
            "precision": 0.80442,
            "recall": 0.76781,
            "fmeasure": 0.77977
        },
        "rouge2": {
            "precision": 0.61689,
            "recall": 0.58795,
            "fmeasure": 0.59798
        },
        "rougeL": {
            "precision": 0.71454,
            "recall": 0.67895,
            "fmeasure": 0.69149
        },
        "rougeLsum": {
            "precision": 0.71454,
            "recall": 0.67895,
            "fmeasure": 0.69149
        },
        "bleu": 56.82802,
        "local_recall": {
            "1": 0.25,
            "2": 0.45112781954887216,
            "3": 0.8207547169811321
        },
        "bertscore": {
            "precision": 0.93603,
            "recall": 0.93196,
            "f1": 0.93291
        },
        "nubia": {
            "semantic_relation": 4.25844,
            "contradiction": 7.56027,
            "irrelevancy": 34.29285,
            "logical_agreement": 58.14689,
            "grammar_ref": 4.51918,
            "grammar_hyp": 4.43514,
            "nubia_score": 0.76042
        },
        "meteor": 0.42159279480346984,
        "bleurt": 0.2934
    },
    "totto_test_contrast_challenge_table_size-table_size_33": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.755,
        "total_length": 313,
        "mean_pred_length": 14.904761904761905,
        "std_pred_length": 5.519702906987467,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 25,
        "distinct-1": 0.5878594249201278,
        "vocab_size-1": 184,
        "unique-1": 154,
        "entropy-1": 6.833866984939051,
        "distinct-2": 0.9178082191780822,
        "vocab_size-2": 268,
        "unique-2": 258,
        "entropy-2": 7.969828562450169,
        "cond_entropy-2": 0.9247989858107504,
        "distinct-3": 0.985239852398524,
        "vocab_size-3": 267,
        "unique-3": 265,
        "entropy-3": 8.045248672350146,
        "cond_entropy-3": 0.0422476945885797,
        "total_length-nopunct": 267,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 4.712120714991612,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6704119850187266,
        "vocab_size-1-nopunct": 179,
        "unique-1-nopunct": 154,
        "entropy-1-nopunct": 6.951038680903091,
        "distinct-2-nopunct": 0.9349593495934959,
        "vocab_size-2-nopunct": 230,
        "unique-2-nopunct": 224,
        "entropy-2-nopunct": 7.764163680213557,
        "cond_entropy-2-nopunct": 0.8606581773268132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 225,
        "unique-3-nopunct": 225,
        "entropy-3-nopunct": 7.81378119121699,
        "cond_entropy-3-nopunct": 0.030708032459696232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.275471747275123,
        "rouge1": {
            "precision": 0.76257,
            "recall": 0.76836,
            "fmeasure": 0.75463
        },
        "rouge2": {
            "precision": 0.56577,
            "recall": 0.5627,
            "fmeasure": 0.55681
        },
        "rougeL": {
            "precision": 0.67621,
            "recall": 0.68474,
            "fmeasure": 0.6724
        },
        "rougeLsum": {
            "precision": 0.67621,
            "recall": 0.68474,
            "fmeasure": 0.6724
        },
        "bleu": 51.57435,
        "local_recall": {
            "1": 0.2753623188405797,
            "2": 0.37735849056603776,
            "3": 0.8351063829787234
        },
        "bertscore": {
            "precision": 0.93475,
            "recall": 0.93366,
            "f1": 0.93133
        },
        "nubia": {
            "semantic_relation": 4.0227,
            "contradiction": 5.2002,
            "irrelevancy": 44.5619,
            "logical_agreement": 50.2379,
            "grammar_ref": 4.80447,
            "grammar_hyp": 4.72174,
            "nubia_score": 0.6962
        },
        "meteor": 0.4059180652326663,
        "bleurt": 0.24164
    },
    "totto_test_contrast_challenge_table_size-table_size_34": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 15.571428571428571,
        "std_pred_length": 5.122977450583173,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7064220183486238,
        "vocab_size-1": 77,
        "unique-1": 61,
        "entropy-1": 6.026038884505533,
        "distinct-2": 0.9313725490196079,
        "vocab_size-2": 95,
        "unique-2": 89,
        "entropy-2": 6.527769582146367,
        "cond_entropy-2": 0.40060562977388947,
        "distinct-3": 0.9578947368421052,
        "vocab_size-3": 91,
        "unique-3": 87,
        "entropy-3": 6.485645082015158,
        "cond_entropy-3": -0.03146565467040596,
        "total_length-nopunct": 96,
        "mean_pred_length-nopunct": 13.714285714285714,
        "std_pred_length-nopunct": 5.006118705124352,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.974241766522298,
        "distinct-2-nopunct": 0.9213483146067416,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 76,
        "entropy-2-nopunct": 6.309948178133111,
        "cond_entropy-2-nopunct": 0.3837406266601536,
        "distinct-3-nopunct": 0.9512195121951219,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.259991029008332,
        "cond_entropy-3-nopunct": -0.03580474949266216,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8540770935583177,
        "rouge1": {
            "precision": 0.63859,
            "recall": 0.64121,
            "fmeasure": 0.62201
        },
        "rouge2": {
            "precision": 0.31008,
            "recall": 0.32982,
            "fmeasure": 0.30922
        },
        "rougeL": {
            "precision": 0.47815,
            "recall": 0.51745,
            "fmeasure": 0.48435
        },
        "rougeLsum": {
            "precision": 0.47815,
            "recall": 0.51745,
            "fmeasure": 0.48435
        },
        "bleu": 16.70885,
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.6521739130434783,
            "3": 0.5789473684210527
        },
        "bertscore": {
            "precision": 0.90702,
            "recall": 0.91552,
            "f1": 0.90738
        },
        "nubia": {
            "semantic_relation": 4.02417,
            "contradiction": 14.75972,
            "irrelevancy": 42.17067,
            "logical_agreement": 43.06961,
            "grammar_ref": 4.83605,
            "grammar_hyp": 4.38455,
            "nubia_score": 0.71141
        },
        "meteor": 0.30523310586422725,
        "bleurt": 0.03714
    },
    "totto_test_contrast_challenge_input_size-input_length_28": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 2.0,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": -0.03214388408660256,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9583333333333334,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.501629167387823,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.034621791174768185,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3522233164272153,
        "rouge1": {
            "precision": 0.54792,
            "recall": 0.38889,
            "fmeasure": 0.42351
        },
        "rouge2": {
            "precision": 0.23333,
            "recall": 0.16512,
            "fmeasure": 0.17383
        },
        "rougeL": {
            "precision": 0.5375,
            "recall": 0.37222,
            "fmeasure": 0.41069
        },
        "rougeLsum": {
            "precision": 0.5375,
            "recall": 0.37222,
            "fmeasure": 0.41069
        },
        "bleu": 7.13182,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.1,
            "3": 0.45454545454545453
        },
        "bertscore": {
            "precision": 0.87857,
            "recall": 0.84593,
            "f1": 0.85456
        },
        "nubia": {
            "semantic_relation": 3.09104,
            "contradiction": 45.89257,
            "irrelevancy": 37.7705,
            "logical_agreement": 16.33693,
            "grammar_ref": 5.71002,
            "grammar_hyp": 5.28263,
            "nubia_score": 0.33438
        },
        "meteor": 0.21793979017915246,
        "bleurt": 0.00916
    },
    "totto_test_contrast_challenge_input_size-input_length_32": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.095795255000932,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.3138381850938442,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.4103196730332333,
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.36266,
            "fmeasure": 0.49654
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.27498,
            "fmeasure": 0.37863
        },
        "rougeL": {
            "precision": 0.68421,
            "recall": 0.31364,
            "fmeasure": 0.42972
        },
        "rougeLsum": {
            "precision": 0.68421,
            "recall": 0.31364,
            "fmeasure": 0.42972
        },
        "bleu": 23.854,
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.35714285714285715
        },
        "bertscore": {
            "precision": 0.95218,
            "recall": 0.83976,
            "f1": 0.89244
        },
        "nubia": {
            "semantic_relation": 2.2613,
            "contradiction": 34.56572,
            "irrelevancy": 54.05953,
            "logical_agreement": 11.37476,
            "grammar_ref": 4.14314,
            "grammar_hyp": 4.17375,
            "nubia_score": 0.1251
        },
        "meteor": 0.254283259229903,
        "bleurt": -0.68294
    },
    "totto_test_contrast_challenge_input_size-input_length_33": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.0018894374052805774,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.15725,
            "fmeasure": 0.24451
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.08201,
            "fmeasure": 0.13051
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.15725,
            "fmeasure": 0.24451
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.15725,
            "fmeasure": 0.24451
        },
        "bleu": 2.72734,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.11764705882352941
        },
        "bertscore": {
            "precision": 0.88466,
            "recall": 0.7482,
            "f1": 0.81073
        },
        "nubia": {
            "semantic_relation": 2.8156,
            "contradiction": 0.22279,
            "irrelevancy": 0.89932,
            "logical_agreement": 98.87789,
            "grammar_ref": 4.39709,
            "grammar_hyp": 5.40059,
            "nubia_score": 0.20403
        },
        "meteor": 0.11254123629036765,
        "bleurt": -0.48567
    },
    "totto_test_contrast_challenge_continent-south_america": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.71083,
        "msttr-100_nopunct": 0.76364,
        "total_length": 1270,
        "mean_pred_length": 16.075949367088608,
        "std_pred_length": 4.820242527378967,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.4645669291338583,
        "vocab_size-1": 590,
        "unique-1": 463,
        "entropy-1": 7.876999977962047,
        "distinct-2": 0.8547439126784215,
        "vocab_size-2": 1018,
        "unique-2": 932,
        "entropy-2": 9.823669047333777,
        "cond_entropy-2": 1.7367442245502538,
        "distinct-3": 0.9514388489208633,
        "vocab_size-3": 1058,
        "unique-3": 1019,
        "entropy-3": 10.00954472336033,
        "cond_entropy-3": 0.2012972618106548,
        "total_length-nopunct": 1108,
        "mean_pred_length-nopunct": 14.025316455696203,
        "std_pred_length-nopunct": 4.5534093042752986,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.526173285198556,
        "vocab_size-1-nopunct": 583,
        "unique-1-nopunct": 462,
        "entropy-1-nopunct": 8.151106758045342,
        "distinct-2-nopunct": 0.8649173955296404,
        "vocab_size-2-nopunct": 890,
        "unique-2-nopunct": 828,
        "entropy-2-nopunct": 9.62586720392397,
        "cond_entropy-2-nopunct": 1.5793346476847787,
        "distinct-3-nopunct": 0.9621052631578947,
        "vocab_size-3-nopunct": 914,
        "unique-3-nopunct": 885,
        "entropy-3-nopunct": 9.809915874259444,
        "cond_entropy-3-nopunct": 0.20100829662483716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.742161071368759,
        "rouge1": {
            "precision": 0.84111,
            "recall": 0.78085,
            "fmeasure": 0.80314
        },
        "rouge2": {
            "precision": 0.62596,
            "recall": 0.58205,
            "fmeasure": 0.59779
        },
        "rougeL": {
            "precision": 0.7291,
            "recall": 0.66862,
            "fmeasure": 0.69135
        },
        "rougeLsum": {
            "precision": 0.7291,
            "recall": 0.66862,
            "fmeasure": 0.69135
        },
        "bleu": 49.5822,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.41262135922330095,
            "3": 0.8036677454153183
        },
        "bertscore": {
            "precision": 0.95094,
            "recall": 0.9414,
            "f1": 0.94502
        },
        "nubia": {
            "semantic_relation": 4.43695,
            "contradiction": 7.53383,
            "irrelevancy": 21.45856,
            "logical_agreement": 71.00761,
            "grammar_ref": 4.82253,
            "grammar_hyp": 4.87237,
            "nubia_score": 0.79142
        },
        "meteor": 0.4174210957093153,
        "bleurt": 0.44651
    },
    "totto_test_contrast_challenge_input_size-input_length_34": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.220175521464345,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.31924673803861636,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.152391277629865,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.25454711376829514,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.691947872193295,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.50877,
            "fmeasure": 0.52371
        },
        "rouge2": {
            "precision": 0.25397,
            "recall": 0.23407,
            "fmeasure": 0.24229
        },
        "rougeL": {
            "precision": 0.4697,
            "recall": 0.43995,
            "fmeasure": 0.4519
        },
        "rougeLsum": {
            "precision": 0.4697,
            "recall": 0.43995,
            "fmeasure": 0.4519
        },
        "bleu": 10.86604,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.47619047619047616
        },
        "bertscore": {
            "precision": 0.88701,
            "recall": 0.84856,
            "f1": 0.86482
        },
        "nubia": {
            "semantic_relation": 2.78837,
            "contradiction": 0.97581,
            "irrelevancy": 96.0341,
            "logical_agreement": 2.99009,
            "grammar_ref": 4.75948,
            "grammar_hyp": 5.47672,
            "nubia_score": 0.28255
        },
        "meteor": 0.23236313026387917,
        "bleurt": -0.71187
    },
    "totto_test_contrast_challenge_input_size-input_length_35": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 1.5,
        "median_pred_length": 19.5,
        "min_pred_length": 18,
        "max_pred_length": 21,
        "distinct-1": 0.7435897435897436,
        "vocab_size-1": 29,
        "unique-1": 19,
        "entropy-1": 4.772581706041735,
        "distinct-2": 0.8648648648648649,
        "vocab_size-2": 32,
        "unique-2": 27,
        "entropy-2": 4.939183095358683,
        "cond_entropy-2": 0.14026736298291742,
        "distinct-3": 0.8857142857142857,
        "vocab_size-3": 31,
        "unique-3": 27,
        "entropy-3": 4.900711588373535,
        "cond_entropy-3": -0.023027491541126217,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.66992500144231,
        "distinct-2-nopunct": 0.8529411764705882,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.793345194191515,
        "cond_entropy-2-nopunct": 0.15283195745508588,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.75,
        "cond_entropy-3-nopunct": -0.024962841250339415,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2577885531173434,
        "rouge1": {
            "precision": 0.41457,
            "recall": 0.32456,
            "fmeasure": 0.36275
        },
        "rouge2": {
            "precision": 0.13125,
            "recall": 0.09674,
            "fmeasure": 0.11104
        },
        "rougeL": {
            "precision": 0.33193,
            "recall": 0.25526,
            "fmeasure": 0.28758
        },
        "rougeLsum": {
            "precision": 0.33193,
            "recall": 0.25526,
            "fmeasure": 0.28758
        },
        "bleu": 10.19852,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.36363636363636365
        },
        "bertscore": {
            "precision": 0.80734,
            "recall": 0.76476,
            "f1": 0.78471
        },
        "nubia": {
            "semantic_relation": 2.54847,
            "contradiction": 34.6175,
            "irrelevancy": 64.6263,
            "logical_agreement": 0.75621,
            "grammar_ref": 3.96887,
            "grammar_hyp": 4.07491,
            "nubia_score": 0.21657
        },
        "meteor": 0.15003358384773097,
        "bleurt": -0.6512
    },
    "totto_test_contrast_challenge_input_size-input_length_38": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337128,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0480981409606436,
        "rouge1": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.07143,
            "fmeasure": 0.07407
        },
        "rougeL": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "rougeLsum": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "bleu": 5.84728,
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "bertscore": {
            "precision": 0.78357,
            "recall": 0.77779,
            "f1": 0.77822
        },
        "nubia": {
            "semantic_relation": 2.25701,
            "contradiction": 0.40226,
            "irrelevancy": 99.05462,
            "logical_agreement": 0.54312,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.71865,
            "nubia_score": 0.22654
        },
        "meteor": 0.11564440949896566,
        "bleurt": -0.38075
    },
    "totto_test_contrast_challenge_table_size-table_size_54": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.71417,
        "msttr-100_nopunct": 0.76364,
        "total_length": 1269,
        "mean_pred_length": 15.8625,
        "std_pred_length": 5.238663355284437,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.49487785657998423,
        "vocab_size-1": 628,
        "unique-1": 518,
        "entropy-1": 7.9942496343549,
        "distinct-2": 0.8730025231286795,
        "vocab_size-2": 1038,
        "unique-2": 969,
        "entropy-2": 9.852465702710816,
        "cond_entropy-2": 1.6450271414327955,
        "distinct-3": 0.9693417493237151,
        "vocab_size-3": 1075,
        "unique-3": 1055,
        "entropy-3": 10.03860460603803,
        "cond_entropy-3": 0.20082825973884552,
        "total_length-nopunct": 1102,
        "mean_pred_length-nopunct": 13.775,
        "std_pred_length-nopunct": 4.358827250534254,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5626134301270418,
        "vocab_size-1-nopunct": 620,
        "unique-1-nopunct": 515,
        "entropy-1-nopunct": 8.244127428385847,
        "distinct-2-nopunct": 0.8825831702544031,
        "vocab_size-2-nopunct": 902,
        "unique-2-nopunct": 850,
        "entropy-2-nopunct": 9.64854646901108,
        "cond_entropy-2-nopunct": 1.5015377715182332,
        "distinct-3-nopunct": 0.970276008492569,
        "vocab_size-3-nopunct": 914,
        "unique-3-nopunct": 899,
        "entropy-3-nopunct": 9.803133130259083,
        "cond_entropy-3-nopunct": 0.18100984697457642,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.737296363465439,
        "rouge1": {
            "precision": 0.72985,
            "recall": 0.66765,
            "fmeasure": 0.68319
        },
        "rouge2": {
            "precision": 0.48695,
            "recall": 0.45922,
            "fmeasure": 0.45993
        },
        "rougeL": {
            "precision": 0.62997,
            "recall": 0.59345,
            "fmeasure": 0.59536
        },
        "rougeLsum": {
            "precision": 0.62997,
            "recall": 0.59345,
            "fmeasure": 0.59536
        },
        "bleu": 42.11296,
        "local_recall": {
            "1": 0.1864406779661017,
            "2": 0.4327485380116959,
            "3": 0.7115135834411385
        },
        "bertscore": {
            "precision": 0.91599,
            "recall": 0.9072,
            "f1": 0.90935
        },
        "nubia": {
            "semantic_relation": 3.90443,
            "contradiction": 12.92997,
            "irrelevancy": 35.20212,
            "logical_agreement": 51.86791,
            "grammar_ref": 4.56456,
            "grammar_hyp": 4.57582,
            "nubia_score": 0.62326
        },
        "meteor": 0.3505197999756113,
        "bleurt": 0.11772
    },
    "cs_restaurants_test_contrast_challenge_acts-?request": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 149,
        "msttr-100": 0.13,
        "msttr-100_nopunct": 0.11,
        "total_length": 2235,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.0058165548098434005,
        "vocab_size-1": 13,
        "unique-1": 0,
        "entropy-1": 3.5898980954642865,
        "distinct-2": 0.006711409395973154,
        "vocab_size-2": 14,
        "unique-2": 0,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.2400991480321905,
        "distinct-3": 0.006711409395973154,
        "vocab_size-3": 13,
        "unique-3": 0,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 1639,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.006711409395973154,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 0.006711409395973154,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.006711409395973154,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.3651736180131448,
        "rouge1": {
            "precision": 0.06823,
            "recall": 0.15284,
            "fmeasure": 0.09271
        },
        "rouge2": {
            "precision": 0.02448,
            "recall": 0.05856,
            "fmeasure": 0.03413
        },
        "rougeL": {
            "precision": 0.05742,
            "recall": 0.13314,
            "fmeasure": 0.07893
        },
        "rougeLsum": {
            "precision": 0.05742,
            "recall": 0.13314,
            "fmeasure": 0.07893
        },
        "bleu": 0.41891,
        "local_recall": {
            "1": 0.0871313672922252
        },
        "bertscore": {
            "precision": 0.80177,
            "recall": 0.84632,
            "f1": 0.82338
        },
        "nubia": {
            "semantic_relation": 0.98491,
            "contradiction": 55.68036,
            "irrelevancy": 36.17341,
            "logical_agreement": 8.14623,
            "grammar_ref": 6.81129,
            "grammar_hyp": 6.01036,
            "nubia_score": 0.07021
        },
        "meteor": 0.053825414462325125,
        "bleurt": -0.83804
    },
    "totto_test_contrast_challenge_input_size-input_length_40": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4576245353579584,
        "rouge1": {
            "precision": 0.38462,
            "recall": 0.33333,
            "fmeasure": 0.35714
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "rougeLsum": {
            "precision": 0.23077,
            "recall": 0.2,
            "fmeasure": 0.21429
        },
        "bleu": 3.85291,
        "local_recall": {
            "1": 0,
            "2": 0.3076923076923077
        },
        "bertscore": {
            "precision": 0.76123,
            "recall": 0.78307,
            "f1": 0.772
        },
        "nubia": {
            "semantic_relation": 2.6318,
            "contradiction": 10.84192,
            "irrelevancy": 88.34376,
            "logical_agreement": 0.81432,
            "grammar_ref": 5.57252,
            "grammar_hyp": 4.69272,
            "nubia_score": 0.26808
        },
        "meteor": 0.11494252873563221,
        "bleurt": -0.81101
    },
    "totto_test_contrast_challenge_input_size-input_length_41": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 6,
        "mean_pred_length": 6.0,
        "std_pred_length": 0.0,
        "median_pred_length": 6.0,
        "min_pred_length": 6,
        "max_pred_length": 6,
        "distinct-1": 1.0,
        "vocab_size-1": 6,
        "unique-1": 6,
        "entropy-1": 2.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 5,
        "unique-2": 5,
        "entropy-2": 2.321928094887362,
        "cond_entropy-2": -0.26303440583379406,
        "distinct-3": 1.0,
        "vocab_size-3": 4,
        "unique-3": 4,
        "entropy-3": 2.0,
        "cond_entropy-3": -0.32192809488736235,
        "total_length-nopunct": 5,
        "mean_pred_length-nopunct": 5.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 5,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 5,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 4,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 2.0,
        "cond_entropy-2-nopunct": -0.32192809488736235,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 3,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 1.584962500721156,
        "cond_entropy-3-nopunct": -0.4150374992788437,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.4716332873945959,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.32576
        },
        "rouge2": {
            "precision": 0.2,
            "recall": 0.2037,
            "fmeasure": 0.19577
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.32576
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.32576
        },
        "bleu": 9.65243,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.89982,
            "recall": 0.91641,
            "f1": 0.90804
        },
        "nubia": {
            "semantic_relation": 2.49455,
            "contradiction": 57.50551,
            "irrelevancy": 27.85064,
            "logical_agreement": 14.64384,
            "grammar_ref": 6.66832,
            "grammar_hyp": 5.83783,
            "nubia_score": 0.21697
        },
        "meteor": 0.1936313790573835,
        "bleurt": -0.04863
    },
    "totto_test_contrast_challenge_input_size-input_length_42": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.229871195093384,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.24291000358771486,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.084183719779189,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.17625665551219521,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9517651696802483,
        "rouge1": {
            "precision": 0.38333,
            "recall": 0.35111,
            "fmeasure": 0.3619
        },
        "rouge2": {
            "precision": 0.12281,
            "recall": 0.10714,
            "fmeasure": 0.11323
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.30222,
            "fmeasure": 0.27937
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.30222,
            "fmeasure": 0.27937
        },
        "bleu": 4.71672,
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.25
        },
        "bertscore": {
            "precision": 0.82619,
            "recall": 0.7936,
            "f1": 0.80115
        },
        "nubia": {
            "semantic_relation": 2.9741,
            "contradiction": 0.24526,
            "irrelevancy": 82.94016,
            "logical_agreement": 16.81458,
            "grammar_ref": 4.19943,
            "grammar_hyp": 4.00574,
            "nubia_score": 0.42549
        },
        "meteor": 0.20846428354730145,
        "bleurt": -0.18453
    },
    "totto_test_contrast_challenge_input_size-input_length_52": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.315824333525707,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.3434164716336324,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.029610672108601997,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.5600057374556348,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.41905,
            "fmeasure": 0.5307
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.16141,
            "fmeasure": 0.20587
        },
        "rougeL": {
            "precision": 0.36364,
            "recall": 0.20952,
            "fmeasure": 0.26535
        },
        "rougeLsum": {
            "precision": 0.36364,
            "recall": 0.20952,
            "fmeasure": 0.26535
        },
        "bleu": 13.57946,
        "local_recall": {
            "1": 0.0,
            "2": 0.5
        },
        "bertscore": {
            "precision": 0.88458,
            "recall": 0.84558,
            "f1": 0.86322
        },
        "nubia": {
            "semantic_relation": 3.25414,
            "contradiction": 3.17337,
            "irrelevancy": 1.31544,
            "logical_agreement": 95.51119,
            "grammar_ref": 3.72412,
            "grammar_hyp": 3.85986,
            "nubia_score": 0.40147
        },
        "meteor": 0.2374434019715587,
        "bleurt": -0.14905
    },
    "totto_test_contrast_challenge_table_size-table_size_74": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6476388007204534,
        "rouge1": {
            "precision": 0.7037,
            "recall": 0.6,
            "fmeasure": 0.63889
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.32143,
            "fmeasure": 0.34091
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.48148,
            "fmeasure": 0.50926
        },
        "bleu": 22.08959,
        "local_recall": {
            "1": 0,
            "2": 0.2,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.92614,
            "recall": 0.93439,
            "f1": 0.93025
        },
        "nubia": {
            "semantic_relation": 4.03669,
            "contradiction": 0.06382,
            "irrelevancy": 34.0709,
            "logical_agreement": 65.86528,
            "grammar_ref": 4.68314,
            "grammar_hyp": 5.46374,
            "nubia_score": 0.65321
        },
        "meteor": 0.3387350864807313,
        "bleurt": 0.27507
    },
    "totto_test_contrast_challenge_table_size-table_size_2": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 71,
        "msttr-100": 0.66125,
        "msttr-100_nopunct": 0.69429,
        "total_length": 851,
        "mean_pred_length": 11.985915492957746,
        "std_pred_length": 4.400681630129584,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.4383078730904818,
        "vocab_size-1": 373,
        "unique-1": 295,
        "entropy-1": 7.173156932390896,
        "distinct-2": 0.7884615384615384,
        "vocab_size-2": 615,
        "unique-2": 545,
        "entropy-2": 8.98109314546397,
        "cond_entropy-2": 1.486626221225591,
        "distinct-3": 0.8984485190409027,
        "vocab_size-3": 637,
        "unique-3": 593,
        "entropy-3": 9.222450870883865,
        "cond_entropy-3": 0.2408700013593251,
        "total_length-nopunct": 761,
        "mean_pred_length-nopunct": 10.71830985915493,
        "std_pred_length-nopunct": 4.018208901640971,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4835742444152431,
        "vocab_size-1-nopunct": 368,
        "unique-1-nopunct": 294,
        "entropy-1-nopunct": 7.342271972541942,
        "distinct-2-nopunct": 0.7956521739130434,
        "vocab_size-2-nopunct": 549,
        "unique-2-nopunct": 486,
        "entropy-2-nopunct": 8.833344042243496,
        "cond_entropy-2-nopunct": 1.6414308041029817,
        "distinct-3-nopunct": 0.8917609046849758,
        "vocab_size-3-nopunct": 552,
        "unique-3-nopunct": 511,
        "entropy-3-nopunct": 9.010050234163966,
        "cond_entropy-3-nopunct": 0.2368431534187999,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.415967037738535,
        "rouge1": {
            "precision": 0.77437,
            "recall": 0.79424,
            "fmeasure": 0.76832
        },
        "rouge2": {
            "precision": 0.59254,
            "recall": 0.61545,
            "fmeasure": 0.5908
        },
        "rougeL": {
            "precision": 0.74334,
            "recall": 0.76927,
            "fmeasure": 0.74108
        },
        "rougeLsum": {
            "precision": 0.74334,
            "recall": 0.76927,
            "fmeasure": 0.74108
        },
        "bleu": 59.1656,
        "local_recall": {
            "1": 0.22346368715083798,
            "2": 0.6631578947368421,
            "3": 0.821285140562249
        },
        "bertscore": {
            "precision": 0.94353,
            "recall": 0.95013,
            "f1": 0.94524
        },
        "nubia": {
            "semantic_relation": 4.14127,
            "contradiction": 9.02552,
            "irrelevancy": 40.75564,
            "logical_agreement": 50.21884,
            "grammar_ref": 5.37595,
            "grammar_hyp": 5.17351,
            "nubia_score": 0.71651
        },
        "meteor": 0.4467454821274789,
        "bleurt": 0.39958
    },
    "totto_test_contrast_challenge_table_size-table_size_15": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 136,
        "msttr-100": 0.6595,
        "msttr-100_nopunct": 0.70056,
        "total_length": 2085,
        "mean_pred_length": 15.330882352941176,
        "std_pred_length": 4.876496975377413,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.376978417266187,
        "vocab_size-1": 786,
        "unique-1": 619,
        "entropy-1": 7.7306388561599775,
        "distinct-2": 0.7090815802975885,
        "vocab_size-2": 1382,
        "unique-2": 1248,
        "entropy-2": 9.781280194065191,
        "cond_entropy-2": 1.817004708971648,
        "distinct-3": 0.8207391064533922,
        "vocab_size-3": 1488,
        "unique-3": 1418,
        "entropy-3": 10.12253499124376,
        "cond_entropy-3": 0.37064259649427356,
        "total_length-nopunct": 1819,
        "mean_pred_length-nopunct": 13.375,
        "std_pred_length-nopunct": 4.318117611399943,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4277075316107751,
        "vocab_size-1-nopunct": 778,
        "unique-1-nopunct": 618,
        "entropy-1-nopunct": 7.96320598753861,
        "distinct-2-nopunct": 0.7189542483660131,
        "vocab_size-2-nopunct": 1210,
        "unique-2-nopunct": 1106,
        "entropy-2-nopunct": 9.584207419529495,
        "cond_entropy-2-nopunct": 1.7456428730803626,
        "distinct-3-nopunct": 0.8287007110536523,
        "vocab_size-3-nopunct": 1282,
        "unique-3-nopunct": 1227,
        "entropy-3-nopunct": 9.919166675577065,
        "cond_entropy-3-nopunct": 0.3835275477269174,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.70609435222809,
        "rouge1": {
            "precision": 0.77332,
            "recall": 0.7384,
            "fmeasure": 0.74588
        },
        "rouge2": {
            "precision": 0.55527,
            "recall": 0.53389,
            "fmeasure": 0.53739
        },
        "rougeL": {
            "precision": 0.68867,
            "recall": 0.6598,
            "fmeasure": 0.66522
        },
        "rougeLsum": {
            "precision": 0.68867,
            "recall": 0.6598,
            "fmeasure": 0.66522
        },
        "bleu": 50.0053,
        "local_recall": {
            "1": 0.23376623376623376,
            "2": 0.4512987012987013,
            "3": 0.7745987438939288
        },
        "bertscore": {
            "precision": 0.93498,
            "recall": 0.92622,
            "f1": 0.92904
        },
        "nubia": {
            "semantic_relation": 4.17005,
            "contradiction": 5.14246,
            "irrelevancy": 26.45539,
            "logical_agreement": 68.40216,
            "grammar_ref": 4.4992,
            "grammar_hyp": 4.49674,
            "nubia_score": 0.73591
        },
        "meteor": 0.3977977111638803,
        "bleurt": 0.35196
    },
    "totto_test_contrast_challenge_table_size-table_size_35": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 103,
        "msttr-100": 0.70471,
        "msttr-100_nopunct": 0.74867,
        "total_length": 1769,
        "mean_pred_length": 17.174757281553397,
        "std_pred_length": 5.732596599800059,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.43583945732052004,
        "vocab_size-1": 771,
        "unique-1": 603,
        "entropy-1": 8.066129692782246,
        "distinct-2": 0.8079231692677071,
        "vocab_size-2": 1346,
        "unique-2": 1217,
        "entropy-2": 10.09973329908013,
        "cond_entropy-2": 1.8054516232394606,
        "distinct-3": 0.909149072296865,
        "vocab_size-3": 1421,
        "unique-3": 1363,
        "entropy-3": 10.339089365277115,
        "cond_entropy-3": 0.23843010660118605,
        "total_length-nopunct": 1549,
        "mean_pred_length-nopunct": 15.03883495145631,
        "std_pred_length-nopunct": 5.5000835476392,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4925758553905746,
        "vocab_size-1-nopunct": 763,
        "unique-1-nopunct": 600,
        "entropy-1-nopunct": 8.301787435440147,
        "distinct-2-nopunct": 0.813969571230982,
        "vocab_size-2-nopunct": 1177,
        "unique-2-nopunct": 1081,
        "entropy-2-nopunct": 9.89076298492934,
        "cond_entropy-2-nopunct": 1.6946925908068073,
        "distinct-3-nopunct": 0.9061801935964259,
        "vocab_size-3-nopunct": 1217,
        "unique-3-nopunct": 1171,
        "entropy-3-nopunct": 10.102912749097413,
        "cond_entropy-3-nopunct": 0.2486879027676884,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.154678613477252,
        "rouge1": {
            "precision": 0.78567,
            "recall": 0.76936,
            "fmeasure": 0.76759
        },
        "rouge2": {
            "precision": 0.57181,
            "recall": 0.56412,
            "fmeasure": 0.5608
        },
        "rougeL": {
            "precision": 0.69336,
            "recall": 0.68957,
            "fmeasure": 0.68213
        },
        "rougeLsum": {
            "precision": 0.69336,
            "recall": 0.68957,
            "fmeasure": 0.68213
        },
        "bleu": 54.94913,
        "local_recall": {
            "1": 0.20426829268292682,
            "2": 0.5252525252525253,
            "3": 0.8176156583629893
        },
        "bertscore": {
            "precision": 0.93651,
            "recall": 0.93516,
            "f1": 0.93469
        },
        "nubia": {
            "semantic_relation": 4.28351,
            "contradiction": 9.90265,
            "irrelevancy": 29.27437,
            "logical_agreement": 60.82298,
            "grammar_ref": 4.60982,
            "grammar_hyp": 4.50204,
            "nubia_score": 0.76818
        },
        "meteor": 0.425552928911659,
        "bleurt": 0.31216
    },
    "totto_test_contrast_challenge_table_size-table_size_3": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 52,
        "msttr-100": 0.63571,
        "msttr-100_nopunct": 0.67667,
        "total_length": 764,
        "mean_pred_length": 14.692307692307692,
        "std_pred_length": 4.861696686811736,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.42539267015706805,
        "vocab_size-1": 325,
        "unique-1": 246,
        "entropy-1": 7.080702282509913,
        "distinct-2": 0.7443820224719101,
        "vocab_size-2": 530,
        "unique-2": 458,
        "entropy-2": 8.686637527060759,
        "cond_entropy-2": 1.399868990433573,
        "distinct-3": 0.8545454545454545,
        "vocab_size-3": 564,
        "unique-3": 520,
        "entropy-3": 8.96108866325456,
        "cond_entropy-3": 0.28127486648181205,
        "total_length-nopunct": 660,
        "mean_pred_length-nopunct": 12.692307692307692,
        "std_pred_length-nopunct": 4.2223692835733715,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.48484848484848486,
        "vocab_size-1-nopunct": 320,
        "unique-1-nopunct": 245,
        "entropy-1-nopunct": 7.236470543124768,
        "distinct-2-nopunct": 0.7697368421052632,
        "vocab_size-2-nopunct": 468,
        "unique-2-nopunct": 409,
        "entropy-2-nopunct": 8.546250027138173,
        "cond_entropy-2-nopunct": 1.3965657533803633,
        "distinct-3-nopunct": 0.8687050359712231,
        "vocab_size-3-nopunct": 483,
        "unique-3-nopunct": 447,
        "entropy-3-nopunct": 8.771847728583632,
        "cond_entropy-3-nopunct": 0.2703859510627111,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.817306641319034,
        "rouge1": {
            "precision": 0.73289,
            "recall": 0.76844,
            "fmeasure": 0.73706
        },
        "rouge2": {
            "precision": 0.54794,
            "recall": 0.54193,
            "fmeasure": 0.53531
        },
        "rougeL": {
            "precision": 0.68749,
            "recall": 0.72027,
            "fmeasure": 0.69109
        },
        "rougeLsum": {
            "precision": 0.68749,
            "recall": 0.72027,
            "fmeasure": 0.69109
        },
        "bleu": 51.56542,
        "local_recall": {
            "1": 0.2894736842105263,
            "2": 0.5945945945945946,
            "3": 0.7789203084832905
        },
        "bertscore": {
            "precision": 0.93449,
            "recall": 0.93683,
            "f1": 0.9333
        },
        "nubia": {
            "semantic_relation": 4.11701,
            "contradiction": 12.39385,
            "irrelevancy": 28.67651,
            "logical_agreement": 58.92964,
            "grammar_ref": 5.15177,
            "grammar_hyp": 4.87879,
            "nubia_score": 0.70481
        },
        "meteor": 0.42538566194289423,
        "bleurt": 0.38875
    },
    "totto_test_contrast_challenge_table_size-table_size_4": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.688,
        "msttr-100_nopunct": 0.722,
        "total_length": 570,
        "mean_pred_length": 15.833333333333334,
        "std_pred_length": 5.361902647381805,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5105263157894737,
        "vocab_size-1": 291,
        "unique-1": 241,
        "entropy-1": 7.227165532853997,
        "distinct-2": 0.8183520599250936,
        "vocab_size-2": 437,
        "unique-2": 398,
        "entropy-2": 8.54042101409119,
        "cond_entropy-2": 1.117301607072356,
        "distinct-3": 0.9096385542168675,
        "vocab_size-3": 453,
        "unique-3": 428,
        "entropy-3": 8.730476304510153,
        "cond_entropy-3": 0.17227403446075076,
        "total_length-nopunct": 505,
        "mean_pred_length-nopunct": 14.027777777777779,
        "std_pred_length-nopunct": 4.645703577327665,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5603960396039604,
        "vocab_size-1-nopunct": 283,
        "unique-1-nopunct": 238,
        "entropy-1-nopunct": 7.30060478127873,
        "distinct-2-nopunct": 0.8208955223880597,
        "vocab_size-2-nopunct": 385,
        "unique-2-nopunct": 352,
        "entropy-2-nopunct": 8.359431493124546,
        "cond_entropy-2-nopunct": 1.1204331021669585,
        "distinct-3-nopunct": 0.9168591224018475,
        "vocab_size-3-nopunct": 397,
        "unique-3-nopunct": 377,
        "entropy-3-nopunct": 8.543918393665605,
        "cond_entropy-3-nopunct": 0.1894859866731298,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.3241690948796645,
        "rouge1": {
            "precision": 0.71726,
            "recall": 0.70733,
            "fmeasure": 0.69561
        },
        "rouge2": {
            "precision": 0.52,
            "recall": 0.51825,
            "fmeasure": 0.50683
        },
        "rougeL": {
            "precision": 0.65254,
            "recall": 0.63877,
            "fmeasure": 0.63013
        },
        "rougeLsum": {
            "precision": 0.65254,
            "recall": 0.63877,
            "fmeasure": 0.63013
        },
        "bleu": 45.97634,
        "local_recall": {
            "1": 0.2079207920792079,
            "2": 0.49206349206349204,
            "3": 0.750733137829912
        },
        "bertscore": {
            "precision": 0.91482,
            "recall": 0.90311,
            "f1": 0.90716
        },
        "nubia": {
            "semantic_relation": 3.88438,
            "contradiction": 13.74937,
            "irrelevancy": 42.16311,
            "logical_agreement": 44.08752,
            "grammar_ref": 4.68979,
            "grammar_hyp": 4.56258,
            "nubia_score": 0.64797
        },
        "meteor": 0.37265673187237924,
        "bleurt": 0.15814
    },
    "totto_test_contrast_challenge_table_size-table_size_75": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.72429,
        "msttr-100_nopunct": 0.77833,
        "total_length": 716,
        "mean_pred_length": 16.272727272727273,
        "std_pred_length": 5.824570356233218,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.526536312849162,
        "vocab_size-1": 377,
        "unique-1": 298,
        "entropy-1": 7.582481219253806,
        "distinct-2": 0.90625,
        "vocab_size-2": 609,
        "unique-2": 563,
        "entropy-2": 9.172208192126659,
        "cond_entropy-2": 1.4040217733518037,
        "distinct-3": 0.9745222929936306,
        "vocab_size-3": 612,
        "unique-3": 597,
        "entropy-3": 9.242463284716315,
        "cond_entropy-3": 0.07173585476558669,
        "total_length-nopunct": 614,
        "mean_pred_length-nopunct": 13.954545454545455,
        "std_pred_length-nopunct": 4.9952456735222714,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6042345276872965,
        "vocab_size-1-nopunct": 371,
        "unique-1-nopunct": 298,
        "entropy-1-nopunct": 7.8023426833598695,
        "distinct-2-nopunct": 0.9263157894736842,
        "vocab_size-2-nopunct": 528,
        "unique-2-nopunct": 500,
        "entropy-2-nopunct": 8.972978213452619,
        "cond_entropy-2-nopunct": 1.251501119289807,
        "distinct-3-nopunct": 0.9866920152091255,
        "vocab_size-3-nopunct": 519,
        "unique-3-nopunct": 512,
        "entropy-3-nopunct": 9.012303019710545,
        "cond_entropy-3-nopunct": 0.05263460741081538,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.085617056701111,
        "rouge1": {
            "precision": 0.77962,
            "recall": 0.75939,
            "fmeasure": 0.75862
        },
        "rouge2": {
            "precision": 0.5253,
            "recall": 0.5234,
            "fmeasure": 0.51643
        },
        "rougeL": {
            "precision": 0.69388,
            "recall": 0.67825,
            "fmeasure": 0.67565
        },
        "rougeLsum": {
            "precision": 0.69388,
            "recall": 0.67825,
            "fmeasure": 0.67565
        },
        "bleu": 49.61353,
        "local_recall": {
            "1": 0.22772277227722773,
            "2": 0.504,
            "3": 0.7948164146868251
        },
        "bertscore": {
            "precision": 0.93389,
            "recall": 0.92871,
            "f1": 0.92985
        },
        "nubia": {
            "semantic_relation": 4.28665,
            "contradiction": 8.01832,
            "irrelevancy": 26.17529,
            "logical_agreement": 65.8064,
            "grammar_ref": 4.70505,
            "grammar_hyp": 4.63445,
            "nubia_score": 0.76844
        },
        "meteor": 0.40938237679213874,
        "bleurt": 0.31892
    },
    "totto_test_contrast_challenge_table_size-table_size_55": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 73,
        "msttr-100": 0.71273,
        "msttr-100_nopunct": 0.754,
        "total_length": 1185,
        "mean_pred_length": 16.232876712328768,
        "std_pred_length": 6.087311186225889,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.4708860759493671,
        "vocab_size-1": 558,
        "unique-1": 429,
        "entropy-1": 7.8971515139386135,
        "distinct-2": 0.8363309352517986,
        "vocab_size-2": 930,
        "unique-2": 817,
        "entropy-2": 9.709637158680742,
        "cond_entropy-2": 1.5963149346819907,
        "distinct-3": 0.9239653512993262,
        "vocab_size-3": 960,
        "unique-3": 892,
        "entropy-3": 9.859503098181605,
        "cond_entropy-3": 0.14275768465822636,
        "total_length-nopunct": 1024,
        "mean_pred_length-nopunct": 14.027397260273972,
        "std_pred_length-nopunct": 5.477157053630057,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5361328125,
        "vocab_size-1-nopunct": 549,
        "unique-1-nopunct": 427,
        "entropy-1-nopunct": 8.130347761533157,
        "distinct-2-nopunct": 0.8485804416403786,
        "vocab_size-2-nopunct": 807,
        "unique-2-nopunct": 721,
        "entropy-2-nopunct": 9.507001304883026,
        "cond_entropy-2-nopunct": 1.468565002667453,
        "distinct-3-nopunct": 0.9362186788154897,
        "vocab_size-3-nopunct": 822,
        "unique-3-nopunct": 775,
        "entropy-3-nopunct": 9.641659774739463,
        "cond_entropy-3-nopunct": 0.14741463898666068,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.684871331250694,
        "rouge1": {
            "precision": 0.79445,
            "recall": 0.73724,
            "fmeasure": 0.75258
        },
        "rouge2": {
            "precision": 0.58797,
            "recall": 0.54773,
            "fmeasure": 0.55689
        },
        "rougeL": {
            "precision": 0.72597,
            "recall": 0.68111,
            "fmeasure": 0.69088
        },
        "rougeLsum": {
            "precision": 0.72597,
            "recall": 0.68111,
            "fmeasure": 0.69088
        },
        "bleu": 52.79212,
        "local_recall": {
            "1": 0.26976744186046514,
            "2": 0.43373493975903615,
            "3": 0.7684848484848484
        },
        "bertscore": {
            "precision": 0.93928,
            "recall": 0.9257,
            "f1": 0.93076
        },
        "nubia": {
            "semantic_relation": 4.23596,
            "contradiction": 4.98284,
            "irrelevancy": 34.16633,
            "logical_agreement": 60.85083,
            "grammar_ref": 4.56245,
            "grammar_hyp": 4.65151,
            "nubia_score": 0.74742
        },
        "meteor": 0.4119028049804939,
        "bleurt": 0.27518
    },
    "totto_test_contrast_challenge_table_size-table_size_76": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 33,
        "msttr-100": 0.718,
        "msttr-100_nopunct": 0.7575,
        "total_length": 543,
        "mean_pred_length": 16.454545454545453,
        "std_pred_length": 4.8933529998628975,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.574585635359116,
        "vocab_size-1": 312,
        "unique-1": 272,
        "entropy-1": 7.264756878852711,
        "distinct-2": 0.9313725490196079,
        "vocab_size-2": 475,
        "unique-2": 453,
        "entropy-2": 8.813141131404615,
        "cond_entropy-2": 1.3775116680954025,
        "distinct-3": 0.9916142557651991,
        "vocab_size-3": 473,
        "unique-3": 469,
        "entropy-3": 8.881073967535949,
        "cond_entropy-3": 0.07050121889392223,
        "total_length-nopunct": 468,
        "mean_pred_length-nopunct": 14.181818181818182,
        "std_pred_length-nopunct": 4.337675298733779,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6538461538461539,
        "vocab_size-1-nopunct": 306,
        "unique-1-nopunct": 271,
        "entropy-1-nopunct": 7.438591004944547,
        "distinct-2-nopunct": 0.9425287356321839,
        "vocab_size-2-nopunct": 410,
        "unique-2-nopunct": 397,
        "entropy-2-nopunct": 8.60012816940399,
        "cond_entropy-2-nopunct": 1.2655567795929759,
        "distinct-3-nopunct": 0.9975124378109452,
        "vocab_size-3-nopunct": 401,
        "unique-3-nopunct": 400,
        "entropy-3-nopunct": 8.64607656680077,
        "cond_entropy-3-nopunct": 0.05698454889917388,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.108895416217065,
        "rouge1": {
            "precision": 0.83825,
            "recall": 0.77975,
            "fmeasure": 0.80111
        },
        "rouge2": {
            "precision": 0.63101,
            "recall": 0.58075,
            "fmeasure": 0.59864
        },
        "rougeL": {
            "precision": 0.73466,
            "recall": 0.67825,
            "fmeasure": 0.69899
        },
        "rougeLsum": {
            "precision": 0.73466,
            "recall": 0.67825,
            "fmeasure": 0.69899
        },
        "bleu": 51.79025,
        "local_recall": {
            "1": 0.1375,
            "2": 0.19402985074626866,
            "3": 0.802439024390244
        },
        "bertscore": {
            "precision": 0.94663,
            "recall": 0.93663,
            "f1": 0.94073
        },
        "nubia": {
            "semantic_relation": 4.498,
            "contradiction": 3.7328,
            "irrelevancy": 16.98834,
            "logical_agreement": 79.27886,
            "grammar_ref": 4.92209,
            "grammar_hyp": 5.06996,
            "nubia_score": 0.79958
        },
        "meteor": 0.4138087499945175,
        "bleurt": 0.34192
    },
    "totto_test_contrast_challenge_table_size-table_size_77": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 30,
        "msttr-100": 0.698,
        "msttr-100_nopunct": 0.755,
        "total_length": 500,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 5.539755309477927,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.57,
        "vocab_size-1": 285,
        "unique-1": 226,
        "entropy-1": 7.305762228546021,
        "distinct-2": 0.9,
        "vocab_size-2": 423,
        "unique-2": 393,
        "entropy-2": 8.63428615628423,
        "cond_entropy-2": 1.136970393478279,
        "distinct-3": 0.9590909090909091,
        "vocab_size-3": 422,
        "unique-3": 405,
        "entropy-3": 8.697825878292507,
        "cond_entropy-3": 0.0747783484026447,
        "total_length-nopunct": 444,
        "mean_pred_length-nopunct": 14.8,
        "std_pred_length-nopunct": 4.70035459655262,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6283783783783784,
        "vocab_size-1-nopunct": 279,
        "unique-1-nopunct": 226,
        "entropy-1-nopunct": 7.442120919404419,
        "distinct-2-nopunct": 0.893719806763285,
        "vocab_size-2-nopunct": 370,
        "unique-2-nopunct": 343,
        "entropy-2-nopunct": 8.432983403315864,
        "cond_entropy-2-nopunct": 1.0603346904001094,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 368,
        "unique-3-nopunct": 353,
        "entropy-3-nopunct": 8.499663314517674,
        "cond_entropy-3-nopunct": 0.07838089695858412,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.71643414457305,
        "rouge1": {
            "precision": 0.77461,
            "recall": 0.7441,
            "fmeasure": 0.74898
        },
        "rouge2": {
            "precision": 0.53914,
            "recall": 0.52375,
            "fmeasure": 0.52469
        },
        "rougeL": {
            "precision": 0.66372,
            "recall": 0.64878,
            "fmeasure": 0.64736
        },
        "rougeLsum": {
            "precision": 0.66372,
            "recall": 0.64878,
            "fmeasure": 0.64736
        },
        "bleu": 48.6665,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.37383177570093457,
            "3": 0.808955223880597
        },
        "bertscore": {
            "precision": 0.93591,
            "recall": 0.92519,
            "f1": 0.92938
        },
        "nubia": {
            "semantic_relation": 4.08394,
            "contradiction": 11.52021,
            "irrelevancy": 28.63409,
            "logical_agreement": 59.8457,
            "grammar_ref": 4.79957,
            "grammar_hyp": 4.65762,
            "nubia_score": 0.7086
        },
        "meteor": 0.403291568299593,
        "bleurt": 0.22316
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 251,
        "msttr-100": 0.52017,
        "msttr-100_nopunct": 0.51778,
        "total_length": 5879,
        "mean_pred_length": 23.422310756972113,
        "std_pred_length": 2.9357224619418005,
        "median_pred_length": 23.0,
        "min_pred_length": 15,
        "max_pred_length": 30,
        "distinct-1": 0.15836026535125022,
        "vocab_size-1": 931,
        "unique-1": 331,
        "entropy-1": 7.948114337902668,
        "distinct-2": 0.4072494669509595,
        "vocab_size-2": 2292,
        "unique-2": 1305,
        "entropy-2": 10.423988525531579,
        "cond_entropy-2": 2.5111984694843743,
        "distinct-3": 0.583968755811791,
        "vocab_size-3": 3140,
        "unique-3": 2185,
        "entropy-3": 11.184514513784672,
        "cond_entropy-3": 0.8154399178771884,
        "total_length-nopunct": 5428,
        "mean_pred_length-nopunct": 21.625498007968126,
        "std_pred_length-nopunct": 2.9570611101833153,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.17022844509948415,
        "vocab_size-1-nopunct": 924,
        "unique-1-nopunct": 331,
        "entropy-1-nopunct": 8.06205236757474,
        "distinct-2-nopunct": 0.4183890283948233,
        "vocab_size-2-nopunct": 2166,
        "unique-2-nopunct": 1257,
        "entropy-2-nopunct": 10.37519292621485,
        "cond_entropy-2-nopunct": 2.42583163146984,
        "distinct-3-nopunct": 0.5917580186764109,
        "vocab_size-3-nopunct": 2915,
        "unique-3-nopunct": 2046,
        "entropy-3-nopunct": 11.087204500396654,
        "cond_entropy-3-nopunct": 0.7682880814199369,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 4.842629815202643,
        "rouge1": {
            "precision": 0.76442,
            "recall": 0.59223,
            "fmeasure": 0.65148
        },
        "rouge2": {
            "precision": 0.49041,
            "recall": 0.37064,
            "fmeasure": 0.41073
        },
        "rougeL": {
            "precision": 0.59838,
            "recall": 0.45972,
            "fmeasure": 0.50666
        },
        "rougeLsum": {
            "precision": 0.59838,
            "recall": 0.45972,
            "fmeasure": 0.50666
        },
        "bleu": 33.85625,
        "local_recall": {
            "1": 0.18358741485566007,
            "2": 0.4767772511848341,
            "3": 0.6909604519774011
        },
        "bertscore": {
            "precision": 0.90957,
            "recall": 0.87052,
            "f1": 0.88771
        },
        "nubia": {
            "semantic_relation": 3.74426,
            "contradiction": 5.80555,
            "irrelevancy": 12.04984,
            "logical_agreement": 82.14461,
            "grammar_ref": 4.22372,
            "grammar_hyp": 4.58714,
            "nubia_score": 0.54377
        },
        "meteor": 0.2903333965628778,
        "bleurt": -0.14941
    },
    "totto_test_contrast_challenge_table_size-table_size_78": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 66,
        "msttr-100": 0.742,
        "msttr-100_nopunct": 0.79889,
        "total_length": 1034,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 5.097038157577201,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5183752417794971,
        "vocab_size-1": 536,
        "unique-1": 447,
        "entropy-1": 7.896274137644939,
        "distinct-2": 0.875,
        "vocab_size-2": 847,
        "unique-2": 784,
        "entropy-2": 9.56831339243142,
        "cond_entropy-2": 1.4348608641502956,
        "distinct-3": 0.9656319290465631,
        "vocab_size-3": 871,
        "unique-3": 851,
        "entropy-3": 9.728320465327418,
        "cond_entropy-3": 0.13376765638824045,
        "total_length-nopunct": 900,
        "mean_pred_length-nopunct": 13.636363636363637,
        "std_pred_length-nopunct": 4.574754054115629,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5855555555555556,
        "vocab_size-1-nopunct": 527,
        "unique-1-nopunct": 443,
        "entropy-1-nopunct": 8.141907367488542,
        "distinct-2-nopunct": 0.8908872901678657,
        "vocab_size-2-nopunct": 743,
        "unique-2-nopunct": 692,
        "entropy-2-nopunct": 9.402097102338292,
        "cond_entropy-2-nopunct": 1.3095840266249752,
        "distinct-3-nopunct": 0.9778645833333334,
        "vocab_size-3-nopunct": 751,
        "unique-3-nopunct": 737,
        "entropy-3-nopunct": 9.537104574286086,
        "cond_entropy-3-nopunct": 0.10308642974083847,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.552346696873035,
        "rouge1": {
            "precision": 0.74839,
            "recall": 0.71677,
            "fmeasure": 0.72179
        },
        "rouge2": {
            "precision": 0.52234,
            "recall": 0.50832,
            "fmeasure": 0.50756
        },
        "rougeL": {
            "precision": 0.65431,
            "recall": 0.63629,
            "fmeasure": 0.63599
        },
        "rougeLsum": {
            "precision": 0.65431,
            "recall": 0.63629,
            "fmeasure": 0.63599
        },
        "bleu": 40.16811,
        "local_recall": {
            "1": 0.18407960199004975,
            "2": 0.42346938775510207,
            "3": 0.7385057471264368
        },
        "bertscore": {
            "precision": 0.92228,
            "recall": 0.92068,
            "f1": 0.91999
        },
        "nubia": {
            "semantic_relation": 4.1969,
            "contradiction": 4.58482,
            "irrelevancy": 34.81652,
            "logical_agreement": 60.59866,
            "grammar_ref": 4.35949,
            "grammar_hyp": 4.2848,
            "nubia_score": 0.74707
        },
        "meteor": 0.37289944029232985,
        "bleurt": 0.28276
    },
    "totto_test_contrast_challenge_table_size-table_size_79": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.031262576450960075,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.031262576450960075,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.440615426764121,
        "rouge1": {
            "precision": 0.51515,
            "recall": 0.40476,
            "fmeasure": 0.45333
        },
        "rouge2": {
            "precision": 0.26984,
            "recall": 0.22284,
            "fmeasure": 0.24322
        },
        "rougeL": {
            "precision": 0.27273,
            "recall": 0.2619,
            "fmeasure": 0.26605
        },
        "rougeLsum": {
            "precision": 0.27273,
            "recall": 0.2619,
            "fmeasure": 0.26605
        },
        "bleu": 6.00123,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6,
            "3": 0.35714285714285715
        },
        "bertscore": {
            "precision": 0.85037,
            "recall": 0.8046,
            "f1": 0.82685
        },
        "nubia": {
            "semantic_relation": 3.54975,
            "contradiction": 0.25915,
            "irrelevancy": 59.40129,
            "logical_agreement": 40.33957,
            "grammar_ref": 3.5675,
            "grammar_hyp": 3.75335,
            "nubia_score": 0.56415
        },
        "meteor": 0.2657924432305396,
        "bleurt": -0.38123
    },
    "totto_test_contrast_challenge_table_size-table_size_5": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 41,
        "msttr-100": 0.606,
        "msttr-100_nopunct": 0.6325,
        "total_length": 534,
        "mean_pred_length": 13.024390243902438,
        "std_pred_length": 4.96076216055188,
        "median_pred_length": 12.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.44569288389513106,
        "vocab_size-1": 238,
        "unique-1": 191,
        "entropy-1": 6.790562686018204,
        "distinct-2": 0.7809330628803245,
        "vocab_size-2": 385,
        "unique-2": 346,
        "entropy-2": 8.30669611794769,
        "cond_entropy-2": 1.2702376568538802,
        "distinct-3": 0.8827433628318584,
        "vocab_size-3": 399,
        "unique-3": 376,
        "entropy-3": 8.492581907455023,
        "cond_entropy-3": 0.18097933928411314,
        "total_length-nopunct": 459,
        "mean_pred_length-nopunct": 11.195121951219512,
        "std_pred_length-nopunct": 4.423989548101721,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5054466230936819,
        "vocab_size-1-nopunct": 232,
        "unique-1-nopunct": 190,
        "entropy-1-nopunct": 6.9034345906578345,
        "distinct-2-nopunct": 0.8110047846889952,
        "vocab_size-2-nopunct": 339,
        "unique-2-nopunct": 308,
        "entropy-2-nopunct": 8.162900653979637,
        "cond_entropy-2-nopunct": 1.3472352852475493,
        "distinct-3-nopunct": 0.9045092838196287,
        "vocab_size-3-nopunct": 341,
        "unique-3-nopunct": 325,
        "entropy-3-nopunct": 8.289712572926984,
        "cond_entropy-3-nopunct": 0.1250156261148196,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.31657063390787,
        "rouge1": {
            "precision": 0.76703,
            "recall": 0.71871,
            "fmeasure": 0.73199
        },
        "rouge2": {
            "precision": 0.55803,
            "recall": 0.52921,
            "fmeasure": 0.53537
        },
        "rougeL": {
            "precision": 0.67724,
            "recall": 0.6423,
            "fmeasure": 0.65036
        },
        "rougeLsum": {
            "precision": 0.67724,
            "recall": 0.6423,
            "fmeasure": 0.65036
        },
        "bleu": 45.60336,
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.4297520661157025,
            "3": 0.7545454545454545
        },
        "bertscore": {
            "precision": 0.9346,
            "recall": 0.92664,
            "f1": 0.92865
        },
        "nubia": {
            "semantic_relation": 3.88361,
            "contradiction": 6.65461,
            "irrelevancy": 29.69872,
            "logical_agreement": 63.64667,
            "grammar_ref": 4.45723,
            "grammar_hyp": 4.46967,
            "nubia_score": 0.67906
        },
        "meteor": 0.3967377034816156,
        "bleurt": 0.29889
    },
    "totto_test_contrast_challenge_table_size-table_size_56": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 64,
        "msttr-100": 0.726,
        "msttr-100_nopunct": 0.79222,
        "total_length": 1069,
        "mean_pred_length": 16.703125,
        "std_pred_length": 5.101101864732266,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5088868101028999,
        "vocab_size-1": 544,
        "unique-1": 437,
        "entropy-1": 7.899692019512919,
        "distinct-2": 0.9134328358208955,
        "vocab_size-2": 918,
        "unique-2": 861,
        "entropy-2": 9.762444487520142,
        "cond_entropy-2": 1.6443907001579454,
        "distinct-3": 0.9776833156216791,
        "vocab_size-3": 920,
        "unique-3": 904,
        "entropy-3": 9.829406452036848,
        "cond_entropy-3": 0.07490485410977492,
        "total_length-nopunct": 925,
        "mean_pred_length-nopunct": 14.453125,
        "std_pred_length-nopunct": 4.565254947357814,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5827027027027027,
        "vocab_size-1-nopunct": 539,
        "unique-1-nopunct": 437,
        "entropy-1-nopunct": 8.178224069411467,
        "distinct-2-nopunct": 0.9256678281068524,
        "vocab_size-2-nopunct": 797,
        "unique-2-nopunct": 759,
        "entropy-2-nopunct": 9.56162529262958,
        "cond_entropy-2-nopunct": 1.4786806031275013,
        "distinct-3-nopunct": 0.9824341279799247,
        "vocab_size-3-nopunct": 783,
        "unique-3-nopunct": 773,
        "entropy-3-nopunct": 9.599515525020937,
        "cond_entropy-3-nopunct": 0.05300644898504722,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.072688710876241,
        "rouge1": {
            "precision": 0.75933,
            "recall": 0.71739,
            "fmeasure": 0.73136
        },
        "rouge2": {
            "precision": 0.51039,
            "recall": 0.48691,
            "fmeasure": 0.49385
        },
        "rougeL": {
            "precision": 0.64622,
            "recall": 0.6144,
            "fmeasure": 0.62416
        },
        "rougeLsum": {
            "precision": 0.64622,
            "recall": 0.6144,
            "fmeasure": 0.62416
        },
        "bleu": 45.19097,
        "local_recall": {
            "1": 0.1752136752136752,
            "2": 0.44052863436123346,
            "3": 0.765034965034965
        },
        "bertscore": {
            "precision": 0.93087,
            "recall": 0.92169,
            "f1": 0.92454
        },
        "nubia": {
            "semantic_relation": 4.23827,
            "contradiction": 8.39798,
            "irrelevancy": 29.53112,
            "logical_agreement": 62.07091,
            "grammar_ref": 4.72038,
            "grammar_hyp": 4.6627,
            "nubia_score": 0.74008
        },
        "meteor": 0.39090669040427256,
        "bleurt": 0.26779
    },
    "totto_test_contrast_challenge_table_size-table_size_57": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.81,
        "total_length": 145,
        "mean_pred_length": 12.083333333333334,
        "std_pred_length": 3.6619287571199717,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.7241379310344828,
        "vocab_size-1": 105,
        "unique-1": 91,
        "entropy-1": 6.333920879667375,
        "distinct-2": 0.9774436090225563,
        "vocab_size-2": 130,
        "unique-2": 128,
        "entropy-2": 7.004493807665383,
        "cond_entropy-2": 0.42344742811468516,
        "distinct-3": 1.0,
        "vocab_size-3": 121,
        "unique-3": 121,
        "entropy-3": 6.918863237274603,
        "cond_entropy-3": -0.08059368167978981,
        "total_length-nopunct": 128,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 3.223179934302286,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.796875,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.440244214908246,
        "distinct-2-nopunct": 0.9741379310344828,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.799749206315803,
        "cond_entropy-2-nopunct": 0.40879007262396033,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 6.7004397181411,
        "cond_entropy-3-nopunct": -0.09259043561952351,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.5310962331564895,
        "rouge1": {
            "precision": 0.79313,
            "recall": 0.76017,
            "fmeasure": 0.76261
        },
        "rouge2": {
            "precision": 0.61072,
            "recall": 0.569,
            "fmeasure": 0.57743
        },
        "rougeL": {
            "precision": 0.68542,
            "recall": 0.65547,
            "fmeasure": 0.65889
        },
        "rougeLsum": {
            "precision": 0.68542,
            "recall": 0.65547,
            "fmeasure": 0.65889
        },
        "bleu": 46.70188,
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.6428571428571429,
            "3": 0.782608695652174
        },
        "bertscore": {
            "precision": 0.93096,
            "recall": 0.93076,
            "f1": 0.92967
        },
        "nubia": {
            "semantic_relation": 4.35793,
            "contradiction": 9.63796,
            "irrelevancy": 21.29864,
            "logical_agreement": 69.0634,
            "grammar_ref": 5.5602,
            "grammar_hyp": 5.43385,
            "nubia_score": 0.75988
        },
        "meteor": 0.4212398811528695,
        "bleurt": 0.28928
    },
    "totto_test_contrast_challenge_table_size-table_size_36": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 131,
        "msttr-100": 0.72238,
        "msttr-100_nopunct": 0.78444,
        "total_length": 2105,
        "mean_pred_length": 16.068702290076335,
        "std_pred_length": 5.73883361782237,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.45890736342042754,
        "vocab_size-1": 966,
        "unique-1": 777,
        "entropy-1": 8.355020105350782,
        "distinct-2": 0.8505572441742655,
        "vocab_size-2": 1679,
        "unique-2": 1531,
        "entropy-2": 10.517409884999763,
        "cond_entropy-2": 1.9051696910007767,
        "distinct-3": 0.9555073250135648,
        "vocab_size-3": 1761,
        "unique-3": 1707,
        "entropy-3": 10.74486276150208,
        "cond_entropy-3": 0.22970171618781676,
        "total_length-nopunct": 1838,
        "mean_pred_length-nopunct": 14.030534351145038,
        "std_pred_length-nopunct": 5.242135412590417,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.5195865070729053,
        "vocab_size-1-nopunct": 955,
        "unique-1-nopunct": 774,
        "entropy-1-nopunct": 8.642565412140254,
        "distinct-2-nopunct": 0.8670181605155243,
        "vocab_size-2-nopunct": 1480,
        "unique-2-nopunct": 1371,
        "entropy-2-nopunct": 10.336293314712242,
        "cond_entropy-2-nopunct": 1.795494637190446,
        "distinct-3-nopunct": 0.9644670050761421,
        "vocab_size-3-nopunct": 1520,
        "unique-3-nopunct": 1479,
        "entropy-3-nopunct": 10.54286781722327,
        "cond_entropy-3-nopunct": 0.23397623328894074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.642493615649677,
        "rouge1": {
            "precision": 0.77496,
            "recall": 0.72203,
            "fmeasure": 0.73551
        },
        "rouge2": {
            "precision": 0.54716,
            "recall": 0.50896,
            "fmeasure": 0.51791
        },
        "rougeL": {
            "precision": 0.67576,
            "recall": 0.62978,
            "fmeasure": 0.64135
        },
        "rougeLsum": {
            "precision": 0.67576,
            "recall": 0.62978,
            "fmeasure": 0.64135
        },
        "bleu": 45.81694,
        "local_recall": {
            "1": 0.19363395225464192,
            "2": 0.47115384615384615,
            "3": 0.7440392706872371
        },
        "bertscore": {
            "precision": 0.93212,
            "recall": 0.92673,
            "f1": 0.92833
        },
        "nubia": {
            "semantic_relation": 4.20798,
            "contradiction": 9.92072,
            "irrelevancy": 26.29788,
            "logical_agreement": 63.7814,
            "grammar_ref": 4.61481,
            "grammar_hyp": 4.68327,
            "nubia_score": 0.71527
        },
        "meteor": 0.386764359505482,
        "bleurt": 0.27132
    },
    "totto_test_contrast_challenge_table_size-table_size_58": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.758686591026307,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.87729,
            "fmeasure": 0.8545
        },
        "rouge2": {
            "precision": 0.64103,
            "recall": 0.67949,
            "fmeasure": 0.65949
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.87729,
            "fmeasure": 0.8545
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.87729,
            "fmeasure": 0.8545
        },
        "bleu": 57.31224,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97775,
            "recall": 0.98898,
            "f1": 0.98333
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18524,
            "irrelevancy": 0.4389,
            "logical_agreement": 99.37586,
            "grammar_ref": 5.12321,
            "grammar_hyp": 4.48706,
            "nubia_score": 1.0
        },
        "meteor": 0.5292514112764231,
        "bleurt": 0.7288
    },
    "totto_test_contrast_challenge_table_size-table_size_80": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 83,
        "msttr-100": 0.72769,
        "msttr-100_nopunct": 0.78727,
        "total_length": 1378,
        "mean_pred_length": 16.602409638554217,
        "std_pred_length": 5.507803355975944,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.4985486211901306,
        "vocab_size-1": 687,
        "unique-1": 562,
        "entropy-1": 8.113650286415291,
        "distinct-2": 0.8756756756756757,
        "vocab_size-2": 1134,
        "unique-2": 1049,
        "entropy-2": 10.000873804770022,
        "cond_entropy-2": 1.6662352342426243,
        "distinct-3": 0.9628712871287128,
        "vocab_size-3": 1167,
        "unique-3": 1135,
        "entropy-3": 10.158797199226653,
        "cond_entropy-3": 0.15630837296949218,
        "total_length-nopunct": 1199,
        "mean_pred_length-nopunct": 14.44578313253012,
        "std_pred_length-nopunct": 5.011439953825629,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5663052543786489,
        "vocab_size-1-nopunct": 679,
        "unique-1-nopunct": 561,
        "entropy-1-nopunct": 8.364362941606682,
        "distinct-2-nopunct": 0.8853046594982079,
        "vocab_size-2-nopunct": 988,
        "unique-2-nopunct": 924,
        "entropy-2-nopunct": 9.804665677199036,
        "cond_entropy-2-nopunct": 1.5307108088222219,
        "distinct-3-nopunct": 0.9699903194578896,
        "vocab_size-3-nopunct": 1002,
        "unique-3-nopunct": 980,
        "entropy-3-nopunct": 9.944129972067145,
        "cond_entropy-3-nopunct": 0.15932375050640812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.548586366668378,
        "rouge1": {
            "precision": 0.78145,
            "recall": 0.73051,
            "fmeasure": 0.74421
        },
        "rouge2": {
            "precision": 0.5456,
            "recall": 0.51197,
            "fmeasure": 0.52052
        },
        "rougeL": {
            "precision": 0.67626,
            "recall": 0.63415,
            "fmeasure": 0.64527
        },
        "rougeLsum": {
            "precision": 0.67626,
            "recall": 0.63415,
            "fmeasure": 0.64527
        },
        "bleu": 48.36751,
        "local_recall": {
            "1": 0.18951612903225806,
            "2": 0.5365853658536586,
            "3": 0.7606837606837606
        },
        "bertscore": {
            "precision": 0.93294,
            "recall": 0.9234,
            "f1": 0.9267
        },
        "nubia": {
            "semantic_relation": 4.26063,
            "contradiction": 7.25265,
            "irrelevancy": 24.43166,
            "logical_agreement": 68.3157,
            "grammar_ref": 4.65999,
            "grammar_hyp": 4.68534,
            "nubia_score": 0.74091
        },
        "meteor": 0.39202520044149397,
        "bleurt": 0.28539
    },
    "totto_test_contrast_challenge_table_size-table_size_37": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74,
        "total_length": 134,
        "mean_pred_length": 13.4,
        "std_pred_length": 4.651881339845203,
        "median_pred_length": 13.0,
        "min_pred_length": 5,
        "max_pred_length": 23,
        "distinct-1": 0.6343283582089553,
        "vocab_size-1": 85,
        "unique-1": 64,
        "entropy-1": 6.068903302825079,
        "distinct-2": 0.8548387096774194,
        "vocab_size-2": 106,
        "unique-2": 96,
        "entropy-2": 6.615171310247286,
        "cond_entropy-2": 0.3587887971597503,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 102,
        "unique-3": 96,
        "entropy-3": 6.58263277720878,
        "cond_entropy-3": -0.020343357587686718,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 12.2,
        "std_pred_length-nopunct": 4.261455150532504,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.680327868852459,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 6.124150222858731,
        "distinct-2-nopunct": 0.8482142857142857,
        "vocab_size-2-nopunct": 95,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.449862957617345,
        "cond_entropy-2-nopunct": 0.37987229857150606,
        "distinct-3-nopunct": 0.8823529411764706,
        "vocab_size-3-nopunct": 90,
        "unique-3-nopunct": 84,
        "entropy-3-nopunct": 6.392726077138354,
        "cond_entropy-3-nopunct": -0.02208864867113876,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.257986495308206,
        "rouge1": {
            "precision": 0.89516,
            "recall": 0.91801,
            "fmeasure": 0.90182
        },
        "rouge2": {
            "precision": 0.81622,
            "recall": 0.85261,
            "fmeasure": 0.82929
        },
        "rougeL": {
            "precision": 0.87103,
            "recall": 0.88714,
            "fmeasure": 0.87452
        },
        "rougeLsum": {
            "precision": 0.87103,
            "recall": 0.88714,
            "fmeasure": 0.87452
        },
        "bleu": 75.06285,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.18181818181818182,
            "3": 0.9245283018867925
        },
        "bertscore": {
            "precision": 0.97819,
            "recall": 0.97773,
            "f1": 0.97743
        },
        "nubia": {
            "semantic_relation": 4.82506,
            "contradiction": 0.25079,
            "irrelevancy": 14.0019,
            "logical_agreement": 85.74732,
            "grammar_ref": 5.03704,
            "grammar_hyp": 4.96364,
            "nubia_score": 0.93517
        },
        "meteor": 0.5554308631009598,
        "bleurt": 0.78836
    },
    "totto_test_contrast_challenge_table_size-table_size_38": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 11.666666666666666,
        "std_pred_length": 2.6874192494328497,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.7571428571428571,
        "vocab_size-1": 53,
        "unique-1": 46,
        "entropy-1": 5.444766631789347,
        "distinct-2": 0.953125,
        "vocab_size-2": 61,
        "unique-2": 58,
        "entropy-2": 5.90625,
        "cond_entropy-2": 0.26246725537609594,
        "distinct-3": 0.9655172413793104,
        "vocab_size-3": 56,
        "unique-3": 54,
        "entropy-3": 5.789015477886191,
        "cond_entropy-3": -0.1075362462517382,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.23606797749979,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8166666666666667,
        "vocab_size-1-nopunct": 49,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.43581288716701,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.643776391052356,
        "cond_entropy-2-nopunct": 0.24178695297143915,
        "distinct-3-nopunct": 0.9583333333333334,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.5016291673878275,
        "cond_entropy-3-nopunct": -0.14909166810897917,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.529415087256286,
        "rouge1": {
            "precision": 0.74957,
            "recall": 0.82401,
            "fmeasure": 0.78038
        },
        "rouge2": {
            "precision": 0.53964,
            "recall": 0.59123,
            "fmeasure": 0.56026
        },
        "rougeL": {
            "precision": 0.71165,
            "recall": 0.79524,
            "fmeasure": 0.74457
        },
        "rougeLsum": {
            "precision": 0.71165,
            "recall": 0.79524,
            "fmeasure": 0.74457
        },
        "bleu": 55.37075,
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.6,
            "3": 0.9696969696969697
        },
        "bertscore": {
            "precision": 0.91817,
            "recall": 0.93601,
            "f1": 0.92654
        },
        "nubia": {
            "semantic_relation": 3.8457,
            "contradiction": 20.14973,
            "irrelevancy": 27.0586,
            "logical_agreement": 52.79166,
            "grammar_ref": 5.1808,
            "grammar_hyp": 4.70192,
            "nubia_score": 0.6778
        },
        "meteor": 0.44418179653911755,
        "bleurt": 0.31707
    },
    "totto_test_contrast_challenge_table_size-table_size_81": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.79,
        "total_length": 196,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 6.7371276438025784,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 29,
        "distinct-1": 0.6581632653061225,
        "vocab_size-1": 129,
        "unique-1": 106,
        "entropy-1": 6.516894619806953,
        "distinct-2": 0.9619565217391305,
        "vocab_size-2": 177,
        "unique-2": 170,
        "entropy-2": 7.447474999535286,
        "cond_entropy-2": 0.8216374544175822,
        "distinct-3": 1.0,
        "vocab_size-3": 172,
        "unique-3": 172,
        "entropy-3": 7.426264754702066,
        "cond_entropy-3": -0.01590185251770574,
        "total_length-nopunct": 167,
        "mean_pred_length-nopunct": 13.916666666666666,
        "std_pred_length-nopunct": 5.251322584729384,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7544910179640718,
        "vocab_size-1-nopunct": 126,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.7436213404406145,
        "distinct-2-nopunct": 0.9741935483870968,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 147,
        "entropy-2-nopunct": 7.2245115020484505,
        "cond_entropy-2-nopunct": 0.5239933578942576,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.159871336778397,
        "cond_entropy-3-nopunct": -0.06030901255179222,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.403327507672227,
        "rouge1": {
            "precision": 0.70236,
            "recall": 0.61405,
            "fmeasure": 0.64397
        },
        "rouge2": {
            "precision": 0.43183,
            "recall": 0.3783,
            "fmeasure": 0.3956
        },
        "rougeL": {
            "precision": 0.55359,
            "recall": 0.48756,
            "fmeasure": 0.51069
        },
        "rougeLsum": {
            "precision": 0.55359,
            "recall": 0.48756,
            "fmeasure": 0.51069
        },
        "bleu": 26.7473,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.325,
            "3": 0.6307692307692307
        },
        "bertscore": {
            "precision": 0.91433,
            "recall": 0.90215,
            "f1": 0.90716
        },
        "nubia": {
            "semantic_relation": 3.96702,
            "contradiction": 6.22471,
            "irrelevancy": 27.23346,
            "logical_agreement": 66.54184,
            "grammar_ref": 4.67736,
            "grammar_hyp": 4.58531,
            "nubia_score": 0.68964
        },
        "meteor": 0.28488502810964556,
        "bleurt": 0.03929
    },
    "web_nlg_ru_test_contrast_challenge_combinations-seen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 494,
        "msttr-100": 0.352,
        "msttr-100_nopunct": 0.58406,
        "total_length": 6583,
        "mean_pred_length": 13.32591093117409,
        "std_pred_length": 6.967031724687027,
        "median_pred_length": 13.0,
        "min_pred_length": 1,
        "max_pred_length": 60,
        "distinct-1": 0.1465897007443415,
        "vocab_size-1": 965,
        "unique-1": 490,
        "entropy-1": 6.172289527598555,
        "distinct-2": 0.3182788635243882,
        "vocab_size-2": 1938,
        "unique-2": 997,
        "entropy-2": 9.933540145354582,
        "cond_entropy-2": 3.9469411083607335,
        "distinct-3": 0.4680128663330951,
        "vocab_size-3": 2619,
        "unique-3": 1611,
        "entropy-3": 10.663119343468878,
        "cond_entropy-3": 0.8061344312697923,
        "total_length-nopunct": 3275,
        "mean_pred_length-nopunct": 6.629554655870446,
        "std_pred_length-nopunct": 3.5487377302052017,
        "median_pred_length-nopunct": 6.5,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.2912977099236641,
        "vocab_size-1-nopunct": 954,
        "unique-1-nopunct": 489,
        "entropy-1-nopunct": 8.852425343175147,
        "distinct-2-nopunct": 0.6177633944624236,
        "vocab_size-2-nopunct": 1718,
        "unique-2-nopunct": 1178,
        "entropy-2-nopunct": 10.413832054616712,
        "cond_entropy-2-nopunct": 1.688767277262348,
        "distinct-3-nopunct": 0.7427078798432738,
        "vocab_size-3-nopunct": 1706,
        "unique-3-nopunct": 1316,
        "entropy-3-nopunct": 10.557392906223404,
        "cond_entropy-3-nopunct": 0.22605807652059196,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.4183906484394195,
        "rouge1": {
            "precision": 0.05367,
            "recall": 0.17448,
            "fmeasure": 0.07498
        },
        "rouge2": {
            "precision": 0.01547,
            "recall": 0.05787,
            "fmeasure": 0.02173
        },
        "rougeL": {
            "precision": 0.05047,
            "recall": 0.16796,
            "fmeasure": 0.07086
        },
        "rougeLsum": {
            "precision": 0.05047,
            "recall": 0.16796,
            "fmeasure": 0.07086
        },
        "bleu": 0.38312,
        "local_recall": {
            "1": 0.0020787139689578712,
            "2": 0.008782201405152224,
            "3": 0.01736239379386775,
            "4": 0.0,
            "5": 0.0,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.60304,
            "recall": 0.53255,
            "f1": 0.56447
        },
        "nubia": {
            "semantic_relation": 2.4044,
            "contradiction": 32.91203,
            "irrelevancy": 33.99218,
            "logical_agreement": 33.09579,
            "grammar_ref": 2.60025,
            "grammar_hyp": 4.71023,
            "nubia_score": 0.2627
        },
        "meteor": 0.022011939022128862,
        "bleurt": -1.29063
    },
    "totto_test_contrast_challenge_table_size-table_size_82": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8093501752298837,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.55754,
            "fmeasure": 0.61111
        },
        "rouge2": {
            "precision": 0.30303,
            "recall": 0.22857,
            "fmeasure": 0.24612
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.38889,
            "fmeasure": 0.41616
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.38889,
            "fmeasure": 0.41616
        },
        "bleu": 12.97528,
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.94492,
            "recall": 0.94376,
            "f1": 0.92226
        },
        "nubia": {
            "semantic_relation": 3.48183,
            "contradiction": 0.09756,
            "irrelevancy": 66.73166,
            "logical_agreement": 33.17078,
            "grammar_ref": 5.89248,
            "grammar_hyp": 6.17242,
            "nubia_score": 0.45234
        },
        "meteor": 0.2953621508171658,
        "bleurt": 0.0645
    },
    "totto_test_contrast_challenge_table_size-table_size_16": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 111,
        "msttr-100": 0.68294,
        "msttr-100_nopunct": 0.73133,
        "total_length": 1773,
        "mean_pred_length": 15.972972972972974,
        "std_pred_length": 5.512409357730744,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 34,
        "distinct-1": 0.4218838127467569,
        "vocab_size-1": 748,
        "unique-1": 630,
        "entropy-1": 7.810794628625985,
        "distinct-2": 0.7478941034897714,
        "vocab_size-2": 1243,
        "unique-2": 1154,
        "entropy-2": 9.723459876688372,
        "cond_entropy-2": 1.698612229504261,
        "distinct-3": 0.8407479045776918,
        "vocab_size-3": 1304,
        "unique-3": 1254,
        "entropy-3": 9.98360289365002,
        "cond_entropy-3": 0.2867529352661438,
        "total_length-nopunct": 1519,
        "mean_pred_length-nopunct": 13.684684684684685,
        "std_pred_length-nopunct": 4.659547946178729,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4858459512837393,
        "vocab_size-1-nopunct": 738,
        "unique-1-nopunct": 627,
        "entropy-1-nopunct": 8.062646272557034,
        "distinct-2-nopunct": 0.7613636363636364,
        "vocab_size-2-nopunct": 1072,
        "unique-2-nopunct": 1010,
        "entropy-2-nopunct": 9.502937943434507,
        "cond_entropy-2-nopunct": 1.5604218260737746,
        "distinct-3-nopunct": 0.8481110254433307,
        "vocab_size-3-nopunct": 1100,
        "unique-3-nopunct": 1063,
        "entropy-3-nopunct": 9.744276925823531,
        "cond_entropy-3-nopunct": 0.28658103701600096,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.211485768838992,
        "rouge1": {
            "precision": 0.77308,
            "recall": 0.71281,
            "fmeasure": 0.73028
        },
        "rouge2": {
            "precision": 0.57144,
            "recall": 0.52337,
            "fmeasure": 0.53786
        },
        "rougeL": {
            "precision": 0.68168,
            "recall": 0.62904,
            "fmeasure": 0.64383
        },
        "rougeLsum": {
            "precision": 0.68168,
            "recall": 0.62904,
            "fmeasure": 0.64383
        },
        "bleu": 48.50543,
        "local_recall": {
            "1": 0.18484848484848485,
            "2": 0.43703703703703706,
            "3": 0.7414205905826018
        },
        "bertscore": {
            "precision": 0.93358,
            "recall": 0.92382,
            "f1": 0.92675
        },
        "nubia": {
            "semantic_relation": 4.19408,
            "contradiction": 6.47723,
            "irrelevancy": 21.64002,
            "logical_agreement": 71.88276,
            "grammar_ref": 4.48776,
            "grammar_hyp": 4.50294,
            "nubia_score": 0.73887
        },
        "meteor": 0.3884457037918066,
        "bleurt": 0.33659
    },
    "totto_test_contrast_challenge_table_size-table_size_39": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.6975,
        "msttr-100_nopunct": 0.74,
        "total_length": 413,
        "mean_pred_length": 15.884615384615385,
        "std_pred_length": 4.2906600090906135,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.559322033898305,
        "vocab_size-1": 231,
        "unique-1": 190,
        "entropy-1": 6.997073429065763,
        "distinct-2": 0.8940568475452196,
        "vocab_size-2": 346,
        "unique-2": 316,
        "entropy-2": 8.35777977550746,
        "cond_entropy-2": 1.1586510633138962,
        "distinct-3": 0.9750692520775623,
        "vocab_size-3": 352,
        "unique-3": 343,
        "entropy-3": 8.445993531042319,
        "cond_entropy-3": 0.09221312394034288,
        "total_length-nopunct": 357,
        "mean_pred_length-nopunct": 13.73076923076923,
        "std_pred_length-nopunct": 3.5794036064007635,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6302521008403361,
        "vocab_size-1-nopunct": 225,
        "unique-1-nopunct": 189,
        "entropy-1-nopunct": 7.1212585977283815,
        "distinct-2-nopunct": 0.9063444108761329,
        "vocab_size-2-nopunct": 300,
        "unique-2-nopunct": 278,
        "entropy-2-nopunct": 8.156926417374653,
        "cond_entropy-2-nopunct": 1.1159296801347396,
        "distinct-3-nopunct": 0.9737704918032787,
        "vocab_size-3-nopunct": 297,
        "unique-3-nopunct": 289,
        "entropy-3-nopunct": 8.200206416056762,
        "cond_entropy-3-nopunct": 0.058223558437009756,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.044149274531488,
        "rouge1": {
            "precision": 0.70023,
            "recall": 0.70556,
            "fmeasure": 0.68639
        },
        "rouge2": {
            "precision": 0.45359,
            "recall": 0.44883,
            "fmeasure": 0.44036
        },
        "rougeL": {
            "precision": 0.62908,
            "recall": 0.64281,
            "fmeasure": 0.6217
        },
        "rougeLsum": {
            "precision": 0.62908,
            "recall": 0.64281,
            "fmeasure": 0.6217
        },
        "bleu": 43.12216,
        "local_recall": {
            "1": 0.3103448275862069,
            "2": 0.4946236559139785,
            "3": 0.7339055793991416
        },
        "bertscore": {
            "precision": 0.90776,
            "recall": 0.90805,
            "f1": 0.906
        },
        "nubia": {
            "semantic_relation": 3.8133,
            "contradiction": 10.61789,
            "irrelevancy": 47.62746,
            "logical_agreement": 41.75465,
            "grammar_ref": 4.64456,
            "grammar_hyp": 4.54342,
            "nubia_score": 0.61956
        },
        "meteor": 0.3562661103545709,
        "bleurt": 0.07363
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 460,
        "msttr-100": 0.29557,
        "msttr-100_nopunct": 0.47333,
        "total_length": 6160,
        "mean_pred_length": 13.391304347826088,
        "std_pred_length": 6.585815656689317,
        "median_pred_length": 12.0,
        "min_pred_length": 3,
        "max_pred_length": 60,
        "distinct-1": 0.1292207792207792,
        "vocab_size-1": 796,
        "unique-1": 374,
        "entropy-1": 5.866487770012566,
        "distinct-2": 0.29385964912280704,
        "vocab_size-2": 1675,
        "unique-2": 826,
        "entropy-2": 9.691850247925753,
        "cond_entropy-2": 3.960916206774484,
        "distinct-3": 0.44656488549618323,
        "vocab_size-3": 2340,
        "unique-3": 1426,
        "entropy-3": 10.438762071985947,
        "cond_entropy-3": 0.8131348795182958,
        "total_length-nopunct": 3047,
        "mean_pred_length-nopunct": 6.623913043478261,
        "std_pred_length-nopunct": 3.3021524457612883,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.25894322284213983,
        "vocab_size-1-nopunct": 789,
        "unique-1-nopunct": 374,
        "entropy-1-nopunct": 8.566176495006609,
        "distinct-2-nopunct": 0.5956706609972942,
        "vocab_size-2-nopunct": 1541,
        "unique-2-nopunct": 1043,
        "entropy-2-nopunct": 10.25559744247478,
        "cond_entropy-2-nopunct": 1.8077369152421667,
        "distinct-3-nopunct": 0.7305164319248826,
        "vocab_size-3-nopunct": 1556,
        "unique-3-nopunct": 1197,
        "entropy-3-nopunct": 10.410587451641357,
        "cond_entropy-3-nopunct": 0.22476496739639698,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.16906435548830384,
        "rouge1": {
            "precision": 0.02014,
            "recall": 0.10012,
            "fmeasure": 0.03207
        },
        "rouge2": {
            "precision": 0.00408,
            "recall": 0.01761,
            "fmeasure": 0.00612
        },
        "rougeL": {
            "precision": 0.01909,
            "recall": 0.09599,
            "fmeasure": 0.03041
        },
        "rougeLsum": {
            "precision": 0.01909,
            "recall": 0.09599,
            "fmeasure": 0.03041
        },
        "bleu": 0.15821,
        "local_recall": {
            "1": 0.0016689847009735744,
            "2": 0.0052821795941062,
            "3": 0.003998400639744102,
            "4": 0.0,
            "5": 0.0,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.58465,
            "recall": 0.5184,
            "f1": 0.54845
        },
        "nubia": {
            "semantic_relation": 2.36091,
            "contradiction": 33.24012,
            "irrelevancy": 35.02449,
            "logical_agreement": 31.73538,
            "grammar_ref": 2.52111,
            "grammar_hyp": 4.78527,
            "nubia_score": 0.22837
        },
        "meteor": 0.012213170765661573,
        "bleurt": -1.30195
    },
    "totto_test_contrast_challenge_table_size-table_size_84": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 80,
        "msttr-100": 0.72583,
        "msttr-100_nopunct": 0.78273,
        "total_length": 1295,
        "mean_pred_length": 16.1875,
        "std_pred_length": 5.601548335058799,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.5127413127413127,
        "vocab_size-1": 664,
        "unique-1": 539,
        "entropy-1": 8.13554857997949,
        "distinct-2": 0.9119341563786009,
        "vocab_size-2": 1108,
        "unique-2": 1041,
        "entropy-2": 10.022463663664974,
        "cond_entropy-2": 1.6944556751309017,
        "distinct-3": 0.9859030837004406,
        "vocab_size-3": 1119,
        "unique-3": 1103,
        "entropy-3": 10.1202827495792,
        "cond_entropy-3": 0.101224671102911,
        "total_length-nopunct": 1132,
        "mean_pred_length-nopunct": 14.15,
        "std_pred_length-nopunct": 5.19879793798528,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5795053003533569,
        "vocab_size-1-nopunct": 656,
        "unique-1-nopunct": 536,
        "entropy-1-nopunct": 8.408157771860836,
        "distinct-2-nopunct": 0.9287072243346007,
        "vocab_size-2-nopunct": 977,
        "unique-2-nopunct": 933,
        "entropy-2-nopunct": 9.849397068819435,
        "cond_entropy-2-nopunct": 1.53366518352523,
        "distinct-3-nopunct": 0.9917695473251029,
        "vocab_size-3-nopunct": 964,
        "unique-3-nopunct": 956,
        "entropy-3-nopunct": 9.908351598255917,
        "cond_entropy-3-nopunct": 0.07455304140963269,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.007563130686755,
        "rouge1": {
            "precision": 0.74802,
            "recall": 0.69569,
            "fmeasure": 0.70993
        },
        "rouge2": {
            "precision": 0.50247,
            "recall": 0.46319,
            "fmeasure": 0.47468
        },
        "rougeL": {
            "precision": 0.65524,
            "recall": 0.61254,
            "fmeasure": 0.62282
        },
        "rougeLsum": {
            "precision": 0.65524,
            "recall": 0.61254,
            "fmeasure": 0.62282
        },
        "bleu": 40.9573,
        "local_recall": {
            "1": 0.25,
            "2": 0.4272300469483568,
            "3": 0.7114317425083241
        },
        "bertscore": {
            "precision": 0.92452,
            "recall": 0.91862,
            "f1": 0.9199
        },
        "nubia": {
            "semantic_relation": 4.12243,
            "contradiction": 8.98201,
            "irrelevancy": 32.20038,
            "logical_agreement": 58.81761,
            "grammar_ref": 4.79239,
            "grammar_hyp": 4.76235,
            "nubia_score": 0.70633
        },
        "meteor": 0.3635744766365266,
        "bleurt": 0.26054
    },
    "totto_test_contrast_challenge_table_size-table_size_17": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.54,
        "msttr-100_nopunct": 0.56,
        "total_length": 709,
        "mean_pred_length": 14.770833333333334,
        "std_pred_length": 3.531050264754415,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.3342736248236953,
        "vocab_size-1": 237,
        "unique-1": 191,
        "entropy-1": 6.348085135551591,
        "distinct-2": 0.5960665658093798,
        "vocab_size-2": 394,
        "unique-2": 349,
        "entropy-2": 7.905005170152733,
        "cond_entropy-2": 1.3793724452956655,
        "distinct-3": 0.7096247960848288,
        "vocab_size-3": 435,
        "unique-3": 397,
        "entropy-3": 8.27494504890729,
        "cond_entropy-3": 0.4061698330247824,
        "total_length-nopunct": 613,
        "mean_pred_length-nopunct": 12.770833333333334,
        "std_pred_length-nopunct": 3.0838259741575706,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.3768352365415987,
        "vocab_size-1-nopunct": 231,
        "unique-1-nopunct": 190,
        "entropy-1-nopunct": 6.441692650734524,
        "distinct-2-nopunct": 0.6070796460176991,
        "vocab_size-2-nopunct": 343,
        "unique-2-nopunct": 305,
        "entropy-2-nopunct": 7.72825071171246,
        "cond_entropy-2-nopunct": 1.3703361535328769,
        "distinct-3-nopunct": 0.7098646034816247,
        "vocab_size-3-nopunct": 367,
        "unique-3-nopunct": 333,
        "entropy-3-nopunct": 8.03693733559677,
        "cond_entropy-3-nopunct": 0.4099541859421668,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.527335305676142,
        "rouge1": {
            "precision": 0.84737,
            "recall": 0.8216,
            "fmeasure": 0.82714
        },
        "rouge2": {
            "precision": 0.68502,
            "recall": 0.66659,
            "fmeasure": 0.67091
        },
        "rougeL": {
            "precision": 0.79547,
            "recall": 0.77055,
            "fmeasure": 0.7764
        },
        "rougeLsum": {
            "precision": 0.79547,
            "recall": 0.77055,
            "fmeasure": 0.7764
        },
        "bleu": 67.74784,
        "local_recall": {
            "1": 0.22972972972972974,
            "2": 0.6625,
            "3": 0.8362919132149902
        },
        "bertscore": {
            "precision": 0.96212,
            "recall": 0.95557,
            "f1": 0.95794
        },
        "nubia": {
            "semantic_relation": 4.53978,
            "contradiction": 5.46227,
            "irrelevancy": 12.7922,
            "logical_agreement": 81.74554,
            "grammar_ref": 4.06325,
            "grammar_hyp": 4.00786,
            "nubia_score": 0.87554
        },
        "meteor": 0.46863107145459776,
        "bleurt": 0.63705
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 158,
        "msttr-100": 0.52324,
        "msttr-100_nopunct": 0.53886,
        "total_length": 3796,
        "mean_pred_length": 24.025316455696203,
        "std_pred_length": 2.6264221393915665,
        "median_pred_length": 24.0,
        "min_pred_length": 18,
        "max_pred_length": 30,
        "distinct-1": 0.19099051633298209,
        "vocab_size-1": 725,
        "unique-1": 264,
        "entropy-1": 7.781495732833151,
        "distinct-2": 0.44310060472787244,
        "vocab_size-2": 1612,
        "unique-2": 932,
        "entropy-2": 10.032837657791825,
        "cond_entropy-2": 2.3227783002966693,
        "distinct-3": 0.603735632183908,
        "vocab_size-3": 2101,
        "unique-3": 1467,
        "entropy-3": 10.662999022227607,
        "cond_entropy-3": 0.6828832162315828,
        "total_length-nopunct": 3542,
        "mean_pred_length-nopunct": 22.417721518987342,
        "std_pred_length-nopunct": 2.7100730754625526,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.20242800677583286,
        "vocab_size-1-nopunct": 717,
        "unique-1-nopunct": 263,
        "entropy-1-nopunct": 7.854463405744533,
        "distinct-2-nopunct": 0.45951536643026003,
        "vocab_size-2-nopunct": 1555,
        "unique-2-nopunct": 923,
        "entropy-2-nopunct": 10.023278552506737,
        "cond_entropy-2-nopunct": 2.2613248210406454,
        "distinct-3-nopunct": 0.6205827650340979,
        "vocab_size-3-nopunct": 2002,
        "unique-3-nopunct": 1430,
        "entropy-3-nopunct": 10.610523808105823,
        "cond_entropy-3-nopunct": 0.6383899567180812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 2.873804278585243,
        "rouge1": {
            "precision": 0.76929,
            "recall": 0.52885,
            "fmeasure": 0.61308
        },
        "rouge2": {
            "precision": 0.4838,
            "recall": 0.31709,
            "fmeasure": 0.37328
        },
        "rougeL": {
            "precision": 0.58876,
            "recall": 0.39806,
            "fmeasure": 0.46367
        },
        "rougeLsum": {
            "precision": 0.58876,
            "recall": 0.39806,
            "fmeasure": 0.46367
        },
        "bleu": 28.33043,
        "local_recall": {
            "1": 0.15992812219227315,
            "2": 0.37392795883361923,
            "3": 0.6337477797513321
        },
        "bertscore": {
            "precision": 0.90106,
            "recall": 0.84785,
            "f1": 0.8721
        },
        "nubia": {
            "semantic_relation": 3.47656,
            "contradiction": 7.46335,
            "irrelevancy": 12.89727,
            "logical_agreement": 79.63938,
            "grammar_ref": 4.0976,
            "grammar_hyp": 4.52742,
            "nubia_score": 0.47669
        },
        "meteor": 0.25966622455065386,
        "bleurt": -0.30278
    },
    "totto_test_contrast_challenge_table_size-table_size_6": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 144,
        "msttr-100": 0.7015,
        "msttr-100_nopunct": 0.73722,
        "total_length": 2065,
        "mean_pred_length": 14.340277777777779,
        "std_pred_length": 5.330941122932502,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.36368038740920094,
        "vocab_size-1": 751,
        "unique-1": 540,
        "entropy-1": 7.966057180757652,
        "distinct-2": 0.6959916710046851,
        "vocab_size-2": 1337,
        "unique-2": 1137,
        "entropy-2": 9.919945747313632,
        "cond_entropy-2": 1.6858322948232067,
        "distinct-3": 0.8418683173888576,
        "vocab_size-3": 1496,
        "unique-3": 1362,
        "entropy-3": 10.362962747728867,
        "cond_entropy-3": 0.4292461964729757,
        "total_length-nopunct": 1825,
        "mean_pred_length-nopunct": 12.67361111111111,
        "std_pred_length-nopunct": 4.919956330416955,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4071232876712329,
        "vocab_size-1-nopunct": 743,
        "unique-1-nopunct": 539,
        "entropy-1-nopunct": 8.17461818595361,
        "distinct-2-nopunct": 0.7156454491374182,
        "vocab_size-2-nopunct": 1203,
        "unique-2-nopunct": 1043,
        "entropy-2-nopunct": 9.767246224491641,
        "cond_entropy-2-nopunct": 1.6650951801588447,
        "distinct-3-nopunct": 0.852309694209499,
        "vocab_size-3-nopunct": 1310,
        "unique-3-nopunct": 1205,
        "entropy-3-nopunct": 10.178479691634111,
        "cond_entropy-3-nopunct": 0.44127452809963386,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.687915592831957,
        "rouge1": {
            "precision": 0.75916,
            "recall": 0.72545,
            "fmeasure": 0.72705
        },
        "rouge2": {
            "precision": 0.54597,
            "recall": 0.52956,
            "fmeasure": 0.52596
        },
        "rougeL": {
            "precision": 0.67994,
            "recall": 0.65353,
            "fmeasure": 0.65206
        },
        "rougeLsum": {
            "precision": 0.67994,
            "recall": 0.65353,
            "fmeasure": 0.65206
        },
        "bleu": 48.34598,
        "local_recall": {
            "1": 0.24124513618677043,
            "2": 0.5209713024282561,
            "3": 0.757976653696498
        },
        "bertscore": {
            "precision": 0.93061,
            "recall": 0.92427,
            "f1": 0.92538
        },
        "nubia": {
            "semantic_relation": 4.08496,
            "contradiction": 4.97628,
            "irrelevancy": 34.9174,
            "logical_agreement": 60.10632,
            "grammar_ref": 4.70586,
            "grammar_hyp": 4.6737,
            "nubia_score": 0.71733
        },
        "meteor": 0.4086738382830753,
        "bleurt": 0.26999
    },
    "totto_test_contrast_challenge_table_size-table_size_85": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.77,
        "total_length": 422,
        "mean_pred_length": 16.88,
        "std_pred_length": 5.171614834846076,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5781990521327014,
        "vocab_size-1": 244,
        "unique-1": 195,
        "entropy-1": 7.246812072272431,
        "distinct-2": 0.9219143576826196,
        "vocab_size-2": 366,
        "unique-2": 344,
        "entropy-2": 8.457240946486007,
        "cond_entropy-2": 1.0790274976704652,
        "distinct-3": 0.9758064516129032,
        "vocab_size-3": 363,
        "unique-3": 354,
        "entropy-3": 8.49077171433388,
        "cond_entropy-3": 0.04265403738124884,
        "total_length-nopunct": 368,
        "mean_pred_length-nopunct": 14.72,
        "std_pred_length-nopunct": 4.3956341977011695,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6467391304347826,
        "vocab_size-1-nopunct": 238,
        "unique-1-nopunct": 194,
        "entropy-1-nopunct": 7.361462105984397,
        "distinct-2-nopunct": 0.9271137026239067,
        "vocab_size-2-nopunct": 318,
        "unique-2-nopunct": 302,
        "entropy-2-nopunct": 8.253626172846786,
        "cond_entropy-2-nopunct": 0.9681188664304389,
        "distinct-3-nopunct": 0.9842767295597484,
        "vocab_size-3-nopunct": 313,
        "unique-3-nopunct": 308,
        "entropy-3-nopunct": 8.281436414403867,
        "cond_entropy-3-nopunct": 0.041052269334238924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.121564364171537,
        "rouge1": {
            "precision": 0.73504,
            "recall": 0.70544,
            "fmeasure": 0.70974
        },
        "rouge2": {
            "precision": 0.54068,
            "recall": 0.50825,
            "fmeasure": 0.51692
        },
        "rougeL": {
            "precision": 0.64507,
            "recall": 0.62367,
            "fmeasure": 0.62529
        },
        "rougeLsum": {
            "precision": 0.64507,
            "recall": 0.62367,
            "fmeasure": 0.62529
        },
        "bleu": 45.33435,
        "local_recall": {
            "1": 0.15942028985507245,
            "2": 0.4057971014492754,
            "3": 0.7385159010600707
        },
        "bertscore": {
            "precision": 0.92421,
            "recall": 0.921,
            "f1": 0.92166
        },
        "nubia": {
            "semantic_relation": 3.93175,
            "contradiction": 12.25262,
            "irrelevancy": 30.95851,
            "logical_agreement": 56.78887,
            "grammar_ref": 4.78896,
            "grammar_hyp": 4.82667,
            "nubia_score": 0.64053
        },
        "meteor": 0.3835996690124684,
        "bleurt": 0.11635
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 213,
        "msttr-100": 0.66412,
        "msttr-100_nopunct": 0.67723,
        "total_length": 5153,
        "mean_pred_length": 24.1924882629108,
        "std_pred_length": 2.524163024225443,
        "median_pred_length": 24.0,
        "min_pred_length": 19,
        "max_pred_length": 30,
        "distinct-1": 0.18008926838734718,
        "vocab_size-1": 928,
        "unique-1": 372,
        "entropy-1": 7.937892383462059,
        "distinct-2": 0.444331983805668,
        "vocab_size-2": 2195,
        "unique-2": 1331,
        "entropy-2": 10.417777851974439,
        "cond_entropy-2": 2.5551817742144416,
        "distinct-3": 0.6259784218320288,
        "vocab_size-3": 2959,
        "unique-3": 2135,
        "entropy-3": 11.173711890516334,
        "cond_entropy-3": 0.8123901424881537,
        "total_length-nopunct": 4797,
        "mean_pred_length-nopunct": 22.52112676056338,
        "std_pred_length-nopunct": 2.548271005090934,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.19178653324994788,
        "vocab_size-1-nopunct": 920,
        "unique-1-nopunct": 370,
        "entropy-1-nopunct": 8.039150889983475,
        "distinct-2-nopunct": 0.46138743455497383,
        "vocab_size-2-nopunct": 2115,
        "unique-2-nopunct": 1314,
        "entropy-2-nopunct": 10.419167325418561,
        "cond_entropy-2-nopunct": 2.479689150339784,
        "distinct-3-nopunct": 0.6412720201326928,
        "vocab_size-3-nopunct": 2803,
        "unique-3-nopunct": 2066,
        "entropy-3-nopunct": 11.108682219872492,
        "cond_entropy-3-nopunct": 0.7446450212332767,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 4.10003958123136,
        "rouge1": {
            "precision": 0.7489,
            "recall": 0.53965,
            "fmeasure": 0.61828
        },
        "rouge2": {
            "precision": 0.45823,
            "recall": 0.31588,
            "fmeasure": 0.36756
        },
        "rougeL": {
            "precision": 0.57128,
            "recall": 0.40541,
            "fmeasure": 0.4668
        },
        "rougeLsum": {
            "precision": 0.57128,
            "recall": 0.40541,
            "fmeasure": 0.4668
        },
        "bleu": 30.53167,
        "local_recall": {
            "1": 0.16256499133448873,
            "2": 0.3986527862829149,
            "3": 0.6615739406168925
        },
        "bertscore": {
            "precision": 0.90038,
            "recall": 0.85355,
            "f1": 0.87482
        },
        "nubia": {
            "semantic_relation": 3.51171,
            "contradiction": 8.81618,
            "irrelevancy": 14.62533,
            "logical_agreement": 76.55849,
            "grammar_ref": 4.14495,
            "grammar_hyp": 4.52651,
            "nubia_score": 0.4737
        },
        "meteor": 0.2707342370924386,
        "bleurt": -0.28704
    },
    "totto_test_contrast_challenge_table_size-table_size_86": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.02961067210860199,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.023638630780208267,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4761904761904763,
        "rouge1": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "rouge2": {
            "precision": 0.41176,
            "recall": 0.58333,
            "fmeasure": 0.48276
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.76923,
            "fmeasure": 0.64516
        },
        "bleu": 42.18752,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.90683,
            "recall": 0.96715,
            "f1": 0.93602
        },
        "nubia": {
            "semantic_relation": 3.87181,
            "contradiction": 0.14944,
            "irrelevancy": 99.72932,
            "logical_agreement": 0.12125,
            "grammar_ref": 3.82301,
            "grammar_hyp": 3.607,
            "nubia_score": 0.77748
        },
        "meteor": 0.5257564971249777,
        "bleurt": 0.45281
    },
    "totto_test_contrast_challenge_table_size-table_size_87": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 8.640987597877148,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 32,
        "unique-1": 24,
        "entropy-1": 4.8801799226757385,
        "distinct-2": 0.9487179487179487,
        "vocab_size-2": 37,
        "unique-2": 35,
        "entropy-2": 5.182838116298145,
        "cond_entropy-2": 0.29077133465597377,
        "distinct-3": 0.9722222222222222,
        "vocab_size-3": 35,
        "unique-3": 34,
        "entropy-3": 5.114369445886754,
        "cond_entropy-3": -0.05992166186438025,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 8.640987597877148,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.785151577725659,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.058813890331199,
        "cond_entropy-2-nopunct": 0.2875720882558123,
        "distinct-3-nopunct": 0.9696969696969697,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.9837880587523955,
        "cond_entropy-3-nopunct": -0.06492482147779848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.009021197916642,
        "rouge1": {
            "precision": 0.58594,
            "recall": 0.53704,
            "fmeasure": 0.55644
        },
        "rouge2": {
            "precision": 0.35333,
            "recall": 0.3351,
            "fmeasure": 0.34084
        },
        "rougeL": {
            "precision": 0.57312,
            "recall": 0.52513,
            "fmeasure": 0.54409
        },
        "rougeLsum": {
            "precision": 0.57312,
            "recall": 0.52513,
            "fmeasure": 0.54409
        },
        "bleu": 11.58639,
        "local_recall": {
            "1": 0.0,
            "2": 0.18181818181818182,
            "3": 0.53125
        },
        "bertscore": {
            "precision": 0.89152,
            "recall": 0.88562,
            "f1": 0.88786
        },
        "nubia": {
            "semantic_relation": 3.38563,
            "contradiction": 21.46349,
            "irrelevancy": 22.93693,
            "logical_agreement": 55.59957,
            "grammar_ref": 5.04645,
            "grammar_hyp": 5.21865,
            "nubia_score": 0.4424
        },
        "meteor": 0.2615930656105834,
        "bleurt": 0.02408
    },
    "totto_test_contrast_challenge_table_size-table_size_60": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.78,
        "total_length": 1892,
        "mean_pred_length": 16.596491228070175,
        "std_pred_length": 5.163500951339552,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.4704016913319239,
        "vocab_size-1": 890,
        "unique-1": 718,
        "entropy-1": 8.31383455722439,
        "distinct-2": 0.8622047244094488,
        "vocab_size-2": 1533,
        "unique-2": 1409,
        "entropy-2": 10.403560402218451,
        "cond_entropy-2": 1.852226147589256,
        "distinct-3": 0.9645432692307693,
        "vocab_size-3": 1605,
        "unique-3": 1556,
        "entropy-3": 10.624181393026879,
        "cond_entropy-3": 0.20911184210893818,
        "total_length-nopunct": 1649,
        "mean_pred_length-nopunct": 14.464912280701755,
        "std_pred_length-nopunct": 4.742824357599822,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5336567616737417,
        "vocab_size-1-nopunct": 880,
        "unique-1-nopunct": 713,
        "entropy-1-nopunct": 8.614841209954205,
        "distinct-2-nopunct": 0.8775244299674267,
        "vocab_size-2-nopunct": 1347,
        "unique-2-nopunct": 1255,
        "entropy-2-nopunct": 10.222847141331302,
        "cond_entropy-2-nopunct": 1.6926764890505304,
        "distinct-3-nopunct": 0.9669247009148487,
        "vocab_size-3-nopunct": 1374,
        "unique-3-nopunct": 1334,
        "entropy-3-nopunct": 10.401875082393055,
        "cond_entropy-3-nopunct": 0.19832361564010212,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.667490535128502,
        "rouge1": {
            "precision": 0.7438,
            "recall": 0.73241,
            "fmeasure": 0.72635
        },
        "rouge2": {
            "precision": 0.50635,
            "recall": 0.4981,
            "fmeasure": 0.494
        },
        "rougeL": {
            "precision": 0.62625,
            "recall": 0.62871,
            "fmeasure": 0.61645
        },
        "rougeLsum": {
            "precision": 0.62625,
            "recall": 0.62871,
            "fmeasure": 0.61645
        },
        "bleu": 43.19282,
        "local_recall": {
            "1": 0.24533333333333332,
            "2": 0.5123152709359606,
            "3": 0.7821080602302923
        },
        "bertscore": {
            "precision": 0.92679,
            "recall": 0.924,
            "f1": 0.92395
        },
        "nubia": {
            "semantic_relation": 4.18025,
            "contradiction": 6.36755,
            "irrelevancy": 33.4681,
            "logical_agreement": 60.16435,
            "grammar_ref": 4.84845,
            "grammar_hyp": 4.68527,
            "nubia_score": 0.72773
        },
        "meteor": 0.38861082795138335,
        "bleurt": 0.26096
    },
    "totto_test_contrast_challenge_table_size-table_size_61": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.272001872658765,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 19,
        "distinct-1": 0.7407407407407407,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.1343361131944505,
        "distinct-2": 0.98,
        "vocab_size-2": 49,
        "unique-2": 48,
        "entropy-2": 5.603856189774728,
        "cond_entropy-2": 0.35916418769779485,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.07681597284814654,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 4.272001872658765,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.78,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.133660689688187,
        "distinct-2-nopunct": 0.9782608695652174,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.480083695187445,
        "cond_entropy-2-nopunct": 0.36904870115896066,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.3923174227787625,
        "cond_entropy-3-nopunct": -0.08362548565920491,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.462109918524034,
        "rouge1": {
            "precision": 0.71248,
            "recall": 0.81271,
            "fmeasure": 0.72474
        },
        "rouge2": {
            "precision": 0.49171,
            "recall": 0.58954,
            "fmeasure": 0.50794
        },
        "rougeL": {
            "precision": 0.6557,
            "recall": 0.78525,
            "fmeasure": 0.68792
        },
        "rougeLsum": {
            "precision": 0.6557,
            "recall": 0.78525,
            "fmeasure": 0.68792
        },
        "bleu": 36.34603,
        "local_recall": {
            "1": 0.42105263157894735,
            "2": 0.6571428571428571,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.90751,
            "recall": 0.91977,
            "f1": 0.90756
        },
        "nubia": {
            "semantic_relation": 3.99169,
            "contradiction": 0.94915,
            "irrelevancy": 48.14325,
            "logical_agreement": 50.9076,
            "grammar_ref": 5.36601,
            "grammar_hyp": 5.01721,
            "nubia_score": 0.64958
        },
        "meteor": 0.4119696675115638,
        "bleurt": 0.0856
    },
    "totto_test_contrast_challenge_table_size-table_size_7": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.68286,
        "msttr-100_nopunct": 0.73167,
        "total_length": 762,
        "mean_pred_length": 16.21276595744681,
        "std_pred_length": 5.507967807708757,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.4461942257217848,
        "vocab_size-1": 340,
        "unique-1": 250,
        "entropy-1": 7.342468582969854,
        "distinct-2": 0.7748251748251749,
        "vocab_size-2": 554,
        "unique-2": 478,
        "entropy-2": 8.86789875860185,
        "cond_entropy-2": 1.321615593057216,
        "distinct-3": 0.8727544910179641,
        "vocab_size-3": 583,
        "unique-3": 540,
        "entropy-3": 9.047722776222688,
        "cond_entropy-3": 0.2039234848841669,
        "total_length-nopunct": 649,
        "mean_pred_length-nopunct": 13.808510638297872,
        "std_pred_length-nopunct": 4.661468574512052,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.514637904468413,
        "vocab_size-1-nopunct": 334,
        "unique-1-nopunct": 250,
        "entropy-1-nopunct": 7.5355990118232565,
        "distinct-2-nopunct": 0.7873754152823921,
        "vocab_size-2-nopunct": 474,
        "unique-2-nopunct": 416,
        "entropy-2-nopunct": 8.643645351626903,
        "cond_entropy-2-nopunct": 1.1923739547801848,
        "distinct-3-nopunct": 0.8774774774774775,
        "vocab_size-3-nopunct": 487,
        "unique-3-nopunct": 454,
        "entropy-3-nopunct": 8.792594834473936,
        "cond_entropy-3-nopunct": 0.1805870833511856,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.41846275509624,
        "rouge1": {
            "precision": 0.71748,
            "recall": 0.74633,
            "fmeasure": 0.71784
        },
        "rouge2": {
            "precision": 0.4942,
            "recall": 0.49883,
            "fmeasure": 0.48915
        },
        "rougeL": {
            "precision": 0.63085,
            "recall": 0.65437,
            "fmeasure": 0.63094
        },
        "rougeLsum": {
            "precision": 0.63085,
            "recall": 0.65437,
            "fmeasure": 0.63094
        },
        "bleu": 46.63533,
        "local_recall": {
            "1": 0.21379310344827587,
            "2": 0.39568345323741005,
            "3": 0.7569892473118279
        },
        "bertscore": {
            "precision": 0.91868,
            "recall": 0.92445,
            "f1": 0.91996
        },
        "nubia": {
            "semantic_relation": 4.05111,
            "contradiction": 8.60139,
            "irrelevancy": 30.82514,
            "logical_agreement": 60.57347,
            "grammar_ref": 4.53522,
            "grammar_hyp": 4.21147,
            "nubia_score": 0.70727
        },
        "meteor": 0.3920318382405033,
        "bleurt": 0.30516
    },
    "totto_test_contrast_challenge_table_size-table_size_40": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 110,
        "msttr-100": 0.72647,
        "msttr-100_nopunct": 0.76867,
        "total_length": 1756,
        "mean_pred_length": 15.963636363636363,
        "std_pred_length": 5.31708613421653,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.46867881548974943,
        "vocab_size-1": 823,
        "unique-1": 654,
        "entropy-1": 8.230745625559177,
        "distinct-2": 0.850546780072904,
        "vocab_size-2": 1400,
        "unique-2": 1277,
        "entropy-2": 10.268962979216848,
        "cond_entropy-2": 1.778056246554564,
        "distinct-3": 0.9498697916666666,
        "vocab_size-3": 1459,
        "unique-3": 1403,
        "entropy-3": 10.470927008861821,
        "cond_entropy-3": 0.20503490889231812,
        "total_length-nopunct": 1544,
        "mean_pred_length-nopunct": 14.036363636363637,
        "std_pred_length-nopunct": 4.74423530139909,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5278497409326425,
        "vocab_size-1-nopunct": 815,
        "unique-1-nopunct": 653,
        "entropy-1-nopunct": 8.484912450882362,
        "distinct-2-nopunct": 0.8528591352859135,
        "vocab_size-2-nopunct": 1223,
        "unique-2-nopunct": 1123,
        "entropy-2-nopunct": 10.065784632686514,
        "cond_entropy-2-nopunct": 1.6942198554601156,
        "distinct-3-nopunct": 0.9486404833836858,
        "vocab_size-3-nopunct": 1256,
        "unique-3-nopunct": 1207,
        "entropy-3-nopunct": 10.253127935137034,
        "cond_entropy-3-nopunct": 0.2146884039317424,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.011245128562637,
        "rouge1": {
            "precision": 0.7711,
            "recall": 0.7508,
            "fmeasure": 0.74877
        },
        "rouge2": {
            "precision": 0.55711,
            "recall": 0.53995,
            "fmeasure": 0.53949
        },
        "rougeL": {
            "precision": 0.67779,
            "recall": 0.66127,
            "fmeasure": 0.65911
        },
        "rougeLsum": {
            "precision": 0.67779,
            "recall": 0.66127,
            "fmeasure": 0.65911
        },
        "bleu": 49.58099,
        "local_recall": {
            "1": 0.23544973544973544,
            "2": 0.5596816976127321,
            "3": 0.8018867924528302
        },
        "bertscore": {
            "precision": 0.9368,
            "recall": 0.93425,
            "f1": 0.93433
        },
        "nubia": {
            "semantic_relation": 4.26279,
            "contradiction": 6.80543,
            "irrelevancy": 23.31981,
            "logical_agreement": 69.87477,
            "grammar_ref": 4.79734,
            "grammar_hyp": 4.70221,
            "nubia_score": 0.75605
        },
        "meteor": 0.40758701080943416,
        "bleurt": 0.30799
    },
    "totto_test_contrast_challenge_table_size-table_size_41": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185189,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.801849348582585,
        "rouge1": {
            "precision": 0.72222,
            "recall": 0.92857,
            "fmeasure": 0.8125
        },
        "rouge2": {
            "precision": 0.64706,
            "recall": 0.84615,
            "fmeasure": 0.73333
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.92857,
            "fmeasure": 0.8125
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.92857,
            "fmeasure": 0.8125
        },
        "bleu": 58.56596,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.93066,
            "recall": 0.97134,
            "f1": 0.95056
        },
        "nubia": {
            "semantic_relation": 3.80221,
            "contradiction": 0.15225,
            "irrelevancy": 99.75188,
            "logical_agreement": 0.09587,
            "grammar_ref": 4.76643,
            "grammar_hyp": 3.70922,
            "nubia_score": 0.73826
        },
        "meteor": 0.5205556596137819,
        "bleurt": 0.35154
    },
    "totto_test_contrast_challenge_table_size-table_size_8": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 59,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.7625,
        "total_length": 921,
        "mean_pred_length": 15.610169491525424,
        "std_pred_length": 4.804718546414105,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.4723127035830619,
        "vocab_size-1": 435,
        "unique-1": 353,
        "entropy-1": 7.560171389130618,
        "distinct-2": 0.808584686774942,
        "vocab_size-2": 697,
        "unique-2": 625,
        "entropy-2": 9.21533497256785,
        "cond_entropy-2": 1.4292754519610462,
        "distinct-3": 0.9041095890410958,
        "vocab_size-3": 726,
        "unique-3": 676,
        "entropy-3": 9.425031559228874,
        "cond_entropy-3": 0.19995445792263855,
        "total_length-nopunct": 804,
        "mean_pred_length-nopunct": 13.627118644067796,
        "std_pred_length-nopunct": 4.344871533997355,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5310945273631841,
        "vocab_size-1-nopunct": 427,
        "unique-1-nopunct": 351,
        "entropy-1-nopunct": 7.729020456825563,
        "distinct-2-nopunct": 0.8161073825503355,
        "vocab_size-2-nopunct": 608,
        "unique-2-nopunct": 552,
        "entropy-2-nopunct": 9.011125938039449,
        "cond_entropy-2-nopunct": 1.3483903165093136,
        "distinct-3-nopunct": 0.9096209912536443,
        "vocab_size-3-nopunct": 624,
        "unique-3-nopunct": 584,
        "entropy-3-nopunct": 9.20954624433737,
        "cond_entropy-3-nopunct": 0.21737600229620446,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.542635032669626,
        "rouge1": {
            "precision": 0.80807,
            "recall": 0.75991,
            "fmeasure": 0.77661
        },
        "rouge2": {
            "precision": 0.61648,
            "recall": 0.57674,
            "fmeasure": 0.59009
        },
        "rougeL": {
            "precision": 0.72599,
            "recall": 0.68868,
            "fmeasure": 0.70006
        },
        "rougeLsum": {
            "precision": 0.72599,
            "recall": 0.68868,
            "fmeasure": 0.70006
        },
        "bleu": 54.05371,
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.46616541353383456,
            "3": 0.8184663536776213
        },
        "bertscore": {
            "precision": 0.94644,
            "recall": 0.93526,
            "f1": 0.93951
        },
        "nubia": {
            "semantic_relation": 4.27227,
            "contradiction": 6.27536,
            "irrelevancy": 23.94154,
            "logical_agreement": 69.78309,
            "grammar_ref": 4.6237,
            "grammar_hyp": 4.46024,
            "nubia_score": 0.77557
        },
        "meteor": 0.4256085940157849,
        "bleurt": 0.37561
    },
    "totto_test_contrast_challenge_table_size-table_size_18": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 123,
        "msttr-100": 0.65556,
        "msttr-100_nopunct": 0.69625,
        "total_length": 1843,
        "mean_pred_length": 14.983739837398375,
        "std_pred_length": 5.448925813193026,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.3966359196961476,
        "vocab_size-1": 731,
        "unique-1": 603,
        "entropy-1": 7.668271111422165,
        "distinct-2": 0.7302325581395349,
        "vocab_size-2": 1256,
        "unique-2": 1156,
        "entropy-2": 9.714863114089825,
        "cond_entropy-2": 1.8175618109944178,
        "distinct-3": 0.8371947401377583,
        "vocab_size-3": 1337,
        "unique-3": 1283,
        "entropy-3": 10.02777867902907,
        "cond_entropy-3": 0.3213647927769787,
        "total_length-nopunct": 1611,
        "mean_pred_length-nopunct": 13.097560975609756,
        "std_pred_length-nopunct": 4.945910085260874,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4500310366232154,
        "vocab_size-1-nopunct": 725,
        "unique-1-nopunct": 603,
        "entropy-1-nopunct": 7.909599356713502,
        "distinct-2-nopunct": 0.7426075268817204,
        "vocab_size-2-nopunct": 1105,
        "unique-2-nopunct": 1028,
        "entropy-2-nopunct": 9.539118971702509,
        "cond_entropy-2-nopunct": 1.7471434168375177,
        "distinct-3-nopunct": 0.8490842490842491,
        "vocab_size-3-nopunct": 1159,
        "unique-3-nopunct": 1118,
        "entropy-3-nopunct": 9.839573441394824,
        "cond_entropy-3-nopunct": 0.34252363913799666,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.320077669670775,
        "rouge1": {
            "precision": 0.77529,
            "recall": 0.73656,
            "fmeasure": 0.74509
        },
        "rouge2": {
            "precision": 0.55463,
            "recall": 0.52982,
            "fmeasure": 0.53485
        },
        "rougeL": {
            "precision": 0.68126,
            "recall": 0.64619,
            "fmeasure": 0.65421
        },
        "rougeLsum": {
            "precision": 0.68126,
            "recall": 0.64619,
            "fmeasure": 0.65421
        },
        "bleu": 48.89366,
        "local_recall": {
            "1": 0.21201413427561838,
            "2": 0.40468227424749165,
            "3": 0.7498075442648191
        },
        "bertscore": {
            "precision": 0.93316,
            "recall": 0.92508,
            "f1": 0.92758
        },
        "nubia": {
            "semantic_relation": 4.24334,
            "contradiction": 6.56887,
            "irrelevancy": 23.07379,
            "logical_agreement": 70.35734,
            "grammar_ref": 4.71387,
            "grammar_hyp": 4.57423,
            "nubia_score": 0.76739
        },
        "meteor": 0.39375600907649183,
        "bleurt": 0.3721
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 80,
        "msttr-100": 0.53526,
        "msttr-100_nopunct": 0.53167,
        "total_length": 1997,
        "mean_pred_length": 24.9625,
        "std_pred_length": 2.352890509564778,
        "median_pred_length": 25.0,
        "min_pred_length": 19,
        "max_pred_length": 30,
        "distinct-1": 0.26089133700550826,
        "vocab_size-1": 521,
        "unique-1": 282,
        "entropy-1": 7.471397738180196,
        "distinct-2": 0.5461658841940532,
        "vocab_size-2": 1047,
        "unique-2": 728,
        "entropy-2": 9.513559993812615,
        "cond_entropy-2": 2.0933049837219153,
        "distinct-3": 0.6913445835601524,
        "vocab_size-3": 1270,
        "unique-3": 1004,
        "entropy-3": 9.99433783720906,
        "cond_entropy-3": 0.5160897235951633,
        "total_length-nopunct": 1843,
        "mean_pred_length-nopunct": 23.0375,
        "std_pred_length-nopunct": 2.30458103567655,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.27943570265870865,
        "vocab_size-1-nopunct": 515,
        "unique-1-nopunct": 281,
        "entropy-1-nopunct": 7.557701625418789,
        "distinct-2-nopunct": 0.5604083947816222,
        "vocab_size-2-nopunct": 988,
        "unique-2-nopunct": 691,
        "entropy-2-nopunct": 9.472939200129312,
        "cond_entropy-2-nopunct": 1.9924028183573028,
        "distinct-3-nopunct": 0.6993464052287581,
        "vocab_size-3-nopunct": 1177,
        "unique-3-nopunct": 939,
        "entropy-3-nopunct": 9.88984130567476,
        "cond_entropy-3-nopunct": 0.45389528044342575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 1.9805371554279987,
        "rouge1": {
            "precision": 0.77302,
            "recall": 0.4726,
            "fmeasure": 0.57819
        },
        "rouge2": {
            "precision": 0.45709,
            "recall": 0.2646,
            "fmeasure": 0.33027
        },
        "rougeL": {
            "precision": 0.5863,
            "recall": 0.35262,
            "fmeasure": 0.43424
        },
        "rougeLsum": {
            "precision": 0.5863,
            "recall": 0.35262,
            "fmeasure": 0.43424
        },
        "bleu": 25.31295,
        "local_recall": {
            "1": 0.13732928679817905,
            "2": 0.3632707774798928,
            "3": 0.6120107962213225
        },
        "bertscore": {
            "precision": 0.89884,
            "recall": 0.82741,
            "f1": 0.86008
        },
        "nubia": {
            "semantic_relation": 3.28221,
            "contradiction": 6.39097,
            "irrelevancy": 14.13849,
            "logical_agreement": 79.47054,
            "grammar_ref": 4.0565,
            "grammar_hyp": 4.61167,
            "nubia_score": 0.38462
        },
        "meteor": 0.2352049957386277,
        "bleurt": -0.38279
    },
    "web_nlg_ru_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 354,
        "msttr-100": 0.35571,
        "msttr-100_nopunct": 0.55483,
        "total_length": 5636,
        "mean_pred_length": 15.92090395480226,
        "std_pred_length": 6.554807032099683,
        "median_pred_length": 15.0,
        "min_pred_length": 3,
        "max_pred_length": 34,
        "distinct-1": 0.14034776437189497,
        "vocab_size-1": 791,
        "unique-1": 352,
        "entropy-1": 6.0923944963986525,
        "distinct-2": 0.301211662249148,
        "vocab_size-2": 1591,
        "unique-2": 749,
        "entropy-2": 9.576467204353117,
        "cond_entropy-2": 3.638722969681589,
        "distinct-3": 0.44155844155844154,
        "vocab_size-3": 2176,
        "unique-3": 1276,
        "entropy-3": 10.357063727511303,
        "cond_entropy-3": 0.8615376394131325,
        "total_length-nopunct": 2970,
        "mean_pred_length-nopunct": 8.389830508474576,
        "std_pred_length-nopunct": 3.9646044786129164,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.2632996632996633,
        "vocab_size-1-nopunct": 782,
        "unique-1-nopunct": 351,
        "entropy-1-nopunct": 8.411000710423918,
        "distinct-2-nopunct": 0.5508409785932722,
        "vocab_size-2-nopunct": 1441,
        "unique-2-nopunct": 945,
        "entropy-2-nopunct": 10.030510992822064,
        "cond_entropy-2-nopunct": 1.7660634580035182,
        "distinct-3-nopunct": 0.674469964664311,
        "vocab_size-3-nopunct": 1527,
        "unique-3-nopunct": 1140,
        "entropy-3-nopunct": 10.265664026405627,
        "cond_entropy-3-nopunct": 0.3303334830285242,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.3202530294020558,
        "rouge1": {
            "precision": 0.0429,
            "recall": 0.18716,
            "fmeasure": 0.06503
        },
        "rouge2": {
            "precision": 0.00987,
            "recall": 0.0298,
            "fmeasure": 0.01377
        },
        "rougeL": {
            "precision": 0.04022,
            "recall": 0.17631,
            "fmeasure": 0.06084
        },
        "rougeLsum": {
            "precision": 0.04022,
            "recall": 0.17631,
            "fmeasure": 0.06084
        },
        "bleu": 0.35123,
        "local_recall": {
            "1": 0.004884463648318617,
            "2": 0.011501597444089457,
            "3": 0.01907587961000424,
            "4": 0.13513513513513514,
            "5": 0.0,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.59196,
            "recall": 0.52515,
            "f1": 0.5555
        },
        "nubia": {
            "semantic_relation": 2.49341,
            "contradiction": 31.59247,
            "irrelevancy": 34.78338,
            "logical_agreement": 33.62416,
            "grammar_ref": 2.54394,
            "grammar_hyp": 4.28042,
            "nubia_score": 0.27906
        },
        "meteor": 0.016313194458386037,
        "bleurt": -1.27867
    },
    "totto_test_contrast_challenge_table_size-table_size_63": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 39,
        "msttr-100": 0.72167,
        "msttr-100_nopunct": 0.818,
        "total_length": 655,
        "mean_pred_length": 16.794871794871796,
        "std_pred_length": 6.4814507998397195,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.5740458015267176,
        "vocab_size-1": 376,
        "unique-1": 320,
        "entropy-1": 7.562828512627131,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 572,
        "unique-2": 545,
        "entropy-2": 9.085738184468672,
        "cond_entropy-2": 1.3767200623729365,
        "distinct-3": 0.9844020797227037,
        "vocab_size-3": 568,
        "unique-3": 559,
        "entropy-3": 9.141231668090757,
        "cond_entropy-3": 0.06773072087143178,
        "total_length-nopunct": 550,
        "mean_pred_length-nopunct": 14.102564102564102,
        "std_pred_length-nopunct": 5.157990424598502,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6745454545454546,
        "vocab_size-1-nopunct": 371,
        "unique-1-nopunct": 320,
        "entropy-1-nopunct": 7.886540785581108,
        "distinct-2-nopunct": 0.9452054794520548,
        "vocab_size-2-nopunct": 483,
        "unique-2-nopunct": 463,
        "entropy-2-nopunct": 8.868185064184406,
        "cond_entropy-2-nopunct": 1.0565624956070796,
        "distinct-3-nopunct": 0.989406779661017,
        "vocab_size-3-nopunct": 467,
        "unique-3-nopunct": 462,
        "entropy-3-nopunct": 8.861456608683898,
        "cond_entropy-3-nopunct": 0.0039299814769605465,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.3853039218789185,
        "rouge1": {
            "precision": 0.78349,
            "recall": 0.66804,
            "fmeasure": 0.70941
        },
        "rouge2": {
            "precision": 0.52936,
            "recall": 0.4589,
            "fmeasure": 0.48359
        },
        "rougeL": {
            "precision": 0.67303,
            "recall": 0.57506,
            "fmeasure": 0.60956
        },
        "rougeLsum": {
            "precision": 0.67303,
            "recall": 0.57506,
            "fmeasure": 0.60956
        },
        "bleu": 46.17186,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.582010582010582,
            "3": 0.6997518610421837
        },
        "bertscore": {
            "precision": 0.93155,
            "recall": 0.91555,
            "f1": 0.92211
        },
        "nubia": {
            "semantic_relation": 4.07413,
            "contradiction": 8.57028,
            "irrelevancy": 31.06411,
            "logical_agreement": 60.3656,
            "grammar_ref": 4.28467,
            "grammar_hyp": 4.32373,
            "nubia_score": 0.69387
        },
        "meteor": 0.3763715851678122,
        "bleurt": 0.25473
    },
    "totto_test_contrast_challenge_table_size-table_size_88": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.736,
        "msttr-100_nopunct": 0.7575,
        "total_length": 565,
        "mean_pred_length": 16.142857142857142,
        "std_pred_length": 5.472752544027847,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5646017699115045,
        "vocab_size-1": 319,
        "unique-1": 259,
        "entropy-1": 7.428011115166222,
        "distinct-2": 0.909433962264151,
        "vocab_size-2": 482,
        "unique-2": 454,
        "entropy-2": 8.822172529638495,
        "cond_entropy-2": 1.2269302232706196,
        "distinct-3": 0.9717171717171718,
        "vocab_size-3": 481,
        "unique-3": 473,
        "entropy-3": 8.884578553333357,
        "cond_entropy-3": 0.07446392408559165,
        "total_length-nopunct": 494,
        "mean_pred_length-nopunct": 14.114285714285714,
        "std_pred_length-nopunct": 5.311827388392966,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.631578947368421,
        "vocab_size-1-nopunct": 312,
        "unique-1-nopunct": 258,
        "entropy-1-nopunct": 7.561584672562614,
        "distinct-2-nopunct": 0.9172113289760349,
        "vocab_size-2-nopunct": 421,
        "unique-2-nopunct": 401,
        "entropy-2-nopunct": 8.62738674755247,
        "cond_entropy-2-nopunct": 1.1593803474625637,
        "distinct-3-nopunct": 0.9811320754716981,
        "vocab_size-3-nopunct": 416,
        "unique-3-nopunct": 412,
        "entropy-3-nopunct": 8.683063025297555,
        "cond_entropy-3-nopunct": 0.07106242362992136,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.536176581251961,
        "rouge1": {
            "precision": 0.80633,
            "recall": 0.72851,
            "fmeasure": 0.75661
        },
        "rouge2": {
            "precision": 0.55091,
            "recall": 0.50128,
            "fmeasure": 0.51804
        },
        "rougeL": {
            "precision": 0.71576,
            "recall": 0.66305,
            "fmeasure": 0.67983
        },
        "rougeLsum": {
            "precision": 0.71576,
            "recall": 0.66305,
            "fmeasure": 0.67983
        },
        "bleu": 44.58964,
        "local_recall": {
            "1": 0.20212765957446807,
            "2": 0.504424778761062,
            "3": 0.7329974811083123
        },
        "bertscore": {
            "precision": 0.94349,
            "recall": 0.93083,
            "f1": 0.9352
        },
        "nubia": {
            "semantic_relation": 4.2182,
            "contradiction": 7.16692,
            "irrelevancy": 23.57188,
            "logical_agreement": 69.2612,
            "grammar_ref": 4.59802,
            "grammar_hyp": 4.58657,
            "nubia_score": 0.74583
        },
        "meteor": 0.3931445139071157,
        "bleurt": 0.29729
    },
    "totto_test_contrast_challenge_table_size-table_size_19": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.5075,
        "msttr-100_nopunct": 0.5025,
        "total_length": 467,
        "mean_pred_length": 16.103448275862068,
        "std_pred_length": 5.067440540019681,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.3297644539614561,
        "vocab_size-1": 154,
        "unique-1": 114,
        "entropy-1": 5.896405045382558,
        "distinct-2": 0.5570776255707762,
        "vocab_size-2": 244,
        "unique-2": 207,
        "entropy-2": 7.0809924935680915,
        "cond_entropy-2": 1.1162288463387755,
        "distinct-3": 0.6454767726161369,
        "vocab_size-3": 264,
        "unique-3": 233,
        "entropy-3": 7.367272083120128,
        "cond_entropy-3": 0.3965975416668525,
        "total_length-nopunct": 403,
        "mean_pred_length-nopunct": 13.89655172413793,
        "std_pred_length-nopunct": 4.229166605651649,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.36476426799007444,
        "vocab_size-1-nopunct": 147,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 5.8569175735396435,
        "distinct-2-nopunct": 0.5454545454545454,
        "vocab_size-2-nopunct": 204,
        "unique-2-nopunct": 173,
        "entropy-2-nopunct": 6.799193218927487,
        "cond_entropy-2-nopunct": 1.1206321805732642,
        "distinct-3-nopunct": 0.6434782608695652,
        "vocab_size-3-nopunct": 222,
        "unique-3-nopunct": 197,
        "entropy-3-nopunct": 7.1173789613071365,
        "cond_entropy-3-nopunct": 0.4487349591856392,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.48875957543336,
        "rouge1": {
            "precision": 0.82441,
            "recall": 0.80842,
            "fmeasure": 0.80663
        },
        "rouge2": {
            "precision": 0.68288,
            "recall": 0.66556,
            "fmeasure": 0.66536
        },
        "rougeL": {
            "precision": 0.77876,
            "recall": 0.76004,
            "fmeasure": 0.76016
        },
        "rougeLsum": {
            "precision": 0.77876,
            "recall": 0.76004,
            "fmeasure": 0.76016
        },
        "bleu": 61.08795,
        "local_recall": {
            "1": 0.225,
            "2": 0.42105263157894735,
            "3": 0.8106508875739645
        },
        "bertscore": {
            "precision": 0.94719,
            "recall": 0.9456,
            "f1": 0.94512
        },
        "nubia": {
            "semantic_relation": 4.25998,
            "contradiction": 10.85249,
            "irrelevancy": 17.00209,
            "logical_agreement": 72.14543,
            "grammar_ref": 4.31347,
            "grammar_hyp": 4.31141,
            "nubia_score": 0.76899
        },
        "meteor": 0.41647201983576837,
        "bleurt": 0.47716
    },
    "totto_test_contrast_challenge_table_size-table_size_42": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 54,
        "msttr-100": 0.76125,
        "msttr-100_nopunct": 0.8,
        "total_length": 871,
        "mean_pred_length": 16.12962962962963,
        "std_pred_length": 5.364652128089796,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5304247990815155,
        "vocab_size-1": 462,
        "unique-1": 377,
        "entropy-1": 7.812819240864888,
        "distinct-2": 0.8959608323133414,
        "vocab_size-2": 732,
        "unique-2": 690,
        "entropy-2": 9.396015867029229,
        "cond_entropy-2": 1.3721518244818585,
        "distinct-3": 0.9777195281782438,
        "vocab_size-3": 746,
        "unique-3": 731,
        "entropy-3": 9.528999567929759,
        "cond_entropy-3": 0.14043019586425887,
        "total_length-nopunct": 775,
        "mean_pred_length-nopunct": 14.351851851851851,
        "std_pred_length-nopunct": 5.274527914305968,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5858064516129032,
        "vocab_size-1-nopunct": 454,
        "unique-1-nopunct": 375,
        "entropy-1-nopunct": 7.985479622881538,
        "distinct-2-nopunct": 0.9042995839112344,
        "vocab_size-2-nopunct": 652,
        "unique-2-nopunct": 620,
        "entropy-2-nopunct": 9.231170543927082,
        "cond_entropy-2-nopunct": 1.3215015379077695,
        "distinct-3-nopunct": 0.9850074962518741,
        "vocab_size-3-nopunct": 657,
        "unique-3-nopunct": 647,
        "entropy-3-nopunct": 9.351557943688343,
        "cond_entropy-3-nopunct": 0.13478023692187738,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.664646654367209,
        "rouge1": {
            "precision": 0.75742,
            "recall": 0.70624,
            "fmeasure": 0.71992
        },
        "rouge2": {
            "precision": 0.50913,
            "recall": 0.47824,
            "fmeasure": 0.48481
        },
        "rougeL": {
            "precision": 0.63011,
            "recall": 0.59364,
            "fmeasure": 0.60145
        },
        "rougeLsum": {
            "precision": 0.63011,
            "recall": 0.59364,
            "fmeasure": 0.60145
        },
        "bleu": 41.57795,
        "local_recall": {
            "1": 0.22346368715083798,
            "2": 0.38857142857142857,
            "3": 0.7258064516129032
        },
        "bertscore": {
            "precision": 0.93085,
            "recall": 0.92325,
            "f1": 0.92593
        },
        "nubia": {
            "semantic_relation": 4.14939,
            "contradiction": 12.05272,
            "irrelevancy": 31.29923,
            "logical_agreement": 56.64805,
            "grammar_ref": 4.68502,
            "grammar_hyp": 4.66079,
            "nubia_score": 0.70701
        },
        "meteor": 0.3792136889873532,
        "bleurt": 0.23059
    },
    "totto_test_contrast_challenge_table_size-table_size_43": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 77,
        "mean_pred_length": 12.833333333333334,
        "std_pred_length": 6.309164410249233,
        "median_pred_length": 9.5,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 56,
        "unique-1": 49,
        "entropy-1": 5.5300455542897,
        "distinct-2": 0.8169014084507042,
        "vocab_size-2": 58,
        "unique-2": 53,
        "entropy-2": 5.677778457471905,
        "cond_entropy-2": 0.04647664183001761,
        "distinct-3": 0.8615384615384616,
        "vocab_size-3": 56,
        "unique-3": 52,
        "entropy-3": 5.679834543697837,
        "cond_entropy-3": -0.07745449881720426,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 11.166666666666666,
        "std_pred_length-nopunct": 5.2094998693625945,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7761194029850746,
        "vocab_size-1-nopunct": 52,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.463633549015972,
        "distinct-2-nopunct": 0.8360655737704918,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.512544304705066,
        "cond_entropy-2-nopunct": -0.022978853349421666,
        "distinct-3-nopunct": 0.8909090909090909,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.522002213406648,
        "cond_entropy-3-nopunct": -0.09037557862301694,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.755517595815154,
        "rouge1": {
            "precision": 0.90694,
            "recall": 0.87265,
            "fmeasure": 0.88798
        },
        "rouge2": {
            "precision": 0.81988,
            "recall": 0.8,
            "fmeasure": 0.80894
        },
        "rougeL": {
            "precision": 0.87917,
            "recall": 0.85114,
            "fmeasure": 0.86373
        },
        "rougeLsum": {
            "precision": 0.87917,
            "recall": 0.85114,
            "fmeasure": 0.86373
        },
        "bleu": 59.91051,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7702702702702703
        },
        "bertscore": {
            "precision": 0.97769,
            "recall": 0.97026,
            "f1": 0.97382
        },
        "nubia": {
            "semantic_relation": 4.64614,
            "contradiction": 14.31035,
            "irrelevancy": 12.01911,
            "logical_agreement": 73.67054,
            "grammar_ref": 5.92578,
            "grammar_hyp": 5.9717,
            "nubia_score": 0.86373
        },
        "meteor": 0.46020919279669137,
        "bleurt": 0.73546
    },
    "totto_test_contrast_challenge_table_size-table_size_64": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.69333,
        "msttr-100_nopunct": 0.726,
        "total_length": 639,
        "mean_pred_length": 17.75,
        "std_pred_length": 5.2934708210524155,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5555555555555556,
        "vocab_size-1": 355,
        "unique-1": 297,
        "entropy-1": 7.448665590340093,
        "distinct-2": 0.9303482587064676,
        "vocab_size-2": 561,
        "unique-2": 541,
        "entropy-2": 9.029497898346207,
        "cond_entropy-2": 1.4192218273756276,
        "distinct-3": 0.9964726631393298,
        "vocab_size-3": 565,
        "unique-3": 563,
        "entropy-3": 9.140150251220978,
        "cond_entropy-3": 0.11537845351977544,
        "total_length-nopunct": 567,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 5.046313285734228,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6119929453262787,
        "vocab_size-1-nopunct": 347,
        "unique-1-nopunct": 295,
        "entropy-1-nopunct": 7.5525431123836455,
        "distinct-2-nopunct": 0.9303201506591338,
        "vocab_size-2-nopunct": 494,
        "unique-2-nopunct": 477,
        "entropy-2-nopunct": 8.839725207096768,
        "cond_entropy-2-nopunct": 1.3772439831338035,
        "distinct-3-nopunct": 0.9959595959595959,
        "vocab_size-3-nopunct": 493,
        "unique-3-nopunct": 491,
        "entropy-3-nopunct": 8.943203906886195,
        "cond_entropy-3-nopunct": 0.11693797731161452,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.532710298142203,
        "rouge1": {
            "precision": 0.77178,
            "recall": 0.69722,
            "fmeasure": 0.72187
        },
        "rouge2": {
            "precision": 0.48288,
            "recall": 0.43408,
            "fmeasure": 0.45053
        },
        "rougeL": {
            "precision": 0.63871,
            "recall": 0.59204,
            "fmeasure": 0.60524
        },
        "rougeLsum": {
            "precision": 0.63871,
            "recall": 0.59204,
            "fmeasure": 0.60524
        },
        "bleu": 40.7325,
        "local_recall": {
            "1": 0.26495726495726496,
            "2": 0.5147058823529411,
            "3": 0.7512562814070352
        },
        "bertscore": {
            "precision": 0.92536,
            "recall": 0.91958,
            "f1": 0.92109
        },
        "nubia": {
            "semantic_relation": 4.12312,
            "contradiction": 9.1269,
            "irrelevancy": 31.74861,
            "logical_agreement": 59.1245,
            "grammar_ref": 4.71629,
            "grammar_hyp": 4.94838,
            "nubia_score": 0.68076
        },
        "meteor": 0.3582166689942662,
        "bleurt": 0.18096
    },
    "totto_test_contrast_challenge_table_size-table_size_9": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 105,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.7525,
        "total_length": 1483,
        "mean_pred_length": 14.123809523809523,
        "std_pred_length": 6.254438786585683,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.41065407956844235,
        "vocab_size-1": 609,
        "unique-1": 481,
        "entropy-1": 7.8136794029362795,
        "distinct-2": 0.772133526850508,
        "vocab_size-2": 1064,
        "unique-2": 948,
        "entropy-2": 9.746711460255739,
        "cond_entropy-2": 1.6739889589666817,
        "distinct-3": 0.8790259230164965,
        "vocab_size-3": 1119,
        "unique-3": 1042,
        "entropy-3": 10.005919809632857,
        "cond_entropy-3": 0.27731030522478833,
        "total_length-nopunct": 1282,
        "mean_pred_length-nopunct": 12.209523809523809,
        "std_pred_length-nopunct": 5.31430278201731,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.46801872074882994,
        "vocab_size-1-nopunct": 600,
        "unique-1-nopunct": 478,
        "entropy-1-nopunct": 8.03639493344084,
        "distinct-2-nopunct": 0.7926932880203909,
        "vocab_size-2-nopunct": 933,
        "unique-2-nopunct": 843,
        "entropy-2-nopunct": 9.576182354277258,
        "cond_entropy-2-nopunct": 1.6700093146122303,
        "distinct-3-nopunct": 0.894589552238806,
        "vocab_size-3-nopunct": 959,
        "unique-3-nopunct": 906,
        "entropy-3-nopunct": 9.79458841535698,
        "cond_entropy-3-nopunct": 0.24837888895175142,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.540165473323762,
        "rouge1": {
            "precision": 0.64628,
            "recall": 0.59867,
            "fmeasure": 0.60674
        },
        "rouge2": {
            "precision": 0.41042,
            "recall": 0.37842,
            "fmeasure": 0.38623
        },
        "rougeL": {
            "precision": 0.56212,
            "recall": 0.52456,
            "fmeasure": 0.52978
        },
        "rougeLsum": {
            "precision": 0.56212,
            "recall": 0.52456,
            "fmeasure": 0.52978
        },
        "bleu": 39.14406,
        "local_recall": {
            "1": 0.2138728323699422,
            "2": 0.3746130030959752,
            "3": 0.6870967741935484
        },
        "bertscore": {
            "precision": 0.89574,
            "recall": 0.89269,
            "f1": 0.89304
        },
        "nubia": {
            "semantic_relation": 3.48105,
            "contradiction": 21.93632,
            "irrelevancy": 26.33219,
            "logical_agreement": 51.73149,
            "grammar_ref": 4.94529,
            "grammar_hyp": 4.91774,
            "nubia_score": 0.58521
        },
        "meteor": 0.34149072855534635,
        "bleurt": 0.09698
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 41,
        "msttr-100": 0.533,
        "msttr-100_nopunct": 0.58333,
        "total_length": 1032,
        "mean_pred_length": 25.170731707317074,
        "std_pred_length": 2.565269339012489,
        "median_pred_length": 25.0,
        "min_pred_length": 19,
        "max_pred_length": 32,
        "distinct-1": 0.33430232558139533,
        "vocab_size-1": 345,
        "unique-1": 201,
        "entropy-1": 7.227551849018558,
        "distinct-2": 0.6508577194752775,
        "vocab_size-2": 645,
        "unique-2": 485,
        "entropy-2": 8.996125740834941,
        "cond_entropy-2": 1.8109090493808206,
        "distinct-3": 0.7757894736842105,
        "vocab_size-3": 737,
        "unique-3": 608,
        "entropy-3": 9.348298042178577,
        "cond_entropy-3": 0.3755163451764007,
        "total_length-nopunct": 962,
        "mean_pred_length-nopunct": 23.463414634146343,
        "std_pred_length-nopunct": 2.253426236575824,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.35550935550935553,
        "vocab_size-1-nopunct": 342,
        "unique-1-nopunct": 200,
        "entropy-1-nopunct": 7.295935449215281,
        "distinct-2-nopunct": 0.6731813246471227,
        "vocab_size-2-nopunct": 620,
        "unique-2-nopunct": 469,
        "entropy-2-nopunct": 8.986523004535444,
        "cond_entropy-2-nopunct": 1.733496648106761,
        "distinct-3-nopunct": 0.7897727272727273,
        "vocab_size-3-nopunct": 695,
        "unique-3-nopunct": 582,
        "entropy-3-nopunct": 9.274044855562435,
        "cond_entropy-3-nopunct": 0.31217747091701037,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 1.3587764537521914,
        "rouge1": {
            "precision": 0.77382,
            "recall": 0.44168,
            "fmeasure": 0.5576
        },
        "rouge2": {
            "precision": 0.46663,
            "recall": 0.25773,
            "fmeasure": 0.32884
        },
        "rougeL": {
            "precision": 0.59925,
            "recall": 0.3382,
            "fmeasure": 0.42858
        },
        "rougeLsum": {
            "precision": 0.59925,
            "recall": 0.3382,
            "fmeasure": 0.42858
        },
        "bleu": 23.0559,
        "local_recall": {
            "1": 0.12537764350453173,
            "2": 0.31887755102040816,
            "3": 0.5626398210290827
        },
        "bertscore": {
            "precision": 0.89487,
            "recall": 0.81455,
            "f1": 0.85157
        },
        "nubia": {
            "semantic_relation": 3.0329,
            "contradiction": 5.63177,
            "irrelevancy": 11.05198,
            "logical_agreement": 83.31625,
            "grammar_ref": 3.92594,
            "grammar_hyp": 4.42253,
            "nubia_score": 0.31247
        },
        "meteor": 0.22142981796247965,
        "bleurt": -0.44957
    },
    "totto_test_contrast_challenge_table_size-table_size_20": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 112,
        "msttr-100": 0.69824,
        "msttr-100_nopunct": 0.74867,
        "total_length": 1765,
        "mean_pred_length": 15.758928571428571,
        "std_pred_length": 5.519843320295626,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.4447592067988669,
        "vocab_size-1": 785,
        "unique-1": 656,
        "entropy-1": 8.008129290988506,
        "distinct-2": 0.7997580157289776,
        "vocab_size-2": 1322,
        "unique-2": 1216,
        "entropy-2": 10.038400707863318,
        "cond_entropy-2": 1.789452309807067,
        "distinct-3": 0.890330953926022,
        "vocab_size-3": 1372,
        "unique-3": 1309,
        "entropy-3": 10.26787740681111,
        "cond_entropy-3": 0.24043091224037844,
        "total_length-nopunct": 1541,
        "mean_pred_length-nopunct": 13.758928571428571,
        "std_pred_length-nopunct": 4.798149821460734,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5009733939000649,
        "vocab_size-1-nopunct": 772,
        "unique-1-nopunct": 649,
        "entropy-1-nopunct": 8.23729402478226,
        "distinct-2-nopunct": 0.8096571028691393,
        "vocab_size-2-nopunct": 1157,
        "unique-2-nopunct": 1077,
        "entropy-2-nopunct": 9.842757143111044,
        "cond_entropy-2-nopunct": 1.7079676738124336,
        "distinct-3-nopunct": 0.89749430523918,
        "vocab_size-3-nopunct": 1182,
        "unique-3-nopunct": 1134,
        "entropy-3-nopunct": 10.060310080227836,
        "cond_entropy-3-nopunct": 0.2534601333911751,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.473373593040935,
        "rouge1": {
            "precision": 0.77319,
            "recall": 0.73809,
            "fmeasure": 0.74352
        },
        "rouge2": {
            "precision": 0.55181,
            "recall": 0.52111,
            "fmeasure": 0.52871
        },
        "rougeL": {
            "precision": 0.6674,
            "recall": 0.63364,
            "fmeasure": 0.64061
        },
        "rougeLsum": {
            "precision": 0.6674,
            "recall": 0.63364,
            "fmeasure": 0.64061
        },
        "bleu": 46.19108,
        "local_recall": {
            "1": 0.20474777448071216,
            "2": 0.4551282051282051,
            "3": 0.7865266841644795
        },
        "bertscore": {
            "precision": 0.9298,
            "recall": 0.92448,
            "f1": 0.92602
        },
        "nubia": {
            "semantic_relation": 4.18103,
            "contradiction": 8.50455,
            "irrelevancy": 22.73801,
            "logical_agreement": 68.75744,
            "grammar_ref": 4.71051,
            "grammar_hyp": 4.58174,
            "nubia_score": 0.74596
        },
        "meteor": 0.3890732729641593,
        "bleurt": 0.29597
    },
    "totto_test_contrast_challenge_table_size-table_size_90": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 78,
        "msttr-100": 0.73667,
        "msttr-100_nopunct": 0.77545,
        "total_length": 1275,
        "mean_pred_length": 16.346153846153847,
        "std_pred_length": 5.859086572454006,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 29,
        "distinct-1": 0.4886274509803922,
        "vocab_size-1": 623,
        "unique-1": 479,
        "entropy-1": 8.062425705134604,
        "distinct-2": 0.8563074352548037,
        "vocab_size-2": 1025,
        "unique-2": 918,
        "entropy-2": 9.84185382603185,
        "cond_entropy-2": 1.561193921537319,
        "distinct-3": 0.9472743521000894,
        "vocab_size-3": 1060,
        "unique-3": 1005,
        "entropy-3": 10.019406497022636,
        "cond_entropy-3": 0.19108859069480322,
        "total_length-nopunct": 1118,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 5.123266853079512,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5483005366726297,
        "vocab_size-1-nopunct": 613,
        "unique-1-nopunct": 476,
        "entropy-1-nopunct": 8.274963871803994,
        "distinct-2-nopunct": 0.8596153846153847,
        "vocab_size-2-nopunct": 894,
        "unique-2-nopunct": 809,
        "entropy-2-nopunct": 9.634045964708816,
        "cond_entropy-2-nopunct": 1.4449850462497187,
        "distinct-3-nopunct": 0.9532224532224532,
        "vocab_size-3-nopunct": 917,
        "unique-3-nopunct": 875,
        "entropy-3-nopunct": 9.813474281792857,
        "cond_entropy-3-nopunct": 0.20259786403717528,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.551395502084023,
        "rouge1": {
            "precision": 0.77392,
            "recall": 0.7312,
            "fmeasure": 0.74216
        },
        "rouge2": {
            "precision": 0.5435,
            "recall": 0.51329,
            "fmeasure": 0.52027
        },
        "rougeL": {
            "precision": 0.69371,
            "recall": 0.65629,
            "fmeasure": 0.66543
        },
        "rougeLsum": {
            "precision": 0.69371,
            "recall": 0.65629,
            "fmeasure": 0.66543
        },
        "bleu": 50.03642,
        "local_recall": {
            "1": 0.20600858369098712,
            "2": 0.5063829787234042,
            "3": 0.7785888077858881
        },
        "bertscore": {
            "precision": 0.9309,
            "recall": 0.93052,
            "f1": 0.9294
        },
        "nubia": {
            "semantic_relation": 4.27761,
            "contradiction": 7.46609,
            "irrelevancy": 32.02543,
            "logical_agreement": 60.50848,
            "grammar_ref": 4.66269,
            "grammar_hyp": 4.6833,
            "nubia_score": 0.74391
        },
        "meteor": 0.41427816296449027,
        "bleurt": 0.29071
    },
    "totto_test_contrast_challenge_table_size-table_size_91": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.745,
        "total_length": 259,
        "mean_pred_length": 14.38888888888889,
        "std_pred_length": 5.089628767174903,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.6177606177606177,
        "vocab_size-1": 160,
        "unique-1": 134,
        "entropy-1": 6.636204410032053,
        "distinct-2": 0.9253112033195021,
        "vocab_size-2": 223,
        "unique-2": 212,
        "entropy-2": 7.733970599803586,
        "cond_entropy-2": 0.8994013619502457,
        "distinct-3": 0.9775784753363229,
        "vocab_size-3": 218,
        "unique-3": 214,
        "entropy-3": 7.7526717048433476,
        "cond_entropy-3": 0.024174366275994803,
        "total_length-nopunct": 230,
        "mean_pred_length-nopunct": 12.777777777777779,
        "std_pred_length-nopunct": 5.017254179944727,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6739130434782609,
        "vocab_size-1-nopunct": 155,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.716967394430135,
        "distinct-2-nopunct": 0.9292452830188679,
        "vocab_size-2-nopunct": 197,
        "unique-2-nopunct": 188,
        "entropy-2-nopunct": 7.556389662220756,
        "cond_entropy-2-nopunct": 0.9041790853214303,
        "distinct-3-nopunct": 0.9896907216494846,
        "vocab_size-3-nopunct": 192,
        "unique-3-nopunct": 190,
        "entropy-3-nopunct": 7.579294285486073,
        "cond_entropy-3-nopunct": 0.023355933895063793,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.871426980317638,
        "rouge1": {
            "precision": 0.77881,
            "recall": 0.70208,
            "fmeasure": 0.73298
        },
        "rouge2": {
            "precision": 0.4971,
            "recall": 0.44565,
            "fmeasure": 0.46447
        },
        "rougeL": {
            "precision": 0.65941,
            "recall": 0.59648,
            "fmeasure": 0.62082
        },
        "rougeLsum": {
            "precision": 0.65941,
            "recall": 0.59648,
            "fmeasure": 0.62082
        },
        "bleu": 41.329,
        "local_recall": {
            "1": 0.24489795918367346,
            "2": 0.5178571428571429,
            "3": 0.7647058823529411
        },
        "bertscore": {
            "precision": 0.93136,
            "recall": 0.92055,
            "f1": 0.92527
        },
        "nubia": {
            "semantic_relation": 4.33061,
            "contradiction": 1.85739,
            "irrelevancy": 36.46048,
            "logical_agreement": 61.68214,
            "grammar_ref": 4.90853,
            "grammar_hyp": 4.84539,
            "nubia_score": 0.77901
        },
        "meteor": 0.36969928995393164,
        "bleurt": 0.30622
    },
    "cs_restaurants_test_contrast_challenge_acts-inform": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 609,
        "msttr-100": 0.61029,
        "msttr-100_nopunct": 0.65237,
        "total_length": 6868,
        "mean_pred_length": 11.277504105090312,
        "std_pred_length": 4.191652860725368,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 25,
        "distinct-1": 0.09682585905649388,
        "vocab_size-1": 665,
        "unique-1": 245,
        "entropy-1": 7.101310231523108,
        "distinct-2": 0.290301965170155,
        "vocab_size-2": 1817,
        "unique-2": 998,
        "entropy-2": 9.520918601756042,
        "cond_entropy-2": 2.1307668334225482,
        "distinct-3": 0.4568141592920354,
        "vocab_size-3": 2581,
        "unique-3": 1773,
        "entropy-3": 10.394718854827618,
        "cond_entropy-3": 0.9626935605929483,
        "total_length-nopunct": 5974,
        "mean_pred_length-nopunct": 9.80952380952381,
        "std_pred_length-nopunct": 3.7227178927330518,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.11064613324405759,
        "vocab_size-1-nopunct": 661,
        "unique-1-nopunct": 245,
        "entropy-1-nopunct": 7.365816406325556,
        "distinct-2-nopunct": 0.29692451071761417,
        "vocab_size-2-nopunct": 1593,
        "unique-2-nopunct": 910,
        "entropy-2-nopunct": 9.305189781111798,
        "cond_entropy-2-nopunct": 2.1860142697432567,
        "distinct-3-nopunct": 0.46719932716568546,
        "vocab_size-3-nopunct": 2222,
        "unique-3-nopunct": 1563,
        "entropy-3-nopunct": 10.183050119210785,
        "cond_entropy-3-nopunct": 1.0490370753395462,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 4.119893101539692,
        "rouge1": {
            "precision": 0.53206,
            "recall": 0.54639,
            "fmeasure": 0.52554
        },
        "rouge2": {
            "precision": 0.29214,
            "recall": 0.30043,
            "fmeasure": 0.28857
        },
        "rougeL": {
            "precision": 0.47598,
            "recall": 0.48745,
            "fmeasure": 0.4701
        },
        "rougeLsum": {
            "precision": 0.47598,
            "recall": 0.48745,
            "fmeasure": 0.4701
        },
        "bleu": 17.20018,
        "local_recall": {
            "1": 0.49369785194390203
        },
        "bertscore": {
            "precision": 0.90002,
            "recall": 0.90015,
            "f1": 0.89984
        },
        "nubia": {
            "semantic_relation": 3.48157,
            "contradiction": 19.08016,
            "irrelevancy": 32.27801,
            "logical_agreement": 48.64184,
            "grammar_ref": 6.96179,
            "grammar_hyp": 6.95054,
            "nubia_score": 0.51345
        },
        "meteor": 0.2462347098460381,
        "bleurt": -0.11764
    },
    "totto_test_contrast_challenge_table_size-table_size_65": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 62,
        "msttr-100": 0.738,
        "msttr-100_nopunct": 0.79125,
        "total_length": 1038,
        "mean_pred_length": 16.741935483870968,
        "std_pred_length": 5.324730748519099,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.476878612716763,
        "vocab_size-1": 495,
        "unique-1": 390,
        "entropy-1": 7.8448031639180575,
        "distinct-2": 0.8360655737704918,
        "vocab_size-2": 816,
        "unique-2": 733,
        "entropy-2": 9.500122567396977,
        "cond_entropy-2": 1.4619557582441085,
        "distinct-3": 0.9234135667396062,
        "vocab_size-3": 844,
        "unique-3": 806,
        "entropy-3": 9.645236757690643,
        "cond_entropy-3": 0.13712525785405674,
        "total_length-nopunct": 894,
        "mean_pred_length-nopunct": 14.419354838709678,
        "std_pred_length-nopunct": 4.456052017623549,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.5436241610738255,
        "vocab_size-1-nopunct": 486,
        "unique-1-nopunct": 386,
        "entropy-1-nopunct": 8.093741059453283,
        "distinct-2-nopunct": 0.8557692307692307,
        "vocab_size-2-nopunct": 712,
        "unique-2-nopunct": 655,
        "entropy-2-nopunct": 9.312932851913848,
        "cond_entropy-2-nopunct": 1.2822398200149343,
        "distinct-3-nopunct": 0.9363636363636364,
        "vocab_size-3-nopunct": 721,
        "unique-3-nopunct": 693,
        "entropy-3-nopunct": 9.435287407676517,
        "cond_entropy-3-nopunct": 0.1171927709652959,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.578469076629227,
        "rouge1": {
            "precision": 0.78838,
            "recall": 0.77177,
            "fmeasure": 0.77156
        },
        "rouge2": {
            "precision": 0.58505,
            "recall": 0.58315,
            "fmeasure": 0.57726
        },
        "rougeL": {
            "precision": 0.6873,
            "recall": 0.68271,
            "fmeasure": 0.67637
        },
        "rougeLsum": {
            "precision": 0.6873,
            "recall": 0.68271,
            "fmeasure": 0.67637
        },
        "bleu": 52.82262,
        "local_recall": {
            "1": 0.22093023255813954,
            "2": 0.4519774011299435,
            "3": 0.8061224489795918
        },
        "bertscore": {
            "precision": 0.93735,
            "recall": 0.93515,
            "f1": 0.93373
        },
        "nubia": {
            "semantic_relation": 4.36085,
            "contradiction": 5.83994,
            "irrelevancy": 29.06239,
            "logical_agreement": 65.09766,
            "grammar_ref": 4.56742,
            "grammar_hyp": 4.43177,
            "nubia_score": 0.78417
        },
        "meteor": 0.408360774007346,
        "bleurt": 0.34478
    },
    "totto_test_contrast_challenge_table_size-table_size_44": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.69429,
        "msttr-100_nopunct": 0.75,
        "total_length": 721,
        "mean_pred_length": 15.340425531914894,
        "std_pred_length": 5.292614668733078,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.5395284327323162,
        "vocab_size-1": 389,
        "unique-1": 325,
        "entropy-1": 7.487151307369995,
        "distinct-2": 0.9020771513353115,
        "vocab_size-2": 608,
        "unique-2": 570,
        "entropy-2": 9.145614250245723,
        "cond_entropy-2": 1.4522102874094058,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 608,
        "unique-3": 594,
        "entropy-3": 9.223550635228378,
        "cond_entropy-3": 0.07442211856146323,
        "total_length-nopunct": 629,
        "mean_pred_length-nopunct": 13.382978723404255,
        "std_pred_length-nopunct": 4.8137798281173865,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6089030206677265,
        "vocab_size-1-nopunct": 383,
        "unique-1-nopunct": 323,
        "entropy-1-nopunct": 7.673227174316137,
        "distinct-2-nopunct": 0.915807560137457,
        "vocab_size-2-nopunct": 533,
        "unique-2-nopunct": 504,
        "entropy-2-nopunct": 8.96700061803827,
        "cond_entropy-2-nopunct": 1.40544261285547,
        "distinct-3-nopunct": 0.9813084112149533,
        "vocab_size-3-nopunct": 525,
        "unique-3-nopunct": 516,
        "entropy-3-nopunct": 9.024600899041477,
        "cond_entropy-3-nopunct": 0.061787406365615534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.204082872970712,
        "rouge1": {
            "precision": 0.77294,
            "recall": 0.68761,
            "fmeasure": 0.71759
        },
        "rouge2": {
            "precision": 0.53754,
            "recall": 0.48446,
            "fmeasure": 0.50247
        },
        "rougeL": {
            "precision": 0.68014,
            "recall": 0.61209,
            "fmeasure": 0.63539
        },
        "rougeLsum": {
            "precision": 0.68014,
            "recall": 0.61209,
            "fmeasure": 0.63539
        },
        "bleu": 41.19009,
        "local_recall": {
            "1": 0.12389380530973451,
            "2": 0.45294117647058824,
            "3": 0.7270833333333333
        },
        "bertscore": {
            "precision": 0.93201,
            "recall": 0.91325,
            "f1": 0.9212
        },
        "nubia": {
            "semantic_relation": 4.16696,
            "contradiction": 7.17922,
            "irrelevancy": 31.34305,
            "logical_agreement": 61.47774,
            "grammar_ref": 4.69178,
            "grammar_hyp": 4.94099,
            "nubia_score": 0.6832
        },
        "meteor": 0.36515082199797727,
        "bleurt": 0.23096
    },
    "totto_test_contrast_challenge_table_size-table_size_92": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.77,
        "total_length": 316,
        "mean_pred_length": 14.363636363636363,
        "std_pred_length": 3.723945299684371,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 22,
        "distinct-1": 0.6044303797468354,
        "vocab_size-1": 191,
        "unique-1": 160,
        "entropy-1": 6.802348966980249,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 273,
        "unique-2": 258,
        "entropy-2": 8.031271749583508,
        "cond_entropy-2": 1.0075758559921268,
        "distinct-3": 0.9779411764705882,
        "vocab_size-3": 266,
        "unique-3": 260,
        "entropy-3": 8.043345194191527,
        "cond_entropy-3": 0.02569408098870654,
        "total_length-nopunct": 273,
        "mean_pred_length-nopunct": 12.409090909090908,
        "std_pred_length-nopunct": 3.256588997835994,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.673992673992674,
        "vocab_size-1-nopunct": 184,
        "unique-1-nopunct": 156,
        "entropy-1-nopunct": 6.936194546362827,
        "distinct-2-nopunct": 0.9402390438247012,
        "vocab_size-2-nopunct": 236,
        "unique-2-nopunct": 227,
        "entropy-2-nopunct": 7.822102219272172,
        "cond_entropy-2-nopunct": 0.9729969740230079,
        "distinct-3-nopunct": 0.9912663755458515,
        "vocab_size-3-nopunct": 227,
        "unique-3-nopunct": 225,
        "entropy-3-nopunct": 7.8217365391886515,
        "cond_entropy-3-nopunct": 0.013991129361573483,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.027694899306655,
        "rouge1": {
            "precision": 0.71905,
            "recall": 0.75178,
            "fmeasure": 0.72507
        },
        "rouge2": {
            "precision": 0.49479,
            "recall": 0.50804,
            "fmeasure": 0.4923
        },
        "rougeL": {
            "precision": 0.61546,
            "recall": 0.63753,
            "fmeasure": 0.61859
        },
        "rougeLsum": {
            "precision": 0.61546,
            "recall": 0.63753,
            "fmeasure": 0.61859
        },
        "bleu": 44.85641,
        "local_recall": {
            "1": 0.2,
            "2": 0.45454545454545453,
            "3": 0.8097826086956522
        },
        "bertscore": {
            "precision": 0.91871,
            "recall": 0.93028,
            "f1": 0.92277
        },
        "nubia": {
            "semantic_relation": 4.20474,
            "contradiction": 3.45956,
            "irrelevancy": 35.77146,
            "logical_agreement": 60.76898,
            "grammar_ref": 5.03776,
            "grammar_hyp": 5.03022,
            "nubia_score": 0.72634
        },
        "meteor": 0.3966929608149736,
        "bleurt": 0.2208
    },
    "totto_test_contrast_challenge_table_size-table_size_93": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 92,
        "mean_pred_length": 18.4,
        "std_pred_length": 6.468384651518491,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.75,
        "vocab_size-1": 69,
        "unique-1": 56,
        "entropy-1": 5.8984557060099885,
        "distinct-2": 0.9770114942528736,
        "vocab_size-2": 85,
        "unique-2": 83,
        "entropy-2": 6.39696648435447,
        "cond_entropy-2": 0.4309881490368525,
        "distinct-3": 1.0,
        "vocab_size-3": 82,
        "unique-3": 82,
        "entropy-3": 6.357552004618087,
        "cond_entropy-3": -0.061001247328205575,
        "total_length-nopunct": 73,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 4.363484845854286,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8767123287671232,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 55,
        "entropy-1-nopunct": 5.943249216414273,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 68,
        "entropy-2-nopunct": 6.087462841250345,
        "cond_entropy-2-nopunct": 0.11822651766443996,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 5.97727992349992,
        "cond_entropy-3-nopunct": -0.11018291775042297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.719674458428823,
        "rouge1": {
            "precision": 0.76988,
            "recall": 0.85162,
            "fmeasure": 0.79639
        },
        "rouge2": {
            "precision": 0.60028,
            "recall": 0.67182,
            "fmeasure": 0.62385
        },
        "rougeL": {
            "precision": 0.70988,
            "recall": 0.80599,
            "fmeasure": 0.74456
        },
        "rougeLsum": {
            "precision": 0.70988,
            "recall": 0.80599,
            "fmeasure": 0.74456
        },
        "bleu": 66.11122,
        "local_recall": {
            "1": 0.19047619047619047,
            "2": 0.6,
            "3": 0.9347826086956522
        },
        "bertscore": {
            "precision": 0.92567,
            "recall": 0.9615,
            "f1": 0.94089
        },
        "nubia": {
            "semantic_relation": 4.21063,
            "contradiction": 1.25683,
            "irrelevancy": 33.88338,
            "logical_agreement": 64.8598,
            "grammar_ref": 4.96303,
            "grammar_hyp": 4.36959,
            "nubia_score": 0.77465
        },
        "meteor": 0.47406186942846845,
        "bleurt": 0.37404
    },
    "totto_test_contrast_challenge_table_size-table_size_94": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 9.5,
        "median_pred_length": 19.5,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.765795487926596,
        "distinct-2": 0.8918918918918919,
        "vocab_size-2": 33,
        "unique-2": 30,
        "entropy-2": 4.972834784489399,
        "cond_entropy-2": 0.23512614688364541,
        "distinct-3": 0.9428571428571428,
        "vocab_size-3": 33,
        "unique-3": 31,
        "entropy-3": 5.014997302659249,
        "cond_entropy-3": 0.055683579949258655,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.651084443403434,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.11912872925811885,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.103614493974174,
        "rouge1": {
            "precision": 0.925,
            "recall": 0.76914,
            "fmeasure": 0.83812
        },
        "rouge2": {
            "precision": 0.82346,
            "recall": 0.67531,
            "fmeasure": 0.74049
        },
        "rougeL": {
            "precision": 0.89167,
            "recall": 0.78198,
            "fmeasure": 0.83117
        },
        "rougeLsum": {
            "precision": 0.89167,
            "recall": 0.78198,
            "fmeasure": 0.83117
        },
        "bleu": 78.42813,
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 0.8148148148148148
        },
        "bertscore": {
            "precision": 0.97572,
            "recall": 0.91454,
            "f1": 0.94351
        },
        "nubia": {
            "semantic_relation": 4.12859,
            "contradiction": 2.94935,
            "irrelevancy": 17.11257,
            "logical_agreement": 79.93807,
            "grammar_ref": 4.15024,
            "grammar_hyp": 4.79174,
            "nubia_score": 0.68843
        },
        "meteor": 0.4270770120108186,
        "bleurt": 0.23739
    },
    "cs_restaurants_test_contrast_challenge_acts-?confirm": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 22,
        "msttr-100": 0.25,
        "msttr-100_nopunct": 0.24,
        "total_length": 248,
        "mean_pred_length": 11.272727272727273,
        "std_pred_length": 2.9723241316857845,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 15,
        "distinct-1": 0.10483870967741936,
        "vocab_size-1": 26,
        "unique-1": 0,
        "entropy-1": 4.44768585922316,
        "distinct-2": 0.1592920353982301,
        "vocab_size-2": 36,
        "unique-2": 0,
        "entropy-2": 4.9969571144861105,
        "cond_entropy-2": 0.45650901772127345,
        "distinct-3": 0.1568627450980392,
        "vocab_size-3": 32,
        "unique-3": 0,
        "entropy-3": 4.835347277673324,
        "cond_entropy-3": -0.1477536204436923,
        "total_length-nopunct": 201,
        "mean_pred_length-nopunct": 9.136363636363637,
        "std_pred_length-nopunct": 2.242065900934277,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.11940298507462686,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 4.390301982053493,
        "distinct-2-nopunct": 0.16201117318435754,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 4.678035888415951,
        "cond_entropy-2-nopunct": 0.31082313511520915,
        "distinct-3-nopunct": 0.1592356687898089,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 4.473280700555945,
        "cond_entropy-3-nopunct": -0.18919502837262925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.7609860690036403,
        "rouge1": {
            "precision": 0.37311,
            "recall": 0.39739,
            "fmeasure": 0.37997
        },
        "rouge2": {
            "precision": 0.2257,
            "recall": 0.22203,
            "fmeasure": 0.22123
        },
        "rougeL": {
            "precision": 0.33775,
            "recall": 0.35768,
            "fmeasure": 0.34289
        },
        "rougeLsum": {
            "precision": 0.33775,
            "recall": 0.35768,
            "fmeasure": 0.34289
        },
        "bleu": 15.29328,
        "local_recall": {
            "1": 0.2914285714285714
        },
        "bertscore": {
            "precision": 0.88191,
            "recall": 0.89272,
            "f1": 0.88721
        },
        "nubia": {
            "semantic_relation": 2.41804,
            "contradiction": 35.03959,
            "irrelevancy": 32.54264,
            "logical_agreement": 32.41777,
            "grammar_ref": 6.09546,
            "grammar_hyp": 6.2875,
            "nubia_score": 0.28714
        },
        "meteor": 0.15585729127290388,
        "bleurt": -0.23802
    },
    "totto_test_contrast_challenge_table_size-table_size_66": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.71714,
        "msttr-100_nopunct": 0.76167,
        "total_length": 797,
        "mean_pred_length": 16.604166666666668,
        "std_pred_length": 5.302277746926839,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5319949811794228,
        "vocab_size-1": 424,
        "unique-1": 352,
        "entropy-1": 7.651944064730084,
        "distinct-2": 0.9078771695594126,
        "vocab_size-2": 680,
        "unique-2": 637,
        "entropy-2": 9.31783428377152,
        "cond_entropy-2": 1.4759039656601778,
        "distinct-3": 0.9743223965763196,
        "vocab_size-3": 683,
        "unique-3": 667,
        "entropy-3": 9.399761682506655,
        "cond_entropy-3": 0.08633168687336776,
        "total_length-nopunct": 696,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.886205071423016,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5991379310344828,
        "vocab_size-1-nopunct": 417,
        "unique-1-nopunct": 350,
        "entropy-1-nopunct": 7.85295627192152,
        "distinct-2-nopunct": 0.9120370370370371,
        "vocab_size-2-nopunct": 591,
        "unique-2-nopunct": 559,
        "entropy-2-nopunct": 9.111061664322012,
        "cond_entropy-2-nopunct": 1.3357839117769263,
        "distinct-3-nopunct": 0.9766666666666667,
        "vocab_size-3-nopunct": 586,
        "unique-3-nopunct": 574,
        "entropy-3-nopunct": 9.179635732155353,
        "cond_entropy-3-nopunct": 0.08187713491826346,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.220636996586225,
        "rouge1": {
            "precision": 0.72836,
            "recall": 0.66927,
            "fmeasure": 0.68641
        },
        "rouge2": {
            "precision": 0.47625,
            "recall": 0.44124,
            "fmeasure": 0.45018
        },
        "rougeL": {
            "precision": 0.61514,
            "recall": 0.57352,
            "fmeasure": 0.58398
        },
        "rougeLsum": {
            "precision": 0.61514,
            "recall": 0.57352,
            "fmeasure": 0.58398
        },
        "bleu": 34.32162,
        "local_recall": {
            "1": 0.25146198830409355,
            "2": 0.5448717948717948,
            "3": 0.6640926640926641
        },
        "bertscore": {
            "precision": 0.91593,
            "recall": 0.90072,
            "f1": 0.90605
        },
        "nubia": {
            "semantic_relation": 3.94889,
            "contradiction": 6.92853,
            "irrelevancy": 39.61082,
            "logical_agreement": 53.46064,
            "grammar_ref": 4.63301,
            "grammar_hyp": 4.53445,
            "nubia_score": 0.67599
        },
        "meteor": 0.3383507678061647,
        "bleurt": 0.12535
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_only_match": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 16,
        "msttr-100": 0.52333,
        "msttr-100_nopunct": 0.51,
        "total_length": 312,
        "mean_pred_length": 19.5,
        "std_pred_length": 3.2210246816812815,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.32371794871794873,
        "vocab_size-1": 101,
        "unique-1": 53,
        "entropy-1": 5.807432618408812,
        "distinct-2": 0.5337837837837838,
        "vocab_size-2": 158,
        "unique-2": 111,
        "entropy-2": 6.798280047080139,
        "cond_entropy-2": 1.036953893560711,
        "distinct-3": 0.6357142857142857,
        "vocab_size-3": 178,
        "unique-3": 139,
        "entropy-3": 7.073796778152677,
        "cond_entropy-3": 0.33203060819614066,
        "total_length-nopunct": 278,
        "mean_pred_length-nopunct": 17.375,
        "std_pred_length-nopunct": 3.4977671449083054,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.35251798561151076,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.841854343956951,
        "distinct-2-nopunct": 0.549618320610687,
        "vocab_size-2-nopunct": 144,
        "unique-2-nopunct": 101,
        "entropy-2-nopunct": 6.700584036551117,
        "cond_entropy-2-nopunct": 0.9555105019957213,
        "distinct-3-nopunct": 0.6626016260162602,
        "vocab_size-3-nopunct": 163,
        "unique-3-nopunct": 128,
        "entropy-3-nopunct": 7.008418810623864,
        "cond_entropy-3-nopunct": 0.36069451124710433,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 2.903754332947818,
        "rouge1": {
            "precision": 0.50895,
            "recall": 0.56052,
            "fmeasure": 0.52491
        },
        "rouge2": {
            "precision": 0.27365,
            "recall": 0.31575,
            "fmeasure": 0.28762
        },
        "rougeL": {
            "precision": 0.40294,
            "recall": 0.45841,
            "fmeasure": 0.42186
        },
        "rougeLsum": {
            "precision": 0.40294,
            "recall": 0.45841,
            "fmeasure": 0.42186
        },
        "bleu": 15.4411,
        "local_recall": {
            "1": 0.46558704453441296
        },
        "bertscore": {
            "precision": 0.90177,
            "recall": 0.91017,
            "f1": 0.90584
        },
        "nubia": {
            "semantic_relation": 3.31891,
            "contradiction": 32.16954,
            "irrelevancy": 25.57774,
            "logical_agreement": 42.25272,
            "grammar_ref": 5.92126,
            "grammar_hyp": 5.98884,
            "nubia_score": 0.50931
        },
        "meteor": 0.24615322791464722,
        "bleurt": -0.10213
    },
    "totto_test_contrast_challenge_table_size-table_size_67": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.5722674991690163,
        "rouge1": {
            "precision": 0.59259,
            "recall": 0.47037,
            "fmeasure": 0.5083
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.30263,
            "fmeasure": 0.32407
        },
        "rougeL": {
            "precision": 0.59259,
            "recall": 0.47037,
            "fmeasure": 0.5083
        },
        "rougeLsum": {
            "precision": 0.59259,
            "recall": 0.47037,
            "fmeasure": 0.5083
        },
        "bleu": 21.10534,
        "local_recall": {
            "1": 0,
            "2": 0.1111111111111111,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.90944,
            "recall": 0.91334,
            "f1": 0.91139
        },
        "nubia": {
            "semantic_relation": 2.74655,
            "contradiction": 96.5611,
            "irrelevancy": 2.55251,
            "logical_agreement": 0.88639,
            "grammar_ref": 4.8547,
            "grammar_hyp": 6.02581,
            "nubia_score": 0.14774
        },
        "meteor": 0.22207000090074602,
        "bleurt": -0.69365
    },
    "totto_test_contrast_challenge_table_size-table_size_95": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.762,
        "msttr-100_nopunct": 0.81,
        "total_length": 540,
        "mean_pred_length": 17.419354838709676,
        "std_pred_length": 5.147966673754745,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.6055555555555555,
        "vocab_size-1": 327,
        "unique-1": 271,
        "entropy-1": 7.635330892946357,
        "distinct-2": 0.9155206286836935,
        "vocab_size-2": 466,
        "unique-2": 442,
        "entropy-2": 8.78692662900814,
        "cond_entropy-2": 0.9973218522808738,
        "distinct-3": 0.9769874476987448,
        "vocab_size-3": 467,
        "unique-3": 459,
        "entropy-3": 8.849078340403072,
        "cond_entropy-3": 0.06338092525879876,
        "total_length-nopunct": 466,
        "mean_pred_length-nopunct": 15.03225806451613,
        "std_pred_length-nopunct": 4.329075524998916,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6845493562231759,
        "vocab_size-1-nopunct": 319,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.840752185754894,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 406,
        "unique-2-nopunct": 390,
        "entropy-2-nopunct": 8.60250563560251,
        "cond_entropy-2-nopunct": 0.8218488296755733,
        "distinct-3-nopunct": 0.9925742574257426,
        "vocab_size-3-nopunct": 401,
        "unique-3-nopunct": 398,
        "entropy-3-nopunct": 8.643359997603245,
        "cond_entropy-3-nopunct": 0.05083788826097765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.509029206670647,
        "rouge1": {
            "precision": 0.80759,
            "recall": 0.78727,
            "fmeasure": 0.78666
        },
        "rouge2": {
            "precision": 0.636,
            "recall": 0.61569,
            "fmeasure": 0.61705
        },
        "rougeL": {
            "precision": 0.73761,
            "recall": 0.72091,
            "fmeasure": 0.71969
        },
        "rougeLsum": {
            "precision": 0.73761,
            "recall": 0.72091,
            "fmeasure": 0.71969
        },
        "bleu": 59.57925,
        "local_recall": {
            "1": 0.26548672566371684,
            "2": 0.4897959183673469,
            "3": 0.7961432506887053
        },
        "bertscore": {
            "precision": 0.94488,
            "recall": 0.9402,
            "f1": 0.94177
        },
        "nubia": {
            "semantic_relation": 4.2439,
            "contradiction": 12.49973,
            "irrelevancy": 18.63396,
            "logical_agreement": 68.86631,
            "grammar_ref": 4.87083,
            "grammar_hyp": 4.82211,
            "nubia_score": 0.72966
        },
        "meteor": 0.45548036562769456,
        "bleurt": 0.37678
    },
    "totto_test_contrast_challenge_table_size-table_size_45": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 79,
        "msttr-100": 0.73545,
        "msttr-100_nopunct": 0.789,
        "total_length": 1181,
        "mean_pred_length": 14.949367088607595,
        "std_pred_length": 5.116116837813358,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.5097375105842507,
        "vocab_size-1": 602,
        "unique-1": 485,
        "entropy-1": 8.002234325726088,
        "distinct-2": 0.8847549909255898,
        "vocab_size-2": 975,
        "unique-2": 900,
        "entropy-2": 9.802685065780212,
        "cond_entropy-2": 1.5291375482094138,
        "distinct-3": 0.9716520039100685,
        "vocab_size-3": 994,
        "unique-3": 966,
        "entropy-3": 9.941156522118533,
        "cond_entropy-3": 0.12546069336098103,
        "total_length-nopunct": 1028,
        "mean_pred_length-nopunct": 13.012658227848101,
        "std_pred_length-nopunct": 4.57703035361088,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5797665369649806,
        "vocab_size-1-nopunct": 596,
        "unique-1-nopunct": 484,
        "entropy-1-nopunct": 8.275667025556887,
        "distinct-2-nopunct": 0.9030558482613277,
        "vocab_size-2-nopunct": 857,
        "unique-2-nopunct": 803,
        "entropy-2-nopunct": 9.626709868234556,
        "cond_entropy-2-nopunct": 1.4477149521230912,
        "distinct-3-nopunct": 0.9793103448275862,
        "vocab_size-3-nopunct": 852,
        "unique-3-nopunct": 834,
        "entropy-3-nopunct": 9.723492280391321,
        "cond_entropy-3-nopunct": 0.11496723778217219,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.629979497713265,
        "rouge1": {
            "precision": 0.75191,
            "recall": 0.68205,
            "fmeasure": 0.69885
        },
        "rouge2": {
            "precision": 0.52268,
            "recall": 0.47377,
            "fmeasure": 0.48349
        },
        "rougeL": {
            "precision": 0.65397,
            "recall": 0.59531,
            "fmeasure": 0.60819
        },
        "rougeLsum": {
            "precision": 0.65397,
            "recall": 0.59531,
            "fmeasure": 0.60819
        },
        "bleu": 41.38344,
        "local_recall": {
            "1": 0.2282958199356913,
            "2": 0.410958904109589,
            "3": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.92971,
            "recall": 0.91504,
            "f1": 0.92046
        },
        "nubia": {
            "semantic_relation": 4.08534,
            "contradiction": 10.13075,
            "irrelevancy": 30.47736,
            "logical_agreement": 59.39189,
            "grammar_ref": 4.80224,
            "grammar_hyp": 4.92488,
            "nubia_score": 0.68269
        },
        "meteor": 0.3674130687428946,
        "bleurt": 0.1825
    },
    "totto_test_contrast_challenge_table_size-table_size_21": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 91,
        "msttr-100": 0.69923,
        "msttr-100_nopunct": 0.74455,
        "total_length": 1375,
        "mean_pred_length": 15.10989010989011,
        "std_pred_length": 4.960172252969947,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 30,
        "distinct-1": 0.4109090909090909,
        "vocab_size-1": 565,
        "unique-1": 449,
        "entropy-1": 7.651687411688512,
        "distinct-2": 0.7398753894080997,
        "vocab_size-2": 950,
        "unique-2": 843,
        "entropy-2": 9.493274192615663,
        "cond_entropy-2": 1.5932285412539597,
        "distinct-3": 0.854149203688181,
        "vocab_size-3": 1019,
        "unique-3": 955,
        "entropy-3": 9.77800154256314,
        "cond_entropy-3": 0.29443254763617455,
        "total_length-nopunct": 1195,
        "mean_pred_length-nopunct": 13.131868131868131,
        "std_pred_length-nopunct": 4.516657305284521,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.46694560669456064,
        "vocab_size-1-nopunct": 558,
        "unique-1-nopunct": 447,
        "entropy-1-nopunct": 7.89650690560339,
        "distinct-2-nopunct": 0.759963768115942,
        "vocab_size-2-nopunct": 839,
        "unique-2-nopunct": 758,
        "entropy-2-nopunct": 9.327881269375744,
        "cond_entropy-2-nopunct": 1.5378161626687552,
        "distinct-3-nopunct": 0.8647581441263573,
        "vocab_size-3-nopunct": 876,
        "unique-3-nopunct": 824,
        "entropy-3-nopunct": 9.576969521217576,
        "cond_entropy-3-nopunct": 0.28941308406669913,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.393084824213788,
        "rouge1": {
            "precision": 0.79689,
            "recall": 0.73864,
            "fmeasure": 0.7555
        },
        "rouge2": {
            "precision": 0.58943,
            "recall": 0.539,
            "fmeasure": 0.55485
        },
        "rougeL": {
            "precision": 0.70782,
            "recall": 0.65582,
            "fmeasure": 0.6711
        },
        "rougeLsum": {
            "precision": 0.70782,
            "recall": 0.65582,
            "fmeasure": 0.6711
        },
        "bleu": 49.59285,
        "local_recall": {
            "1": 0.23873873873873874,
            "2": 0.42857142857142855,
            "3": 0.7615546218487395
        },
        "bertscore": {
            "precision": 0.93521,
            "recall": 0.92139,
            "f1": 0.9271
        },
        "nubia": {
            "semantic_relation": 4.14243,
            "contradiction": 5.33218,
            "irrelevancy": 24.913,
            "logical_agreement": 69.75483,
            "grammar_ref": 4.3909,
            "grammar_hyp": 4.41075,
            "nubia_score": 0.73948
        },
        "meteor": 0.3944034739419327,
        "bleurt": 0.30172
    },
    "totto_test_contrast_challenge_table_size-table_size_46": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 10.75,
        "std_pred_length": 3.344772040064913,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.7906976744186046,
        "vocab_size-1": 34,
        "unique-1": 28,
        "entropy-1": 4.9435929523262025,
        "distinct-2": 1.0,
        "vocab_size-2": 39,
        "unique-2": 39,
        "entropy-2": 5.285402218862247,
        "cond_entropy-2": 0.1861858616515212,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.15611920191728196,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 8.75,
        "std_pred_length-nopunct": 2.165063509461097,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.822000516883151,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.17184514835040765,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.19930880822340663,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.400662708729556,
        "rouge1": {
            "precision": 0.83102,
            "recall": 0.76877,
            "fmeasure": 0.79358
        },
        "rouge2": {
            "precision": 0.61134,
            "recall": 0.56601,
            "fmeasure": 0.5846
        },
        "rougeL": {
            "precision": 0.72569,
            "recall": 0.67988,
            "fmeasure": 0.69792
        },
        "rougeLsum": {
            "precision": 0.72569,
            "recall": 0.67988,
            "fmeasure": 0.69792
        },
        "bleu": 50.5491,
        "local_recall": {
            "1": 0.19230769230769232,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.94348,
            "recall": 0.94909,
            "f1": 0.94605
        },
        "nubia": {
            "semantic_relation": 4.25635,
            "contradiction": 1.02628,
            "irrelevancy": 44.09387,
            "logical_agreement": 54.87984,
            "grammar_ref": 6.02061,
            "grammar_hyp": 6.11829,
            "nubia_score": 0.71617
        },
        "meteor": 0.4172758523736073,
        "bleurt": 0.33974
    },
    "totto_test_contrast_challenge_table_size-table_size_68": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.702,
        "msttr-100_nopunct": 0.734,
        "total_length": 596,
        "mean_pred_length": 16.555555555555557,
        "std_pred_length": 5.852086258783863,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.575503355704698,
        "vocab_size-1": 343,
        "unique-1": 296,
        "entropy-1": 7.368326195319431,
        "distinct-2": 0.9285714285714286,
        "vocab_size-2": 520,
        "unique-2": 502,
        "entropy-2": 8.915516336828201,
        "cond_entropy-2": 1.4071525519462227,
        "distinct-3": 0.9847328244274809,
        "vocab_size-3": 516,
        "unique-3": 508,
        "entropy-3": 9.002888650392443,
        "cond_entropy-3": 0.09824178013708765,
        "total_length-nopunct": 530,
        "mean_pred_length-nopunct": 14.722222222222221,
        "std_pred_length-nopunct": 5.69898193204088,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6339622641509434,
        "vocab_size-1-nopunct": 336,
        "unique-1-nopunct": 295,
        "entropy-1-nopunct": 7.485000842507507,
        "distinct-2-nopunct": 0.9271255060728745,
        "vocab_size-2-nopunct": 458,
        "unique-2-nopunct": 444,
        "entropy-2-nopunct": 8.722234962626365,
        "cond_entropy-2-nopunct": 1.329500577503072,
        "distinct-3-nopunct": 0.9890829694323144,
        "vocab_size-3-nopunct": 453,
        "unique-3-nopunct": 448,
        "entropy-3-nopunct": 8.817369726961594,
        "cond_entropy-3-nopunct": 0.11072594704801617,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.63597585658722,
        "rouge1": {
            "precision": 0.81871,
            "recall": 0.7409,
            "fmeasure": 0.76525
        },
        "rouge2": {
            "precision": 0.59435,
            "recall": 0.52917,
            "fmeasure": 0.55009
        },
        "rougeL": {
            "precision": 0.73416,
            "recall": 0.66596,
            "fmeasure": 0.68708
        },
        "rougeLsum": {
            "precision": 0.73416,
            "recall": 0.66596,
            "fmeasure": 0.68708
        },
        "bleu": 45.76628,
        "local_recall": {
            "1": 0.22972972972972974,
            "2": 0.3595505617977528,
            "3": 0.7796610169491526
        },
        "bertscore": {
            "precision": 0.94461,
            "recall": 0.92822,
            "f1": 0.93472
        },
        "nubia": {
            "semantic_relation": 4.20443,
            "contradiction": 3.5246,
            "irrelevancy": 22.38082,
            "logical_agreement": 74.09458,
            "grammar_ref": 4.82696,
            "grammar_hyp": 5.03672,
            "nubia_score": 0.70459
        },
        "meteor": 0.38123134675158465,
        "bleurt": 0.28093
    },
    "totto_test_contrast_challenge_table_size-table_size_47": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.8108108108108109,
        "vocab_size-1": 30,
        "unique-1": 24,
        "entropy-1": 4.810672622327237,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.2842550085206872,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.08488889758651327,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8285714285714286,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.764857659740294,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.30162284490328883,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.116092548264776,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.74242,
            "fmeasure": 0.70242
        },
        "rouge2": {
            "precision": 0.44862,
            "recall": 0.5,
            "fmeasure": 0.47287
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.69481,
            "fmeasure": 0.65797
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.69481,
            "fmeasure": 0.65797
        },
        "bleu": 30.53703,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.91921,
            "recall": 0.94021,
            "f1": 0.92957
        },
        "nubia": {
            "semantic_relation": 4.37221,
            "contradiction": 46.08143,
            "irrelevancy": 3.39202,
            "logical_agreement": 50.52655,
            "grammar_ref": 5.14789,
            "grammar_hyp": 4.71194,
            "nubia_score": 0.79879
        },
        "meteor": 0.3619032402340874,
        "bleurt": 0.4629
    },
    "totto_test_contrast_challenge_table_size-table_size_22": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.725,
        "total_length": 280,
        "mean_pred_length": 16.470588235294116,
        "std_pred_length": 6.010947337090332,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.6035714285714285,
        "vocab_size-1": 169,
        "unique-1": 136,
        "entropy-1": 6.733514054173602,
        "distinct-2": 0.9049429657794676,
        "vocab_size-2": 238,
        "unique-2": 219,
        "entropy-2": 7.821355183403075,
        "cond_entropy-2": 0.9951504677514302,
        "distinct-3": 0.9715447154471545,
        "vocab_size-3": 239,
        "unique-3": 232,
        "entropy-3": 7.885603936233586,
        "cond_entropy-3": 0.07928364998544774,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 14.764705882352942,
        "std_pred_length-nopunct": 5.546905992530015,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.649402390438247,
        "vocab_size-1-nopunct": 163,
        "unique-1-nopunct": 134,
        "entropy-1-nopunct": 6.754450676296279,
        "distinct-2-nopunct": 0.9017094017094017,
        "vocab_size-2-nopunct": 211,
        "unique-2-nopunct": 194,
        "entropy-2-nopunct": 7.642931895015552,
        "cond_entropy-2-nopunct": 0.9598084790617023,
        "distinct-3-nopunct": 0.967741935483871,
        "vocab_size-3-nopunct": 210,
        "unique-3-nopunct": 203,
        "entropy-3-nopunct": 7.697035103412234,
        "cond_entropy-3-nopunct": 0.06731223151947872,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.962007572445823,
        "rouge1": {
            "precision": 0.68899,
            "recall": 0.64582,
            "fmeasure": 0.64314
        },
        "rouge2": {
            "precision": 0.45176,
            "recall": 0.40266,
            "fmeasure": 0.41199
        },
        "rougeL": {
            "precision": 0.57991,
            "recall": 0.53639,
            "fmeasure": 0.53704
        },
        "rougeLsum": {
            "precision": 0.57991,
            "recall": 0.53639,
            "fmeasure": 0.53704
        },
        "bleu": 39.87184,
        "local_recall": {
            "1": 0.10526315789473684,
            "2": 0.421875,
            "3": 0.7192982456140351
        },
        "bertscore": {
            "precision": 0.90881,
            "recall": 0.89998,
            "f1": 0.90347
        },
        "nubia": {
            "semantic_relation": 3.95439,
            "contradiction": 14.05921,
            "irrelevancy": 18.5827,
            "logical_agreement": 67.35809,
            "grammar_ref": 4.31337,
            "grammar_hyp": 4.3168,
            "nubia_score": 0.62648
        },
        "meteor": 0.34690102125163136,
        "bleurt": 0.19219
    },
    "cs_restaurants_test_contrast_challenge_acts-inform_no_match": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 34,
        "msttr-100": 0.50333,
        "msttr-100_nopunct": 0.54667,
        "total_length": 358,
        "mean_pred_length": 10.529411764705882,
        "std_pred_length": 3.21060095270475,
        "median_pred_length": 9.5,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.2681564245810056,
        "vocab_size-1": 96,
        "unique-1": 35,
        "entropy-1": 5.810935556006452,
        "distinct-2": 0.5061728395061729,
        "vocab_size-2": 164,
        "unique-2": 89,
        "entropy-2": 6.990596926976507,
        "cond_entropy-2": 0.9262792441807376,
        "distinct-3": 0.6551724137931034,
        "vocab_size-3": 190,
        "unique-3": 126,
        "entropy-3": 7.353832733152943,
        "cond_entropy-3": 0.2839737397725323,
        "total_length-nopunct": 313,
        "mean_pred_length-nopunct": 9.205882352941176,
        "std_pred_length-nopunct": 2.730862950927308,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.3003194888178914,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.9070679370196055,
        "distinct-2-nopunct": 0.5268817204301075,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.882461491846043,
        "cond_entropy-2-nopunct": 0.9437980958565699,
        "distinct-3-nopunct": 0.6775510204081633,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 7.174053908240224,
        "cond_entropy-3-nopunct": 0.2824380016912184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 2.8308032965001213,
        "rouge1": {
            "precision": 0.52081,
            "recall": 0.49323,
            "fmeasure": 0.49957
        },
        "rouge2": {
            "precision": 0.30541,
            "recall": 0.2927,
            "fmeasure": 0.29424
        },
        "rougeL": {
            "precision": 0.44403,
            "recall": 0.42434,
            "fmeasure": 0.42802
        },
        "rougeLsum": {
            "precision": 0.44403,
            "recall": 0.42434,
            "fmeasure": 0.42802
        },
        "bleu": 15.29368,
        "local_recall": {
            "1": 0.382089552238806
        },
        "bertscore": {
            "precision": 0.91229,
            "recall": 0.9076,
            "f1": 0.90981
        },
        "nubia": {
            "semantic_relation": 3.15447,
            "contradiction": 27.13352,
            "irrelevancy": 18.91087,
            "logical_agreement": 53.95562,
            "grammar_ref": 6.46033,
            "grammar_hyp": 6.45522,
            "nubia_score": 0.42785
        },
        "meteor": 0.21200697287450498,
        "bleurt": -0.17228
    },
    "totto_test_contrast_challenge_table_size-table_size_69": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 16.5,
        "std_pred_length": 6.5,
        "median_pred_length": 15.5,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.696969696969697,
        "vocab_size-1": 69,
        "unique-1": 54,
        "entropy-1": 5.834699706311361,
        "distinct-2": 0.956989247311828,
        "vocab_size-2": 89,
        "unique-2": 85,
        "entropy-2": 6.453137305731693,
        "cond_entropy-2": 0.5029340131653052,
        "distinct-3": 1.0,
        "vocab_size-3": 87,
        "unique-3": 87,
        "entropy-3": 6.442943495848723,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 5.639641438562877,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7764705882352941,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.897511230204448,
        "distinct-2-nopunct": 0.9746835443037974,
        "vocab_size-2-nopunct": 77,
        "unique-2-nopunct": 75,
        "entropy-2-nopunct": 6.2531478367846995,
        "cond_entropy-2-nopunct": 0.3290714576455358,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": -0.07286029888612669,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.459540992020568,
        "rouge1": {
            "precision": 0.67508,
            "recall": 0.57827,
            "fmeasure": 0.61223
        },
        "rouge2": {
            "precision": 0.36006,
            "recall": 0.31295,
            "fmeasure": 0.32901
        },
        "rougeL": {
            "precision": 0.52048,
            "recall": 0.44172,
            "fmeasure": 0.46736
        },
        "rougeLsum": {
            "precision": 0.52048,
            "recall": 0.44172,
            "fmeasure": 0.46736
        },
        "bleu": 27.02339,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.4230769230769231,
            "3": 0.7068965517241379
        },
        "bertscore": {
            "precision": 0.9108,
            "recall": 0.89148,
            "f1": 0.90065
        },
        "nubia": {
            "semantic_relation": 3.77769,
            "contradiction": 15.94916,
            "irrelevancy": 50.3578,
            "logical_agreement": 33.69303,
            "grammar_ref": 3.92533,
            "grammar_hyp": 4.32458,
            "nubia_score": 0.62555
        },
        "meteor": 0.31709128991757196,
        "bleurt": 0.03846
    },
    "totto_test_contrast_challenge_table_size-table_size_23": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.68,
        "total_length": 117,
        "mean_pred_length": 16.714285714285715,
        "std_pred_length": 4.948716593053935,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.6153846153846154,
        "vocab_size-1": 72,
        "unique-1": 57,
        "entropy-1": 5.734519822236548,
        "distinct-2": 0.9272727272727272,
        "vocab_size-2": 102,
        "unique-2": 95,
        "entropy-2": 6.629042554414091,
        "cond_entropy-2": 0.8167149074238983,
        "distinct-3": 0.9805825242718447,
        "vocab_size-3": 101,
        "unique-3": 99,
        "entropy-3": 6.647665575726925,
        "cond_entropy-3": 0.028974672902864415,
        "total_length-nopunct": 103,
        "mean_pred_length-nopunct": 14.714285714285714,
        "std_pred_length-nopunct": 4.89064079103534,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6796116504854369,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.77985899334581,
        "distinct-2-nopunct": 0.9479166666666666,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 87,
        "entropy-2-nopunct": 6.472932422573624,
        "cond_entropy-2-nopunct": 0.7487660410701316,
        "distinct-3-nopunct": 0.9887640449438202,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 87,
        "entropy-3-nopunct": 6.453261520854051,
        "cond_entropy-3-nopunct": -0.010859547258539604,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.082987845576468,
        "rouge1": {
            "precision": 0.62581,
            "recall": 0.64819,
            "fmeasure": 0.63245
        },
        "rouge2": {
            "precision": 0.39275,
            "recall": 0.40773,
            "fmeasure": 0.39736
        },
        "rougeL": {
            "precision": 0.49898,
            "recall": 0.52848,
            "fmeasure": 0.51052
        },
        "rougeLsum": {
            "precision": 0.49898,
            "recall": 0.52848,
            "fmeasure": 0.51052
        },
        "bleu": 29.39864,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.3076923076923077,
            "3": 0.64
        },
        "bertscore": {
            "precision": 0.90082,
            "recall": 0.89324,
            "f1": 0.89381
        },
        "nubia": {
            "semantic_relation": 4.04814,
            "contradiction": 0.41685,
            "irrelevancy": 47.24657,
            "logical_agreement": 52.33658,
            "grammar_ref": 4.51794,
            "grammar_hyp": 4.20652,
            "nubia_score": 0.70125
        },
        "meteor": 0.3002697482424693,
        "bleurt": 0.167
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 349,
        "msttr-100": 0.65825,
        "msttr-100_nopunct": 0.69431,
        "total_length": 5703,
        "mean_pred_length": 16.340974212034386,
        "std_pred_length": 4.024432569149715,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.17306680694371385,
        "vocab_size-1": 987,
        "unique-1": 432,
        "entropy-1": 7.8410784896978525,
        "distinct-2": 0.4445274561075831,
        "vocab_size-2": 2380,
        "unique-2": 1497,
        "entropy-2": 10.479086841784936,
        "cond_entropy-2": 2.4156726478473236,
        "distinct-3": 0.621978021978022,
        "vocab_size-3": 3113,
        "unique-3": 2306,
        "entropy-3": 11.193943008287027,
        "cond_entropy-3": 0.7984573132587054,
        "total_length-nopunct": 5110,
        "mean_pred_length-nopunct": 14.641833810888253,
        "std_pred_length-nopunct": 3.7363808954490816,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.19158512720156556,
        "vocab_size-1-nopunct": 979,
        "unique-1-nopunct": 431,
        "entropy-1-nopunct": 8.05094683972441,
        "distinct-2-nopunct": 0.42953161100609116,
        "vocab_size-2-nopunct": 2045,
        "unique-2-nopunct": 1271,
        "entropy-2-nopunct": 10.243262358043843,
        "cond_entropy-2-nopunct": 2.382092134601942,
        "distinct-3-nopunct": 0.6092475067996374,
        "vocab_size-3-nopunct": 2688,
        "unique-3-nopunct": 1978,
        "entropy-3-nopunct": 10.962930226071881,
        "cond_entropy-3-nopunct": 0.7923415227622524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 9.095445986847112,
        "rouge1": {
            "precision": 0.79155,
            "recall": 0.78495,
            "fmeasure": 0.78184
        },
        "rouge2": {
            "precision": 0.56152,
            "recall": 0.55408,
            "fmeasure": 0.55232
        },
        "rougeL": {
            "precision": 0.67521,
            "recall": 0.66705,
            "fmeasure": 0.66493
        },
        "rougeLsum": {
            "precision": 0.67521,
            "recall": 0.66705,
            "fmeasure": 0.66493
        },
        "bleu": 54.15676,
        "local_recall": {
            "1": 0.2369573874950219,
            "2": 0.555256064690027,
            "3": 0.8947368421052632,
            "4": 1.0
        },
        "bertscore": {
            "precision": 0.93564,
            "recall": 0.93491,
            "f1": 0.93377
        },
        "nubia": {
            "semantic_relation": 4.64422,
            "contradiction": 4.9781,
            "irrelevancy": 7.47713,
            "logical_agreement": 87.54478,
            "grammar_ref": 4.75348,
            "grammar_hyp": 4.8224,
            "nubia_score": 0.83957
        },
        "meteor": 0.42547091849663266,
        "bleurt": 0.29547
    },
    "cs_restaurants_test_contrast_challenge_acts-?select": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 12,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 6.5,
        "std_pred_length": 1.9790570145063195,
        "median_pred_length": 6.0,
        "min_pred_length": 5,
        "max_pred_length": 12,
        "distinct-1": 0.38461538461538464,
        "vocab_size-1": 30,
        "unique-1": 13,
        "entropy-1": 4.481426135780647,
        "distinct-2": 0.6363636363636364,
        "vocab_size-2": 42,
        "unique-2": 29,
        "entropy-2": 5.183879156942225,
        "cond_entropy-2": 0.3786373088634742,
        "distinct-3": 0.6851851851851852,
        "vocab_size-3": 37,
        "unique-3": 28,
        "entropy-3": 5.0134226870281395,
        "cond_entropy-3": -0.1553378672350489,
        "total_length-nopunct": 64,
        "mean_pred_length-nopunct": 5.333333333333333,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.4375,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 4.504834617629517,
        "distinct-2-nopunct": 0.6346153846153846,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.829589477465242,
        "cond_entropy-2-nopunct": 0.4179711499010652,
        "distinct-3-nopunct": 0.675,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.558694969562842,
        "cond_entropy-3-nopunct": -0.2723838108078165,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 1.6700767251458624,
        "rouge1": {
            "precision": 0.39216,
            "recall": 0.33322,
            "fmeasure": 0.35518
        },
        "rouge2": {
            "precision": 0.26892,
            "recall": 0.22962,
            "fmeasure": 0.24355
        },
        "rougeL": {
            "precision": 0.39216,
            "recall": 0.33322,
            "fmeasure": 0.35518
        },
        "rougeLsum": {
            "precision": 0.39216,
            "recall": 0.33322,
            "fmeasure": 0.35518
        },
        "bleu": 15.60958,
        "local_recall": {
            "1": 0.25609756097560976
        },
        "bertscore": {
            "precision": 0.88544,
            "recall": 0.87239,
            "f1": 0.87871
        },
        "nubia": {
            "semantic_relation": 2.3857,
            "contradiction": 33.23519,
            "irrelevancy": 25.39791,
            "logical_agreement": 41.3669,
            "grammar_ref": 6.83527,
            "grammar_hyp": 7.22958,
            "nubia_score": 0.21048
        },
        "meteor": 0.1434963216127851,
        "bleurt": -0.29023
    },
    "totto_test_contrast_challenge_table_size-table_size_96": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 50,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.74714,
        "total_length": 787,
        "mean_pred_length": 15.74,
        "std_pred_length": 5.888327436547665,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.5463786531130876,
        "vocab_size-1": 430,
        "unique-1": 361,
        "entropy-1": 7.638527553574481,
        "distinct-2": 0.9063772048846676,
        "vocab_size-2": 668,
        "unique-2": 633,
        "entropy-2": 9.259336188328781,
        "cond_entropy-2": 1.4121564011141692,
        "distinct-3": 0.9781659388646288,
        "vocab_size-3": 672,
        "unique-3": 661,
        "entropy-3": 9.376102897248167,
        "cond_entropy-3": 0.12740605540872377,
        "total_length-nopunct": 702,
        "mean_pred_length-nopunct": 14.04,
        "std_pred_length-nopunct": 5.458791074954234,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.6054131054131054,
        "vocab_size-1-nopunct": 425,
        "unique-1-nopunct": 360,
        "entropy-1-nopunct": 7.81949004242883,
        "distinct-2-nopunct": 0.9156441717791411,
        "vocab_size-2-nopunct": 597,
        "unique-2-nopunct": 574,
        "entropy-2-nopunct": 9.093853820634743,
        "cond_entropy-2-nopunct": 1.366511373676303,
        "distinct-3-nopunct": 0.9817275747508306,
        "vocab_size-3-nopunct": 591,
        "unique-3-nopunct": 583,
        "entropy-3-nopunct": 9.193312928410077,
        "cond_entropy-3-nopunct": 0.11896694279147521,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.460663720345049,
        "rouge1": {
            "precision": 0.77212,
            "recall": 0.69963,
            "fmeasure": 0.72383
        },
        "rouge2": {
            "precision": 0.53112,
            "recall": 0.48929,
            "fmeasure": 0.50188
        },
        "rougeL": {
            "precision": 0.66594,
            "recall": 0.61589,
            "fmeasure": 0.63126
        },
        "rougeLsum": {
            "precision": 0.66594,
            "recall": 0.61589,
            "fmeasure": 0.63126
        },
        "bleu": 41.55597,
        "local_recall": {
            "1": 0.21333333333333335,
            "2": 0.46540880503144655,
            "3": 0.7098540145985401
        },
        "bertscore": {
            "precision": 0.92799,
            "recall": 0.91036,
            "f1": 0.91818
        },
        "nubia": {
            "semantic_relation": 4.114,
            "contradiction": 10.84776,
            "irrelevancy": 30.90687,
            "logical_agreement": 58.24537,
            "grammar_ref": 4.7145,
            "grammar_hyp": 4.72444,
            "nubia_score": 0.69644
        },
        "meteor": 0.36052232033995735,
        "bleurt": 0.21378
    },
    "totto_test_contrast_challenge_table_size-table_size_98": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.68,
        "total_length": 189,
        "mean_pred_length": 17.181818181818183,
        "std_pred_length": 4.763844547845055,
        "median_pred_length": 18.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.6402116402116402,
        "vocab_size-1": 121,
        "unique-1": 101,
        "entropy-1": 6.44463249971269,
        "distinct-2": 0.9044943820224719,
        "vocab_size-2": 161,
        "unique-2": 151,
        "entropy-2": 7.252281534838184,
        "cond_entropy-2": 0.7164377101626668,
        "distinct-3": 0.9341317365269461,
        "vocab_size-3": 156,
        "unique-3": 149,
        "entropy-3": 7.233886627751551,
        "cond_entropy-3": -0.003676518718911851,
        "total_length-nopunct": 171,
        "mean_pred_length-nopunct": 15.545454545454545,
        "std_pred_length-nopunct": 4.716771553117399,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6842105263157895,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 99,
        "entropy-1-nopunct": 6.464358560121558,
        "distinct-2-nopunct": 0.89375,
        "vocab_size-2-nopunct": 143,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.0733378604447585,
        "cond_entropy-2-nopunct": 0.6745320097132399,
        "distinct-3-nopunct": 0.9261744966442953,
        "vocab_size-3-nopunct": 138,
        "unique-3-nopunct": 131,
        "entropy-3-nopunct": 7.0512520774510685,
        "cond_entropy-3-nopunct": -0.0037334838066539968,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.986825031611994,
        "rouge1": {
            "precision": 0.77288,
            "recall": 0.76107,
            "fmeasure": 0.76256
        },
        "rouge2": {
            "precision": 0.57611,
            "recall": 0.55732,
            "fmeasure": 0.56412
        },
        "rougeL": {
            "precision": 0.70512,
            "recall": 0.6861,
            "fmeasure": 0.69149
        },
        "rougeLsum": {
            "precision": 0.70512,
            "recall": 0.6861,
            "fmeasure": 0.69149
        },
        "bleu": 51.28355,
        "local_recall": {
            "1": 0.23255813953488372,
            "2": 0.5789473684210527,
            "3": 0.7647058823529411
        },
        "bertscore": {
            "precision": 0.93168,
            "recall": 0.93103,
            "f1": 0.93061
        },
        "nubia": {
            "semantic_relation": 4.3395,
            "contradiction": 1.04635,
            "irrelevancy": 26.57364,
            "logical_agreement": 72.38001,
            "grammar_ref": 4.3854,
            "grammar_hyp": 4.51827,
            "nubia_score": 0.78855
        },
        "meteor": 0.40429689208471237,
        "bleurt": 0.32625
    },
    "totto_test_contrast_challenge_table_size-table_size_10": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 162,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.7565,
        "total_length": 2351,
        "mean_pred_length": 14.512345679012345,
        "std_pred_length": 4.879078103470499,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.3432581880051042,
        "vocab_size-1": 807,
        "unique-1": 584,
        "entropy-1": 7.957051514016011,
        "distinct-2": 0.7163088168113294,
        "vocab_size-2": 1568,
        "unique-2": 1323,
        "entropy-2": 10.244311460771682,
        "cond_entropy-2": 2.0073236747999608,
        "distinct-3": 0.8870251603354712,
        "vocab_size-3": 1798,
        "unique-3": 1674,
        "entropy-3": 10.688941131833468,
        "cond_entropy-3": 0.44784186310693613,
        "total_length-nopunct": 2051,
        "mean_pred_length-nopunct": 12.660493827160494,
        "std_pred_length-nopunct": 4.360546432298767,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.3900536323744515,
        "vocab_size-1-nopunct": 800,
        "unique-1-nopunct": 583,
        "entropy-1-nopunct": 8.272328261215224,
        "distinct-2-nopunct": 0.7400741132874536,
        "vocab_size-2-nopunct": 1398,
        "unique-2-nopunct": 1208,
        "entropy-2-nopunct": 10.082936857144155,
        "cond_entropy-2-nopunct": 1.9157471431320339,
        "distinct-3-nopunct": 0.8992472495657209,
        "vocab_size-3-nopunct": 1553,
        "unique-3-nopunct": 1463,
        "entropy-3-nopunct": 10.485110740550008,
        "cond_entropy-3-nopunct": 0.4225268618632949,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.7386922192360705,
        "rouge1": {
            "precision": 0.74552,
            "recall": 0.73156,
            "fmeasure": 0.72802
        },
        "rouge2": {
            "precision": 0.50985,
            "recall": 0.49839,
            "fmeasure": 0.49557
        },
        "rougeL": {
            "precision": 0.63568,
            "recall": 0.62627,
            "fmeasure": 0.62112
        },
        "rougeLsum": {
            "precision": 0.63568,
            "recall": 0.62627,
            "fmeasure": 0.62112
        },
        "bleu": 44.40251,
        "local_recall": {
            "1": 0.18501529051987767,
            "2": 0.36877828054298645,
            "3": 0.7844882390336936
        },
        "bertscore": {
            "precision": 0.9318,
            "recall": 0.92983,
            "f1": 0.92814
        },
        "nubia": {
            "semantic_relation": 4.16039,
            "contradiction": 12.69489,
            "irrelevancy": 25.42595,
            "logical_agreement": 61.87917,
            "grammar_ref": 4.55751,
            "grammar_hyp": 4.44912,
            "nubia_score": 0.74521
        },
        "meteor": 0.3937547077170461,
        "bleurt": 0.31157
    },
    "totto_test_contrast_challenge_table_size-table_size_99": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.765,
        "msttr-100_nopunct": 0.8,
        "total_length": 249,
        "mean_pred_length": 17.785714285714285,
        "std_pred_length": 6.349112102475111,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 33,
        "distinct-1": 0.6746987951807228,
        "vocab_size-1": 168,
        "unique-1": 141,
        "entropy-1": 6.9545895175666805,
        "distinct-2": 0.9531914893617022,
        "vocab_size-2": 224,
        "unique-2": 214,
        "entropy-2": 7.7796876380451385,
        "cond_entropy-2": 0.7230641885551097,
        "distinct-3": 0.9773755656108597,
        "vocab_size-3": 216,
        "unique-3": 211,
        "entropy-3": 7.742653690613132,
        "cond_entropy-3": -0.030899964086855733,
        "total_length-nopunct": 218,
        "mean_pred_length-nopunct": 15.571428571428571,
        "std_pred_length-nopunct": 5.010193690500052,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7385321100917431,
        "vocab_size-1-nopunct": 161,
        "unique-1-nopunct": 139,
        "entropy-1-nopunct": 6.999538052058391,
        "distinct-2-nopunct": 0.9558823529411765,
        "vocab_size-2-nopunct": 195,
        "unique-2-nopunct": 187,
        "entropy-2-nopunct": 7.580489618921676,
        "cond_entropy-2-nopunct": 0.6287998404812117,
        "distinct-3-nopunct": 0.9842105263157894,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.538276660962538,
        "cond_entropy-3-nopunct": -0.035438746787056004,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.913526625210614,
        "rouge1": {
            "precision": 0.66894,
            "recall": 0.62915,
            "fmeasure": 0.63319
        },
        "rouge2": {
            "precision": 0.39937,
            "recall": 0.37244,
            "fmeasure": 0.3728
        },
        "rougeL": {
            "precision": 0.57559,
            "recall": 0.55781,
            "fmeasure": 0.55175
        },
        "rougeLsum": {
            "precision": 0.57559,
            "recall": 0.55781,
            "fmeasure": 0.55175
        },
        "bleu": 31.87584,
        "local_recall": {
            "1": 0.11864406779661017,
            "2": 0.21739130434782608,
            "3": 0.696969696969697
        },
        "bertscore": {
            "precision": 0.9077,
            "recall": 0.90389,
            "f1": 0.90359
        },
        "nubia": {
            "semantic_relation": 3.80235,
            "contradiction": 5.57858,
            "irrelevancy": 38.12003,
            "logical_agreement": 56.30139,
            "grammar_ref": 4.70274,
            "grammar_hyp": 4.51261,
            "nubia_score": 0.6127
        },
        "meteor": 0.3262538919802199,
        "bleurt": 0.06165
    },
    "totto_test_contrast_challenge_table_size-table_size_70": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 81,
        "msttr-100": 0.72231,
        "msttr-100_nopunct": 0.79417,
        "total_length": 1396,
        "mean_pred_length": 17.234567901234566,
        "std_pred_length": 5.6004223935458795,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.47492836676217765,
        "vocab_size-1": 663,
        "unique-1": 525,
        "entropy-1": 8.100678805444698,
        "distinct-2": 0.8615969581749049,
        "vocab_size-2": 1133,
        "unique-2": 1035,
        "entropy-2": 9.990894341774709,
        "cond_entropy-2": 1.7092119591648252,
        "distinct-3": 0.9432739059967585,
        "vocab_size-3": 1164,
        "unique-3": 1116,
        "entropy-3": 10.1402298801009,
        "cond_entropy-3": 0.15456762676238225,
        "total_length-nopunct": 1204,
        "mean_pred_length-nopunct": 14.864197530864198,
        "std_pred_length-nopunct": 5.083872069617883,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5440199335548173,
        "vocab_size-1-nopunct": 655,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 8.385678267915132,
        "distinct-2-nopunct": 0.8771148708815673,
        "vocab_size-2-nopunct": 985,
        "unique-2-nopunct": 916,
        "entropy-2-nopunct": 9.79267125000106,
        "cond_entropy-2-nopunct": 1.5037629172883642,
        "distinct-3-nopunct": 0.9491362763915547,
        "vocab_size-3-nopunct": 989,
        "unique-3-nopunct": 953,
        "entropy-3-nopunct": 9.909684895749022,
        "cond_entropy-3-nopunct": 0.1396414268943911,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.750800602561263,
        "rouge1": {
            "precision": 0.77022,
            "recall": 0.74994,
            "fmeasure": 0.74525
        },
        "rouge2": {
            "precision": 0.55833,
            "recall": 0.54019,
            "fmeasure": 0.53759
        },
        "rougeL": {
            "precision": 0.66531,
            "recall": 0.64829,
            "fmeasure": 0.64281
        },
        "rougeLsum": {
            "precision": 0.66531,
            "recall": 0.64829,
            "fmeasure": 0.64281
        },
        "bleu": 51.37013,
        "local_recall": {
            "1": 0.24232081911262798,
            "2": 0.5193798449612403,
            "3": 0.7950819672131147
        },
        "bertscore": {
            "precision": 0.93263,
            "recall": 0.93098,
            "f1": 0.93001
        },
        "nubia": {
            "semantic_relation": 4.20533,
            "contradiction": 4.95242,
            "irrelevancy": 30.94223,
            "logical_agreement": 64.10536,
            "grammar_ref": 4.67017,
            "grammar_hyp": 4.68761,
            "nubia_score": 0.71985
        },
        "meteor": 0.4079562157414404,
        "bleurt": 0.26451
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 183,
        "msttr-100": 0.1916,
        "msttr-100_nopunct": 0.19158,
        "total_length": 2561,
        "mean_pred_length": 13.994535519125684,
        "std_pred_length": 2.591489365979396,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 15,
        "distinct-1": 0.018352206169465052,
        "vocab_size-1": 47,
        "unique-1": 10,
        "entropy-1": 4.040239703534966,
        "distinct-2": 0.03280067283431455,
        "vocab_size-2": 78,
        "unique-2": 27,
        "entropy-2": 4.418257667406067,
        "cond_entropy-2": 0.36005287355464904,
        "distinct-3": 0.03280182232346242,
        "vocab_size-3": 72,
        "unique-3": 26,
        "entropy-3": 4.2989552246452565,
        "cond_entropy-3": -0.10456267482511626,
        "total_length-nopunct": 1904,
        "mean_pred_length-nopunct": 10.404371584699453,
        "std_pred_length-nopunct": 1.7210946172703412,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.023634453781512604,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 4.034938783974795,
        "distinct-2-nopunct": 0.03660662405578152,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.038890549618124,
        "cond_entropy-2-nopunct": 0.01468751596504552,
        "distinct-3-nopunct": 0.036410923276983094,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 3.878536245268372,
        "cond_entropy-3-nopunct": -0.15033598371649404,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 0.642965277525477,
        "rouge1": {
            "precision": 0.12613,
            "recall": 0.19406,
            "fmeasure": 0.14445
        },
        "rouge2": {
            "precision": 0.0647,
            "recall": 0.08943,
            "fmeasure": 0.07036
        },
        "rougeL": {
            "precision": 0.11307,
            "recall": 0.17325,
            "fmeasure": 0.12878
        },
        "rougeLsum": {
            "precision": 0.11307,
            "recall": 0.17325,
            "fmeasure": 0.12878
        },
        "bleu": 2.79778,
        "local_recall": {
            "1": 0.1365902293120638
        },
        "bertscore": {
            "precision": 0.81689,
            "recall": 0.8536,
            "f1": 0.83468
        },
        "nubia": {
            "semantic_relation": 1.24905,
            "contradiction": 51.72714,
            "irrelevancy": 35.03033,
            "logical_agreement": 13.24253,
            "grammar_ref": 6.72681,
            "grammar_hyp": 6.12363,
            "nubia_score": 0.10549
        },
        "meteor": 0.07691214110777378,
        "bleurt": -0.72998
    },
    "totto_test_contrast_challenge_table_size-table_size_11": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.622,
        "msttr-100_nopunct": 0.68,
        "total_length": 593,
        "mean_pred_length": 16.47222222222222,
        "std_pred_length": 5.166591994681424,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.4317032040472175,
        "vocab_size-1": 256,
        "unique-1": 210,
        "entropy-1": 6.866147236001074,
        "distinct-2": 0.7271095152603232,
        "vocab_size-2": 405,
        "unique-2": 359,
        "entropy-2": 8.298900430013255,
        "cond_entropy-2": 1.2987420444973679,
        "distinct-3": 0.8406909788867563,
        "vocab_size-3": 438,
        "unique-3": 408,
        "entropy-3": 8.580825948447856,
        "cond_entropy-3": 0.2906012451883672,
        "total_length-nopunct": 507,
        "mean_pred_length-nopunct": 14.083333333333334,
        "std_pred_length-nopunct": 4.710360920354193,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.4930966469428008,
        "vocab_size-1-nopunct": 250,
        "unique-1-nopunct": 209,
        "entropy-1-nopunct": 6.960702907104673,
        "distinct-2-nopunct": 0.7643312101910829,
        "vocab_size-2-nopunct": 360,
        "unique-2-nopunct": 326,
        "entropy-2-nopunct": 8.1868904837128,
        "cond_entropy-2-nopunct": 1.2950113393497753,
        "distinct-3-nopunct": 0.8505747126436781,
        "vocab_size-3-nopunct": 370,
        "unique-3-nopunct": 347,
        "entropy-3-nopunct": 8.354979531516022,
        "cond_entropy-3-nopunct": 0.19704787439989677,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.752724200001205,
        "rouge1": {
            "precision": 0.77285,
            "recall": 0.7628,
            "fmeasure": 0.75954
        },
        "rouge2": {
            "precision": 0.56675,
            "recall": 0.56317,
            "fmeasure": 0.55837
        },
        "rougeL": {
            "precision": 0.69875,
            "recall": 0.69629,
            "fmeasure": 0.69002
        },
        "rougeLsum": {
            "precision": 0.69875,
            "recall": 0.69629,
            "fmeasure": 0.69002
        },
        "bleu": 51.04285,
        "local_recall": {
            "1": 0.23684210526315788,
            "2": 0.5660377358490566,
            "3": 0.7859237536656891
        },
        "bertscore": {
            "precision": 0.94066,
            "recall": 0.94119,
            "f1": 0.939
        },
        "nubia": {
            "semantic_relation": 4.07312,
            "contradiction": 6.94955,
            "irrelevancy": 31.18737,
            "logical_agreement": 61.86307,
            "grammar_ref": 3.9304,
            "grammar_hyp": 3.88733,
            "nubia_score": 0.75609
        },
        "meteor": 0.42772686392136317,
        "bleurt": 0.41434
    },
    "common_gen_validation": {
        "predictions_file": "ByT5-xl (Baseline)/common_gen_validation",
        "N": 993,
        "msttr-100": 0.61293,
        "msttr-100_nopunct": 0.63981,
        "total_length": 11657,
        "mean_pred_length": 11.739174219536757,
        "std_pred_length": 3.159003202195336,
        "median_pred_length": 11.0,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.1405164278974007,
        "vocab_size-1": 1638,
        "unique-1": 816,
        "entropy-1": 7.58452171337349,
        "distinct-2": 0.5059077269317329,
        "vocab_size-2": 5395,
        "unique-2": 4029,
        "entropy-2": 11.348024384478864,
        "cond_entropy-2": 3.517394460029092,
        "distinct-3": 0.7762382380312274,
        "vocab_size-3": 7507,
        "unique-3": 6550,
        "entropy-3": 12.563313400091504,
        "cond_entropy-3": 1.2702651229362896,
        "total_length-nopunct": 10795,
        "mean_pred_length-nopunct": 10.871097683786505,
        "std_pred_length-nopunct": 3.047046430095012,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.15136637332098193,
        "vocab_size-1-nopunct": 1634,
        "unique-1-nopunct": 814,
        "entropy-1-nopunct": 7.763056011773199,
        "distinct-2-nopunct": 0.5054070597837176,
        "vocab_size-2-nopunct": 4954,
        "unique-2-nopunct": 3742,
        "entropy-2-nopunct": 11.180007819047827,
        "cond_entropy-2-nopunct": 3.7135912323526252,
        "distinct-3-nopunct": 0.7802247701214666,
        "vocab_size-3-nopunct": 6873,
        "unique-3-nopunct": 6022,
        "entropy-3-nopunct": 12.433745901321915,
        "cond_entropy-3-nopunct": 1.335752466321319,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/common_gen_validation.json",
        "nist": 6.285615431757454,
        "rouge1": {
            "precision": 0.59542,
            "recall": 0.6185,
            "fmeasure": 0.59424
        },
        "rouge2": {
            "precision": 0.26739,
            "recall": 0.27297,
            "fmeasure": 0.26291
        },
        "rougeL": {
            "precision": 0.49724,
            "recall": 0.51442,
            "fmeasure": 0.49452
        },
        "rougeLsum": {
            "precision": 0.49724,
            "recall": 0.51442,
            "fmeasure": 0.49452
        },
        "bleu": 19.54978,
        "local_recall": {
            "1": 0.10579927509061367,
            "2": 0.3156914893617021,
            "3": 0.5033738191632928,
            "4": 0.7637335926105979,
            "5": 0.7939914163090128,
            "6": 0.7619047619047619,
            "7": 1.0,
            "8": 1.0
        },
        "bertscore": {
            "precision": 0.86855,
            "recall": 0.87603,
            "f1": 0.87073
        },
        "nubia": {
            "semantic_relation": 3.00163,
            "contradiction": 30.37766,
            "irrelevancy": 37.34637,
            "logical_agreement": 32.27597,
            "grammar_ref": 4.64808,
            "grammar_hyp": 4.8286,
            "nubia_score": 0.39633
        },
        "meteor": 0.24976048452325977,
        "bleurt": -0.56345
    },
    "common_gen_test": {
        "predictions_file": "ByT5-xl (Baseline)/common_gen_test",
        "N": 1497
    },
    "totto_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 898,
        "msttr-100": 0.7048,
        "msttr-100_nopunct": 0.7569,
        "total_length": 10072,
        "mean_pred_length": 11.216035634743875,
        "std_pred_length": 3.696155994955025,
        "median_pred_length": 11.0,
        "min_pred_length": 4,
        "max_pred_length": 26,
        "distinct-1": 0.3242652899126291,
        "vocab_size-1": 3266,
        "unique-1": 2439,
        "entropy-1": 8.997229906070846,
        "distinct-2": 0.6608894702419882,
        "vocab_size-2": 6063,
        "unique-2": 5200,
        "entropy-2": 11.843193241723558,
        "cond_entropy-2": 2.307997137607839,
        "distinct-3": 0.8142822619623006,
        "vocab_size-3": 6739,
        "unique-3": 6089,
        "entropy-3": 12.457755949179491,
        "cond_entropy-3": 0.5804779162550161,
        "total_length-nopunct": 8759,
        "mean_pred_length-nopunct": 9.75389755011136,
        "std_pred_length-nopunct": 3.2594921104386514,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.3713894280168969,
        "vocab_size-1-nopunct": 3253,
        "unique-1-nopunct": 2436,
        "entropy-1-nopunct": 9.464815927718835,
        "distinct-2-nopunct": 0.685281770767078,
        "vocab_size-2-nopunct": 5387,
        "unique-2-nopunct": 4687,
        "entropy-2-nopunct": 11.706048029240408,
        "cond_entropy-2-nopunct": 2.4395600392367447,
        "distinct-3-nopunct": 0.8233520034467902,
        "vocab_size-3-nopunct": 5733,
        "unique-3-nopunct": 5204,
        "entropy-3-nopunct": 12.237326921340918,
        "cond_entropy-3-nopunct": 0.6120002543989026,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.937410747252589,
        "rouge1": {
            "precision": 0.74374,
            "recall": 0.73295,
            "fmeasure": 0.72374
        },
        "rouge2": {
            "precision": 0.55847,
            "recall": 0.55139,
            "fmeasure": 0.5436
        },
        "rougeL": {
            "precision": 0.70675,
            "recall": 0.69942,
            "fmeasure": 0.68935
        },
        "rougeLsum": {
            "precision": 0.70675,
            "recall": 0.69942,
            "fmeasure": 0.68935
        },
        "bleu": 52.34509,
        "local_recall": {
            "1": 0.24541101356743814,
            "2": 0.5511727078891258,
            "3": 0.7669687442204549
        },
        "bertscore": {
            "precision": 0.93113,
            "recall": 0.92832,
            "f1": 0.9281
        },
        "nubia": {
            "semantic_relation": 4.07599,
            "contradiction": 10.84738,
            "irrelevancy": 31.14502,
            "logical_agreement": 58.0076,
            "grammar_ref": 5.09815,
            "grammar_hyp": 4.97196,
            "nubia_score": 0.71155
        },
        "meteor": 0.4142864535087701,
        "bleurt": 0.33758
    },
    "totto_test_contrast_challenge_table_size-table_size_48": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 114,
        "msttr-100": 0.72389,
        "msttr-100_nopunct": 0.76375,
        "total_length": 1813,
        "mean_pred_length": 15.903508771929825,
        "std_pred_length": 5.126418157653162,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.46552675124103693,
        "vocab_size-1": 844,
        "unique-1": 654,
        "entropy-1": 8.266938381544046,
        "distinct-2": 0.872277810476751,
        "vocab_size-2": 1482,
        "unique-2": 1359,
        "entropy-2": 10.378532076614938,
        "cond_entropy-2": 1.8632920668411386,
        "distinct-3": 0.9678233438485805,
        "vocab_size-3": 1534,
        "unique-3": 1490,
        "entropy-3": 10.562270634483548,
        "cond_entropy-3": 0.19011167389141462,
        "total_length-nopunct": 1600,
        "mean_pred_length-nopunct": 14.035087719298245,
        "std_pred_length-nopunct": 4.853882194772178,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5225,
        "vocab_size-1-nopunct": 836,
        "unique-1-nopunct": 653,
        "entropy-1-nopunct": 8.529303338064183,
        "distinct-2-nopunct": 0.8842530282637954,
        "vocab_size-2-nopunct": 1314,
        "unique-2-nopunct": 1221,
        "entropy-2-nopunct": 10.20703094940011,
        "cond_entropy-2-nopunct": 1.7880458563871051,
        "distinct-3-nopunct": 0.9759475218658892,
        "vocab_size-3-nopunct": 1339,
        "unique-3-nopunct": 1309,
        "entropy-3-nopunct": 10.372309181255568,
        "cond_entropy-3-nopunct": 0.18323841365556984,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.495855090913935,
        "rouge1": {
            "precision": 0.75097,
            "recall": 0.71,
            "fmeasure": 0.7193
        },
        "rouge2": {
            "precision": 0.50101,
            "recall": 0.47349,
            "fmeasure": 0.47918
        },
        "rougeL": {
            "precision": 0.6344,
            "recall": 0.6006,
            "fmeasure": 0.60808
        },
        "rougeLsum": {
            "precision": 0.6344,
            "recall": 0.6006,
            "fmeasure": 0.60808
        },
        "bleu": 41.48301,
        "local_recall": {
            "1": 0.1865671641791045,
            "2": 0.467005076142132,
            "3": 0.7673397717295873
        },
        "bertscore": {
            "precision": 0.92586,
            "recall": 0.92312,
            "f1": 0.92347
        },
        "nubia": {
            "semantic_relation": 4.21025,
            "contradiction": 6.88213,
            "irrelevancy": 35.19805,
            "logical_agreement": 57.91982,
            "grammar_ref": 4.6714,
            "grammar_hyp": 4.67101,
            "nubia_score": 0.73038
        },
        "meteor": 0.38156760471652335,
        "bleurt": 0.20857
    },
    "totto_test_contrast_challenge_table_size-table_size_100": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 48,
        "msttr-100": 0.73286,
        "msttr-100_nopunct": 0.78,
        "total_length": 757,
        "mean_pred_length": 15.770833333333334,
        "std_pred_length": 4.9169756258858515,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.5429326287978864,
        "vocab_size-1": 411,
        "unique-1": 347,
        "entropy-1": 7.564955827407791,
        "distinct-2": 0.9097320169252469,
        "vocab_size-2": 645,
        "unique-2": 606,
        "entropy-2": 9.239002827856375,
        "cond_entropy-2": 1.4557718861583104,
        "distinct-3": 0.9773071104387292,
        "vocab_size-3": 646,
        "unique-3": 633,
        "entropy-3": 9.32083660522265,
        "cond_entropy-3": 0.09253070851680659,
        "total_length-nopunct": 668,
        "mean_pred_length-nopunct": 13.916666666666666,
        "std_pred_length-nopunct": 4.821105221373576,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6077844311377245,
        "vocab_size-1-nopunct": 406,
        "unique-1-nopunct": 346,
        "entropy-1-nopunct": 7.802678054897551,
        "distinct-2-nopunct": 0.9112903225806451,
        "vocab_size-2-nopunct": 565,
        "unique-2-nopunct": 534,
        "entropy-2-nopunct": 9.042627379515368,
        "cond_entropy-2-nopunct": 1.3366661744565653,
        "distinct-3-nopunct": 0.9842657342657343,
        "vocab_size-3-nopunct": 563,
        "unique-3-nopunct": 555,
        "entropy-3-nopunct": 9.127083071914521,
        "cond_entropy-3-nopunct": 0.10055334491034944,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.191510856961245,
        "rouge1": {
            "precision": 0.78217,
            "recall": 0.74539,
            "fmeasure": 0.75596
        },
        "rouge2": {
            "precision": 0.52729,
            "recall": 0.50694,
            "fmeasure": 0.51189
        },
        "rougeL": {
            "precision": 0.64336,
            "recall": 0.61498,
            "fmeasure": 0.62281
        },
        "rougeLsum": {
            "precision": 0.64336,
            "recall": 0.61498,
            "fmeasure": 0.62281
        },
        "bleu": 46.09807,
        "local_recall": {
            "1": 0.15436241610738255,
            "2": 0.4375,
            "3": 0.7841584158415842
        },
        "bertscore": {
            "precision": 0.93745,
            "recall": 0.93425,
            "f1": 0.93468
        },
        "nubia": {
            "semantic_relation": 4.24589,
            "contradiction": 6.7935,
            "irrelevancy": 22.61446,
            "logical_agreement": 70.59204,
            "grammar_ref": 4.77611,
            "grammar_hyp": 4.79567,
            "nubia_score": 0.74001
        },
        "meteor": 0.3984373110619974,
        "bleurt": 0.28909
    },
    "totto_test_contrast_challenge_table_size-table_size_24": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 169,
        "msttr-100": 0.72407,
        "msttr-100_nopunct": 0.75792,
        "total_length": 2782,
        "mean_pred_length": 16.46153846153846,
        "std_pred_length": 5.436018382786078,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.40618260244428467,
        "vocab_size-1": 1130,
        "unique-1": 877,
        "entropy-1": 8.416710814248134,
        "distinct-2": 0.7853042479908151,
        "vocab_size-2": 2052,
        "unique-2": 1840,
        "entropy-2": 10.66839246412528,
        "cond_entropy-2": 2.0168299433977177,
        "distinct-3": 0.9009819967266776,
        "vocab_size-3": 2202,
        "unique-3": 2080,
        "entropy-3": 10.982522257836255,
        "cond_entropy-3": 0.31928333311593526,
        "total_length-nopunct": 2426,
        "mean_pred_length-nopunct": 14.355029585798816,
        "std_pred_length-nopunct": 4.955839437043123,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.46125309150865623,
        "vocab_size-1-nopunct": 1119,
        "unique-1-nopunct": 875,
        "entropy-1-nopunct": 8.695298981054407,
        "distinct-2-nopunct": 0.8059370846256092,
        "vocab_size-2-nopunct": 1819,
        "unique-2-nopunct": 1658,
        "entropy-2-nopunct": 10.50158570912156,
        "cond_entropy-2-nopunct": 1.9125406535868308,
        "distinct-3-nopunct": 0.9085249042145593,
        "vocab_size-3-nopunct": 1897,
        "unique-3-nopunct": 1800,
        "entropy-3-nopunct": 10.774712765647351,
        "cond_entropy-3-nopunct": 0.3096175146548134,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.038973095127284,
        "rouge1": {
            "precision": 0.77142,
            "recall": 0.74316,
            "fmeasure": 0.74761
        },
        "rouge2": {
            "precision": 0.56275,
            "recall": 0.5394,
            "fmeasure": 0.54379
        },
        "rougeL": {
            "precision": 0.67258,
            "recall": 0.64876,
            "fmeasure": 0.65214
        },
        "rougeLsum": {
            "precision": 0.67258,
            "recall": 0.64876,
            "fmeasure": 0.65214
        },
        "bleu": 48.10726,
        "local_recall": {
            "1": 0.21548117154811716,
            "2": 0.4584269662921348,
            "3": 0.7713675213675214
        },
        "bertscore": {
            "precision": 0.93194,
            "recall": 0.92753,
            "f1": 0.92813
        },
        "nubia": {
            "semantic_relation": 4.20593,
            "contradiction": 6.43038,
            "irrelevancy": 28.86835,
            "logical_agreement": 64.70128,
            "grammar_ref": 4.66226,
            "grammar_hyp": 4.66288,
            "nubia_score": 0.74128
        },
        "meteor": 0.39788318057725464,
        "bleurt": 0.29902
    },
    "totto_test_contrast_challenge_table_size-table_size_72": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 76,
        "msttr-100": 0.74417,
        "msttr-100_nopunct": 0.799,
        "total_length": 1201,
        "mean_pred_length": 15.802631578947368,
        "std_pred_length": 5.38765581492131,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.5270607826810991,
        "vocab_size-1": 633,
        "unique-1": 524,
        "entropy-1": 8.07995969588513,
        "distinct-2": 0.9075555555555556,
        "vocab_size-2": 1021,
        "unique-2": 965,
        "entropy-2": 9.889481000016444,
        "cond_entropy-2": 1.5901162246144944,
        "distinct-3": 0.9799809342230696,
        "vocab_size-3": 1028,
        "unique-3": 1012,
        "entropy-3": 9.988788798128608,
        "cond_entropy-3": 0.09773374831821664,
        "total_length-nopunct": 1040,
        "mean_pred_length-nopunct": 13.68421052631579,
        "std_pred_length-nopunct": 4.782673020271882,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6019230769230769,
        "vocab_size-1-nopunct": 626,
        "unique-1-nopunct": 523,
        "entropy-1-nopunct": 8.3670368713502,
        "distinct-2-nopunct": 0.9190871369294605,
        "vocab_size-2-nopunct": 886,
        "unique-2-nopunct": 843,
        "entropy-2-nopunct": 9.694146746643302,
        "cond_entropy-2-nopunct": 1.4234398414338036,
        "distinct-3-nopunct": 0.9864864864864865,
        "vocab_size-3-nopunct": 876,
        "unique-3-nopunct": 865,
        "entropy-3-nopunct": 9.766538740784574,
        "cond_entropy-3-nopunct": 0.09111320676348007,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.969295769340692,
        "rouge1": {
            "precision": 0.72628,
            "recall": 0.69921,
            "fmeasure": 0.69701
        },
        "rouge2": {
            "precision": 0.47357,
            "recall": 0.45618,
            "fmeasure": 0.45353
        },
        "rougeL": {
            "precision": 0.62807,
            "recall": 0.60925,
            "fmeasure": 0.60521
        },
        "rougeLsum": {
            "precision": 0.62807,
            "recall": 0.60925,
            "fmeasure": 0.60521
        },
        "bleu": 42.37746,
        "local_recall": {
            "1": 0.18729096989966554,
            "2": 0.45934959349593496,
            "3": 0.7534626038781164
        },
        "bertscore": {
            "precision": 0.92155,
            "recall": 0.92038,
            "f1": 0.91886
        },
        "nubia": {
            "semantic_relation": 4.07318,
            "contradiction": 7.81544,
            "irrelevancy": 36.50067,
            "logical_agreement": 55.68389,
            "grammar_ref": 4.73156,
            "grammar_hyp": 4.739,
            "nubia_score": 0.68716
        },
        "meteor": 0.3777517926709747,
        "bleurt": 0.19605
    },
    "totto_test_contrast_challenge_table_size-table_size_73": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.070656113151927,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.2673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.85,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.984183719779189,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.28151981340693205,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.507243626342639,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.84211,
            "fmeasure": 0.82051
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.38889,
            "fmeasure": 0.37838
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.57895,
            "fmeasure": 0.5641
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.57895,
            "fmeasure": 0.5641
        },
        "bleu": 16.96555,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7647058823529411
        },
        "bertscore": {
            "precision": 0.9359,
            "recall": 0.92323,
            "f1": 0.92867
        },
        "nubia": {
            "semantic_relation": 4.64379,
            "contradiction": 0.55831,
            "irrelevancy": 18.56129,
            "logical_agreement": 80.88041,
            "grammar_ref": 4.70075,
            "grammar_hyp": 4.86414,
            "nubia_score": 0.79794
        },
        "meteor": 0.3915403836689872,
        "bleurt": 0.35425
    },
    "totto_test_contrast_challenge_table_size-table_size_121": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 1.6583123951777,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.7592592592592593,
        "vocab_size-1": 41,
        "unique-1": 33,
        "entropy-1": 5.185352548419701,
        "distinct-2": 1.0,
        "vocab_size-2": 50,
        "unique-2": 50,
        "entropy-2": 5.643856189774728,
        "cond_entropy-2": 0.34406643765452577,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.6583123951777,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8043478260869565,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.0723687494882395,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.36291945486849647,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.14438990933517482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.386189965601749,
        "rouge1": {
            "precision": 0.68091,
            "recall": 0.69168,
            "fmeasure": 0.67163
        },
        "rouge2": {
            "precision": 0.30128,
            "recall": 0.3446,
            "fmeasure": 0.31651
        },
        "rougeL": {
            "precision": 0.52137,
            "recall": 0.57365,
            "fmeasure": 0.53911
        },
        "rougeLsum": {
            "precision": 0.52137,
            "recall": 0.57365,
            "fmeasure": 0.53911
        },
        "bleu": 22.54385,
        "local_recall": {
            "1": 0.125,
            "2": 0.14285714285714285,
            "3": 0.6486486486486487
        },
        "bertscore": {
            "precision": 0.89394,
            "recall": 0.89425,
            "f1": 0.88727
        },
        "nubia": {
            "semantic_relation": 3.45135,
            "contradiction": 22.74628,
            "irrelevancy": 37.24787,
            "logical_agreement": 40.00585,
            "grammar_ref": 5.13429,
            "grammar_hyp": 4.33212,
            "nubia_score": 0.58022
        },
        "meteor": 0.315042290624294,
        "bleurt": 0.18331
    },
    "web_nlg_ru_test_contrast_challenge_args-both_seen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 1075,
        "msttr-100": 0.35336,
        "msttr-100_nopunct": 0.57629,
        "total_length": 13711,
        "mean_pred_length": 12.754418604651162,
        "std_pred_length": 7.9331606951748945,
        "median_pred_length": 12.0,
        "min_pred_length": 0,
        "max_pred_length": 60,
        "distinct-1": 0.12406097294143388,
        "vocab_size-1": 1701,
        "unique-1": 826,
        "entropy-1": 6.513880997821444,
        "distinct-2": 0.2681016063939226,
        "vocab_size-2": 3388,
        "unique-2": 1654,
        "entropy-2": 10.501316917824118,
        "cond_entropy-2": 4.201829683493275,
        "distinct-3": 0.4129796059453854,
        "vocab_size-3": 4779,
        "unique-3": 2839,
        "entropy-3": 11.374520144162643,
        "cond_entropy-3": 0.9787258969737095,
        "total_length-nopunct": 7082,
        "mean_pred_length-nopunct": 6.587906976744186,
        "std_pred_length-nopunct": 4.334442137404705,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.2377859361762214,
        "vocab_size-1-nopunct": 1684,
        "unique-1-nopunct": 821,
        "entropy-1-nopunct": 9.320118348601763,
        "distinct-2-nopunct": 0.540432612312812,
        "vocab_size-2-nopunct": 3248,
        "unique-2-nopunct": 2134,
        "entropy-2-nopunct": 11.177925349201088,
        "cond_entropy-2-nopunct": 2.034007411430095,
        "distinct-3-nopunct": 0.6693740095087163,
        "vocab_size-3-nopunct": 3379,
        "unique-3-nopunct": 2516,
        "entropy-3-nopunct": 11.412998517384011,
        "cond_entropy-3-nopunct": 0.34936314640566146,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.40775666420989615,
        "rouge1": {
            "precision": 0.06327,
            "recall": 0.19193,
            "fmeasure": 0.08387
        },
        "rouge2": {
            "precision": 0.02133,
            "recall": 0.05885,
            "fmeasure": 0.02634
        },
        "rougeL": {
            "precision": 0.06096,
            "recall": 0.18559,
            "fmeasure": 0.08069
        },
        "rougeLsum": {
            "precision": 0.06096,
            "recall": 0.18559,
            "fmeasure": 0.08069
        },
        "bleu": 0.41021,
        "local_recall": {
            "1": 0.005072831364591637,
            "2": 0.011756473058082575,
            "3": 0.01776165011459129,
            "4": 0.1038961038961039,
            "5": 0.02702702702702703,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.59999,
            "recall": 0.52717,
            "f1": 0.55979
        },
        "nubia": {
            "semantic_relation": 2.32077,
            "contradiction": 34.21666,
            "irrelevancy": 33.83475,
            "logical_agreement": 31.94859,
            "grammar_ref": 2.64396,
            "grammar_hyp": 4.97191,
            "nubia_score": 0.24077
        },
        "meteor": 0.020436150481380908,
        "bleurt": -1.29869
    },
    "totto_test_contrast_challenge_table_size-table_size_49": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.745,
        "total_length": 314,
        "mean_pred_length": 17.444444444444443,
        "std_pred_length": 5.29383522203182,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.589171974522293,
        "vocab_size-1": 185,
        "unique-1": 150,
        "entropy-1": 6.871611428481591,
        "distinct-2": 0.9054054054054054,
        "vocab_size-2": 268,
        "unique-2": 250,
        "entropy-2": 7.9885612102733194,
        "cond_entropy-2": 0.9974030512761783,
        "distinct-3": 0.9784172661870504,
        "vocab_size-3": 272,
        "unique-3": 267,
        "entropy-3": 8.07306018242791,
        "cond_entropy-3": 0.08800997501934449,
        "total_length-nopunct": 283,
        "mean_pred_length-nopunct": 15.722222222222221,
        "std_pred_length-nopunct": 4.997839039197681,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6360424028268551,
        "vocab_size-1-nopunct": 180,
        "unique-1-nopunct": 149,
        "entropy-1-nopunct": 6.903261947409857,
        "distinct-2-nopunct": 0.8981132075471698,
        "vocab_size-2-nopunct": 238,
        "unique-2-nopunct": 221,
        "entropy-2-nopunct": 7.810663349506162,
        "cond_entropy-2-nopunct": 0.9684399240440816,
        "distinct-3-nopunct": 0.9757085020242915,
        "vocab_size-3-nopunct": 241,
        "unique-3-nopunct": 236,
        "entropy-3-nopunct": 7.896728010928176,
        "cond_entropy-3-nopunct": 0.09539799583083948,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.735000779663388,
        "rouge1": {
            "precision": 0.6829,
            "recall": 0.67003,
            "fmeasure": 0.66504
        },
        "rouge2": {
            "precision": 0.43984,
            "recall": 0.4373,
            "fmeasure": 0.43034
        },
        "rougeL": {
            "precision": 0.55909,
            "recall": 0.55058,
            "fmeasure": 0.54477
        },
        "rougeLsum": {
            "precision": 0.55909,
            "recall": 0.55058,
            "fmeasure": 0.54477
        },
        "bleu": 33.51831,
        "local_recall": {
            "1": 0.22330097087378642,
            "2": 0.3409090909090909,
            "3": 0.7448979591836735
        },
        "bertscore": {
            "precision": 0.90417,
            "recall": 0.90698,
            "f1": 0.90316
        },
        "nubia": {
            "semantic_relation": 3.8807,
            "contradiction": 5.3159,
            "irrelevancy": 55.12227,
            "logical_agreement": 39.56184,
            "grammar_ref": 4.5439,
            "grammar_hyp": 4.57645,
            "nubia_score": 0.63421
        },
        "meteor": 0.35689333135581436,
        "bleurt": 0.0439
    },
    "totto_test_contrast_challenge_table_size-table_size_123": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.716990566028302,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 55,
        "unique-1": 45,
        "entropy-1": 5.639787838280821,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 64,
        "unique-2": 62,
        "entropy-2": 5.983788058752401,
        "cond_entropy-2": 0.25245447372394747,
        "distinct-3": 1.0,
        "vocab_size-3": 62,
        "unique-3": 62,
        "entropy-3": 5.954196310386873,
        "cond_entropy-3": -0.025681679939320082,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.153311931459037,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8225806451612904,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.562830786088641,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 56,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.789015477886191,
        "cond_entropy-2-nopunct": 0.2531754176112214,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 54,
        "entropy-3-nopunct": 5.7548875021634665,
        "cond_entropy-3-nopunct": -0.029019418890029305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.307840252802037,
        "rouge1": {
            "precision": 0.79033,
            "recall": 0.86763,
            "fmeasure": 0.82353
        },
        "rouge2": {
            "precision": 0.63829,
            "recall": 0.69405,
            "fmeasure": 0.6605
        },
        "rougeL": {
            "precision": 0.7134,
            "recall": 0.77006,
            "fmeasure": 0.73829
        },
        "rougeLsum": {
            "precision": 0.7134,
            "recall": 0.77006,
            "fmeasure": 0.73829
        },
        "bleu": 54.60608,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.5,
            "3": 0.8367346938775511
        },
        "bertscore": {
            "precision": 0.95139,
            "recall": 0.94525,
            "f1": 0.94744
        },
        "nubia": {
            "semantic_relation": 4.17274,
            "contradiction": 9.16126,
            "irrelevancy": 31.63936,
            "logical_agreement": 59.19938,
            "grammar_ref": 5.56433,
            "grammar_hyp": 4.73535,
            "nubia_score": 0.81422
        },
        "meteor": 0.4294656590864363,
        "bleurt": 0.47273
    },
    "web_nlg_ru_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 3.25,
        "std_pred_length": 1.479019945774904,
        "median_pred_length": 3.5,
        "min_pred_length": 1,
        "max_pred_length": 5,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.085055102756477,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.1361519499678871,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.5849625007211562,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 1.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 1.5,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 2,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 2,
        "unique-2-nopunct": 2,
        "entropy-2-nopunct": 1.0,
        "cond_entropy-2-nopunct": -1.584962500721156,
        "distinct-3-nopunct": 0,
        "vocab_size-3-nopunct": 0,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 0,
        "cond_entropy-3-nopunct": 0,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.0,
        "rouge1": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.125,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "rougeLsum": {
            "precision": 0.16667,
            "recall": 0.16667,
            "fmeasure": 0.16667
        },
        "bleu": 2.12154,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.0
        },
        "bertscore": {
            "precision": 0.59568,
            "recall": 0.49995,
            "f1": 0.54294
        },
        "nubia": {
            "semantic_relation": 1.6216,
            "contradiction": 58.56897,
            "irrelevancy": 29.98165,
            "logical_agreement": 11.44938,
            "grammar_ref": 3.0388,
            "grammar_hyp": 8.25598,
            "nubia_score": 0.05885
        },
        "meteor": 0.02419354838709678,
        "bleurt": -1.43312
    },
    "web_nlg_ru_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.37,
        "msttr-100_nopunct": NaN,
        "total_length": 148,
        "mean_pred_length": 7.7894736842105265,
        "std_pred_length": 7.578216339013186,
        "median_pred_length": 5.0,
        "min_pred_length": 1,
        "max_pred_length": 30,
        "distinct-1": 0.3108108108108108,
        "vocab_size-1": 46,
        "unique-1": 25,
        "entropy-1": 4.383312288745327,
        "distinct-2": 0.5891472868217055,
        "vocab_size-2": 76,
        "unique-2": 47,
        "entropy-2": 5.9905702560221,
        "cond_entropy-2": 1.7296845799146991,
        "distinct-3": 0.7053571428571429,
        "vocab_size-3": 79,
        "unique-3": 57,
        "entropy-3": 6.131919739095595,
        "cond_entropy-3": 0.1689620094657214,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 3.9473684210526314,
        "std_pred_length-nopunct": 3.6630973981695396,
        "median_pred_length-nopunct": 3.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.5466666666666666,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 5.046882651641293,
        "distinct-2-nopunct": 0.7894736842105263,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.372106461419293,
        "cond_entropy-2-nopunct": 0.34981280664427583,
        "distinct-3-nopunct": 0.8863636363636364,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.232158891364569,
        "cond_entropy-3-nopunct": -0.0492615203799354,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.35911357966992447,
        "rouge1": {
            "precision": 0.09744,
            "recall": 0.15501,
            "fmeasure": 0.10882
        },
        "rouge2": {
            "precision": 0.02807,
            "recall": 0.04825,
            "fmeasure": 0.03369
        },
        "rougeL": {
            "precision": 0.09339,
            "recall": 0.14624,
            "fmeasure": 0.10328
        },
        "rougeLsum": {
            "precision": 0.09339,
            "recall": 0.14624,
            "fmeasure": 0.10328
        },
        "bleu": 0.31119,
        "local_recall": {
            "1": 0.0,
            "2": 0.03125,
            "3": 0.07608695652173914
        },
        "bertscore": {
            "precision": 0.62959,
            "recall": 0.52508,
            "f1": 0.57092
        },
        "nubia": {
            "semantic_relation": 1.7494,
            "contradiction": 38.73091,
            "irrelevancy": 35.9477,
            "logical_agreement": 25.32139,
            "grammar_ref": 2.97301,
            "grammar_hyp": 6.42859,
            "nubia_score": 0.14398
        },
        "meteor": 0.040902097846004876,
        "bleurt": -1.37714
    },
    "totto_test_contrast_challenge_table_size-table_size_102": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75667,
        "total_length": 407,
        "mean_pred_length": 16.958333333333332,
        "std_pred_length": 5.19197430870206,
        "median_pred_length": 17.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.5773955773955773,
        "vocab_size-1": 235,
        "unique-1": 199,
        "entropy-1": 6.992761839510644,
        "distinct-2": 0.9295039164490861,
        "vocab_size-2": 356,
        "unique-2": 340,
        "entropy-2": 8.40712477392738,
        "cond_entropy-2": 1.2791238510634422,
        "distinct-3": 0.9860724233983287,
        "vocab_size-3": 354,
        "unique-3": 349,
        "entropy-3": 8.459984880619722,
        "cond_entropy-3": 0.0644974866141305,
        "total_length-nopunct": 348,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.406434688800762,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6551724137931034,
        "vocab_size-1-nopunct": 228,
        "unique-1-nopunct": 197,
        "entropy-1-nopunct": 7.189600184366591,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 300,
        "unique-2-nopunct": 287,
        "entropy-2-nopunct": 8.152593723677626,
        "cond_entropy-2-nopunct": 1.0213587074411328,
        "distinct-3-nopunct": 0.9866666666666667,
        "vocab_size-3-nopunct": 296,
        "unique-3-nopunct": 292,
        "entropy-3-nopunct": 8.202152023829267,
        "cond_entropy-3-nopunct": 0.06453880248811326,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.443099978305464,
        "rouge1": {
            "precision": 0.74572,
            "recall": 0.71995,
            "fmeasure": 0.72002
        },
        "rouge2": {
            "precision": 0.47667,
            "recall": 0.45938,
            "fmeasure": 0.45903
        },
        "rougeL": {
            "precision": 0.61743,
            "recall": 0.59585,
            "fmeasure": 0.59633
        },
        "rougeLsum": {
            "precision": 0.61743,
            "recall": 0.59585,
            "fmeasure": 0.59633
        },
        "bleu": 44.0952,
        "local_recall": {
            "1": 0.125,
            "2": 0.3763440860215054,
            "3": 0.8395061728395061
        },
        "bertscore": {
            "precision": 0.92517,
            "recall": 0.91865,
            "f1": 0.91919
        },
        "nubia": {
            "semantic_relation": 4.03687,
            "contradiction": 8.4978,
            "irrelevancy": 32.64274,
            "logical_agreement": 58.85945,
            "grammar_ref": 4.72162,
            "grammar_hyp": 4.44007,
            "nubia_score": 0.7186
        },
        "meteor": 0.40333055263021045,
        "bleurt": 0.21106
    },
    "web_nlg_ru_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 67,
        "mean_pred_length": 16.75,
        "std_pred_length": 6.869315832017043,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 22,
        "distinct-1": 0.40298507462686567,
        "vocab_size-1": 27,
        "unique-1": 18,
        "entropy-1": 3.832756607691338,
        "distinct-2": 0.7301587301587301,
        "vocab_size-2": 46,
        "unique-2": 36,
        "entropy-2": 5.338158296412768,
        "cond_entropy-2": 1.5764159539980693,
        "distinct-3": 0.8135593220338984,
        "vocab_size-3": 48,
        "unique-3": 41,
        "entropy-3": 5.450273981491891,
        "cond_entropy-3": 0.1285821936829808,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 7.75,
        "std_pred_length-nopunct": 2.7726341266023544,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.7096774193548387,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.23275992404493,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.49623065384619014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.1878472852368907,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.34211532053153443,
        "rouge1": {
            "precision": 0.15595,
            "recall": 0.34091,
            "fmeasure": 0.2085
        },
        "rouge2": {
            "precision": 0.01923,
            "recall": 0.0625,
            "fmeasure": 0.02941
        },
        "rougeL": {
            "precision": 0.1381,
            "recall": 0.29091,
            "fmeasure": 0.18219
        },
        "rougeLsum": {
            "precision": 0.1381,
            "recall": 0.29091,
            "fmeasure": 0.18219
        },
        "bleu": 0.70156,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.038461538461538464
        },
        "bertscore": {
            "precision": 0.64425,
            "recall": 0.5638,
            "f1": 0.60117
        },
        "nubia": {
            "semantic_relation": 2.19978,
            "contradiction": 31.79716,
            "irrelevancy": 46.20901,
            "logical_agreement": 21.99382,
            "grammar_ref": 2.93748,
            "grammar_hyp": 4.92425,
            "nubia_score": 0.19608
        },
        "meteor": 0.03145192598154195,
        "bleurt": -1.19813
    },
    "totto_test_contrast_challenge_table_size-table_size_104": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.78,
        "total_length": 474,
        "mean_pred_length": 16.344827586206897,
        "std_pred_length": 5.3128073108289575,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.5907172995780591,
        "vocab_size-1": 280,
        "unique-1": 234,
        "entropy-1": 7.318076575754257,
        "distinct-2": 0.9325842696629213,
        "vocab_size-2": 415,
        "unique-2": 395,
        "entropy-2": 8.633572649429794,
        "cond_entropy-2": 1.1498399023842065,
        "distinct-3": 0.9903846153846154,
        "vocab_size-3": 412,
        "unique-3": 408,
        "entropy-3": 8.681208948910301,
        "cond_entropy-3": 0.05426749519275038,
        "total_length-nopunct": 412,
        "mean_pred_length-nopunct": 14.206896551724139,
        "std_pred_length-nopunct": 4.744356432100743,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6674757281553398,
        "vocab_size-1-nopunct": 275,
        "unique-1-nopunct": 233,
        "entropy-1-nopunct": 7.494779328622422,
        "distinct-2-nopunct": 0.9425587467362925,
        "vocab_size-2-nopunct": 361,
        "unique-2-nopunct": 348,
        "entropy-2-nopunct": 8.434295457887082,
        "cond_entropy-2-nopunct": 0.9935132727223118,
        "distinct-3-nopunct": 0.9971751412429378,
        "vocab_size-3-nopunct": 353,
        "unique-3-nopunct": 352,
        "entropy-3-nopunct": 8.461955832568846,
        "cond_entropy-3-nopunct": 0.03074038483896703,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.363556951567895,
        "rouge1": {
            "precision": 0.75534,
            "recall": 0.7285,
            "fmeasure": 0.7291
        },
        "rouge2": {
            "precision": 0.52995,
            "recall": 0.50472,
            "fmeasure": 0.50884
        },
        "rougeL": {
            "precision": 0.6667,
            "recall": 0.64116,
            "fmeasure": 0.64152
        },
        "rougeLsum": {
            "precision": 0.6667,
            "recall": 0.64116,
            "fmeasure": 0.64152
        },
        "bleu": 43.22064,
        "local_recall": {
            "1": 0.20388349514563106,
            "2": 0.46511627906976744,
            "3": 0.7516556291390728
        },
        "bertscore": {
            "precision": 0.92919,
            "recall": 0.93008,
            "f1": 0.92798
        },
        "nubia": {
            "semantic_relation": 4.23786,
            "contradiction": 6.63418,
            "irrelevancy": 28.67219,
            "logical_agreement": 64.69363,
            "grammar_ref": 4.69384,
            "grammar_hyp": 4.51308,
            "nubia_score": 0.73637
        },
        "meteor": 0.3853263389067228,
        "bleurt": 0.30223
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 267,
        "msttr-100": 0.4925,
        "msttr-100_nopunct": 0.51714,
        "total_length": 2471,
        "mean_pred_length": 9.254681647940075,
        "std_pred_length": 3.2686695961223293,
        "median_pred_length": 8.0,
        "min_pred_length": 4,
        "max_pred_length": 20,
        "distinct-1": 0.13193039255362202,
        "vocab_size-1": 326,
        "unique-1": 157,
        "entropy-1": 6.276309746924937,
        "distinct-2": 0.31715063520871145,
        "vocab_size-2": 699,
        "unique-2": 430,
        "entropy-2": 8.15603795211512,
        "cond_entropy-2": 1.6251212036599165,
        "distinct-3": 0.4279814145585958,
        "vocab_size-3": 829,
        "unique-3": 574,
        "entropy-3": 8.793672534419414,
        "cond_entropy-3": 0.9080598940843009,
        "total_length-nopunct": 2161,
        "mean_pred_length-nopunct": 8.093632958801498,
        "std_pred_length-nopunct": 2.791546345015053,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.14946783896344285,
        "vocab_size-1-nopunct": 323,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 6.432203983348163,
        "distinct-2-nopunct": 0.28299894403379094,
        "vocab_size-2-nopunct": 536,
        "unique-2-nopunct": 313,
        "entropy-2-nopunct": 7.726824742159523,
        "cond_entropy-2-nopunct": 1.7318071495602305,
        "distinct-3-nopunct": 0.3945912722802704,
        "vocab_size-3-nopunct": 642,
        "unique-3-nopunct": 423,
        "entropy-3-nopunct": 8.406607923847963,
        "cond_entropy-3-nopunct": 1.036681986434167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 3.9075446083433487,
        "rouge1": {
            "precision": 0.52518,
            "recall": 0.55739,
            "fmeasure": 0.5271
        },
        "rouge2": {
            "precision": 0.29127,
            "recall": 0.3079,
            "fmeasure": 0.2911
        },
        "rougeL": {
            "precision": 0.49145,
            "recall": 0.51603,
            "fmeasure": 0.49137
        },
        "rougeLsum": {
            "precision": 0.49145,
            "recall": 0.51603,
            "fmeasure": 0.49137
        },
        "bleu": 16.30951,
        "local_recall": {
            "1": 0.5144422310756972
        },
        "bertscore": {
            "precision": 0.89776,
            "recall": 0.89848,
            "f1": 0.89784
        },
        "nubia": {
            "semantic_relation": 3.46887,
            "contradiction": 21.15344,
            "irrelevancy": 30.98704,
            "logical_agreement": 47.85952,
            "grammar_ref": 7.44295,
            "grammar_hyp": 7.45678,
            "nubia_score": 0.48664
        },
        "meteor": 0.2575409619237857,
        "bleurt": -0.10456
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 297,
        "msttr-100": 0.61794,
        "msttr-100_nopunct": 0.65931,
        "total_length": 3425,
        "mean_pred_length": 11.531986531986531,
        "std_pred_length": 3.33936128086321,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 21,
        "distinct-1": 0.12291970802919708,
        "vocab_size-1": 421,
        "unique-1": 174,
        "entropy-1": 6.955666491672649,
        "distinct-2": 0.3289641943734015,
        "vocab_size-2": 1029,
        "unique-2": 562,
        "entropy-2": 8.99738152720002,
        "cond_entropy-2": 1.722894352448519,
        "distinct-3": 0.48922642175909575,
        "vocab_size-3": 1385,
        "unique-3": 921,
        "entropy-3": 9.61556947440878,
        "cond_entropy-3": 0.5976629262011314,
        "total_length-nopunct": 2940,
        "mean_pred_length-nopunct": 9.8989898989899,
        "std_pred_length-nopunct": 2.9410422675348595,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.14183673469387756,
        "vocab_size-1-nopunct": 417,
        "unique-1-nopunct": 174,
        "entropy-1-nopunct": 7.235622037633713,
        "distinct-2-nopunct": 0.34846765039727584,
        "vocab_size-2-nopunct": 921,
        "unique-2-nopunct": 511,
        "entropy-2-nopunct": 8.874155439739349,
        "cond_entropy-2-nopunct": 1.7269138094858527,
        "distinct-3-nopunct": 0.5106564364876386,
        "vocab_size-3-nopunct": 1198,
        "unique-3-nopunct": 815,
        "entropy-3-nopunct": 9.428522294672078,
        "cond_entropy-3-nopunct": 0.641594083449315,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 3.7281902527340125,
        "rouge1": {
            "precision": 0.52503,
            "recall": 0.53463,
            "fmeasure": 0.51581
        },
        "rouge2": {
            "precision": 0.29179,
            "recall": 0.29924,
            "fmeasure": 0.28784
        },
        "rougeL": {
            "precision": 0.46699,
            "recall": 0.47635,
            "fmeasure": 0.45972
        },
        "rougeLsum": {
            "precision": 0.46699,
            "recall": 0.47635,
            "fmeasure": 0.45972
        },
        "bleu": 17.81988,
        "local_recall": {
            "1": 0.4722524483133841
        },
        "bertscore": {
            "precision": 0.89917,
            "recall": 0.90024,
            "f1": 0.89947
        },
        "nubia": {
            "semantic_relation": 3.51316,
            "contradiction": 18.86075,
            "irrelevancy": 34.06522,
            "logical_agreement": 47.07404,
            "grammar_ref": 6.65825,
            "grammar_hyp": 6.60924,
            "nubia_score": 0.52427
        },
        "meteor": 0.23975442798294186,
        "bleurt": -0.14367
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 339,
        "msttr-100": 0.33292,
        "msttr-100_nopunct": 0.53417,
        "total_length": 2413,
        "mean_pred_length": 7.117994100294985,
        "std_pred_length": 7.85586984118354,
        "median_pred_length": 4.0,
        "min_pred_length": 0,
        "max_pred_length": 54,
        "distinct-1": 0.23331951927061748,
        "vocab_size-1": 563,
        "unique-1": 359,
        "entropy-1": 5.7660729429873285,
        "distinct-2": 0.4472289156626506,
        "vocab_size-2": 928,
        "unique-2": 614,
        "entropy-2": 8.951846664717198,
        "cond_entropy-2": 3.5260771287300066,
        "distinct-3": 0.5085812356979404,
        "vocab_size-3": 889,
        "unique-3": 614,
        "entropy-3": 9.07880295785291,
        "cond_entropy-3": 0.30441968464379543,
        "total_length-nopunct": 1286,
        "mean_pred_length-nopunct": 3.793510324483776,
        "std_pred_length-nopunct": 4.348242693465928,
        "median_pred_length-nopunct": 2.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4284603421461897,
        "vocab_size-1-nopunct": 551,
        "unique-1-nopunct": 354,
        "entropy-1-nopunct": 8.078892827552618,
        "distinct-2-nopunct": 0.5678233438485805,
        "vocab_size-2-nopunct": 540,
        "unique-2-nopunct": 391,
        "entropy-2-nopunct": 8.432554033002969,
        "cond_entropy-2-nopunct": 0.6187899024349713,
        "distinct-3-nopunct": 0.5828729281767956,
        "vocab_size-3-nopunct": 422,
        "unique-3-nopunct": 305,
        "entropy-3-nopunct": 8.221053391725434,
        "cond_entropy-3-nopunct": 0.08860335694429221,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.4476291606071272,
        "rouge1": {
            "precision": 0.08866,
            "recall": 0.18541,
            "fmeasure": 0.10236
        },
        "rouge2": {
            "precision": 0.03805,
            "recall": 0.07608,
            "fmeasure": 0.04121
        },
        "rougeL": {
            "precision": 0.08837,
            "recall": 0.18505,
            "fmeasure": 0.10204
        },
        "rougeLsum": {
            "precision": 0.08837,
            "recall": 0.18505,
            "fmeasure": 0.10204
        },
        "bleu": 0.42847,
        "local_recall": {
            "1": 0.012532411408815903,
            "2": 0.019038984587488667,
            "3": 0.01692047377326565,
            "4": 0.08333333333333333,
            "5": 0.06666666666666667,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.60195,
            "recall": 0.51824,
            "f1": 0.55484
        },
        "nubia": {
            "semantic_relation": 1.85894,
            "contradiction": 40.51698,
            "irrelevancy": 34.10263,
            "logical_agreement": 25.38039,
            "grammar_ref": 2.83259,
            "grammar_hyp": 6.45853,
            "nubia_score": 0.13364
        },
        "meteor": 0.025740164076124217,
        "bleurt": -1.35478
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 316,
        "msttr-100": 0.3122,
        "msttr-100_nopunct": 0.5085,
        "total_length": 4106,
        "mean_pred_length": 12.99367088607595,
        "std_pred_length": 6.93367934861467,
        "median_pred_length": 12.0,
        "min_pred_length": 2,
        "max_pred_length": 60,
        "distinct-1": 0.17243058938139308,
        "vocab_size-1": 708,
        "unique-1": 340,
        "entropy-1": 6.031255733121014,
        "distinct-2": 0.37889182058047494,
        "vocab_size-2": 1436,
        "unique-2": 724,
        "entropy-2": 9.732814203386672,
        "cond_entropy-2": 3.8368620285671877,
        "distinct-3": 0.5175590097869891,
        "vocab_size-3": 1798,
        "unique-3": 1124,
        "entropy-3": 10.2667131212368,
        "cond_entropy-3": 0.5944048334316341,
        "total_length-nopunct": 2046,
        "mean_pred_length-nopunct": 6.474683544303797,
        "std_pred_length-nopunct": 3.5233387630337645,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.3421309872922776,
        "vocab_size-1-nopunct": 700,
        "unique-1-nopunct": 338,
        "entropy-1-nopunct": 8.63784405809745,
        "distinct-2-nopunct": 0.6554913294797687,
        "vocab_size-2-nopunct": 1134,
        "unique-2-nopunct": 807,
        "entropy-2-nopunct": 9.886720008919653,
        "cond_entropy-2-nopunct": 1.3422514885911416,
        "distinct-3-nopunct": 0.7475386779184248,
        "vocab_size-3-nopunct": 1063,
        "unique-3-nopunct": 825,
        "entropy-3-nopunct": 9.881043335894798,
        "cond_entropy-3-nopunct": 0.060148174636795476,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.33772566023212675,
        "rouge1": {
            "precision": 0.04758,
            "recall": 0.19085,
            "fmeasure": 0.0708
        },
        "rouge2": {
            "precision": 0.01281,
            "recall": 0.05472,
            "fmeasure": 0.01885
        },
        "rougeL": {
            "precision": 0.04537,
            "recall": 0.18435,
            "fmeasure": 0.06765
        },
        "rougeLsum": {
            "precision": 0.04537,
            "recall": 0.18435,
            "fmeasure": 0.06765
        },
        "bleu": 0.32058,
        "local_recall": {
            "1": 0.0030459231490159327,
            "2": 0.008200675349734683,
            "3": 0.01267605633802817,
            "4": 0.21052631578947367,
            "5": 0.0,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.59805,
            "recall": 0.53264,
            "f1": 0.56235
        },
        "nubia": {
            "semantic_relation": 2.36447,
            "contradiction": 32.7819,
            "irrelevancy": 35.62672,
            "logical_agreement": 31.59137,
            "grammar_ref": 2.6064,
            "grammar_hyp": 4.85822,
            "nubia_score": 0.246
        },
        "meteor": 0.018655535381224893,
        "bleurt": -1.29659
    },
    "totto_test_contrast_challenge_table_size-table_size_124": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.705,
        "total_length": 254,
        "mean_pred_length": 18.142857142857142,
        "std_pred_length": 5.343315488361441,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.5551181102362205,
        "vocab_size-1": 141,
        "unique-1": 112,
        "entropy-1": 6.397987474478869,
        "distinct-2": 0.8666666666666667,
        "vocab_size-2": 208,
        "unique-2": 184,
        "entropy-2": 7.596864045789531,
        "cond_entropy-2": 1.1056726157538272,
        "distinct-3": 0.9247787610619469,
        "vocab_size-3": 209,
        "unique-3": 192,
        "entropy-3": 7.669736484539109,
        "cond_entropy-3": 0.06995372944634416,
        "total_length-nopunct": 224,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.277986629117476,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6116071428571429,
        "vocab_size-1-nopunct": 137,
        "unique-1-nopunct": 112,
        "entropy-1-nopunct": 6.414812081376905,
        "distinct-2-nopunct": 0.8714285714285714,
        "vocab_size-2-nopunct": 183,
        "unique-2-nopunct": 162,
        "entropy-2-nopunct": 7.417072317872936,
        "cond_entropy-2-nopunct": 1.0542156520617734,
        "distinct-3-nopunct": 0.9183673469387755,
        "vocab_size-3-nopunct": 180,
        "unique-3-nopunct": 164,
        "entropy-3-nopunct": 7.451444537992745,
        "cond_entropy-3-nopunct": 0.04029275479891577,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.683410855782926,
        "rouge1": {
            "precision": 0.73045,
            "recall": 0.72732,
            "fmeasure": 0.71846
        },
        "rouge2": {
            "precision": 0.51983,
            "recall": 0.51153,
            "fmeasure": 0.50896
        },
        "rougeL": {
            "precision": 0.65079,
            "recall": 0.62308,
            "fmeasure": 0.6309
        },
        "rougeLsum": {
            "precision": 0.65079,
            "recall": 0.62308,
            "fmeasure": 0.6309
        },
        "bleu": 41.99472,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.3333333333333333,
            "3": 0.7294117647058823
        },
        "bertscore": {
            "precision": 0.9324,
            "recall": 0.93633,
            "f1": 0.93281
        },
        "nubia": {
            "semantic_relation": 4.41437,
            "contradiction": 1.14787,
            "irrelevancy": 28.72264,
            "logical_agreement": 70.1295,
            "grammar_ref": 4.7817,
            "grammar_hyp": 4.74747,
            "nubia_score": 0.77022
        },
        "meteor": 0.37636971148804904,
        "bleurt": 0.32139
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 217,
        "msttr-100": 0.32719,
        "msttr-100_nopunct": 0.53125,
        "total_length": 3241,
        "mean_pred_length": 14.935483870967742,
        "std_pred_length": 6.066109213249217,
        "median_pred_length": 14.0,
        "min_pred_length": 1,
        "max_pred_length": 34,
        "distinct-1": 0.1931502622647331,
        "vocab_size-1": 626,
        "unique-1": 314,
        "entropy-1": 6.088873317433556,
        "distinct-2": 0.4037698412698413,
        "vocab_size-2": 1221,
        "unique-2": 633,
        "entropy-2": 9.634621579587414,
        "cond_entropy-2": 3.707335378211805,
        "distinct-3": 0.5455840455840456,
        "vocab_size-3": 1532,
        "unique-3": 949,
        "entropy-3": 10.168896937733605,
        "cond_entropy-3": 0.5919740542909664,
        "total_length-nopunct": 1666,
        "mean_pred_length-nopunct": 7.67741935483871,
        "std_pred_length-nopunct": 3.5348295670910574,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.37034813925570226,
        "vocab_size-1-nopunct": 617,
        "unique-1-nopunct": 312,
        "entropy-1-nopunct": 8.587950301372011,
        "distinct-2-nopunct": 0.673567977915804,
        "vocab_size-2-nopunct": 976,
        "unique-2-nopunct": 668,
        "entropy-2-nopunct": 9.734020052580732,
        "cond_entropy-2-nopunct": 1.2547308422432837,
        "distinct-3-nopunct": 0.7696674776966748,
        "vocab_size-3-nopunct": 949,
        "unique-3-nopunct": 739,
        "entropy-3-nopunct": 9.75245464160035,
        "cond_entropy-3-nopunct": 0.0690347058858393,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.33652338096591494,
        "rouge1": {
            "precision": 0.05336,
            "recall": 0.20189,
            "fmeasure": 0.077
        },
        "rouge2": {
            "precision": 0.01224,
            "recall": 0.03962,
            "fmeasure": 0.017
        },
        "rougeL": {
            "precision": 0.05019,
            "recall": 0.19197,
            "fmeasure": 0.07234
        },
        "rougeLsum": {
            "precision": 0.05019,
            "recall": 0.19197,
            "fmeasure": 0.07234
        },
        "bleu": 0.1979,
        "local_recall": {
            "1": 0.00245398773006135,
            "2": 0.00707395498392283,
            "3": 0.013939838591342627,
            "4": 0.045454545454545456
        },
        "bertscore": {
            "precision": 0.59933,
            "recall": 0.53349,
            "f1": 0.56336
        },
        "nubia": {
            "semantic_relation": 2.56114,
            "contradiction": 30.185,
            "irrelevancy": 32.67808,
            "logical_agreement": 37.13691,
            "grammar_ref": 2.56565,
            "grammar_hyp": 4.33893,
            "nubia_score": 0.2945
        },
        "meteor": 0.018160173160362995,
        "bleurt": -1.26714
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-4_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 143,
        "msttr-100": 0.3164,
        "msttr-100_nopunct": 0.4825,
        "total_length": 2505,
        "mean_pred_length": 17.517482517482517,
        "std_pred_length": 5.195281811686564,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 35,
        "distinct-1": 0.19081836327345308,
        "vocab_size-1": 478,
        "unique-1": 244,
        "entropy-1": 5.885438198284889,
        "distinct-2": 0.3831498729889924,
        "vocab_size-2": 905,
        "unique-2": 473,
        "entropy-2": 9.101729747682912,
        "cond_entropy-2": 3.364389479589706,
        "distinct-3": 0.5295178008111762,
        "vocab_size-3": 1175,
        "unique-3": 749,
        "entropy-3": 9.694687968400803,
        "cond_entropy-3": 0.6425835823502588,
        "total_length-nopunct": 1281,
        "mean_pred_length-nopunct": 8.958041958041958,
        "std_pred_length-nopunct": 3.092680566943281,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.3669008587041374,
        "vocab_size-1-nopunct": 470,
        "unique-1-nopunct": 244,
        "entropy-1-nopunct": 8.09137136553893,
        "distinct-2-nopunct": 0.6590509666080844,
        "vocab_size-2-nopunct": 750,
        "unique-2-nopunct": 529,
        "entropy-2-nopunct": 9.295694860470666,
        "cond_entropy-2-nopunct": 1.293595546164124,
        "distinct-3-nopunct": 0.7829145728643216,
        "vocab_size-3-nopunct": 779,
        "unique-3-nopunct": 634,
        "entropy-3-nopunct": 9.451312030530609,
        "cond_entropy-3-nopunct": 0.21346531029245763,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.38580499436969184,
        "rouge1": {
            "precision": 0.0574,
            "recall": 0.17482,
            "fmeasure": 0.07864
        },
        "rouge2": {
            "precision": 0.02018,
            "recall": 0.05401,
            "fmeasure": 0.0256
        },
        "rougeL": {
            "precision": 0.05456,
            "recall": 0.1677,
            "fmeasure": 0.07476
        },
        "rougeLsum": {
            "precision": 0.05456,
            "recall": 0.1677,
            "fmeasure": 0.07476
        },
        "bleu": 0.47437,
        "local_recall": {
            "1": 0.0038744672607516468,
            "2": 0.008861622358554875,
            "3": 0.017013232514177693
        },
        "bertscore": {
            "precision": 0.60343,
            "recall": 0.5298,
            "f1": 0.56322
        },
        "nubia": {
            "semantic_relation": 2.68402,
            "contradiction": 32.05743,
            "irrelevancy": 30.9072,
            "logical_agreement": 37.03536,
            "grammar_ref": 2.5384,
            "grammar_hyp": 3.75168,
            "nubia_score": 0.32366
        },
        "meteor": 0.018942173471818632,
        "bleurt": -1.24758
    },
    "totto_test_contrast_challenge_table_size-table_size_125": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 115,
        "mean_pred_length": 19.166666666666668,
        "std_pred_length": 8.47381587925744,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.6869565217391305,
        "vocab_size-1": 79,
        "unique-1": 65,
        "entropy-1": 5.964254668978174,
        "distinct-2": 0.944954128440367,
        "vocab_size-2": 103,
        "unique-2": 98,
        "entropy-2": 6.6511670082433065,
        "cond_entropy-2": 0.6168444474136967,
        "distinct-3": 0.9805825242718447,
        "vocab_size-3": 101,
        "unique-3": 99,
        "entropy-3": 6.647665575726925,
        "cond_entropy-3": 0.003315110194287181,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.619905100029122,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7849462365591398,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.951298225483764,
        "distinct-2-nopunct": 0.9770114942528736,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 83,
        "entropy-2-nopunct": 6.39696648435447,
        "cond_entropy-2-nopunct": 0.4862103682241125,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 81,
        "entropy-3-nopunct": 6.339850002884614,
        "cond_entropy-3-nopunct": -0.053710776914720704,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.285114725879495,
        "rouge1": {
            "precision": 0.85303,
            "recall": 0.7664,
            "fmeasure": 0.79982
        },
        "rouge2": {
            "precision": 0.65701,
            "recall": 0.59509,
            "fmeasure": 0.61804
        },
        "rougeL": {
            "precision": 0.78217,
            "recall": 0.70854,
            "fmeasure": 0.73607
        },
        "rougeLsum": {
            "precision": 0.78217,
            "recall": 0.70854,
            "fmeasure": 0.73607
        },
        "bleu": 47.34513,
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.4166666666666667,
            "3": 0.8148148148148148
        },
        "bertscore": {
            "precision": 0.95178,
            "recall": 0.94175,
            "f1": 0.9453
        },
        "nubia": {
            "semantic_relation": 4.46592,
            "contradiction": 2.88506,
            "irrelevancy": 23.76926,
            "logical_agreement": 73.34568,
            "grammar_ref": 5.04309,
            "grammar_hyp": 5.14774,
            "nubia_score": 0.77442
        },
        "meteor": 0.4061672401442041,
        "bleurt": 0.38597
    },
    "totto_test_contrast_challenge_table_size-table_size_50": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 55,
        "msttr-100": 0.7525,
        "msttr-100_nopunct": 0.79143,
        "total_length": 843,
        "mean_pred_length": 15.327272727272728,
        "std_pred_length": 4.820616880383465,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5432977461447213,
        "vocab_size-1": 458,
        "unique-1": 371,
        "entropy-1": 7.825334124377694,
        "distinct-2": 0.8984771573604061,
        "vocab_size-2": 708,
        "unique-2": 659,
        "entropy-2": 9.373250915334248,
        "cond_entropy-2": 1.3129920649038402,
        "distinct-3": 0.975443383356071,
        "vocab_size-3": 715,
        "unique-3": 700,
        "entropy-3": 9.465466574345959,
        "cond_entropy-3": 0.08583028622889559,
        "total_length-nopunct": 731,
        "mean_pred_length-nopunct": 13.290909090909091,
        "std_pred_length-nopunct": 4.3679524109658985,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.615595075239398,
        "vocab_size-1-nopunct": 450,
        "unique-1-nopunct": 369,
        "entropy-1-nopunct": 8.040998962570027,
        "distinct-2-nopunct": 0.9112426035502958,
        "vocab_size-2-nopunct": 616,
        "unique-2-nopunct": 582,
        "entropy-2-nopunct": 9.1776017780433,
        "cond_entropy-2-nopunct": 1.2242942401021417,
        "distinct-3-nopunct": 0.9806763285024155,
        "vocab_size-3-nopunct": 609,
        "unique-3-nopunct": 600,
        "entropy-3-nopunct": 9.236155315697896,
        "cond_entropy-3-nopunct": 0.07671822558251258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.972086207859089,
        "rouge1": {
            "precision": 0.75595,
            "recall": 0.69738,
            "fmeasure": 0.71414
        },
        "rouge2": {
            "precision": 0.53522,
            "recall": 0.49222,
            "fmeasure": 0.5044
        },
        "rougeL": {
            "precision": 0.66223,
            "recall": 0.62065,
            "fmeasure": 0.63088
        },
        "rougeLsum": {
            "precision": 0.66223,
            "recall": 0.62065,
            "fmeasure": 0.63088
        },
        "bleu": 46.90831,
        "local_recall": {
            "1": 0.25980392156862747,
            "2": 0.39344262295081966,
            "3": 0.7434944237918215
        },
        "bertscore": {
            "precision": 0.92843,
            "recall": 0.9215,
            "f1": 0.92399
        },
        "nubia": {
            "semantic_relation": 4.1475,
            "contradiction": 7.34067,
            "irrelevancy": 31.09125,
            "logical_agreement": 61.56809,
            "grammar_ref": 4.83026,
            "grammar_hyp": 4.87791,
            "nubia_score": 0.7096
        },
        "meteor": 0.388276440332285,
        "bleurt": 0.23044
    },
    "totto_test_contrast_challenge_table_size-table_size_12": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 158,
        "msttr-100": 0.7312,
        "msttr-100_nopunct": 0.78091,
        "total_length": 2566,
        "mean_pred_length": 16.240506329113924,
        "std_pred_length": 5.263235732564354,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.4193296960249415,
        "vocab_size-1": 1076,
        "unique-1": 849,
        "entropy-1": 8.427130598959396,
        "distinct-2": 0.7931893687707641,
        "vocab_size-2": 1910,
        "unique-2": 1704,
        "entropy-2": 10.617332402702194,
        "cond_entropy-2": 1.9265844755979036,
        "distinct-3": 0.9048888888888889,
        "vocab_size-3": 2036,
        "unique-3": 1933,
        "entropy-3": 10.88083762783875,
        "cond_entropy-3": 0.2706801693889979,
        "total_length-nopunct": 2216,
        "mean_pred_length-nopunct": 14.025316455696203,
        "std_pred_length-nopunct": 4.5672878791184015,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4805956678700361,
        "vocab_size-1-nopunct": 1065,
        "unique-1-nopunct": 846,
        "entropy-1-nopunct": 8.741875366909845,
        "distinct-2-nopunct": 0.8168124392614189,
        "vocab_size-2-nopunct": 1681,
        "unique-2-nopunct": 1521,
        "entropy-2-nopunct": 10.458823022099445,
        "cond_entropy-2-nopunct": 1.8307894479686373,
        "distinct-3-nopunct": 0.9110526315789473,
        "vocab_size-3-nopunct": 1731,
        "unique-3-nopunct": 1651,
        "entropy-3-nopunct": 10.653656502644871,
        "cond_entropy-3-nopunct": 0.2213841887961186,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.991978858669626,
        "rouge1": {
            "precision": 0.75057,
            "recall": 0.73047,
            "fmeasure": 0.72881
        },
        "rouge2": {
            "precision": 0.51768,
            "recall": 0.50168,
            "fmeasure": 0.50157
        },
        "rougeL": {
            "precision": 0.64675,
            "recall": 0.634,
            "fmeasure": 0.62997
        },
        "rougeLsum": {
            "precision": 0.64675,
            "recall": 0.634,
            "fmeasure": 0.62997
        },
        "bleu": 46.40299,
        "local_recall": {
            "1": 0.24558303886925795,
            "2": 0.4782608695652174,
            "3": 0.7645585472761428
        },
        "bertscore": {
            "precision": 0.92826,
            "recall": 0.92283,
            "f1": 0.9239
        },
        "nubia": {
            "semantic_relation": 4.15534,
            "contradiction": 6.78488,
            "irrelevancy": 32.89172,
            "logical_agreement": 60.3234,
            "grammar_ref": 4.68014,
            "grammar_hyp": 4.54184,
            "nubia_score": 0.73672
        },
        "meteor": 0.3961615708808695,
        "bleurt": 0.26238
    },
    "totto_test_contrast_challenge_table_size-table_size_146": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 9,
        "unique-1": 7,
        "entropy-1": 3.0957952550009344,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.262496476250065,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.9219280948873623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.18133023988828356,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.064950502999094,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.5,
            "fmeasure": 0.5
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.27407,
            "fmeasure": 0.2846
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.43636,
            "fmeasure": 0.45079
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.43636,
            "fmeasure": 0.45079
        },
        "bleu": 25.96536,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.86806,
            "recall": 0.78973,
            "f1": 0.82705
        },
        "nubia": {
            "semantic_relation": 2.85029,
            "contradiction": 0.1994,
            "irrelevancy": 42.05017,
            "logical_agreement": 57.75043,
            "grammar_ref": 5.00001,
            "grammar_hyp": 4.02683,
            "nubia_score": 0.4329
        },
        "meteor": 0.22743634744500976,
        "bleurt": -0.28401
    },
    "totto_test_contrast_challenge_table_size-table_size_105": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 36,
        "msttr-100": 0.718,
        "msttr-100_nopunct": 0.7675,
        "total_length": 573,
        "mean_pred_length": 15.916666666666666,
        "std_pred_length": 4.861269838678413,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5671902268760908,
        "vocab_size-1": 325,
        "unique-1": 272,
        "entropy-1": 7.41633451095045,
        "distinct-2": 0.9329608938547486,
        "vocab_size-2": 501,
        "unique-2": 482,
        "entropy-2": 8.898032310626608,
        "cond_entropy-2": 1.2682168813939487,
        "distinct-3": 0.9920159680638723,
        "vocab_size-3": 497,
        "unique-3": 494,
        "entropy-3": 8.951191967841506,
        "cond_entropy-3": 0.05194601913671002,
        "total_length-nopunct": 497,
        "mean_pred_length-nopunct": 13.805555555555555,
        "std_pred_length-nopunct": 4.234904199653979,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6378269617706237,
        "vocab_size-1-nopunct": 317,
        "unique-1-nopunct": 269,
        "entropy-1-nopunct": 7.58452271338831,
        "distinct-2-nopunct": 0.9370932754880694,
        "vocab_size-2-nopunct": 432,
        "unique-2-nopunct": 418,
        "entropy-2-nopunct": 8.683371726834178,
        "cond_entropy-2-nopunct": 1.1779731303119652,
        "distinct-3-nopunct": 0.9952941176470588,
        "vocab_size-3-nopunct": 423,
        "unique-3-nopunct": 421,
        "entropy-3-nopunct": 8.721907266319242,
        "cond_entropy-3-nopunct": 0.052533289342512265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.432737567057944,
        "rouge1": {
            "precision": 0.7159,
            "recall": 0.74232,
            "fmeasure": 0.72073
        },
        "rouge2": {
            "precision": 0.48306,
            "recall": 0.51588,
            "fmeasure": 0.49091
        },
        "rougeL": {
            "precision": 0.60584,
            "recall": 0.64099,
            "fmeasure": 0.61536
        },
        "rougeLsum": {
            "precision": 0.60584,
            "recall": 0.64099,
            "fmeasure": 0.61536
        },
        "bleu": 42.48694,
        "local_recall": {
            "1": 0.12962962962962962,
            "2": 0.5508474576271186,
            "3": 0.7753846153846153
        },
        "bertscore": {
            "precision": 0.92025,
            "recall": 0.92938,
            "f1": 0.92296
        },
        "nubia": {
            "semantic_relation": 4.19888,
            "contradiction": 2.73645,
            "irrelevancy": 54.11621,
            "logical_agreement": 43.14733,
            "grammar_ref": 4.61474,
            "grammar_hyp": 4.46262,
            "nubia_score": 0.73984
        },
        "meteor": 0.40440168538833876,
        "bleurt": 0.24231
    },
    "totto_test_contrast_challenge_table_size-table_size_172": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.79,
        "total_length": 150,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.878524367060187,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.7066666666666667,
        "vocab_size-1": 106,
        "unique-1": 88,
        "entropy-1": 6.363009397568569,
        "distinct-2": 0.9785714285714285,
        "vocab_size-2": 137,
        "unique-2": 134,
        "entropy-2": 7.086425874087835,
        "cond_entropy-2": 0.5814791044927585,
        "distinct-3": 1.0,
        "vocab_size-3": 130,
        "unique-3": 130,
        "entropy-3": 7.022367813028455,
        "cond_entropy-3": -0.06076135776266604,
        "total_length-nopunct": 132,
        "mean_pred_length-nopunct": 13.2,
        "std_pred_length-nopunct": 4.5563142999578075,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 102,
        "unique-1-nopunct": 86,
        "entropy-1-nopunct": 6.4255260551788185,
        "distinct-2-nopunct": 0.9836065573770492,
        "vocab_size-2-nopunct": 120,
        "unique-2-nopunct": 118,
        "entropy-2-nopunct": 6.897950452317,
        "cond_entropy-2-nopunct": 0.523151287644686,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.807354922057591,
        "cond_entropy-3-nopunct": -0.08766812979099618,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8808131339126435,
        "rouge1": {
            "precision": 0.7264,
            "recall": 0.65119,
            "fmeasure": 0.67073
        },
        "rouge2": {
            "precision": 0.44284,
            "recall": 0.40683,
            "fmeasure": 0.41548
        },
        "rougeL": {
            "precision": 0.61308,
            "recall": 0.54813,
            "fmeasure": 0.56478
        },
        "rougeLsum": {
            "precision": 0.61308,
            "recall": 0.54813,
            "fmeasure": 0.56478
        },
        "bleu": 31.80732,
        "local_recall": {
            "1": 0.25806451612903225,
            "2": 0.25,
            "3": 0.5945945945945946
        },
        "bertscore": {
            "precision": 0.91016,
            "recall": 0.89835,
            "f1": 0.90244
        },
        "nubia": {
            "semantic_relation": 3.93994,
            "contradiction": 4.91394,
            "irrelevancy": 47.32526,
            "logical_agreement": 47.7608,
            "grammar_ref": 4.7085,
            "grammar_hyp": 5.12241,
            "nubia_score": 0.59102
        },
        "meteor": 0.3139066864579536,
        "bleurt": 0.15662
    },
    "totto_test_contrast_challenge_table_size-table_size_106": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 6.0,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 25,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.984769618706745,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.144219710220949,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 5.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8857142857142857,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.900711588373536,
        "distinct-2-nopunct": 0.9696969696969697,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.9837880587523955,
        "cond_entropy-2-nopunct": 0.09692928423166855,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.025681679939320114,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.620165891130366,
        "rouge1": {
            "precision": 0.67391,
            "recall": 0.72609,
            "fmeasure": 0.68918
        },
        "rouge2": {
            "precision": 0.46212,
            "recall": 0.50107,
            "fmeasure": 0.47192
        },
        "rougeL": {
            "precision": 0.61775,
            "recall": 0.66911,
            "fmeasure": 0.63292
        },
        "rougeLsum": {
            "precision": 0.61775,
            "recall": 0.66911,
            "fmeasure": 0.63292
        },
        "bleu": 41.27549,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.87156,
            "recall": 0.92085,
            "f1": 0.89424
        },
        "nubia": {
            "semantic_relation": 4.15939,
            "contradiction": 0.20378,
            "irrelevancy": 50.06858,
            "logical_agreement": 49.72765,
            "grammar_ref": 4.99819,
            "grammar_hyp": 5.18185,
            "nubia_score": 0.72153
        },
        "meteor": 0.365703409067082,
        "bleurt": 0.29497
    },
    "totto_test_contrast_challenge_table_size-table_size_174": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.73,
        "total_length": 187,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.04524979109513,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6256684491978609,
        "vocab_size-1": 117,
        "unique-1": 97,
        "entropy-1": 6.3354745757912365,
        "distinct-2": 0.9602272727272727,
        "vocab_size-2": 169,
        "unique-2": 164,
        "entropy-2": 7.368522527728217,
        "cond_entropy-2": 0.9029703256652923,
        "distinct-3": 0.9939393939393939,
        "vocab_size-3": 164,
        "unique-3": 163,
        "entropy-3": 7.354201002124596,
        "cond_entropy-3": -0.00826091954299653,
        "total_length-nopunct": 167,
        "mean_pred_length-nopunct": 15.181818181818182,
        "std_pred_length-nopunct": 4.508944279140816,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6766467065868264,
        "vocab_size-1-nopunct": 113,
        "unique-1-nopunct": 95,
        "entropy-1-nopunct": 6.369834607580919,
        "distinct-2-nopunct": 0.9551282051282052,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.1828381162981625,
        "cond_entropy-2-nopunct": 0.8780840634212161,
        "distinct-3-nopunct": 0.993103448275862,
        "vocab_size-3-nopunct": 144,
        "unique-3-nopunct": 143,
        "entropy-3-nopunct": 7.166115986566681,
        "cond_entropy-3-nopunct": -0.00894140470938272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.004937168535087,
        "rouge1": {
            "precision": 0.67749,
            "recall": 0.68364,
            "fmeasure": 0.66986
        },
        "rouge2": {
            "precision": 0.42446,
            "recall": 0.44665,
            "fmeasure": 0.4248
        },
        "rougeL": {
            "precision": 0.58001,
            "recall": 0.59861,
            "fmeasure": 0.57782
        },
        "rougeLsum": {
            "precision": 0.58001,
            "recall": 0.59861,
            "fmeasure": 0.57782
        },
        "bleu": 36.30743,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.2619047619047619,
            "3": 0.6771653543307087
        },
        "bertscore": {
            "precision": 0.90931,
            "recall": 0.91743,
            "f1": 0.90809
        },
        "nubia": {
            "semantic_relation": 3.90811,
            "contradiction": 8.35423,
            "irrelevancy": 48.50896,
            "logical_agreement": 43.13681,
            "grammar_ref": 4.8345,
            "grammar_hyp": 4.35728,
            "nubia_score": 0.66079
        },
        "meteor": 0.3319791005234028,
        "bleurt": 0.16902
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-5_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 56,
        "msttr-100": 0.345,
        "msttr-100_nopunct": 0.532,
        "total_length": 1042,
        "mean_pred_length": 18.607142857142858,
        "std_pred_length": 5.8084869293270565,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.2591170825335892,
        "vocab_size-1": 270,
        "unique-1": 163,
        "entropy-1": 5.661664354449752,
        "distinct-2": 0.4898580121703854,
        "vocab_size-2": 483,
        "unique-2": 295,
        "entropy-2": 8.285250938657022,
        "cond_entropy-2": 2.7883236819735204,
        "distinct-3": 0.621505376344086,
        "vocab_size-3": 578,
        "unique-3": 400,
        "entropy-3": 8.833633986587694,
        "cond_entropy-3": 0.6078554957135469,
        "total_length-nopunct": 553,
        "mean_pred_length-nopunct": 9.875,
        "std_pred_length-nopunct": 3.3169612814829694,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.46835443037974683,
        "vocab_size-1-nopunct": 259,
        "unique-1-nopunct": 161,
        "entropy-1-nopunct": 7.22794599034833,
        "distinct-2-nopunct": 0.716297786720322,
        "vocab_size-2-nopunct": 356,
        "unique-2-nopunct": 270,
        "entropy-2-nopunct": 8.245560769264639,
        "cond_entropy-2-nopunct": 1.1319756078815133,
        "distinct-3-nopunct": 0.8072562358276644,
        "vocab_size-3-nopunct": 356,
        "unique-3-nopunct": 293,
        "entropy-3-nopunct": 8.353165614322105,
        "cond_entropy-3-nopunct": 0.15602765265915397,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.5386606911288161,
        "rouge1": {
            "precision": 0.09226,
            "recall": 0.26463,
            "fmeasure": 0.1246
        },
        "rouge2": {
            "precision": 0.02587,
            "recall": 0.09271,
            "fmeasure": 0.03839
        },
        "rougeL": {
            "precision": 0.0804,
            "recall": 0.23485,
            "fmeasure": 0.10945
        },
        "rougeLsum": {
            "precision": 0.0804,
            "recall": 0.23485,
            "fmeasure": 0.10945
        },
        "bleu": 1.12778,
        "local_recall": {
            "1": 0.006427915518824609,
            "2": 0.022257551669316374,
            "3": 0.03350970017636684
        },
        "bertscore": {
            "precision": 0.61201,
            "recall": 0.52752,
            "f1": 0.56528
        },
        "nubia": {
            "semantic_relation": 2.66115,
            "contradiction": 30.40506,
            "irrelevancy": 34.32433,
            "logical_agreement": 35.2706,
            "grammar_ref": 2.50981,
            "grammar_hyp": 3.7065,
            "nubia_score": 0.33845
        },
        "meteor": 0.03448425394350386,
        "bleurt": -1.26797
    },
    "totto_test_contrast_challenge_table_size-table_size_108": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 51,
        "msttr-100": 0.7175,
        "msttr-100_nopunct": 0.77429,
        "total_length": 844,
        "mean_pred_length": 16.54901960784314,
        "std_pred_length": 5.428009151849018,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 36,
        "distinct-1": 0.542654028436019,
        "vocab_size-1": 458,
        "unique-1": 388,
        "entropy-1": 7.671509924601126,
        "distinct-2": 0.9092055485498108,
        "vocab_size-2": 721,
        "unique-2": 680,
        "entropy-2": 9.385535205112028,
        "cond_entropy-2": 1.5202771590095776,
        "distinct-3": 0.9865229110512129,
        "vocab_size-3": 732,
        "unique-3": 723,
        "entropy-3": 9.507303830121971,
        "cond_entropy-3": 0.1268533243065064,
        "total_length-nopunct": 733,
        "mean_pred_length-nopunct": 14.372549019607844,
        "std_pred_length-nopunct": 4.6482583046991826,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.616643929058663,
        "vocab_size-1-nopunct": 452,
        "unique-1-nopunct": 386,
        "entropy-1-nopunct": 7.90784352029268,
        "distinct-2-nopunct": 0.9178885630498533,
        "vocab_size-2-nopunct": 626,
        "unique-2-nopunct": 598,
        "entropy-2-nopunct": 9.178247687069632,
        "cond_entropy-2-nopunct": 1.3614435273561307,
        "distinct-3-nopunct": 0.9920760697305864,
        "vocab_size-3-nopunct": 626,
        "unique-3-nopunct": 621,
        "entropy-3-nopunct": 9.285648334443694,
        "cond_entropy-3-nopunct": 0.1232554688315627,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.188757243875251,
        "rouge1": {
            "precision": 0.78303,
            "recall": 0.75477,
            "fmeasure": 0.75348
        },
        "rouge2": {
            "precision": 0.55521,
            "recall": 0.53639,
            "fmeasure": 0.53441
        },
        "rougeL": {
            "precision": 0.67573,
            "recall": 0.6547,
            "fmeasure": 0.65191
        },
        "rougeLsum": {
            "precision": 0.67573,
            "recall": 0.6547,
            "fmeasure": 0.65191
        },
        "bleu": 49.4212,
        "local_recall": {
            "1": 0.22395833333333334,
            "2": 0.4782608695652174,
            "3": 0.7703435804701627
        },
        "bertscore": {
            "precision": 0.93334,
            "recall": 0.92932,
            "f1": 0.92954
        },
        "nubia": {
            "semantic_relation": 4.18299,
            "contradiction": 5.23013,
            "irrelevancy": 31.76523,
            "logical_agreement": 63.00464,
            "grammar_ref": 4.80362,
            "grammar_hyp": 4.77717,
            "nubia_score": 0.70824
        },
        "meteor": 0.3988767255612941,
        "bleurt": 0.28168
    },
    "totto_test_contrast_challenge_table_size-table_size_147": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.775,
        "total_length": 278,
        "mean_pred_length": 16.352941176470587,
        "std_pred_length": 4.588235294117647,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 24,
        "distinct-1": 0.6187050359712231,
        "vocab_size-1": 172,
        "unique-1": 137,
        "entropy-1": 6.834378376397093,
        "distinct-2": 0.9425287356321839,
        "vocab_size-2": 246,
        "unique-2": 234,
        "entropy-2": 7.90240834330486,
        "cond_entropy-2": 0.9218137440631314,
        "distinct-3": 0.9877049180327869,
        "vocab_size-3": 241,
        "unique-3": 238,
        "entropy-3": 7.906147173628419,
        "cond_entropy-3": 0.012482519280556964,
        "total_length-nopunct": 249,
        "mean_pred_length-nopunct": 14.647058823529411,
        "std_pred_length-nopunct": 4.727157788909281,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6706827309236948,
        "vocab_size-1-nopunct": 167,
        "unique-1-nopunct": 136,
        "entropy-1-nopunct": 6.895309443800062,
        "distinct-2-nopunct": 0.9353448275862069,
        "vocab_size-2-nopunct": 217,
        "unique-2-nopunct": 205,
        "entropy-2-nopunct": 7.716796135204433,
        "cond_entropy-2-nopunct": 0.8787815938979243,
        "distinct-3-nopunct": 0.986046511627907,
        "vocab_size-3-nopunct": 212,
        "unique-3-nopunct": 209,
        "entropy-3-nopunct": 7.72028587284525,
        "cond_entropy-3-nopunct": 0.005350866099857667,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.362261137359569,
        "rouge1": {
            "precision": 0.76878,
            "recall": 0.77546,
            "fmeasure": 0.75706
        },
        "rouge2": {
            "precision": 0.54841,
            "recall": 0.57582,
            "fmeasure": 0.54912
        },
        "rougeL": {
            "precision": 0.65981,
            "recall": 0.68769,
            "fmeasure": 0.66023
        },
        "rougeLsum": {
            "precision": 0.65981,
            "recall": 0.68769,
            "fmeasure": 0.66023
        },
        "bleu": 50.23468,
        "local_recall": {
            "1": 0.24242424242424243,
            "2": 0.5306122448979592,
            "3": 0.7795698924731183
        },
        "bertscore": {
            "precision": 0.9342,
            "recall": 0.93255,
            "f1": 0.92945
        },
        "nubia": {
            "semantic_relation": 4.33967,
            "contradiction": 13.56098,
            "irrelevancy": 20.16344,
            "logical_agreement": 66.27558,
            "grammar_ref": 4.21928,
            "grammar_hyp": 3.89036,
            "nubia_score": 0.79216
        },
        "meteor": 0.39132248977596823,
        "bleurt": 0.38362
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-6_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 19,
        "msttr-100": 0.26667,
        "msttr-100_nopunct": 0.425,
        "total_length": 368,
        "mean_pred_length": 19.36842105263158,
        "std_pred_length": 6.376028514066446,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.22282608695652173,
        "vocab_size-1": 82,
        "unique-1": 50,
        "entropy-1": 4.483737526376216,
        "distinct-2": 0.3868194842406877,
        "vocab_size-2": 135,
        "unique-2": 81,
        "entropy-2": 6.251491851237963,
        "cond_entropy-2": 1.8621819969386526,
        "distinct-3": 0.5060606060606061,
        "vocab_size-3": 167,
        "unique-3": 111,
        "entropy-3": 6.803736703864786,
        "cond_entropy-3": 0.632083151954638,
        "total_length-nopunct": 208,
        "mean_pred_length-nopunct": 10.947368421052632,
        "std_pred_length-nopunct": 4.260883083791389,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.3701923076923077,
        "vocab_size-1-nopunct": 77,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.362796086679495,
        "distinct-2-nopunct": 0.582010582010582,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.347151472675414,
        "cond_entropy-2-nopunct": 1.1044292283938464,
        "distinct-3-nopunct": 0.711764705882353,
        "vocab_size-3-nopunct": 121,
        "unique-3-nopunct": 95,
        "entropy-3-nopunct": 6.67775683940271,
        "cond_entropy-3-nopunct": 0.39536955779977184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.3053189214576011,
        "rouge1": {
            "precision": 0.02969,
            "recall": 0.1288,
            "fmeasure": 0.04725
        },
        "rouge2": {
            "precision": 0.00329,
            "recall": 0.01316,
            "fmeasure": 0.00526
        },
        "rougeL": {
            "precision": 0.02969,
            "recall": 0.1288,
            "fmeasure": 0.04725
        },
        "rougeLsum": {
            "precision": 0.02969,
            "recall": 0.1288,
            "fmeasure": 0.04725
        },
        "bleu": 0.19611,
        "local_recall": {
            "1": 0.010169491525423728,
            "2": 0.03383458646616541,
            "3": 0.039603960396039604
        },
        "bertscore": {
            "precision": 0.58365,
            "recall": 0.51305,
            "f1": 0.54536
        },
        "nubia": {
            "semantic_relation": 2.46661,
            "contradiction": 29.91266,
            "irrelevancy": 38.05291,
            "logical_agreement": 32.03444,
            "grammar_ref": 2.51721,
            "grammar_hyp": 3.69494,
            "nubia_score": 0.30463
        },
        "meteor": 0.012774586008786754,
        "bleurt": -1.27812
    },
    "web_nlg_ru_test_contrast_challenge_max_subj_same-7_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 12,
        "msttr-100": 0.26,
        "msttr-100_nopunct": 0.27,
        "total_length": 264,
        "mean_pred_length": 22.0,
        "std_pred_length": 5.612486080160912,
        "median_pred_length": 23.5,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.22727272727272727,
        "vocab_size-1": 60,
        "unique-1": 25,
        "entropy-1": 4.534489041673077,
        "distinct-2": 0.3888888888888889,
        "vocab_size-2": 98,
        "unique-2": 49,
        "entropy-2": 6.033065908633251,
        "cond_entropy-2": 1.5169611953803321,
        "distinct-3": 0.5208333333333334,
        "vocab_size-3": 125,
        "unique-3": 76,
        "entropy-3": 6.5411843265664125,
        "cond_entropy-3": 0.5485401327594835,
        "total_length-nopunct": 154,
        "mean_pred_length-nopunct": 12.833333333333334,
        "std_pred_length-nopunct": 4.13991411612474,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.35064935064935066,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 5.095284864501278,
        "distinct-2-nopunct": 0.5774647887323944,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 6.026345404908402,
        "cond_entropy-2-nopunct": 0.9986562340387213,
        "distinct-3-nopunct": 0.7,
        "vocab_size-3-nopunct": 91,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.2586431013735,
        "cond_entropy-3-nopunct": 0.2808430470321204,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.3727813541405702,
        "rouge1": {
            "precision": 0.04577,
            "recall": 0.17199,
            "fmeasure": 0.06881
        },
        "rouge2": {
            "precision": 0.00309,
            "recall": 0.00694,
            "fmeasure": 0.00427
        },
        "rougeL": {
            "precision": 0.03936,
            "recall": 0.1581,
            "fmeasure": 0.06004
        },
        "rougeLsum": {
            "precision": 0.03936,
            "recall": 0.1581,
            "fmeasure": 0.06004
        },
        "bleu": 0.1626,
        "local_recall": {
            "1": 0.0,
            "2": 0.011494252873563218,
            "3": 0.056962025316455694
        },
        "bertscore": {
            "precision": 0.59656,
            "recall": 0.5107,
            "f1": 0.55011
        },
        "nubia": {
            "semantic_relation": 2.54408,
            "contradiction": 31.7116,
            "irrelevancy": 32.10406,
            "logical_agreement": 36.18434,
            "grammar_ref": 2.55511,
            "grammar_hyp": 3.26896,
            "nubia_score": 0.38421
        },
        "meteor": 0.015800315502454764,
        "bleurt": -1.26044
    },
    "totto_test_contrast_challenge_table_size-table_size_25": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 56,
        "msttr-100": 0.73875,
        "msttr-100_nopunct": 0.78857,
        "total_length": 899,
        "mean_pred_length": 16.053571428571427,
        "std_pred_length": 5.079439096062895,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.5094549499443827,
        "vocab_size-1": 458,
        "unique-1": 373,
        "entropy-1": 7.722892524158443,
        "distinct-2": 0.8837485172004745,
        "vocab_size-2": 745,
        "unique-2": 687,
        "entropy-2": 9.428602914811782,
        "cond_entropy-2": 1.4859663416565707,
        "distinct-3": 0.9644218551461246,
        "vocab_size-3": 759,
        "unique-3": 739,
        "entropy-3": 9.540144158406259,
        "cond_entropy-3": 0.123649405273304,
        "total_length-nopunct": 790,
        "mean_pred_length-nopunct": 14.107142857142858,
        "std_pred_length-nopunct": 4.5696145954577405,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.569620253164557,
        "vocab_size-1-nopunct": 450,
        "unique-1-nopunct": 372,
        "entropy-1-nopunct": 7.924878022353228,
        "distinct-2-nopunct": 0.888283378746594,
        "vocab_size-2-nopunct": 652,
        "unique-2-nopunct": 606,
        "entropy-2-nopunct": 9.233378802081301,
        "cond_entropy-2-nopunct": 1.404174964900956,
        "distinct-3-nopunct": 0.9660766961651918,
        "vocab_size-3-nopunct": 655,
        "unique-3-nopunct": 638,
        "entropy-3-nopunct": 9.329168343660863,
        "cond_entropy-3-nopunct": 0.1179582985747736,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.075050982672298,
        "rouge1": {
            "precision": 0.78802,
            "recall": 0.72575,
            "fmeasure": 0.74709
        },
        "rouge2": {
            "precision": 0.56755,
            "recall": 0.51662,
            "fmeasure": 0.53396
        },
        "rougeL": {
            "precision": 0.70026,
            "recall": 0.6451,
            "fmeasure": 0.66369
        },
        "rougeLsum": {
            "precision": 0.70026,
            "recall": 0.6451,
            "fmeasure": 0.66369
        },
        "bleu": 46.67358,
        "local_recall": {
            "1": 0.20105820105820105,
            "2": 0.4430379746835443,
            "3": 0.7601246105919003
        },
        "bertscore": {
            "precision": 0.92876,
            "recall": 0.9227,
            "f1": 0.92462
        },
        "nubia": {
            "semantic_relation": 4.27598,
            "contradiction": 6.64215,
            "irrelevancy": 29.11713,
            "logical_agreement": 64.24073,
            "grammar_ref": 4.75668,
            "grammar_hyp": 4.8405,
            "nubia_score": 0.73657
        },
        "meteor": 0.3994212656575001,
        "bleurt": 0.25466
    },
    "totto_test_contrast_challenge_table_size-table_size_148": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.71,
        "total_length": 142,
        "mean_pred_length": 14.2,
        "std_pred_length": 4.214261501141095,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6267605633802817,
        "vocab_size-1": 89,
        "unique-1": 76,
        "entropy-1": 5.859814882760559,
        "distinct-2": 0.9166666666666666,
        "vocab_size-2": 121,
        "unique-2": 113,
        "entropy-2": 6.850381691521801,
        "cond_entropy-2": 0.8366277285988897,
        "distinct-3": 0.9672131147540983,
        "vocab_size-3": 118,
        "unique-3": 114,
        "entropy-3": 6.865163567071098,
        "cond_entropy-3": 0.0306845335686689,
        "total_length-nopunct": 123,
        "mean_pred_length-nopunct": 12.3,
        "std_pred_length-nopunct": 3.5227829907617076,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6910569105691057,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 5.883168064571841,
        "distinct-2-nopunct": 0.9292035398230089,
        "vocab_size-2-nopunct": 105,
        "unique-2-nopunct": 100,
        "entropy-2-nopunct": 6.646642321048508,
        "cond_entropy-2-nopunct": 0.8572217291109231,
        "distinct-3-nopunct": 0.9902912621359223,
        "vocab_size-3-nopunct": 102,
        "unique-3-nopunct": 101,
        "entropy-3-nopunct": 6.667083051455081,
        "cond_entropy-3-nopunct": 0.037288948014990074,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.291399225817968,
        "rouge1": {
            "precision": 0.84042,
            "recall": 0.77788,
            "fmeasure": 0.80264
        },
        "rouge2": {
            "precision": 0.59528,
            "recall": 0.56868,
            "fmeasure": 0.57503
        },
        "rougeL": {
            "precision": 0.74575,
            "recall": 0.71622,
            "fmeasure": 0.72364
        },
        "rougeLsum": {
            "precision": 0.74575,
            "recall": 0.71622,
            "fmeasure": 0.72364
        },
        "bleu": 56.6376,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.35294117647058826,
            "3": 0.8301886792452831
        },
        "bertscore": {
            "precision": 0.9531,
            "recall": 0.95118,
            "f1": 0.95174
        },
        "nubia": {
            "semantic_relation": 4.71649,
            "contradiction": 0.85647,
            "irrelevancy": 24.14436,
            "logical_agreement": 74.99916,
            "grammar_ref": 5.26168,
            "grammar_hyp": 5.34728,
            "nubia_score": 0.85619
        },
        "meteor": 0.4403791645851367,
        "bleurt": 0.4102
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 86,
        "msttr-100": 0.64714,
        "msttr-100_nopunct": 0.67,
        "total_length": 1457,
        "mean_pred_length": 16.941860465116278,
        "std_pred_length": 4.121285222780238,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.21413864104323954,
        "vocab_size-1": 312,
        "unique-1": 147,
        "entropy-1": 6.948447489189798,
        "distinct-2": 0.5142231947483589,
        "vocab_size-2": 705,
        "unique-2": 466,
        "entropy-2": 8.907120943853283,
        "cond_entropy-2": 1.830576529398971,
        "distinct-3": 0.6957198443579766,
        "vocab_size-3": 894,
        "unique-3": 703,
        "entropy-3": 9.474890785770992,
        "cond_entropy-3": 0.5529191344718793,
        "total_length-nopunct": 1297,
        "mean_pred_length-nopunct": 15.081395348837209,
        "std_pred_length-nopunct": 3.828337171000236,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.23747108712413262,
        "vocab_size-1-nopunct": 308,
        "unique-1-nopunct": 146,
        "entropy-1-nopunct": 7.110147218002993,
        "distinct-2-nopunct": 0.5400495458298926,
        "vocab_size-2-nopunct": 654,
        "unique-2-nopunct": 438,
        "entropy-2-nopunct": 8.852491805959021,
        "cond_entropy-2-nopunct": 1.7979269316028947,
        "distinct-3-nopunct": 0.7235555555555555,
        "vocab_size-3-nopunct": 814,
        "unique-3-nopunct": 649,
        "entropy-3-nopunct": 9.390119175150097,
        "cond_entropy-3-nopunct": 0.5275212191785662,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 3.8649623775789794,
        "rouge1": {
            "precision": 0.57379,
            "recall": 0.53308,
            "fmeasure": 0.54492
        },
        "rouge2": {
            "precision": 0.30096,
            "recall": 0.28119,
            "fmeasure": 0.28648
        },
        "rougeL": {
            "precision": 0.44337,
            "recall": 0.41277,
            "fmeasure": 0.42195
        },
        "rougeLsum": {
            "precision": 0.44337,
            "recall": 0.41277,
            "fmeasure": 0.42195
        },
        "bleu": 16.24594,
        "local_recall": {
            "1": 0.47452471482889735
        },
        "bertscore": {
            "precision": 0.91516,
            "recall": 0.90874,
            "f1": 0.91182
        },
        "nubia": {
            "semantic_relation": 3.28848,
            "contradiction": 18.85598,
            "irrelevancy": 23.29958,
            "logical_agreement": 57.84444,
            "grammar_ref": 6.22337,
            "grammar_hyp": 6.27823,
            "nubia_score": 0.52442
        },
        "meteor": 0.23592465312366487,
        "bleurt": -0.08524
    },
    "totto_test_contrast_challenge_table_size-table_size_126": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 57,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75625,
        "total_length": 913,
        "mean_pred_length": 16.017543859649123,
        "std_pred_length": 5.010484544520954,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5093099671412924,
        "vocab_size-1": 465,
        "unique-1": 376,
        "entropy-1": 7.685828954136379,
        "distinct-2": 0.8691588785046729,
        "vocab_size-2": 744,
        "unique-2": 690,
        "entropy-2": 9.382930629557803,
        "cond_entropy-2": 1.485527861602954,
        "distinct-3": 0.951188986232791,
        "vocab_size-3": 760,
        "unique-3": 737,
        "entropy-3": 9.524404634104437,
        "cond_entropy-3": 0.15203291861434567,
        "total_length-nopunct": 816,
        "mean_pred_length-nopunct": 14.31578947368421,
        "std_pred_length-nopunct": 4.66099114049995,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5612745098039216,
        "vocab_size-1-nopunct": 458,
        "unique-1-nopunct": 373,
        "entropy-1-nopunct": 7.845898971934817,
        "distinct-2-nopunct": 0.8708827404479579,
        "vocab_size-2-nopunct": 661,
        "unique-2-nopunct": 616,
        "entropy-2-nopunct": 9.2061083034111,
        "cond_entropy-2-nopunct": 1.470034253201993,
        "distinct-3-nopunct": 0.9515669515669516,
        "vocab_size-3-nopunct": 668,
        "unique-3-nopunct": 650,
        "entropy-3-nopunct": 9.335669100646543,
        "cond_entropy-3-nopunct": 0.14671230792429757,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.517556186132739,
        "rouge1": {
            "precision": 0.78264,
            "recall": 0.77682,
            "fmeasure": 0.76984
        },
        "rouge2": {
            "precision": 0.57715,
            "recall": 0.57509,
            "fmeasure": 0.56667
        },
        "rougeL": {
            "precision": 0.66897,
            "recall": 0.66813,
            "fmeasure": 0.65959
        },
        "rougeLsum": {
            "precision": 0.66897,
            "recall": 0.66813,
            "fmeasure": 0.65959
        },
        "bleu": 50.92474,
        "local_recall": {
            "1": 0.22580645161290322,
            "2": 0.5365853658536586,
            "3": 0.8311195445920304
        },
        "bertscore": {
            "precision": 0.93004,
            "recall": 0.93062,
            "f1": 0.92893
        },
        "nubia": {
            "semantic_relation": 4.21229,
            "contradiction": 9.7905,
            "irrelevancy": 32.99703,
            "logical_agreement": 57.21247,
            "grammar_ref": 4.80748,
            "grammar_hyp": 4.63021,
            "nubia_score": 0.74706
        },
        "meteor": 0.41629291306045585,
        "bleurt": 0.23804
    },
    "totto_test_contrast_challenge_table_size-table_size_175": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 21,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.745,
        "total_length": 308,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 2.8171808490950556,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 19,
        "distinct-1": 0.6298701298701299,
        "vocab_size-1": 194,
        "unique-1": 164,
        "entropy-1": 6.941588468771853,
        "distinct-2": 0.9407665505226481,
        "vocab_size-2": 270,
        "unique-2": 259,
        "entropy-2": 8.024263972053351,
        "cond_entropy-2": 0.8582521361457277,
        "distinct-3": 0.9962406015037594,
        "vocab_size-3": 265,
        "unique-3": 264,
        "entropy-3": 8.04776363850876,
        "cond_entropy-3": 0.02708426061723225,
        "total_length-nopunct": 274,
        "mean_pred_length-nopunct": 13.047619047619047,
        "std_pred_length-nopunct": 2.627259852215947,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6897810218978102,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 163,
        "entropy-1-nopunct": 7.047220622106707,
        "distinct-2-nopunct": 0.9446640316205533,
        "vocab_size-2-nopunct": 239,
        "unique-2-nopunct": 231,
        "entropy-2-nopunct": 7.847165400873721,
        "cond_entropy-2-nopunct": 0.8548740897412774,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 232,
        "unique-3-nopunct": 232,
        "entropy-3-nopunct": 7.857980995127551,
        "cond_entropy-3-nopunct": 0.016278650932740682,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.1298726765503275,
        "rouge1": {
            "precision": 0.7358,
            "recall": 0.68207,
            "fmeasure": 0.70172
        },
        "rouge2": {
            "precision": 0.4915,
            "recall": 0.46177,
            "fmeasure": 0.47225
        },
        "rougeL": {
            "precision": 0.60554,
            "recall": 0.55681,
            "fmeasure": 0.57575
        },
        "rougeLsum": {
            "precision": 0.60554,
            "recall": 0.55681,
            "fmeasure": 0.57575
        },
        "bleu": 43.05971,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.425531914893617,
            "3": 0.7577319587628866
        },
        "bertscore": {
            "precision": 0.93318,
            "recall": 0.91917,
            "f1": 0.92479
        },
        "nubia": {
            "semantic_relation": 4.092,
            "contradiction": 9.82136,
            "irrelevancy": 27.17241,
            "logical_agreement": 63.00623,
            "grammar_ref": 4.90831,
            "grammar_hyp": 4.92736,
            "nubia_score": 0.67136
        },
        "meteor": 0.37037566396350036,
        "bleurt": 0.24925
    },
    "totto_test_contrast_challenge_table_size-table_size_26": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.74,
        "total_length": 218,
        "mean_pred_length": 18.166666666666668,
        "std_pred_length": 7.243771270700244,
        "median_pred_length": 16.0,
        "min_pred_length": 5,
        "max_pred_length": 33,
        "distinct-1": 0.5091743119266054,
        "vocab_size-1": 111,
        "unique-1": 80,
        "entropy-1": 6.185501951277543,
        "distinct-2": 0.8252427184466019,
        "vocab_size-2": 170,
        "unique-2": 151,
        "entropy-2": 7.245753014952776,
        "cond_entropy-2": 0.9677192223013501,
        "distinct-3": 0.8917525773195877,
        "vocab_size-3": 173,
        "unique-3": 160,
        "entropy-3": 7.349761682326378,
        "cond_entropy-3": 0.1312714000889111,
        "total_length-nopunct": 179,
        "mean_pred_length-nopunct": 14.916666666666666,
        "std_pred_length-nopunct": 5.619287222494405,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5865921787709497,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.1776007263045765,
        "distinct-2-nopunct": 0.8383233532934131,
        "vocab_size-2-nopunct": 140,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 6.9613730049711515,
        "cond_entropy-2-nopunct": 0.8406863841161342,
        "distinct-3-nopunct": 0.9032258064516129,
        "vocab_size-3-nopunct": 140,
        "unique-3-nopunct": 130,
        "entropy-3-nopunct": 7.055062066522704,
        "cond_entropy-3-nopunct": 0.116160112837406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.264514732139591,
        "rouge1": {
            "precision": 0.81227,
            "recall": 0.75266,
            "fmeasure": 0.76768
        },
        "rouge2": {
            "precision": 0.62427,
            "recall": 0.59792,
            "fmeasure": 0.60209
        },
        "rougeL": {
            "precision": 0.76847,
            "recall": 0.7185,
            "fmeasure": 0.72758
        },
        "rougeLsum": {
            "precision": 0.76847,
            "recall": 0.7185,
            "fmeasure": 0.72758
        },
        "bleu": 60.94065,
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.4444444444444444,
            "3": 0.8489208633093526
        },
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.94249,
            "f1": 0.94247
        },
        "nubia": {
            "semantic_relation": 4.20229,
            "contradiction": 4.10248,
            "irrelevancy": 23.71981,
            "logical_agreement": 72.17771,
            "grammar_ref": 4.07585,
            "grammar_hyp": 4.21893,
            "nubia_score": 0.75042
        },
        "meteor": 0.4442500699486426,
        "bleurt": 0.4346
    },
    "cs_restaurants_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 9,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.72,
        "total_length": 185,
        "mean_pred_length": 20.555555555555557,
        "std_pred_length": 2.2662308949301266,
        "median_pred_length": 21.0,
        "min_pred_length": 16,
        "max_pred_length": 24,
        "distinct-1": 0.5513513513513514,
        "vocab_size-1": 102,
        "unique-1": 68,
        "entropy-1": 6.249833345906385,
        "distinct-2": 0.875,
        "vocab_size-2": 154,
        "unique-2": 134,
        "entropy-2": 7.200853351567267,
        "cond_entropy-2": 0.9277938461181409,
        "distinct-3": 0.9520958083832335,
        "vocab_size-3": 159,
        "unique-3": 151,
        "entropy-3": 7.287895909240498,
        "cond_entropy-3": 0.08301384152733526,
        "total_length-nopunct": 167,
        "mean_pred_length-nopunct": 18.555555555555557,
        "std_pred_length-nopunct": 2.1140330656044943,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.5988023952095808,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 6.309565556285884,
        "distinct-2-nopunct": 0.8860759493670886,
        "vocab_size-2-nopunct": 140,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 7.066377108909225,
        "cond_entropy-2-nopunct": 0.7815733318861613,
        "distinct-3-nopunct": 0.959731543624161,
        "vocab_size-3-nopunct": 143,
        "unique-3-nopunct": 137,
        "entropy-3-nopunct": 7.138631607710492,
        "cond_entropy-3-nopunct": 0.05189683270710308,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 2.4919958420710326,
        "rouge1": {
            "precision": 0.48569,
            "recall": 0.55976,
            "fmeasure": 0.5159
        },
        "rouge2": {
            "precision": 0.2619,
            "recall": 0.29964,
            "fmeasure": 0.277
        },
        "rougeL": {
            "precision": 0.37495,
            "recall": 0.42953,
            "fmeasure": 0.39681
        },
        "rougeLsum": {
            "precision": 0.37495,
            "recall": 0.42953,
            "fmeasure": 0.39681
        },
        "bleu": 11.68487,
        "local_recall": {
            "1": 0.48148148148148145
        },
        "bertscore": {
            "precision": 0.90005,
            "recall": 0.91043,
            "f1": 0.90518
        },
        "nubia": {
            "semantic_relation": 3.13601,
            "contradiction": 20.64924,
            "irrelevancy": 34.98277,
            "logical_agreement": 44.36798,
            "grammar_ref": 6.01604,
            "grammar_hyp": 6.0383,
            "nubia_score": 0.51627
        },
        "meteor": 0.22803709950218348,
        "bleurt": -0.13488
    },
    "totto_test_contrast_challenge_table_size-table_size_176": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.77,
        "total_length": 360,
        "mean_pred_length": 15.652173913043478,
        "std_pred_length": 5.8503711933679075,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.5972222222222222,
        "vocab_size-1": 215,
        "unique-1": 185,
        "entropy-1": 6.925101570101755,
        "distinct-2": 0.9347181008902077,
        "vocab_size-2": 315,
        "unique-2": 304,
        "entropy-2": 8.226986800592137,
        "cond_entropy-2": 1.1000851121340958,
        "distinct-3": 0.9936305732484076,
        "vocab_size-3": 312,
        "unique-3": 311,
        "entropy-3": 8.279477795063105,
        "cond_entropy-3": 0.03943753445042662,
        "total_length-nopunct": 306,
        "mean_pred_length-nopunct": 13.304347826086957,
        "std_pred_length-nopunct": 5.068528494189247,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6830065359477124,
        "vocab_size-1-nopunct": 209,
        "unique-1-nopunct": 183,
        "entropy-1-nopunct": 7.093797252011521,
        "distinct-2-nopunct": 0.9399293286219081,
        "vocab_size-2-nopunct": 266,
        "unique-2-nopunct": 257,
        "entropy-2-nopunct": 7.9877452677203165,
        "cond_entropy-2-nopunct": 0.9516145884643861,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 260,
        "unique-3-nopunct": 260,
        "entropy-3-nopunct": 8.022367813028454,
        "cond_entropy-3-nopunct": 0.04850330849105925,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.48828540989706,
        "rouge1": {
            "precision": 0.80253,
            "recall": 0.73976,
            "fmeasure": 0.75769
        },
        "rouge2": {
            "precision": 0.61373,
            "recall": 0.56506,
            "fmeasure": 0.57973
        },
        "rougeL": {
            "precision": 0.72488,
            "recall": 0.6647,
            "fmeasure": 0.68233
        },
        "rougeLsum": {
            "precision": 0.72488,
            "recall": 0.6647,
            "fmeasure": 0.68233
        },
        "bleu": 55.68506,
        "local_recall": {
            "1": 0.1506849315068493,
            "2": 0.3023255813953488,
            "3": 0.8247863247863247
        },
        "bertscore": {
            "precision": 0.94531,
            "recall": 0.93271,
            "f1": 0.9355
        },
        "nubia": {
            "semantic_relation": 4.32502,
            "contradiction": 0.67495,
            "irrelevancy": 25.27216,
            "logical_agreement": 74.05288,
            "grammar_ref": 4.50686,
            "grammar_hyp": 4.61063,
            "nubia_score": 0.76662
        },
        "meteor": 0.40262542247768207,
        "bleurt": 0.35797
    },
    "totto_test_contrast_challenge_table_size-table_size_27": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.652,
        "msttr-100_nopunct": 0.684,
        "total_length": 596,
        "mean_pred_length": 14.9,
        "std_pred_length": 4.968903299521937,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.4664429530201342,
        "vocab_size-1": 278,
        "unique-1": 231,
        "entropy-1": 6.900910578923515,
        "distinct-2": 0.7931654676258992,
        "vocab_size-2": 441,
        "unique-2": 400,
        "entropy-2": 8.515592940966618,
        "cond_entropy-2": 1.425031783587323,
        "distinct-3": 0.8856589147286822,
        "vocab_size-3": 457,
        "unique-3": 435,
        "entropy-3": 8.696154527932588,
        "cond_entropy-3": 0.20095748773304928,
        "total_length-nopunct": 511,
        "mean_pred_length-nopunct": 12.775,
        "std_pred_length-nopunct": 4.28069795710933,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5322896281800391,
        "vocab_size-1-nopunct": 272,
        "unique-1-nopunct": 230,
        "entropy-1-nopunct": 7.063033528781488,
        "distinct-2-nopunct": 0.8004246284501062,
        "vocab_size-2-nopunct": 377,
        "unique-2-nopunct": 346,
        "entropy-2-nopunct": 8.286191757456251,
        "cond_entropy-2-nopunct": 1.3214975837076908,
        "distinct-3-nopunct": 0.888631090487239,
        "vocab_size-3-nopunct": 383,
        "unique-3-nopunct": 366,
        "entropy-3-nopunct": 8.440144988535566,
        "cond_entropy-3-nopunct": 0.18590189790444306,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.480348035847165,
        "rouge1": {
            "precision": 0.76281,
            "recall": 0.7137,
            "fmeasure": 0.72823
        },
        "rouge2": {
            "precision": 0.56286,
            "recall": 0.52395,
            "fmeasure": 0.53394
        },
        "rougeL": {
            "precision": 0.66816,
            "recall": 0.63161,
            "fmeasure": 0.63934
        },
        "rougeLsum": {
            "precision": 0.66816,
            "recall": 0.63161,
            "fmeasure": 0.63934
        },
        "bleu": 45.74589,
        "local_recall": {
            "1": 0.18803418803418803,
            "2": 0.4153846153846154,
            "3": 0.7304964539007093
        },
        "bertscore": {
            "precision": 0.92726,
            "recall": 0.92004,
            "f1": 0.92202
        },
        "nubia": {
            "semantic_relation": 4.07012,
            "contradiction": 5.34546,
            "irrelevancy": 26.36266,
            "logical_agreement": 68.29188,
            "grammar_ref": 4.3823,
            "grammar_hyp": 4.34683,
            "nubia_score": 0.71701
        },
        "meteor": 0.3785415251484294,
        "bleurt": 0.31504
    },
    "totto_test_contrast_challenge_table_size-table_size_127": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.646824711872685,
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.86667,
            "fmeasure": 0.72222
        },
        "rouge2": {
            "precision": 0.48718,
            "recall": 0.7037,
            "fmeasure": 0.57576
        },
        "rougeL": {
            "precision": 0.61905,
            "recall": 0.86667,
            "fmeasure": 0.72222
        },
        "rougeLsum": {
            "precision": 0.61905,
            "recall": 0.86667,
            "fmeasure": 0.72222
        },
        "bleu": 46.04629,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.90625,
            "recall": 0.97086,
            "f1": 0.93745
        },
        "nubia": {
            "semantic_relation": 3.71299,
            "contradiction": 0.52674,
            "irrelevancy": 93.10545,
            "logical_agreement": 6.3678,
            "grammar_ref": 6.33221,
            "grammar_hyp": 5.47382,
            "nubia_score": 0.54189
        },
        "meteor": 0.46456349980817785,
        "bleurt": 0.50957
    },
    "totto_test_contrast_challenge_table_size-table_size_177": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.265986323710904,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.958353821370877,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.10674500480228638,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.801969876934213,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.12916314291673192,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.15200309344505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.769270583736884,
        "rouge1": {
            "precision": 0.91481,
            "recall": 0.76129,
            "fmeasure": 0.81689
        },
        "rouge2": {
            "precision": 0.6455,
            "recall": 0.5371,
            "fmeasure": 0.56998
        },
        "rougeL": {
            "precision": 0.85648,
            "recall": 0.71347,
            "fmeasure": 0.76216
        },
        "rougeLsum": {
            "precision": 0.85648,
            "recall": 0.71347,
            "fmeasure": 0.76216
        },
        "bleu": 48.11716,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.42857142857142855,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.94572,
            "recall": 0.93145,
            "f1": 0.93817
        },
        "nubia": {
            "semantic_relation": 4.24391,
            "contradiction": 5.30955,
            "irrelevancy": 34.7208,
            "logical_agreement": 59.96965,
            "grammar_ref": 5.80868,
            "grammar_hyp": 6.14993,
            "nubia_score": 0.69672
        },
        "meteor": 0.4128937252591148,
        "bleurt": 0.19263
    },
    "totto_test_contrast_challenge_table_size-table_size_150": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 37,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.774,
        "total_length": 639,
        "mean_pred_length": 17.27027027027027,
        "std_pred_length": 5.410943109325711,
        "median_pred_length": 17.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.5539906103286385,
        "vocab_size-1": 354,
        "unique-1": 288,
        "entropy-1": 7.55938180764921,
        "distinct-2": 0.8970099667774086,
        "vocab_size-2": 540,
        "unique-2": 502,
        "entropy-2": 8.972767818824504,
        "cond_entropy-2": 1.245601434846046,
        "distinct-3": 0.9716814159292035,
        "vocab_size-3": 549,
        "unique-3": 538,
        "entropy-3": 9.075541321949435,
        "cond_entropy-3": 0.10923636815800152,
        "total_length-nopunct": 558,
        "mean_pred_length-nopunct": 15.08108108108108,
        "std_pred_length-nopunct": 4.806405514144519,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6236559139784946,
        "vocab_size-1-nopunct": 348,
        "unique-1-nopunct": 287,
        "entropy-1-nopunct": 7.749715143288351,
        "distinct-2-nopunct": 0.9021113243761996,
        "vocab_size-2-nopunct": 470,
        "unique-2-nopunct": 443,
        "entropy-2-nopunct": 8.765959488426274,
        "cond_entropy-2-nopunct": 1.09241152984927,
        "distinct-3-nopunct": 0.9752066115702479,
        "vocab_size-3-nopunct": 472,
        "unique-3-nopunct": 465,
        "entropy-3-nopunct": 8.857686294145644,
        "cond_entropy-3-nopunct": 0.11154015847245344,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.324709660466137,
        "rouge1": {
            "precision": 0.71964,
            "recall": 0.71577,
            "fmeasure": 0.70357
        },
        "rouge2": {
            "precision": 0.49558,
            "recall": 0.49863,
            "fmeasure": 0.48621
        },
        "rougeL": {
            "precision": 0.6393,
            "recall": 0.63937,
            "fmeasure": 0.62583
        },
        "rougeLsum": {
            "precision": 0.6393,
            "recall": 0.63937,
            "fmeasure": 0.62583
        },
        "bleu": 43.04846,
        "local_recall": {
            "1": 0.2426470588235294,
            "2": 0.3979591836734694,
            "3": 0.7270531400966184
        },
        "bertscore": {
            "precision": 0.91603,
            "recall": 0.91626,
            "f1": 0.91468
        },
        "nubia": {
            "semantic_relation": 4.02085,
            "contradiction": 6.5483,
            "irrelevancy": 39.99079,
            "logical_agreement": 53.46091,
            "grammar_ref": 4.9523,
            "grammar_hyp": 4.65079,
            "nubia_score": 0.68192
        },
        "meteor": 0.383054582740193,
        "bleurt": 0.16486
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 1099,
        "msttr-100": 0.32442,
        "msttr-100_nopunct": 0.50465,
        "total_length": 13892,
        "mean_pred_length": 12.640582347588717,
        "std_pred_length": 7.957863899378719,
        "median_pred_length": 12.0,
        "min_pred_length": 0,
        "max_pred_length": 60,
        "distinct-1": 0.12446012093291103,
        "vocab_size-1": 1729,
        "unique-1": 845,
        "entropy-1": 6.525584292690255,
        "distinct-2": 0.26879787400343913,
        "vocab_size-2": 3439,
        "unique-2": 1687,
        "entropy-2": 10.517742975608389,
        "cond_entropy-2": 4.207753379521558,
        "distinct-3": 0.41467372736590363,
        "vocab_size-3": 4855,
        "unique-3": 2898,
        "entropy-3": 11.396720881353032,
        "cond_entropy-3": 0.9838212669829377,
        "total_length-nopunct": 7170,
        "mean_pred_length-nopunct": 6.524112829845314,
        "std_pred_length-nopunct": 4.336202114837132,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.2387726638772664,
        "vocab_size-1-nopunct": 1712,
        "unique-1-nopunct": 840,
        "entropy-1-nopunct": 9.340421451759156,
        "distinct-2-nopunct": 0.5430452674897119,
        "vocab_size-2-nopunct": 3299,
        "unique-2-nopunct": 2177,
        "entropy-2-nopunct": 11.20034601320008,
        "cond_entropy-2-nopunct": 2.035794012932575,
        "distinct-3-nopunct": 0.6717677064940161,
        "vocab_size-3-nopunct": 3424,
        "unique-3-nopunct": 2558,
        "entropy-3-nopunct": 11.433294970258387,
        "cond_entropy-3-nopunct": 0.3488037544261357,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.4146924087797622,
        "rouge1": {
            "precision": 0.06475,
            "recall": 0.19227,
            "fmeasure": 0.08529
        },
        "rouge2": {
            "precision": 0.02187,
            "recall": 0.05908,
            "fmeasure": 0.02691
        },
        "rougeL": {
            "precision": 0.06235,
            "recall": 0.18573,
            "fmeasure": 0.08199
        },
        "rougeLsum": {
            "precision": 0.06235,
            "recall": 0.18573,
            "fmeasure": 0.08199
        },
        "bleu": 0.40854,
        "local_recall": {
            "1": 0.005009302991269501,
            "2": 0.011991729841488628,
            "3": 0.018945788782592385,
            "4": 0.1038961038961039,
            "5": 0.02702702702702703,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.6006,
            "recall": 0.52708,
            "f1": 0.56
        },
        "nubia": {
            "semantic_relation": 2.30722,
            "contradiction": 34.38006,
            "irrelevancy": 33.92144,
            "logical_agreement": 31.6985,
            "grammar_ref": 2.65247,
            "grammar_hyp": 5.00841,
            "nubia_score": 0.23827
        },
        "meteor": 0.020794471422244384,
        "bleurt": -1.30008
    },
    "totto_test_contrast_challenge_table_size-table_size_128": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.775,
        "total_length": 285,
        "mean_pred_length": 14.25,
        "std_pred_length": 4.288064831599447,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6140350877192983,
        "vocab_size-1": 175,
        "unique-1": 144,
        "entropy-1": 6.757078100204988,
        "distinct-2": 0.9433962264150944,
        "vocab_size-2": 250,
        "unique-2": 239,
        "entropy-2": 7.915849398490793,
        "cond_entropy-2": 0.9380778578299908,
        "distinct-3": 0.9836734693877551,
        "vocab_size-3": 241,
        "unique-3": 237,
        "entropy-3": 7.903984877778109,
        "cond_entropy-3": -0.0009258145119627552,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 12.55,
        "std_pred_length-nopunct": 3.980891859872609,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6852589641434262,
        "vocab_size-1-nopunct": 172,
        "unique-1-nopunct": 144,
        "entropy-1-nopunct": 6.908205742735509,
        "distinct-2-nopunct": 0.948051948051948,
        "vocab_size-2-nopunct": 219,
        "unique-2-nopunct": 211,
        "entropy-2-nopunct": 7.724001097674354,
        "cond_entropy-2-nopunct": 0.8948722217107551,
        "distinct-3-nopunct": 0.995260663507109,
        "vocab_size-3-nopunct": 210,
        "unique-3-nopunct": 209,
        "entropy-3-nopunct": 7.71162051572143,
        "cond_entropy-3-nopunct": -0.009750445105427384,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.562303622556243,
        "rouge1": {
            "precision": 0.713,
            "recall": 0.6837,
            "fmeasure": 0.6839
        },
        "rouge2": {
            "precision": 0.49039,
            "recall": 0.46575,
            "fmeasure": 0.47046
        },
        "rougeL": {
            "precision": 0.60044,
            "recall": 0.59272,
            "fmeasure": 0.58515
        },
        "rougeLsum": {
            "precision": 0.60044,
            "recall": 0.59272,
            "fmeasure": 0.58515
        },
        "bleu": 38.98414,
        "local_recall": {
            "1": 0.28,
            "2": 0.3770491803278688,
            "3": 0.675392670157068
        },
        "bertscore": {
            "precision": 0.92155,
            "recall": 0.91558,
            "f1": 0.91667
        },
        "nubia": {
            "semantic_relation": 4.10351,
            "contradiction": 6.27654,
            "irrelevancy": 27.15008,
            "logical_agreement": 66.57338,
            "grammar_ref": 4.72495,
            "grammar_hyp": 4.83339,
            "nubia_score": 0.66724
        },
        "meteor": 0.36311412850215663,
        "bleurt": 0.25073
    },
    "web_nlg_ru_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 8.178562764256865,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 26,
        "distinct-1": 0.23404255319148937,
        "vocab_size-1": 11,
        "unique-1": 4,
        "entropy-1": 2.811276150197903,
        "distinct-2": 0.38636363636363635,
        "vocab_size-2": 17,
        "unique-2": 6,
        "entropy-2": 3.7591419842479024,
        "cond_entropy-2": 0.9908223818126027,
        "distinct-3": 0.4878048780487805,
        "vocab_size-3": 20,
        "unique-3": 10,
        "entropy-3": 4.045980358012783,
        "cond_entropy-3": 0.3183874952553826,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 4.08248290463863,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.375,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.6981203125901447,
        "distinct-2-nopunct": 0.5714285714285714,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 3.3680424225727146,
        "cond_entropy-2-nopunct": 0.6375733748163049,
        "distinct-3-nopunct": 0.6666666666666666,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.4193819456463714,
        "cond_entropy-3-nopunct": 0.1109409119968853,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.0,
        "rouge1": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeLsum": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "bleu": 0.2785,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.0
        },
        "bertscore": {
            "precision": 0.61544,
            "recall": 0.56028,
            "f1": 0.58581
        },
        "nubia": {
            "semantic_relation": 2.57426,
            "contradiction": 32.19145,
            "irrelevancy": 26.82123,
            "logical_agreement": 40.98731,
            "grammar_ref": 2.52713,
            "grammar_hyp": 5.14221,
            "nubia_score": 0.2425
        },
        "meteor": 0.0023622047244094492,
        "bleurt": -1.33039
    },
    "totto_test_contrast_challenge_table_size-table_size_110": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.82,
        "total_length": 537,
        "mean_pred_length": 17.322580645161292,
        "std_pred_length": 4.699945756544866,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5810055865921788,
        "vocab_size-1": 312,
        "unique-1": 246,
        "entropy-1": 7.532290089865501,
        "distinct-2": 0.9387351778656127,
        "vocab_size-2": 475,
        "unique-2": 447,
        "entropy-2": 8.855019488721647,
        "cond_entropy-2": 1.1779842333969686,
        "distinct-3": 0.9642105263157895,
        "vocab_size-3": 458,
        "unique-3": 441,
        "entropy-3": 8.820204755849819,
        "cond_entropy-3": -0.026462739892498102,
        "total_length-nopunct": 476,
        "mean_pred_length-nopunct": 15.35483870967742,
        "std_pred_length-nopunct": 4.3887568016817715,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6470588235294118,
        "vocab_size-1-nopunct": 308,
        "unique-1-nopunct": 246,
        "entropy-1-nopunct": 7.711091264367197,
        "distinct-2-nopunct": 0.9370786516853933,
        "vocab_size-2-nopunct": 417,
        "unique-2-nopunct": 392,
        "entropy-2-nopunct": 8.665628070792696,
        "cond_entropy-2-nopunct": 1.0222009838782495,
        "distinct-3-nopunct": 0.9637681159420289,
        "vocab_size-3-nopunct": 399,
        "unique-3-nopunct": 384,
        "entropy-3-nopunct": 8.62102318938341,
        "cond_entropy-3-nopunct": -0.03471831834920887,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.516985563181385,
        "rouge1": {
            "precision": 0.75238,
            "recall": 0.72806,
            "fmeasure": 0.73147
        },
        "rouge2": {
            "precision": 0.52234,
            "recall": 0.5081,
            "fmeasure": 0.50727
        },
        "rougeL": {
            "precision": 0.66913,
            "recall": 0.65138,
            "fmeasure": 0.65187
        },
        "rougeLsum": {
            "precision": 0.66913,
            "recall": 0.65138,
            "fmeasure": 0.65187
        },
        "bleu": 44.89408,
        "local_recall": {
            "1": 0.22522522522522523,
            "2": 0.46987951807228917,
            "3": 0.744
        },
        "bertscore": {
            "precision": 0.92889,
            "recall": 0.92822,
            "f1": 0.92768
        },
        "nubia": {
            "semantic_relation": 4.32391,
            "contradiction": 8.79342,
            "irrelevancy": 24.56197,
            "logical_agreement": 66.64462,
            "grammar_ref": 4.88113,
            "grammar_hyp": 4.82327,
            "nubia_score": 0.76376
        },
        "meteor": 0.3852760205504899,
        "bleurt": 0.27343
    },
    "totto_test_contrast_challenge_table_size-table_size_111": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765371,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.03126257645096008,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.139029546634618,
        "rouge1": {
            "precision": 0.78333,
            "recall": 0.94444,
            "fmeasure": 0.85575
        },
        "rouge2": {
            "precision": 0.49123,
            "recall": 0.64957,
            "fmeasure": 0.55882
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.86905,
            "fmeasure": 0.75381
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.86905,
            "fmeasure": 0.75381
        },
        "bleu": 35.78835,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.91483,
            "recall": 0.97636,
            "f1": 0.9446
        },
        "nubia": {
            "semantic_relation": 3.80721,
            "contradiction": 0.22962,
            "irrelevancy": 99.65754,
            "logical_agreement": 0.11284,
            "grammar_ref": 3.66146,
            "grammar_hyp": 4.33844,
            "nubia_score": 0.61077
        },
        "meteor": 0.4800163911630881,
        "bleurt": -0.06089
    },
    "totto_test_contrast_challenge_gender-male": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.72739,
        "msttr-100_nopunct": 0.77756,
        "total_length": 4680,
        "mean_pred_length": 15.6,
        "std_pred_length": 5.136146415358503,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.386965811965812,
        "vocab_size-1": 1811,
        "unique-1": 1408,
        "entropy-1": 8.811459614741286,
        "distinct-2": 0.7897260273972603,
        "vocab_size-2": 3459,
        "unique-2": 3088,
        "entropy-2": 11.43445350832826,
        "cond_entropy-2": 2.338767376371029,
        "distinct-3": 0.928921568627451,
        "vocab_size-3": 3790,
        "unique-3": 3628,
        "entropy-3": 11.811259432038199,
        "cond_entropy-3": 0.37792058704202425,
        "total_length-nopunct": 4129,
        "mean_pred_length-nopunct": 13.763333333333334,
        "std_pred_length-nopunct": 4.8621657268706455,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.4364252845725357,
        "vocab_size-1-nopunct": 1802,
        "unique-1-nopunct": 1406,
        "entropy-1-nopunct": 9.173911335414372,
        "distinct-2-nopunct": 0.8161399843301123,
        "vocab_size-2-nopunct": 3125,
        "unique-2-nopunct": 2846,
        "entropy-2-nopunct": 11.303022875294158,
        "cond_entropy-2-nopunct": 2.2421433841820004,
        "distinct-3-nopunct": 0.9484273165202607,
        "vocab_size-3-nopunct": 3347,
        "unique-3-nopunct": 3230,
        "entropy-3-nopunct": 11.659633719205486,
        "cond_entropy-3-nopunct": 0.3827249446119738,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.63344022830886,
        "rouge1": {
            "precision": 0.79812,
            "recall": 0.7657,
            "fmeasure": 0.77204
        },
        "rouge2": {
            "precision": 0.57251,
            "recall": 0.55068,
            "fmeasure": 0.55388
        },
        "rougeL": {
            "precision": 0.69025,
            "recall": 0.66616,
            "fmeasure": 0.66947
        },
        "rougeLsum": {
            "precision": 0.69025,
            "recall": 0.66616,
            "fmeasure": 0.66947
        },
        "bleu": 46.94417,
        "local_recall": {
            "1": 0.17386231038506417,
            "2": 0.39820742637644047,
            "3": 0.8057926829268293
        },
        "bertscore": {
            "precision": 0.94087,
            "recall": 0.93806,
            "f1": 0.93826
        },
        "nubia": {
            "semantic_relation": 4.37909,
            "contradiction": 5.25325,
            "irrelevancy": 24.50744,
            "logical_agreement": 70.23932,
            "grammar_ref": 4.83962,
            "grammar_hyp": 4.87913,
            "nubia_score": 0.77513
        },
        "meteor": 0.4111067513994354,
        "bleurt": 0.36575
    },
    "totto_test_contrast_challenge_table_size-table_size_180": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.73429,
        "msttr-100_nopunct": 0.785,
        "total_length": 705,
        "mean_pred_length": 16.785714285714285,
        "std_pred_length": 5.110846143186051,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.5602836879432624,
        "vocab_size-1": 395,
        "unique-1": 326,
        "entropy-1": 7.699428905669038,
        "distinct-2": 0.9215686274509803,
        "vocab_size-2": 611,
        "unique-2": 577,
        "entropy-2": 9.181072427388639,
        "cond_entropy-2": 1.3025429911306217,
        "distinct-3": 0.9871175523349437,
        "vocab_size-3": 613,
        "unique-3": 606,
        "entropy-3": 9.25146896304786,
        "cond_entropy-3": 0.07692679423335005,
        "total_length-nopunct": 627,
        "mean_pred_length-nopunct": 14.928571428571429,
        "std_pred_length-nopunct": 4.757914995251682,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6220095693779905,
        "vocab_size-1-nopunct": 390,
        "unique-1-nopunct": 326,
        "entropy-1-nopunct": 7.86952022345829,
        "distinct-2-nopunct": 0.9213675213675213,
        "vocab_size-2-nopunct": 539,
        "unique-2-nopunct": 511,
        "entropy-2-nopunct": 8.995440651229574,
        "cond_entropy-2-nopunct": 1.2133951229709303,
        "distinct-3-nopunct": 0.9871086556169429,
        "vocab_size-3-nopunct": 536,
        "unique-3-nopunct": 530,
        "entropy-3-nopunct": 9.057635482643837,
        "cond_entropy-3-nopunct": 0.07742096558756928,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.140657182882309,
        "rouge1": {
            "precision": 0.78398,
            "recall": 0.78579,
            "fmeasure": 0.77576
        },
        "rouge2": {
            "precision": 0.60331,
            "recall": 0.60825,
            "fmeasure": 0.59843
        },
        "rougeL": {
            "precision": 0.70408,
            "recall": 0.71084,
            "fmeasure": 0.69782
        },
        "rougeLsum": {
            "precision": 0.70408,
            "recall": 0.71084,
            "fmeasure": 0.69782
        },
        "bleu": 53.63545,
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.5268817204301075,
            "3": 0.7995867768595041
        },
        "bertscore": {
            "precision": 0.9411,
            "recall": 0.94469,
            "f1": 0.94133
        },
        "nubia": {
            "semantic_relation": 4.3203,
            "contradiction": 12.15028,
            "irrelevancy": 25.93523,
            "logical_agreement": 61.91449,
            "grammar_ref": 4.60727,
            "grammar_hyp": 4.49247,
            "nubia_score": 0.76234
        },
        "meteor": 0.43991865107958994,
        "bleurt": 0.38689
    },
    "totto_test_contrast_challenge_table_size-table_size_152": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 24,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.775,
        "total_length": 331,
        "mean_pred_length": 13.791666666666666,
        "std_pred_length": 4.932706885901717,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.6193353474320241,
        "vocab_size-1": 205,
        "unique-1": 174,
        "entropy-1": 6.978415183780518,
        "distinct-2": 0.9641693811074918,
        "vocab_size-2": 296,
        "unique-2": 285,
        "entropy-2": 8.190433607585128,
        "cond_entropy-2": 0.9819617735222923,
        "distinct-3": 1.0,
        "vocab_size-3": 283,
        "unique-3": 283,
        "entropy-3": 8.14465824283186,
        "cond_entropy-3": -0.03969808663723703,
        "total_length-nopunct": 292,
        "mean_pred_length-nopunct": 12.166666666666666,
        "std_pred_length-nopunct": 4.687453703475078,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6883561643835616,
        "vocab_size-1-nopunct": 201,
        "unique-1-nopunct": 172,
        "entropy-1-nopunct": 7.150450545442687,
        "distinct-2-nopunct": 0.9626865671641791,
        "vocab_size-2-nopunct": 258,
        "unique-2-nopunct": 248,
        "entropy-2-nopunct": 7.991462324786099,
        "cond_entropy-2-nopunct": 0.922896019352789,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 244,
        "unique-3-nopunct": 244,
        "entropy-3-nopunct": 7.930737337562843,
        "cond_entropy-3-nopunct": -0.05338463978013234,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.514611710238883,
        "rouge1": {
            "precision": 0.78015,
            "recall": 0.6904,
            "fmeasure": 0.72505
        },
        "rouge2": {
            "precision": 0.54625,
            "recall": 0.48525,
            "fmeasure": 0.50842
        },
        "rougeL": {
            "precision": 0.73959,
            "recall": 0.64774,
            "fmeasure": 0.68313
        },
        "rougeLsum": {
            "precision": 0.73959,
            "recall": 0.64774,
            "fmeasure": 0.68313
        },
        "bleu": 44.21104,
        "local_recall": {
            "1": 0.10638297872340426,
            "2": 0.29069767441860467,
            "3": 0.7637130801687764
        },
        "bertscore": {
            "precision": 0.93712,
            "recall": 0.92673,
            "f1": 0.9307
        },
        "nubia": {
            "semantic_relation": 4.15109,
            "contradiction": 15.45993,
            "irrelevancy": 33.80082,
            "logical_agreement": 50.73925,
            "grammar_ref": 4.6818,
            "grammar_hyp": 4.94125,
            "nubia_score": 0.69011
        },
        "meteor": 0.3708193988590002,
        "bleurt": 0.23536
    },
    "totto_test_contrast_challenge_table_size-table_size_182": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.77,
        "total_length": 224,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.542047068934521,
        "median_pred_length": 15.5,
        "min_pred_length": 5,
        "max_pred_length": 29,
        "distinct-1": 0.6473214285714286,
        "vocab_size-1": 145,
        "unique-1": 119,
        "entropy-1": 6.686964043698739,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 204,
        "unique-2": 200,
        "entropy-2": 7.649913255740744,
        "cond_entropy-2": 0.783818275795411,
        "distinct-3": 0.9948979591836735,
        "vocab_size-3": 195,
        "unique-3": 194,
        "entropy-3": 7.60450576248254,
        "cond_entropy-3": -0.051016413324756246,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 14.214285714285714,
        "std_pred_length-nopunct": 4.783581614358063,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7085427135678392,
        "vocab_size-1-nopunct": 141,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.762186915070433,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 180,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.469166460492912,
        "cond_entropy-2-nopunct": 0.7506130744775381,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 171,
        "unique-3-nopunct": 171,
        "entropy-3-nopunct": 7.417852514885889,
        "cond_entropy-3-nopunct": -0.06475789298196591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.577010083600819,
        "rouge1": {
            "precision": 0.78921,
            "recall": 0.73721,
            "fmeasure": 0.75387
        },
        "rouge2": {
            "precision": 0.54389,
            "recall": 0.51299,
            "fmeasure": 0.52046
        },
        "rougeL": {
            "precision": 0.68436,
            "recall": 0.63124,
            "fmeasure": 0.64841
        },
        "rougeLsum": {
            "precision": 0.68436,
            "recall": 0.63124,
            "fmeasure": 0.64841
        },
        "bleu": 44.94242,
        "local_recall": {
            "1": 0.19672131147540983,
            "2": 0.5142857142857142,
            "3": 0.7295597484276729
        },
        "bertscore": {
            "precision": 0.93711,
            "recall": 0.92424,
            "f1": 0.92834
        },
        "nubia": {
            "semantic_relation": 4.45255,
            "contradiction": 3.03347,
            "irrelevancy": 20.56813,
            "logical_agreement": 76.39841,
            "grammar_ref": 4.54419,
            "grammar_hyp": 4.56595,
            "nubia_score": 0.81202
        },
        "meteor": 0.38219205375692833,
        "bleurt": 0.37211
    },
    "totto_test_contrast_challenge_table_size-table_size_153": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.69,
        "total_length": 148,
        "mean_pred_length": 13.454545454545455,
        "std_pred_length": 2.3496087242400154,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 18,
        "distinct-1": 0.6283783783783784,
        "vocab_size-1": 93,
        "unique-1": 68,
        "entropy-1": 6.152026204960809,
        "distinct-2": 0.8832116788321168,
        "vocab_size-2": 121,
        "unique-2": 105,
        "entropy-2": 6.864455440624746,
        "cond_entropy-2": 0.5195675638562081,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 117,
        "unique-3": 108,
        "entropy-3": 6.834422780642783,
        "cond_entropy-3": -0.02551406422251495,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 12.181818181818182,
        "std_pred_length-nopunct": 2.442732516826255,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.664179104477612,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.182167757816921,
        "distinct-2-nopunct": 0.8780487804878049,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.6986120663148405,
        "cond_entropy-2-nopunct": 0.5338278309233637,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 104,
        "unique-3-nopunct": 96,
        "entropy-3-nopunct": 6.664497779200449,
        "cond_entropy-3-nopunct": -0.036945297567349926,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6014689581900825,
        "rouge1": {
            "precision": 0.6273,
            "recall": 0.63516,
            "fmeasure": 0.62301
        },
        "rouge2": {
            "precision": 0.38878,
            "recall": 0.39404,
            "fmeasure": 0.385
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.57274,
            "fmeasure": 0.56129
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.57274,
            "fmeasure": 0.56129
        },
        "bleu": 32.22517,
        "local_recall": {
            "1": 0.35555555555555557,
            "2": 0.1724137931034483,
            "3": 0.6881720430107527
        },
        "bertscore": {
            "precision": 0.90187,
            "recall": 0.9003,
            "f1": 0.89919
        },
        "nubia": {
            "semantic_relation": 4.01023,
            "contradiction": 21.18308,
            "irrelevancy": 41.26993,
            "logical_agreement": 37.54699,
            "grammar_ref": 5.00152,
            "grammar_hyp": 4.61366,
            "nubia_score": 0.67006
        },
        "meteor": 0.32660921455818875,
        "bleurt": 0.16148
    },
    "totto_test_contrast_challenge_table_size-table_size_112": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 47,
        "msttr-100": 0.69875,
        "msttr-100_nopunct": 0.75857,
        "total_length": 822,
        "mean_pred_length": 17.48936170212766,
        "std_pred_length": 4.958862002368414,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.5267639902676399,
        "vocab_size-1": 433,
        "unique-1": 353,
        "entropy-1": 7.6226806465932775,
        "distinct-2": 0.8993548387096775,
        "vocab_size-2": 697,
        "unique-2": 645,
        "entropy-2": 9.343441774313263,
        "cond_entropy-2": 1.5339136681131729,
        "distinct-3": 0.9601648351648352,
        "vocab_size-3": 699,
        "unique-3": 671,
        "entropy-3": 9.427087377146288,
        "cond_entropy-3": 0.09080469158671933,
        "total_length-nopunct": 714,
        "mean_pred_length-nopunct": 15.191489361702128,
        "std_pred_length-nopunct": 4.634001523761861,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.5966386554621849,
        "vocab_size-1-nopunct": 426,
        "unique-1-nopunct": 351,
        "entropy-1-nopunct": 7.850767263329292,
        "distinct-2-nopunct": 0.9025487256371814,
        "vocab_size-2-nopunct": 602,
        "unique-2-nopunct": 558,
        "entropy-2-nopunct": 9.131815177525985,
        "cond_entropy-2-nopunct": 1.3727589990694937,
        "distinct-3-nopunct": 0.9629032258064516,
        "vocab_size-3-nopunct": 597,
        "unique-3-nopunct": 574,
        "entropy-3-nopunct": 9.201930856887161,
        "cond_entropy-3-nopunct": 0.07936923639656956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.0460572306767375,
        "rouge1": {
            "precision": 0.78098,
            "recall": 0.76379,
            "fmeasure": 0.75871
        },
        "rouge2": {
            "precision": 0.56621,
            "recall": 0.55152,
            "fmeasure": 0.54894
        },
        "rougeL": {
            "precision": 0.68574,
            "recall": 0.67612,
            "fmeasure": 0.66959
        },
        "rougeLsum": {
            "precision": 0.68574,
            "recall": 0.67612,
            "fmeasure": 0.66959
        },
        "bleu": 50.8012,
        "local_recall": {
            "1": 0.2265625,
            "2": 0.4186046511627907,
            "3": 0.7909090909090909
        },
        "bertscore": {
            "precision": 0.93454,
            "recall": 0.93086,
            "f1": 0.93181
        },
        "nubia": {
            "semantic_relation": 4.25285,
            "contradiction": 5.51246,
            "irrelevancy": 27.40383,
            "logical_agreement": 67.0837,
            "grammar_ref": 4.39993,
            "grammar_hyp": 4.27471,
            "nubia_score": 0.76576
        },
        "meteor": 0.41681006319340425,
        "bleurt": 0.32257
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 369,
        "msttr-100": 0.64486,
        "msttr-100_nopunct": 0.69129,
        "total_length": 3543,
        "mean_pred_length": 9.601626016260163,
        "std_pred_length": 2.5302714832277085,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 18,
        "distinct-1": 0.222692633361558,
        "vocab_size-1": 789,
        "unique-1": 436,
        "entropy-1": 7.53203506595662,
        "distinct-2": 0.5396975425330813,
        "vocab_size-2": 1713,
        "unique-2": 1206,
        "entropy-2": 10.178519190610228,
        "cond_entropy-2": 2.14975702116391,
        "distinct-3": 0.7290552584670231,
        "vocab_size-3": 2045,
        "unique-3": 1667,
        "entropy-3": 10.734372009626183,
        "cond_entropy-3": 0.6520257464655711,
        "total_length-nopunct": 3102,
        "mean_pred_length-nopunct": 8.40650406504065,
        "std_pred_length-nopunct": 2.335669208399915,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.25177304964539005,
        "vocab_size-1-nopunct": 781,
        "unique-1-nopunct": 434,
        "entropy-1-nopunct": 7.84573138760178,
        "distinct-2-nopunct": 0.5151847786315404,
        "vocab_size-2-nopunct": 1408,
        "unique-2-nopunct": 968,
        "entropy-2-nopunct": 9.857479898784232,
        "cond_entropy-2-nopunct": 2.3222288734276186,
        "distinct-3-nopunct": 0.7157360406091371,
        "vocab_size-3-nopunct": 1692,
        "unique-3-nopunct": 1365,
        "entropy-3-nopunct": 10.444335623779331,
        "cond_entropy-3-nopunct": 0.7120990747730775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 9.36468880371995,
        "rouge1": {
            "precision": 0.83869,
            "recall": 0.79784,
            "fmeasure": 0.81068
        },
        "rouge2": {
            "precision": 0.62563,
            "recall": 0.59222,
            "fmeasure": 0.60258
        },
        "rougeL": {
            "precision": 0.75858,
            "recall": 0.72169,
            "fmeasure": 0.73296
        },
        "rougeLsum": {
            "precision": 0.75858,
            "recall": 0.72169,
            "fmeasure": 0.73296
        },
        "bleu": 63.35175,
        "local_recall": {
            "1": 0.2288135593220339,
            "2": 0.6794453507340946,
            "3": 0.8824701195219123,
            "4": 0.9736842105263158
        },
        "bertscore": {
            "precision": 0.95248,
            "recall": 0.94916,
            "f1": 0.95002
        },
        "nubia": {
            "semantic_relation": 4.59456,
            "contradiction": 6.57264,
            "irrelevancy": 7.27003,
            "logical_agreement": 86.15733,
            "grammar_ref": 5.18632,
            "grammar_hyp": 5.3067,
            "nubia_score": 0.83443
        },
        "meteor": 0.4698868187423942,
        "bleurt": 0.41166
    },
    "totto_test_contrast_challenge_table_size-table_size_130": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.756,
        "msttr-100_nopunct": 0.792,
        "total_length": 594,
        "mean_pred_length": 19.161290322580644,
        "std_pred_length": 5.775905314843326,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.563973063973064,
        "vocab_size-1": 335,
        "unique-1": 262,
        "entropy-1": 7.638461989398737,
        "distinct-2": 0.9005328596802842,
        "vocab_size-2": 507,
        "unique-2": 466,
        "entropy-2": 8.911425004691765,
        "cond_entropy-2": 1.1580427152571722,
        "distinct-3": 0.9605263157894737,
        "vocab_size-3": 511,
        "unique-3": 492,
        "entropy-3": 8.973497144139772,
        "cond_entropy-3": 0.07145663066788548,
        "total_length-nopunct": 521,
        "mean_pred_length-nopunct": 16.806451612903224,
        "std_pred_length-nopunct": 5.220427339068843,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6314779270633397,
        "vocab_size-1-nopunct": 329,
        "unique-1-nopunct": 262,
        "entropy-1-nopunct": 7.797862646259543,
        "distinct-2-nopunct": 0.9061224489795918,
        "vocab_size-2-nopunct": 444,
        "unique-2-nopunct": 411,
        "entropy-2-nopunct": 8.721364585012056,
        "cond_entropy-2-nopunct": 0.9694933864917497,
        "distinct-3-nopunct": 0.9694989106753813,
        "vocab_size-3-nopunct": 445,
        "unique-3-nopunct": 432,
        "entropy-3-nopunct": 8.779703529683706,
        "cond_entropy-3-nopunct": 0.06852080518073723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.210004216063344,
        "rouge1": {
            "precision": 0.81629,
            "recall": 0.75572,
            "fmeasure": 0.77942
        },
        "rouge2": {
            "precision": 0.5921,
            "recall": 0.55798,
            "fmeasure": 0.57039
        },
        "rougeL": {
            "precision": 0.7139,
            "recall": 0.66543,
            "fmeasure": 0.68327
        },
        "rougeLsum": {
            "precision": 0.7139,
            "recall": 0.66543,
            "fmeasure": 0.68327
        },
        "bleu": 52.37107,
        "local_recall": {
            "1": 0.35514018691588783,
            "2": 0.3670886075949367,
            "3": 0.7855477855477856
        },
        "bertscore": {
            "precision": 0.94187,
            "recall": 0.93714,
            "f1": 0.93875
        },
        "nubia": {
            "semantic_relation": 4.25957,
            "contradiction": 6.33292,
            "irrelevancy": 28.07173,
            "logical_agreement": 65.59535,
            "grammar_ref": 4.57329,
            "grammar_hyp": 4.77231,
            "nubia_score": 0.73096
        },
        "meteor": 0.4217240611772433,
        "bleurt": 0.25703
    },
    "totto_test_contrast_challenge_table_size-table_size_183": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.965962168790184,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.28571,
            "fmeasure": 0.28571
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.625,
            "fmeasure": 0.625
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.625,
            "fmeasure": 0.625
        },
        "bleu": 16.03659,
        "local_recall": {
            "1": 0.2,
            "2": 0.3333333333333333,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.93788,
            "recall": 0.94253,
            "f1": 0.9402
        },
        "nubia": {
            "semantic_relation": 4.57638,
            "contradiction": 0.15278,
            "irrelevancy": 1.33726,
            "logical_agreement": 98.50996,
            "grammar_ref": 4.0172,
            "grammar_hyp": 3.52783,
            "nubia_score": 0.98526
        },
        "meteor": 0.3876739285978294,
        "bleurt": 0.28678
    },
    "totto_test_contrast_challenge_table_size-table_size_28": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 77,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.76818,
        "total_length": 1270,
        "mean_pred_length": 16.493506493506494,
        "std_pred_length": 4.966441608431316,
        "median_pred_length": 16.0,
        "min_pred_length": 7,
        "max_pred_length": 30,
        "distinct-1": 0.48661417322834644,
        "vocab_size-1": 618,
        "unique-1": 499,
        "entropy-1": 7.984326053005982,
        "distinct-2": 0.8692372170997485,
        "vocab_size-2": 1037,
        "unique-2": 956,
        "entropy-2": 9.868090104222741,
        "cond_entropy-2": 1.6603413436450465,
        "distinct-3": 0.9471326164874552,
        "vocab_size-3": 1057,
        "unique-3": 1025,
        "entropy-3": 9.989224056054992,
        "cond_entropy-3": 0.11397156628449374,
        "total_length-nopunct": 1112,
        "mean_pred_length-nopunct": 14.441558441558442,
        "std_pred_length-nopunct": 4.680696769347976,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5467625899280576,
        "vocab_size-1-nopunct": 608,
        "unique-1-nopunct": 496,
        "entropy-1-nopunct": 8.201407880096468,
        "distinct-2-nopunct": 0.8869565217391304,
        "vocab_size-2-nopunct": 918,
        "unique-2-nopunct": 859,
        "entropy-2-nopunct": 9.707399683162238,
        "cond_entropy-2-nopunct": 1.607705263180717,
        "distinct-3-nopunct": 0.9582463465553236,
        "vocab_size-3-nopunct": 918,
        "unique-3-nopunct": 894,
        "entropy-3-nopunct": 9.802696358293982,
        "cond_entropy-3-nopunct": 0.10374703663428092,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.539471906344377,
        "rouge1": {
            "precision": 0.77264,
            "recall": 0.74978,
            "fmeasure": 0.75221
        },
        "rouge2": {
            "precision": 0.53695,
            "recall": 0.51943,
            "fmeasure": 0.52144
        },
        "rougeL": {
            "precision": 0.66578,
            "recall": 0.65,
            "fmeasure": 0.65011
        },
        "rougeLsum": {
            "precision": 0.66578,
            "recall": 0.65,
            "fmeasure": 0.65011
        },
        "bleu": 48.7357,
        "local_recall": {
            "1": 0.24124513618677043,
            "2": 0.47674418604651164,
            "3": 0.7984395318595578
        },
        "bertscore": {
            "precision": 0.93172,
            "recall": 0.92952,
            "f1": 0.9293
        },
        "nubia": {
            "semantic_relation": 4.19328,
            "contradiction": 5.84273,
            "irrelevancy": 30.70595,
            "logical_agreement": 63.45131,
            "grammar_ref": 4.69344,
            "grammar_hyp": 4.6463,
            "nubia_score": 0.7284
        },
        "meteor": 0.40723963119747847,
        "bleurt": 0.26313
    },
    "totto_test_contrast_challenge_table_size-table_size_154": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.75,
        "total_length": 243,
        "mean_pred_length": 14.294117647058824,
        "std_pred_length": 4.011229910878193,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.6008230452674898,
        "vocab_size-1": 146,
        "unique-1": 120,
        "entropy-1": 6.588702772343732,
        "distinct-2": 0.9424778761061947,
        "vocab_size-2": 213,
        "unique-2": 203,
        "entropy-2": 7.689162854121245,
        "cond_entropy-2": 0.8934998920880914,
        "distinct-3": 0.9856459330143541,
        "vocab_size-3": 206,
        "unique-3": 203,
        "entropy-3": 7.6786509981096085,
        "cond_entropy-3": -0.018993799356138145,
        "total_length-nopunct": 218,
        "mean_pred_length-nopunct": 12.823529411764707,
        "std_pred_length-nopunct": 3.929306092274055,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6605504587155964,
        "vocab_size-1-nopunct": 144,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 6.7076898458988445,
        "distinct-2-nopunct": 0.9502487562189055,
        "vocab_size-2-nopunct": 191,
        "unique-2-nopunct": 184,
        "entropy-2-nopunct": 7.533590793296169,
        "cond_entropy-2-nopunct": 0.8741027192283636,
        "distinct-3-nopunct": 0.9945652173913043,
        "vocab_size-3-nopunct": 183,
        "unique-3-nopunct": 182,
        "entropy-3-nopunct": 7.512692390839635,
        "cond_entropy-3-nopunct": -0.020915602108672358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.057973049622572,
        "rouge1": {
            "precision": 0.65161,
            "recall": 0.61795,
            "fmeasure": 0.628
        },
        "rouge2": {
            "precision": 0.39535,
            "recall": 0.37454,
            "fmeasure": 0.38085
        },
        "rougeL": {
            "precision": 0.58117,
            "recall": 0.54428,
            "fmeasure": 0.55499
        },
        "rougeLsum": {
            "precision": 0.58117,
            "recall": 0.54428,
            "fmeasure": 0.55499
        },
        "bleu": 35.14904,
        "local_recall": {
            "1": 0.1527777777777778,
            "2": 0.36065573770491804,
            "3": 0.6583850931677019
        },
        "bertscore": {
            "precision": 0.91534,
            "recall": 0.90952,
            "f1": 0.91198
        },
        "nubia": {
            "semantic_relation": 4.05882,
            "contradiction": 11.38021,
            "irrelevancy": 43.71846,
            "logical_agreement": 44.90133,
            "grammar_ref": 4.51289,
            "grammar_hyp": 4.57954,
            "nubia_score": 0.68365
        },
        "meteor": 0.332619856028881,
        "bleurt": 0.19494
    },
    "totto_test_contrast_challenge_table_size-table_size_29": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 14.857142857142858,
        "std_pred_length": 8.13157112614726,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 72,
        "unique-1": 56,
        "entropy-1": 5.8705958477199625,
        "distinct-2": 0.979381443298969,
        "vocab_size-2": 95,
        "unique-2": 93,
        "entropy-2": 6.558675728785079,
        "cond_entropy-2": 0.6147200314706996,
        "distinct-3": 1.0,
        "vocab_size-3": 90,
        "unique-3": 90,
        "entropy-3": 6.491853096329662,
        "cond_entropy-3": -0.06361530141300877,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 7.8636336825845055,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 69,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.857429211327192,
        "distinct-2-nopunct": 0.9764705882352941,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 81,
        "entropy-2-nopunct": 6.3623321126082955,
        "cond_entropy-2-nopunct": 0.5479961861412099,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 78,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.285402218862257,
        "cond_entropy-3-nopunct": -0.0855271788139149,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3071404749863085,
        "rouge1": {
            "precision": 0.76842,
            "recall": 0.70084,
            "fmeasure": 0.71674
        },
        "rouge2": {
            "precision": 0.59721,
            "recall": 0.5301,
            "fmeasure": 0.54965
        },
        "rougeL": {
            "precision": 0.71988,
            "recall": 0.65338,
            "fmeasure": 0.67081
        },
        "rougeLsum": {
            "precision": 0.71988,
            "recall": 0.65338,
            "fmeasure": 0.67081
        },
        "bleu": 39.92083,
        "local_recall": {
            "1": 0.29411764705882354,
            "2": 0.4827586206896552,
            "3": 0.6610169491525424
        },
        "bertscore": {
            "precision": 0.91824,
            "recall": 0.90472,
            "f1": 0.91079
        },
        "nubia": {
            "semantic_relation": 4.1257,
            "contradiction": 15.99124,
            "irrelevancy": 18.06259,
            "logical_agreement": 65.94617,
            "grammar_ref": 4.56703,
            "grammar_hyp": 4.66597,
            "nubia_score": 0.69274
        },
        "meteor": 0.31190547461696383,
        "bleurt": 0.1825
    },
    "totto_test_contrast_challenge_table_size-table_size_114": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 28,
        "msttr-100": 0.7375,
        "msttr-100_nopunct": 0.7875,
        "total_length": 475,
        "mean_pred_length": 16.964285714285715,
        "std_pred_length": 4.483956662027274,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6063157894736843,
        "vocab_size-1": 288,
        "unique-1": 242,
        "entropy-1": 7.377678614404649,
        "distinct-2": 0.9373601789709173,
        "vocab_size-2": 419,
        "unique-2": 403,
        "entropy-2": 8.63585522487715,
        "cond_entropy-2": 1.0932963817082244,
        "distinct-3": 0.9952267303102625,
        "vocab_size-3": 417,
        "unique-3": 415,
        "entropy-3": 8.701259894319863,
        "cond_entropy-3": 0.0766498300551116,
        "total_length-nopunct": 427,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.14578098794425,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6651053864168618,
        "vocab_size-1-nopunct": 284,
        "unique-1-nopunct": 242,
        "entropy-1-nopunct": 7.510675704265695,
        "distinct-2-nopunct": 0.9373433583959899,
        "vocab_size-2-nopunct": 374,
        "unique-2-nopunct": 361,
        "entropy-2-nopunct": 8.466763029082284,
        "cond_entropy-2-nopunct": 1.0347030229367764,
        "distinct-3-nopunct": 0.9973045822102425,
        "vocab_size-3-nopunct": 370,
        "unique-3-nopunct": 369,
        "entropy-3-nopunct": 8.529884541041218,
        "cond_entropy-3-nopunct": 0.07621448608275316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.1620225121369145,
        "rouge1": {
            "precision": 0.75711,
            "recall": 0.67756,
            "fmeasure": 0.70254
        },
        "rouge2": {
            "precision": 0.5293,
            "recall": 0.49343,
            "fmeasure": 0.50217
        },
        "rougeL": {
            "precision": 0.66457,
            "recall": 0.60857,
            "fmeasure": 0.62387
        },
        "rougeLsum": {
            "precision": 0.66457,
            "recall": 0.60857,
            "fmeasure": 0.62387
        },
        "bleu": 44.93144,
        "local_recall": {
            "1": 0.1282051282051282,
            "2": 0.5066666666666667,
            "3": 0.7076023391812866
        },
        "bertscore": {
            "precision": 0.91921,
            "recall": 0.9109,
            "f1": 0.91208
        },
        "nubia": {
            "semantic_relation": 4.03014,
            "contradiction": 7.63895,
            "irrelevancy": 30.58372,
            "logical_agreement": 61.77733,
            "grammar_ref": 4.55489,
            "grammar_hyp": 4.59195,
            "nubia_score": 0.69449
        },
        "meteor": 0.360478030915109,
        "bleurt": 0.19164
    },
    "totto_test_contrast_challenge_table_size-table_size_155": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.785,
        "total_length": 294,
        "mean_pred_length": 17.294117647058822,
        "std_pred_length": 6.559812639741482,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.5986394557823129,
        "vocab_size-1": 176,
        "unique-1": 144,
        "entropy-1": 6.847969519241738,
        "distinct-2": 0.9061371841155235,
        "vocab_size-2": 251,
        "unique-2": 230,
        "entropy-2": 7.910620640755038,
        "cond_entropy-2": 0.934043139928322,
        "distinct-3": 0.9538461538461539,
        "vocab_size-3": 248,
        "unique-3": 238,
        "entropy-3": 7.924253293781042,
        "cond_entropy-3": 0.026913675833741064,
        "total_length-nopunct": 246,
        "mean_pred_length-nopunct": 14.470588235294118,
        "std_pred_length-nopunct": 4.628780134801413,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6951219512195121,
        "vocab_size-1-nopunct": 171,
        "unique-1-nopunct": 143,
        "entropy-1-nopunct": 7.013914290477818,
        "distinct-2-nopunct": 0.9344978165938864,
        "vocab_size-2-nopunct": 214,
        "unique-2-nopunct": 200,
        "entropy-2-nopunct": 7.704902969310206,
        "cond_entropy-2-nopunct": 0.7555572537347875,
        "distinct-3-nopunct": 0.9716981132075472,
        "vocab_size-3-nopunct": 206,
        "unique-3-nopunct": 200,
        "entropy-3-nopunct": 7.671316680978306,
        "cond_entropy-3-nopunct": -0.022816883051841697,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.851792723991065,
        "rouge1": {
            "precision": 0.81241,
            "recall": 0.77256,
            "fmeasure": 0.78117
        },
        "rouge2": {
            "precision": 0.61093,
            "recall": 0.59738,
            "fmeasure": 0.59666
        },
        "rougeL": {
            "precision": 0.68034,
            "recall": 0.65324,
            "fmeasure": 0.6588
        },
        "rougeLsum": {
            "precision": 0.68034,
            "recall": 0.65324,
            "fmeasure": 0.6588
        },
        "bleu": 59.0819,
        "local_recall": {
            "1": 0.23404255319148937,
            "2": 0.3157894736842105,
            "3": 0.8064516129032258
        },
        "bertscore": {
            "precision": 0.94558,
            "recall": 0.93902,
            "f1": 0.94093
        },
        "nubia": {
            "semantic_relation": 4.48351,
            "contradiction": 1.96649,
            "irrelevancy": 14.61979,
            "logical_agreement": 83.41372,
            "grammar_ref": 4.52442,
            "grammar_hyp": 4.55076,
            "nubia_score": 0.82174
        },
        "meteor": 0.4645101282133882,
        "bleurt": 0.39902
    },
    "totto_test_contrast_challenge_table_size-table_size_184": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.68667,
        "msttr-100_nopunct": 0.685,
        "total_length": 325,
        "mean_pred_length": 18.055555555555557,
        "std_pred_length": 6.2403011165080295,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.5476923076923077,
        "vocab_size-1": 178,
        "unique-1": 140,
        "entropy-1": 6.709584804530029,
        "distinct-2": 0.8664495114006515,
        "vocab_size-2": 266,
        "unique-2": 244,
        "entropy-2": 7.9163653160951615,
        "cond_entropy-2": 1.0889949655072397,
        "distinct-3": 0.9377162629757786,
        "vocab_size-3": 271,
        "unique-3": 257,
        "entropy-3": 8.035256035522805,
        "cond_entropy-3": 0.14042404651049,
        "total_length-nopunct": 281,
        "mean_pred_length-nopunct": 15.61111111111111,
        "std_pred_length-nopunct": 5.261378029131921,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.604982206405694,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 137,
        "entropy-1-nopunct": 6.7241509104676105,
        "distinct-2-nopunct": 0.8593155893536122,
        "vocab_size-2-nopunct": 226,
        "unique-2-nopunct": 207,
        "entropy-2-nopunct": 7.668637323949156,
        "cond_entropy-2-nopunct": 1.0235738464656965,
        "distinct-3-nopunct": 0.9346938775510204,
        "vocab_size-3-nopunct": 229,
        "unique-3-nopunct": 217,
        "entropy-3-nopunct": 7.788211294200153,
        "cond_entropy-3-nopunct": 0.14269670484763072,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.566888863503423,
        "rouge1": {
            "precision": 0.7793,
            "recall": 0.76566,
            "fmeasure": 0.75963
        },
        "rouge2": {
            "precision": 0.60342,
            "recall": 0.58356,
            "fmeasure": 0.58304
        },
        "rougeL": {
            "precision": 0.74468,
            "recall": 0.71421,
            "fmeasure": 0.71851
        },
        "rougeLsum": {
            "precision": 0.74468,
            "recall": 0.71421,
            "fmeasure": 0.71851
        },
        "bleu": 57.05797,
        "local_recall": {
            "1": 0.45454545454545453,
            "2": 0.29411764705882354,
            "3": 0.759825327510917
        },
        "bertscore": {
            "precision": 0.93792,
            "recall": 0.93952,
            "f1": 0.93802
        },
        "nubia": {
            "semantic_relation": 4.3762,
            "contradiction": 5.71909,
            "irrelevancy": 28.24545,
            "logical_agreement": 66.03546,
            "grammar_ref": 4.5077,
            "grammar_hyp": 4.34099,
            "nubia_score": 0.79504
        },
        "meteor": 0.4263455549503265,
        "bleurt": 0.32036
    },
    "totto_test_contrast_challenge_gender-female": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 300,
        "msttr-100": 0.6954,
        "msttr-100_nopunct": 0.73841,
        "total_length": 5047,
        "mean_pred_length": 16.823333333333334,
        "std_pred_length": 5.076625081904535,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.3677432137903705,
        "vocab_size-1": 1856,
        "unique-1": 1492,
        "entropy-1": 8.504077374029968,
        "distinct-2": 0.7356224984200548,
        "vocab_size-2": 3492,
        "unique-2": 3147,
        "entropy-2": 11.225513663003401,
        "cond_entropy-2": 2.4840359776255405,
        "distinct-3": 0.8909377108162806,
        "vocab_size-3": 3962,
        "unique-3": 3764,
        "entropy-3": 11.800291827200281,
        "cond_entropy-3": 0.5945033523704916,
        "total_length-nopunct": 4444,
        "mean_pred_length-nopunct": 14.813333333333333,
        "std_pred_length-nopunct": 4.824087708802797,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4153915391539154,
        "vocab_size-1-nopunct": 1846,
        "unique-1-nopunct": 1488,
        "entropy-1-nopunct": 8.816866398961134,
        "distinct-2-nopunct": 0.7550675675675675,
        "vocab_size-2-nopunct": 3129,
        "unique-2-nopunct": 2860,
        "entropy-2-nopunct": 11.070037058942626,
        "cond_entropy-2-nopunct": 2.402135668191087,
        "distinct-3-nopunct": 0.9107700312174818,
        "vocab_size-3-nopunct": 3501,
        "unique-3-nopunct": 3348,
        "entropy-3-nopunct": 11.656094523587964,
        "cond_entropy-3-nopunct": 0.6474866385711696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.674654394825629,
        "rouge1": {
            "precision": 0.81987,
            "recall": 0.76189,
            "fmeasure": 0.7809
        },
        "rouge2": {
            "precision": 0.57995,
            "recall": 0.53918,
            "fmeasure": 0.55243
        },
        "rougeL": {
            "precision": 0.70713,
            "recall": 0.65721,
            "fmeasure": 0.67346
        },
        "rougeLsum": {
            "precision": 0.70713,
            "recall": 0.65721,
            "fmeasure": 0.67346
        },
        "bleu": 47.30251,
        "local_recall": {
            "1": 0.188422247446084,
            "2": 0.3545197740112994,
            "3": 0.7914409534127844
        },
        "bertscore": {
            "precision": 0.94339,
            "recall": 0.93549,
            "f1": 0.93825
        },
        "nubia": {
            "semantic_relation": 4.40954,
            "contradiction": 5.69804,
            "irrelevancy": 23.94402,
            "logical_agreement": 70.35793,
            "grammar_ref": 4.91577,
            "grammar_hyp": 4.98576,
            "nubia_score": 0.76819
        },
        "meteor": 0.40487573548403044,
        "bleurt": 0.34009
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 986,
        "msttr-100": 0.32488,
        "msttr-100_nopunct": 0.50234,
        "total_length": 12342,
        "mean_pred_length": 12.517241379310345,
        "std_pred_length": 8.239826039474556,
        "median_pred_length": 12.0,
        "min_pred_length": 0,
        "max_pred_length": 60,
        "distinct-1": 0.13109706692594394,
        "vocab_size-1": 1618,
        "unique-1": 812,
        "entropy-1": 6.492249398036174,
        "distinct-2": 0.2800035220568812,
        "vocab_size-2": 3180,
        "unique-2": 1610,
        "entropy-2": 10.41866814747451,
        "cond_entropy-2": 4.147711251764302,
        "distinct-3": 0.4244029275808937,
        "vocab_size-3": 4407,
        "unique-3": 2674,
        "entropy-3": 11.27560026152431,
        "cond_entropy-3": 0.9648959451916757,
        "total_length-nopunct": 6409,
        "mean_pred_length-nopunct": 6.5,
        "std_pred_length-nopunct": 4.491201676047181,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.2498049617725074,
        "vocab_size-1-nopunct": 1601,
        "unique-1-nopunct": 807,
        "entropy-1-nopunct": 9.238675253090339,
        "distinct-2-nopunct": 0.5476322093237516,
        "vocab_size-2-nopunct": 2972,
        "unique-2-nopunct": 1986,
        "entropy-2-nopunct": 11.042065707749867,
        "cond_entropy-2-nopunct": 1.9863029250666344,
        "distinct-3-nopunct": 0.6685664182376151,
        "vocab_size-3-nopunct": 3050,
        "unique-3-nopunct": 2286,
        "entropy-3-nopunct": 11.254554094172079,
        "cond_entropy-3-nopunct": 0.3347631891171855,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.44711681048548385,
        "rouge1": {
            "precision": 0.07143,
            "recall": 0.20906,
            "fmeasure": 0.09379
        },
        "rouge2": {
            "precision": 0.0241,
            "recall": 0.06315,
            "fmeasure": 0.0295
        },
        "rougeL": {
            "precision": 0.06876,
            "recall": 0.20178,
            "fmeasure": 0.09011
        },
        "rougeLsum": {
            "precision": 0.06876,
            "recall": 0.20178,
            "fmeasure": 0.09011
        },
        "bleu": 0.45425,
        "local_recall": {
            "1": 0.005721291377196567,
            "2": 0.013086150490730643,
            "3": 0.021317011397214015,
            "4": 0.1038961038961039,
            "5": 0.02702702702702703,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.60304,
            "recall": 0.52732,
            "f1": 0.56117
        },
        "nubia": {
            "semantic_relation": 2.2817,
            "contradiction": 34.71789,
            "irrelevancy": 34.2736,
            "logical_agreement": 31.00851,
            "grammar_ref": 2.66553,
            "grammar_hyp": 5.08238,
            "nubia_score": 0.2346
        },
        "meteor": 0.022308121961092997,
        "bleurt": -1.30315
    },
    "web_nlg_ru_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 116,
        "msttr-100": 0.284,
        "msttr-100_nopunct": 0.44286,
        "total_length": 1597,
        "mean_pred_length": 13.767241379310345,
        "std_pred_length": 4.841198481248158,
        "median_pred_length": 13.5,
        "min_pred_length": 4,
        "max_pred_length": 28,
        "distinct-1": 0.16217908578584847,
        "vocab_size-1": 259,
        "unique-1": 120,
        "entropy-1": 5.308430409610953,
        "distinct-2": 0.34233625928426736,
        "vocab_size-2": 507,
        "unique-2": 237,
        "entropy-2": 8.219267174348367,
        "cond_entropy-2": 3.0333881466811956,
        "distinct-3": 0.46373626373626375,
        "vocab_size-3": 633,
        "unique-3": 369,
        "entropy-3": 8.691978917447743,
        "cond_entropy-3": 0.5360942286827987,
        "total_length-nopunct": 785,
        "mean_pred_length-nopunct": 6.767241379310345,
        "std_pred_length-nopunct": 2.6663864175964678,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.32229299363057323,
        "vocab_size-1-nopunct": 253,
        "unique-1-nopunct": 120,
        "entropy-1-nopunct": 7.227128743017619,
        "distinct-2-nopunct": 0.5994020926756353,
        "vocab_size-2-nopunct": 401,
        "unique-2-nopunct": 269,
        "entropy-2-nopunct": 8.307261967190861,
        "cond_entropy-2-nopunct": 1.1831573493229506,
        "distinct-3-nopunct": 0.7396021699819169,
        "vocab_size-3-nopunct": 409,
        "unique-3-nopunct": 314,
        "entropy-3-nopunct": 8.490689282534582,
        "cond_entropy-3-nopunct": 0.24820332859313365,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.1354138029615728,
        "rouge1": {
            "precision": 0.00625,
            "recall": 0.04454,
            "fmeasure": 0.0108
        },
        "rouge2": {
            "precision": 0.00236,
            "recall": 0.02299,
            "fmeasure": 0.00426
        },
        "rougeL": {
            "precision": 0.00625,
            "recall": 0.04454,
            "fmeasure": 0.0108
        },
        "rougeLsum": {
            "precision": 0.00625,
            "recall": 0.04454,
            "fmeasure": 0.0108
        },
        "bleu": 0.06847,
        "local_recall": {
            "1": 0.0,
            "2": 0.003537735849056604,
            "3": 0.0
        },
        "bertscore": {
            "precision": 0.58031,
            "recall": 0.5259,
            "f1": 0.55077
        },
        "nubia": {
            "semantic_relation": 2.53102,
            "contradiction": 31.4519,
            "irrelevancy": 30.74443,
            "logical_agreement": 37.80367,
            "grammar_ref": 2.53819,
            "grammar_hyp": 4.38316,
            "nubia_score": 0.26959
        },
        "meteor": 0.009399998135025041,
        "bleurt": -1.27484
    },
    "totto_test_contrast_challenge_table_size-table_size_185": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 105,
        "mean_pred_length": 13.125,
        "std_pred_length": 1.3635890143294642,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.7047619047619048,
        "vocab_size-1": 74,
        "unique-1": 59,
        "entropy-1": 5.915442632133476,
        "distinct-2": 0.9381443298969072,
        "vocab_size-2": 91,
        "unique-2": 85,
        "entropy-2": 6.476201501980957,
        "cond_entropy-2": 0.37921683978829596,
        "distinct-3": 0.9438202247191011,
        "vocab_size-3": 84,
        "unique-3": 79,
        "entropy-3": 6.363373880404612,
        "cond_entropy-3": -0.10170750110837044,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5811388300841898,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 72,
        "unique-1-nopunct": 59,
        "entropy-1-nopunct": 5.998946059247345,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.2494602799216175,
        "cond_entropy-2-nopunct": 0.3004776394180615,
        "distinct-3-nopunct": 0.9342105263157895,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.116348566075171,
        "cond_entropy-3-nopunct": -0.11807411986149058,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.234318678366881,
        "rouge1": {
            "precision": 0.78957,
            "recall": 0.77096,
            "fmeasure": 0.7737
        },
        "rouge2": {
            "precision": 0.5834,
            "recall": 0.58704,
            "fmeasure": 0.579
        },
        "rougeL": {
            "precision": 0.6648,
            "recall": 0.66968,
            "fmeasure": 0.66111
        },
        "rougeLsum": {
            "precision": 0.6648,
            "recall": 0.66968,
            "fmeasure": 0.66111
        },
        "bleu": 51.35819,
        "local_recall": {
            "1": 0.058823529411764705,
            "2": 0.1,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.9453,
            "recall": 0.93182,
            "f1": 0.93697
        },
        "nubia": {
            "semantic_relation": 3.92213,
            "contradiction": 45.9483,
            "irrelevancy": 11.40141,
            "logical_agreement": 42.65029,
            "grammar_ref": 5.14697,
            "grammar_hyp": 5.0891,
            "nubia_score": 0.61679
        },
        "meteor": 0.4223308547369709,
        "bleurt": 0.39842
    },
    "totto_test_contrast_challenge_table_size-table_size_156": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 32,
        "msttr-100": 0.704,
        "msttr-100_nopunct": 0.738,
        "total_length": 595,
        "mean_pred_length": 18.59375,
        "std_pred_length": 5.308362359287467,
        "median_pred_length": 19.5,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5159663865546219,
        "vocab_size-1": 307,
        "unique-1": 232,
        "entropy-1": 7.356928489771004,
        "distinct-2": 0.8312611012433393,
        "vocab_size-2": 468,
        "unique-2": 410,
        "entropy-2": 8.710725682383256,
        "cond_entropy-2": 1.2261456708204095,
        "distinct-3": 0.9133709981167608,
        "vocab_size-3": 485,
        "unique-3": 442,
        "entropy-3": 8.874121934980932,
        "cond_entropy-3": 0.1594143434603733,
        "total_length-nopunct": 534,
        "mean_pred_length-nopunct": 16.6875,
        "std_pred_length-nopunct": 4.844052409914657,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5655430711610487,
        "vocab_size-1-nopunct": 302,
        "unique-1-nopunct": 232,
        "entropy-1-nopunct": 7.459792195554304,
        "distinct-2-nopunct": 0.8306772908366534,
        "vocab_size-2-nopunct": 417,
        "unique-2-nopunct": 366,
        "entropy-2-nopunct": 8.53880939176517,
        "cond_entropy-2-nopunct": 1.1397224393464658,
        "distinct-3-nopunct": 0.9170212765957447,
        "vocab_size-3-nopunct": 431,
        "unique-3-nopunct": 393,
        "entropy-3-nopunct": 8.708953356134874,
        "cond_entropy-3-nopunct": 0.17407480094413166,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.852933152083942,
        "rouge1": {
            "precision": 0.76289,
            "recall": 0.75598,
            "fmeasure": 0.74922
        },
        "rouge2": {
            "precision": 0.56593,
            "recall": 0.5679,
            "fmeasure": 0.55805
        },
        "rougeL": {
            "precision": 0.66579,
            "recall": 0.67392,
            "fmeasure": 0.66073
        },
        "rougeLsum": {
            "precision": 0.66579,
            "recall": 0.67392,
            "fmeasure": 0.66073
        },
        "bleu": 51.28843,
        "local_recall": {
            "1": 0.19387755102040816,
            "2": 0.3373493975903614,
            "3": 0.826530612244898
        },
        "bertscore": {
            "precision": 0.93096,
            "recall": 0.93181,
            "f1": 0.92965
        },
        "nubia": {
            "semantic_relation": 4.30863,
            "contradiction": 10.60333,
            "irrelevancy": 32.55505,
            "logical_agreement": 56.84162,
            "grammar_ref": 4.40347,
            "grammar_hyp": 4.29283,
            "nubia_score": 0.76066
        },
        "meteor": 0.4012203493140285,
        "bleurt": 0.28002
    },
    "totto_test_contrast_challenge_ethnicity-african_american": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.7015,
        "msttr-100_nopunct": 0.75,
        "total_length": 2013,
        "mean_pred_length": 15.7265625,
        "std_pred_length": 5.381848607457641,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 32,
        "distinct-1": 0.3909587680079483,
        "vocab_size-1": 787,
        "unique-1": 608,
        "entropy-1": 7.923353745927854,
        "distinct-2": 0.7692307692307693,
        "vocab_size-2": 1450,
        "unique-2": 1285,
        "entropy-2": 10.143466135743093,
        "cond_entropy-2": 1.9932554158306497,
        "distinct-3": 0.92942515651679,
        "vocab_size-3": 1633,
        "unique-3": 1565,
        "entropy-3": 10.586930263065739,
        "cond_entropy-3": 0.3689222417688801,
        "total_length-nopunct": 1748,
        "mean_pred_length-nopunct": 13.65625,
        "std_pred_length-nopunct": 5.045786453814707,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.44450800915331806,
        "vocab_size-1-nopunct": 777,
        "unique-1-nopunct": 605,
        "entropy-1-nopunct": 8.207937991296898,
        "distinct-2-nopunct": 0.808641975308642,
        "vocab_size-2-nopunct": 1310,
        "unique-2-nopunct": 1188,
        "entropy-2-nopunct": 10.051990731406946,
        "cond_entropy-2-nopunct": 1.8533767124053495,
        "distinct-3-nopunct": 0.9524128686327078,
        "vocab_size-3-nopunct": 1421,
        "unique-3-nopunct": 1378,
        "entropy-3-nopunct": 10.425676871240979,
        "cond_entropy-3-nopunct": 0.3509412522912167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.651267125879177,
        "rouge1": {
            "precision": 0.81156,
            "recall": 0.77069,
            "fmeasure": 0.78282
        },
        "rouge2": {
            "precision": 0.58265,
            "recall": 0.5608,
            "fmeasure": 0.56566
        },
        "rougeL": {
            "precision": 0.71301,
            "recall": 0.6787,
            "fmeasure": 0.68819
        },
        "rougeLsum": {
            "precision": 0.71301,
            "recall": 0.6787,
            "fmeasure": 0.68819
        },
        "bleu": 48.19694,
        "local_recall": {
            "1": 0.16363636363636364,
            "2": 0.32558139534883723,
            "3": 0.7962085308056872
        },
        "bertscore": {
            "precision": 0.93918,
            "recall": 0.93773,
            "f1": 0.93685
        },
        "nubia": {
            "semantic_relation": 4.4177,
            "contradiction": 6.0687,
            "irrelevancy": 31.39196,
            "logical_agreement": 62.53934,
            "grammar_ref": 4.21731,
            "grammar_hyp": 4.25198,
            "nubia_score": 0.81588
        },
        "meteor": 0.41322987215912127,
        "bleurt": 0.3367
    },
    "totto_test_contrast_challenge_table_size-table_size_132": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 43,
        "msttr-100": 0.695,
        "msttr-100_nopunct": 0.74833,
        "total_length": 695,
        "mean_pred_length": 16.162790697674417,
        "std_pred_length": 4.209238082511169,
        "median_pred_length": 15.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.5280575539568345,
        "vocab_size-1": 367,
        "unique-1": 301,
        "entropy-1": 7.410309155336458,
        "distinct-2": 0.9049079754601227,
        "vocab_size-2": 590,
        "unique-2": 555,
        "entropy-2": 9.092474463403313,
        "cond_entropy-2": 1.5040730284815338,
        "distinct-3": 0.9852216748768473,
        "vocab_size-3": 600,
        "unique-3": 591,
        "entropy-3": 9.220741767660128,
        "cond_entropy-3": 0.14307667815739722,
        "total_length-nopunct": 608,
        "mean_pred_length-nopunct": 14.13953488372093,
        "std_pred_length-nopunct": 4.174013713602444,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.5953947368421053,
        "vocab_size-1-nopunct": 362,
        "unique-1-nopunct": 300,
        "entropy-1-nopunct": 7.608168424736652,
        "distinct-2-nopunct": 0.9097345132743363,
        "vocab_size-2-nopunct": 514,
        "unique-2-nopunct": 488,
        "entropy-2-nopunct": 8.888005054797478,
        "cond_entropy-2-nopunct": 1.3802875208790737,
        "distinct-3-nopunct": 0.9904214559386973,
        "vocab_size-3-nopunct": 517,
        "unique-3-nopunct": 512,
        "entropy-3-nopunct": 9.008748908447233,
        "cond_entropy-3-nopunct": 0.13784421017786497,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.65181713930496,
        "rouge1": {
            "precision": 0.8362,
            "recall": 0.79138,
            "fmeasure": 0.8034
        },
        "rouge2": {
            "precision": 0.63664,
            "recall": 0.6034,
            "fmeasure": 0.6125
        },
        "rougeL": {
            "precision": 0.74351,
            "recall": 0.70382,
            "fmeasure": 0.71526
        },
        "rougeLsum": {
            "precision": 0.74351,
            "recall": 0.70382,
            "fmeasure": 0.71526
        },
        "bleu": 55.26738,
        "local_recall": {
            "1": 0.2248062015503876,
            "2": 0.603448275862069,
            "3": 0.8253275109170306
        },
        "bertscore": {
            "precision": 0.95187,
            "recall": 0.94487,
            "f1": 0.94718
        },
        "nubia": {
            "semantic_relation": 4.5213,
            "contradiction": 0.85508,
            "irrelevancy": 19.73474,
            "logical_agreement": 79.41019,
            "grammar_ref": 4.66047,
            "grammar_hyp": 4.5932,
            "nubia_score": 0.84012
        },
        "meteor": 0.440196521222614,
        "bleurt": 0.40938
    },
    "totto_test_contrast_challenge_table_size-table_size_115": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 332,
        "mean_pred_length": 16.6,
        "std_pred_length": 6.514598989960932,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5843373493975904,
        "vocab_size-1": 194,
        "unique-1": 154,
        "entropy-1": 6.925497880078888,
        "distinct-2": 0.8782051282051282,
        "vocab_size-2": 274,
        "unique-2": 245,
        "entropy-2": 8.020036874248518,
        "cond_entropy-2": 0.9468857281420846,
        "distinct-3": 0.9383561643835616,
        "vocab_size-3": 274,
        "unique-3": 260,
        "entropy-3": 8.056195962960008,
        "cond_entropy-3": 0.03805093593781633,
        "total_length-nopunct": 286,
        "mean_pred_length-nopunct": 14.3,
        "std_pred_length-nopunct": 5.441507144165116,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6608391608391608,
        "vocab_size-1-nopunct": 189,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 7.1062812602650025,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 238,
        "unique-2-nopunct": 216,
        "entropy-2-nopunct": 7.827728582068976,
        "cond_entropy-2-nopunct": 0.7668300343237667,
        "distinct-3-nopunct": 0.9471544715447154,
        "vocab_size-3-nopunct": 233,
        "unique-3-nopunct": 223,
        "entropy-3-nopunct": 7.827617503280373,
        "cond_entropy-3-nopunct": 0.014324193848173555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.813026470317123,
        "rouge1": {
            "precision": 0.84035,
            "recall": 0.81997,
            "fmeasure": 0.8256
        },
        "rouge2": {
            "precision": 0.69097,
            "recall": 0.67483,
            "fmeasure": 0.67907
        },
        "rougeL": {
            "precision": 0.7259,
            "recall": 0.7072,
            "fmeasure": 0.71255
        },
        "rougeLsum": {
            "precision": 0.7259,
            "recall": 0.7072,
            "fmeasure": 0.71255
        },
        "bleu": 62.1363,
        "local_recall": {
            "1": 0.1568627450980392,
            "2": 0.5185185185185185,
            "3": 0.8666666666666667
        },
        "bertscore": {
            "precision": 0.95306,
            "recall": 0.94697,
            "f1": 0.9489
        },
        "nubia": {
            "semantic_relation": 4.40294,
            "contradiction": 4.04359,
            "irrelevancy": 19.24864,
            "logical_agreement": 76.70778,
            "grammar_ref": 4.56897,
            "grammar_hyp": 4.52513,
            "nubia_score": 0.80319
        },
        "meteor": 0.4537118868679865,
        "bleurt": 0.46305
    },
    "web_nlg_ru_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 642,
        "msttr-100": 0.32662,
        "msttr-100_nopunct": 0.48951,
        "total_length": 7779,
        "mean_pred_length": 12.116822429906541,
        "std_pred_length": 8.775340548437681,
        "median_pred_length": 12.0,
        "min_pred_length": 0,
        "max_pred_length": 54,
        "distinct-1": 0.15490422933539016,
        "vocab_size-1": 1205,
        "unique-1": 618,
        "entropy-1": 6.4549408400636095,
        "distinct-2": 0.3066685346035304,
        "vocab_size-2": 2189,
        "unique-2": 1123,
        "entropy-2": 9.967297785616488,
        "cond_entropy-2": 3.765639422859507,
        "distinct-3": 0.4323244738055001,
        "vocab_size-3": 2814,
        "unique-3": 1658,
        "entropy-3": 10.727478970355602,
        "cond_entropy-3": 0.8919224802460228,
        "total_length-nopunct": 4147,
        "mean_pred_length-nopunct": 6.459501557632398,
        "std_pred_length-nopunct": 4.944780287131452,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.2867132867132867,
        "vocab_size-1-nopunct": 1189,
        "unique-1-nopunct": 613,
        "entropy-1-nopunct": 8.853243813560228,
        "distinct-2-nopunct": 0.5388999715018524,
        "vocab_size-2-nopunct": 1891,
        "unique-2-nopunct": 1225,
        "entropy-2-nopunct": 10.376669759568621,
        "cond_entropy-2-nopunct": 1.7342216528607282,
        "distinct-3-nopunct": 0.6495812395309882,
        "vocab_size-3-nopunct": 1939,
        "unique-3-nopunct": 1416,
        "entropy-3-nopunct": 10.582088728455673,
        "cond_entropy-3-nopunct": 0.33450870399554034,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.5930394734361549,
        "rouge1": {
            "precision": 0.09641,
            "recall": 0.2574,
            "fmeasure": 0.12302
        },
        "rouge2": {
            "precision": 0.03451,
            "recall": 0.08852,
            "fmeasure": 0.04168
        },
        "rougeL": {
            "precision": 0.09306,
            "recall": 0.24917,
            "fmeasure": 0.11856
        },
        "rougeLsum": {
            "precision": 0.09306,
            "recall": 0.24917,
            "fmeasure": 0.11856
        },
        "bleu": 0.6029,
        "local_recall": {
            "1": 0.008503152030494062,
            "2": 0.018528610354223433,
            "3": 0.03184044786564031,
            "4": 0.10526315789473684,
            "5": 0.030303030303030304,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.6121,
            "recall": 0.53345,
            "f1": 0.5684
        },
        "nubia": {
            "semantic_relation": 2.27,
            "contradiction": 35.18661,
            "irrelevancy": 33.09791,
            "logical_agreement": 31.71548,
            "grammar_ref": 2.74601,
            "grammar_hyp": 5.16892,
            "nubia_score": 0.24538
        },
        "meteor": 0.02887835278913636,
        "bleurt": -1.29889
    },
    "totto_test_contrast_challenge_table_size-table_size_159": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.9655172413793104,
        "vocab_size-1": 28,
        "unique-1": 27,
        "entropy-1": 4.789015477886192,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": -0.10309349296410335,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.754887502163471,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.11103131238874399,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3880657671746712,
        "rouge1": {
            "precision": 0.7298,
            "recall": 0.54499,
            "fmeasure": 0.60211
        },
        "rouge2": {
            "precision": 0.36786,
            "recall": 0.30278,
            "fmeasure": 0.32117
        },
        "rougeL": {
            "precision": 0.67424,
            "recall": 0.51811,
            "fmeasure": 0.56588
        },
        "rougeLsum": {
            "precision": 0.67424,
            "recall": 0.51811,
            "fmeasure": 0.56588
        },
        "bleu": 11.95167,
        "local_recall": {
            "1": 0.5,
            "2": 0.6363636363636364,
            "3": 0.4230769230769231
        },
        "bertscore": {
            "precision": 0.90342,
            "recall": 0.8469,
            "f1": 0.87381
        },
        "nubia": {
            "semantic_relation": 3.89801,
            "contradiction": 45.94325,
            "irrelevancy": 2.58944,
            "logical_agreement": 51.46731,
            "grammar_ref": 4.83168,
            "grammar_hyp": 4.85159,
            "nubia_score": 0.55894
        },
        "meteor": 0.2508593157421421,
        "bleurt": -0.11107
    },
    "totto_test_contrast_challenge_table_size-table_size_198": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.72,
        "total_length": 310,
        "mean_pred_length": 17.22222222222222,
        "std_pred_length": 5.318265752788586,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.6161290322580645,
        "vocab_size-1": 191,
        "unique-1": 165,
        "entropy-1": 6.903345609381,
        "distinct-2": 0.934931506849315,
        "vocab_size-2": 273,
        "unique-2": 259,
        "entropy-2": 8.04340371126991,
        "cond_entropy-2": 0.9986540550603477,
        "distinct-3": 0.9781021897810219,
        "vocab_size-3": 268,
        "unique-3": 262,
        "entropy-3": 8.054236462522528,
        "cond_entropy-3": 0.01680200401541257,
        "total_length-nopunct": 279,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 5.123475382979799,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 6.982394155132982,
        "distinct-2-nopunct": 0.9272030651340997,
        "vocab_size-2-nopunct": 242,
        "unique-2-nopunct": 228,
        "entropy-2-nopunct": 7.864094167059648,
        "cond_entropy-2-nopunct": 0.9527769805877463,
        "distinct-3-nopunct": 0.9753086419753086,
        "vocab_size-3-nopunct": 237,
        "unique-3-nopunct": 231,
        "entropy-3-nopunct": 7.875429787556379,
        "cond_entropy-3-nopunct": 0.019354603752618396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.955857908193901,
        "rouge1": {
            "precision": 0.71386,
            "recall": 0.70479,
            "fmeasure": 0.69708
        },
        "rouge2": {
            "precision": 0.46763,
            "recall": 0.47661,
            "fmeasure": 0.45969
        },
        "rougeL": {
            "precision": 0.60693,
            "recall": 0.619,
            "fmeasure": 0.60313
        },
        "rougeLsum": {
            "precision": 0.60693,
            "recall": 0.619,
            "fmeasure": 0.60313
        },
        "bleu": 38.42363,
        "local_recall": {
            "1": 0.20588235294117646,
            "2": 0.5492957746478874,
            "3": 0.7419354838709677
        },
        "bertscore": {
            "precision": 0.91392,
            "recall": 0.91207,
            "f1": 0.91197
        },
        "nubia": {
            "semantic_relation": 3.88908,
            "contradiction": 12.25225,
            "irrelevancy": 39.27717,
            "logical_agreement": 48.47058,
            "grammar_ref": 4.71491,
            "grammar_hyp": 4.3832,
            "nubia_score": 0.66191
        },
        "meteor": 0.3838233890186765,
        "bleurt": 0.0541
    },
    "totto_test_contrast_challenge_table_size-table_size_116": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.74,
        "total_length": 288,
        "mean_pred_length": 16.941176470588236,
        "std_pred_length": 6.111422172363658,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.5902777777777778,
        "vocab_size-1": 170,
        "unique-1": 134,
        "entropy-1": 6.698789447011251,
        "distinct-2": 0.9261992619926199,
        "vocab_size-2": 251,
        "unique-2": 234,
        "entropy-2": 7.924381928799729,
        "cond_entropy-2": 1.1016291810180159,
        "distinct-3": 0.9606299212598425,
        "vocab_size-3": 244,
        "unique-3": 234,
        "entropy-3": 7.909944529291813,
        "cond_entropy-3": -0.0038781833133456787,
        "total_length-nopunct": 247,
        "mean_pred_length-nopunct": 14.529411764705882,
        "std_pred_length-nopunct": 5.595351506161936,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6680161943319838,
        "vocab_size-1-nopunct": 165,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.847597064207767,
        "distinct-2-nopunct": 0.9260869565217391,
        "vocab_size-2-nopunct": 213,
        "unique-2-nopunct": 199,
        "entropy-2-nopunct": 7.685686192239306,
        "cond_entropy-2-nopunct": 0.910754749098561,
        "distinct-3-nopunct": 0.9671361502347418,
        "vocab_size-3-nopunct": 206,
        "unique-3-nopunct": 199,
        "entropy-3-nopunct": 7.668981920695363,
        "cond_entropy-3-nopunct": -0.008644808642652218,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.910360266834288,
        "rouge1": {
            "precision": 0.81057,
            "recall": 0.76619,
            "fmeasure": 0.78125
        },
        "rouge2": {
            "precision": 0.59255,
            "recall": 0.54866,
            "fmeasure": 0.56337
        },
        "rougeL": {
            "precision": 0.73434,
            "recall": 0.68537,
            "fmeasure": 0.70213
        },
        "rougeLsum": {
            "precision": 0.73434,
            "recall": 0.68537,
            "fmeasure": 0.70213
        },
        "bleu": 45.62284,
        "local_recall": {
            "1": 0.041666666666666664,
            "2": 0.4166666666666667,
            "3": 0.7799043062200957
        },
        "bertscore": {
            "precision": 0.93962,
            "recall": 0.9329,
            "f1": 0.93561
        },
        "nubia": {
            "semantic_relation": 4.23318,
            "contradiction": 7.15341,
            "irrelevancy": 21.80592,
            "logical_agreement": 71.04066,
            "grammar_ref": 4.34644,
            "grammar_hyp": 4.52749,
            "nubia_score": 0.73717
        },
        "meteor": 0.4062558412327795,
        "bleurt": 0.35309
    },
    "totto_test_contrast_challenge_table_size-table_size_133": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.78,
        "total_length": 150,
        "mean_pred_length": 13.636363636363637,
        "std_pred_length": 3.9375286959468574,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7,
        "vocab_size-1": 105,
        "unique-1": 88,
        "entropy-1": 6.367701238156217,
        "distinct-2": 0.9856115107913669,
        "vocab_size-2": 137,
        "unique-2": 135,
        "entropy-2": 7.090164094306257,
        "cond_entropy-2": 0.5516212088612542,
        "distinct-3": 1.0,
        "vocab_size-3": 128,
        "unique-3": 128,
        "entropy-3": 7.0,
        "cond_entropy-3": -0.08769107272350732,
        "total_length-nopunct": 135,
        "mean_pred_length-nopunct": 12.272727272727273,
        "std_pred_length-nopunct": 3.979285205134416,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.762962962962963,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 88,
        "entropy-1-nopunct": 6.452084512401686,
        "distinct-2-nopunct": 0.9838709677419355,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 6.921938245870731,
        "cond_entropy-2-nopunct": 0.5172089103331204,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 113,
        "unique-3-nopunct": 113,
        "entropy-3-nopunct": 6.8201789624152065,
        "cond_entropy-3-nopunct": -0.10746867540531553,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6827253308032475,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.69223,
            "fmeasure": 0.73431
        },
        "rouge2": {
            "precision": 0.58312,
            "recall": 0.51584,
            "fmeasure": 0.5411
        },
        "rougeL": {
            "precision": 0.6902,
            "recall": 0.59849,
            "fmeasure": 0.63244
        },
        "rougeLsum": {
            "precision": 0.6902,
            "recall": 0.59849,
            "fmeasure": 0.63244
        },
        "bleu": 36.14182,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.2727272727272727,
            "3": 0.7301587301587301
        },
        "bertscore": {
            "precision": 0.92894,
            "recall": 0.91497,
            "f1": 0.92111
        },
        "nubia": {
            "semantic_relation": 4.15342,
            "contradiction": 13.81305,
            "irrelevancy": 22.28904,
            "logical_agreement": 63.89791,
            "grammar_ref": 4.38413,
            "grammar_hyp": 4.76866,
            "nubia_score": 0.67464
        },
        "meteor": 0.3748245445323507,
        "bleurt": 0.22372
    },
    "totto_test_contrast_challenge_table_size-table_size_30": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 122,
        "msttr-100": 0.73053,
        "msttr-100_nopunct": 0.77412,
        "total_length": 1946,
        "mean_pred_length": 15.950819672131148,
        "std_pred_length": 5.3313985785671125,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.46557040082219936,
        "vocab_size-1": 906,
        "unique-1": 732,
        "entropy-1": 8.309908516618323,
        "distinct-2": 0.8569078947368421,
        "vocab_size-2": 1563,
        "unique-2": 1437,
        "entropy-2": 10.442112990531285,
        "cond_entropy-2": 1.8895580654624542,
        "distinct-3": 0.9506462984723855,
        "vocab_size-3": 1618,
        "unique-3": 1563,
        "entropy-3": 10.615282924266888,
        "cond_entropy-3": 0.18217989077442448,
        "total_length-nopunct": 1722,
        "mean_pred_length-nopunct": 14.114754098360656,
        "std_pred_length-nopunct": 5.0492601654322495,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5203252032520326,
        "vocab_size-1-nopunct": 896,
        "unique-1-nopunct": 728,
        "entropy-1-nopunct": 8.580041292700328,
        "distinct-2-nopunct": 0.865625,
        "vocab_size-2-nopunct": 1385,
        "unique-2-nopunct": 1287,
        "entropy-2-nopunct": 10.266201210965955,
        "cond_entropy-2-nopunct": 1.7976499563379515,
        "distinct-3-nopunct": 0.956021650879567,
        "vocab_size-3-nopunct": 1413,
        "unique-3-nopunct": 1371,
        "entropy-3-nopunct": 10.42329336510467,
        "cond_entropy-3-nopunct": 0.18031205935723527,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.478637565935421,
        "rouge1": {
            "precision": 0.75787,
            "recall": 0.72171,
            "fmeasure": 0.72964
        },
        "rouge2": {
            "precision": 0.52255,
            "recall": 0.49436,
            "fmeasure": 0.50057
        },
        "rougeL": {
            "precision": 0.64621,
            "recall": 0.61303,
            "fmeasure": 0.62055
        },
        "rougeLsum": {
            "precision": 0.64621,
            "recall": 0.61303,
            "fmeasure": 0.62055
        },
        "bleu": 43.36689,
        "local_recall": {
            "1": 0.18651685393258427,
            "2": 0.3857566765578635,
            "3": 0.7572168763878608
        },
        "bertscore": {
            "precision": 0.92749,
            "recall": 0.92098,
            "f1": 0.92282
        },
        "nubia": {
            "semantic_relation": 4.21835,
            "contradiction": 8.28895,
            "irrelevancy": 25.53463,
            "logical_agreement": 66.17642,
            "grammar_ref": 4.69288,
            "grammar_hyp": 4.58865,
            "nubia_score": 0.74229
        },
        "meteor": 0.38299785682613596,
        "bleurt": 0.26532
    },
    "totto_test_contrast_challenge_table_size-table_size_134": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.855388542207534,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.73333,
            "fmeasure": 0.72878
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.35859,
            "fmeasure": 0.35338
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.425,
            "fmeasure": 0.41615
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.425,
            "fmeasure": 0.41615
        },
        "bleu": 25.96536,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75
        },
        "bertscore": {
            "precision": 0.93468,
            "recall": 0.93468,
            "f1": 0.93468
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 6.02223,
            "irrelevancy": 1.59074,
            "logical_agreement": 92.38703,
            "grammar_ref": 5.93899,
            "grammar_hyp": 6.13844,
            "nubia_score": 0.79997
        },
        "meteor": 0.38797373573077903,
        "bleurt": 0.48513
    },
    "totto_test_contrast_challenge_table_size-table_size_117": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.79,
        "total_length": 143,
        "mean_pred_length": 17.875,
        "std_pred_length": 6.13264828601804,
        "median_pred_length": 17.5,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 99,
        "unique-1": 85,
        "entropy-1": 6.218994851156124,
        "distinct-2": 0.9555555555555556,
        "vocab_size-2": 129,
        "unique-2": 123,
        "entropy-2": 6.987926708161963,
        "cond_entropy-2": 0.6568987268619307,
        "distinct-3": 0.9921259842519685,
        "vocab_size-3": 126,
        "unique-3": 125,
        "entropy-3": 6.972936655276085,
        "cond_entropy-3": -0.017264768546381398,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 4.602988159880492,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7786885245901639,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.267672968795839,
        "distinct-2-nopunct": 0.9912280701754386,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 112,
        "entropy-2-nopunct": 6.81534615451563,
        "cond_entropy-2-nopunct": 0.5854320887911646,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 106,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.727920454563184,
        "cond_entropy-3-nopunct": -0.08610163507324067,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.193624501200014,
        "rouge1": {
            "precision": 0.74067,
            "recall": 0.65242,
            "fmeasure": 0.67391
        },
        "rouge2": {
            "precision": 0.50499,
            "recall": 0.41858,
            "fmeasure": 0.44574
        },
        "rougeL": {
            "precision": 0.59624,
            "recall": 0.52044,
            "fmeasure": 0.54224
        },
        "rougeLsum": {
            "precision": 0.59624,
            "recall": 0.52044,
            "fmeasure": 0.54224
        },
        "bleu": 26.66411,
        "local_recall": {
            "1": 0.25,
            "2": 0.5128205128205128,
            "3": 0.632183908045977
        },
        "bertscore": {
            "precision": 0.90768,
            "recall": 0.89291,
            "f1": 0.89927
        },
        "nubia": {
            "semantic_relation": 3.77874,
            "contradiction": 7.47758,
            "irrelevancy": 42.09587,
            "logical_agreement": 50.42655,
            "grammar_ref": 4.12019,
            "grammar_hyp": 4.43255,
            "nubia_score": 0.59611
        },
        "meteor": 0.330287193396721,
        "bleurt": 0.00018
    },
    "totto_test_contrast_challenge_table_size-table_size_160": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.77667,
        "total_length": 443,
        "mean_pred_length": 15.275862068965518,
        "std_pred_length": 4.62300508121882,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.5778781038374717,
        "vocab_size-1": 256,
        "unique-1": 206,
        "entropy-1": 7.207163421766301,
        "distinct-2": 0.9299516908212561,
        "vocab_size-2": 385,
        "unique-2": 362,
        "entropy-2": 8.538017083159733,
        "cond_entropy-2": 1.105321311154606,
        "distinct-3": 0.9766233766233766,
        "vocab_size-3": 376,
        "unique-3": 367,
        "entropy-3": 8.541961388829064,
        "cond_entropy-3": 0.010460218281900061,
        "total_length-nopunct": 380,
        "mean_pred_length-nopunct": 13.10344827586207,
        "std_pred_length-nopunct": 3.9246772552235987,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6578947368421053,
        "vocab_size-1-nopunct": 250,
        "unique-1-nopunct": 205,
        "entropy-1-nopunct": 7.414416855824388,
        "distinct-2-nopunct": 0.9259259259259259,
        "vocab_size-2-nopunct": 325,
        "unique-2-nopunct": 305,
        "entropy-2-nopunct": 8.289046513818535,
        "cond_entropy-2-nopunct": 0.9424566782350199,
        "distinct-3-nopunct": 0.9813664596273292,
        "vocab_size-3-nopunct": 316,
        "unique-3-nopunct": 310,
        "entropy-3-nopunct": 8.293649797369318,
        "cond_entropy-3-nopunct": 0.013367695004467203,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.43165714772927,
        "rouge1": {
            "precision": 0.84581,
            "recall": 0.82172,
            "fmeasure": 0.82431
        },
        "rouge2": {
            "precision": 0.64205,
            "recall": 0.62768,
            "fmeasure": 0.62508
        },
        "rougeL": {
            "precision": 0.72819,
            "recall": 0.70775,
            "fmeasure": 0.70921
        },
        "rougeLsum": {
            "precision": 0.72819,
            "recall": 0.70775,
            "fmeasure": 0.70921
        },
        "bleu": 59.79033,
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.30612244897959184,
            "3": 0.844776119402985
        },
        "bertscore": {
            "precision": 0.95786,
            "recall": 0.95513,
            "f1": 0.95427
        },
        "nubia": {
            "semantic_relation": 4.62721,
            "contradiction": 6.03898,
            "irrelevancy": 20.39656,
            "logical_agreement": 73.56446,
            "grammar_ref": 4.52589,
            "grammar_hyp": 4.59745,
            "nubia_score": 0.86633
        },
        "meteor": 0.4618540709389285,
        "bleurt": 0.50748
    },
    "totto_test_contrast_challenge_table_size-table_size_186": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.715,
        "total_length": 235,
        "mean_pred_length": 16.785714285714285,
        "std_pred_length": 4.426842980670334,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.6085106382978723,
        "vocab_size-1": 143,
        "unique-1": 117,
        "entropy-1": 6.465980746773953,
        "distinct-2": 0.9321266968325792,
        "vocab_size-2": 206,
        "unique-2": 199,
        "entropy-2": 7.601200636636481,
        "cond_entropy-2": 0.9833852196737048,
        "distinct-3": 0.9951690821256038,
        "vocab_size-3": 206,
        "unique-3": 205,
        "entropy-3": 7.6838251217505045,
        "cond_entropy-3": 0.09525166829552716,
        "total_length-nopunct": 214,
        "mean_pred_length-nopunct": 15.285714285714286,
        "std_pred_length-nopunct": 4.3659162256960355,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6495327102803738,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.495843633281264,
        "distinct-2-nopunct": 0.925,
        "vocab_size-2-nopunct": 185,
        "unique-2-nopunct": 178,
        "entropy-2-nopunct": 7.4375505651305405,
        "cond_entropy-2-nopunct": 1.0189005665676296,
        "distinct-3-nopunct": 0.9946236559139785,
        "vocab_size-3-nopunct": 185,
        "unique-3-nopunct": 184,
        "entropy-3-nopunct": 7.528406122936004,
        "cond_entropy-3-nopunct": 0.10638393815502686,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.504807332594976,
        "rouge1": {
            "precision": 0.69606,
            "recall": 0.75366,
            "fmeasure": 0.7139
        },
        "rouge2": {
            "precision": 0.48929,
            "recall": 0.51545,
            "fmeasure": 0.4976
        },
        "rougeL": {
            "precision": 0.57546,
            "recall": 0.63343,
            "fmeasure": 0.59496
        },
        "rougeLsum": {
            "precision": 0.57546,
            "recall": 0.63343,
            "fmeasure": 0.59496
        },
        "bleu": 42.81887,
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.46153846153846156,
            "3": 0.8174603174603174
        },
        "bertscore": {
            "precision": 0.91239,
            "recall": 0.92657,
            "f1": 0.91665
        },
        "nubia": {
            "semantic_relation": 4.17837,
            "contradiction": 11.93629,
            "irrelevancy": 40.29389,
            "logical_agreement": 47.76982,
            "grammar_ref": 4.72137,
            "grammar_hyp": 4.47297,
            "nubia_score": 0.73607
        },
        "meteor": 0.40428825677117136,
        "bleurt": 0.26944
    },
    "totto_test_contrast_challenge_table_size-table_size_31": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 61,
        "mean_pred_length": 15.25,
        "std_pred_length": 5.261891294962297,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.7868852459016393,
        "vocab_size-1": 48,
        "unique-1": 44,
        "entropy-1": 5.3302588050532025,
        "distinct-2": 1.0,
        "vocab_size-2": 57,
        "unique-2": 57,
        "entropy-2": 5.832890014164737,
        "cond_entropy-2": 0.42061539390080027,
        "distinct-3": 1.0,
        "vocab_size-3": 53,
        "unique-3": 53,
        "entropy-3": 5.727920454563195,
        "cond_entropy-3": -0.10496955960154235,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 3.6314597615834874,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8679245283018868,
        "vocab_size-1-nopunct": 46,
        "unique-1-nopunct": 44,
        "entropy-1-nopunct": 5.3455683317992255,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 49,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.614709844115208,
        "cond_entropy-2-nopunct": 0.3003539305007929,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": -0.12285674778553377,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9305208764151067,
        "rouge1": {
            "precision": 0.71874,
            "recall": 0.75726,
            "fmeasure": 0.72081
        },
        "rouge2": {
            "precision": 0.54771,
            "recall": 0.60074,
            "fmeasure": 0.55992
        },
        "rougeL": {
            "precision": 0.697,
            "recall": 0.74444,
            "fmeasure": 0.70468
        },
        "rougeLsum": {
            "precision": 0.697,
            "recall": 0.74444,
            "fmeasure": 0.70468
        },
        "bleu": 40.88936,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.6363636363636364,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.92763,
            "recall": 0.94275,
            "f1": 0.93269
        },
        "nubia": {
            "semantic_relation": 3.89227,
            "contradiction": 0.35391,
            "irrelevancy": 74.60711,
            "logical_agreement": 25.03898,
            "grammar_ref": 4.43427,
            "grammar_hyp": 4.11942,
            "nubia_score": 0.68778
        },
        "meteor": 0.33584283716252605,
        "bleurt": 0.27707
    },
    "totto_test_contrast_challenge_table_size-table_size_200": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.75667,
        "msttr-100_nopunct": 0.78,
        "total_length": 390,
        "mean_pred_length": 15.6,
        "std_pred_length": 5.027922035990614,
        "median_pred_length": 13.0,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6358974358974359,
        "vocab_size-1": 248,
        "unique-1": 213,
        "entropy-1": 7.2950365049586186,
        "distinct-2": 0.915068493150685,
        "vocab_size-2": 334,
        "unique-2": 313,
        "entropy-2": 8.31304217427977,
        "cond_entropy-2": 0.8594326715364814,
        "distinct-3": 0.9764705882352941,
        "vocab_size-3": 332,
        "unique-3": 325,
        "entropy-3": 8.360111855248965,
        "cond_entropy-3": 0.05579839269625594,
        "total_length-nopunct": 351,
        "mean_pred_length-nopunct": 14.04,
        "std_pred_length-nopunct": 4.991833330551011,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 243,
        "unique-1-nopunct": 211,
        "entropy-1-nopunct": 7.408893695746784,
        "distinct-2-nopunct": 0.9202453987730062,
        "vocab_size-2-nopunct": 300,
        "unique-2-nopunct": 284,
        "entropy-2-nopunct": 8.156920408792525,
        "cond_entropy-2-nopunct": 0.8103823820634523,
        "distinct-3-nopunct": 0.9800664451827242,
        "vocab_size-3-nopunct": 295,
        "unique-3-nopunct": 290,
        "entropy-3-nopunct": 8.191244635224244,
        "cond_entropy-3-nopunct": 0.04361058402635621,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.665852718088612,
        "rouge1": {
            "precision": 0.83793,
            "recall": 0.78572,
            "fmeasure": 0.80567
        },
        "rouge2": {
            "precision": 0.67059,
            "recall": 0.64116,
            "fmeasure": 0.65208
        },
        "rougeL": {
            "precision": 0.73629,
            "recall": 0.69229,
            "fmeasure": 0.70888
        },
        "rougeLsum": {
            "precision": 0.73629,
            "recall": 0.69229,
            "fmeasure": 0.70888
        },
        "bleu": 57.1745,
        "local_recall": {
            "1": 0.17857142857142858,
            "2": 0.3488372093023256,
            "3": 0.8246753246753247
        },
        "bertscore": {
            "precision": 0.94898,
            "recall": 0.93689,
            "f1": 0.94225
        },
        "nubia": {
            "semantic_relation": 4.15296,
            "contradiction": 17.22101,
            "irrelevancy": 18.81902,
            "logical_agreement": 63.95997,
            "grammar_ref": 4.85173,
            "grammar_hyp": 5.0501,
            "nubia_score": 0.69359
        },
        "meteor": 0.4349207263351451,
        "bleurt": 0.37766
    },
    "totto_test_contrast_challenge_ethnicity-all_usa": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.68895,
        "msttr-100_nopunct": 0.74824,
        "total_length": 1973,
        "mean_pred_length": 15.4140625,
        "std_pred_length": 4.764004591317451,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.4262544348707552,
        "vocab_size-1": 841,
        "unique-1": 671,
        "entropy-1": 8.122737749350566,
        "distinct-2": 0.8265582655826558,
        "vocab_size-2": 1525,
        "unique-2": 1382,
        "entropy-2": 10.32306138151868,
        "cond_entropy-2": 1.9498110098896564,
        "distinct-3": 0.9499126383226558,
        "vocab_size-3": 1631,
        "unique-3": 1575,
        "entropy-3": 10.621088766053253,
        "cond_entropy-3": 0.2682056229960132,
        "total_length-nopunct": 1743,
        "mean_pred_length-nopunct": 13.6171875,
        "std_pred_length-nopunct": 4.52962659496826,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4790590935169248,
        "vocab_size-1-nopunct": 835,
        "unique-1-nopunct": 671,
        "entropy-1-nopunct": 8.410558137852872,
        "distinct-2-nopunct": 0.8458204334365325,
        "vocab_size-2-nopunct": 1366,
        "unique-2-nopunct": 1255,
        "entropy-2-nopunct": 10.184012420967909,
        "cond_entropy-2-nopunct": 1.847805978787347,
        "distinct-3-nopunct": 0.9663752521856086,
        "vocab_size-3-nopunct": 1437,
        "unique-3-nopunct": 1400,
        "entropy-3-nopunct": 10.461101379609076,
        "cond_entropy-3-nopunct": 0.27668751916682954,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.062366979276565,
        "rouge1": {
            "precision": 0.81738,
            "recall": 0.78671,
            "fmeasure": 0.79344
        },
        "rouge2": {
            "precision": 0.58512,
            "recall": 0.56957,
            "fmeasure": 0.57104
        },
        "rougeL": {
            "precision": 0.70866,
            "recall": 0.68573,
            "fmeasure": 0.68987
        },
        "rougeLsum": {
            "precision": 0.70866,
            "recall": 0.68573,
            "fmeasure": 0.68987
        },
        "bleu": 48.63466,
        "local_recall": {
            "1": 0.1887905604719764,
            "2": 0.3142857142857143,
            "3": 0.8130904183535762
        },
        "bertscore": {
            "precision": 0.9413,
            "recall": 0.93816,
            "f1": 0.93846
        },
        "nubia": {
            "semantic_relation": 4.49805,
            "contradiction": 4.1503,
            "irrelevancy": 21.46983,
            "logical_agreement": 74.37987,
            "grammar_ref": 4.60573,
            "grammar_hyp": 4.59363,
            "nubia_score": 0.82519
        },
        "meteor": 0.41794494203099664,
        "bleurt": 0.38457
    },
    "totto_test_contrast_challenge_table_size-table_size_203": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 16.8,
        "std_pred_length": 4.019950248448356,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 64,
        "unique-1": 53,
        "entropy-1": 5.793928583415779,
        "distinct-2": 0.9746835443037974,
        "vocab_size-2": 77,
        "unique-2": 75,
        "entropy-2": 6.2531478367846995,
        "cond_entropy-2": 0.39582614193619614,
        "distinct-3": 1.0,
        "vocab_size-3": 74,
        "unique-3": 74,
        "entropy-3": 6.2094533656289554,
        "cond_entropy-3": -0.040273328494099044,
        "total_length-nopunct": 75,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.521363372331802,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8133333333333334,
        "vocab_size-1-nopunct": 61,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.7553550237715285,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 68,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.072140159802115,
        "cond_entropy-2-nopunct": 0.3506039693680417,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.022367813028458,
        "cond_entropy-3-nopunct": -0.04537674237805066,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8648924736610213,
        "rouge1": {
            "precision": 0.58724,
            "recall": 0.60829,
            "fmeasure": 0.58493
        },
        "rouge2": {
            "precision": 0.29054,
            "recall": 0.33678,
            "fmeasure": 0.30032
        },
        "rougeL": {
            "precision": 0.43825,
            "recall": 0.51547,
            "fmeasure": 0.46002
        },
        "rougeLsum": {
            "precision": 0.43825,
            "recall": 0.51547,
            "fmeasure": 0.46002
        },
        "bleu": 23.15157,
        "local_recall": {
            "1": 0.18518518518518517,
            "2": 0.15625,
            "3": 0.725
        },
        "bertscore": {
            "precision": 0.89825,
            "recall": 0.9035,
            "f1": 0.89245
        },
        "nubia": {
            "semantic_relation": 3.68467,
            "contradiction": 19.54289,
            "irrelevancy": 29.89595,
            "logical_agreement": 50.56116,
            "grammar_ref": 4.63083,
            "grammar_hyp": 4.36642,
            "nubia_score": 0.55287
        },
        "meteor": 0.3419023272971187,
        "bleurt": -0.1007
    },
    "totto_test_contrast_challenge_table_size-table_size_135": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.75667,
        "msttr-100_nopunct": 0.78333,
        "total_length": 380,
        "mean_pred_length": 16.52173913043478,
        "std_pred_length": 4.461132291610664,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5789473684210527,
        "vocab_size-1": 220,
        "unique-1": 176,
        "entropy-1": 7.073132550381381,
        "distinct-2": 0.9159663865546218,
        "vocab_size-2": 327,
        "unique-2": 306,
        "entropy-2": 8.284333660357404,
        "cond_entropy-2": 1.032817733849408,
        "distinct-3": 0.9640718562874252,
        "vocab_size-3": 322,
        "unique-3": 311,
        "entropy-3": 8.309587862826803,
        "cond_entropy-3": 0.03272507637505395,
        "total_length-nopunct": 336,
        "mean_pred_length-nopunct": 14.608695652173912,
        "std_pred_length-nopunct": 4.115074413557005,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6398809523809523,
        "vocab_size-1-nopunct": 215,
        "unique-1-nopunct": 175,
        "entropy-1-nopunct": 7.18237233326993,
        "distinct-2-nopunct": 0.9137380191693291,
        "vocab_size-2-nopunct": 286,
        "unique-2-nopunct": 268,
        "entropy-2-nopunct": 8.0862666504124,
        "cond_entropy-2-nopunct": 0.9635071352168709,
        "distinct-3-nopunct": 0.9689655172413794,
        "vocab_size-3-nopunct": 281,
        "unique-3-nopunct": 273,
        "entropy-3-nopunct": 8.115237064145402,
        "cond_entropy-3-nopunct": 0.03419929483132115,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.681289304344992,
        "rouge1": {
            "precision": 0.78695,
            "recall": 0.77808,
            "fmeasure": 0.77848
        },
        "rouge2": {
            "precision": 0.59734,
            "recall": 0.59219,
            "fmeasure": 0.59202
        },
        "rougeL": {
            "precision": 0.70634,
            "recall": 0.69464,
            "fmeasure": 0.69623
        },
        "rougeLsum": {
            "precision": 0.70634,
            "recall": 0.69464,
            "fmeasure": 0.69623
        },
        "bleu": 54.8268,
        "local_recall": {
            "1": 0.22077922077922077,
            "2": 0.5362318840579711,
            "3": 0.8508771929824561
        },
        "bertscore": {
            "precision": 0.93553,
            "recall": 0.93817,
            "f1": 0.93629
        },
        "nubia": {
            "semantic_relation": 4.28372,
            "contradiction": 9.25448,
            "irrelevancy": 28.15053,
            "logical_agreement": 62.59499,
            "grammar_ref": 4.82223,
            "grammar_hyp": 4.79653,
            "nubia_score": 0.75316
        },
        "meteor": 0.4372498771455377,
        "bleurt": 0.27698
    },
    "totto_test_contrast_challenge_continent-africa": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 45,
        "msttr-100": 0.66714,
        "msttr-100_nopunct": 0.695,
        "total_length": 710,
        "mean_pred_length": 15.777777777777779,
        "std_pred_length": 4.481512090498468,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.4507042253521127,
        "vocab_size-1": 320,
        "unique-1": 249,
        "entropy-1": 7.1596988432041435,
        "distinct-2": 0.7789473684210526,
        "vocab_size-2": 518,
        "unique-2": 446,
        "entropy-2": 8.730192382342617,
        "cond_entropy-2": 1.391902562302931,
        "distinct-3": 0.9241935483870968,
        "vocab_size-3": 573,
        "unique-3": 537,
        "entropy-3": 9.10328366421179,
        "cond_entropy-3": 0.3961130017379279,
        "total_length-nopunct": 643,
        "mean_pred_length-nopunct": 14.28888888888889,
        "std_pred_length-nopunct": 4.450329437105239,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.49144634525660963,
        "vocab_size-1-nopunct": 316,
        "unique-1-nopunct": 247,
        "entropy-1-nopunct": 7.287415681599234,
        "distinct-2-nopunct": 0.7709030100334449,
        "vocab_size-2-nopunct": 461,
        "unique-2-nopunct": 397,
        "entropy-2-nopunct": 8.540461049706007,
        "cond_entropy-2-nopunct": 1.3264847860290445,
        "distinct-3-nopunct": 0.918625678119349,
        "vocab_size-3-nopunct": 508,
        "unique-3-nopunct": 474,
        "entropy-3-nopunct": 8.92458728061669,
        "cond_entropy-3-nopunct": 0.42693249720518583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.242971847176812,
        "rouge1": {
            "precision": 0.82111,
            "recall": 0.76873,
            "fmeasure": 0.78575
        },
        "rouge2": {
            "precision": 0.59834,
            "recall": 0.5633,
            "fmeasure": 0.57339
        },
        "rougeL": {
            "precision": 0.69004,
            "recall": 0.64744,
            "fmeasure": 0.66068
        },
        "rougeLsum": {
            "precision": 0.69004,
            "recall": 0.64744,
            "fmeasure": 0.66068
        },
        "bleu": 47.7683,
        "local_recall": {
            "1": 0.12,
            "2": 0.5078125,
            "3": 0.8238866396761133
        },
        "bertscore": {
            "precision": 0.95067,
            "recall": 0.94371,
            "f1": 0.9466
        },
        "nubia": {
            "semantic_relation": 4.47822,
            "contradiction": 4.66973,
            "irrelevancy": 19.71999,
            "logical_agreement": 75.61028,
            "grammar_ref": 4.86201,
            "grammar_hyp": 4.92552,
            "nubia_score": 0.79566
        },
        "meteor": 0.41365100580802017,
        "bleurt": 0.41924
    },
    "totto_test_contrast_challenge_table_size-table_size_187": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.13452278258006412,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.831327223525026,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.78333,
            "fmeasure": 0.7914
        },
        "rouge2": {
            "precision": 0.54762,
            "recall": 0.53651,
            "fmeasure": 0.54187
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.78333,
            "fmeasure": 0.7914
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.78333,
            "fmeasure": 0.7914
        },
        "bleu": 28.97791,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.92911,
            "recall": 0.95992,
            "f1": 0.94427
        },
        "nubia": {
            "semantic_relation": 4.17689,
            "contradiction": 0.47637,
            "irrelevancy": 72.07946,
            "logical_agreement": 27.44417,
            "grammar_ref": 5.18542,
            "grammar_hyp": 5.54025,
            "nubia_score": 0.62331
        },
        "meteor": 0.38694980860409883,
        "bleurt": 0.29811
    },
    "totto_test_contrast_challenge_table_size-table_size_188": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.4969125210773475,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.75,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.8147832555327446,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.4739652756011968,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 30,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.736323877152398,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.34748852623240756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6043448909241,
        "rouge1": {
            "precision": 0.88928,
            "recall": 0.77975,
            "fmeasure": 0.82991
        },
        "rouge2": {
            "precision": 0.64506,
            "recall": 0.56092,
            "fmeasure": 0.59925
        },
        "rougeL": {
            "precision": 0.70682,
            "recall": 0.62137,
            "fmeasure": 0.6606
        },
        "rougeLsum": {
            "precision": 0.70682,
            "recall": 0.62137,
            "fmeasure": 0.6606
        },
        "bleu": 44.51562,
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.96829,
            "recall": 0.96756,
            "f1": 0.9679
        },
        "nubia": {
            "semantic_relation": 4.75865,
            "contradiction": 1.29111,
            "irrelevancy": 22.58511,
            "logical_agreement": 76.12378,
            "grammar_ref": 5.15044,
            "grammar_hyp": 5.47016,
            "nubia_score": 0.86671
        },
        "meteor": 0.4587155040560464,
        "bleurt": 0.5035
    },
    "totto_test_contrast_challenge_table_size-table_size_119": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 14.142857142857142,
        "std_pred_length": 2.899683304312063,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7171717171717171,
        "vocab_size-1": 71,
        "unique-1": 57,
        "entropy-1": 5.8790467722261415,
        "distinct-2": 0.9782608695652174,
        "vocab_size-2": 90,
        "unique-2": 88,
        "entropy-2": 6.480083695187462,
        "cond_entropy-2": 0.444522623837085,
        "distinct-3": 0.9882352941176471,
        "vocab_size-3": 84,
        "unique-3": 83,
        "entropy-3": 6.385861524373001,
        "cond_entropy-3": -0.09064160815460505,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 12.285714285714286,
        "std_pred_length-nopunct": 2.710523708715754,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7674418604651163,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.846330999109922,
        "distinct-2-nopunct": 0.9873417721518988,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.278464292480902,
        "cond_entropy-2-nopunct": 0.4708616008285141,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.1699250014423175,
        "cond_entropy-3-nopunct": -0.10607796895701274,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.1093692436150535,
        "rouge1": {
            "precision": 0.76414,
            "recall": 0.74065,
            "fmeasure": 0.74741
        },
        "rouge2": {
            "precision": 0.56654,
            "recall": 0.56757,
            "fmeasure": 0.56187
        },
        "rougeL": {
            "precision": 0.64805,
            "recall": 0.64287,
            "fmeasure": 0.63919
        },
        "rougeLsum": {
            "precision": 0.64805,
            "recall": 0.64287,
            "fmeasure": 0.63919
        },
        "bleu": 47.37448,
        "local_recall": {
            "1": 0.1282051282051282,
            "2": 0.3888888888888889,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.9324,
            "recall": 0.93772,
            "f1": 0.93387
        },
        "nubia": {
            "semantic_relation": 4.2236,
            "contradiction": 9.69613,
            "irrelevancy": 18.65282,
            "logical_agreement": 71.65106,
            "grammar_ref": 4.57228,
            "grammar_hyp": 4.34898,
            "nubia_score": 0.74075
        },
        "meteor": 0.41021850212720035,
        "bleurt": 0.22199
    },
    "totto_test_contrast_challenge_table_size-table_size_161": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 149,
        "mean_pred_length": 16.555555555555557,
        "std_pred_length": 5.101440125888443,
        "median_pred_length": 17.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6912751677852349,
        "vocab_size-1": 103,
        "unique-1": 89,
        "entropy-1": 6.253789636004635,
        "distinct-2": 0.95,
        "vocab_size-2": 133,
        "unique-2": 130,
        "entropy-2": 6.998107817112118,
        "cond_entropy-2": 0.625239680740189,
        "distinct-3": 0.9923664122137404,
        "vocab_size-3": 130,
        "unique-3": 129,
        "entropy-3": 7.018155825964931,
        "cond_entropy-3": 0.029060045482562417,
        "total_length-nopunct": 135,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.291502622129181,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 99,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.257873069132123,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 119,
        "unique-2-nopunct": 116,
        "entropy-2-nopunct": 6.831529701463414,
        "cond_entropy-2-nopunct": 0.6116369517800904,
        "distinct-3-nopunct": 0.9914529914529915,
        "vocab_size-3-nopunct": 116,
        "unique-3-nopunct": 115,
        "entropy-3-nopunct": 6.853270702489366,
        "cond_entropy-3-nopunct": 0.032952556567251,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.336218407409141,
        "rouge1": {
            "precision": 0.72754,
            "recall": 0.76001,
            "fmeasure": 0.73503
        },
        "rouge2": {
            "precision": 0.48407,
            "recall": 0.51614,
            "fmeasure": 0.49226
        },
        "rougeL": {
            "precision": 0.58796,
            "recall": 0.63802,
            "fmeasure": 0.60207
        },
        "rougeLsum": {
            "precision": 0.58796,
            "recall": 0.63802,
            "fmeasure": 0.60207
        },
        "bleu": 36.98062,
        "local_recall": {
            "1": 0.2972972972972973,
            "2": 0.5454545454545454,
            "3": 0.8507462686567164
        },
        "bertscore": {
            "precision": 0.90305,
            "recall": 0.92061,
            "f1": 0.91089
        },
        "nubia": {
            "semantic_relation": 4.23248,
            "contradiction": 2.67144,
            "irrelevancy": 39.69613,
            "logical_agreement": 57.63243,
            "grammar_ref": 5.14381,
            "grammar_hyp": 4.81325,
            "nubia_score": 0.74206
        },
        "meteor": 0.3700029502263116,
        "bleurt": 0.24427
    },
    "totto_test_contrast_challenge_continent-asia": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.71625,
        "msttr-100_nopunct": 0.75857,
        "total_length": 2432,
        "mean_pred_length": 16.213333333333335,
        "std_pred_length": 4.307492180943442,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.4292763157894737,
        "vocab_size-1": 1044,
        "unique-1": 832,
        "entropy-1": 8.301073991404413,
        "distinct-2": 0.7852760736196319,
        "vocab_size-2": 1792,
        "unique-2": 1601,
        "entropy-2": 10.472618490352923,
        "cond_entropy-2": 1.927815243366276,
        "distinct-3": 0.9099437148217636,
        "vocab_size-3": 1940,
        "unique-3": 1844,
        "entropy-3": 10.82292974071023,
        "cond_entropy-3": 0.3675371886172813,
        "total_length-nopunct": 2119,
        "mean_pred_length-nopunct": 14.126666666666667,
        "std_pred_length-nopunct": 3.9569292246499543,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.48890986314299195,
        "vocab_size-1-nopunct": 1036,
        "unique-1-nopunct": 829,
        "entropy-1-nopunct": 8.620487487254536,
        "distinct-2-nopunct": 0.8044692737430168,
        "vocab_size-2-nopunct": 1584,
        "unique-2-nopunct": 1445,
        "entropy-2-nopunct": 10.291714258148858,
        "cond_entropy-2-nopunct": 1.7841266830553815,
        "distinct-3-nopunct": 0.9323804288070369,
        "vocab_size-3-nopunct": 1696,
        "unique-3-nopunct": 1631,
        "entropy-3-nopunct": 10.654028695820733,
        "cond_entropy-3-nopunct": 0.40452192025329625,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.420124833148089,
        "rouge1": {
            "precision": 0.82369,
            "recall": 0.78541,
            "fmeasure": 0.79624
        },
        "rouge2": {
            "precision": 0.61074,
            "recall": 0.59034,
            "fmeasure": 0.59394
        },
        "rougeL": {
            "precision": 0.72129,
            "recall": 0.69008,
            "fmeasure": 0.6983
        },
        "rougeLsum": {
            "precision": 0.72129,
            "recall": 0.69008,
            "fmeasure": 0.6983
        },
        "bleu": 51.04402,
        "local_recall": {
            "1": 0.188470066518847,
            "2": 0.43243243243243246,
            "3": 0.7989690721649485
        },
        "bertscore": {
            "precision": 0.95224,
            "recall": 0.94787,
            "f1": 0.94907
        },
        "nubia": {
            "semantic_relation": 4.47742,
            "contradiction": 6.92293,
            "irrelevancy": 22.74922,
            "logical_agreement": 70.32785,
            "grammar_ref": 5.14336,
            "grammar_hyp": 5.16172,
            "nubia_score": 0.78735
        },
        "meteor": 0.41915192752255925,
        "bleurt": 0.39735
    },
    "totto_test_contrast_challenge_table_size-table_size_228": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.78,
        "total_length": 184,
        "mean_pred_length": 16.727272727272727,
        "std_pred_length": 5.609908589287822,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.7119565217391305,
        "vocab_size-1": 131,
        "unique-1": 115,
        "entropy-1": 6.5986493670871855,
        "distinct-2": 0.9710982658959537,
        "vocab_size-2": 168,
        "unique-2": 164,
        "entropy-2": 7.372461247855434,
        "cond_entropy-2": 0.6677119586045979,
        "distinct-3": 1.0,
        "vocab_size-3": 162,
        "unique-3": 162,
        "entropy-3": 7.339850002884606,
        "cond_entropy-3": -0.02839003029430084,
        "total_length-nopunct": 163,
        "mean_pred_length-nopunct": 14.818181818181818,
        "std_pred_length-nopunct": 5.3226476975652535,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7791411042944786,
        "vocab_size-1-nopunct": 127,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.651460722590183,
        "distinct-2-nopunct": 0.9671052631578947,
        "vocab_size-2-nopunct": 147,
        "unique-2-nopunct": 143,
        "entropy-2-nopunct": 7.177171674613544,
        "cond_entropy-2-nopunct": 0.5657437102295088,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.139551352398772,
        "cond_entropy-3-nopunct": -0.03210036315710779,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.654564514111267,
        "rouge1": {
            "precision": 0.74176,
            "recall": 0.75947,
            "fmeasure": 0.73269
        },
        "rouge2": {
            "precision": 0.52339,
            "recall": 0.53456,
            "fmeasure": 0.5152
        },
        "rougeL": {
            "precision": 0.65934,
            "recall": 0.66156,
            "fmeasure": 0.64455
        },
        "rougeLsum": {
            "precision": 0.65934,
            "recall": 0.66156,
            "fmeasure": 0.64455
        },
        "bleu": 47.4691,
        "local_recall": {
            "1": 0.25,
            "2": 0.42105263157894735,
            "3": 0.7571428571428571
        },
        "bertscore": {
            "precision": 0.90913,
            "recall": 0.91017,
            "f1": 0.90856
        },
        "nubia": {
            "semantic_relation": 3.84634,
            "contradiction": 11.21427,
            "irrelevancy": 39.60006,
            "logical_agreement": 49.18568,
            "grammar_ref": 4.46209,
            "grammar_hyp": 4.33651,
            "nubia_score": 0.68335
        },
        "meteor": 0.4145337256038618,
        "bleurt": 0.09778
    },
    "totto_test_contrast_challenge_table_size-table_size_204": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 210,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.605057240266746,
        "median_pred_length": 16.5,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.6523809523809524,
        "vocab_size-1": 137,
        "unique-1": 115,
        "entropy-1": 6.610857776844887,
        "distinct-2": 0.9797979797979798,
        "vocab_size-2": 194,
        "unique-2": 191,
        "entropy-2": 7.585140016533312,
        "cond_entropy-2": 0.8733800777741969,
        "distinct-3": 1.0,
        "vocab_size-3": 186,
        "unique-3": 186,
        "entropy-3": 7.539158811108047,
        "cond_entropy-3": -0.04312852132553806,
        "total_length-nopunct": 191,
        "mean_pred_length-nopunct": 15.916666666666666,
        "std_pred_length-nopunct": 5.6782968886414835,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6963350785340314,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 113,
        "entropy-1-nopunct": 6.641090293118572,
        "distinct-2-nopunct": 0.9776536312849162,
        "vocab_size-2-nopunct": 175,
        "unique-2-nopunct": 172,
        "entropy-2-nopunct": 7.434905791218642,
        "cond_entropy-2-nopunct": 0.8510002043515111,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 167,
        "unique-3-nopunct": 167,
        "entropy-3-nopunct": 7.383704292474028,
        "cond_entropy-3-nopunct": -0.04768700872934527,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.4882817184065855,
        "rouge1": {
            "precision": 0.77461,
            "recall": 0.69092,
            "fmeasure": 0.71664
        },
        "rouge2": {
            "precision": 0.52963,
            "recall": 0.46236,
            "fmeasure": 0.48334
        },
        "rougeL": {
            "precision": 0.69993,
            "recall": 0.5962,
            "fmeasure": 0.62967
        },
        "rougeLsum": {
            "precision": 0.69993,
            "recall": 0.5962,
            "fmeasure": 0.62967
        },
        "bleu": 31.62816,
        "local_recall": {
            "1": 0.12,
            "2": 0.15384615384615385,
            "3": 0.7058823529411765
        },
        "bertscore": {
            "precision": 0.93404,
            "recall": 0.90734,
            "f1": 0.91904
        },
        "nubia": {
            "semantic_relation": 4.11425,
            "contradiction": 18.96493,
            "irrelevancy": 25.51688,
            "logical_agreement": 55.51819,
            "grammar_ref": 4.36261,
            "grammar_hyp": 4.50993,
            "nubia_score": 0.68754
        },
        "meteor": 0.33319541948252396,
        "bleurt": 0.22945
    },
    "totto_test_contrast_challenge_table_size-table_size_230": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.84,
        "total_length": 167,
        "mean_pred_length": 16.7,
        "std_pred_length": 4.712748667179271,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7305389221556886,
        "vocab_size-1": 122,
        "unique-1": 106,
        "entropy-1": 6.545456167208276,
        "distinct-2": 0.9745222929936306,
        "vocab_size-2": 153,
        "unique-2": 151,
        "entropy-2": 7.234048933577438,
        "cond_entropy-2": 0.5303965899601323,
        "distinct-3": 1.0,
        "vocab_size-3": 147,
        "unique-3": 147,
        "entropy-3": 7.199672344836354,
        "cond_entropy-3": -0.030256057087051987,
        "total_length-nopunct": 146,
        "mean_pred_length-nopunct": 14.6,
        "std_pred_length-nopunct": 3.97994974842648,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8013698630136986,
        "vocab_size-1-nopunct": 117,
        "unique-1-nopunct": 105,
        "entropy-1-nopunct": 6.592164415276038,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 132,
        "unique-2-nopunct": 130,
        "entropy-2-nopunct": 7.017538025042041,
        "cond_entropy-2-nopunct": 0.4693192085604289,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 126,
        "unique-3-nopunct": 126,
        "entropy-3-nopunct": 6.977279923499926,
        "cond_entropy-3-nopunct": -0.034708512954177415,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.688684300019809,
        "rouge1": {
            "precision": 0.7221,
            "recall": 0.68562,
            "fmeasure": 0.69757
        },
        "rouge2": {
            "precision": 0.49648,
            "recall": 0.45973,
            "fmeasure": 0.4737
        },
        "rougeL": {
            "precision": 0.61148,
            "recall": 0.56756,
            "fmeasure": 0.58446
        },
        "rougeLsum": {
            "precision": 0.61148,
            "recall": 0.56756,
            "fmeasure": 0.58446
        },
        "bleu": 52.45637,
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.6052631578947368,
            "3": 0.7524752475247525
        },
        "bertscore": {
            "precision": 0.92606,
            "recall": 0.91747,
            "f1": 0.92109
        },
        "nubia": {
            "semantic_relation": 4.27628,
            "contradiction": 15.58349,
            "irrelevancy": 33.18283,
            "logical_agreement": 51.23368,
            "grammar_ref": 5.06465,
            "grammar_hyp": 4.79839,
            "nubia_score": 0.75041
        },
        "meteor": 0.4010004349799593,
        "bleurt": 0.28456
    },
    "totto_test_contrast_challenge_table_size-table_size_189": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.745,
        "total_length": 259,
        "mean_pred_length": 14.38888888888889,
        "std_pred_length": 4.461425891758634,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.5945945945945946,
        "vocab_size-1": 154,
        "unique-1": 123,
        "entropy-1": 6.619632032951261,
        "distinct-2": 0.921161825726141,
        "vocab_size-2": 222,
        "unique-2": 210,
        "entropy-2": 7.72091978226115,
        "cond_entropy-2": 0.9114970752879149,
        "distinct-3": 0.9730941704035875,
        "vocab_size-3": 217,
        "unique-3": 211,
        "entropy-3": 7.747088240727489,
        "cond_entropy-3": 0.0416637587867129,
        "total_length-nopunct": 229,
        "mean_pred_length-nopunct": 12.722222222222221,
        "std_pred_length-nopunct": 4.292183535937489,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6637554585152838,
        "vocab_size-1-nopunct": 152,
        "unique-1-nopunct": 123,
        "entropy-1-nopunct": 6.774616670447074,
        "distinct-2-nopunct": 0.9146919431279621,
        "vocab_size-2-nopunct": 193,
        "unique-2-nopunct": 182,
        "entropy-2-nopunct": 7.511314058344697,
        "cond_entropy-2-nopunct": 0.8077525685433601,
        "distinct-3-nopunct": 0.9740932642487047,
        "vocab_size-3-nopunct": 188,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.540643565765468,
        "cond_entropy-3-nopunct": 0.04889495999348797,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.7301401861826475,
        "rouge1": {
            "precision": 0.74582,
            "recall": 0.69393,
            "fmeasure": 0.7083
        },
        "rouge2": {
            "precision": 0.50364,
            "recall": 0.46793,
            "fmeasure": 0.4764
        },
        "rougeL": {
            "precision": 0.63188,
            "recall": 0.57766,
            "fmeasure": 0.59462
        },
        "rougeLsum": {
            "precision": 0.63188,
            "recall": 0.57766,
            "fmeasure": 0.59462
        },
        "bleu": 41.15544,
        "local_recall": {
            "1": 0.17045454545454544,
            "2": 0.3728813559322034,
            "3": 0.7763975155279503
        },
        "bertscore": {
            "precision": 0.92845,
            "recall": 0.92155,
            "f1": 0.9229
        },
        "nubia": {
            "semantic_relation": 4.25427,
            "contradiction": 15.88024,
            "irrelevancy": 21.88468,
            "logical_agreement": 62.23508,
            "grammar_ref": 4.82101,
            "grammar_hyp": 4.64598,
            "nubia_score": 0.75002
        },
        "meteor": 0.3839877389654228,
        "bleurt": 0.29688
    },
    "totto_test_contrast_challenge_continent-europe": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.71348,
        "msttr-100_nopunct": 0.762,
        "total_length": 2337,
        "mean_pred_length": 15.58,
        "std_pred_length": 5.22847332720875,
        "median_pred_length": 14.0,
        "min_pred_length": 5,
        "max_pred_length": 30,
        "distinct-1": 0.41762943945228925,
        "vocab_size-1": 976,
        "unique-1": 771,
        "entropy-1": 8.194844385057497,
        "distinct-2": 0.8166438042981253,
        "vocab_size-2": 1786,
        "unique-2": 1614,
        "entropy-2": 10.52258279844156,
        "cond_entropy-2": 2.0844127646110135,
        "distinct-3": 0.9405989199803633,
        "vocab_size-3": 1916,
        "unique-3": 1832,
        "entropy-3": 10.853667624108832,
        "cond_entropy-3": 0.34706840126122385,
        "total_length-nopunct": 2057,
        "mean_pred_length-nopunct": 13.713333333333333,
        "std_pred_length-nopunct": 4.800467569819516,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4720466699076325,
        "vocab_size-1-nopunct": 971,
        "unique-1-nopunct": 771,
        "entropy-1-nopunct": 8.489375849004949,
        "distinct-2-nopunct": 0.8311484006292607,
        "vocab_size-2-nopunct": 1585,
        "unique-2-nopunct": 1454,
        "entropy-2-nopunct": 10.346997669280508,
        "cond_entropy-2-nopunct": 1.9731446325117845,
        "distinct-3-nopunct": 0.9533295389869095,
        "vocab_size-3-nopunct": 1675,
        "unique-3-nopunct": 1615,
        "entropy-3-nopunct": 10.671833516453416,
        "cond_entropy-3-nopunct": 0.3560019435598432,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.078362121886864,
        "rouge1": {
            "precision": 0.79357,
            "recall": 0.75135,
            "fmeasure": 0.76386
        },
        "rouge2": {
            "precision": 0.55154,
            "recall": 0.52357,
            "fmeasure": 0.53144
        },
        "rougeL": {
            "precision": 0.67401,
            "recall": 0.64494,
            "fmeasure": 0.65181
        },
        "rougeLsum": {
            "precision": 0.67401,
            "recall": 0.64494,
            "fmeasure": 0.65181
        },
        "bleu": 46.42616,
        "local_recall": {
            "1": 0.1788793103448276,
            "2": 0.44054054054054054,
            "3": 0.7872212176009644
        },
        "bertscore": {
            "precision": 0.93975,
            "recall": 0.93549,
            "f1": 0.93573
        },
        "nubia": {
            "semantic_relation": 4.39399,
            "contradiction": 6.31528,
            "irrelevancy": 22.51316,
            "logical_agreement": 71.17156,
            "grammar_ref": 4.85127,
            "grammar_hyp": 4.81284,
            "nubia_score": 0.77876
        },
        "meteor": 0.4054512727303515,
        "bleurt": 0.35485
    },
    "totto_test_contrast_challenge_table_size-table_size_136": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.72667,
        "msttr-100_nopunct": 0.77,
        "total_length": 379,
        "mean_pred_length": 16.47826086956522,
        "std_pred_length": 4.499947489716734,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.6279683377308707,
        "vocab_size-1": 238,
        "unique-1": 208,
        "entropy-1": 7.170431270536705,
        "distinct-2": 0.9578651685393258,
        "vocab_size-2": 341,
        "unique-2": 330,
        "entropy-2": 8.375986871965507,
        "cond_entropy-2": 1.0301025949184892,
        "distinct-3": 0.993993993993994,
        "vocab_size-3": 331,
        "unique-3": 329,
        "entropy-3": 8.367366355059282,
        "cond_entropy-3": -0.001731114933192971,
        "total_length-nopunct": 332,
        "mean_pred_length-nopunct": 14.434782608695652,
        "std_pred_length-nopunct": 4.178891957950012,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6987951807228916,
        "vocab_size-1-nopunct": 232,
        "unique-1-nopunct": 207,
        "entropy-1-nopunct": 7.2954078031885405,
        "distinct-2-nopunct": 0.9644012944983819,
        "vocab_size-2-nopunct": 298,
        "unique-2-nopunct": 291,
        "entropy-2-nopunct": 8.182434629832104,
        "cond_entropy-2-nopunct": 0.9501646886265868,
        "distinct-3-nopunct": 0.9965034965034965,
        "vocab_size-3-nopunct": 285,
        "unique-3-nopunct": 284,
        "entropy-3-nopunct": 8.152878329785432,
        "cond_entropy-3-nopunct": -0.022396673628338585,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.220518243397987,
        "rouge1": {
            "precision": 0.77772,
            "recall": 0.7273,
            "fmeasure": 0.73332
        },
        "rouge2": {
            "precision": 0.54798,
            "recall": 0.52133,
            "fmeasure": 0.51884
        },
        "rougeL": {
            "precision": 0.65681,
            "recall": 0.62135,
            "fmeasure": 0.62234
        },
        "rougeLsum": {
            "precision": 0.65681,
            "recall": 0.62135,
            "fmeasure": 0.62234
        },
        "bleu": 43.29377,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.37349397590361444,
            "3": 0.757201646090535
        },
        "bertscore": {
            "precision": 0.93255,
            "recall": 0.91707,
            "f1": 0.92278
        },
        "nubia": {
            "semantic_relation": 4.21643,
            "contradiction": 3.74553,
            "irrelevancy": 34.01718,
            "logical_agreement": 62.23729,
            "grammar_ref": 4.55066,
            "grammar_hyp": 4.47805,
            "nubia_score": 0.73872
        },
        "meteor": 0.37955003339593024,
        "bleurt": 0.24848
    },
    "totto_test_contrast_challenge_table_size-table_size_205": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.76,
        "total_length": 182,
        "mean_pred_length": 15.166666666666666,
        "std_pred_length": 2.576604138956718,
        "median_pred_length": 15.5,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.6263736263736264,
        "vocab_size-1": 114,
        "unique-1": 93,
        "entropy-1": 6.29456795894697,
        "distinct-2": 0.9117647058823529,
        "vocab_size-2": 155,
        "unique-2": 145,
        "entropy-2": 7.207834097864203,
        "cond_entropy-2": 0.7458494928370746,
        "distinct-3": 0.9746835443037974,
        "vocab_size-3": 154,
        "unique-3": 150,
        "entropy-3": 7.253147836784714,
        "cond_entropy-3": 0.06062185321972024,
        "total_length-nopunct": 158,
        "mean_pred_length-nopunct": 13.166666666666666,
        "std_pred_length-nopunct": 2.0749832663314556,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.6962025316455697,
        "vocab_size-1-nopunct": 110,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.355757292612798,
        "distinct-2-nopunct": 0.910958904109589,
        "vocab_size-2-nopunct": 133,
        "unique-2-nopunct": 125,
        "entropy-2-nopunct": 6.982532349931456,
        "cond_entropy-2-nopunct": 0.6909961632554615,
        "distinct-3-nopunct": 0.9850746268656716,
        "vocab_size-3-nopunct": 132,
        "unique-3-nopunct": 130,
        "entropy-3-nopunct": 7.036238444189124,
        "cond_entropy-3-nopunct": 0.06480688908887759,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.992006708953836,
        "rouge1": {
            "precision": 0.80255,
            "recall": 0.7743,
            "fmeasure": 0.78344
        },
        "rouge2": {
            "precision": 0.57371,
            "recall": 0.53913,
            "fmeasure": 0.55243
        },
        "rougeL": {
            "precision": 0.72577,
            "recall": 0.68638,
            "fmeasure": 0.70069
        },
        "rougeLsum": {
            "precision": 0.72577,
            "recall": 0.68638,
            "fmeasure": 0.70069
        },
        "bleu": 53.03407,
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.3448275862068966,
            "3": 0.8016528925619835
        },
        "bertscore": {
            "precision": 0.95465,
            "recall": 0.94718,
            "f1": 0.94875
        },
        "nubia": {
            "semantic_relation": 4.6764,
            "contradiction": 0.4034,
            "irrelevancy": 15.75033,
            "logical_agreement": 83.84627,
            "grammar_ref": 4.24445,
            "grammar_hyp": 4.09728,
            "nubia_score": 0.91913
        },
        "meteor": 0.4261317313701453,
        "bleurt": 0.52419
    },
    "totto_test_contrast_challenge_table_size-table_size_138": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 291,
        "mean_pred_length": 15.31578947368421,
        "std_pred_length": 4.942326658344624,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 22,
        "distinct-1": 0.5773195876288659,
        "vocab_size-1": 168,
        "unique-1": 134,
        "entropy-1": 6.776517477804038,
        "distinct-2": 0.8823529411764706,
        "vocab_size-2": 240,
        "unique-2": 218,
        "entropy-2": 7.814525962730029,
        "cond_entropy-2": 0.8809199964543828,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 242,
        "unique-3": 232,
        "entropy-3": 7.893053307887306,
        "cond_entropy-3": 0.09902458109363134,
        "total_length-nopunct": 265,
        "mean_pred_length-nopunct": 13.947368421052632,
        "std_pred_length-nopunct": 4.925483510441827,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6226415094339622,
        "vocab_size-1-nopunct": 165,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.856092811925701,
        "distinct-2-nopunct": 0.8739837398373984,
        "vocab_size-2-nopunct": 215,
        "unique-2-nopunct": 194,
        "entropy-2-nopunct": 7.64886072095908,
        "cond_entropy-2-nopunct": 0.8650218456892639,
        "distinct-3-nopunct": 0.9559471365638766,
        "vocab_size-3-nopunct": 217,
        "unique-3-nopunct": 208,
        "entropy-3-nopunct": 7.735117264814406,
        "cond_entropy-3-nopunct": 0.1064302086272877,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.791578148147138,
        "rouge1": {
            "precision": 0.73371,
            "recall": 0.64018,
            "fmeasure": 0.67093
        },
        "rouge2": {
            "precision": 0.53094,
            "recall": 0.47679,
            "fmeasure": 0.49326
        },
        "rougeL": {
            "precision": 0.65663,
            "recall": 0.58002,
            "fmeasure": 0.60419
        },
        "rougeLsum": {
            "precision": 0.65663,
            "recall": 0.58002,
            "fmeasure": 0.60419
        },
        "bleu": 39.91511,
        "local_recall": {
            "1": 0.12987012987012986,
            "2": 0.21568627450980393,
            "3": 0.6810344827586207
        },
        "bertscore": {
            "precision": 0.91926,
            "recall": 0.89483,
            "f1": 0.90369
        },
        "nubia": {
            "semantic_relation": 4.10725,
            "contradiction": 9.58374,
            "irrelevancy": 26.19696,
            "logical_agreement": 64.2193,
            "grammar_ref": 4.44575,
            "grammar_hyp": 4.84187,
            "nubia_score": 0.67383
        },
        "meteor": 0.35937270934030663,
        "bleurt": 0.18745
    },
    "totto_test_contrast_challenge_table_size-table_size_207": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 5.436502143433364,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 35,
        "unique-1": 27,
        "entropy-1": 4.969274489883449,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 43,
        "unique-2": 42,
        "entropy-2": 5.41397707318275,
        "cond_entropy-2": 0.34824674433072633,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.05309912621433557,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 5.792715732327589,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7906976744186046,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.972549056927052,
        "distinct-2-nopunct": 0.975,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.271928094887364,
        "cond_entropy-2-nopunct": 0.3334077152934375,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.05842067520435857,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.00667284688068,
        "rouge1": {
            "precision": 0.68357,
            "recall": 0.88788,
            "fmeasure": 0.75442
        },
        "rouge2": {
            "precision": 0.54978,
            "recall": 0.70722,
            "fmeasure": 0.6003
        },
        "rougeL": {
            "precision": 0.67874,
            "recall": 0.88361,
            "fmeasure": 0.74989
        },
        "rougeLsum": {
            "precision": 0.67874,
            "recall": 0.88361,
            "fmeasure": 0.74989
        },
        "bleu": 56.16215,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8888888888888888,
            "3": 0.8636363636363636
        },
        "bertscore": {
            "precision": 0.91051,
            "recall": 0.94837,
            "f1": 0.92869
        },
        "nubia": {
            "semantic_relation": 4.33868,
            "contradiction": 0.36571,
            "irrelevancy": 52.8534,
            "logical_agreement": 46.78089,
            "grammar_ref": 5.944,
            "grammar_hyp": 5.33907,
            "nubia_score": 0.79796
        },
        "meteor": 0.471415050458596,
        "bleurt": 0.30984
    },
    "totto_test_contrast_challenge_table_size-table_size_231": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.79,
        "total_length": 229,
        "mean_pred_length": 14.3125,
        "std_pred_length": 3.8196653976493806,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 22,
        "distinct-1": 0.6069868995633187,
        "vocab_size-1": 139,
        "unique-1": 109,
        "entropy-1": 6.55802356408691,
        "distinct-2": 0.9342723004694836,
        "vocab_size-2": 199,
        "unique-2": 187,
        "entropy-2": 7.5938645498033415,
        "cond_entropy-2": 0.8316103922148036,
        "distinct-3": 0.9644670050761421,
        "vocab_size-3": 190,
        "unique-3": 183,
        "entropy-3": 7.550985829608622,
        "cond_entropy-3": -0.031439526657786446,
        "total_length-nopunct": 199,
        "mean_pred_length-nopunct": 12.4375,
        "std_pred_length-nopunct": 3.4635377506243525,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.678391959798995,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 109,
        "entropy-1-nopunct": 6.6523005185639015,
        "distinct-2-nopunct": 0.9344262295081968,
        "vocab_size-2-nopunct": 171,
        "unique-2-nopunct": 161,
        "entropy-2-nopunct": 7.373623335551797,
        "cond_entropy-2-nopunct": 0.7865787225049486,
        "distinct-3-nopunct": 0.9700598802395209,
        "vocab_size-3-nopunct": 162,
        "unique-3-nopunct": 157,
        "entropy-3-nopunct": 7.32382405295307,
        "cond_entropy-3-nopunct": -0.03618716257645745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.451041125826967,
        "rouge1": {
            "precision": 0.81221,
            "recall": 0.79665,
            "fmeasure": 0.80218
        },
        "rouge2": {
            "precision": 0.59101,
            "recall": 0.58584,
            "fmeasure": 0.58684
        },
        "rougeL": {
            "precision": 0.70857,
            "recall": 0.69582,
            "fmeasure": 0.70014
        },
        "rougeLsum": {
            "precision": 0.70857,
            "recall": 0.69582,
            "fmeasure": 0.70014
        },
        "bleu": 54.70959,
        "local_recall": {
            "1": 0.24390243902439024,
            "2": 0.43478260869565216,
            "3": 0.8292682926829268
        },
        "bertscore": {
            "precision": 0.94116,
            "recall": 0.94277,
            "f1": 0.94178
        },
        "nubia": {
            "semantic_relation": 4.56007,
            "contradiction": 5.53082,
            "irrelevancy": 34.81954,
            "logical_agreement": 59.64964,
            "grammar_ref": 4.58203,
            "grammar_hyp": 4.56721,
            "nubia_score": 0.83216
        },
        "meteor": 0.42592144182537556,
        "bleurt": 0.40994
    },
    "totto_test_contrast_challenge_table_size-table_size_190": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.8,
        "total_length": 187,
        "mean_pred_length": 14.384615384615385,
        "std_pred_length": 3.520018827276169,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 18,
        "distinct-1": 0.6470588235294118,
        "vocab_size-1": 121,
        "unique-1": 100,
        "entropy-1": 6.467907993264188,
        "distinct-2": 0.9367816091954023,
        "vocab_size-2": 163,
        "unique-2": 155,
        "entropy-2": 7.30067402744547,
        "cond_entropy-2": 0.6369103314816927,
        "distinct-3": 0.9937888198757764,
        "vocab_size-3": 160,
        "unique-3": 159,
        "entropy-3": 7.318494517866155,
        "cond_entropy-3": 0.029308087248270324,
        "total_length-nopunct": 163,
        "mean_pred_length-nopunct": 12.538461538461538,
        "std_pred_length-nopunct": 3.1772117581635975,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7116564417177914,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.553238872496441,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 140,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.07711944048144,
        "cond_entropy-2-nopunct": 0.5861563057353673,
        "distinct-3-nopunct": 0.9927007299270073,
        "vocab_size-3-nopunct": 136,
        "unique-3-nopunct": 135,
        "entropy-3-nopunct": 7.083433542814526,
        "cond_entropy-3-nopunct": 0.020708921677517846,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.768943781608881,
        "rouge1": {
            "precision": 0.89961,
            "recall": 0.86039,
            "fmeasure": 0.87684
        },
        "rouge2": {
            "precision": 0.67519,
            "recall": 0.64472,
            "fmeasure": 0.65737
        },
        "rougeL": {
            "precision": 0.78666,
            "recall": 0.75158,
            "fmeasure": 0.76593
        },
        "rougeLsum": {
            "precision": 0.78666,
            "recall": 0.75158,
            "fmeasure": 0.76593
        },
        "bleu": 61.46168,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.09090909090909091,
            "3": 0.9078947368421053
        },
        "bertscore": {
            "precision": 0.97212,
            "recall": 0.96802,
            "f1": 0.96966
        },
        "nubia": {
            "semantic_relation": 4.7818,
            "contradiction": 0.30461,
            "irrelevancy": 9.96873,
            "logical_agreement": 89.72666,
            "grammar_ref": 5.1809,
            "grammar_hyp": 5.23772,
            "nubia_score": 0.90431
        },
        "meteor": 0.48437317368120986,
        "bleurt": 0.64336
    },
    "totto_test_contrast_challenge_table_size-table_size_162": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.7325,
        "msttr-100_nopunct": 0.75667,
        "total_length": 422,
        "mean_pred_length": 16.23076923076923,
        "std_pred_length": 4.448921151052693,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6066350710900474,
        "vocab_size-1": 256,
        "unique-1": 220,
        "entropy-1": 7.216904344171016,
        "distinct-2": 0.9343434343434344,
        "vocab_size-2": 370,
        "unique-2": 356,
        "entropy-2": 8.465165837229545,
        "cond_entropy-2": 1.0762153147435614,
        "distinct-3": 0.9918918918918919,
        "vocab_size-3": 367,
        "unique-3": 364,
        "entropy-3": 8.515165244300118,
        "cond_entropy-3": 0.04328068504883837,
        "total_length-nopunct": 380,
        "mean_pred_length-nopunct": 14.615384615384615,
        "std_pred_length-nopunct": 4.403468240418988,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6605263157894737,
        "vocab_size-1-nopunct": 251,
        "unique-1-nopunct": 219,
        "entropy-1-nopunct": 7.299831974175103,
        "distinct-2-nopunct": 0.940677966101695,
        "vocab_size-2-nopunct": 333,
        "unique-2-nopunct": 323,
        "entropy-2-nopunct": 8.314315543002484,
        "cond_entropy-2-nopunct": 1.061231895167981,
        "distinct-3-nopunct": 0.9969512195121951,
        "vocab_size-3-nopunct": 327,
        "unique-3-nopunct": 326,
        "entropy-3-nopunct": 8.351454443642481,
        "cond_entropy-3-nopunct": 0.04319237681097127,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.04643372094199,
        "rouge1": {
            "precision": 0.74464,
            "recall": 0.68286,
            "fmeasure": 0.70094
        },
        "rouge2": {
            "precision": 0.50281,
            "recall": 0.45805,
            "fmeasure": 0.47102
        },
        "rougeL": {
            "precision": 0.60555,
            "recall": 0.56667,
            "fmeasure": 0.57553
        },
        "rougeLsum": {
            "precision": 0.60555,
            "recall": 0.56667,
            "fmeasure": 0.57553
        },
        "bleu": 44.05591,
        "local_recall": {
            "1": 0.18823529411764706,
            "2": 0.5522388059701493,
            "3": 0.7165354330708661
        },
        "bertscore": {
            "precision": 0.9178,
            "recall": 0.90931,
            "f1": 0.91207
        },
        "nubia": {
            "semantic_relation": 3.9383,
            "contradiction": 14.64049,
            "irrelevancy": 38.35819,
            "logical_agreement": 47.00132,
            "grammar_ref": 4.52061,
            "grammar_hyp": 4.5895,
            "nubia_score": 0.63917
        },
        "meteor": 0.3616242790836437,
        "bleurt": 0.13671
    },
    "totto_test_contrast_challenge_table_size-table_size_232": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 161,
        "mean_pred_length": 17.88888888888889,
        "std_pred_length": 4.771313456351975,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.6645962732919255,
        "vocab_size-1": 107,
        "unique-1": 94,
        "entropy-1": 6.143611941907758,
        "distinct-2": 0.9407894736842105,
        "vocab_size-2": 143,
        "unique-2": 138,
        "entropy-2": 7.09325794104668,
        "cond_entropy-2": 0.8906608673722071,
        "distinct-3": 0.986013986013986,
        "vocab_size-3": 141,
        "unique-3": 139,
        "entropy-3": 7.131899308806369,
        "cond_entropy-3": 0.048375816372055125,
        "total_length-nopunct": 147,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 4.760952285695233,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7074829931972789,
        "vocab_size-1-nopunct": 104,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.138482989254233,
        "distinct-2-nopunct": 0.9347826086956522,
        "vocab_size-2-nopunct": 129,
        "unique-2-nopunct": 124,
        "entropy-2-nopunct": 6.938163768341015,
        "cond_entropy-2-nopunct": 0.8616424037261925,
        "distinct-3-nopunct": 0.9844961240310077,
        "vocab_size-3-nopunct": 127,
        "unique-3-nopunct": 125,
        "entropy-3-nopunct": 6.9802195034852526,
        "cond_entropy-3-nopunct": 0.053941364570100035,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.139999291513029,
        "rouge1": {
            "precision": 0.73602,
            "recall": 0.71719,
            "fmeasure": 0.71849
        },
        "rouge2": {
            "precision": 0.46404,
            "recall": 0.46184,
            "fmeasure": 0.45758
        },
        "rougeL": {
            "precision": 0.59478,
            "recall": 0.59283,
            "fmeasure": 0.5856
        },
        "rougeLsum": {
            "precision": 0.59478,
            "recall": 0.59283,
            "fmeasure": 0.5856
        },
        "bleu": 30.26646,
        "local_recall": {
            "1": 0.4090909090909091,
            "2": 0.25,
            "3": 0.7043478260869566
        },
        "bertscore": {
            "precision": 0.93081,
            "recall": 0.92331,
            "f1": 0.92679
        },
        "nubia": {
            "semantic_relation": 4.24565,
            "contradiction": 6.19753,
            "irrelevancy": 23.32098,
            "logical_agreement": 70.48149,
            "grammar_ref": 4.7133,
            "grammar_hyp": 4.33891,
            "nubia_score": 0.78103
        },
        "meteor": 0.34249154539199583,
        "bleurt": 0.27442
    },
    "totto_test_contrast_challenge_continent-north_ameria": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 150,
        "msttr-100": 0.70958,
        "msttr-100_nopunct": 0.7719,
        "total_length": 2495,
        "mean_pred_length": 16.633333333333333,
        "std_pred_length": 5.111316420997193,
        "median_pred_length": 15.5,
        "min_pred_length": 7,
        "max_pred_length": 33,
        "distinct-1": 0.42925851703406814,
        "vocab_size-1": 1071,
        "unique-1": 840,
        "entropy-1": 8.30760521904733,
        "distinct-2": 0.8217484008528785,
        "vocab_size-2": 1927,
        "unique-2": 1743,
        "entropy-2": 10.657374587243153,
        "cond_entropy-2": 2.1136311812389548,
        "distinct-3": 0.9435079726651481,
        "vocab_size-3": 2071,
        "unique-3": 1989,
        "entropy-3": 10.96580995976984,
        "cond_entropy-3": 0.2961302710051594,
        "total_length-nopunct": 2143,
        "mean_pred_length-nopunct": 14.286666666666667,
        "std_pred_length-nopunct": 4.517132817273462,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.49510032664489034,
        "vocab_size-1-nopunct": 1061,
        "unique-1-nopunct": 838,
        "entropy-1-nopunct": 8.6628409431898,
        "distinct-2-nopunct": 0.8534872052182639,
        "vocab_size-2-nopunct": 1701,
        "unique-2-nopunct": 1580,
        "entropy-2-nopunct": 10.500829010030818,
        "cond_entropy-2-nopunct": 1.934742608341506,
        "distinct-3-nopunct": 0.9614758545849159,
        "vocab_size-3-nopunct": 1772,
        "unique-3-nopunct": 1721,
        "entropy-3-nopunct": 10.758968706177798,
        "cond_entropy-3-nopunct": 0.2842166007687662,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.360166217603517,
        "rouge1": {
            "precision": 0.83188,
            "recall": 0.78089,
            "fmeasure": 0.79931
        },
        "rouge2": {
            "precision": 0.59492,
            "recall": 0.55675,
            "fmeasure": 0.57011
        },
        "rougeL": {
            "precision": 0.72573,
            "recall": 0.67766,
            "fmeasure": 0.69516
        },
        "rougeLsum": {
            "precision": 0.72573,
            "recall": 0.67766,
            "fmeasure": 0.69516
        },
        "bleu": 49.92583,
        "local_recall": {
            "1": 0.16706443914081145,
            "2": 0.3003533568904594,
            "3": 0.8002148227712137
        },
        "bertscore": {
            "precision": 0.94454,
            "recall": 0.9405,
            "f1": 0.94168
        },
        "nubia": {
            "semantic_relation": 4.52458,
            "contradiction": 3.02066,
            "irrelevancy": 19.93495,
            "logical_agreement": 77.04439,
            "grammar_ref": 4.5685,
            "grammar_hyp": 4.66592,
            "nubia_score": 0.81869
        },
        "meteor": 0.42449255288219206,
        "bleurt": 0.40236
    },
    "totto_test_contrast_challenge_table_size-table_size_164": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.65,
        "msttr-100_nopunct": 0.72,
        "total_length": 161,
        "mean_pred_length": 13.416666666666666,
        "std_pred_length": 4.424521317486095,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 20,
        "distinct-1": 0.6211180124223602,
        "vocab_size-1": 100,
        "unique-1": 76,
        "entropy-1": 6.139052590333506,
        "distinct-2": 0.9328859060402684,
        "vocab_size-2": 139,
        "unique-2": 130,
        "entropy-2": 7.079873973467784,
        "cond_entropy-2": 0.7480886411525082,
        "distinct-3": 0.9854014598540146,
        "vocab_size-3": 135,
        "unique-3": 133,
        "entropy-3": 7.068835002668541,
        "cond_entropy-3": 0.0011620114192665313,
        "total_length-nopunct": 142,
        "mean_pred_length-nopunct": 11.833333333333334,
        "std_pred_length-nopunct": 4.239365780658968,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6901408450704225,
        "vocab_size-1-nopunct": 98,
        "unique-1-nopunct": 76,
        "entropy-1-nopunct": 6.239753345774404,
        "distinct-2-nopunct": 0.9307692307692308,
        "vocab_size-2-nopunct": 121,
        "unique-2-nopunct": 113,
        "entropy-2-nopunct": 6.878099447627198,
        "cond_entropy-2-nopunct": 0.6992686040432853,
        "distinct-3-nopunct": 0.9915254237288136,
        "vocab_size-3-nopunct": 117,
        "unique-3-nopunct": 116,
        "entropy-3-nopunct": 6.86569389681946,
        "cond_entropy-3-nopunct": -0.006208767885566839,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.213236334411125,
        "rouge1": {
            "precision": 0.83334,
            "recall": 0.74556,
            "fmeasure": 0.77701
        },
        "rouge2": {
            "precision": 0.55055,
            "recall": 0.49178,
            "fmeasure": 0.51263
        },
        "rougeL": {
            "precision": 0.73295,
            "recall": 0.65383,
            "fmeasure": 0.68254
        },
        "rougeLsum": {
            "precision": 0.73295,
            "recall": 0.65383,
            "fmeasure": 0.68254
        },
        "bleu": 42.16898,
        "local_recall": {
            "1": 0.1724137931034483,
            "2": 0.5238095238095238,
            "3": 0.7383177570093458
        },
        "bertscore": {
            "precision": 0.93379,
            "recall": 0.92131,
            "f1": 0.9246
        },
        "nubia": {
            "semantic_relation": 4.4509,
            "contradiction": 3.15231,
            "irrelevancy": 18.72581,
            "logical_agreement": 78.12188,
            "grammar_ref": 4.9625,
            "grammar_hyp": 5.32879,
            "nubia_score": 0.76921
        },
        "meteor": 0.4088210480968684,
        "bleurt": 0.26939
    },
    "totto_test_contrast_challenge_table_size-table_size_258": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 143,
        "mean_pred_length": 15.88888888888889,
        "std_pred_length": 3.9845380171202462,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.6993006993006993,
        "vocab_size-1": 100,
        "unique-1": 87,
        "entropy-1": 6.210306959301735,
        "distinct-2": 0.9701492537313433,
        "vocab_size-2": 130,
        "unique-2": 127,
        "entropy-2": 7.000754209098351,
        "cond_entropy-2": 0.6413185511720544,
        "distinct-3": 1.0,
        "vocab_size-3": 125,
        "unique-3": 125,
        "entropy-3": 6.965784284662096,
        "cond_entropy-3": -0.030265805778377862,
        "total_length-nopunct": 130,
        "mean_pred_length-nopunct": 14.444444444444445,
        "std_pred_length-nopunct": 3.7151674438445528,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7384615384615385,
        "vocab_size-1-nopunct": 96,
        "unique-1-nopunct": 85,
        "entropy-1-nopunct": 6.212687959442445,
        "distinct-2-nopunct": 0.9669421487603306,
        "vocab_size-2-nopunct": 117,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.846508795107963,
        "cond_entropy-2-nopunct": 0.694044957006618,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 112,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.807354922057591,
        "cond_entropy-3-nopunct": -0.03333967680481657,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.477230403857195,
        "rouge1": {
            "precision": 0.68145,
            "recall": 0.74518,
            "fmeasure": 0.67812
        },
        "rouge2": {
            "precision": 0.45736,
            "recall": 0.54037,
            "fmeasure": 0.47504
        },
        "rougeL": {
            "precision": 0.62064,
            "recall": 0.70674,
            "fmeasure": 0.63413
        },
        "rougeLsum": {
            "precision": 0.62064,
            "recall": 0.70674,
            "fmeasure": 0.63413
        },
        "bleu": 34.89861,
        "local_recall": {
            "1": 0.10344827586206896,
            "2": 0.35714285714285715,
            "3": 0.8051948051948052
        },
        "bertscore": {
            "precision": 0.90676,
            "recall": 0.90816,
            "f1": 0.9053
        },
        "nubia": {
            "semantic_relation": 4.07218,
            "contradiction": 11.88116,
            "irrelevancy": 31.03001,
            "logical_agreement": 57.08883,
            "grammar_ref": 5.16318,
            "grammar_hyp": 4.79768,
            "nubia_score": 0.67746
        },
        "meteor": 0.34488499596051697,
        "bleurt": 0.19643
    },
    "totto_test_contrast_challenge_table_size-table_size_165": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.70333,
        "msttr-100_nopunct": 0.76,
        "total_length": 329,
        "mean_pred_length": 17.31578947368421,
        "std_pred_length": 6.07889040757091,
        "median_pred_length": 18.0,
        "min_pred_length": 7,
        "max_pred_length": 28,
        "distinct-1": 0.5805471124620061,
        "vocab_size-1": 191,
        "unique-1": 154,
        "entropy-1": 6.929101472983784,
        "distinct-2": 0.9129032258064517,
        "vocab_size-2": 283,
        "unique-2": 260,
        "entropy-2": 8.090609002034444,
        "cond_entropy-2": 1.0557785087741838,
        "distinct-3": 0.9690721649484536,
        "vocab_size-3": 282,
        "unique-3": 273,
        "entropy-3": 8.12301967280519,
        "cond_entropy-3": 0.02131068850058759,
        "total_length-nopunct": 288,
        "mean_pred_length-nopunct": 15.157894736842104,
        "std_pred_length-nopunct": 5.450863358894692,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6458333333333334,
        "vocab_size-1-nopunct": 186,
        "unique-1-nopunct": 153,
        "entropy-1-nopunct": 7.007137268492451,
        "distinct-2-nopunct": 0.929368029739777,
        "vocab_size-2-nopunct": 250,
        "unique-2-nopunct": 234,
        "entropy-2-nopunct": 7.919957204555988,
        "cond_entropy-2-nopunct": 0.9652101476845396,
        "distinct-3-nopunct": 0.972,
        "vocab_size-3-nopunct": 243,
        "unique-3-nopunct": 236,
        "entropy-3-nopunct": 7.909784284662099,
        "cond_entropy-3-nopunct": -0.0113382278916526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.679588798295056,
        "rouge1": {
            "precision": 0.72639,
            "recall": 0.70131,
            "fmeasure": 0.70644
        },
        "rouge2": {
            "precision": 0.46715,
            "recall": 0.45301,
            "fmeasure": 0.45362
        },
        "rougeL": {
            "precision": 0.62329,
            "recall": 0.60953,
            "fmeasure": 0.60965
        },
        "rougeLsum": {
            "precision": 0.62329,
            "recall": 0.60953,
            "fmeasure": 0.60965
        },
        "bleu": 40.43459,
        "local_recall": {
            "1": 0.2459016393442623,
            "2": 0.3728813559322034,
            "3": 0.7246376811594203
        },
        "bertscore": {
            "precision": 0.91646,
            "recall": 0.92058,
            "f1": 0.91638
        },
        "nubia": {
            "semantic_relation": 3.90955,
            "contradiction": 5.61008,
            "irrelevancy": 39.39879,
            "logical_agreement": 54.99113,
            "grammar_ref": 4.52561,
            "grammar_hyp": 4.43941,
            "nubia_score": 0.67258
        },
        "meteor": 0.37180981701450144,
        "bleurt": 0.14686
    },
    "totto_test_contrast_challenge_table_size-table_size_208": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 23,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.74,
        "total_length": 371,
        "mean_pred_length": 16.130434782608695,
        "std_pred_length": 4.046515923027106,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 25,
        "distinct-1": 0.5525606469002695,
        "vocab_size-1": 205,
        "unique-1": 162,
        "entropy-1": 6.924569453055074,
        "distinct-2": 0.8994252873563219,
        "vocab_size-2": 313,
        "unique-2": 294,
        "entropy-2": 8.185398516235432,
        "cond_entropy-2": 1.081311457458314,
        "distinct-3": 0.9723076923076923,
        "vocab_size-3": 316,
        "unique-3": 311,
        "entropy-3": 8.276603600223469,
        "cond_entropy-3": 0.08481595946844374,
        "total_length-nopunct": 327,
        "mean_pred_length-nopunct": 14.217391304347826,
        "std_pred_length-nopunct": 3.5989916672304134,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6116207951070336,
        "vocab_size-1-nopunct": 200,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 7.04144464286982,
        "distinct-2-nopunct": 0.9078947368421053,
        "vocab_size-2-nopunct": 276,
        "unique-2-nopunct": 261,
        "entropy-2-nopunct": 8.008221048301227,
        "cond_entropy-2-nopunct": 1.0223074508948595,
        "distinct-3-nopunct": 0.9822064056939501,
        "vocab_size-3-nopunct": 276,
        "unique-3-nopunct": 273,
        "entropy-3-nopunct": 8.091721693886411,
        "cond_entropy-3-nopunct": 0.06650967163046277,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.020811217365055,
        "rouge1": {
            "precision": 0.73932,
            "recall": 0.73361,
            "fmeasure": 0.72556
        },
        "rouge2": {
            "precision": 0.51992,
            "recall": 0.51525,
            "fmeasure": 0.50812
        },
        "rougeL": {
            "precision": 0.63811,
            "recall": 0.64223,
            "fmeasure": 0.62924
        },
        "rougeLsum": {
            "precision": 0.63811,
            "recall": 0.64223,
            "fmeasure": 0.62924
        },
        "bleu": 41.91579,
        "local_recall": {
            "1": 0.22666666666666666,
            "2": 0.4918032786885246,
            "3": 0.7542372881355932
        },
        "bertscore": {
            "precision": 0.9092,
            "recall": 0.90996,
            "f1": 0.90751
        },
        "nubia": {
            "semantic_relation": 4.25612,
            "contradiction": 6.46844,
            "irrelevancy": 29.36271,
            "logical_agreement": 64.16886,
            "grammar_ref": 4.22562,
            "grammar_hyp": 4.04248,
            "nubia_score": 0.77663
        },
        "meteor": 0.39007805734019235,
        "bleurt": 0.20313
    },
    "totto_test_contrast_challenge_table_size-table_size_209": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.403677461028802,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.66667,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.2,
            "fmeasure": 0.16667
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "bleu": 10.55267,
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.85044,
            "recall": 0.87917,
            "f1": 0.86457
        },
        "nubia": {
            "semantic_relation": 4.02698,
            "contradiction": 1.86126,
            "irrelevancy": 26.31256,
            "logical_agreement": 71.82617,
            "grammar_ref": 6.80479,
            "grammar_hyp": 5.54028,
            "nubia_score": 0.7693
        },
        "meteor": 0.2976554604054448,
        "bleurt": -0.26375
    },
    "totto_test_contrast_challenge_table_size-table_size_259": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.5491933384829668,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.7230769230769231,
        "vocab_size-1": 47,
        "unique-1": 40,
        "entropy-1": 5.243457190211676,
        "distinct-2": 0.95,
        "vocab_size-2": 57,
        "unique-2": 55,
        "entropy-2": 5.794309137239126,
        "cond_entropy-2": 0.42226715768823797,
        "distinct-3": 1.0,
        "vocab_size-3": 55,
        "unique-3": 55,
        "entropy-3": 5.7813597135246555,
        "cond_entropy-3": -0.0027147456808866294,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 11.6,
        "std_pred_length-nopunct": 1.7435595774162693,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7758620689655172,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.21971289153009,
        "distinct-2-nopunct": 0.9433962264150944,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.600469746975206,
        "cond_entropy-2-nopunct": 0.44097082748261607,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.002231130880304183,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.328506771552792,
        "rouge1": {
            "precision": 0.84505,
            "recall": 0.818,
            "fmeasure": 0.82747
        },
        "rouge2": {
            "precision": 0.61079,
            "recall": 0.58791,
            "fmeasure": 0.59048
        },
        "rougeL": {
            "precision": 0.78444,
            "recall": 0.76547,
            "fmeasure": 0.7712
        },
        "rougeLsum": {
            "precision": 0.78444,
            "recall": 0.76547,
            "fmeasure": 0.7712
        },
        "bleu": 56.62655,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.2222222222222222,
            "3": 0.84
        },
        "bertscore": {
            "precision": 0.9693,
            "recall": 0.95077,
            "f1": 0.95959
        },
        "nubia": {
            "semantic_relation": 4.654,
            "contradiction": 1.38953,
            "irrelevancy": 1.07636,
            "logical_agreement": 97.53411,
            "grammar_ref": 4.84964,
            "grammar_hyp": 4.8908,
            "nubia_score": 0.83608
        },
        "meteor": 0.48038080165608465,
        "bleurt": 0.55256
    },
    "totto_test_contrast_challenge_table_size-table_size_234": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.7,
        "total_length": 180,
        "mean_pred_length": 12.857142857142858,
        "std_pred_length": 3.979539507766891,
        "median_pred_length": 13.5,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.6166666666666667,
        "vocab_size-1": 111,
        "unique-1": 94,
        "entropy-1": 6.159978440748256,
        "distinct-2": 0.9397590361445783,
        "vocab_size-2": 156,
        "unique-2": 149,
        "entropy-2": 7.232812681500904,
        "cond_entropy-2": 0.8640587965920106,
        "distinct-3": 0.993421052631579,
        "vocab_size-3": 151,
        "unique-3": 150,
        "entropy-3": 7.234769618706724,
        "cond_entropy-3": -0.011259020045202243,
        "total_length-nopunct": 160,
        "mean_pred_length-nopunct": 11.428571428571429,
        "std_pred_length-nopunct": 3.499271061118826,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.68125,
        "vocab_size-1-nopunct": 109,
        "unique-1-nopunct": 94,
        "entropy-1-nopunct": 6.253648756815365,
        "distinct-2-nopunct": 0.9452054794520548,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.055511952890727,
        "cond_entropy-2-nopunct": 0.8769036805480211,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 132,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.044394119358443,
        "cond_entropy-3-nopunct": -0.0120240722909821,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.237427228451539,
        "rouge1": {
            "precision": 0.74162,
            "recall": 0.70351,
            "fmeasure": 0.70661
        },
        "rouge2": {
            "precision": 0.5136,
            "recall": 0.49747,
            "fmeasure": 0.49474
        },
        "rougeL": {
            "precision": 0.68441,
            "recall": 0.65651,
            "fmeasure": 0.65481
        },
        "rougeLsum": {
            "precision": 0.68441,
            "recall": 0.65651,
            "fmeasure": 0.65481
        },
        "bleu": 47.01705,
        "local_recall": {
            "1": 0.16216216216216217,
            "2": 0.36666666666666664,
            "3": 0.7421875
        },
        "bertscore": {
            "precision": 0.9337,
            "recall": 0.92169,
            "f1": 0.9261
        },
        "nubia": {
            "semantic_relation": 4.22629,
            "contradiction": 5.95764,
            "irrelevancy": 19.28743,
            "logical_agreement": 74.75494,
            "grammar_ref": 4.23107,
            "grammar_hyp": 4.29194,
            "nubia_score": 0.76691
        },
        "meteor": 0.4136251038648109,
        "bleurt": 0.29442
    },
    "totto_test_contrast_challenge_table_size-table_size_235": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "total_length": 108,
        "mean_pred_length": 15.428571428571429,
        "std_pred_length": 3.9227229193559943,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7129629629629629,
        "vocab_size-1": 77,
        "unique-1": 64,
        "entropy-1": 5.974510882371852,
        "distinct-2": 0.9306930693069307,
        "vocab_size-2": 94,
        "unique-2": 88,
        "entropy-2": 6.5121234876808565,
        "cond_entropy-2": 0.43813598485568794,
        "distinct-3": 0.9680851063829787,
        "vocab_size-3": 91,
        "unique-3": 88,
        "entropy-3": 6.490759064443584,
        "cond_entropy-3": -0.03176212573199277,
        "total_length-nopunct": 97,
        "mean_pred_length-nopunct": 13.857142857142858,
        "std_pred_length-nopunct": 3.8703477668983046,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7525773195876289,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.939953951145862,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.3501321240834026,
        "cond_entropy-2-nopunct": 0.4392860866852139,
        "distinct-3-nopunct": 0.9759036144578314,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.326846660262594,
        "cond_entropy-3-nopunct": -0.035429478209695935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.991068954919409,
        "rouge1": {
            "precision": 0.71984,
            "recall": 0.72451,
            "fmeasure": 0.71585
        },
        "rouge2": {
            "precision": 0.52231,
            "recall": 0.49603,
            "fmeasure": 0.50234
        },
        "rougeL": {
            "precision": 0.65021,
            "recall": 0.63425,
            "fmeasure": 0.63371
        },
        "rougeLsum": {
            "precision": 0.65021,
            "recall": 0.63425,
            "fmeasure": 0.63371
        },
        "bleu": 44.17243,
        "local_recall": {
            "1": 0.2571428571428571,
            "2": 0.5,
            "3": 0.7846153846153846
        },
        "bertscore": {
            "precision": 0.90384,
            "recall": 0.91263,
            "f1": 0.90571
        },
        "nubia": {
            "semantic_relation": 4.08066,
            "contradiction": 10.62514,
            "irrelevancy": 51.8573,
            "logical_agreement": 37.51756,
            "grammar_ref": 5.24762,
            "grammar_hyp": 4.58931,
            "nubia_score": 0.72134
        },
        "meteor": 0.3511653903535462,
        "bleurt": 0.09963
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 350,
        "msttr-100": 0.67068,
        "msttr-100_nopunct": 0.69735,
        "total_length": 7468,
        "mean_pred_length": 21.337142857142858,
        "std_pred_length": 3.8195800602598577,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.14113551151580075,
        "vocab_size-1": 1054,
        "unique-1": 374,
        "entropy-1": 7.970044888623509,
        "distinct-2": 0.3973026130935656,
        "vocab_size-2": 2828,
        "unique-2": 1675,
        "entropy-2": 10.678168584477637,
        "cond_entropy-2": 2.6315790043638043,
        "distinct-3": 0.5938238770685579,
        "vocab_size-3": 4019,
        "unique-3": 2907,
        "entropy-3": 11.535946104490957,
        "cond_entropy-3": 0.9201330490648875,
        "total_length-nopunct": 6806,
        "mean_pred_length-nopunct": 19.445714285714285,
        "std_pred_length-nopunct": 3.783599409265722,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.15383485160152807,
        "vocab_size-1-nopunct": 1047,
        "unique-1-nopunct": 374,
        "entropy-1-nopunct": 8.123437513701619,
        "distinct-2-nopunct": 0.40257125154894674,
        "vocab_size-2-nopunct": 2599,
        "unique-2-nopunct": 1574,
        "entropy-2-nopunct": 10.557808783019707,
        "cond_entropy-2-nopunct": 2.5734538128033133,
        "distinct-3-nopunct": 0.5962987225679659,
        "vocab_size-3-nopunct": 3641,
        "unique-3-nopunct": 2662,
        "entropy-3-nopunct": 11.388504303224897,
        "cond_entropy-3-nopunct": 0.8850387411884343,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 8.529334541821509,
        "rouge1": {
            "precision": 0.76161,
            "recall": 0.74198,
            "fmeasure": 0.74455
        },
        "rouge2": {
            "precision": 0.50283,
            "recall": 0.4829,
            "fmeasure": 0.48741
        },
        "rougeL": {
            "precision": 0.61251,
            "recall": 0.58911,
            "fmeasure": 0.5944
        },
        "rougeLsum": {
            "precision": 0.61251,
            "recall": 0.58911,
            "fmeasure": 0.5944
        },
        "bleu": 46.46765,
        "local_recall": {
            "1": 0.22120225051821144,
            "2": 0.561328334226031,
            "3": 0.8566978193146417,
            "4": 0.5,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.91788,
            "recall": 0.91256,
            "f1": 0.91378
        },
        "nubia": {
            "semantic_relation": 4.38102,
            "contradiction": 7.44444,
            "irrelevancy": 10.25858,
            "logical_agreement": 82.29698,
            "grammar_ref": 4.50573,
            "grammar_hyp": 4.66946,
            "nubia_score": 0.75326
        },
        "meteor": 0.38405139375468567,
        "bleurt": 0.13197
    },
    "totto_test_contrast_challenge_table_size-table_size_168": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 44,
        "msttr-100": 0.745,
        "msttr-100_nopunct": 0.786,
        "total_length": 638,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.9800639556304986,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.5376175548589341,
        "vocab_size-1": 343,
        "unique-1": 278,
        "entropy-1": 7.48000560374069,
        "distinct-2": 0.8602693602693603,
        "vocab_size-2": 511,
        "unique-2": 468,
        "entropy-2": 8.85503737183676,
        "cond_entropy-2": 1.1527569947721823,
        "distinct-3": 0.9254545454545454,
        "vocab_size-3": 509,
        "unique-3": 480,
        "entropy-3": 8.937726626546558,
        "cond_entropy-3": 0.10052270371787497,
        "total_length-nopunct": 574,
        "mean_pred_length-nopunct": 13.045454545454545,
        "std_pred_length-nopunct": 4.022406253241423,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.5871080139372822,
        "vocab_size-1-nopunct": 337,
        "unique-1-nopunct": 274,
        "entropy-1-nopunct": 7.644088134511499,
        "distinct-2-nopunct": 0.8547169811320755,
        "vocab_size-2-nopunct": 453,
        "unique-2-nopunct": 415,
        "entropy-2-nopunct": 8.671247660049733,
        "cond_entropy-2-nopunct": 1.1153597177151244,
        "distinct-3-nopunct": 0.9238683127572016,
        "vocab_size-3-nopunct": 449,
        "unique-3-nopunct": 423,
        "entropy-3-nopunct": 8.75546319800126,
        "cond_entropy-3-nopunct": 0.10785445591900299,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.872088346377729,
        "rouge1": {
            "precision": 0.76445,
            "recall": 0.70575,
            "fmeasure": 0.72612
        },
        "rouge2": {
            "precision": 0.54571,
            "recall": 0.51618,
            "fmeasure": 0.52447
        },
        "rougeL": {
            "precision": 0.67442,
            "recall": 0.64019,
            "fmeasure": 0.64863
        },
        "rougeLsum": {
            "precision": 0.67442,
            "recall": 0.64019,
            "fmeasure": 0.64863
        },
        "bleu": 48.16372,
        "local_recall": {
            "1": 0.24285714285714285,
            "2": 0.5448717948717948,
            "3": 0.7294685990338164
        },
        "bertscore": {
            "precision": 0.93108,
            "recall": 0.92151,
            "f1": 0.92415
        },
        "nubia": {
            "semantic_relation": 4.19527,
            "contradiction": 7.03959,
            "irrelevancy": 31.25839,
            "logical_agreement": 61.70202,
            "grammar_ref": 4.41204,
            "grammar_hyp": 4.51085,
            "nubia_score": 0.7374
        },
        "meteor": 0.3866550022703358,
        "bleurt": 0.29224
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 114,
        "msttr-100": 0.65815,
        "msttr-100_nopunct": 0.6788,
        "total_length": 2733,
        "mean_pred_length": 23.973684210526315,
        "std_pred_length": 2.820540343640128,
        "median_pred_length": 24.0,
        "min_pred_length": 18,
        "max_pred_length": 30,
        "distinct-1": 0.22502744237102085,
        "vocab_size-1": 615,
        "unique-1": 300,
        "entropy-1": 7.626447533236882,
        "distinct-2": 0.48949980908743795,
        "vocab_size-2": 1282,
        "unique-2": 830,
        "entropy-2": 9.753940255707846,
        "cond_entropy-2": 2.189321661973887,
        "distinct-3": 0.6435129740518962,
        "vocab_size-3": 1612,
        "unique-3": 1206,
        "entropy-3": 10.313770220437613,
        "cond_entropy-3": 0.6008166424772293,
        "total_length-nopunct": 2515,
        "mean_pred_length-nopunct": 22.06140350877193,
        "std_pred_length-nopunct": 2.7697776455162826,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.24174950298210734,
        "vocab_size-1-nopunct": 608,
        "unique-1-nopunct": 298,
        "entropy-1-nopunct": 7.726611462626654,
        "distinct-2-nopunct": 0.5039566847147022,
        "vocab_size-2-nopunct": 1210,
        "unique-2-nopunct": 797,
        "entropy-2-nopunct": 9.704928898626928,
        "cond_entropy-2-nopunct": 2.0678833881827123,
        "distinct-3-nopunct": 0.6523830345430696,
        "vocab_size-3-nopunct": 1492,
        "unique-3-nopunct": 1133,
        "entropy-3-nopunct": 10.207122883227983,
        "cond_entropy-3-nopunct": 0.5462072001158679,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 1.5679371597404141,
        "rouge1": {
            "precision": 0.78549,
            "recall": 0.46144,
            "fmeasure": 0.57126
        },
        "rouge2": {
            "precision": 0.47685,
            "recall": 0.26379,
            "fmeasure": 0.33339
        },
        "rougeL": {
            "precision": 0.60359,
            "recall": 0.34801,
            "fmeasure": 0.43371
        },
        "rougeLsum": {
            "precision": 0.60359,
            "recall": 0.34801,
            "fmeasure": 0.43371
        },
        "bleu": 23.33601,
        "local_recall": {
            "1": 0.13363533408833522,
            "2": 0.3951612903225806,
            "3": 0.5924812030075188
        },
        "bertscore": {
            "precision": 0.90514,
            "recall": 0.83081,
            "f1": 0.8649
        },
        "nubia": {
            "semantic_relation": 3.26316,
            "contradiction": 5.06616,
            "irrelevancy": 12.5375,
            "logical_agreement": 82.39634,
            "grammar_ref": 4.06233,
            "grammar_hyp": 4.61469,
            "nubia_score": 0.37857
        },
        "meteor": 0.23246274096800096,
        "bleurt": -0.37096
    },
    "totto_test_contrast_challenge_table_size-table_size_238": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.67,
        "msttr-100_nopunct": 0.69,
        "total_length": 119,
        "mean_pred_length": 13.222222222222221,
        "std_pred_length": 5.370242654930921,
        "median_pred_length": 12.0,
        "min_pred_length": 6,
        "max_pred_length": 23,
        "distinct-1": 0.6302521008403361,
        "vocab_size-1": 75,
        "unique-1": 54,
        "entropy-1": 5.913572755152411,
        "distinct-2": 0.8545454545454545,
        "vocab_size-2": 94,
        "unique-2": 78,
        "entropy-2": 6.490450622615573,
        "cond_entropy-2": 0.397804049830603,
        "distinct-3": 0.8712871287128713,
        "vocab_size-3": 88,
        "unique-3": 75,
        "entropy-3": 6.400785740177523,
        "cond_entropy-3": -0.06374229017880548,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 11.777777777777779,
        "std_pred_length-nopunct": 5.533288710217215,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6886792452830188,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.970950351190287,
        "distinct-2-nopunct": 0.845360824742268,
        "vocab_size-2-nopunct": 82,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 6.290634491671673,
        "cond_entropy-2-nopunct": 0.379609201619057,
        "distinct-3-nopunct": 0.8636363636363636,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 64,
        "entropy-3-nopunct": 6.186704345910031,
        "cond_entropy-3-nopunct": -0.08366304173164854,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.2543353723223065,
        "rouge1": {
            "precision": 0.86313,
            "recall": 0.74771,
            "fmeasure": 0.78626
        },
        "rouge2": {
            "precision": 0.61904,
            "recall": 0.55684,
            "fmeasure": 0.57876
        },
        "rougeL": {
            "precision": 0.81827,
            "recall": 0.71278,
            "fmeasure": 0.74846
        },
        "rougeLsum": {
            "precision": 0.81827,
            "recall": 0.71278,
            "fmeasure": 0.74846
        },
        "bleu": 51.24901,
        "local_recall": {
            "1": 0.32432432432432434,
            "2": 0.55,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.95455,
            "recall": 0.91893,
            "f1": 0.93569
        },
        "nubia": {
            "semantic_relation": 4.04938,
            "contradiction": 2.83374,
            "irrelevancy": 16.8273,
            "logical_agreement": 80.33896,
            "grammar_ref": 4.78166,
            "grammar_hyp": 5.25541,
            "nubia_score": 0.67163
        },
        "meteor": 0.3849692750615796,
        "bleurt": 0.24828
    },
    "totto_test_contrast_challenge_table_size-table_size_260": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 22,
        "msttr-100": 0.70667,
        "msttr-100_nopunct": 0.76,
        "total_length": 325,
        "mean_pred_length": 14.772727272727273,
        "std_pred_length": 3.8368052309395755,
        "median_pred_length": 14.5,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.5876923076923077,
        "vocab_size-1": 191,
        "unique-1": 151,
        "entropy-1": 6.9485126781657245,
        "distinct-2": 0.8844884488448845,
        "vocab_size-2": 268,
        "unique-2": 244,
        "entropy-2": 7.978688948861009,
        "cond_entropy-2": 0.8271022283723124,
        "distinct-3": 0.9572953736654805,
        "vocab_size-3": 269,
        "unique-3": 259,
        "entropy-3": 8.043644202767808,
        "cond_entropy-3": 0.06430995412552261,
        "total_length-nopunct": 284,
        "mean_pred_length-nopunct": 12.909090909090908,
        "std_pred_length-nopunct": 3.476009871691848,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6514084507042254,
        "vocab_size-1-nopunct": 185,
        "unique-1-nopunct": 150,
        "entropy-1-nopunct": 7.051763454078363,
        "distinct-2-nopunct": 0.8969465648854962,
        "vocab_size-2-nopunct": 235,
        "unique-2-nopunct": 218,
        "entropy-2-nopunct": 7.7914990397617,
        "cond_entropy-2-nopunct": 0.7824010845988946,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 232,
        "unique-3-nopunct": 225,
        "entropy-3-nopunct": 7.8370785643495475,
        "cond_entropy-3-nopunct": 0.046214533577936576,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.908025364334025,
        "rouge1": {
            "precision": 0.85679,
            "recall": 0.84131,
            "fmeasure": 0.84224
        },
        "rouge2": {
            "precision": 0.70772,
            "recall": 0.68918,
            "fmeasure": 0.69326
        },
        "rougeL": {
            "precision": 0.78673,
            "recall": 0.77729,
            "fmeasure": 0.77585
        },
        "rougeLsum": {
            "precision": 0.78673,
            "recall": 0.77729,
            "fmeasure": 0.77585
        },
        "bleu": 64.25765,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.2222222222222222,
            "3": 0.8656126482213439
        },
        "bertscore": {
            "precision": 0.95675,
            "recall": 0.95659,
            "f1": 0.95602
        },
        "nubia": {
            "semantic_relation": 4.53348,
            "contradiction": 0.61451,
            "irrelevancy": 22.74762,
            "logical_agreement": 76.63787,
            "grammar_ref": 4.36588,
            "grammar_hyp": 4.32989,
            "nubia_score": 0.86116
        },
        "meteor": 0.48427036697195197,
        "bleurt": 0.51585
    },
    "totto_test_contrast_challenge_table_size-table_size_261": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 0.5,
        "median_pred_length": 14.5,
        "min_pred_length": 14,
        "max_pred_length": 15,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 24,
        "entropy-1": 4.625053839880556,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.02968289595149494,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.96,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5638561897747225,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": -0.03333771197858132,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0787978894207506,
        "rouge1": {
            "precision": 0.60909,
            "recall": 0.62882,
            "fmeasure": 0.60692
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.42521,
            "fmeasure": 0.36746
        },
        "rougeL": {
            "precision": 0.58283,
            "recall": 0.62161,
            "fmeasure": 0.57764
        },
        "rougeLsum": {
            "precision": 0.58283,
            "recall": 0.62161,
            "fmeasure": 0.57764
        },
        "bleu": 26.15934,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.0,
            "3": 0.7647058823529411
        },
        "bertscore": {
            "precision": 0.88701,
            "recall": 0.89142,
            "f1": 0.88782
        },
        "nubia": {
            "semantic_relation": 3.99657,
            "contradiction": 28.19838,
            "irrelevancy": 34.01031,
            "logical_agreement": 37.79131,
            "grammar_ref": 5.15434,
            "grammar_hyp": 4.56636,
            "nubia_score": 0.6407
        },
        "meteor": 0.38335913433933433,
        "bleurt": 0.31832
    },
    "totto_test_contrast_challenge_table_size-table_size_192": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.724,
        "msttr-100_nopunct": 0.77,
        "total_length": 515,
        "mean_pred_length": 16.612903225806452,
        "std_pred_length": 5.660715897702845,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.574757281553398,
        "vocab_size-1": 296,
        "unique-1": 247,
        "entropy-1": 7.2849030115043485,
        "distinct-2": 0.9008264462809917,
        "vocab_size-2": 436,
        "unique-2": 406,
        "entropy-2": 8.671362307642788,
        "cond_entropy-2": 1.2443474392290577,
        "distinct-3": 0.9602649006622517,
        "vocab_size-3": 435,
        "unique-3": 417,
        "entropy-3": 8.743897041370776,
        "cond_entropy-3": 0.08505687240038368,
        "total_length-nopunct": 462,
        "mean_pred_length-nopunct": 14.903225806451612,
        "std_pred_length-nopunct": 5.479314995506207,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6298701298701299,
        "vocab_size-1-nopunct": 291,
        "unique-1-nopunct": 246,
        "entropy-1-nopunct": 7.41604176617816,
        "distinct-2-nopunct": 0.8979118329466357,
        "vocab_size-2-nopunct": 387,
        "unique-2-nopunct": 360,
        "entropy-2-nopunct": 8.493920944379903,
        "cond_entropy-2-nopunct": 1.1645079497352755,
        "distinct-3-nopunct": 0.9575,
        "vocab_size-3-nopunct": 383,
        "unique-3-nopunct": 366,
        "entropy-3-nopunct": 8.558856189774747,
        "cond_entropy-3-nopunct": 0.07990103678477047,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.997194568238436,
        "rouge1": {
            "precision": 0.72829,
            "recall": 0.68608,
            "fmeasure": 0.69446
        },
        "rouge2": {
            "precision": 0.49943,
            "recall": 0.46043,
            "fmeasure": 0.47264
        },
        "rougeL": {
            "precision": 0.60498,
            "recall": 0.57359,
            "fmeasure": 0.58013
        },
        "rougeLsum": {
            "precision": 0.60498,
            "recall": 0.57359,
            "fmeasure": 0.58013
        },
        "bleu": 41.20066,
        "local_recall": {
            "1": 0.17721518987341772,
            "2": 0.4888888888888889,
            "3": 0.6845070422535211
        },
        "bertscore": {
            "precision": 0.91782,
            "recall": 0.90361,
            "f1": 0.91003
        },
        "nubia": {
            "semantic_relation": 4.00594,
            "contradiction": 10.00972,
            "irrelevancy": 33.80329,
            "logical_agreement": 56.18698,
            "grammar_ref": 4.61479,
            "grammar_hyp": 4.72293,
            "nubia_score": 0.65487
        },
        "meteor": 0.36677541931811514,
        "bleurt": 0.15254
    },
    "totto_test_contrast_challenge_table_size-table_size_194": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673078,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.0562872997343227,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0616737594280283,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33333,
            "fmeasure": 0.33333
        },
        "bleu": 4.36858,
        "local_recall": {
            "1": 0,
            "2": 0.375
        },
        "bertscore": {
            "precision": 0.822,
            "recall": 0.86373,
            "f1": 0.84235
        },
        "nubia": {
            "semantic_relation": 2.66651,
            "contradiction": 0.26799,
            "irrelevancy": 99.65968,
            "logical_agreement": 0.07233,
            "grammar_ref": 3.85254,
            "grammar_hyp": 4.84783,
            "nubia_score": 0.2403
        },
        "meteor": 0.22113495551548806,
        "bleurt": -0.58621
    },
    "totto_test_contrast_challenge_table_size-table_size_264": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.72,
        "msttr-100_nopunct": NaN,
        "total_length": 113,
        "mean_pred_length": 18.833333333333332,
        "std_pred_length": 6.2826922749902545,
        "median_pred_length": 22.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.7079646017699115,
        "vocab_size-1": 80,
        "unique-1": 67,
        "entropy-1": 6.029169422722684,
        "distinct-2": 0.9719626168224299,
        "vocab_size-2": 104,
        "unique-2": 101,
        "entropy-2": 6.685392220045998,
        "cond_entropy-2": 0.592077159601075,
        "distinct-3": 1.0,
        "vocab_size-3": 101,
        "unique-3": 101,
        "entropy-3": 6.658211482751779,
        "cond_entropy-3": -0.043651543253312566,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 5.120763831912406,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8085106382978723,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 67,
        "entropy-1-nopunct": 6.0624115909702825,
        "distinct-2-nopunct": 0.9886363636363636,
        "vocab_size-2-nopunct": 87,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.436704345910033,
        "cond_entropy-2-nopunct": 0.4078502954425057,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 82,
        "unique-3-nopunct": 82,
        "entropy-3-nopunct": 6.357552004618087,
        "cond_entropy-3-nopunct": -0.07748937011677476,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.540661642038164,
        "rouge1": {
            "precision": 0.81199,
            "recall": 0.66333,
            "fmeasure": 0.71397
        },
        "rouge2": {
            "precision": 0.54812,
            "recall": 0.46007,
            "fmeasure": 0.48987
        },
        "rougeL": {
            "precision": 0.71305,
            "recall": 0.58464,
            "fmeasure": 0.62813
        },
        "rougeLsum": {
            "precision": 0.71305,
            "recall": 0.58464,
            "fmeasure": 0.62813
        },
        "bleu": 46.97237,
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.3404255319148936,
            "3": 0.8064516129032258
        },
        "bertscore": {
            "precision": 0.93422,
            "recall": 0.90219,
            "f1": 0.91764
        },
        "nubia": {
            "semantic_relation": 3.91574,
            "contradiction": 7.7544,
            "irrelevancy": 36.86508,
            "logical_agreement": 55.38052,
            "grammar_ref": 4.79112,
            "grammar_hyp": 4.67144,
            "nubia_score": 0.6435
        },
        "meteor": 0.35095721472573205,
        "bleurt": 0.14646
    },
    "totto_test_contrast_challenge_table_size-table_size_169": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 18,
        "distinct-1": 0.6981132075471698,
        "vocab_size-1": 37,
        "unique-1": 29,
        "entropy-1": 4.963216209035257,
        "distinct-2": 0.92,
        "vocab_size-2": 46,
        "unique-2": 43,
        "entropy-2": 5.468758439731459,
        "cond_entropy-2": 0.4563267353846029,
        "distinct-3": 0.9574468085106383,
        "vocab_size-3": 45,
        "unique-3": 43,
        "entropy-3": 5.469482468698916,
        "cond_entropy-3": 0.011900481097880139,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7142857142857143,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.884619282669957,
        "distinct-2-nopunct": 0.9130434782608695,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.33323831470563,
        "cond_entropy-2-nopunct": 0.4617779273316459,
        "distinct-3-nopunct": 0.9534883720930233,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.333241498888144,
        "cond_entropy-3-nopunct": -0.02357801527486131,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.282082580323346,
        "rouge1": {
            "precision": 0.64947,
            "recall": 0.64208,
            "fmeasure": 0.63244
        },
        "rouge2": {
            "precision": 0.48889,
            "recall": 0.49917,
            "fmeasure": 0.48298
        },
        "rougeL": {
            "precision": 0.58737,
            "recall": 0.57614,
            "fmeasure": 0.56986
        },
        "rougeLsum": {
            "precision": 0.58737,
            "recall": 0.57614,
            "fmeasure": 0.56986
        },
        "bleu": 38.35213,
        "local_recall": {
            "1": 0.7,
            "2": 0.0,
            "3": 0.53125
        },
        "bertscore": {
            "precision": 0.93326,
            "recall": 0.92233,
            "f1": 0.91668
        },
        "nubia": {
            "semantic_relation": 4.01971,
            "contradiction": 0.15167,
            "irrelevancy": 44.46563,
            "logical_agreement": 55.3827,
            "grammar_ref": 4.07664,
            "grammar_hyp": 3.98279,
            "nubia_score": 0.721
        },
        "meteor": 0.3542368623378321,
        "bleurt": -0.02117
    },
    "totto_test_contrast_challenge_table_size-table_size_140": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 42,
        "msttr-100": 0.71833,
        "msttr-100_nopunct": 0.774,
        "total_length": 667,
        "mean_pred_length": 15.880952380952381,
        "std_pred_length": 4.494453624044285,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.5562218890554723,
        "vocab_size-1": 371,
        "unique-1": 297,
        "entropy-1": 7.599225948287546,
        "distinct-2": 0.9088,
        "vocab_size-2": 568,
        "unique-2": 526,
        "entropy-2": 9.074034179514822,
        "cond_entropy-2": 1.2516966055264156,
        "distinct-3": 0.9777015437392796,
        "vocab_size-3": 570,
        "unique-3": 557,
        "entropy-3": 9.14275516067917,
        "cond_entropy-3": 0.0738230127276077,
        "total_length-nopunct": 595,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 4.352977452091005,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6168067226890757,
        "vocab_size-1-nopunct": 367,
        "unique-1-nopunct": 296,
        "entropy-1-nopunct": 7.81751918437119,
        "distinct-2-nopunct": 0.9132007233273056,
        "vocab_size-2-nopunct": 505,
        "unique-2-nopunct": 471,
        "entropy-2-nopunct": 8.903551606004138,
        "cond_entropy-2-nopunct": 1.1684873860076725,
        "distinct-3-nopunct": 0.9843444227005871,
        "vocab_size-3-nopunct": 503,
        "unique-3-nopunct": 495,
        "entropy-3-nopunct": 8.965868326338795,
        "cond_entropy-3-nopunct": 0.06959368843182012,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.085127491287568,
        "rouge1": {
            "precision": 0.774,
            "recall": 0.76732,
            "fmeasure": 0.76449
        },
        "rouge2": {
            "precision": 0.53657,
            "recall": 0.53679,
            "fmeasure": 0.53132
        },
        "rougeL": {
            "precision": 0.66441,
            "recall": 0.66337,
            "fmeasure": 0.65727
        },
        "rougeLsum": {
            "precision": 0.66441,
            "recall": 0.66337,
            "fmeasure": 0.65727
        },
        "bleu": 47.24285,
        "local_recall": {
            "1": 0.25862068965517243,
            "2": 0.4716981132075472,
            "3": 0.797752808988764
        },
        "bertscore": {
            "precision": 0.93763,
            "recall": 0.93626,
            "f1": 0.93559
        },
        "nubia": {
            "semantic_relation": 4.27581,
            "contradiction": 6.097,
            "irrelevancy": 33.20449,
            "logical_agreement": 60.69851,
            "grammar_ref": 4.66791,
            "grammar_hyp": 4.65638,
            "nubia_score": 0.75933
        },
        "meteor": 0.41432773429229436,
        "bleurt": 0.27446
    },
    "totto_test_contrast_challenge_table_size-table_size_265": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 93,
        "mean_pred_length": 15.5,
        "std_pred_length": 4.272001872658765,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.7096774193548387,
        "vocab_size-1": 66,
        "unique-1": 54,
        "entropy-1": 5.748109010943551,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 84,
        "unique-2": 81,
        "entropy-2": 6.373977978607345,
        "cond_entropy-2": 0.5702521435289242,
        "distinct-3": 0.9753086419753086,
        "vocab_size-3": 79,
        "unique-3": 77,
        "entropy-3": 6.2904672868352325,
        "cond_entropy-3": -0.07840213493941187,
        "total_length-nopunct": 85,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 4.775516260631467,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7411764705882353,
        "vocab_size-1-nopunct": 63,
        "unique-1-nopunct": 53,
        "entropy-1-nopunct": 5.693946890100842,
        "distinct-2-nopunct": 0.9620253164556962,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.227831381088497,
        "cond_entropy-2-nopunct": 0.5428427413104427,
        "distinct-3-nopunct": 0.9726027397260274,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.135030038332081,
        "cond_entropy-3-nopunct": -0.10025755916009932,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.866762722626294,
        "rouge1": {
            "precision": 0.8214,
            "recall": 0.70041,
            "fmeasure": 0.74303
        },
        "rouge2": {
            "precision": 0.63043,
            "recall": 0.54755,
            "fmeasure": 0.5757
        },
        "rougeL": {
            "precision": 0.70007,
            "recall": 0.60635,
            "fmeasure": 0.63838
        },
        "rougeLsum": {
            "precision": 0.70007,
            "recall": 0.60635,
            "fmeasure": 0.63838
        },
        "bleu": 58.36076,
        "local_recall": {
            "1": 0.36666666666666664,
            "2": 0.125,
            "3": 0.7435897435897436
        },
        "bertscore": {
            "precision": 0.9384,
            "recall": 0.91053,
            "f1": 0.92345
        },
        "nubia": {
            "semantic_relation": 3.93126,
            "contradiction": 0.91079,
            "irrelevancy": 22.35683,
            "logical_agreement": 76.73238,
            "grammar_ref": 4.20009,
            "grammar_hyp": 4.17964,
            "nubia_score": 0.66602
        },
        "meteor": 0.39835085428457123,
        "bleurt": 0.17527
    },
    "totto_test_contrast_challenge_table_size-table_size_240": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.82,
        "total_length": 538,
        "mean_pred_length": 17.35483870967742,
        "std_pred_length": 5.677052774089025,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 33,
        "distinct-1": 0.5780669144981413,
        "vocab_size-1": 311,
        "unique-1": 252,
        "entropy-1": 7.512645010153495,
        "distinct-2": 0.9092702169625246,
        "vocab_size-2": 461,
        "unique-2": 426,
        "entropy-2": 8.779472725005238,
        "cond_entropy-2": 1.1089211573883329,
        "distinct-3": 0.957983193277311,
        "vocab_size-3": 456,
        "unique-3": 437,
        "entropy-3": 8.80919825174885,
        "cond_entropy-3": 0.03896385777713971,
        "total_length-nopunct": 464,
        "mean_pred_length-nopunct": 14.96774193548387,
        "std_pred_length-nopunct": 4.373555953150502,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6594827586206896,
        "vocab_size-1-nopunct": 306,
        "unique-1-nopunct": 252,
        "entropy-1-nopunct": 7.73121125277825,
        "distinct-2-nopunct": 0.9330254041570438,
        "vocab_size-2-nopunct": 404,
        "unique-2-nopunct": 381,
        "entropy-2-nopunct": 8.606930431806822,
        "cond_entropy-2-nopunct": 0.9352109504175071,
        "distinct-3-nopunct": 0.9676616915422885,
        "vocab_size-3-nopunct": 389,
        "unique-3-nopunct": 376,
        "entropy-3-nopunct": 8.58637507426346,
        "cond_entropy-3-nopunct": -0.016351187716137344,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.314777406641797,
        "rouge1": {
            "precision": 0.80678,
            "recall": 0.81094,
            "fmeasure": 0.80173
        },
        "rouge2": {
            "precision": 0.62227,
            "recall": 0.61867,
            "fmeasure": 0.61454
        },
        "rougeL": {
            "precision": 0.70674,
            "recall": 0.69747,
            "fmeasure": 0.69554
        },
        "rougeLsum": {
            "precision": 0.70674,
            "recall": 0.69747,
            "fmeasure": 0.69554
        },
        "bleu": 57.37396,
        "local_recall": {
            "1": 0.2037037037037037,
            "2": 0.325,
            "3": 0.8594594594594595
        },
        "bertscore": {
            "precision": 0.94635,
            "recall": 0.94445,
            "f1": 0.9442
        },
        "nubia": {
            "semantic_relation": 4.32541,
            "contradiction": 8.77209,
            "irrelevancy": 18.17465,
            "logical_agreement": 73.05326,
            "grammar_ref": 4.66938,
            "grammar_hyp": 4.57546,
            "nubia_score": 0.77665
        },
        "meteor": 0.4446545545035644,
        "bleurt": 0.37693
    },
    "totto_test_contrast_challenge_table_size-table_size_141": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 17.4,
        "std_pred_length": 6.887670143089026,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 31,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 66,
        "unique-1": 58,
        "entropy-1": 5.797668030476108,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 80,
        "unique-2": 79,
        "entropy-2": 6.299565571664875,
        "cond_entropy-2": 0.42435381955634344,
        "distinct-3": 1.0,
        "vocab_size-3": 77,
        "unique-3": 77,
        "entropy-3": 6.266786540694905,
        "cond_entropy-3": -0.04959760676159415,
        "total_length-nopunct": 78,
        "mean_pred_length-nopunct": 15.6,
        "std_pred_length-nopunct": 6.740919818541086,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.8205128205128205,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.817077539208654,
        "distinct-2-nopunct": 0.9726027397260274,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.124689113644912,
        "cond_entropy-2-nopunct": 0.317976792210867,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.087462841250345,
        "cond_entropy-3-nopunct": -0.05574517349082016,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.170522597686793,
        "rouge1": {
            "precision": 0.83871,
            "recall": 0.73631,
            "fmeasure": 0.77886
        },
        "rouge2": {
            "precision": 0.65091,
            "recall": 0.57177,
            "fmeasure": 0.60467
        },
        "rougeL": {
            "precision": 0.75083,
            "recall": 0.65147,
            "fmeasure": 0.69256
        },
        "rougeLsum": {
            "precision": 0.75083,
            "recall": 0.65147,
            "fmeasure": 0.69256
        },
        "bleu": 55.17839,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7638888888888888
        },
        "bertscore": {
            "precision": 0.95123,
            "recall": 0.92764,
            "f1": 0.93907
        },
        "nubia": {
            "semantic_relation": 4.45008,
            "contradiction": 0.74078,
            "irrelevancy": 20.89318,
            "logical_agreement": 78.36604,
            "grammar_ref": 4.6156,
            "grammar_hyp": 4.6441,
            "nubia_score": 0.81548
        },
        "meteor": 0.431427801070373,
        "bleurt": 0.42168
    },
    "totto_test_contrast_challenge_table_size-table_size_195": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.79,
        "total_length": 226,
        "mean_pred_length": 15.066666666666666,
        "std_pred_length": 5.2721490452713455,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6371681415929203,
        "vocab_size-1": 144,
        "unique-1": 119,
        "entropy-1": 6.642277282471939,
        "distinct-2": 0.9478672985781991,
        "vocab_size-2": 200,
        "unique-2": 192,
        "entropy-2": 7.603777446990796,
        "cond_entropy-2": 0.812508737330763,
        "distinct-3": 0.9846938775510204,
        "vocab_size-3": 193,
        "unique-3": 190,
        "entropy-3": 7.584097599217234,
        "cond_entropy-3": -0.03110930631563245,
        "total_length-nopunct": 198,
        "mean_pred_length-nopunct": 13.2,
        "std_pred_length-nopunct": 4.384822307308093,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.702020202020202,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.7022316790777685,
        "distinct-2-nopunct": 0.9508196721311475,
        "vocab_size-2-nopunct": 174,
        "unique-2-nopunct": 168,
        "entropy-2-nopunct": 7.402285152479864,
        "cond_entropy-2-nopunct": 0.7414033319383934,
        "distinct-3-nopunct": 0.9880952380952381,
        "vocab_size-3-nopunct": 166,
        "unique-3-nopunct": 164,
        "entropy-3-nopunct": 7.368507898969267,
        "cond_entropy-3-nopunct": -0.04251954347717999,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.674028133522557,
        "rouge1": {
            "precision": 0.80758,
            "recall": 0.73474,
            "fmeasure": 0.76171
        },
        "rouge2": {
            "precision": 0.55638,
            "recall": 0.51529,
            "fmeasure": 0.53039
        },
        "rougeL": {
            "precision": 0.68899,
            "recall": 0.62872,
            "fmeasure": 0.65084
        },
        "rougeLsum": {
            "precision": 0.68899,
            "recall": 0.62872,
            "fmeasure": 0.65084
        },
        "bleu": 47.9851,
        "local_recall": {
            "1": 0.15384615384615385,
            "2": 0.29545454545454547,
            "3": 0.7961783439490446
        },
        "bertscore": {
            "precision": 0.93353,
            "recall": 0.92381,
            "f1": 0.92811
        },
        "nubia": {
            "semantic_relation": 4.38864,
            "contradiction": 1.18353,
            "irrelevancy": 38.67441,
            "logical_agreement": 60.14206,
            "grammar_ref": 4.60593,
            "grammar_hyp": 4.66205,
            "nubia_score": 0.77183
        },
        "meteor": 0.389264491363984,
        "bleurt": 0.32565
    },
    "totto_test_contrast_challenge_table_size-table_size_266": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.73,
        "total_length": 122,
        "mean_pred_length": 15.25,
        "std_pred_length": 4.815340071064556,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6967213114754098,
        "vocab_size-1": 85,
        "unique-1": 71,
        "entropy-1": 6.056727579504774,
        "distinct-2": 0.9122807017543859,
        "vocab_size-2": 104,
        "unique-2": 96,
        "entropy-2": 6.64420777728469,
        "cond_entropy-2": 0.4382879000997833,
        "distinct-3": 0.9528301886792453,
        "vocab_size-3": 101,
        "unique-3": 97,
        "entropy-3": 6.626459251712587,
        "cond_entropy-3": -0.02237628127924552,
        "total_length-nopunct": 108,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 3.905124837953327,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 81,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.045357960653361,
        "distinct-2-nopunct": 0.91,
        "vocab_size-2-nopunct": 91,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.448758439731468,
        "cond_entropy-2-nopunct": 0.44016284239889375,
        "distinct-3-nopunct": 0.9565217391304348,
        "vocab_size-3-nopunct": 88,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.428400135381335,
        "cond_entropy-3-nopunct": -0.025132413042021885,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.668413456335887,
        "rouge1": {
            "precision": 0.76562,
            "recall": 0.76716,
            "fmeasure": 0.75953
        },
        "rouge2": {
            "precision": 0.54741,
            "recall": 0.5518,
            "fmeasure": 0.54508
        },
        "rougeL": {
            "precision": 0.60991,
            "recall": 0.60731,
            "fmeasure": 0.60389
        },
        "rougeLsum": {
            "precision": 0.60991,
            "recall": 0.60731,
            "fmeasure": 0.60389
        },
        "bleu": 45.64983,
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.37142857142857144,
            "3": 0.8985507246376812
        },
        "bertscore": {
            "precision": 0.92733,
            "recall": 0.94151,
            "f1": 0.93375
        },
        "nubia": {
            "semantic_relation": 4.20221,
            "contradiction": 13.48505,
            "irrelevancy": 28.04187,
            "logical_agreement": 58.47308,
            "grammar_ref": 4.49967,
            "grammar_hyp": 4.46546,
            "nubia_score": 0.76126
        },
        "meteor": 0.4369342399226427,
        "bleurt": 0.18238
    },
    "totto_test_contrast_challenge_table_size-table_size_243": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 3.5,
        "median_pred_length": 16.5,
        "min_pred_length": 13,
        "max_pred_length": 20,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 24,
        "unique-1": 19,
        "entropy-1": 4.366681150370567,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 30,
        "unique-2": 29,
        "entropy-2": 4.889680181354619,
        "cond_entropy-2": 0.5022063193058501,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.02724979801792366,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.1767526697769215,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.4333543065887286,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.03333771197858132,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2399196323520063,
        "rouge1": {
            "precision": 0.71491,
            "recall": 0.92857,
            "fmeasure": 0.79752
        },
        "rouge2": {
            "precision": 0.49747,
            "recall": 0.64828,
            "fmeasure": 0.55518
        },
        "rougeL": {
            "precision": 0.57675,
            "recall": 0.76128,
            "fmeasure": 0.64854
        },
        "rougeLsum": {
            "precision": 0.57675,
            "recall": 0.76128,
            "fmeasure": 0.64854
        },
        "bleu": 43.81631,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9473684210526315
        },
        "bertscore": {
            "precision": 0.92844,
            "recall": 0.95422,
            "f1": 0.94104
        },
        "nubia": {
            "semantic_relation": 4.44625,
            "contradiction": 0.23859,
            "irrelevancy": 21.59026,
            "logical_agreement": 78.17115,
            "grammar_ref": 5.56806,
            "grammar_hyp": 4.51203,
            "nubia_score": 0.88025
        },
        "meteor": 0.4818876824264251,
        "bleurt": 0.4175
    },
    "totto_test_contrast_challenge_table_size-table_size_268": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 92,
        "mean_pred_length": 18.4,
        "std_pred_length": 5.4626001134990645,
        "median_pred_length": 20.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7065217391304348,
        "vocab_size-1": 65,
        "unique-1": 51,
        "entropy-1": 5.765144157026396,
        "distinct-2": 0.9540229885057471,
        "vocab_size-2": 83,
        "unique-2": 79,
        "entropy-2": 6.350989472860216,
        "cond_entropy-2": 0.5374785226746731,
        "distinct-3": 1.0,
        "vocab_size-3": 82,
        "unique-3": 82,
        "entropy-3": 6.357552004618087,
        "cond_entropy-3": 0.012169484379111417,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 16.6,
        "std_pred_length-nopunct": 4.923413450036469,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7469879518072289,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.727154642059974,
        "distinct-2-nopunct": 0.9487179487179487,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 70,
        "entropy-2-nopunct": 6.182838116298154,
        "cond_entropy-2-nopunct": 0.4843940376540073,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.189824558880028,
        "cond_entropy-3-nopunct": 0.014011381113659235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.731008835862237,
        "rouge1": {
            "precision": 0.80116,
            "recall": 0.74388,
            "fmeasure": 0.76448
        },
        "rouge2": {
            "precision": 0.58416,
            "recall": 0.5273,
            "fmeasure": 0.54956
        },
        "rougeL": {
            "precision": 0.72485,
            "recall": 0.67199,
            "fmeasure": 0.69093
        },
        "rougeLsum": {
            "precision": 0.72485,
            "recall": 0.67199,
            "fmeasure": 0.69093
        },
        "bleu": 48.86392,
        "local_recall": {
            "1": 0.36363636363636365,
            "2": 0.5,
            "3": 0.7619047619047619
        },
        "bertscore": {
            "precision": 0.9508,
            "recall": 0.93932,
            "f1": 0.94377
        },
        "nubia": {
            "semantic_relation": 4.0808,
            "contradiction": 6.59682,
            "irrelevancy": 37.39964,
            "logical_agreement": 56.00354,
            "grammar_ref": 4.37077,
            "grammar_hyp": 4.27112,
            "nubia_score": 0.71286
        },
        "meteor": 0.38096223837920984,
        "bleurt": 0.11804
    },
    "totto_test_contrast_challenge_table_size-table_size_143": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.66,
        "total_length": 159,
        "mean_pred_length": 15.9,
        "std_pred_length": 4.657252408878007,
        "median_pred_length": 15.5,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.5471698113207547,
        "vocab_size-1": 87,
        "unique-1": 57,
        "entropy-1": 6.0012575191393704,
        "distinct-2": 0.8187919463087249,
        "vocab_size-2": 122,
        "unique-2": 102,
        "entropy-2": 6.808971101141607,
        "cond_entropy-2": 0.704270154810729,
        "distinct-3": 0.8776978417266187,
        "vocab_size-3": 122,
        "unique-3": 106,
        "entropy-3": 6.8689059108374515,
        "cond_entropy-3": 0.04084910243715027,
        "total_length-nopunct": 144,
        "mean_pred_length-nopunct": 14.4,
        "std_pred_length-nopunct": 4.294182110716778,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5902777777777778,
        "vocab_size-1-nopunct": 85,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 6.027498999152446,
        "distinct-2-nopunct": 0.8208955223880597,
        "vocab_size-2-nopunct": 110,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.660383757796582,
        "cond_entropy-2-nopunct": 0.642940314060916,
        "distinct-3-nopunct": 0.8790322580645161,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 95,
        "entropy-3-nopunct": 6.706173024079091,
        "cond_entropy-3-nopunct": 0.046249381819722324,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.243220465299919,
        "rouge1": {
            "precision": 0.65084,
            "recall": 0.65349,
            "fmeasure": 0.63038
        },
        "rouge2": {
            "precision": 0.41144,
            "recall": 0.41963,
            "fmeasure": 0.39663
        },
        "rougeL": {
            "precision": 0.49623,
            "recall": 0.51906,
            "fmeasure": 0.4924
        },
        "rougeLsum": {
            "precision": 0.49623,
            "recall": 0.51906,
            "fmeasure": 0.4924
        },
        "bleu": 26.93698,
        "local_recall": {
            "1": 0.15254237288135594,
            "2": 0.23076923076923078,
            "3": 0.6764705882352942
        },
        "bertscore": {
            "precision": 0.903,
            "recall": 0.89715,
            "f1": 0.89646
        },
        "nubia": {
            "semantic_relation": 3.86203,
            "contradiction": 8.73724,
            "irrelevancy": 52.98177,
            "logical_agreement": 38.28099,
            "grammar_ref": 4.73444,
            "grammar_hyp": 4.46526,
            "nubia_score": 0.63464
        },
        "meteor": 0.31425994912128996,
        "bleurt": 0.10737
    },
    "totto_test_contrast_challenge_table_size-table_size_244": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.75,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 5.120763831912406,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.75,
        "vocab_size-1": 78,
        "unique-1": 68,
        "entropy-1": 5.9948235836674995,
        "distinct-2": 1.0,
        "vocab_size-2": 98,
        "unique-2": 98,
        "entropy-2": 6.614709844115218,
        "cond_entropy-2": 0.5140092842477628,
        "distinct-3": 1.0,
        "vocab_size-3": 92,
        "unique-3": 92,
        "entropy-3": 6.523561956057027,
        "cond_entropy-3": -0.09114788805819554,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 3.901566636906542,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8043478260869565,
        "vocab_size-1-nopunct": 74,
        "unique-1-nopunct": 68,
        "entropy-1-nopunct": 5.94726249944122,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.426264754702099,
        "cond_entropy-2-nopunct": 0.4843254731643165,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.10433665981473575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.0827890663019515,
        "rouge1": {
            "precision": 0.81168,
            "recall": 0.78506,
            "fmeasure": 0.79549
        },
        "rouge2": {
            "precision": 0.60103,
            "recall": 0.58095,
            "fmeasure": 0.58866
        },
        "rougeL": {
            "precision": 0.72796,
            "recall": 0.71499,
            "fmeasure": 0.71854
        },
        "rougeLsum": {
            "precision": 0.72796,
            "recall": 0.71499,
            "fmeasure": 0.71854
        },
        "bleu": 61.73209,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.6666666666666666,
            "3": 0.8472222222222222
        },
        "bertscore": {
            "precision": 0.95298,
            "recall": 0.94375,
            "f1": 0.94813
        },
        "nubia": {
            "semantic_relation": 4.32706,
            "contradiction": 21.39517,
            "irrelevancy": 24.7429,
            "logical_agreement": 53.86193,
            "grammar_ref": 4.74863,
            "grammar_hyp": 4.66867,
            "nubia_score": 0.72343
        },
        "meteor": 0.44124466972582094,
        "bleurt": 0.3204
    },
    "totto_test_contrast_challenge_table_size-table_size_120": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 75,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.75,
        "total_length": 1201,
        "mean_pred_length": 16.013333333333332,
        "std_pred_length": 5.584486448088928,
        "median_pred_length": 15.0,
        "min_pred_length": 5,
        "max_pred_length": 31,
        "distinct-1": 0.46794338051623646,
        "vocab_size-1": 562,
        "unique-1": 430,
        "entropy-1": 7.8819905161633885,
        "distinct-2": 0.8312611012433393,
        "vocab_size-2": 936,
        "unique-2": 842,
        "entropy-2": 9.679144064068614,
        "cond_entropy-2": 1.5664515606433587,
        "distinct-3": 0.9181731684110371,
        "vocab_size-3": 965,
        "unique-3": 922,
        "entropy-3": 9.829505506477597,
        "cond_entropy-3": 0.16066472841908325,
        "total_length-nopunct": 1050,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.936935621752965,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5266666666666666,
        "vocab_size-1-nopunct": 553,
        "unique-1-nopunct": 428,
        "entropy-1-nopunct": 8.095696671402399,
        "distinct-2-nopunct": 0.837948717948718,
        "vocab_size-2-nopunct": 817,
        "unique-2-nopunct": 743,
        "entropy-2-nopunct": 9.47694409986953,
        "cond_entropy-2-nopunct": 1.486931827840926,
        "distinct-3-nopunct": 0.9255555555555556,
        "vocab_size-3-nopunct": 833,
        "unique-3-nopunct": 802,
        "entropy-3-nopunct": 9.619473275888799,
        "cond_entropy-3-nopunct": 0.16382771563620696,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 7.532817553519569,
        "rouge1": {
            "precision": 0.79429,
            "recall": 0.74861,
            "fmeasure": 0.75761
        },
        "rouge2": {
            "precision": 0.60736,
            "recall": 0.57643,
            "fmeasure": 0.57996
        },
        "rougeL": {
            "precision": 0.71049,
            "recall": 0.67355,
            "fmeasure": 0.67888
        },
        "rougeLsum": {
            "precision": 0.71049,
            "recall": 0.67355,
            "fmeasure": 0.67888
        },
        "bleu": 48.79534,
        "local_recall": {
            "1": 0.19245283018867926,
            "2": 0.4351851851851852,
            "3": 0.7885350318471338
        },
        "bertscore": {
            "precision": 0.93871,
            "recall": 0.9287,
            "f1": 0.93173
        },
        "nubia": {
            "semantic_relation": 4.14413,
            "contradiction": 10.68526,
            "irrelevancy": 23.86955,
            "logical_agreement": 65.44519,
            "grammar_ref": 4.90125,
            "grammar_hyp": 4.92829,
            "nubia_score": 0.70564
        },
        "meteor": 0.4004668349464207,
        "bleurt": 0.27603
    },
    "totto_test_contrast_challenge_table_size-table_size_210": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.79667,
        "total_length": 449,
        "mean_pred_length": 14.483870967741936,
        "std_pred_length": 5.066467674132354,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.5723830734966593,
        "vocab_size-1": 257,
        "unique-1": 204,
        "entropy-1": 7.235631711028079,
        "distinct-2": 0.9043062200956937,
        "vocab_size-2": 378,
        "unique-2": 357,
        "entropy-2": 8.458222851010452,
        "cond_entropy-2": 0.9872237231567467,
        "distinct-3": 0.9689922480620154,
        "vocab_size-3": 375,
        "unique-3": 366,
        "entropy-3": 8.528322411166377,
        "cond_entropy-3": 0.09005621316153056,
        "total_length-nopunct": 395,
        "mean_pred_length-nopunct": 12.741935483870968,
        "std_pred_length-nopunct": 4.585867082577021,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6379746835443038,
        "vocab_size-1-nopunct": 252,
        "unique-1-nopunct": 203,
        "entropy-1-nopunct": 7.397005174849828,
        "distinct-2-nopunct": 0.8983516483516484,
        "vocab_size-2-nopunct": 327,
        "unique-2-nopunct": 309,
        "entropy-2-nopunct": 8.238182097650851,
        "cond_entropy-2-nopunct": 0.9233744192659261,
        "distinct-3-nopunct": 0.9669669669669669,
        "vocab_size-3-nopunct": 322,
        "unique-3-nopunct": 314,
        "entropy-3-nopunct": 8.306511512697446,
        "cond_entropy-3-nopunct": 0.08566583041672796,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.029878947912951,
        "rouge1": {
            "precision": 0.76616,
            "recall": 0.69744,
            "fmeasure": 0.71602
        },
        "rouge2": {
            "precision": 0.499,
            "recall": 0.45833,
            "fmeasure": 0.4707
        },
        "rougeL": {
            "precision": 0.63815,
            "recall": 0.5901,
            "fmeasure": 0.6013
        },
        "rougeLsum": {
            "precision": 0.63815,
            "recall": 0.5901,
            "fmeasure": 0.6013
        },
        "bleu": 42.65756,
        "local_recall": {
            "1": 0.17346938775510204,
            "2": 0.4639175257731959,
            "3": 0.7684563758389261
        },
        "bertscore": {
            "precision": 0.93308,
            "recall": 0.9236,
            "f1": 0.92683
        },
        "nubia": {
            "semantic_relation": 4.14958,
            "contradiction": 7.84361,
            "irrelevancy": 29.89827,
            "logical_agreement": 62.25812,
            "grammar_ref": 4.50561,
            "grammar_hyp": 4.65131,
            "nubia_score": 0.70527
        },
        "meteor": 0.3840159298307046,
        "bleurt": 0.29547
    },
    "totto_test_contrast_challenge_table_size-table_size_245": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "total_length": 299,
        "mean_pred_length": 14.95,
        "std_pred_length": 4.924175057814253,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.6387959866220736,
        "vocab_size-1": 191,
        "unique-1": 159,
        "entropy-1": 7.021686676000513,
        "distinct-2": 0.9605734767025089,
        "vocab_size-2": 268,
        "unique-2": 260,
        "entropy-2": 8.035394116480939,
        "cond_entropy-2": 0.7900792615062104,
        "distinct-3": 0.9884169884169884,
        "vocab_size-3": 256,
        "unique-3": 253,
        "entropy-3": 7.993642264520495,
        "cond_entropy-3": -0.03490033108408755,
        "total_length-nopunct": 256,
        "mean_pred_length-nopunct": 12.8,
        "std_pred_length-nopunct": 3.9446165846632044,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.71484375,
        "vocab_size-1-nopunct": 183,
        "unique-1-nopunct": 157,
        "entropy-1-nopunct": 7.126680940984533,
        "distinct-2-nopunct": 0.9576271186440678,
        "vocab_size-2-nopunct": 226,
        "unique-2-nopunct": 219,
        "entropy-2-nopunct": 7.786224034522141,
        "cond_entropy-2-nopunct": 0.7335531832847072,
        "distinct-3-nopunct": 0.9861111111111112,
        "vocab_size-3-nopunct": 213,
        "unique-3-nopunct": 210,
        "entropy-3-nopunct": 7.727109724385686,
        "cond_entropy-3-nopunct": -0.05018662357724556,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.250873724252996,
        "rouge1": {
            "precision": 0.81012,
            "recall": 0.72885,
            "fmeasure": 0.75825
        },
        "rouge2": {
            "precision": 0.62824,
            "recall": 0.56194,
            "fmeasure": 0.58578
        },
        "rougeL": {
            "precision": 0.72208,
            "recall": 0.66018,
            "fmeasure": 0.6808
        },
        "rougeLsum": {
            "precision": 0.72208,
            "recall": 0.66018,
            "fmeasure": 0.6808
        },
        "bleu": 52.13774,
        "local_recall": {
            "1": 0.11363636363636363,
            "2": 0.4393939393939394,
            "3": 0.8155339805825242
        },
        "bertscore": {
            "precision": 0.9421,
            "recall": 0.92957,
            "f1": 0.93452
        },
        "nubia": {
            "semantic_relation": 4.27761,
            "contradiction": 11.4191,
            "irrelevancy": 23.65556,
            "logical_agreement": 64.92534,
            "grammar_ref": 4.67668,
            "grammar_hyp": 4.68263,
            "nubia_score": 0.74585
        },
        "meteor": 0.42468369074580203,
        "bleurt": 0.33774
    },
    "totto_test_contrast_challenge_table_size-table_size_196": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.735,
        "total_length": 265,
        "mean_pred_length": 14.722222222222221,
        "std_pred_length": 4.908106169678841,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.5811320754716981,
        "vocab_size-1": 154,
        "unique-1": 123,
        "entropy-1": 6.5665389214391885,
        "distinct-2": 0.9109311740890689,
        "vocab_size-2": 225,
        "unique-2": 206,
        "entropy-2": 7.75561565071654,
        "cond_entropy-2": 1.0158488143094802,
        "distinct-3": 0.9563318777292577,
        "vocab_size-3": 219,
        "unique-3": 209,
        "entropy-3": 7.751867543555464,
        "cond_entropy-3": -0.00606457678713617,
        "total_length-nopunct": 227,
        "mean_pred_length-nopunct": 12.61111111111111,
        "std_pred_length-nopunct": 4.283545894711386,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6563876651982379,
        "vocab_size-1-nopunct": 149,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.66103909031691,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 190,
        "unique-2-nopunct": 174,
        "entropy-2-nopunct": 7.508269943207996,
        "cond_entropy-2-nopunct": 0.9236862076543713,
        "distinct-3-nopunct": 0.9528795811518325,
        "vocab_size-3-nopunct": 182,
        "unique-3-nopunct": 173,
        "entropy-3-nopunct": 7.483187990339414,
        "cond_entropy-3-nopunct": -0.0063196209328996705,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.912223551236699,
        "rouge1": {
            "precision": 0.79616,
            "recall": 0.76121,
            "fmeasure": 0.76835
        },
        "rouge2": {
            "precision": 0.5442,
            "recall": 0.5234,
            "fmeasure": 0.52533
        },
        "rougeL": {
            "precision": 0.68009,
            "recall": 0.64991,
            "fmeasure": 0.65546
        },
        "rougeLsum": {
            "precision": 0.68009,
            "recall": 0.64991,
            "fmeasure": 0.65546
        },
        "bleu": 38.30888,
        "local_recall": {
            "1": 0.21153846153846154,
            "2": 0.3793103448275862,
            "3": 0.782608695652174
        },
        "bertscore": {
            "precision": 0.93083,
            "recall": 0.9324,
            "f1": 0.93039
        },
        "nubia": {
            "semantic_relation": 4.37974,
            "contradiction": 1.32472,
            "irrelevancy": 26.24883,
            "logical_agreement": 72.42645,
            "grammar_ref": 4.68102,
            "grammar_hyp": 4.79391,
            "nubia_score": 0.77165
        },
        "meteor": 0.4031783800812704,
        "bleurt": 0.29111
    },
    "totto_test_contrast_challenge_table_size-table_size_212": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.705,
        "total_length": 247,
        "mean_pred_length": 16.466666666666665,
        "std_pred_length": 5.806509756777781,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 30,
        "distinct-1": 0.5870445344129555,
        "vocab_size-1": 145,
        "unique-1": 116,
        "entropy-1": 6.601735725526473,
        "distinct-2": 0.9137931034482759,
        "vocab_size-2": 212,
        "unique-2": 194,
        "entropy-2": 7.676946512368932,
        "cond_entropy-2": 0.9256915677965731,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 210,
        "unique-3": 203,
        "entropy-3": 7.697035103412234,
        "cond_entropy-3": 0.027994200450547783,
        "total_length-nopunct": 220,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 5.746496517202653,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6363636363636364,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 115,
        "entropy-1-nopunct": 6.639018744944765,
        "distinct-2-nopunct": 0.9073170731707317,
        "vocab_size-2-nopunct": 186,
        "unique-2-nopunct": 169,
        "entropy-2-nopunct": 7.48435814828592,
        "cond_entropy-2-nopunct": 0.9211938034776321,
        "distinct-3-nopunct": 0.968421052631579,
        "vocab_size-3-nopunct": 184,
        "unique-3-nopunct": 178,
        "entropy-3-nopunct": 7.506697713594116,
        "cond_entropy-3-nopunct": 0.03248077198339647,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.307427990208998,
        "rouge1": {
            "precision": 0.78333,
            "recall": 0.66648,
            "fmeasure": 0.7149
        },
        "rouge2": {
            "precision": 0.51057,
            "recall": 0.44076,
            "fmeasure": 0.4696
        },
        "rougeL": {
            "precision": 0.65968,
            "recall": 0.57214,
            "fmeasure": 0.60854
        },
        "rougeLsum": {
            "precision": 0.65968,
            "recall": 0.57214,
            "fmeasure": 0.60854
        },
        "bleu": 41.87843,
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.225,
            "3": 0.7660818713450293
        },
        "bertscore": {
            "precision": 0.91099,
            "recall": 0.9052,
            "f1": 0.90599
        },
        "nubia": {
            "semantic_relation": 4.17745,
            "contradiction": 12.01187,
            "irrelevancy": 31.0094,
            "logical_agreement": 56.97873,
            "grammar_ref": 4.73267,
            "grammar_hyp": 4.8861,
            "nubia_score": 0.6885
        },
        "meteor": 0.37013393958896895,
        "bleurt": 0.13159
    },
    "totto_test_contrast_challenge_table_size-table_size_287": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.082207001484488,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8392857142857143,
        "vocab_size-1": 47,
        "unique-1": 41,
        "entropy-1": 5.436731930947547,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 51,
        "unique-2": 50,
        "entropy-2": 5.661978179679557,
        "cond_entropy-2": 0.09990955574047758,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.07381055075326928,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 2.680951323690902,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9183673469387755,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.45144453799276,
        "distinct-2-nopunct": 0.9777777777777777,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.447408651885229,
        "cond_entropy-2-nopunct": 0.01047658554779966,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.08552060390671319,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8551710771812946,
        "rouge1": {
            "precision": 0.84524,
            "recall": 0.70451,
            "fmeasure": 0.74468
        },
        "rouge2": {
            "precision": 0.65792,
            "recall": 0.57308,
            "fmeasure": 0.59531
        },
        "rougeL": {
            "precision": 0.74762,
            "recall": 0.66493,
            "fmeasure": 0.68906
        },
        "rougeLsum": {
            "precision": 0.74762,
            "recall": 0.66493,
            "fmeasure": 0.68906
        },
        "bleu": 47.10076,
        "local_recall": {
            "1": 0.3,
            "2": 0.6,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.94536,
            "recall": 0.91384,
            "f1": 0.92841
        },
        "nubia": {
            "semantic_relation": 4.29814,
            "contradiction": 0.26412,
            "irrelevancy": 15.90979,
            "logical_agreement": 83.82609,
            "grammar_ref": 4.68915,
            "grammar_hyp": 4.78679,
            "nubia_score": 0.73423
        },
        "meteor": 0.34492931792502013,
        "bleurt": 0.44334
    },
    "totto_test_contrast_challenge_table_size-table_size_270": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 31,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.7875,
        "total_length": 483,
        "mean_pred_length": 15.580645161290322,
        "std_pred_length": 5.072215228645408,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 27,
        "distinct-1": 0.587991718426501,
        "vocab_size-1": 284,
        "unique-1": 239,
        "entropy-1": 7.331014751908066,
        "distinct-2": 0.9446902654867256,
        "vocab_size-2": 427,
        "unique-2": 407,
        "entropy-2": 8.697148784374363,
        "cond_entropy-2": 1.1708638261780835,
        "distinct-3": 0.9857482185273159,
        "vocab_size-3": 415,
        "unique-3": 409,
        "entropy-3": 8.689172860121008,
        "cond_entropy-3": -0.003667288815687595,
        "total_length-nopunct": 427,
        "mean_pred_length-nopunct": 13.774193548387096,
        "std_pred_length-nopunct": 4.6260808844675205,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6533957845433255,
        "vocab_size-1-nopunct": 279,
        "unique-1-nopunct": 236,
        "entropy-1-nopunct": 7.533780849905034,
        "distinct-2-nopunct": 0.9494949494949495,
        "vocab_size-2-nopunct": 376,
        "unique-2-nopunct": 361,
        "entropy-2-nopunct": 8.514180760295746,
        "cond_entropy-2-nopunct": 1.0620505510502074,
        "distinct-3-nopunct": 0.9917808219178083,
        "vocab_size-3-nopunct": 362,
        "unique-3-nopunct": 359,
        "entropy-3-nopunct": 8.495314297603002,
        "cond_entropy-3-nopunct": -0.017303581450759272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.632803473371194,
        "rouge1": {
            "precision": 0.78173,
            "recall": 0.76269,
            "fmeasure": 0.76294
        },
        "rouge2": {
            "precision": 0.58582,
            "recall": 0.5754,
            "fmeasure": 0.57381
        },
        "rougeL": {
            "precision": 0.68856,
            "recall": 0.68008,
            "fmeasure": 0.67494
        },
        "rougeLsum": {
            "precision": 0.68856,
            "recall": 0.68008,
            "fmeasure": 0.67494
        },
        "bleu": 48.89851,
        "local_recall": {
            "1": 0.24,
            "2": 0.569620253164557,
            "3": 0.78125
        },
        "bertscore": {
            "precision": 0.93334,
            "recall": 0.93325,
            "f1": 0.93153
        },
        "nubia": {
            "semantic_relation": 4.27645,
            "contradiction": 4.9471,
            "irrelevancy": 36.05083,
            "logical_agreement": 59.00207,
            "grammar_ref": 4.63543,
            "grammar_hyp": 4.57942,
            "nubia_score": 0.76364
        },
        "meteor": 0.4110097447359086,
        "bleurt": 0.32785
    },
    "totto_test_contrast_challenge_table_size-table_size_170": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.77,
        "total_length": 241,
        "mean_pred_length": 16.066666666666666,
        "std_pred_length": 4.795368135561184,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6390041493775933,
        "vocab_size-1": 154,
        "unique-1": 130,
        "entropy-1": 6.672884579029517,
        "distinct-2": 0.9557522123893806,
        "vocab_size-2": 216,
        "unique-2": 207,
        "entropy-2": 7.728343177007412,
        "cond_entropy-2": 0.9249026467485619,
        "distinct-3": 0.990521327014218,
        "vocab_size-3": 209,
        "unique-3": 207,
        "entropy-3": 7.702141842735648,
        "cond_entropy-3": -0.019672723934716217,
        "total_length-nopunct": 220,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 4.988876515698588,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6909090909090909,
        "vocab_size-1-nopunct": 152,
        "unique-1-nopunct": 130,
        "entropy-1-nopunct": 6.7507441219361155,
        "distinct-2-nopunct": 0.9560975609756097,
        "vocab_size-2-nopunct": 196,
        "unique-2-nopunct": 188,
        "entropy-2-nopunct": 7.587992843397318,
        "cond_entropy-2-nopunct": 0.9126596184067084,
        "distinct-3-nopunct": 0.9947368421052631,
        "vocab_size-3-nopunct": 189,
        "unique-3-nopunct": 188,
        "entropy-3-nopunct": 7.559329292541486,
        "cond_entropy-3-nopunct": -0.021440872742058924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.6260951824684415,
        "rouge1": {
            "precision": 0.79819,
            "recall": 0.71357,
            "fmeasure": 0.74396
        },
        "rouge2": {
            "precision": 0.58894,
            "recall": 0.52973,
            "fmeasure": 0.55078
        },
        "rougeL": {
            "precision": 0.74433,
            "recall": 0.66721,
            "fmeasure": 0.69273
        },
        "rougeLsum": {
            "precision": 0.74433,
            "recall": 0.66721,
            "fmeasure": 0.69273
        },
        "bleu": 47.65665,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3076923076923077,
            "3": 0.7604166666666666
        },
        "bertscore": {
            "precision": 0.93462,
            "recall": 0.92672,
            "f1": 0.92955
        },
        "nubia": {
            "semantic_relation": 4.11457,
            "contradiction": 10.52141,
            "irrelevancy": 28.30852,
            "logical_agreement": 61.17007,
            "grammar_ref": 4.2734,
            "grammar_hyp": 4.51423,
            "nubia_score": 0.68179
        },
        "meteor": 0.3916134142450444,
        "bleurt": 0.26151
    },
    "totto_test_contrast_challenge_table_size-table_size_215": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 93,
        "mean_pred_length": 15.5,
        "std_pred_length": 5.188127472091127,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 69,
        "unique-1": 58,
        "entropy-1": 5.856535763200893,
        "distinct-2": 0.9885057471264368,
        "vocab_size-2": 86,
        "unique-2": 85,
        "entropy-2": 6.419954990101596,
        "cond_entropy-2": 0.4770525350961828,
        "distinct-3": 1.0,
        "vocab_size-3": 81,
        "unique-3": 81,
        "entropy-3": 6.339850002884614,
        "cond_entropy-3": -0.07840213493941194,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 4.955356249106169,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7926829268292683,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 5.8224995292409245,
        "distinct-2-nopunct": 0.9868421052631579,
        "vocab_size-2-nopunct": 75,
        "unique-2-nopunct": 74,
        "entropy-2-nopunct": 6.221611723969907,
        "cond_entropy-2-nopunct": 0.4413531796271756,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 70,
        "unique-3-nopunct": 70,
        "entropy-3-nopunct": 6.129283016944973,
        "cond_entropy-3-nopunct": -0.09007306792719053,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3039408514111135,
        "rouge1": {
            "precision": 0.70811,
            "recall": 0.54636,
            "fmeasure": 0.59304
        },
        "rouge2": {
            "precision": 0.39901,
            "recall": 0.30941,
            "fmeasure": 0.3312
        },
        "rougeL": {
            "precision": 0.56674,
            "recall": 0.45563,
            "fmeasure": 0.48608
        },
        "rougeLsum": {
            "precision": 0.56674,
            "recall": 0.45563,
            "fmeasure": 0.48608
        },
        "bleu": 23.00226,
        "local_recall": {
            "1": 0.2,
            "2": 0.2777777777777778,
            "3": 0.5324675324675324
        },
        "bertscore": {
            "precision": 0.90334,
            "recall": 0.87168,
            "f1": 0.88233
        },
        "nubia": {
            "semantic_relation": 3.62458,
            "contradiction": 2.10286,
            "irrelevancy": 38.66256,
            "logical_agreement": 59.23457,
            "grammar_ref": 4.85958,
            "grammar_hyp": 4.91906,
            "nubia_score": 0.54791
        },
        "meteor": 0.27148679347570637,
        "bleurt": -0.01682
    },
    "totto_test_contrast_challenge_table_size-table_size_272": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 11.142857142857142,
        "std_pred_length": 2.7479120088101925,
        "median_pred_length": 10.0,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 52,
        "unique-1": 41,
        "entropy-1": 5.361583546926741,
        "distinct-2": 0.8732394366197183,
        "vocab_size-2": 62,
        "unique-2": 53,
        "entropy-2": 5.896225992744114,
        "cond_entropy-2": 0.3489416887630916,
        "distinct-3": 0.890625,
        "vocab_size-3": 57,
        "unique-3": 50,
        "entropy-3": 5.78125,
        "cond_entropy-3": -0.11849711950468213,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 9.571428571428571,
        "std_pred_length-nopunct": 2.498979383505129,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.746268656716418,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.403307519464237,
        "distinct-2-nopunct": 0.8833333333333333,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.6735572622751835,
        "cond_entropy-2-nopunct": 0.31424093776019063,
        "distinct-3-nopunct": 0.9056603773584906,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.539241209280177,
        "cond_entropy-3-nopunct": -0.1412342919887155,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.081232215589784,
        "rouge1": {
            "precision": 0.8757,
            "recall": 0.82427,
            "fmeasure": 0.84015
        },
        "rouge2": {
            "precision": 0.67125,
            "recall": 0.63311,
            "fmeasure": 0.64309
        },
        "rougeL": {
            "precision": 0.84351,
            "recall": 0.79267,
            "fmeasure": 0.80835
        },
        "rougeLsum": {
            "precision": 0.84351,
            "recall": 0.79267,
            "fmeasure": 0.80835
        },
        "bleu": 56.634,
        "local_recall": {
            "1": 0.0625,
            "2": 0.6923076923076923,
            "3": 0.8214285714285714
        },
        "bertscore": {
            "precision": 0.95822,
            "recall": 0.95951,
            "f1": 0.95799
        },
        "nubia": {
            "semantic_relation": 4.30584,
            "contradiction": 17.66542,
            "irrelevancy": 27.14469,
            "logical_agreement": 55.18989,
            "grammar_ref": 5.14386,
            "grammar_hyp": 5.2013,
            "nubia_score": 0.77393
        },
        "meteor": 0.46875824789554993,
        "bleurt": 0.50496
    },
    "totto_test_contrast_challenge_table_size-table_size_171": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.78,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 18.166666666666668,
        "std_pred_length": 3.4840908267278117,
        "median_pred_length": 18.5,
        "min_pred_length": 14,
        "max_pred_length": 24,
        "distinct-1": 0.7614678899082569,
        "vocab_size-1": 83,
        "unique-1": 73,
        "entropy-1": 6.145484297428961,
        "distinct-2": 0.9805825242718447,
        "vocab_size-2": 101,
        "unique-2": 99,
        "entropy-2": 6.647665575726925,
        "cond_entropy-2": 0.42574011023629565,
        "distinct-3": 1.0,
        "vocab_size-3": 97,
        "unique-3": 97,
        "entropy-3": 6.599912842187142,
        "cond_entropy-3": -0.06596912829505969,
        "total_length-nopunct": 92,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8586956521739131,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.1728591027256074,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 86,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.426264754702099,
        "cond_entropy-2-nopunct": 0.27787329290660095,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 80,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.321928094887356,
        "cond_entropy-3-nopunct": -0.10433665981473575,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.056075882832224,
        "rouge1": {
            "precision": 0.77082,
            "recall": 0.76685,
            "fmeasure": 0.76294
        },
        "rouge2": {
            "precision": 0.53171,
            "recall": 0.54642,
            "fmeasure": 0.53242
        },
        "rougeL": {
            "precision": 0.64815,
            "recall": 0.68376,
            "fmeasure": 0.65686
        },
        "rougeLsum": {
            "precision": 0.64815,
            "recall": 0.68376,
            "fmeasure": 0.65686
        },
        "bleu": 48.33715,
        "local_recall": {
            "1": 0.3684210526315789,
            "2": 0.4,
            "3": 0.8205128205128205
        },
        "bertscore": {
            "precision": 0.94367,
            "recall": 0.94918,
            "f1": 0.94428
        },
        "nubia": {
            "semantic_relation": 4.4442,
            "contradiction": 0.26958,
            "irrelevancy": 30.99032,
            "logical_agreement": 68.74011,
            "grammar_ref": 4.66241,
            "grammar_hyp": 4.57447,
            "nubia_score": 0.79826
        },
        "meteor": 0.4207491027987556,
        "bleurt": 0.35847
    },
    "totto_test_contrast_challenge_table_size-table_size_273": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.75,
        "total_length": 233,
        "mean_pred_length": 16.642857142857142,
        "std_pred_length": 6.0427895977312485,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.5965665236051502,
        "vocab_size-1": 139,
        "unique-1": 108,
        "entropy-1": 6.560003737606401,
        "distinct-2": 0.908675799086758,
        "vocab_size-2": 199,
        "unique-2": 181,
        "entropy-2": 7.583006237683374,
        "cond_entropy-2": 0.9452597657551892,
        "distinct-3": 0.9463414634146341,
        "vocab_size-3": 194,
        "unique-3": 183,
        "entropy-3": 7.5721630263347,
        "cond_entropy-3": -0.012380130827434933,
        "total_length-nopunct": 213,
        "mean_pred_length-nopunct": 15.214285714285714,
        "std_pred_length-nopunct": 6.014014245654792,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6338028169014085,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 107,
        "entropy-1-nopunct": 6.564074991919854,
        "distinct-2-nopunct": 0.914572864321608,
        "vocab_size-2-nopunct": 182,
        "unique-2-nopunct": 167,
        "entropy-2-nopunct": 7.455720097930594,
        "cond_entropy-2-nopunct": 0.9099063989460315,
        "distinct-3-nopunct": 0.9513513513513514,
        "vocab_size-3-nopunct": 176,
        "unique-3-nopunct": 167,
        "entropy-3-nopunct": 7.434084163219003,
        "cond_entropy-3-nopunct": -0.024162078946255685,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.973616508929633,
        "rouge1": {
            "precision": 0.65995,
            "recall": 0.63022,
            "fmeasure": 0.63316
        },
        "rouge2": {
            "precision": 0.4299,
            "recall": 0.39391,
            "fmeasure": 0.40134
        },
        "rougeL": {
            "precision": 0.59261,
            "recall": 0.56691,
            "fmeasure": 0.56865
        },
        "rougeLsum": {
            "precision": 0.59261,
            "recall": 0.56691,
            "fmeasure": 0.56865
        },
        "bleu": 33.02638,
        "local_recall": {
            "1": 0.2465753424657534,
            "2": 0.5230769230769231,
            "3": 0.7130434782608696
        },
        "bertscore": {
            "precision": 0.91287,
            "recall": 0.90657,
            "f1": 0.90806
        },
        "nubia": {
            "semantic_relation": 3.77337,
            "contradiction": 13.93418,
            "irrelevancy": 44.2519,
            "logical_agreement": 41.81392,
            "grammar_ref": 4.00042,
            "grammar_hyp": 4.12666,
            "nubia_score": 0.66142
        },
        "meteor": 0.340525888978554,
        "bleurt": 0.03579
    },
    "totto_test_contrast_challenge_table_size-table_size_344": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 97,
        "mean_pred_length": 13.857142857142858,
        "std_pred_length": 3.356382892705923,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.7319587628865979,
        "vocab_size-1": 71,
        "unique-1": 61,
        "entropy-1": 5.837890708569678,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 87,
        "unique-2": 84,
        "entropy-2": 6.425186429662997,
        "cond_entropy-2": 0.4282142819924403,
        "distinct-3": 1.0,
        "vocab_size-3": 83,
        "unique-3": 83,
        "entropy-3": 6.375039431346932,
        "cond_entropy-3": -0.04452450835624376,
        "total_length-nopunct": 86,
        "mean_pred_length-nopunct": 12.285714285714286,
        "std_pred_length-nopunct": 2.7627256579733883,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7906976744186046,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 5.850569696512251,
        "distinct-2-nopunct": 0.9620253164556962,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.227831381088498,
        "cond_entropy-2-nopunct": 0.4282726390993964,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 72,
        "entropy-3-nopunct": 6.1699250014423175,
        "cond_entropy-3-nopunct": -0.050522413401457175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.068184509704769,
        "rouge1": {
            "precision": 0.73903,
            "recall": 0.67183,
            "fmeasure": 0.69312
        },
        "rouge2": {
            "precision": 0.51121,
            "recall": 0.46386,
            "fmeasure": 0.47869
        },
        "rougeL": {
            "precision": 0.69158,
            "recall": 0.63541,
            "fmeasure": 0.65315
        },
        "rougeLsum": {
            "precision": 0.69158,
            "recall": 0.63541,
            "fmeasure": 0.65315
        },
        "bleu": 41.45447,
        "local_recall": {
            "1": 0.5384615384615384,
            "2": 0.5925925925925926,
            "3": 0.6461538461538462
        },
        "bertscore": {
            "precision": 0.94122,
            "recall": 0.93,
            "f1": 0.9354
        },
        "nubia": {
            "semantic_relation": 4.32631,
            "contradiction": 6.76984,
            "irrelevancy": 31.24192,
            "logical_agreement": 61.98823,
            "grammar_ref": 4.57813,
            "grammar_hyp": 4.03026,
            "nubia_score": 0.79665
        },
        "meteor": 0.3535811623959241,
        "bleurt": 0.33854
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 305,
        "msttr-100": 0.66847,
        "msttr-100_nopunct": 0.68576,
        "total_length": 7226,
        "mean_pred_length": 23.691803278688525,
        "std_pred_length": 3.0109251931387755,
        "median_pred_length": 24.0,
        "min_pred_length": 15,
        "max_pred_length": 31,
        "distinct-1": 0.1549958483254913,
        "vocab_size-1": 1120,
        "unique-1": 451,
        "entropy-1": 8.022826335720605,
        "distinct-2": 0.42407166594422774,
        "vocab_size-2": 2935,
        "unique-2": 1794,
        "entropy-2": 10.732625287592207,
        "cond_entropy-2": 2.733471660409685,
        "distinct-3": 0.6260580411124547,
        "vocab_size-3": 4142,
        "unique-3": 3055,
        "entropy-3": 11.61516720832604,
        "cond_entropy-3": 0.9385126754126717,
        "total_length-nopunct": 6662,
        "mean_pred_length-nopunct": 21.84262295081967,
        "std_pred_length-nopunct": 2.9821578179694876,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.16691684178925248,
        "vocab_size-1-nopunct": 1112,
        "unique-1-nopunct": 450,
        "entropy-1-nopunct": 8.149639425910953,
        "distinct-2-nopunct": 0.4349535944627969,
        "vocab_size-2-nopunct": 2765,
        "unique-2-nopunct": 1719,
        "entropy-2-nopunct": 10.68796636347703,
        "cond_entropy-2-nopunct": 2.654338916812761,
        "distinct-3-nopunct": 0.6333443489755453,
        "vocab_size-3-nopunct": 3833,
        "unique-3-nopunct": 2851,
        "entropy-3-nopunct": 11.515929820557439,
        "cond_entropy-3-nopunct": 0.8842775543699526,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.8871059510207,
        "rouge1": {
            "precision": 0.75093,
            "recall": 0.63612,
            "fmeasure": 0.68011
        },
        "rouge2": {
            "precision": 0.47387,
            "recall": 0.39486,
            "fmeasure": 0.42463
        },
        "rougeL": {
            "precision": 0.57849,
            "recall": 0.49091,
            "fmeasure": 0.52404
        },
        "rougeLsum": {
            "precision": 0.57849,
            "recall": 0.49091,
            "fmeasure": 0.52404
        },
        "bleu": 39.14513,
        "local_recall": {
            "1": 0.18886401790710688,
            "2": 0.5185185185185185,
            "3": 0.7541843617287035
        },
        "bertscore": {
            "precision": 0.9077,
            "recall": 0.88092,
            "f1": 0.89255
        },
        "nubia": {
            "semantic_relation": 3.89831,
            "contradiction": 7.76319,
            "irrelevancy": 11.53373,
            "logical_agreement": 80.70308,
            "grammar_ref": 4.27079,
            "grammar_hyp": 4.55896,
            "nubia_score": 0.60449
        },
        "meteor": 0.3242231502223987,
        "bleurt": -0.08651
    },
    "totto_test_contrast_challenge_table_size-table_size_216": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 35,
        "msttr-100": 0.734,
        "msttr-100_nopunct": 0.79,
        "total_length": 577,
        "mean_pred_length": 16.485714285714284,
        "std_pred_length": 5.6181920252562625,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.5667244367417678,
        "vocab_size-1": 327,
        "unique-1": 264,
        "entropy-1": 7.49955090307337,
        "distinct-2": 0.9114391143911439,
        "vocab_size-2": 494,
        "unique-2": 460,
        "entropy-2": 8.872876122598903,
        "cond_entropy-2": 1.210708757190107,
        "distinct-3": 0.960552268244576,
        "vocab_size-3": 487,
        "unique-3": 468,
        "entropy-3": 8.905457543508064,
        "cond_entropy-3": 0.03519394981723431,
        "total_length-nopunct": 512,
        "mean_pred_length-nopunct": 14.628571428571428,
        "std_pred_length-nopunct": 5.221306428119933,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.625,
        "vocab_size-1-nopunct": 320,
        "unique-1-nopunct": 262,
        "entropy-1-nopunct": 7.6645265337133734,
        "distinct-2-nopunct": 0.909853249475891,
        "vocab_size-2-nopunct": 434,
        "unique-2-nopunct": 405,
        "entropy-2-nopunct": 8.681019623793347,
        "cond_entropy-2-nopunct": 1.0838315286685238,
        "distinct-3-nopunct": 0.9592760180995475,
        "vocab_size-3-nopunct": 424,
        "unique-3-nopunct": 407,
        "entropy-3-nopunct": 8.704746705314111,
        "cond_entropy-3-nopunct": 0.036371660994646775,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.552474427654848,
        "rouge1": {
            "precision": 0.73919,
            "recall": 0.69949,
            "fmeasure": 0.70614
        },
        "rouge2": {
            "precision": 0.5014,
            "recall": 0.46154,
            "fmeasure": 0.47433
        },
        "rougeL": {
            "precision": 0.64414,
            "recall": 0.61199,
            "fmeasure": 0.6177
        },
        "rougeLsum": {
            "precision": 0.64414,
            "recall": 0.61199,
            "fmeasure": 0.6177
        },
        "bleu": 43.96554,
        "local_recall": {
            "1": 0.27319587628865977,
            "2": 0.3783783783783784,
            "3": 0.7402234636871509
        },
        "bertscore": {
            "precision": 0.93146,
            "recall": 0.91996,
            "f1": 0.92396
        },
        "nubia": {
            "semantic_relation": 3.94945,
            "contradiction": 11.1926,
            "irrelevancy": 38.87235,
            "logical_agreement": 49.93505,
            "grammar_ref": 4.80535,
            "grammar_hyp": 4.64212,
            "nubia_score": 0.65793
        },
        "meteor": 0.36315272715689473,
        "bleurt": 0.17557
    },
    "totto_test_contrast_challenge_table_size-table_size_246": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 14.8,
        "std_pred_length": 5.706137047074843,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7567567567567568,
        "vocab_size-1": 56,
        "unique-1": 47,
        "entropy-1": 5.606356196938539,
        "distinct-2": 1.0,
        "vocab_size-2": 69,
        "unique-2": 69,
        "entropy-2": 6.108524456778164,
        "cond_entropy-2": 0.3776152941731883,
        "distinct-3": 1.0,
        "vocab_size-3": 64,
        "unique-3": 64,
        "entropy-3": 6.0,
        "cond_entropy-3": -0.10852445677816912,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 13.2,
        "std_pred_length-nopunct": 5.230678732248808,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.616141657138908,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.930737337562883,
        "cond_entropy-2-nopunct": 0.34969834126165267,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 56,
        "entropy-3-nopunct": 5.807354922057609,
        "cond_entropy-3-nopunct": -0.1233824155052819,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.928316229748922,
        "rouge1": {
            "precision": 0.77122,
            "recall": 0.77397,
            "fmeasure": 0.76296
        },
        "rouge2": {
            "precision": 0.56482,
            "recall": 0.55868,
            "fmeasure": 0.55358
        },
        "rougeL": {
            "precision": 0.68159,
            "recall": 0.70297,
            "fmeasure": 0.67776
        },
        "rougeLsum": {
            "precision": 0.68159,
            "recall": 0.70297,
            "fmeasure": 0.67776
        },
        "bleu": 46.56413,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.75,
            "3": 0.7959183673469388
        },
        "bertscore": {
            "precision": 0.94615,
            "recall": 0.9466,
            "f1": 0.9441
        },
        "nubia": {
            "semantic_relation": 3.92904,
            "contradiction": 38.64147,
            "irrelevancy": 26.91934,
            "logical_agreement": 34.43919,
            "grammar_ref": 5.41078,
            "grammar_hyp": 5.34438,
            "nubia_score": 0.60721
        },
        "meteor": 0.4008254883545481,
        "bleurt": 0.42205
    },
    "totto_test_contrast_challenge_table_size-table_size_247": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 14.75,
        "std_pred_length": 1.920286436967152,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.6779661016949152,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.1068051254496805,
        "distinct-2": 0.9090909090909091,
        "vocab_size-2": 50,
        "unique-2": 46,
        "entropy-2": 5.585816304394411,
        "cond_entropy-2": 0.3899812097747069,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 50,
        "unique-3": 49,
        "entropy-3": 5.63320965569699,
        "cond_entropy-3": 0.06273008927357067,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 1.479019945774904,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7450980392156863,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.088612841759393,
        "distinct-2-nopunct": 0.9148936170212766,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.368314649503949,
        "cond_entropy-2-nopunct": 0.2956653715770508,
        "distinct-3-nopunct": 0.9767441860465116,
        "vocab_size-3-nopunct": 42,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.379753126795121,
        "cond_entropy-3-nopunct": -0.008093282988508851,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5146693587106017,
        "rouge1": {
            "precision": 0.87625,
            "recall": 0.74769,
            "fmeasure": 0.78082
        },
        "rouge2": {
            "precision": 0.64087,
            "recall": 0.58501,
            "fmeasure": 0.59108
        },
        "rougeL": {
            "precision": 0.80135,
            "recall": 0.67251,
            "fmeasure": 0.70762
        },
        "rougeLsum": {
            "precision": 0.80135,
            "recall": 0.67251,
            "fmeasure": 0.70762
        },
        "bleu": 34.62562,
        "local_recall": {
            "1": 0.1,
            "2": 0.375,
            "3": 0.7068965517241379
        },
        "bertscore": {
            "precision": 0.94829,
            "recall": 0.92942,
            "f1": 0.93259
        },
        "nubia": {
            "semantic_relation": 4.45597,
            "contradiction": 0.93884,
            "irrelevancy": 37.09724,
            "logical_agreement": 61.96392,
            "grammar_ref": 3.32258,
            "grammar_hyp": 3.58271,
            "nubia_score": 0.78627
        },
        "meteor": 0.38087906405929167,
        "bleurt": 0.24818
    },
    "totto_test_contrast_challenge_table_size-table_size_217": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 22.666666666666668,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 23.0,
        "min_pred_length": 20,
        "max_pred_length": 25,
        "distinct-1": 0.6764705882352942,
        "vocab_size-1": 46,
        "unique-1": 35,
        "entropy-1": 5.2421107316126365,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 60,
        "unique-2": 57,
        "entropy-2": 5.837752428413073,
        "cond_entropy-2": 0.561505832596585,
        "distinct-3": 0.9838709677419355,
        "vocab_size-3": 61,
        "unique-3": 60,
        "entropy-3": 5.921938245870743,
        "cond_entropy-3": 0.0931188199390659,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7333333333333333,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.221567004295788,
        "distinct-2-nopunct": 0.9122807017543859,
        "vocab_size-2-nopunct": 52,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.622363698375263,
        "cond_entropy-2-nopunct": 0.419322497131026,
        "distinct-3-nopunct": 0.9814814814814815,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 52,
        "entropy-3-nopunct": 5.717850465126429,
        "cond_entropy-3-nopunct": 0.10718267318391203,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.343470965248014,
        "rouge1": {
            "precision": 0.56437,
            "recall": 0.67994,
            "fmeasure": 0.61049
        },
        "rouge2": {
            "precision": 0.35719,
            "recall": 0.44222,
            "fmeasure": 0.39046
        },
        "rougeL": {
            "precision": 0.39728,
            "recall": 0.50134,
            "fmeasure": 0.43825
        },
        "rougeLsum": {
            "precision": 0.39728,
            "recall": 0.50134,
            "fmeasure": 0.43825
        },
        "bleu": 27.6267,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.87606,
            "recall": 0.91524,
            "f1": 0.89359
        },
        "nubia": {
            "semantic_relation": 3.9308,
            "contradiction": 1.09426,
            "irrelevancy": 55.26717,
            "logical_agreement": 43.63858,
            "grammar_ref": 4.57112,
            "grammar_hyp": 3.80899,
            "nubia_score": 0.71241
        },
        "meteor": 0.3974503411368161,
        "bleurt": -0.00229
    },
    "totto_test_contrast_challenge_table_size-table_size_310": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.82,
        "total_length": 212,
        "mean_pred_length": 15.142857142857142,
        "std_pred_length": 5.422929398886374,
        "median_pred_length": 15.5,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6556603773584906,
        "vocab_size-1": 139,
        "unique-1": 115,
        "entropy-1": 6.635932091039816,
        "distinct-2": 0.9292929292929293,
        "vocab_size-2": 184,
        "unique-2": 173,
        "entropy-2": 7.474028905422202,
        "cond_entropy-2": 0.6672994444505561,
        "distinct-3": 0.9728260869565217,
        "vocab_size-3": 179,
        "unique-3": 174,
        "entropy-3": 7.469214129970069,
        "cond_entropy-3": 0.007003637619596133,
        "total_length-nopunct": 184,
        "mean_pred_length-nopunct": 13.142857142857142,
        "std_pred_length-nopunct": 4.778779623907923,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7336956521739131,
        "vocab_size-1-nopunct": 135,
        "unique-1-nopunct": 114,
        "entropy-1-nopunct": 6.759501187448593,
        "distinct-2-nopunct": 0.9294117647058824,
        "vocab_size-2-nopunct": 158,
        "unique-2-nopunct": 149,
        "entropy-2-nopunct": 7.252009244948476,
        "cond_entropy-2-nopunct": 0.5377836502088494,
        "distinct-3-nopunct": 0.9807692307692307,
        "vocab_size-3-nopunct": 153,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.246940680400726,
        "cond_entropy-3-nopunct": 0.009055433379440765,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.704555191854737,
        "rouge1": {
            "precision": 0.88913,
            "recall": 0.83828,
            "fmeasure": 0.86027
        },
        "rouge2": {
            "precision": 0.74552,
            "recall": 0.70328,
            "fmeasure": 0.72137
        },
        "rougeL": {
            "precision": 0.80658,
            "recall": 0.75818,
            "fmeasure": 0.77904
        },
        "rougeLsum": {
            "precision": 0.80658,
            "recall": 0.75818,
            "fmeasure": 0.77904
        },
        "bleu": 68.87609,
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.5,
            "3": 0.9038461538461539
        },
        "bertscore": {
            "precision": 0.96338,
            "recall": 0.95033,
            "f1": 0.95652
        },
        "nubia": {
            "semantic_relation": 4.41484,
            "contradiction": 3.83238,
            "irrelevancy": 19.67733,
            "logical_agreement": 76.49029,
            "grammar_ref": 4.89936,
            "grammar_hyp": 5.03656,
            "nubia_score": 0.78469
        },
        "meteor": 0.5022896974238952,
        "bleurt": 0.52415
    },
    "web_nlg_en_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 79,
        "msttr-100": 0.68444,
        "msttr-100_nopunct": 0.69588,
        "total_length": 1898,
        "mean_pred_length": 24.025316455696203,
        "std_pred_length": 2.746572932681624,
        "median_pred_length": 24.0,
        "min_pred_length": 19,
        "max_pred_length": 32,
        "distinct-1": 0.24183350895679662,
        "vocab_size-1": 459,
        "unique-1": 224,
        "entropy-1": 7.440153855180098,
        "distinct-2": 0.49697636063771305,
        "vocab_size-2": 904,
        "unique-2": 577,
        "entropy-2": 9.333587295603149,
        "cond_entropy-2": 1.960701495016936,
        "distinct-3": 0.6155172413793103,
        "vocab_size-3": 1071,
        "unique-3": 764,
        "entropy-3": 9.732441208824856,
        "cond_entropy-3": 0.4398046802980329,
        "total_length-nopunct": 1749,
        "mean_pred_length-nopunct": 22.139240506329113,
        "std_pred_length-nopunct": 2.64687146214043,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.25900514579759865,
        "vocab_size-1-nopunct": 453,
        "unique-1-nopunct": 223,
        "entropy-1-nopunct": 7.511930042439207,
        "distinct-2-nopunct": 0.5137724550898204,
        "vocab_size-2-nopunct": 858,
        "unique-2-nopunct": 561,
        "entropy-2-nopunct": 9.275990286115675,
        "cond_entropy-2-nopunct": 1.8355959978623464,
        "distinct-3-nopunct": 0.6266499057196732,
        "vocab_size-3-nopunct": 997,
        "unique-3-nopunct": 725,
        "entropy-3-nopunct": 9.628218652950908,
        "cond_entropy-3-nopunct": 0.39404070643170086,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 0.586079576502142,
        "rouge1": {
            "precision": 0.78445,
            "recall": 0.39408,
            "fmeasure": 0.51705
        },
        "rouge2": {
            "precision": 0.49883,
            "recall": 0.23585,
            "fmeasure": 0.31497
        },
        "rougeL": {
            "precision": 0.61925,
            "recall": 0.30355,
            "fmeasure": 0.40119
        },
        "rougeLsum": {
            "precision": 0.61925,
            "recall": 0.30355,
            "fmeasure": 0.40119
        },
        "bleu": 18.18029,
        "local_recall": {
            "1": 0.13935574229691877,
            "2": 0.2800528401585205,
            "3": 0.5145797598627787
        },
        "bertscore": {
            "precision": 0.90203,
            "recall": 0.81358,
            "f1": 0.85414
        },
        "nubia": {
            "semantic_relation": 3.02282,
            "contradiction": 4.79874,
            "irrelevancy": 9.49796,
            "logical_agreement": 85.7033,
            "grammar_ref": 3.96506,
            "grammar_hyp": 4.54659,
            "nubia_score": 0.31359
        },
        "meteor": 0.19861021142068916,
        "bleurt": -0.51062
    },
    "totto_test_contrast_challenge_table_size-table_size_345": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 93,
        "mean_pred_length": 11.625,
        "std_pred_length": 2.4462982238476156,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.5376344086021505,
        "vocab_size-1": 50,
        "unique-1": 34,
        "entropy-1": 5.244744398123043,
        "distinct-2": 0.7058823529411765,
        "vocab_size-2": 60,
        "unique-2": 48,
        "entropy-2": 5.661042224673745,
        "cond_entropy-2": 0.2557721242433995,
        "distinct-3": 0.7532467532467533,
        "vocab_size-3": 58,
        "unique-3": 49,
        "entropy-3": 5.643409917318278,
        "cond_entropy-3": 0.03414418214728802,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 10.375,
        "std_pred_length-nopunct": 2.117634293262177,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.5783132530120482,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.237924486677003,
        "distinct-2-nopunct": 0.68,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.407356817503396,
        "cond_entropy-2-nopunct": 0.23309888365935091,
        "distinct-3-nopunct": 0.7313432835820896,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.379522026278664,
        "cond_entropy-3-nopunct": 0.04039946226691873,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.450504700606155,
        "rouge1": {
            "precision": 0.90451,
            "recall": 0.85406,
            "fmeasure": 0.86879
        },
        "rouge2": {
            "precision": 0.81291,
            "recall": 0.758,
            "fmeasure": 0.77523
        },
        "rougeL": {
            "precision": 0.88576,
            "recall": 0.83235,
            "fmeasure": 0.84882
        },
        "rougeLsum": {
            "precision": 0.88576,
            "recall": 0.83235,
            "fmeasure": 0.84882
        },
        "bleu": 69.64831,
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.9012345679012346
        },
        "bertscore": {
            "precision": 0.96789,
            "recall": 0.96119,
            "f1": 0.96375
        },
        "nubia": {
            "semantic_relation": 4.54843,
            "contradiction": 0.63727,
            "irrelevancy": 12.75328,
            "logical_agreement": 86.60945,
            "grammar_ref": 5.07225,
            "grammar_hyp": 5.07354,
            "nubia_score": 0.85852
        },
        "meteor": 0.5169963023127024,
        "bleurt": 0.66347
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 297,
        "msttr-100": 0.64037,
        "msttr-100_nopunct": 0.6825,
        "total_length": 2744,
        "mean_pred_length": 9.239057239057239,
        "std_pred_length": 2.2771200844221133,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 18,
        "distinct-1": 0.24380466472303208,
        "vocab_size-1": 669,
        "unique-1": 369,
        "entropy-1": 7.406219628435734,
        "distinct-2": 0.5672251736820597,
        "vocab_size-2": 1388,
        "unique-2": 992,
        "entropy-2": 9.915402395316251,
        "cond_entropy-2": 1.9990123358755085,
        "distinct-3": 0.7548837209302326,
        "vocab_size-3": 1623,
        "unique-3": 1338,
        "entropy-3": 10.435970291082743,
        "cond_entropy-3": 0.60856941915422,
        "total_length-nopunct": 2403,
        "mean_pred_length-nopunct": 8.090909090909092,
        "std_pred_length-nopunct": 2.1591130603152195,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.2750728256346234,
        "vocab_size-1-nopunct": 661,
        "unique-1-nopunct": 367,
        "entropy-1-nopunct": 7.729661293707176,
        "distinct-2-nopunct": 0.5422602089268755,
        "vocab_size-2-nopunct": 1142,
        "unique-2-nopunct": 802,
        "entropy-2-nopunct": 9.59171665339986,
        "cond_entropy-2-nopunct": 2.164616140523225,
        "distinct-3-nopunct": 0.740187949143173,
        "vocab_size-3-nopunct": 1339,
        "unique-3-nopunct": 1093,
        "entropy-3-nopunct": 10.140318444496053,
        "cond_entropy-3-nopunct": 0.6762481110551387,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 9.365976267928266,
        "rouge1": {
            "precision": 0.84551,
            "recall": 0.80345,
            "fmeasure": 0.81729
        },
        "rouge2": {
            "precision": 0.64009,
            "recall": 0.60491,
            "fmeasure": 0.61603
        },
        "rougeL": {
            "precision": 0.77295,
            "recall": 0.7326,
            "fmeasure": 0.7457
        },
        "rougeLsum": {
            "precision": 0.77295,
            "recall": 0.7326,
            "fmeasure": 0.7457
        },
        "bleu": 65.99307,
        "local_recall": {
            "1": 0.2216142270861833,
            "2": 0.6849740932642487,
            "3": 0.8819031435853866,
            "4": 0.9736842105263158
        },
        "bertscore": {
            "precision": 0.95734,
            "recall": 0.95377,
            "f1": 0.95479
        },
        "nubia": {
            "semantic_relation": 4.61686,
            "contradiction": 6.32996,
            "irrelevancy": 6.61478,
            "logical_agreement": 87.05526,
            "grammar_ref": 5.16054,
            "grammar_hyp": 5.25,
            "nubia_score": 0.84793
        },
        "meteor": 0.4799203349581464,
        "bleurt": 0.44429
    },
    "totto_test_contrast_challenge_table_size-table_size_275": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.74,
        "total_length": 132,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.873397172404482,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 27,
        "distinct-1": 0.6515151515151515,
        "vocab_size-1": 86,
        "unique-1": 67,
        "entropy-1": 6.042389100369884,
        "distinct-2": 0.9354838709677419,
        "vocab_size-2": 116,
        "unique-2": 108,
        "entropy-2": 6.825164052322345,
        "cond_entropy-2": 0.6780655983388291,
        "distinct-3": 0.9741379310344828,
        "vocab_size-3": 113,
        "unique-3": 110,
        "entropy-3": 6.806256857196522,
        "cond_entropy-3": -0.027249798017923613,
        "total_length-nopunct": 113,
        "mean_pred_length-nopunct": 14.125,
        "std_pred_length-nopunct": 3.822221212855164,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6991150442477876,
        "vocab_size-1-nopunct": 79,
        "unique-1-nopunct": 64,
        "entropy-1-nopunct": 5.968279294216169,
        "distinct-2-nopunct": 0.9428571428571428,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 93,
        "entropy-2-nopunct": 6.599959803380399,
        "cond_entropy-2-nopunct": 0.6489681029317964,
        "distinct-3-nopunct": 0.979381443298969,
        "vocab_size-3-nopunct": 95,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.55867572878508,
        "cond_entropy-3-nopunct": -0.0318584486748711,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.617606897541387,
        "rouge1": {
            "precision": 0.74416,
            "recall": 0.65554,
            "fmeasure": 0.68906
        },
        "rouge2": {
            "precision": 0.53045,
            "recall": 0.46785,
            "fmeasure": 0.49068
        },
        "rougeL": {
            "precision": 0.69143,
            "recall": 0.61111,
            "fmeasure": 0.64106
        },
        "rougeLsum": {
            "precision": 0.69143,
            "recall": 0.61111,
            "fmeasure": 0.64106
        },
        "bleu": 43.39656,
        "local_recall": {
            "1": 0.08,
            "2": 0.36363636363636365,
            "3": 0.6914893617021277
        },
        "bertscore": {
            "precision": 0.93885,
            "recall": 0.92729,
            "f1": 0.93209
        },
        "nubia": {
            "semantic_relation": 3.77025,
            "contradiction": 27.26896,
            "irrelevancy": 20.20888,
            "logical_agreement": 52.52216,
            "grammar_ref": 5.01189,
            "grammar_hyp": 4.87788,
            "nubia_score": 0.59107
        },
        "meteor": 0.37457491805597304,
        "bleurt": 0.23991
    },
    "totto_test_contrast_challenge_table_size-table_size_248": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.73,
        "total_length": 127,
        "mean_pred_length": 15.875,
        "std_pred_length": 5.988269783501742,
        "median_pred_length": 14.5,
        "min_pred_length": 6,
        "max_pred_length": 28,
        "distinct-1": 0.6771653543307087,
        "vocab_size-1": 86,
        "unique-1": 71,
        "entropy-1": 6.028132081401755,
        "distinct-2": 0.957983193277311,
        "vocab_size-2": 114,
        "unique-2": 111,
        "entropy-2": 6.7939774271734885,
        "cond_entropy-2": 0.6287396385697325,
        "distinct-3": 0.9819819819819819,
        "vocab_size-3": 109,
        "unique-3": 107,
        "entropy-3": 6.758379830314086,
        "cond_entropy-3": -0.028329824885765405,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 14.25,
        "std_pred_length-nopunct": 5.994789404140899,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.075165975501557,
        "distinct-2-nopunct": 0.9528301886792453,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.614712907393373,
        "cond_entropy-2-nopunct": 0.5872996895267962,
        "distinct-3-nopunct": 0.9795918367346939,
        "vocab_size-3-nopunct": 96,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 6.573893517584606,
        "cond_entropy-3-nopunct": -0.031577957386766296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.7446770552612465,
        "rouge1": {
            "precision": 0.80094,
            "recall": 0.7861,
            "fmeasure": 0.78776
        },
        "rouge2": {
            "precision": 0.56008,
            "recall": 0.53899,
            "fmeasure": 0.54578
        },
        "rougeL": {
            "precision": 0.66517,
            "recall": 0.68022,
            "fmeasure": 0.66718
        },
        "rougeLsum": {
            "precision": 0.66517,
            "recall": 0.68022,
            "fmeasure": 0.66718
        },
        "bleu": 54.57386,
        "local_recall": {
            "1": 0.23809523809523808,
            "2": 0.375,
            "3": 0.9078947368421053
        },
        "bertscore": {
            "precision": 0.93102,
            "recall": 0.935,
            "f1": 0.93038
        },
        "nubia": {
            "semantic_relation": 4.39382,
            "contradiction": 2.57781,
            "irrelevancy": 24.64124,
            "logical_agreement": 72.78096,
            "grammar_ref": 4.75129,
            "grammar_hyp": 4.83988,
            "nubia_score": 0.78584
        },
        "meteor": 0.45915437446643276,
        "bleurt": 0.3678
    },
    "totto_test_contrast_challenge_table_size-table_size_219": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.0,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 16,
        "distinct-1": 0.8846153846153846,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.440636352673265,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.08264309517020865,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.316827716832514,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.09517868111048418,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.538294946640081,
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.8963,
            "fmeasure": 0.91033
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.76852,
            "fmeasure": 0.77941
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.77778,
            "fmeasure": 0.77778
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.77778,
            "fmeasure": 0.77778
        },
        "bleu": 82.13434,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9130434782608695
        },
        "bertscore": {
            "precision": 0.97239,
            "recall": 0.96301,
            "f1": 0.96765
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.56438,
            "irrelevancy": 0.54466,
            "logical_agreement": 98.89096,
            "grammar_ref": 4.84371,
            "grammar_hyp": 5.31155,
            "nubia_score": 0.92957
        },
        "meteor": 0.5970121564074208,
        "bleurt": 0.68586
    },
    "totto_test_contrast_challenge_table_size-table_size_144": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 46,
        "msttr-100": 0.72286,
        "msttr-100_nopunct": 0.76333,
        "total_length": 726,
        "mean_pred_length": 15.782608695652174,
        "std_pred_length": 5.356479390007635,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 32,
        "distinct-1": 0.5426997245179064,
        "vocab_size-1": 394,
        "unique-1": 319,
        "entropy-1": 7.616831443380065,
        "distinct-2": 0.9191176470588235,
        "vocab_size-2": 625,
        "unique-2": 588,
        "entropy-2": 9.215458137636448,
        "cond_entropy-2": 1.395474787115193,
        "distinct-3": 0.9826498422712934,
        "vocab_size-3": 623,
        "unique-3": 612,
        "entropy-3": 9.273638714681912,
        "cond_entropy-3": 0.06909683687383067,
        "total_length-nopunct": 641,
        "mean_pred_length-nopunct": 13.934782608695652,
        "std_pred_length-nopunct": 5.210366647839184,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6053042121684867,
        "vocab_size-1-nopunct": 388,
        "unique-1-nopunct": 317,
        "entropy-1-nopunct": 7.824454354576578,
        "distinct-2-nopunct": 0.9226890756302522,
        "vocab_size-2-nopunct": 549,
        "unique-2-nopunct": 519,
        "entropy-2-nopunct": 9.028721819571892,
        "cond_entropy-2-nopunct": 1.2908759987998428,
        "distinct-3-nopunct": 0.9872495446265938,
        "vocab_size-3-nopunct": 542,
        "unique-3-nopunct": 535,
        "entropy-3-nopunct": 9.075161428258436,
        "cond_entropy-3-nopunct": 0.053086431594824485,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.488353850438248,
        "rouge1": {
            "precision": 0.78616,
            "recall": 0.73528,
            "fmeasure": 0.74536
        },
        "rouge2": {
            "precision": 0.57937,
            "recall": 0.54011,
            "fmeasure": 0.54911
        },
        "rougeL": {
            "precision": 0.70468,
            "recall": 0.66294,
            "fmeasure": 0.67034
        },
        "rougeLsum": {
            "precision": 0.70468,
            "recall": 0.66294,
            "fmeasure": 0.67034
        },
        "bleu": 45.40081,
        "local_recall": {
            "1": 0.19090909090909092,
            "2": 0.3795620437956204,
            "3": 0.7391304347826086
        },
        "bertscore": {
            "precision": 0.93176,
            "recall": 0.924,
            "f1": 0.92619
        },
        "nubia": {
            "semantic_relation": 4.2108,
            "contradiction": 8.39452,
            "irrelevancy": 31.30625,
            "logical_agreement": 60.29923,
            "grammar_ref": 4.63942,
            "grammar_hyp": 4.66115,
            "nubia_score": 0.71939
        },
        "meteor": 0.37962431087367987,
        "bleurt": 0.29945
    },
    "totto_test_contrast_challenge_table_size-table_size_288": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 205,
        "mean_pred_length": 17.083333333333332,
        "std_pred_length": 5.453719423985392,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.6195121951219512,
        "vocab_size-1": 127,
        "unique-1": 97,
        "entropy-1": 6.496267387737979,
        "distinct-2": 0.9326424870466321,
        "vocab_size-2": 180,
        "unique-2": 168,
        "entropy-2": 7.453830677153226,
        "cond_entropy-2": 0.859010292484353,
        "distinct-3": 0.988950276243094,
        "vocab_size-3": 179,
        "unique-3": 177,
        "entropy-3": 7.477746439569362,
        "cond_entropy-3": 0.033106460324315454,
        "total_length-nopunct": 184,
        "mean_pred_length-nopunct": 15.333333333333334,
        "std_pred_length-nopunct": 4.955356249106169,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6684782608695652,
        "vocab_size-1-nopunct": 123,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.514388909812175,
        "distinct-2-nopunct": 0.936046511627907,
        "vocab_size-2-nopunct": 161,
        "unique-2-nopunct": 151,
        "entropy-2-nopunct": 7.293968897131349,
        "cond_entropy-2-nopunct": 0.8325455486851373,
        "distinct-3-nopunct": 0.9875,
        "vocab_size-3-nopunct": 158,
        "unique-3-nopunct": 156,
        "entropy-3-nopunct": 7.296928094887368,
        "cond_entropy-3-nopunct": 0.012881387073785782,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.288553137690624,
        "rouge1": {
            "precision": 0.67617,
            "recall": 0.67926,
            "fmeasure": 0.6667
        },
        "rouge2": {
            "precision": 0.50836,
            "recall": 0.50925,
            "fmeasure": 0.49909
        },
        "rougeL": {
            "precision": 0.59339,
            "recall": 0.59688,
            "fmeasure": 0.58574
        },
        "rougeLsum": {
            "precision": 0.59339,
            "recall": 0.59688,
            "fmeasure": 0.58574
        },
        "bleu": 43.73501,
        "local_recall": {
            "1": 0.36666666666666664,
            "2": 0.45161290322580644,
            "3": 0.6564885496183206
        },
        "bertscore": {
            "precision": 0.90493,
            "recall": 0.90471,
            "f1": 0.90378
        },
        "nubia": {
            "semantic_relation": 3.50982,
            "contradiction": 14.29967,
            "irrelevancy": 54.31873,
            "logical_agreement": 31.3816,
            "grammar_ref": 4.5489,
            "grammar_hyp": 4.50606,
            "nubia_score": 0.53009
        },
        "meteor": 0.3567369270707289,
        "bleurt": 0.00084
    },
    "totto_test_contrast_challenge_table_size-table_size_276": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.735,
        "msttr-100_nopunct": 0.78,
        "total_length": 271,
        "mean_pred_length": 15.055555555555555,
        "std_pred_length": 5.104161942552613,
        "median_pred_length": 14.0,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6236162361623616,
        "vocab_size-1": 169,
        "unique-1": 144,
        "entropy-1": 6.704521233289619,
        "distinct-2": 0.9367588932806324,
        "vocab_size-2": 237,
        "unique-2": 227,
        "entropy-2": 7.833292772398123,
        "cond_entropy-2": 0.9301100787100723,
        "distinct-3": 0.9872340425531915,
        "vocab_size-3": 232,
        "unique-3": 229,
        "entropy-3": 7.850985031671364,
        "cond_entropy-3": 0.020648065406549926,
        "total_length-nopunct": 240,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 4.8876260995383936,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6916666666666667,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 143,
        "entropy-1-nopunct": 6.8433116958135844,
        "distinct-2-nopunct": 0.9369369369369369,
        "vocab_size-2-nopunct": 208,
        "unique-2-nopunct": 200,
        "entropy-2-nopunct": 7.641828915985557,
        "cond_entropy-2-nopunct": 0.8641003629449329,
        "distinct-3-nopunct": 0.9901960784313726,
        "vocab_size-3-nopunct": 202,
        "unique-3-nopunct": 200,
        "entropy-3-nopunct": 7.652817498834241,
        "cond_entropy-3-nopunct": 0.019550176508287866,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.546384644352018,
        "rouge1": {
            "precision": 0.69851,
            "recall": 0.71116,
            "fmeasure": 0.69523
        },
        "rouge2": {
            "precision": 0.48309,
            "recall": 0.47942,
            "fmeasure": 0.47561
        },
        "rougeL": {
            "precision": 0.61466,
            "recall": 0.62186,
            "fmeasure": 0.61038
        },
        "rougeLsum": {
            "precision": 0.61466,
            "recall": 0.62186,
            "fmeasure": 0.61038
        },
        "bleu": 42.08991,
        "local_recall": {
            "1": 0.11363636363636363,
            "2": 0.32142857142857145,
            "3": 0.7473684210526316
        },
        "bertscore": {
            "precision": 0.91233,
            "recall": 0.91488,
            "f1": 0.91204
        },
        "nubia": {
            "semantic_relation": 4.10398,
            "contradiction": 1.91263,
            "irrelevancy": 35.18574,
            "logical_agreement": 62.90164,
            "grammar_ref": 5.08526,
            "grammar_hyp": 4.79284,
            "nubia_score": 0.74082
        },
        "meteor": 0.3864429740475043,
        "bleurt": 0.32798
    },
    "web_nlg_en_test_contrast_challenge_single_predicates-unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 72,
        "msttr-100": 0.62714,
        "msttr-100_nopunct": 0.66167,
        "total_length": 799,
        "mean_pred_length": 11.097222222222221,
        "std_pred_length": 2.939953335902451,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 18,
        "distinct-1": 0.34668335419274093,
        "vocab_size-1": 277,
        "unique-1": 173,
        "entropy-1": 6.788702934887215,
        "distinct-2": 0.6643741403026134,
        "vocab_size-2": 483,
        "unique-2": 360,
        "entropy-2": 8.633914228796844,
        "cond_entropy-2": 1.516747071729617,
        "distinct-3": 0.7816793893129771,
        "vocab_size-3": 512,
        "unique-3": 425,
        "entropy-3": 8.82924772859332,
        "cond_entropy-3": 0.2539778958760989,
        "total_length-nopunct": 699,
        "mean_pred_length-nopunct": 9.708333333333334,
        "std_pred_length-nopunct": 2.57357026111371,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.3876967095851216,
        "vocab_size-1-nopunct": 271,
        "unique-1-nopunct": 172,
        "entropy-1-nopunct": 6.933744146036101,
        "distinct-2-nopunct": 0.6491228070175439,
        "vocab_size-2-nopunct": 407,
        "unique-2-nopunct": 295,
        "entropy-2-nopunct": 8.37968907319698,
        "cond_entropy-2-nopunct": 1.643257811417642,
        "distinct-3-nopunct": 0.7801801801801802,
        "vocab_size-3-nopunct": 433,
        "unique-3-nopunct": 359,
        "entropy-3-nopunct": 8.584427514490818,
        "cond_entropy-3-nopunct": 0.25269304811648857,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.401443874924755,
        "rouge1": {
            "precision": 0.81058,
            "recall": 0.77471,
            "fmeasure": 0.78343
        },
        "rouge2": {
            "precision": 0.566,
            "recall": 0.53988,
            "fmeasure": 0.5471
        },
        "rougeL": {
            "precision": 0.69929,
            "recall": 0.67668,
            "fmeasure": 0.68041
        },
        "rougeLsum": {
            "precision": 0.69929,
            "recall": 0.67668,
            "fmeasure": 0.68041
        },
        "bleu": 54.59894,
        "local_recall": {
            "1": 0.2535211267605634,
            "2": 0.6590038314176245,
            "3": 0.8844984802431611
        },
        "bertscore": {
            "precision": 0.93243,
            "recall": 0.93014,
            "f1": 0.93036
        },
        "nubia": {
            "semantic_relation": 4.50259,
            "contradiction": 7.57369,
            "irrelevancy": 9.97295,
            "logical_agreement": 82.45336,
            "grammar_ref": 5.29268,
            "grammar_hyp": 5.54058,
            "nubia_score": 0.77876
        },
        "meteor": 0.43720700958933917,
        "bleurt": 0.27705
    },
    "totto_test_contrast_challenge_table_size-table_size_289": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.55,
        "vocab_size-1": 11,
        "unique-1": 2,
        "entropy-1": 3.4219280948873623,
        "distinct-2": 0.7368421052631579,
        "vocab_size-2": 14,
        "unique-2": 9,
        "entropy-2": 3.7216117239699,
        "cond_entropy-2": 0.2944204711878022,
        "distinct-3": 0.8888888888888888,
        "vocab_size-3": 16,
        "unique-3": 14,
        "entropy-3": 3.94770277922009,
        "cond_entropy-3": 0.2553308213320602,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.55,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 3.4219280948873623,
        "distinct-2-nopunct": 0.7368421052631579,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.7216117239699,
        "cond_entropy-2-nopunct": 0.2944204711878022,
        "distinct-3-nopunct": 0.8888888888888888,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.94770277922009,
        "cond_entropy-3-nopunct": 0.2553308213320602,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0819062393024796,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.45,
            "recall": 0.33333,
            "fmeasure": 0.38298
        },
        "rougeL": {
            "precision": 0.52381,
            "recall": 0.39286,
            "fmeasure": 0.44898
        },
        "rougeLsum": {
            "precision": 0.52381,
            "recall": 0.39286,
            "fmeasure": 0.44898
        },
        "bleu": 21.57615,
        "local_recall": {
            "1": 0.125,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.9161,
            "recall": 0.91625,
            "f1": 0.91617
        },
        "nubia": {
            "semantic_relation": 3.43744,
            "contradiction": 96.31566,
            "irrelevancy": 1.0301,
            "logical_agreement": 2.65424,
            "grammar_ref": 3.99891,
            "grammar_hyp": 3.9064,
            "nubia_score": 0.51869
        },
        "meteor": 0.2874180232957582,
        "bleurt": -0.27025
    },
    "totto_test_contrast_challenge_table_size-table_size_312": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.76,
        "total_length": 228,
        "mean_pred_length": 16.285714285714285,
        "std_pred_length": 3.65334624358412,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6359649122807017,
        "vocab_size-1": 145,
        "unique-1": 125,
        "entropy-1": 6.56294267565872,
        "distinct-2": 0.9485981308411215,
        "vocab_size-2": 203,
        "unique-2": 196,
        "entropy-2": 7.618268257538496,
        "cond_entropy-2": 0.8893269549185124,
        "distinct-3": 0.985,
        "vocab_size-3": 197,
        "unique-3": 194,
        "entropy-3": 7.613856189774742,
        "cond_entropy-3": 0.004211843256579111,
        "total_length-nopunct": 204,
        "mean_pred_length-nopunct": 14.571428571428571,
        "std_pred_length-nopunct": 3.619674131234265,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6862745098039216,
        "vocab_size-1-nopunct": 140,
        "unique-1-nopunct": 122,
        "entropy-1-nopunct": 6.610692303656946,
        "distinct-2-nopunct": 0.9421052631578948,
        "vocab_size-2-nopunct": 179,
        "unique-2-nopunct": 172,
        "entropy-2-nopunct": 7.431094934769904,
        "cond_entropy-2-nopunct": 0.8797673681428567,
        "distinct-3-nopunct": 0.9829545454545454,
        "vocab_size-3-nopunct": 173,
        "unique-3-nopunct": 170,
        "entropy-3-nopunct": 7.425340709546398,
        "cond_entropy-3-nopunct": 0.0052835556279418345,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.073907668963781,
        "rouge1": {
            "precision": 0.7364,
            "recall": 0.73162,
            "fmeasure": 0.72713
        },
        "rouge2": {
            "precision": 0.50476,
            "recall": 0.52752,
            "fmeasure": 0.51073
        },
        "rougeL": {
            "precision": 0.64844,
            "recall": 0.64445,
            "fmeasure": 0.64117
        },
        "rougeLsum": {
            "precision": 0.64844,
            "recall": 0.64445,
            "fmeasure": 0.64117
        },
        "bleu": 49.18071,
        "local_recall": {
            "1": 0.2413793103448276,
            "2": 0.4883720930232558,
            "3": 0.7883211678832117
        },
        "bertscore": {
            "precision": 0.92961,
            "recall": 0.93655,
            "f1": 0.93042
        },
        "nubia": {
            "semantic_relation": 4.1032,
            "contradiction": 16.95453,
            "irrelevancy": 22.35611,
            "logical_agreement": 60.68936,
            "grammar_ref": 4.5978,
            "grammar_hyp": 4.31171,
            "nubia_score": 0.72535
        },
        "meteor": 0.41403594934165805,
        "bleurt": 0.35041
    },
    "totto_test_contrast_challenge_table_size-table_size_290": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.715,
        "msttr-100_nopunct": 0.73,
        "total_length": 203,
        "mean_pred_length": 15.615384615384615,
        "std_pred_length": 4.234264290622426,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6206896551724138,
        "vocab_size-1": 126,
        "unique-1": 102,
        "entropy-1": 6.434241440787845,
        "distinct-2": 0.9315789473684211,
        "vocab_size-2": 177,
        "unique-2": 170,
        "entropy-2": 7.388769440138503,
        "cond_entropy-2": 0.7782575478054686,
        "distinct-3": 0.9887005649717514,
        "vocab_size-3": 175,
        "unique-3": 173,
        "entropy-3": 7.445006680026514,
        "cond_entropy-3": 0.06953735393604185,
        "total_length-nopunct": 173,
        "mean_pred_length-nopunct": 13.307692307692308,
        "std_pred_length-nopunct": 3.6030887472708826,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6994219653179191,
        "vocab_size-1-nopunct": 121,
        "unique-1-nopunct": 99,
        "entropy-1-nopunct": 6.576226531312922,
        "distinct-2-nopunct": 0.93125,
        "vocab_size-2-nopunct": 149,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.131888270158825,
        "cond_entropy-2-nopunct": 0.6129068766722068,
        "distinct-3-nopunct": 0.9931972789115646,
        "vocab_size-3-nopunct": 146,
        "unique-3-nopunct": 145,
        "entropy-3-nopunct": 7.1860669026594834,
        "cond_entropy-3-nopunct": 0.07098487550387751,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.56117830660871,
        "rouge1": {
            "precision": 0.76586,
            "recall": 0.75151,
            "fmeasure": 0.75528
        },
        "rouge2": {
            "precision": 0.57136,
            "recall": 0.56756,
            "fmeasure": 0.56738
        },
        "rougeL": {
            "precision": 0.61242,
            "recall": 0.60224,
            "fmeasure": 0.6049
        },
        "rougeLsum": {
            "precision": 0.61242,
            "recall": 0.60224,
            "fmeasure": 0.6049
        },
        "bleu": 46.20917,
        "local_recall": {
            "1": 0.027777777777777776,
            "2": 0.17647058823529413,
            "3": 0.7973856209150327
        },
        "bertscore": {
            "precision": 0.93636,
            "recall": 0.92684,
            "f1": 0.93095
        },
        "nubia": {
            "semantic_relation": 4.47875,
            "contradiction": 1.18018,
            "irrelevancy": 17.84656,
            "logical_agreement": 80.97326,
            "grammar_ref": 4.72277,
            "grammar_hyp": 4.69706,
            "nubia_score": 0.8245
        },
        "meteor": 0.42023705586750604,
        "bleurt": 0.43134
    },
    "totto_test_contrast_challenge_table_size-table_size_145": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.79,
        "total_length": 291,
        "mean_pred_length": 17.11764705882353,
        "std_pred_length": 5.356495264862216,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.584192439862543,
        "vocab_size-1": 170,
        "unique-1": 138,
        "entropy-1": 6.6507710077777356,
        "distinct-2": 0.8941605839416058,
        "vocab_size-2": 245,
        "unique-2": 227,
        "entropy-2": 7.838319457198695,
        "cond_entropy-2": 1.0491534629145065,
        "distinct-3": 0.9571984435797666,
        "vocab_size-3": 246,
        "unique-3": 236,
        "entropy-3": 7.917084130897549,
        "cond_entropy-3": 0.09594410808769609,
        "total_length-nopunct": 246,
        "mean_pred_length-nopunct": 14.470588235294118,
        "std_pred_length-nopunct": 4.088975811054769,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6747967479674797,
        "vocab_size-1-nopunct": 166,
        "unique-1-nopunct": 138,
        "entropy-1-nopunct": 6.827938506783831,
        "distinct-2-nopunct": 0.9039301310043668,
        "vocab_size-2-nopunct": 207,
        "unique-2-nopunct": 193,
        "entropy-2-nopunct": 7.6016213778062625,
        "cond_entropy-2-nopunct": 0.8520575084698003,
        "distinct-3-nopunct": 0.9622641509433962,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 196,
        "entropy-3-nopunct": 7.652448756450004,
        "cond_entropy-3-nopunct": 0.06516181720477772,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.467377757438318,
        "rouge1": {
            "precision": 0.80583,
            "recall": 0.78938,
            "fmeasure": 0.79132
        },
        "rouge2": {
            "precision": 0.56235,
            "recall": 0.57046,
            "fmeasure": 0.56263
        },
        "rougeL": {
            "precision": 0.66656,
            "recall": 0.66724,
            "fmeasure": 0.66244
        },
        "rougeLsum": {
            "precision": 0.66656,
            "recall": 0.66724,
            "fmeasure": 0.66244
        },
        "bleu": 46.57283,
        "local_recall": {
            "1": 0.13846153846153847,
            "2": 0.5964912280701754,
            "3": 0.8430232558139535
        },
        "bertscore": {
            "precision": 0.94677,
            "recall": 0.94332,
            "f1": 0.94393
        },
        "nubia": {
            "semantic_relation": 4.35509,
            "contradiction": 10.53709,
            "irrelevancy": 23.96223,
            "logical_agreement": 65.50068,
            "grammar_ref": 4.90086,
            "grammar_hyp": 4.75895,
            "nubia_score": 0.76282
        },
        "meteor": 0.4187282347606474,
        "bleurt": 0.28107
    },
    "totto_test_contrast_challenge_table_size-table_size_376": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.77,
        "total_length": 122,
        "mean_pred_length": 15.25,
        "std_pred_length": 3.112474899497183,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.7049180327868853,
        "vocab_size-1": 86,
        "unique-1": 72,
        "entropy-1": 6.057414899497453,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 108,
        "unique-2": 102,
        "entropy-2": 6.7276268562700166,
        "cond_entropy-2": 0.5090468646057668,
        "distinct-3": 0.9528301886792453,
        "vocab_size-3": 101,
        "unique-3": 96,
        "entropy-3": 6.633580831921675,
        "cond_entropy-3": -0.08610163507324062,
        "total_length-nopunct": 106,
        "mean_pred_length-nopunct": 13.25,
        "std_pred_length-nopunct": 2.9047375096555625,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7735849056603774,
        "vocab_size-1-nopunct": 82,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.101445247425766,
        "distinct-2-nopunct": 0.9387755102040817,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 86,
        "entropy-2-nopunct": 6.492260864523381,
        "cond_entropy-2-nopunct": 0.4317523687006494,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 80,
        "entropy-3-nopunct": 6.380741985218552,
        "cond_entropy-3-nopunct": -0.11174563667442246,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.829115152706634,
        "rouge1": {
            "precision": 0.78463,
            "recall": 0.76127,
            "fmeasure": 0.7641
        },
        "rouge2": {
            "precision": 0.62547,
            "recall": 0.62253,
            "fmeasure": 0.61641
        },
        "rougeL": {
            "precision": 0.70199,
            "recall": 0.6986,
            "fmeasure": 0.69188
        },
        "rougeLsum": {
            "precision": 0.70199,
            "recall": 0.6986,
            "fmeasure": 0.69188
        },
        "bleu": 59.64319,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.7666666666666667,
            "3": 0.7808219178082192
        },
        "bertscore": {
            "precision": 0.94206,
            "recall": 0.93984,
            "f1": 0.93773
        },
        "nubia": {
            "semantic_relation": 4.31313,
            "contradiction": 3.39457,
            "irrelevancy": 24.10671,
            "logical_agreement": 72.49872,
            "grammar_ref": 4.8199,
            "grammar_hyp": 4.73446,
            "nubia_score": 0.77098
        },
        "meteor": 0.4493429865544827,
        "bleurt": 0.34686
    },
    "totto_test_contrast_challenge_table_size-table_size_220": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.765,
        "total_length": 269,
        "mean_pred_length": 16.8125,
        "std_pred_length": 5.294085733155443,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6059479553903345,
        "vocab_size-1": 163,
        "unique-1": 132,
        "entropy-1": 6.743274640861058,
        "distinct-2": 0.9367588932806324,
        "vocab_size-2": 237,
        "unique-2": 226,
        "entropy-2": 7.834338869261722,
        "cond_entropy-2": 0.9434264600726191,
        "distinct-3": 0.9957805907172996,
        "vocab_size-3": 236,
        "unique-3": 235,
        "entropy-3": 7.880304430332904,
        "cond_entropy-3": 0.05600132177541205,
        "total_length-nopunct": 244,
        "mean_pred_length-nopunct": 15.25,
        "std_pred_length-nopunct": 5.2855936279664935,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6557377049180327,
        "vocab_size-1-nopunct": 160,
        "unique-1-nopunct": 131,
        "entropy-1-nopunct": 6.8235659720341975,
        "distinct-2-nopunct": 0.9385964912280702,
        "vocab_size-2-nopunct": 214,
        "unique-2-nopunct": 205,
        "entropy-2-nopunct": 7.685479310329525,
        "cond_entropy-2-nopunct": 0.9282720196449923,
        "distinct-3-nopunct": 0.9952830188679245,
        "vocab_size-3-nopunct": 211,
        "unique-3-nopunct": 210,
        "entropy-3-nopunct": 7.7184864922990615,
        "cond_entropy-3-nopunct": 0.04413251810806504,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.3554168861893015,
        "rouge1": {
            "precision": 0.78145,
            "recall": 0.7801,
            "fmeasure": 0.76875
        },
        "rouge2": {
            "precision": 0.55047,
            "recall": 0.56617,
            "fmeasure": 0.55002
        },
        "rougeL": {
            "precision": 0.68749,
            "recall": 0.68913,
            "fmeasure": 0.67742
        },
        "rougeLsum": {
            "precision": 0.68749,
            "recall": 0.68913,
            "fmeasure": 0.67742
        },
        "bleu": 48.94483,
        "local_recall": {
            "1": 0.22727272727272727,
            "2": 0.3,
            "3": 0.8449197860962567
        },
        "bertscore": {
            "precision": 0.93534,
            "recall": 0.9323,
            "f1": 0.93211
        },
        "nubia": {
            "semantic_relation": 4.31766,
            "contradiction": 0.83347,
            "irrelevancy": 29.16871,
            "logical_agreement": 69.99782,
            "grammar_ref": 4.78068,
            "grammar_hyp": 4.67586,
            "nubia_score": 0.78332
        },
        "meteor": 0.41777714555397605,
        "bleurt": 0.28711
    },
    "totto_test_contrast_challenge_table_size-table_size_378": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.75,
        "total_length": 117,
        "mean_pred_length": 16.714285714285715,
        "std_pred_length": 3.8808793449160355,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 23,
        "distinct-1": 0.6752136752136753,
        "vocab_size-1": 79,
        "unique-1": 65,
        "entropy-1": 5.882988279646026,
        "distinct-2": 0.9181818181818182,
        "vocab_size-2": 101,
        "unique-2": 93,
        "entropy-2": 6.610860736232273,
        "cond_entropy-2": 0.6497075481792681,
        "distinct-3": 0.941747572815534,
        "vocab_size-3": 97,
        "unique-3": 91,
        "entropy-3": 6.569995672814303,
        "cond_entropy-3": -0.029277754281601613,
        "total_length-nopunct": 109,
        "mean_pred_length-nopunct": 15.571428571428571,
        "std_pred_length-nopunct": 3.9948947011741605,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6972477064220184,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.850631403048983,
        "distinct-2-nopunct": 0.9117647058823529,
        "vocab_size-2-nopunct": 93,
        "unique-2-nopunct": 85,
        "entropy-2-nopunct": 6.488553895871857,
        "cond_entropy-2-nopunct": 0.6910878894120345,
        "distinct-3-nopunct": 0.9368421052631579,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.443539818857263,
        "cond_entropy-3-nopunct": -0.03146565467040601,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.176803083487864,
        "rouge1": {
            "precision": 0.79388,
            "recall": 0.72217,
            "fmeasure": 0.7532
        },
        "rouge2": {
            "precision": 0.61638,
            "recall": 0.56084,
            "fmeasure": 0.58477
        },
        "rougeL": {
            "precision": 0.67971,
            "recall": 0.61844,
            "fmeasure": 0.64379
        },
        "rougeLsum": {
            "precision": 0.67971,
            "recall": 0.61844,
            "fmeasure": 0.64379
        },
        "bleu": 43.58714,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.42857142857142855,
            "3": 0.7666666666666667
        },
        "bertscore": {
            "precision": 0.9373,
            "recall": 0.92071,
            "f1": 0.92682
        },
        "nubia": {
            "semantic_relation": 4.10019,
            "contradiction": 14.86553,
            "irrelevancy": 28.36557,
            "logical_agreement": 56.7689,
            "grammar_ref": 4.76973,
            "grammar_hyp": 4.69323,
            "nubia_score": 0.70808
        },
        "meteor": 0.4009500127096948,
        "bleurt": 0.20862
    },
    "totto_test_contrast_challenge_table_size-table_size_221": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 14.8,
        "std_pred_length": 3.1240998703626617,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.5945945945945946,
        "vocab_size-1": 44,
        "unique-1": 33,
        "entropy-1": 5.091842225031145,
        "distinct-2": 0.8260869565217391,
        "vocab_size-2": 57,
        "unique-2": 51,
        "entropy-2": 5.668458833928885,
        "cond_entropy-2": 0.48934726438400994,
        "distinct-3": 0.921875,
        "vocab_size-3": 59,
        "unique-3": 57,
        "entropy-3": 5.800704882778696,
        "cond_entropy-3": 0.04162617563490608,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 3.261901286060018,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.6176470588235294,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.041968959929741,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.622287415934836,
        "cond_entropy-2-nopunct": 0.5158701548472137,
        "distinct-3-nopunct": 0.9655172413793104,
        "vocab_size-3-nopunct": 56,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.776000176124752,
        "cond_entropy-3-nopunct": 0.02418259050502379,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.734480376507623,
        "rouge1": {
            "precision": 0.68965,
            "recall": 0.71192,
            "fmeasure": 0.68771
        },
        "rouge2": {
            "precision": 0.54755,
            "recall": 0.57244,
            "fmeasure": 0.54908
        },
        "rougeL": {
            "precision": 0.59709,
            "recall": 0.6209,
            "fmeasure": 0.59524
        },
        "rougeLsum": {
            "precision": 0.59709,
            "recall": 0.6209,
            "fmeasure": 0.59524
        },
        "bleu": 28.14023,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.7380952380952381
        },
        "bertscore": {
            "precision": 0.90287,
            "recall": 0.90703,
            "f1": 0.90029
        },
        "nubia": {
            "semantic_relation": 4.19941,
            "contradiction": 0.70886,
            "irrelevancy": 30.25469,
            "logical_agreement": 69.03645,
            "grammar_ref": 3.91039,
            "grammar_hyp": 3.46648,
            "nubia_score": 0.79371
        },
        "meteor": 0.34271314994488145,
        "bleurt": 0.16012
    },
    "totto_test_contrast_challenge_table_size-table_size_380": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.83,
        "total_length": 129,
        "mean_pred_length": 16.125,
        "std_pred_length": 5.464373248598599,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.7364341085271318,
        "vocab_size-1": 95,
        "unique-1": 82,
        "entropy-1": 6.27451746906931,
        "distinct-2": 0.9421487603305785,
        "vocab_size-2": 114,
        "unique-2": 109,
        "entropy-2": 6.7866318323159245,
        "cond_entropy-2": 0.3984134858617059,
        "distinct-3": 0.9823008849557522,
        "vocab_size-3": 111,
        "unique-3": 109,
        "entropy-3": 6.78478073232671,
        "cond_entropy-3": 0.007510415406080102,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 13.75,
        "std_pred_length-nopunct": 3.766629793329841,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8090909090909091,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.273411504607146,
        "distinct-2-nopunct": 0.9607843137254902,
        "vocab_size-2-nopunct": 98,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.5743861262852255,
        "cond_entropy-2-nopunct": 0.3408136968872991,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 94,
        "entropy-3-nopunct": 6.554588851677623,
        "cond_entropy-3-nopunct": -0.011453511570453781,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.808828666495731,
        "rouge1": {
            "precision": 0.90639,
            "recall": 0.8452,
            "fmeasure": 0.87281
        },
        "rouge2": {
            "precision": 0.70193,
            "recall": 0.65637,
            "fmeasure": 0.67676
        },
        "rougeL": {
            "precision": 0.69434,
            "recall": 0.64865,
            "fmeasure": 0.6692
        },
        "rougeLsum": {
            "precision": 0.69434,
            "recall": 0.64865,
            "fmeasure": 0.6692
        },
        "bleu": 53.34286,
        "local_recall": {
            "1": 0.038461538461538464,
            "2": 0.5,
            "3": 0.8645833333333334
        },
        "bertscore": {
            "precision": 0.95658,
            "recall": 0.95693,
            "f1": 0.95665
        },
        "nubia": {
            "semantic_relation": 4.38778,
            "contradiction": 6.61513,
            "irrelevancy": 8.42584,
            "logical_agreement": 84.95902,
            "grammar_ref": 4.87577,
            "grammar_hyp": 4.8775,
            "nubia_score": 0.79159
        },
        "meteor": 0.46269285423254675,
        "bleurt": 0.42151
    },
    "totto_test_contrast_challenge_table_size-table_size_291": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548847,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983795,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0392016636713215,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.36186,
            "fmeasure": 0.45823
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.15018,
            "fmeasure": 0.1921
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.26455,
            "fmeasure": 0.30924
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.26455,
            "fmeasure": 0.30924
        },
        "bleu": 20.06086,
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.83766,
            "recall": 0.8195,
            "f1": 0.82848
        },
        "nubia": {
            "semantic_relation": 2.82332,
            "contradiction": 0.11243,
            "irrelevancy": 99.73406,
            "logical_agreement": 0.15351,
            "grammar_ref": 3.87789,
            "grammar_hyp": 3.00254,
            "nubia_score": 0.3989
        },
        "meteor": 0.18487486865057903,
        "bleurt": -0.44485
    },
    "totto_test_contrast_challenge_table_size-table_size_250": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 16,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.81,
        "total_length": 262,
        "mean_pred_length": 16.375,
        "std_pred_length": 5.170529469986609,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.6183206106870229,
        "vocab_size-1": 162,
        "unique-1": 133,
        "entropy-1": 6.815638610531861,
        "distinct-2": 0.9308943089430894,
        "vocab_size-2": 229,
        "unique-2": 217,
        "entropy-2": 7.781499706662705,
        "cond_entropy-2": 0.8092803710460369,
        "distinct-3": 0.9739130434782609,
        "vocab_size-3": 224,
        "unique-3": 218,
        "entropy-3": 7.793316137900886,
        "cond_entropy-3": 0.012922121168394102,
        "total_length-nopunct": 223,
        "mean_pred_length-nopunct": 13.9375,
        "std_pred_length-nopunct": 3.2876425824593523,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7085201793721974,
        "vocab_size-1-nopunct": 158,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.963988351982304,
        "distinct-2-nopunct": 0.9468599033816425,
        "vocab_size-2-nopunct": 196,
        "unique-2-nopunct": 187,
        "entropy-2-nopunct": 7.577544928513793,
        "cond_entropy-2-nopunct": 0.66858355608228,
        "distinct-3-nopunct": 0.9790575916230366,
        "vocab_size-3-nopunct": 187,
        "unique-3-nopunct": 183,
        "entropy-3-nopunct": 7.535544011281822,
        "cond_entropy-3-nopunct": -0.03228849595572329,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.56777804977477,
        "rouge1": {
            "precision": 0.80207,
            "recall": 0.78532,
            "fmeasure": 0.78576
        },
        "rouge2": {
            "precision": 0.59332,
            "recall": 0.58611,
            "fmeasure": 0.58346
        },
        "rougeL": {
            "precision": 0.73269,
            "recall": 0.71895,
            "fmeasure": 0.71835
        },
        "rougeLsum": {
            "precision": 0.73269,
            "recall": 0.71895,
            "fmeasure": 0.71835
        },
        "bleu": 54.95876,
        "local_recall": {
            "1": 0.14814814814814814,
            "2": 0.36585365853658536,
            "3": 0.827027027027027
        },
        "bertscore": {
            "precision": 0.95361,
            "recall": 0.95556,
            "f1": 0.95229
        },
        "nubia": {
            "semantic_relation": 4.48466,
            "contradiction": 0.50801,
            "irrelevancy": 27.90812,
            "logical_agreement": 71.58387,
            "grammar_ref": 4.44923,
            "grammar_hyp": 4.36999,
            "nubia_score": 0.82902
        },
        "meteor": 0.43686919427485404,
        "bleurt": 0.46192
    },
    "totto_test_contrast_challenge_table_size-table_size_222": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.78,
        "msttr-100_nopunct": 0.84,
        "total_length": 180,
        "mean_pred_length": 16.363636363636363,
        "std_pred_length": 5.43177063501442,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 27,
        "distinct-1": 0.7055555555555556,
        "vocab_size-1": 127,
        "unique-1": 107,
        "entropy-1": 6.604384583681212,
        "distinct-2": 0.9644970414201184,
        "vocab_size-2": 163,
        "unique-2": 159,
        "entropy-2": 7.318039199595786,
        "cond_entropy-2": 0.5871887524317143,
        "distinct-3": 1.0,
        "vocab_size-3": 158,
        "unique-3": 158,
        "entropy-3": 7.303780748177119,
        "cond_entropy-3": -0.02114932101647364,
        "total_length-nopunct": 154,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.709757762541316,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7922077922077922,
        "vocab_size-1-nopunct": 122,
        "unique-1-nopunct": 106,
        "entropy-1-nopunct": 6.6870189269602145,
        "distinct-2-nopunct": 0.965034965034965,
        "vocab_size-2-nopunct": 138,
        "unique-2-nopunct": 135,
        "entropy-2-nopunct": 7.075955252862312,
        "cond_entropy-2-nopunct": 0.42654082765792256,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 132,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.044394119358443,
        "cond_entropy-3-nopunct": -0.024568126510844997,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.350658680816991,
        "rouge1": {
            "precision": 0.70914,
            "recall": 0.62284,
            "fmeasure": 0.64674
        },
        "rouge2": {
            "precision": 0.45749,
            "recall": 0.38568,
            "fmeasure": 0.40726
        },
        "rougeL": {
            "precision": 0.57794,
            "recall": 0.49411,
            "fmeasure": 0.51722
        },
        "rougeLsum": {
            "precision": 0.57794,
            "recall": 0.49411,
            "fmeasure": 0.51722
        },
        "bleu": 33.87348,
        "local_recall": {
            "1": 0.13513513513513514,
            "2": 0.525,
            "3": 0.6470588235294118
        },
        "bertscore": {
            "precision": 0.90446,
            "recall": 0.89431,
            "f1": 0.89707
        },
        "nubia": {
            "semantic_relation": 3.62975,
            "contradiction": 17.82204,
            "irrelevancy": 32.82654,
            "logical_agreement": 49.35142,
            "grammar_ref": 4.70623,
            "grammar_hyp": 5.26671,
            "nubia_score": 0.52645
        },
        "meteor": 0.3052194217785707,
        "bleurt": -0.00174
    },
    "totto_test_contrast_challenge_table_size-table_size_348": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 4.189935029992178,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 19,
        "distinct-1": 0.825,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.934183719779189,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.17819790593519463,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.7416573867739413,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.871178126382214,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.20037479979988243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.336804201021281,
        "rouge1": {
            "precision": 0.71338,
            "recall": 0.68721,
            "fmeasure": 0.69335
        },
        "rouge2": {
            "precision": 0.44188,
            "recall": 0.425,
            "fmeasure": 0.42763
        },
        "rougeL": {
            "precision": 0.62247,
            "recall": 0.5963,
            "fmeasure": 0.60244
        },
        "rougeLsum": {
            "precision": 0.62247,
            "recall": 0.5963,
            "fmeasure": 0.60244
        },
        "bleu": 50.41846,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6875,
            "3": 0.9333333333333333
        },
        "bertscore": {
            "precision": 0.91895,
            "recall": 0.90784,
            "f1": 0.91294
        },
        "nubia": {
            "semantic_relation": 3.67183,
            "contradiction": 1.47495,
            "irrelevancy": 41.43015,
            "logical_agreement": 57.09491,
            "grammar_ref": 4.86076,
            "grammar_hyp": 5.05858,
            "nubia_score": 0.5447
        },
        "meteor": 0.4263079134713638,
        "bleurt": 0.15827
    },
    "totto_test_contrast_challenge_table_size-table_size_252": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 19,
        "msttr-100": 0.74,
        "msttr-100_nopunct": 0.78,
        "total_length": 311,
        "mean_pred_length": 16.36842105263158,
        "std_pred_length": 4.093776101606328,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.6302250803858521,
        "vocab_size-1": 196,
        "unique-1": 165,
        "entropy-1": 6.949197185696505,
        "distinct-2": 0.9486301369863014,
        "vocab_size-2": 277,
        "unique-2": 266,
        "entropy-2": 8.072137819234168,
        "cond_entropy-2": 0.952533948874228,
        "distinct-3": 0.989010989010989,
        "vocab_size-3": 270,
        "unique-3": 267,
        "entropy-3": 8.070779118941795,
        "cond_entropy-3": 0.006831951917491944,
        "total_length-nopunct": 273,
        "mean_pred_length-nopunct": 14.368421052631579,
        "std_pred_length-nopunct": 3.497525837018137,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6996336996336996,
        "vocab_size-1-nopunct": 191,
        "unique-1-nopunct": 164,
        "entropy-1-nopunct": 7.048775503820797,
        "distinct-2-nopunct": 0.9566929133858267,
        "vocab_size-2-nopunct": 243,
        "unique-2-nopunct": 236,
        "entropy-2-nopunct": 7.884887332533547,
        "cond_entropy-2-nopunct": 0.8984569118028443,
        "distinct-3-nopunct": 0.9914893617021276,
        "vocab_size-3-nopunct": 233,
        "unique-3-nopunct": 231,
        "entropy-3-nopunct": 7.8594956699692355,
        "cond_entropy-3-nopunct": -0.016999536051420256,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.156748794829982,
        "rouge1": {
            "precision": 0.66739,
            "recall": 0.63804,
            "fmeasure": 0.64155
        },
        "rouge2": {
            "precision": 0.41695,
            "recall": 0.40334,
            "fmeasure": 0.40287
        },
        "rougeL": {
            "precision": 0.56544,
            "recall": 0.54826,
            "fmeasure": 0.54728
        },
        "rougeLsum": {
            "precision": 0.56544,
            "recall": 0.54826,
            "fmeasure": 0.54728
        },
        "bleu": 36.93143,
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.42857142857142855,
            "3": 0.7052023121387283
        },
        "bertscore": {
            "precision": 0.90304,
            "recall": 0.90287,
            "f1": 0.90182
        },
        "nubia": {
            "semantic_relation": 3.90305,
            "contradiction": 16.52626,
            "irrelevancy": 41.24564,
            "logical_agreement": 42.2281,
            "grammar_ref": 4.62734,
            "grammar_hyp": 4.64177,
            "nubia_score": 0.63255
        },
        "meteor": 0.3153846820063298,
        "bleurt": 0.09559
    },
    "totto_test_contrast_challenge_table_size-table_size_382": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.04978793508525296,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1986532337201607,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.20913,
            "irrelevancy": 0.49456,
            "logical_agreement": 99.29631,
            "grammar_ref": 4.69221,
            "grammar_hyp": 4.84818,
            "nubia_score": 0.99204
        },
        "meteor": 1.0,
        "bleurt": 0.99035
    },
    "totto_test_contrast_challenge_table_size-table_size_224": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 18,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.72,
        "total_length": 288,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.8876260995383936,
        "median_pred_length": 14.5,
        "min_pred_length": 7,
        "max_pred_length": 24,
        "distinct-1": 0.6111111111111112,
        "vocab_size-1": 176,
        "unique-1": 148,
        "entropy-1": 6.804316525400788,
        "distinct-2": 0.9407407407407408,
        "vocab_size-2": 254,
        "unique-2": 246,
        "entropy-2": 7.929132993417778,
        "cond_entropy-2": 0.9736370128641455,
        "distinct-3": 0.9920634920634921,
        "vocab_size-3": 250,
        "unique-3": 248,
        "entropy-3": 7.961406907626912,
        "cond_entropy-3": 0.04282267161149539,
        "total_length-nopunct": 255,
        "mean_pred_length-nopunct": 14.166666666666666,
        "std_pred_length-nopunct": 4.3237072570242825,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6705882352941176,
        "vocab_size-1-nopunct": 171,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 6.873689622029887,
        "distinct-2-nopunct": 0.9324894514767933,
        "vocab_size-2-nopunct": 221,
        "unique-2-nopunct": 213,
        "entropy-2-nopunct": 7.720497244759367,
        "cond_entropy-2-nopunct": 0.927701920902111,
        "distinct-3-nopunct": 0.9908675799086758,
        "vocab_size-3-nopunct": 217,
        "unique-3-nopunct": 215,
        "entropy-3-nopunct": 7.756522219418535,
        "cond_entropy-3-nopunct": 0.04985341335554961,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.480513797611611,
        "rouge1": {
            "precision": 0.72549,
            "recall": 0.67563,
            "fmeasure": 0.68432
        },
        "rouge2": {
            "precision": 0.49206,
            "recall": 0.4555,
            "fmeasure": 0.4607
        },
        "rougeL": {
            "precision": 0.60175,
            "recall": 0.59073,
            "fmeasure": 0.58366
        },
        "rougeLsum": {
            "precision": 0.60175,
            "recall": 0.59073,
            "fmeasure": 0.58366
        },
        "bleu": 37.98745,
        "local_recall": {
            "1": 0.23333333333333334,
            "2": 0.3,
            "3": 0.6868686868686869
        },
        "bertscore": {
            "precision": 0.91577,
            "recall": 0.90974,
            "f1": 0.90961
        },
        "nubia": {
            "semantic_relation": 4.09344,
            "contradiction": 9.3577,
            "irrelevancy": 27.98006,
            "logical_agreement": 62.66224,
            "grammar_ref": 4.41455,
            "grammar_hyp": 4.28017,
            "nubia_score": 0.7293
        },
        "meteor": 0.3503045504729685,
        "bleurt": 0.14439
    },
    "totto_test_contrast_challenge_table_size-table_size_292": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 1.0,
        "median_pred_length": 18.0,
        "min_pred_length": 17,
        "max_pred_length": 19,
        "distinct-1": 0.8611111111111112,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.871178126382214,
        "distinct-2": 0.9705882352941176,
        "vocab_size-2": 33,
        "unique-2": 32,
        "entropy-2": 5.028639311838573,
        "cond_entropy-2": 0.11621100163636439,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.024962841250339415,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.681727678869737,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.14171030866920942,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.769051542093147,
        "rouge1": {
            "precision": 0.63137,
            "recall": 0.80139,
            "fmeasure": 0.69886
        },
        "rouge2": {
            "precision": 0.2753,
            "recall": 0.29993,
            "fmeasure": 0.28154
        },
        "rougeL": {
            "precision": 0.38431,
            "recall": 0.48889,
            "fmeasure": 0.42439
        },
        "rougeLsum": {
            "precision": 0.38431,
            "recall": 0.48889,
            "fmeasure": 0.42439
        },
        "bleu": 27.64593,
        "local_recall": {
            "1": 0.5,
            "2": 0.4,
            "3": 0.7368421052631579
        },
        "bertscore": {
            "precision": 0.88522,
            "recall": 0.92302,
            "f1": 0.90264
        },
        "nubia": {
            "semantic_relation": 3.99317,
            "contradiction": 0.43177,
            "irrelevancy": 74.46975,
            "logical_agreement": 25.09848,
            "grammar_ref": 4.97036,
            "grammar_hyp": 4.39179,
            "nubia_score": 0.67692
        },
        "meteor": 0.37657012767228676,
        "bleurt": -0.09004
    },
    "totto_test_contrast_challenge_table_size-table_size_384": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 9,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.78,
        "total_length": 156,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 7.571877794400365,
        "median_pred_length": 19.0,
        "min_pred_length": 7,
        "max_pred_length": 27,
        "distinct-1": 0.6858974358974359,
        "vocab_size-1": 107,
        "unique-1": 91,
        "entropy-1": 6.3386852925221815,
        "distinct-2": 0.9795918367346939,
        "vocab_size-2": 144,
        "unique-2": 141,
        "entropy-2": 7.158856018305743,
        "cond_entropy-2": 0.714867680457465,
        "distinct-3": 1.0,
        "vocab_size-3": 138,
        "unique-3": 138,
        "entropy-3": 7.108524456778167,
        "cond_entropy-3": -0.047669627188630354,
        "total_length-nopunct": 141,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 7.180219742846005,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7304964539007093,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 89,
        "entropy-1-nopunct": 6.344670501089452,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 129,
        "unique-2-nopunct": 126,
        "entropy-2-nopunct": 6.998939573903899,
        "cond_entropy-2-nopunct": 0.7008897369188684,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.942514505339227,
        "cond_entropy-3-nopunct": -0.053099126214335726,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.845226094749323,
        "rouge1": {
            "precision": 0.6356,
            "recall": 0.56171,
            "fmeasure": 0.5838
        },
        "rouge2": {
            "precision": 0.3184,
            "recall": 0.28817,
            "fmeasure": 0.29307
        },
        "rougeL": {
            "precision": 0.54913,
            "recall": 0.48748,
            "fmeasure": 0.50296
        },
        "rougeLsum": {
            "precision": 0.54913,
            "recall": 0.48748,
            "fmeasure": 0.50296
        },
        "bleu": 29.67628,
        "local_recall": {
            "1": 0.24528301886792453,
            "2": 0.5714285714285714,
            "3": 0.647887323943662
        },
        "bertscore": {
            "precision": 0.89993,
            "recall": 0.87916,
            "f1": 0.88755
        },
        "nubia": {
            "semantic_relation": 3.56178,
            "contradiction": 9.52348,
            "irrelevancy": 36.9878,
            "logical_agreement": 53.48872,
            "grammar_ref": 4.84583,
            "grammar_hyp": 4.98423,
            "nubia_score": 0.53079
        },
        "meteor": 0.3192196700906949,
        "bleurt": 0.05592
    },
    "totto_test_contrast_challenge_table_size-table_size_315": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.72,
        "total_length": 226,
        "mean_pred_length": 17.384615384615383,
        "std_pred_length": 4.515587729673592,
        "median_pred_length": 19.0,
        "min_pred_length": 11,
        "max_pred_length": 26,
        "distinct-1": 0.6061946902654868,
        "vocab_size-1": 137,
        "unique-1": 101,
        "entropy-1": 6.646460087754738,
        "distinct-2": 0.9154929577464789,
        "vocab_size-2": 195,
        "unique-2": 181,
        "entropy-2": 7.551519244598393,
        "cond_entropy-2": 0.7747248627681995,
        "distinct-3": 0.97,
        "vocab_size-3": 194,
        "unique-3": 189,
        "entropy-3": 7.580081752263924,
        "cond_entropy-3": 0.006695444570521266,
        "total_length-nopunct": 194,
        "mean_pred_length-nopunct": 14.923076923076923,
        "std_pred_length-nopunct": 4.196363599072571,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6855670103092784,
        "vocab_size-1-nopunct": 133,
        "unique-1-nopunct": 101,
        "entropy-1-nopunct": 6.745261534110492,
        "distinct-2-nopunct": 0.9392265193370166,
        "vocab_size-2-nopunct": 170,
        "unique-2-nopunct": 161,
        "entropy-2-nopunct": 7.369957627390763,
        "cond_entropy-2-nopunct": 0.6377103446771512,
        "distinct-3-nopunct": 0.9821428571428571,
        "vocab_size-3-nopunct": 165,
        "unique-3-nopunct": 162,
        "entropy-3-nopunct": 7.356603137064505,
        "cond_entropy-3-nopunct": -0.03160651488680525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.8205102939741185,
        "rouge1": {
            "precision": 0.66107,
            "recall": 0.66039,
            "fmeasure": 0.64287
        },
        "rouge2": {
            "precision": 0.38897,
            "recall": 0.38864,
            "fmeasure": 0.37862
        },
        "rougeL": {
            "precision": 0.51016,
            "recall": 0.51755,
            "fmeasure": 0.49722
        },
        "rougeLsum": {
            "precision": 0.51016,
            "recall": 0.51755,
            "fmeasure": 0.49722
        },
        "bleu": 34.44676,
        "local_recall": {
            "1": 0.1267605633802817,
            "2": 0.41509433962264153,
            "3": 0.6984126984126984
        },
        "bertscore": {
            "precision": 0.8894,
            "recall": 0.89744,
            "f1": 0.89185
        },
        "nubia": {
            "semantic_relation": 3.63111,
            "contradiction": 34.89108,
            "irrelevancy": 43.49291,
            "logical_agreement": 21.61601,
            "grammar_ref": 4.70766,
            "grammar_hyp": 4.19716,
            "nubia_score": 0.57255
        },
        "meteor": 0.3455282028933353,
        "bleurt": -0.00737
    },
    "totto_test_contrast_challenge_table_size-table_size_253": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 2.5,
        "median_pred_length": 19.5,
        "min_pred_length": 17,
        "max_pred_length": 22,
        "distinct-1": 0.8717948717948718,
        "vocab_size-1": 34,
        "unique-1": 32,
        "entropy-1": 4.936437078492072,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.2918792676974258,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.96875,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 4.9375,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": -0.026442737724814768,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2219589170969143,
        "rouge1": {
            "precision": 0.70724,
            "recall": 0.598,
            "fmeasure": 0.60541
        },
        "rouge2": {
            "precision": 0.50556,
            "recall": 0.41022,
            "fmeasure": 0.42009
        },
        "rougeL": {
            "precision": 0.65461,
            "recall": 0.57349,
            "fmeasure": 0.572
        },
        "rougeLsum": {
            "precision": 0.65461,
            "recall": 0.57349,
            "fmeasure": 0.572
        },
        "bleu": 32.99496,
        "local_recall": {
            "1": 0.7777777777777778,
            "2": 0.0,
            "3": 0.47368421052631576
        },
        "bertscore": {
            "precision": 0.92813,
            "recall": 0.8957,
            "f1": 0.90985
        },
        "nubia": {
            "semantic_relation": 3.60168,
            "contradiction": 17.87126,
            "irrelevancy": 65.47695,
            "logical_agreement": 16.65179,
            "grammar_ref": 4.45404,
            "grammar_hyp": 4.20841,
            "nubia_score": 0.47597
        },
        "meteor": 0.2807387611390084,
        "bleurt": -0.12613
    },
    "totto_test_contrast_challenge_table_size-table_size_294": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.73,
        "msttr-100_nopunct": 0.77,
        "total_length": 143,
        "mean_pred_length": 17.875,
        "std_pred_length": 5.464373248598599,
        "median_pred_length": 17.5,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6853146853146853,
        "vocab_size-1": 98,
        "unique-1": 84,
        "entropy-1": 6.192467865256455,
        "distinct-2": 0.9777777777777777,
        "vocab_size-2": 132,
        "unique-2": 130,
        "entropy-2": 7.026779393331125,
        "cond_entropy-2": 0.7114767108693785,
        "distinct-3": 1.0,
        "vocab_size-3": 127,
        "unique-3": 127,
        "entropy-3": 6.988684686772147,
        "cond_entropy-3": -0.047422839401166476,
        "total_length-nopunct": 125,
        "mean_pred_length-nopunct": 15.625,
        "std_pred_length-nopunct": 4.922842166878804,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.752,
        "vocab_size-1-nopunct": 94,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.2071529132756105,
        "distinct-2-nopunct": 0.9829059829059829,
        "vocab_size-2-nopunct": 115,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.82972465546233,
        "cond_entropy-2-nopunct": 0.6375044163423398,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 109,
        "unique-3-nopunct": 109,
        "entropy-3-nopunct": 6.7681843247769145,
        "cond_entropy-3-nopunct": -0.07309851405930111,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.811728750705199,
        "rouge1": {
            "precision": 0.71893,
            "recall": 0.6962,
            "fmeasure": 0.69599
        },
        "rouge2": {
            "precision": 0.46309,
            "recall": 0.45855,
            "fmeasure": 0.4551
        },
        "rougeL": {
            "precision": 0.58163,
            "recall": 0.57861,
            "fmeasure": 0.57259
        },
        "rougeLsum": {
            "precision": 0.58163,
            "recall": 0.57861,
            "fmeasure": 0.57259
        },
        "bleu": 37.32134,
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.5833333333333334,
            "3": 0.7464788732394366
        },
        "bertscore": {
            "precision": 0.91009,
            "recall": 0.92184,
            "f1": 0.91518
        },
        "nubia": {
            "semantic_relation": 3.95756,
            "contradiction": 15.21575,
            "irrelevancy": 51.72526,
            "logical_agreement": 33.05899,
            "grammar_ref": 4.54831,
            "grammar_hyp": 3.99842,
            "nubia_score": 0.72274
        },
        "meteor": 0.35310632727017754,
        "bleurt": 0.27733
    },
    "totto_test_contrast_challenge_table_size-table_size_385": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 3.0,
        "median_pred_length": 19.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 30,
        "unique-1": 25,
        "entropy-1": 4.731884343063671,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.411154167844194,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8055555555555556,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.680768321596843,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": 0.4354684419973452,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.08746284125033942,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.633203726021695,
        "rouge1": {
            "precision": 0.78208,
            "recall": 0.94213,
            "fmeasure": 0.84884
        },
        "rouge2": {
            "precision": 0.68194,
            "recall": 0.80458,
            "fmeasure": 0.73318
        },
        "rougeL": {
            "precision": 0.74875,
            "recall": 0.87165,
            "fmeasure": 0.80195
        },
        "rougeLsum": {
            "precision": 0.74875,
            "recall": 0.87165,
            "fmeasure": 0.80195
        },
        "bleu": 54.97688,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.6666666666666666,
            "3": 0.9473684210526315
        },
        "bertscore": {
            "precision": 0.95384,
            "recall": 0.97167,
            "f1": 0.96154
        },
        "nubia": {
            "semantic_relation": 4.92082,
            "contradiction": 0.39745,
            "irrelevancy": 27.80541,
            "logical_agreement": 71.79714,
            "grammar_ref": 3.86772,
            "grammar_hyp": 3.59383,
            "nubia_score": 0.89877
        },
        "meteor": 0.4953251567003805,
        "bleurt": 0.62037
    },
    "totto_test_contrast_challenge_table_size-table_size_318": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 79,
        "mean_pred_length": 15.8,
        "std_pred_length": 5.912698199637793,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.7341772151898734,
        "vocab_size-1": 58,
        "unique-1": 50,
        "entropy-1": 5.576135894311736,
        "distinct-2": 0.972972972972973,
        "vocab_size-2": 72,
        "unique-2": 71,
        "entropy-2": 6.145198129113233,
        "cond_entropy-2": 0.46134039419189765,
        "distinct-3": 1.0,
        "vocab_size-3": 69,
        "unique-3": 69,
        "entropy-3": 6.108524456778164,
        "cond_entropy-3": -0.032017495775947744,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 5.656854249492381,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.5882215457888655,
        "distinct-2-nopunct": 0.9692307692307692,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.949215697610558,
        "cond_entropy-2-nopunct": 0.4026142649875455,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.906890595608517,
        "cond_entropy-3-nopunct": -0.03622909238387809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.142303650334323,
        "rouge1": {
            "precision": 0.82831,
            "recall": 0.72388,
            "fmeasure": 0.76667
        },
        "rouge2": {
            "precision": 0.68416,
            "recall": 0.58511,
            "fmeasure": 0.62538
        },
        "rougeL": {
            "precision": 0.77561,
            "recall": 0.67733,
            "fmeasure": 0.71749
        },
        "rougeLsum": {
            "precision": 0.77561,
            "recall": 0.67733,
            "fmeasure": 0.71749
        },
        "bleu": 52.60783,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.13333333333333333,
            "3": 0.8035714285714286
        },
        "bertscore": {
            "precision": 0.94406,
            "recall": 0.92772,
            "f1": 0.9356
        },
        "nubia": {
            "semantic_relation": 4.37188,
            "contradiction": 10.59273,
            "irrelevancy": 26.19332,
            "logical_agreement": 63.21395,
            "grammar_ref": 4.74509,
            "grammar_hyp": 4.63301,
            "nubia_score": 0.78449
        },
        "meteor": 0.42769796013277245,
        "bleurt": 0.35694
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-unique_ojects": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 1654,
        "msttr-100": 0.5212,
        "msttr-100_nopunct": 0.5253,
        "total_length": 30881,
        "mean_pred_length": 18.67049576783555,
        "std_pred_length": 6.447510144057231,
        "median_pred_length": 20.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.06210938764936369,
        "vocab_size-1": 1918,
        "unique-1": 604,
        "entropy-1": 8.170569347634624,
        "distinct-2": 0.22256817326444725,
        "vocab_size-2": 6505,
        "unique-2": 3190,
        "entropy-2": 11.284695558233267,
        "cond_entropy-2": 3.0487703061541427,
        "distinct-3": 0.39244913502339246,
        "vocab_size-3": 10821,
        "unique-3": 6721,
        "entropy-3": 12.491206554237374,
        "cond_entropy-3": 1.3129284230043634,
        "total_length-nopunct": 28107,
        "mean_pred_length-nopunct": 16.99334945586457,
        "std_pred_length-nopunct": 6.1693613816443245,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06791902373074322,
        "vocab_size-1-nopunct": 1909,
        "unique-1-nopunct": 603,
        "entropy-1-nopunct": 8.356425221453446,
        "distinct-2-nopunct": 0.22935016822288587,
        "vocab_size-2-nopunct": 6067,
        "unique-2-nopunct": 3096,
        "entropy-2-nopunct": 11.170929206315524,
        "cond_entropy-2-nopunct": 3.0015303313493136,
        "distinct-3-nopunct": 0.3984838098310416,
        "vocab_size-3-nopunct": 9882,
        "unique-3-nopunct": 6249,
        "entropy-3-nopunct": 12.347245805534637,
        "cond_entropy-3-nopunct": 1.2785248016304824,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.001819878569745,
        "rouge1": {
            "precision": 0.78544,
            "recall": 0.68962,
            "fmeasure": 0.72132
        },
        "rouge2": {
            "precision": 0.53267,
            "recall": 0.46459,
            "fmeasure": 0.48644
        },
        "rougeL": {
            "precision": 0.64915,
            "recall": 0.57043,
            "fmeasure": 0.59604
        },
        "rougeLsum": {
            "precision": 0.64915,
            "recall": 0.57043,
            "fmeasure": 0.59604
        },
        "bleu": 40.64237,
        "local_recall": {
            "1": 0.19520483292429677,
            "2": 0.5044229149115417,
            "3": 0.7503367003367003,
            "4": 0.8909090909090909,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.92482,
            "recall": 0.90437,
            "f1": 0.91297
        },
        "nubia": {
            "semantic_relation": 4.17963,
            "contradiction": 6.77328,
            "irrelevancy": 9.52693,
            "logical_agreement": 83.69979,
            "grammar_ref": 4.57661,
            "grammar_hyp": 4.79567,
            "nubia_score": 0.69191
        },
        "meteor": 0.3333451539468804,
        "bleurt": 0.08733
    },
    "totto_test_contrast_challenge_table_size-table_size_279": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 22.5,
        "std_pred_length": 1.5,
        "median_pred_length": 22.5,
        "min_pred_length": 21,
        "max_pred_length": 24,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 4.924969207344631,
        "distinct-2": 0.9534883720930233,
        "vocab_size-2": 41,
        "unique-2": 39,
        "entropy-2": 5.333241498888144,
        "cond_entropy-2": 0.3881273561474685,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": 0.028848225525741733,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 21.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7906976744186046,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.879525801113099,
        "distinct-2-nopunct": 0.9512195121951219,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.259991029008325,
        "cond_entropy-2-nopunct": 0.40713542075322834,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": 0.03041431680826753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.320618635152476,
        "rouge1": {
            "precision": 0.78225,
            "recall": 0.80095,
            "fmeasure": 0.78348
        },
        "rouge2": {
            "precision": 0.40231,
            "recall": 0.41211,
            "fmeasure": 0.40263
        },
        "rougeL": {
            "precision": 0.48514,
            "recall": 0.49284,
            "fmeasure": 0.48373
        },
        "rougeLsum": {
            "precision": 0.48514,
            "recall": 0.49284,
            "fmeasure": 0.48373
        },
        "bleu": 15.49805,
        "local_recall": {
            "1": 0.5,
            "2": 0.16666666666666666,
            "3": 0.9629629629629629
        },
        "bertscore": {
            "precision": 0.92099,
            "recall": 0.93402,
            "f1": 0.92501
        },
        "nubia": {
            "semantic_relation": 4.33215,
            "contradiction": 3.96654,
            "irrelevancy": 82.16388,
            "logical_agreement": 13.86958,
            "grammar_ref": 3.10743,
            "grammar_hyp": 3.44671,
            "nubia_score": 0.81569
        },
        "meteor": 0.39100248448837777,
        "bleurt": -0.00283
    },
    "totto_test_contrast_challenge_table_size-table_size_225": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.76,
        "total_length": 296,
        "mean_pred_length": 17.41176470588235,
        "std_pred_length": 5.064975739206884,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.5878378378378378,
        "vocab_size-1": 174,
        "unique-1": 134,
        "entropy-1": 6.903065942900276,
        "distinct-2": 0.8960573476702509,
        "vocab_size-2": 250,
        "unique-2": 227,
        "entropy-2": 7.898244788500684,
        "cond_entropy-2": 0.8708801172020201,
        "distinct-3": 0.9465648854961832,
        "vocab_size-3": 248,
        "unique-3": 236,
        "entropy-3": 7.920790272513331,
        "cond_entropy-3": 0.03720159430493026,
        "total_length-nopunct": 266,
        "mean_pred_length-nopunct": 15.647058823529411,
        "std_pred_length-nopunct": 4.536663408155022,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.6353383458646616,
        "vocab_size-1-nopunct": 169,
        "unique-1-nopunct": 133,
        "entropy-1-nopunct": 6.944949321961508,
        "distinct-2-nopunct": 0.8835341365461847,
        "vocab_size-2-nopunct": 220,
        "unique-2-nopunct": 197,
        "entropy-2-nopunct": 7.706911369784332,
        "cond_entropy-2-nopunct": 0.8217036660163339,
        "distinct-3-nopunct": 0.9396551724137931,
        "vocab_size-3-nopunct": 218,
        "unique-3-nopunct": 206,
        "entropy-3-nopunct": 7.7307836890744195,
        "cond_entropy-3-nopunct": 0.03810740359538334,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.135655018559324,
        "rouge1": {
            "precision": 0.74767,
            "recall": 0.75534,
            "fmeasure": 0.74109
        },
        "rouge2": {
            "precision": 0.53489,
            "recall": 0.55001,
            "fmeasure": 0.5318
        },
        "rougeL": {
            "precision": 0.65475,
            "recall": 0.66537,
            "fmeasure": 0.64766
        },
        "rougeLsum": {
            "precision": 0.65475,
            "recall": 0.66537,
            "fmeasure": 0.64766
        },
        "bleu": 46.83671,
        "local_recall": {
            "1": 0.16,
            "2": 0.5,
            "3": 0.7971698113207547
        },
        "bertscore": {
            "precision": 0.91783,
            "recall": 0.92771,
            "f1": 0.91956
        },
        "nubia": {
            "semantic_relation": 4.06654,
            "contradiction": 9.32937,
            "irrelevancy": 45.19722,
            "logical_agreement": 45.47341,
            "grammar_ref": 4.59976,
            "grammar_hyp": 4.627,
            "nubia_score": 0.67791
        },
        "meteor": 0.398002205680725,
        "bleurt": 0.1475
    },
    "totto_test_contrast_challenge_table_size-table_size_280": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 25,
        "msttr-100": 0.7525,
        "msttr-100_nopunct": 0.80667,
        "total_length": 412,
        "mean_pred_length": 16.48,
        "std_pred_length": 5.478101861046397,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.6067961165048543,
        "vocab_size-1": 250,
        "unique-1": 210,
        "entropy-1": 7.27568054244782,
        "distinct-2": 0.9741602067183462,
        "vocab_size-2": 377,
        "unique-2": 370,
        "entropy-2": 8.537391597224069,
        "cond_entropy-2": 1.0648582151477968,
        "distinct-3": 1.0,
        "vocab_size-3": 362,
        "unique-3": 362,
        "entropy-3": 8.499845887083191,
        "cond_entropy-3": -0.03348506380660992,
        "total_length-nopunct": 357,
        "mean_pred_length-nopunct": 14.28,
        "std_pred_length-nopunct": 4.660643732361443,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6834733893557423,
        "vocab_size-1-nopunct": 244,
        "unique-1-nopunct": 210,
        "entropy-1-nopunct": 7.424923396854236,
        "distinct-2-nopunct": 0.9698795180722891,
        "vocab_size-2-nopunct": 322,
        "unique-2-nopunct": 315,
        "entropy-2-nopunct": 8.306500613569312,
        "cond_entropy-2-nopunct": 0.957997161532522,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 307,
        "unique-3-nopunct": 307,
        "entropy-3-nopunct": 8.262094845370138,
        "cond_entropy-3-nopunct": -0.03882443124657153,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.773055118946556,
        "rouge1": {
            "precision": 0.7914,
            "recall": 0.77916,
            "fmeasure": 0.77719
        },
        "rouge2": {
            "precision": 0.54339,
            "recall": 0.5327,
            "fmeasure": 0.5325
        },
        "rougeL": {
            "precision": 0.65026,
            "recall": 0.63249,
            "fmeasure": 0.63387
        },
        "rougeLsum": {
            "precision": 0.65026,
            "recall": 0.63249,
            "fmeasure": 0.63387
        },
        "bleu": 47.92377,
        "local_recall": {
            "1": 0.17391304347826086,
            "2": 0.53125,
            "3": 0.7956989247311828
        },
        "bertscore": {
            "precision": 0.9435,
            "recall": 0.93771,
            "f1": 0.93829
        },
        "nubia": {
            "semantic_relation": 4.30659,
            "contradiction": 6.53149,
            "irrelevancy": 25.70355,
            "logical_agreement": 67.76496,
            "grammar_ref": 4.76367,
            "grammar_hyp": 4.78408,
            "nubia_score": 0.75968
        },
        "meteor": 0.4106124247793804,
        "bleurt": 0.34294
    },
    "totto_test_contrast_challenge_table_size-table_size_255": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.74,
        "msttr-100_nopunct": NaN,
        "total_length": 100,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 5.849976258261415,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.74,
        "vocab_size-1": 74,
        "unique-1": 64,
        "entropy-1": 5.919052130997598,
        "distinct-2": 0.9680851063829787,
        "vocab_size-2": 91,
        "unique-2": 88,
        "entropy-2": 6.490759064443583,
        "cond_entropy-2": 0.49446420874628255,
        "distinct-3": 1.0,
        "vocab_size-3": 88,
        "unique-3": 88,
        "entropy-3": 6.459431618637305,
        "cond_entropy-3": -0.02697541485852214,
        "total_length-nopunct": 88,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 5.467073155618908,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7954545454545454,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 5.899646108082303,
        "distinct-2-nopunct": 0.975609756097561,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.308771516813209,
        "cond_entropy-2-nopunct": 0.4378902021861533,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 76,
        "entropy-3-nopunct": 6.247927513443591,
        "cond_entropy-3-nopunct": -0.05699291222712947,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.908299050143126,
        "rouge1": {
            "precision": 0.78017,
            "recall": 0.74895,
            "fmeasure": 0.75936
        },
        "rouge2": {
            "precision": 0.48068,
            "recall": 0.47244,
            "fmeasure": 0.47187
        },
        "rougeL": {
            "precision": 0.63726,
            "recall": 0.6255,
            "fmeasure": 0.62577
        },
        "rougeLsum": {
            "precision": 0.63726,
            "recall": 0.6255,
            "fmeasure": 0.62577
        },
        "bleu": 39.99657,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.3333333333333333,
            "3": 0.7857142857142857
        },
        "bertscore": {
            "precision": 0.93022,
            "recall": 0.92124,
            "f1": 0.92537
        },
        "nubia": {
            "semantic_relation": 4.22336,
            "contradiction": 19.81717,
            "irrelevancy": 24.28117,
            "logical_agreement": 55.90166,
            "grammar_ref": 5.40206,
            "grammar_hyp": 4.98857,
            "nubia_score": 0.76887
        },
        "meteor": 0.3887638090809279,
        "bleurt": 0.27545
    },
    "totto_test_contrast_challenge_table_size-table_size_408": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 15,
        "msttr-100": 0.725,
        "msttr-100_nopunct": 0.8,
        "total_length": 217,
        "mean_pred_length": 14.466666666666667,
        "std_pred_length": 4.978174587358525,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6589861751152074,
        "vocab_size-1": 143,
        "unique-1": 119,
        "entropy-1": 6.632146367144904,
        "distinct-2": 0.9603960396039604,
        "vocab_size-2": 194,
        "unique-2": 187,
        "entropy-2": 7.575266495117294,
        "cond_entropy-2": 0.7368711876029507,
        "distinct-3": 1.0,
        "vocab_size-3": 187,
        "unique-3": 187,
        "entropy-3": 7.546894459887616,
        "cond_entropy-3": -0.03241388114135876,
        "total_length-nopunct": 190,
        "mean_pred_length-nopunct": 12.666666666666666,
        "std_pred_length-nopunct": 4.437216344611663,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7263157894736842,
        "vocab_size-1-nopunct": 138,
        "unique-1-nopunct": 116,
        "entropy-1-nopunct": 6.7385494408420055,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 162,
        "entropy-2-nopunct": 7.366897468962803,
        "cond_entropy-2-nopunct": 0.6700604138973528,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 160,
        "unique-3-nopunct": 160,
        "entropy-3-nopunct": 7.321928094887368,
        "cond_entropy-3-nopunct": -0.04331497005644487,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.584814626142702,
        "rouge1": {
            "precision": 0.81581,
            "recall": 0.78564,
            "fmeasure": 0.79159
        },
        "rouge2": {
            "precision": 0.64756,
            "recall": 0.62066,
            "fmeasure": 0.6264
        },
        "rougeL": {
            "precision": 0.75877,
            "recall": 0.73238,
            "fmeasure": 0.73741
        },
        "rougeLsum": {
            "precision": 0.75877,
            "recall": 0.73238,
            "fmeasure": 0.73741
        },
        "bleu": 59.36591,
        "local_recall": {
            "1": 0.2765957446808511,
            "2": 0.37037037037037035,
            "3": 0.8451612903225807
        },
        "bertscore": {
            "precision": 0.95637,
            "recall": 0.95117,
            "f1": 0.9513
        },
        "nubia": {
            "semantic_relation": 4.42141,
            "contradiction": 13.41713,
            "irrelevancy": 25.58164,
            "logical_agreement": 61.00123,
            "grammar_ref": 4.56596,
            "grammar_hyp": 4.72348,
            "nubia_score": 0.78991
        },
        "meteor": 0.465651749660664,
        "bleurt": 0.32052
    },
    "totto_test_contrast_challenge_table_size-table_size_320": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.74,
        "total_length": 217,
        "mean_pred_length": 15.5,
        "std_pred_length": 5.010702830655881,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.6082949308755761,
        "vocab_size-1": 132,
        "unique-1": 107,
        "entropy-1": 6.498076129898446,
        "distinct-2": 0.9359605911330049,
        "vocab_size-2": 190,
        "unique-2": 180,
        "entropy-2": 7.523686225056297,
        "cond_entropy-2": 0.9008273435666745,
        "distinct-3": 0.9894179894179894,
        "vocab_size-3": 187,
        "unique-3": 185,
        "entropy-3": 7.54107840305706,
        "cond_entropy-3": 0.027884747788084255,
        "total_length-nopunct": 193,
        "mean_pred_length-nopunct": 13.785714285714286,
        "std_pred_length-nopunct": 5.198606563693931,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6580310880829016,
        "vocab_size-1-nopunct": 127,
        "unique-1-nopunct": 104,
        "entropy-1-nopunct": 6.542585419491613,
        "distinct-2-nopunct": 0.9385474860335196,
        "vocab_size-2-nopunct": 168,
        "unique-2-nopunct": 160,
        "entropy-2-nopunct": 7.345520316358307,
        "cond_entropy-2-nopunct": 0.8706066295379141,
        "distinct-3-nopunct": 0.9939393939393939,
        "vocab_size-3-nopunct": 164,
        "unique-3-nopunct": 163,
        "entropy-3-nopunct": 7.354201002124597,
        "cond_entropy-3-nopunct": 0.02041484608558057,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.376471920565457,
        "rouge1": {
            "precision": 0.85374,
            "recall": 0.81138,
            "fmeasure": 0.82518
        },
        "rouge2": {
            "precision": 0.70949,
            "recall": 0.67997,
            "fmeasure": 0.68963
        },
        "rougeL": {
            "precision": 0.74986,
            "recall": 0.73726,
            "fmeasure": 0.73858
        },
        "rougeLsum": {
            "precision": 0.74986,
            "recall": 0.73726,
            "fmeasure": 0.73858
        },
        "bleu": 63.91825,
        "local_recall": {
            "1": 0.30303030303030304,
            "2": 0.5681818181818182,
            "3": 0.8357142857142857
        },
        "bertscore": {
            "precision": 0.95669,
            "recall": 0.94839,
            "f1": 0.95126
        },
        "nubia": {
            "semantic_relation": 4.4063,
            "contradiction": 5.50768,
            "irrelevancy": 21.55763,
            "logical_agreement": 72.93469,
            "grammar_ref": 4.83858,
            "grammar_hyp": 4.8689,
            "nubia_score": 0.79121
        },
        "meteor": 0.4552387879243161,
        "bleurt": 0.47514
    },
    "totto_test_contrast_challenge_table_size-table_size_282": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966059,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4787592938848926,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.76413,
            "fmeasure": 0.77077
        },
        "rouge2": {
            "precision": 0.47059,
            "recall": 0.46187,
            "fmeasure": 0.46611
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.49123,
            "fmeasure": 0.4955
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.49123,
            "fmeasure": 0.4955
        },
        "bleu": 19.81179,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.90392,
            "recall": 0.90333,
            "f1": 0.90363
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.07668,
            "irrelevancy": 0.68202,
            "logical_agreement": 99.24129,
            "grammar_ref": 4.92793,
            "grammar_hyp": 4.45317,
            "nubia_score": 1.0
        },
        "meteor": 0.3628824728623161,
        "bleurt": 0.44392
    },
    "totto_test_contrast_challenge_table_size-table_size_295": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.78,
        "total_length": 178,
        "mean_pred_length": 16.181818181818183,
        "std_pred_length": 5.637829721350419,
        "median_pred_length": 16.0,
        "min_pred_length": 6,
        "max_pred_length": 24,
        "distinct-1": 0.6123595505617978,
        "vocab_size-1": 109,
        "unique-1": 86,
        "entropy-1": 6.314511119731852,
        "distinct-2": 0.8802395209580839,
        "vocab_size-2": 147,
        "unique-2": 132,
        "entropy-2": 7.11352815188263,
        "cond_entropy-2": 0.7046704477831179,
        "distinct-3": 0.9294871794871795,
        "vocab_size-3": 145,
        "unique-3": 135,
        "entropy-3": 7.139537555386856,
        "cond_entropy-3": 0.045060285212556936,
        "total_length-nopunct": 160,
        "mean_pred_length-nopunct": 14.545454545454545,
        "std_pred_length-nopunct": 5.382862306577258,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.65625,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 84,
        "entropy-1-nopunct": 6.331198332810097,
        "distinct-2-nopunct": 0.8657718120805369,
        "vocab_size-2-nopunct": 129,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.916353651477178,
        "cond_entropy-2-nopunct": 0.6515850326459324,
        "distinct-3-nopunct": 0.9202898550724637,
        "vocab_size-3-nopunct": 127,
        "unique-3-nopunct": 117,
        "entropy-3-nopunct": 6.943633967632055,
        "cond_entropy-3-nopunct": 0.04417135643629915,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.12432284326573,
        "rouge1": {
            "precision": 0.83063,
            "recall": 0.88349,
            "fmeasure": 0.85205
        },
        "rouge2": {
            "precision": 0.68232,
            "recall": 0.72061,
            "fmeasure": 0.69759
        },
        "rougeL": {
            "precision": 0.76803,
            "recall": 0.81186,
            "fmeasure": 0.78629
        },
        "rougeLsum": {
            "precision": 0.76803,
            "recall": 0.81186,
            "fmeasure": 0.78629
        },
        "bleu": 60.48118,
        "local_recall": {
            "1": 0.125,
            "2": 0.625,
            "3": 0.8861788617886179
        },
        "bertscore": {
            "precision": 0.9596,
            "recall": 0.95898,
            "f1": 0.95856
        },
        "nubia": {
            "semantic_relation": 4.6609,
            "contradiction": 1.7065,
            "irrelevancy": 11.08484,
            "logical_agreement": 87.20866,
            "grammar_ref": 4.24853,
            "grammar_hyp": 4.11997,
            "nubia_score": 0.89491
        },
        "meteor": 0.47318390704677504,
        "bleurt": 0.54736
    },
    "totto_test_contrast_challenge_table_size-table_size_284": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.984183719779189,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 18,
        "unique-2": 17,
        "entropy-2": 4.142664355548846,
        "cond_entropy-2": 0.17625665551219524,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": 0.033108599109837954,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.892407118592875,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": 0.1861579047855862,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": 0.03518489863155644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2478775610036172,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.54986,
            "fmeasure": 0.60261
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.36,
            "fmeasure": 0.3913
        },
        "rougeL": {
            "precision": 0.59091,
            "recall": 0.5,
            "fmeasure": 0.54167
        },
        "rougeLsum": {
            "precision": 0.59091,
            "recall": 0.5,
            "fmeasure": 0.54167
        },
        "bleu": 21.68895,
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.5882352941176471
        },
        "bertscore": {
            "precision": 0.90451,
            "recall": 0.88781,
            "f1": 0.89559
        },
        "nubia": {
            "semantic_relation": 2.96454,
            "contradiction": 2.05904,
            "irrelevancy": 92.0862,
            "logical_agreement": 5.85475,
            "grammar_ref": 4.71547,
            "grammar_hyp": 5.24957,
            "nubia_score": 0.28607
        },
        "meteor": 0.28666465499261656,
        "bleurt": -0.37123
    },
    "totto_test_contrast_challenge_table_size-table_size_387": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 74,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.024937810560445,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.7162162162162162,
        "vocab_size-1": 53,
        "unique-1": 41,
        "entropy-1": 5.491057967538006,
        "distinct-2": 0.9571428571428572,
        "vocab_size-2": 67,
        "unique-2": 64,
        "entropy-2": 6.0435687312306845,
        "cond_entropy-2": 0.4792762150121621,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 64,
        "unique-3": 62,
        "entropy-3": 5.983788058752402,
        "cond_entropy-3": -0.05458586728348304,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 4.153311931459037,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7741935483870968,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 41,
        "entropy-1-nopunct": 5.354821157826711,
        "distinct-2-nopunct": 0.9482758620689655,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 52,
        "entropy-2-nopunct": 5.754532719265502,
        "cond_entropy-2-nopunct": 0.441047778856734,
        "distinct-3-nopunct": 0.9629629629629629,
        "vocab_size-3-nopunct": 52,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.680813428089394,
        "cond_entropy-3-nopunct": -0.06605645592706638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.583060736386259,
        "rouge1": {
            "precision": 0.63336,
            "recall": 0.74752,
            "fmeasure": 0.676
        },
        "rouge2": {
            "precision": 0.40826,
            "recall": 0.47832,
            "fmeasure": 0.43196
        },
        "rougeL": {
            "precision": 0.55168,
            "recall": 0.64593,
            "fmeasure": 0.58693
        },
        "rougeLsum": {
            "precision": 0.55168,
            "recall": 0.64593,
            "fmeasure": 0.58693
        },
        "bleu": 37.92791,
        "local_recall": {
            "1": 0.14814814814814814,
            "2": 0.4666666666666667,
            "3": 0.717948717948718
        },
        "bertscore": {
            "precision": 0.921,
            "recall": 0.93676,
            "f1": 0.92622
        },
        "nubia": {
            "semantic_relation": 4.03951,
            "contradiction": 1.68331,
            "irrelevancy": 62.91675,
            "logical_agreement": 35.39994,
            "grammar_ref": 4.83213,
            "grammar_hyp": 4.27219,
            "nubia_score": 0.74876
        },
        "meteor": 0.40869128741724065,
        "bleurt": 0.27453
    },
    "totto_test_contrast_challenge_table_size-table_size_322": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 2.5,
        "median_pred_length": 15.5,
        "min_pred_length": 13,
        "max_pred_length": 18,
        "distinct-1": 0.9032258064516129,
        "vocab_size-1": 28,
        "unique-1": 25,
        "entropy-1": 4.760647923290102,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.04171571922345572,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.664497779200462,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.04693094992964164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.069113819808463,
        "rouge1": {
            "precision": 0.86683,
            "recall": 0.77016,
            "fmeasure": 0.81491
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.49561,
            "fmeasure": 0.52048
        },
        "rougeL": {
            "precision": 0.5622,
            "recall": 0.51542,
            "fmeasure": 0.537
        },
        "rougeLsum": {
            "precision": 0.5622,
            "recall": 0.51542,
            "fmeasure": 0.537
        },
        "bleu": 32.29403,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7586206896551724
        },
        "bertscore": {
            "precision": 0.95827,
            "recall": 0.94502,
            "f1": 0.95159
        },
        "nubia": {
            "semantic_relation": 4.65903,
            "contradiction": 17.29664,
            "irrelevancy": 1.86532,
            "logical_agreement": 80.83803,
            "grammar_ref": 4.49155,
            "grammar_hyp": 4.4675,
            "nubia_score": 0.9099
        },
        "meteor": 0.42309176287895983,
        "bleurt": 0.48578
    },
    "totto_test_contrast_challenge_table_size-table_size_285": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.79,
        "msttr-100_nopunct": 0.81,
        "total_length": 139,
        "mean_pred_length": 19.857142857142858,
        "std_pred_length": 6.577636818983622,
        "median_pred_length": 23.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.7050359712230215,
        "vocab_size-1": 98,
        "unique-1": 81,
        "entropy-1": 6.311468656332482,
        "distinct-2": 0.9848484848484849,
        "vocab_size-2": 130,
        "unique-2": 128,
        "entropy-2": 7.0140910890554125,
        "cond_entropy-2": 0.6178358977410707,
        "distinct-3": 1.0,
        "vocab_size-3": 125,
        "unique-3": 125,
        "entropy-3": 6.965784284662096,
        "cond_entropy-3": -0.04660983469636636,
        "total_length-nopunct": 122,
        "mean_pred_length-nopunct": 17.428571428571427,
        "std_pred_length-nopunct": 5.996597674804388,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7622950819672131,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 78,
        "entropy-1-nopunct": 6.332903755845294,
        "distinct-2-nopunct": 0.9826086956521739,
        "vocab_size-2-nopunct": 113,
        "unique-2-nopunct": 111,
        "entropy-2-nopunct": 6.810707442248738,
        "cond_entropy-2-nopunct": 0.5054979044210323,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 108,
        "unique-3-nopunct": 108,
        "entropy-3-nopunct": 6.754887502163458,
        "cond_entropy-3-nopunct": -0.05356551174386936,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.943435627065592,
        "rouge1": {
            "precision": 0.82165,
            "recall": 0.79108,
            "fmeasure": 0.80204
        },
        "rouge2": {
            "precision": 0.54753,
            "recall": 0.532,
            "fmeasure": 0.53711
        },
        "rougeL": {
            "precision": 0.68984,
            "recall": 0.64721,
            "fmeasure": 0.66293
        },
        "rougeLsum": {
            "precision": 0.68984,
            "recall": 0.64721,
            "fmeasure": 0.66293
        },
        "bleu": 54.98372,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.7741935483870968,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.93587,
            "recall": 0.92943,
            "f1": 0.93221
        },
        "nubia": {
            "semantic_relation": 4.53565,
            "contradiction": 1.46731,
            "irrelevancy": 29.69541,
            "logical_agreement": 68.83728,
            "grammar_ref": 4.72263,
            "grammar_hyp": 4.7202,
            "nubia_score": 0.81152
        },
        "meteor": 0.43894689773020634,
        "bleurt": 0.29955
    },
    "totto_test_contrast_challenge_table_size-table_size_296": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 107,
        "mean_pred_length": 15.285714285714286,
        "std_pred_length": 6.1577891606435164,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6261682242990654,
        "vocab_size-1": 67,
        "unique-1": 53,
        "entropy-1": 5.651715968325181,
        "distinct-2": 0.92,
        "vocab_size-2": 92,
        "unique-2": 86,
        "entropy-2": 6.468758439731469,
        "cond_entropy-2": 0.7613790129200058,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 90,
        "unique-3": 88,
        "entropy-3": 6.466525612160043,
        "cond_entropy-3": 0.01094657296947284,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 13.285714285714286,
        "std_pred_length-nopunct": 5.598833697790122,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 51,
        "entropy-1-nopunct": 5.547343424467956,
        "distinct-2-nopunct": 0.9069767441860465,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.222662719768065,
        "cond_entropy-2-nopunct": 0.7327926407243057,
        "distinct-3-nopunct": 0.9620253164556962,
        "vocab_size-3-nopunct": 76,
        "unique-3-nopunct": 74,
        "entropy-3-nopunct": 6.2182758430864284,
        "cond_entropy-3-nopunct": 0.0009955821099855752,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8245749158110294,
        "rouge1": {
            "precision": 0.66665,
            "recall": 0.63698,
            "fmeasure": 0.64313
        },
        "rouge2": {
            "precision": 0.44629,
            "recall": 0.4224,
            "fmeasure": 0.42831
        },
        "rougeL": {
            "precision": 0.58463,
            "recall": 0.55224,
            "fmeasure": 0.56055
        },
        "rougeLsum": {
            "precision": 0.58463,
            "recall": 0.55224,
            "fmeasure": 0.56055
        },
        "bleu": 26.40157,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.47058823529411764,
            "3": 0.6231884057971014
        },
        "bertscore": {
            "precision": 0.89508,
            "recall": 0.89135,
            "f1": 0.89175
        },
        "nubia": {
            "semantic_relation": 3.80412,
            "contradiction": 6.17575,
            "irrelevancy": 53.72732,
            "logical_agreement": 40.09693,
            "grammar_ref": 4.06397,
            "grammar_hyp": 4.37162,
            "nubia_score": 0.64525
        },
        "meteor": 0.34099364015385975,
        "bleurt": 0.00147
    },
    "totto_test_contrast_challenge_table_size-table_size_390": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.77,
        "msttr-100_nopunct": 0.8,
        "total_length": 136,
        "mean_pred_length": 17.0,
        "std_pred_length": 6.123724356957945,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.7058823529411765,
        "vocab_size-1": 96,
        "unique-1": 78,
        "entropy-1": 6.293057694064248,
        "distinct-2": 0.9453125,
        "vocab_size-2": 121,
        "unique-2": 114,
        "entropy-2": 6.890625,
        "cond_entropy-2": 0.5260475104135719,
        "distinct-3": 0.9666666666666667,
        "vocab_size-3": 116,
        "unique-3": 112,
        "entropy-3": 6.840223928941866,
        "cond_entropy-3": -0.04310940439148149,
        "total_length-nopunct": 123,
        "mean_pred_length-nopunct": 15.375,
        "std_pred_length-nopunct": 5.655473012931809,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7560975609756098,
        "vocab_size-1-nopunct": 93,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.316339302016842,
        "distinct-2-nopunct": 0.9391304347826087,
        "vocab_size-2-nopunct": 108,
        "unique-2-nopunct": 101,
        "entropy-2-nopunct": 6.7237509205096035,
        "cond_entropy-2-nopunct": 0.45097163263690876,
        "distinct-3-nopunct": 0.9626168224299065,
        "vocab_size-3-nopunct": 103,
        "unique-3-nopunct": 99,
        "entropy-3-nopunct": 6.66670063126095,
        "cond_entropy-3-nopunct": -0.04794829818808807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.879814621742191,
        "rouge1": {
            "precision": 0.8486,
            "recall": 0.74795,
            "fmeasure": 0.79042
        },
        "rouge2": {
            "precision": 0.59559,
            "recall": 0.52467,
            "fmeasure": 0.55461
        },
        "rougeL": {
            "precision": 0.62787,
            "recall": 0.55307,
            "fmeasure": 0.58511
        },
        "rougeLsum": {
            "precision": 0.62787,
            "recall": 0.55307,
            "fmeasure": 0.58511
        },
        "bleu": 40.91838,
        "local_recall": {
            "1": 0.13043478260869565,
            "2": 0.34615384615384615,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.93803,
            "recall": 0.92632,
            "f1": 0.93093
        },
        "nubia": {
            "semantic_relation": 4.36912,
            "contradiction": 1.5013,
            "irrelevancy": 10.14627,
            "logical_agreement": 88.35243,
            "grammar_ref": 4.47406,
            "grammar_hyp": 4.78024,
            "nubia_score": 0.76878
        },
        "meteor": 0.3823464384932352,
        "bleurt": 0.3248
    },
    "totto_test_contrast_challenge_table_size-table_size_256": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.64,
        "msttr-100_nopunct": 0.67,
        "total_length": 172,
        "mean_pred_length": 17.2,
        "std_pred_length": 2.9597297173897483,
        "median_pred_length": 17.5,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.6395348837209303,
        "vocab_size-1": 110,
        "unique-1": 88,
        "entropy-1": 6.314791099372589,
        "distinct-2": 0.9197530864197531,
        "vocab_size-2": 149,
        "unique-2": 141,
        "entropy-2": 7.150005018303349,
        "cond_entropy-2": 0.6987661140197818,
        "distinct-3": 0.9605263157894737,
        "vocab_size-3": 146,
        "unique-3": 142,
        "entropy-3": 7.155822250285671,
        "cond_entropy-3": 0.018307033599509692,
        "total_length-nopunct": 154,
        "mean_pred_length-nopunct": 15.4,
        "std_pred_length-nopunct": 2.6907248094147422,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6818181818181818,
        "vocab_size-1-nopunct": 105,
        "unique-1-nopunct": 87,
        "entropy-1-nopunct": 6.297959915593389,
        "distinct-2-nopunct": 0.9097222222222222,
        "vocab_size-2-nopunct": 131,
        "unique-2-nopunct": 123,
        "entropy-2-nopunct": 6.956349393788417,
        "cond_entropy-2-nopunct": 0.7048357716048527,
        "distinct-3-nopunct": 0.9552238805970149,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 124,
        "entropy-3-nopunct": 6.9616115785174815,
        "cond_entropy-3-nopunct": 0.021200662912202368,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.631973435977768,
        "rouge1": {
            "precision": 0.70221,
            "recall": 0.75482,
            "fmeasure": 0.71689
        },
        "rouge2": {
            "precision": 0.47949,
            "recall": 0.53092,
            "fmeasure": 0.49497
        },
        "rougeL": {
            "precision": 0.62505,
            "recall": 0.66986,
            "fmeasure": 0.63704
        },
        "rougeLsum": {
            "precision": 0.62505,
            "recall": 0.66986,
            "fmeasure": 0.63704
        },
        "bleu": 48.75578,
        "local_recall": {
            "1": 0.2647058823529412,
            "2": 0.45161290322580644,
            "3": 0.8673469387755102
        },
        "bertscore": {
            "precision": 0.91642,
            "recall": 0.92266,
            "f1": 0.91778
        },
        "nubia": {
            "semantic_relation": 4.14859,
            "contradiction": 11.39899,
            "irrelevancy": 49.71406,
            "logical_agreement": 38.88695,
            "grammar_ref": 4.57625,
            "grammar_hyp": 4.16692,
            "nubia_score": 0.71796
        },
        "meteor": 0.42935133021229277,
        "bleurt": 0.30869
    },
    "totto_test_contrast_challenge_table_size-table_size_350": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.76,
        "msttr-100_nopunct": NaN,
        "total_length": 105,
        "mean_pred_length": 15.0,
        "std_pred_length": 4.869731585445518,
        "median_pred_length": 15.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.7428571428571429,
        "vocab_size-1": 78,
        "unique-1": 63,
        "entropy-1": 6.07209387990211,
        "distinct-2": 0.9897959183673469,
        "vocab_size-2": 97,
        "unique-2": 96,
        "entropy-2": 6.594301680849911,
        "cond_entropy-2": 0.3675504234982422,
        "distinct-3": 1.0,
        "vocab_size-3": 91,
        "unique-3": 91,
        "entropy-3": 6.507794640198703,
        "cond_entropy-3": -0.08493718193849019,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 13.285714285714286,
        "std_pred_length-nopunct": 4.589250972631145,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8064516129032258,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 62,
        "entropy-1-nopunct": 6.111476687335805,
        "distinct-2-nopunct": 0.9883720930232558,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 84,
        "entropy-2-nopunct": 6.403008940748611,
        "cond_entropy-2-nopunct": 0.3147156820919425,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 79,
        "entropy-3-nopunct": 6.303780748177105,
        "cond_entropy-3-nopunct": -0.09716755082879265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.235478011211794,
        "rouge1": {
            "precision": 0.78797,
            "recall": 0.78775,
            "fmeasure": 0.77746
        },
        "rouge2": {
            "precision": 0.57803,
            "recall": 0.58889,
            "fmeasure": 0.5765
        },
        "rougeL": {
            "precision": 0.68299,
            "recall": 0.68876,
            "fmeasure": 0.67727
        },
        "rougeLsum": {
            "precision": 0.68299,
            "recall": 0.68876,
            "fmeasure": 0.67727
        },
        "bleu": 50.74908,
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.375,
            "3": 0.7848101265822784
        },
        "bertscore": {
            "precision": 0.94699,
            "recall": 0.94024,
            "f1": 0.94066
        },
        "nubia": {
            "semantic_relation": 4.32463,
            "contradiction": 0.85923,
            "irrelevancy": 33.96509,
            "logical_agreement": 65.17568,
            "grammar_ref": 4.69419,
            "grammar_hyp": 4.62769,
            "nubia_score": 0.77605
        },
        "meteor": 0.40138056897686364,
        "bleurt": 0.32369
    },
    "totto_test_contrast_challenge_table_size-table_size_440": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.75,
        "msttr-100_nopunct": 0.81,
        "total_length": 126,
        "mean_pred_length": 15.75,
        "std_pred_length": 3.418698582794336,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 91,
        "unique-1": 80,
        "entropy-1": 6.124898253529623,
        "distinct-2": 0.9661016949152542,
        "vocab_size-2": 114,
        "unique-2": 111,
        "entropy-2": 6.808449087479091,
        "cond_entropy-2": 0.5379495912356049,
        "distinct-3": 0.990909090909091,
        "vocab_size-3": 109,
        "unique-3": 108,
        "entropy-3": 6.76317789534285,
        "cond_entropy-3": -0.0398752676356955,
        "total_length-nopunct": 111,
        "mean_pred_length-nopunct": 13.875,
        "std_pred_length-nopunct": 3.295356581616017,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8018018018018018,
        "vocab_size-1-nopunct": 89,
        "unique-1-nopunct": 80,
        "entropy-1-nopunct": 6.220104100928004,
        "distinct-2-nopunct": 0.9611650485436893,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 96,
        "entropy-2-nopunct": 6.601501619395239,
        "cond_entropy-2-nopunct": 0.4260042575291409,
        "distinct-3-nopunct": 0.9894736842105263,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 93,
        "entropy-3-nopunct": 6.548802976752,
        "cond_entropy-3-nopunct": -0.045540839882128946,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.362895667624105,
        "rouge1": {
            "precision": 0.72249,
            "recall": 0.68643,
            "fmeasure": 0.69557
        },
        "rouge2": {
            "precision": 0.44689,
            "recall": 0.48912,
            "fmeasure": 0.44986
        },
        "rougeL": {
            "precision": 0.59715,
            "recall": 0.5888,
            "fmeasure": 0.58299
        },
        "rougeLsum": {
            "precision": 0.59715,
            "recall": 0.5888,
            "fmeasure": 0.58299
        },
        "bleu": 35.19872,
        "local_recall": {
            "1": 0.2682926829268293,
            "2": 0.36,
            "3": 0.855072463768116
        },
        "bertscore": {
            "precision": 0.91872,
            "recall": 0.92641,
            "f1": 0.9181
        },
        "nubia": {
            "semantic_relation": 3.8213,
            "contradiction": 4.12392,
            "irrelevancy": 35.62496,
            "logical_agreement": 60.25112,
            "grammar_ref": 4.83092,
            "grammar_hyp": 4.4077,
            "nubia_score": 0.65013
        },
        "meteor": 0.3907007503780549,
        "bleurt": 0.19895
    },
    "totto_test_contrast_challenge_table_size-table_size_410": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.71,
        "total_length": 160,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.516635916254486,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.625,
        "vocab_size-1": 100,
        "unique-1": 82,
        "entropy-1": 6.163557313865767,
        "distinct-2": 0.9133333333333333,
        "vocab_size-2": 137,
        "unique-2": 127,
        "entropy-2": 7.037119440481444,
        "cond_entropy-2": 0.7907868453504642,
        "distinct-3": 0.9928571428571429,
        "vocab_size-3": 139,
        "unique-3": 138,
        "entropy-3": 7.114997302659264,
        "cond_entropy-3": 0.09157066575025319,
        "total_length-nopunct": 143,
        "mean_pred_length-nopunct": 14.3,
        "std_pred_length-nopunct": 4.517742799230607,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6783216783216783,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 81,
        "entropy-1-nopunct": 6.199456476894091,
        "distinct-2-nopunct": 0.9172932330827067,
        "vocab_size-2-nopunct": 122,
        "unique-2-nopunct": 114,
        "entropy-2-nopunct": 6.86915546180072,
        "cond_entropy-2-nopunct": 0.7419106285069523,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 123,
        "entropy-3-nopunct": 6.942514505339227,
        "cond_entropy-3-nopunct": 0.08849131782311878,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.813043126317905,
        "rouge1": {
            "precision": 0.87933,
            "recall": 0.8665,
            "fmeasure": 0.86962
        },
        "rouge2": {
            "precision": 0.74543,
            "recall": 0.73429,
            "fmeasure": 0.73671
        },
        "rougeL": {
            "precision": 0.7796,
            "recall": 0.79004,
            "fmeasure": 0.78233
        },
        "rougeLsum": {
            "precision": 0.7796,
            "recall": 0.79004,
            "fmeasure": 0.78233
        },
        "bleu": 72.27677,
        "local_recall": {
            "1": 0.4166666666666667,
            "2": 0.6153846153846154,
            "3": 0.926605504587156
        },
        "bertscore": {
            "precision": 0.97325,
            "recall": 0.97062,
            "f1": 0.9707
        },
        "nubia": {
            "semantic_relation": 4.59276,
            "contradiction": 9.13597,
            "irrelevancy": 17.18612,
            "logical_agreement": 73.67791,
            "grammar_ref": 4.86973,
            "grammar_hyp": 4.9558,
            "nubia_score": 0.8435
        },
        "meteor": 0.5116620524619468,
        "bleurt": 0.58988
    },
    "totto_test_contrast_challenge_table_size-table_size_351": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 10,
        "unique-1": 8,
        "entropy-1": 3.180832987205441,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.44743007442701976,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.0220552088742,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.48854979993100167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.210473320391313,
        "rouge1": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77249
        },
        "rougeL": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "rougeLsum": {
            "precision": 0.69444,
            "recall": 0.93939,
            "fmeasure": 0.7942
        },
        "bleu": 34.38931,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.95642,
            "recall": 0.96183,
            "f1": 0.95427
        },
        "nubia": {
            "semantic_relation": 4.97174,
            "contradiction": 0.18493,
            "irrelevancy": 28.82608,
            "logical_agreement": 70.98899,
            "grammar_ref": 3.38649,
            "grammar_hyp": 2.7485,
            "nubia_score": 0.90007
        },
        "meteor": 0.5228493300640051,
        "bleurt": 0.72139
    },
    "totto_test_contrast_challenge_table_size-table_size_324": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.765,
        "msttr-100_nopunct": 0.82,
        "total_length": 207,
        "mean_pred_length": 18.818181818181817,
        "std_pred_length": 5.540235994615488,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.6763285024154589,
        "vocab_size-1": 140,
        "unique-1": 119,
        "entropy-1": 6.668337287157407,
        "distinct-2": 0.9897959183673469,
        "vocab_size-2": 194,
        "unique-2": 193,
        "entropy-2": 7.5904502140021135,
        "cond_entropy-2": 0.8340890562364339,
        "distinct-3": 1.0,
        "vocab_size-3": 185,
        "unique-3": 185,
        "entropy-3": 7.5313814605163,
        "cond_entropy-3": -0.057626288992607064,
        "total_length-nopunct": 182,
        "mean_pred_length-nopunct": 16.545454545454547,
        "std_pred_length-nopunct": 5.662695091780886,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7472527472527473,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.756931416357291,
        "distinct-2-nopunct": 0.9883040935672515,
        "vocab_size-2-nopunct": 169,
        "unique-2-nopunct": 168,
        "entropy-2-nopunct": 7.390046155224114,
        "cond_entropy-2-nopunct": 0.6814158819209705,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 160,
        "unique-3-nopunct": 160,
        "entropy-3-nopunct": 7.321928094887368,
        "cond_entropy-3-nopunct": -0.06620637311001389,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.328670541249321,
        "rouge1": {
            "precision": 0.69953,
            "recall": 0.6946,
            "fmeasure": 0.69055
        },
        "rouge2": {
            "precision": 0.46639,
            "recall": 0.44633,
            "fmeasure": 0.45155
        },
        "rougeL": {
            "precision": 0.65249,
            "recall": 0.63642,
            "fmeasure": 0.6376
        },
        "rougeLsum": {
            "precision": 0.65249,
            "recall": 0.63642,
            "fmeasure": 0.6376
        },
        "bleu": 39.8672,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.4,
            "3": 0.7446808510638298
        },
        "bertscore": {
            "precision": 0.90866,
            "recall": 0.92073,
            "f1": 0.91326
        },
        "nubia": {
            "semantic_relation": 4.02377,
            "contradiction": 9.73273,
            "irrelevancy": 42.40442,
            "logical_agreement": 47.86285,
            "grammar_ref": 4.70918,
            "grammar_hyp": 4.64941,
            "nubia_score": 0.69667
        },
        "meteor": 0.3721745551933878,
        "bleurt": 0.14278
    },
    "totto_test_contrast_challenge_table_size-table_size_286": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 45,
        "mean_pred_length": 11.25,
        "std_pred_length": 3.6996621467371855,
        "median_pred_length": 10.0,
        "min_pred_length": 8,
        "max_pred_length": 17,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 30,
        "unique-1": 22,
        "entropy-1": 4.696865596089289,
        "distinct-2": 0.8780487804878049,
        "vocab_size-2": 36,
        "unique-2": 33,
        "entropy-2": 5.076825785000351,
        "cond_entropy-2": 0.26239799381256507,
        "distinct-3": 0.918918918918919,
        "vocab_size-3": 34,
        "unique-3": 32,
        "entropy-3": 5.026888838543454,
        "cond_entropy-3": -0.14809863898913403,
        "total_length-nopunct": 38,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 2.8722813232690143,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7368421052631579,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.6421498816369064,
        "distinct-2-nopunct": 0.9117647058823529,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.8887896794220005,
        "cond_entropy-2-nopunct": 0.17805812205166366,
        "distinct-3-nopunct": 0.9666666666666667,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.840223928941852,
        "cond_entropy-3-nopunct": -0.18057224564182076,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9949742611914094,
        "rouge1": {
            "precision": 0.85559,
            "recall": 0.73661,
            "fmeasure": 0.77865
        },
        "rouge2": {
            "precision": 0.68992,
            "recall": 0.60135,
            "fmeasure": 0.63077
        },
        "rougeL": {
            "precision": 0.85559,
            "recall": 0.73661,
            "fmeasure": 0.77865
        },
        "rougeLsum": {
            "precision": 0.85559,
            "recall": 0.73661,
            "fmeasure": 0.77865
        },
        "bleu": 51.63051,
        "local_recall": {
            "1": 0.3,
            "2": 0.42857142857142855,
            "3": 0.7419354838709677
        },
        "bertscore": {
            "precision": 0.96146,
            "recall": 0.94542,
            "f1": 0.95029
        },
        "nubia": {
            "semantic_relation": 4.37144,
            "contradiction": 0.64794,
            "irrelevancy": 35.52623,
            "logical_agreement": 63.82583,
            "grammar_ref": 4.09757,
            "grammar_hyp": 4.02887,
            "nubia_score": 0.87096
        },
        "meteor": 0.40865338144348634,
        "bleurt": 0.41273
    },
    "totto_test_contrast_challenge_table_size-table_size_297": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 27,
        "unique-2": 27,
        "entropy-2": 4.754887502163471,
        "cond_entropy-2": 0.045054655184044716,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.11103131238874399,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.05628729973432271,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7251638701599377,
        "rouge1": {
            "precision": 0.54396,
            "recall": 0.75,
            "fmeasure": 0.61943
        },
        "rouge2": {
            "precision": 0.42628,
            "recall": 0.55455,
            "fmeasure": 0.47549
        },
        "rougeL": {
            "precision": 0.54396,
            "recall": 0.75,
            "fmeasure": 0.61943
        },
        "rougeLsum": {
            "precision": 0.54396,
            "recall": 0.75,
            "fmeasure": 0.61943
        },
        "bleu": 41.85324,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8666666666666667
        },
        "bertscore": {
            "precision": 0.86645,
            "recall": 0.94111,
            "f1": 0.90197
        },
        "nubia": {
            "semantic_relation": 3.40302,
            "contradiction": 43.16297,
            "irrelevancy": 21.73428,
            "logical_agreement": 35.10275,
            "grammar_ref": 3.61093,
            "grammar_hyp": 2.98433,
            "nubia_score": 0.5798
        },
        "meteor": 0.46032079876326165,
        "bleurt": 0.21941
    },
    "totto_test_contrast_challenge_table_size-table_size_413": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.595356984321449,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.88889,
            "fmeasure": 0.85948
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.67857,
            "fmeasure": 0.65
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.77778,
            "fmeasure": 0.74837
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.77778,
            "fmeasure": 0.74837
        },
        "bleu": 70.71068,
        "local_recall": {
            "1": 0.4,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.9515,
            "recall": 0.96789,
            "f1": 0.95963
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.39519,
            "irrelevancy": 0.46452,
            "logical_agreement": 99.14029,
            "grammar_ref": 6.12307,
            "grammar_hyp": 5.88408,
            "nubia_score": 0.9931
        },
        "meteor": 0.552269634529355,
        "bleurt": 0.69686
    },
    "totto_test_contrast_challenge_table_size-table_size_441": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.7837837837837838,
        "vocab_size-1": 29,
        "unique-1": 23,
        "entropy-1": 4.736216203349846,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 32,
        "unique-2": 30,
        "entropy-2": 4.969815782426808,
        "cond_entropy-2": 0.1355061668614918,
        "distinct-3": 0.967741935483871,
        "vocab_size-3": 30,
        "unique-3": 29,
        "entropy-3": 4.889680181354619,
        "cond_entropy-3": -0.06875040183120604,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.601409765557392,
        "distinct-2-nopunct": 0.9310344827586207,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.720049960644813,
        "cond_entropy-2-nopunct": 0.15987366761596758,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.623516641218013,
        "cond_entropy-3-nopunct": -0.0806182000634031,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3830099957502755,
        "rouge1": {
            "precision": 0.6375,
            "recall": 0.56461,
            "fmeasure": 0.58892
        },
        "rouge2": {
            "precision": 0.40377,
            "recall": 0.36061,
            "fmeasure": 0.37294
        },
        "rougeL": {
            "precision": 0.6277,
            "recall": 0.55736,
            "fmeasure": 0.58059
        },
        "rougeLsum": {
            "precision": 0.6277,
            "recall": 0.55736,
            "fmeasure": 0.58059
        },
        "bleu": 31.82729,
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.75
        },
        "bertscore": {
            "precision": 0.9007,
            "recall": 0.90227,
            "f1": 0.89981
        },
        "nubia": {
            "semantic_relation": 3.50341,
            "contradiction": 22.45422,
            "irrelevancy": 53.34621,
            "logical_agreement": 24.19957,
            "grammar_ref": 5.06451,
            "grammar_hyp": 5.17197,
            "nubia_score": 0.56263
        },
        "meteor": 0.2795836237494144,
        "bleurt": -0.1478
    },
    "totto_test_contrast_challenge_table_size-table_size_299": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.517587944313568,
        "rouge1": {
            "precision": 0.69231,
            "recall": 0.87273,
            "fmeasure": 0.77174
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.75185,
            "fmeasure": 0.65657
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.87273,
            "fmeasure": 0.77174
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.87273,
            "fmeasure": 0.77174
        },
        "bleu": 46.9247,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.92559,
            "recall": 0.96282,
            "f1": 0.94383
        },
        "nubia": {
            "semantic_relation": 3.58916,
            "contradiction": 0.14804,
            "irrelevancy": 99.7574,
            "logical_agreement": 0.09456,
            "grammar_ref": 3.16175,
            "grammar_hyp": 2.96808,
            "nubia_score": 0.75461
        },
        "meteor": 0.4779454967983016,
        "bleurt": 0.1806
    },
    "totto_test_contrast_challenge_table_size-table_size_475": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.6,
        "msttr-100_nopunct": NaN,
        "total_length": 101,
        "mean_pred_length": 14.428571428571429,
        "std_pred_length": 4.337778985911136,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 23,
        "distinct-1": 0.594059405940594,
        "vocab_size-1": 60,
        "unique-1": 40,
        "entropy-1": 5.545947161686069,
        "distinct-2": 0.8617021276595744,
        "vocab_size-2": 81,
        "unique-2": 69,
        "entropy-2": 6.2699623888886515,
        "cond_entropy-2": 0.6205692191508102,
        "distinct-3": 0.9425287356321839,
        "vocab_size-3": 82,
        "unique-3": 77,
        "entropy-3": 6.328000967113091,
        "cond_entropy-3": 0.05795105224193544,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 12.714285714285714,
        "std_pred_length-nopunct": 4.43087497693452,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6404494382022472,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.500127572277522,
        "distinct-2-nopunct": 0.8658536585365854,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 6.0800533765429225,
        "cond_entropy-2-nopunct": 0.5900384995193322,
        "distinct-3-nopunct": 0.96,
        "vocab_size-3-nopunct": 72,
        "unique-3-nopunct": 69,
        "entropy-3-nopunct": 6.148818690495891,
        "cond_entropy-3-nopunct": 0.0413318525733102,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.754210954057285,
        "rouge1": {
            "precision": 0.61732,
            "recall": 0.69598,
            "fmeasure": 0.64795
        },
        "rouge2": {
            "precision": 0.29372,
            "recall": 0.34161,
            "fmeasure": 0.31218
        },
        "rougeL": {
            "precision": 0.48341,
            "recall": 0.55746,
            "fmeasure": 0.51333
        },
        "rougeLsum": {
            "precision": 0.48341,
            "recall": 0.55746,
            "fmeasure": 0.51333
        },
        "bleu": 32.08227,
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.6666666666666666,
            "3": 0.717391304347826
        },
        "bertscore": {
            "precision": 0.91054,
            "recall": 0.91203,
            "f1": 0.91105
        },
        "nubia": {
            "semantic_relation": 3.94311,
            "contradiction": 23.49224,
            "irrelevancy": 33.54611,
            "logical_agreement": 42.96166,
            "grammar_ref": 5.09695,
            "grammar_hyp": 4.36706,
            "nubia_score": 0.72477
        },
        "meteor": 0.35619241515227085,
        "bleurt": 0.19504
    },
    "totto_test_contrast_challenge_table_size-table_size_352": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 9.0,
        "median_pred_length": 17.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.8529411764705882,
        "vocab_size-1": 29,
        "unique-1": 24,
        "entropy-1": 4.793345194191515,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.1625371587496606,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.664497779200462,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.04693094992964165,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1774260793319136,
        "rouge1": {
            "precision": 0.75541,
            "recall": 0.51916,
            "fmeasure": 0.61169
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.38043,
            "fmeasure": 0.44026
        },
        "rougeL": {
            "precision": 0.61255,
            "recall": 0.43979,
            "fmeasure": 0.50976
        },
        "rougeLsum": {
            "precision": 0.61255,
            "recall": 0.43979,
            "fmeasure": 0.50976
        },
        "bleu": 51.03071,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6176470588235294
        },
        "bertscore": {
            "precision": 0.92825,
            "recall": 0.8892,
            "f1": 0.90702
        },
        "nubia": {
            "semantic_relation": 3.38979,
            "contradiction": 0.66428,
            "irrelevancy": 35.85235,
            "logical_agreement": 63.48338,
            "grammar_ref": 4.82994,
            "grammar_hyp": 4.72499,
            "nubia_score": 0.48669
        },
        "meteor": 0.3846796506495888,
        "bleurt": 0.10679
    },
    "totto_test_contrast_challenge_table_size-table_size_414": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 22,
        "unique-1": 18,
        "entropy-1": 4.3565583354166755,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.23916418769779482,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.220175521464346,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.2724185498326622,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9482934378115195,
        "rouge1": {
            "precision": 0.77165,
            "recall": 0.71192,
            "fmeasure": 0.72151
        },
        "rouge2": {
            "precision": 0.37821,
            "recall": 0.42123,
            "fmeasure": 0.39414
        },
        "rougeL": {
            "precision": 0.69913,
            "recall": 0.71311,
            "fmeasure": 0.69376
        },
        "rougeLsum": {
            "precision": 0.69913,
            "recall": 0.71311,
            "fmeasure": 0.69376
        },
        "bleu": 34.37643,
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.7222222222222222
        },
        "bertscore": {
            "precision": 0.9189,
            "recall": 0.9211,
            "f1": 0.91136
        },
        "nubia": {
            "semantic_relation": 3.98295,
            "contradiction": 0.29357,
            "irrelevancy": 47.10823,
            "logical_agreement": 52.5982,
            "grammar_ref": 4.46073,
            "grammar_hyp": 4.29096,
            "nubia_score": 0.6942
        },
        "meteor": 0.3834199117104838,
        "bleurt": 0.12777
    },
    "totto_test_contrast_challenge_table_size-table_size_354": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1221860348123966,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "rougeLsum": {
            "precision": 0.8,
            "recall": 0.8,
            "fmeasure": 0.8
        },
        "bleu": 58.59059,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.97545,
            "recall": 0.97545,
            "f1": 0.97545
        },
        "nubia": {
            "semantic_relation": 4.90953,
            "contradiction": 0.355,
            "irrelevancy": 0.51033,
            "logical_agreement": 99.13468,
            "grammar_ref": 5.11392,
            "grammar_hyp": 4.76303,
            "nubia_score": 1.0
        },
        "meteor": 0.4076949933266327,
        "bleurt": 0.76706
    },
    "totto_test_contrast_challenge_table_size-table_size_392": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 13,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.73,
        "total_length": 198,
        "mean_pred_length": 15.23076923076923,
        "std_pred_length": 4.060197913968199,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 25,
        "distinct-1": 0.6212121212121212,
        "vocab_size-1": 123,
        "unique-1": 95,
        "entropy-1": 6.45938393645602,
        "distinct-2": 0.8810810810810811,
        "vocab_size-2": 163,
        "unique-2": 142,
        "entropy-2": 7.2894631496937965,
        "cond_entropy-2": 0.6797554017699561,
        "distinct-3": 0.9244186046511628,
        "vocab_size-3": 159,
        "unique-3": 146,
        "entropy-3": 7.275101964004393,
        "cond_entropy-3": -0.007704569173728791,
        "total_length-nopunct": 178,
        "mean_pred_length-nopunct": 13.692307692307692,
        "std_pred_length-nopunct": 3.810604946615642,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6685393258426966,
        "vocab_size-1-nopunct": 119,
        "unique-1-nopunct": 93,
        "entropy-1-nopunct": 6.503119575098472,
        "distinct-2-nopunct": 0.8848484848484849,
        "vocab_size-2-nopunct": 146,
        "unique-2-nopunct": 128,
        "entropy-2-nopunct": 7.131444108172091,
        "cond_entropy-2-nopunct": 0.6807122914147193,
        "distinct-3-nopunct": 0.9342105263157895,
        "vocab_size-3-nopunct": 142,
        "unique-3-nopunct": 132,
        "entropy-3-nopunct": 7.116348566075149,
        "cond_entropy-3-nopunct": -0.014744125130102158,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.796052145829997,
        "rouge1": {
            "precision": 0.77058,
            "recall": 0.74098,
            "fmeasure": 0.74964
        },
        "rouge2": {
            "precision": 0.55578,
            "recall": 0.53884,
            "fmeasure": 0.5428
        },
        "rougeL": {
            "precision": 0.65968,
            "recall": 0.63699,
            "fmeasure": 0.64301
        },
        "rougeLsum": {
            "precision": 0.65968,
            "recall": 0.63699,
            "fmeasure": 0.64301
        },
        "bleu": 48.66872,
        "local_recall": {
            "1": 0.14705882352941177,
            "2": 0.5686274509803921,
            "3": 0.8211382113821138
        },
        "bertscore": {
            "precision": 0.92411,
            "recall": 0.91864,
            "f1": 0.9201
        },
        "nubia": {
            "semantic_relation": 4.35949,
            "contradiction": 1.8707,
            "irrelevancy": 41.08687,
            "logical_agreement": 57.04242,
            "grammar_ref": 4.86507,
            "grammar_hyp": 4.91096,
            "nubia_score": 0.76969
        },
        "meteor": 0.39777684683851844,
        "bleurt": 0.16083
    },
    "totto_test_contrast_challenge_table_size-table_size_416": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 3.7712361663282534,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.6818181818181818,
        "vocab_size-1": 30,
        "unique-1": 23,
        "entropy-1": 4.615808539574484,
        "distinct-2": 0.9512195121951219,
        "vocab_size-2": 39,
        "unique-2": 37,
        "entropy-2": 5.259991029008325,
        "cond_entropy-2": 0.6571305196091708,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.004361333279761104,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 4.4969125210773475,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6829268292682927,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.500980895379943,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.142664355548852,
        "cond_entropy-2-nopunct": 0.6829917056350742,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.004358782212904644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.023884610043862,
        "rouge1": {
            "precision": 0.88364,
            "recall": 0.80549,
            "fmeasure": 0.84111
        },
        "rouge2": {
            "precision": 0.67407,
            "recall": 0.60365,
            "fmeasure": 0.63556
        },
        "rougeL": {
            "precision": 0.75189,
            "recall": 0.69881,
            "fmeasure": 0.7237
        },
        "rougeLsum": {
            "precision": 0.75189,
            "recall": 0.69881,
            "fmeasure": 0.7237
        },
        "bleu": 27.39841,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "bertscore": {
            "precision": 0.95096,
            "recall": 0.94489,
            "f1": 0.94761
        },
        "nubia": {
            "semantic_relation": 4.63286,
            "contradiction": 0.23371,
            "irrelevancy": 1.03804,
            "logical_agreement": 98.72825,
            "grammar_ref": 4.67072,
            "grammar_hyp": 4.23666,
            "nubia_score": 0.92273
        },
        "meteor": 0.39845777066392196,
        "bleurt": 0.48503
    },
    "totto_test_contrast_challenge_table_size-table_size_355": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 70,
        "mean_pred_length": 17.5,
        "std_pred_length": 4.5,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7428571428571429,
        "vocab_size-1": 52,
        "unique-1": 39,
        "entropy-1": 5.554073552566534,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 62,
        "unique-2": 58,
        "entropy-2": 5.923181998146339,
        "cond_entropy-2": 0.3319258752063191,
        "distinct-3": 0.9838709677419355,
        "vocab_size-3": 61,
        "unique-3": 60,
        "entropy-3": 5.921938245870743,
        "cond_entropy-3": 0.0065763845768089324,
        "total_length-nopunct": 63,
        "mean_pred_length-nopunct": 15.75,
        "std_pred_length-nopunct": 4.322904116447646,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.7936507936507936,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.540616828193142,
        "distinct-2-nopunct": 0.9322033898305084,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.7470498290228536,
        "cond_entropy-2-nopunct": 0.21908812593526258,
        "distinct-3-nopunct": 0.9818181818181818,
        "vocab_size-3-nopunct": 54,
        "unique-3-nopunct": 53,
        "entropy-3-nopunct": 5.744996077161019,
        "cond_entropy-3-nopunct": 0.007807573253727382,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.920182282566281,
        "rouge1": {
            "precision": 0.87765,
            "recall": 0.86089,
            "fmeasure": 0.86883
        },
        "rouge2": {
            "precision": 0.73611,
            "recall": 0.73687,
            "fmeasure": 0.73333
        },
        "rougeL": {
            "precision": 0.75283,
            "recall": 0.78097,
            "fmeasure": 0.7598
        },
        "rougeLsum": {
            "precision": 0.75283,
            "recall": 0.78097,
            "fmeasure": 0.7598
        },
        "bleu": 70.74305,
        "local_recall": {
            "1": 0.4,
            "2": 0.8333333333333334,
            "3": 0.9148936170212766
        },
        "bertscore": {
            "precision": 0.96775,
            "recall": 0.96255,
            "f1": 0.96513
        },
        "nubia": {
            "semantic_relation": 4.5909,
            "contradiction": 6.92799,
            "irrelevancy": 19.61222,
            "logical_agreement": 73.45979,
            "grammar_ref": 4.25492,
            "grammar_hyp": 4.45524,
            "nubia_score": 0.81356
        },
        "meteor": 0.5086302734496098,
        "bleurt": 0.48994
    },
    "totto_test_contrast_challenge_table_size-table_size_395": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.20271956237473,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.96296,
            "fmeasure": 0.96296
        },
        "bleu": 91.46912,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.9928,
            "recall": 0.9928,
            "f1": 0.9928
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.61375,
            "irrelevancy": 0.83168,
            "logical_agreement": 98.55457,
            "grammar_ref": 4.07798,
            "grammar_hyp": 4.55122,
            "nubia_score": 0.97788
        },
        "meteor": 0.5118198837985161,
        "bleurt": 0.8833
    },
    "totto_test_contrast_challenge_table_size-table_size_442": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0430243061565188,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.36508,
            "fmeasure": 0.41711
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.20192,
            "fmeasure": 0.23333
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.27381,
            "fmeasure": 0.31283
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.27381,
            "fmeasure": 0.31283
        },
        "bleu": 16.14683,
        "local_recall": {
            "1": 0.0,
            "2": 0.5
        },
        "bertscore": {
            "precision": 0.91067,
            "recall": 0.90289,
            "f1": 0.90676
        },
        "nubia": {
            "semantic_relation": 3.25672,
            "contradiction": 0.91211,
            "irrelevancy": 19.65821,
            "logical_agreement": 79.42967,
            "grammar_ref": 5.77141,
            "grammar_hyp": 5.77885,
            "nubia_score": 0.40752
        },
        "meteor": 0.20916966889821303,
        "bleurt": -0.03041
    },
    "totto_test_contrast_challenge_table_size-table_size_325": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 11.6,
        "std_pred_length": 4.223742416388576,
        "median_pred_length": 12.0,
        "min_pred_length": 7,
        "max_pred_length": 18,
        "distinct-1": 0.8275862068965517,
        "vocab_size-1": 48,
        "unique-1": 42,
        "entropy-1": 5.437902926565497,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.11059771419342831,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.1429579538420431,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 9.8,
        "std_pred_length-nopunct": 3.370459909270543,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8979591836734694,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.3952223440710565,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.08915103593489505,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.1740293997750488,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.922313462586985,
        "rouge1": {
            "precision": 0.82496,
            "recall": 0.76775,
            "fmeasure": 0.79255
        },
        "rouge2": {
            "precision": 0.62872,
            "recall": 0.58405,
            "fmeasure": 0.60328
        },
        "rougeL": {
            "precision": 0.79163,
            "recall": 0.74553,
            "fmeasure": 0.76589
        },
        "rougeLsum": {
            "precision": 0.79163,
            "recall": 0.74553,
            "fmeasure": 0.76589
        },
        "bleu": 58.75731,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.625,
            "3": 0.8421052631578947
        },
        "bertscore": {
            "precision": 0.94782,
            "recall": 0.94152,
            "f1": 0.94411
        },
        "nubia": {
            "semantic_relation": 4.22561,
            "contradiction": 11.31551,
            "irrelevancy": 32.03846,
            "logical_agreement": 56.64603,
            "grammar_ref": 5.12632,
            "grammar_hyp": 5.08063,
            "nubia_score": 0.73319
        },
        "meteor": 0.46406290491444513,
        "bleurt": 0.39941
    },
    "totto_test_contrast_challenge_table_size-table_size_357": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.63,
        "msttr-100_nopunct": NaN,
        "total_length": 109,
        "mean_pred_length": 13.625,
        "std_pred_length": 2.341874249399399,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.6146788990825688,
        "vocab_size-1": 67,
        "unique-1": 51,
        "entropy-1": 5.702926215249813,
        "distinct-2": 0.8415841584158416,
        "vocab_size-2": 85,
        "unique-2": 76,
        "entropy-2": 6.289060863789957,
        "cond_entropy-2": 0.43288776612645646,
        "distinct-3": 0.8709677419354839,
        "vocab_size-3": 81,
        "unique-3": 75,
        "entropy-3": 6.232391875484585,
        "cond_entropy-3": -0.024914096351683186,
        "total_length-nopunct": 93,
        "mean_pred_length-nopunct": 11.625,
        "std_pred_length-nopunct": 1.9324531042175384,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 62,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.642833580610279,
        "distinct-2-nopunct": 0.8352941176470589,
        "vocab_size-2-nopunct": 71,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 6.02669299480852,
        "cond_entropy-2-nopunct": 0.4682194358921464,
        "distinct-3-nopunct": 0.8701298701298701,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 62,
        "entropy-3-nopunct": 5.95802761198299,
        "cond_entropy-3-nopunct": -0.028904557752365796,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.2243413864095265,
        "rouge1": {
            "precision": 0.88341,
            "recall": 0.83272,
            "fmeasure": 0.84839
        },
        "rouge2": {
            "precision": 0.77431,
            "recall": 0.74295,
            "fmeasure": 0.75219
        },
        "rougeL": {
            "precision": 0.85216,
            "recall": 0.80942,
            "fmeasure": 0.82167
        },
        "rougeLsum": {
            "precision": 0.85216,
            "recall": 0.80942,
            "fmeasure": 0.82167
        },
        "bleu": 58.68624,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.375,
            "3": 0.776595744680851
        },
        "bertscore": {
            "precision": 0.97237,
            "recall": 0.95686,
            "f1": 0.96419
        },
        "nubia": {
            "semantic_relation": 4.72966,
            "contradiction": 0.18026,
            "irrelevancy": 4.8134,
            "logical_agreement": 95.00634,
            "grammar_ref": 4.5568,
            "grammar_hyp": 4.48433,
            "nubia_score": 0.91792
        },
        "meteor": 0.4593585714052539,
        "bleurt": 0.71639
    },
    "totto_test_contrast_challenge_table_size-table_size_476": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 4.5,
        "median_pred_length": 16.5,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 30,
        "unique-1": 27,
        "entropy-1": 4.8625759375402735,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.03883444909293795,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9655172413793104,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.789015477886192,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": -0.029019418890029344,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.982855333410896,
        "rouge1": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "rougeLsum": {
            "precision": 0.97059,
            "recall": 0.97059,
            "fmeasure": 0.97059
        },
        "bleu": 91.53254,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9629629629629629
        },
        "bertscore": {
            "precision": 0.99594,
            "recall": 0.99594,
            "f1": 0.99594
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31768,
            "irrelevancy": 0.57052,
            "logical_agreement": 99.11181,
            "grammar_ref": 5.04945,
            "grammar_hyp": 4.81437,
            "nubia_score": 1.0
        },
        "meteor": 0.6276979374374717,
        "bleurt": 0.87023
    },
    "totto_test_contrast_challenge_table_size-table_size_445": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 3.0,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 15,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 22,
        "unique-1": 20,
        "entropy-1": 4.41829583405449,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": -0.03462179117476817,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.03912675144043812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4393043493516706,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.70244,
            "fmeasure": 0.78144
        },
        "rouge2": {
            "precision": 0.80357,
            "recall": 0.60027,
            "fmeasure": 0.67024
        },
        "rougeL": {
            "precision": 0.79808,
            "recall": 0.6326,
            "fmeasure": 0.69185
        },
        "rougeLsum": {
            "precision": 0.79808,
            "recall": 0.6326,
            "fmeasure": 0.69185
        },
        "bleu": 56.08087,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.9814,
            "recall": 0.93225,
            "f1": 0.95555
        },
        "nubia": {
            "semantic_relation": 4.36892,
            "contradiction": 0.38357,
            "irrelevancy": 0.5779,
            "logical_agreement": 99.03854,
            "grammar_ref": 5.26806,
            "grammar_hyp": 5.12533,
            "nubia_score": 0.76865
        },
        "meteor": 0.4071117545172738,
        "bleurt": 0.47935
    },
    "totto_test_contrast_challenge_table_size-table_size_477": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 5.5,
        "median_pred_length": 19.5,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.7948717948717948,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.782590924645919,
        "distinct-2": 0.9459459459459459,
        "vocab_size-2": 35,
        "unique-2": 33,
        "entropy-2": 5.101345257520845,
        "cond_entropy-2": 0.29187926769742584,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": 0.034115365601730965,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.6261504319610545,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.923181998146335,
        "cond_entropy-2-nopunct": 0.3275244501236931,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": 0.03883444909293794,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.072299446348946,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.90909,
            "fmeasure": 0.875
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.79091,
            "fmeasure": 0.76877
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.90909,
            "fmeasure": 0.875
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.90909,
            "fmeasure": 0.875
        },
        "bleu": 81.76593,
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9615384615384616
        },
        "bertscore": {
            "precision": 0.97053,
            "recall": 0.97817,
            "f1": 0.97432
        },
        "nubia": {
            "semantic_relation": 4.99278,
            "contradiction": 0.24497,
            "irrelevancy": 1.4493,
            "logical_agreement": 98.30572,
            "grammar_ref": 3.8433,
            "grammar_hyp": 3.55213,
            "nubia_score": 0.99714
        },
        "meteor": 0.5973499335340159,
        "bleurt": 0.77759
    },
    "totto_test_contrast_challenge_table_size-table_size_396": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.66,
        "msttr-100_nopunct": NaN,
        "total_length": 120,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.449489742783178,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.625,
        "vocab_size-1": 75,
        "unique-1": 54,
        "entropy-1": 5.871025907910207,
        "distinct-2": 0.8660714285714286,
        "vocab_size-2": 97,
        "unique-2": 82,
        "entropy-2": 6.53949777920045,
        "cond_entropy-2": 0.528176491840141,
        "distinct-3": 0.8942307692307693,
        "vocab_size-3": 93,
        "unique-3": 82,
        "entropy-3": 6.488901256602638,
        "cond_entropy-3": -0.04922289622420451,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 12.375,
        "std_pred_length-nopunct": 3.1598061649411346,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7070707070707071,
        "vocab_size-1-nopunct": 70,
        "unique-1-nopunct": 52,
        "entropy-1-nopunct": 5.92456432199055,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 78,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.222080354484413,
        "cond_entropy-2-nopunct": 0.3265087619962006,
        "distinct-3-nopunct": 0.8795180722891566,
        "vocab_size-3-nopunct": 73,
        "unique-3-nopunct": 63,
        "entropy-3-nopunct": 6.134075575925245,
        "cond_entropy-3-nopunct": -0.08456243776743387,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.105253798602162,
        "rouge1": {
            "precision": 0.68225,
            "recall": 0.71326,
            "fmeasure": 0.69039
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.55233,
            "fmeasure": 0.50465
        },
        "rougeL": {
            "precision": 0.59997,
            "recall": 0.64716,
            "fmeasure": 0.61649
        },
        "rougeLsum": {
            "precision": 0.59997,
            "recall": 0.64716,
            "fmeasure": 0.61649
        },
        "bleu": 48.77681,
        "local_recall": {
            "1": 0.3170731707317073,
            "2": 0.5238095238095238,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.9265,
            "recall": 0.9257,
            "f1": 0.92509
        },
        "nubia": {
            "semantic_relation": 3.73141,
            "contradiction": 29.86934,
            "irrelevancy": 39.52998,
            "logical_agreement": 30.60068,
            "grammar_ref": 5.12618,
            "grammar_hyp": 4.68981,
            "nubia_score": 0.61248
        },
        "meteor": 0.3946138392018218,
        "bleurt": 0.15645
    },
    "totto_test_contrast_challenge_table_size-table_size_360": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.795,
        "total_length": 306,
        "mean_pred_length": 15.3,
        "std_pred_length": 4.796873982084582,
        "median_pred_length": 13.5,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.6045751633986928,
        "vocab_size-1": 185,
        "unique-1": 147,
        "entropy-1": 6.92498629065724,
        "distinct-2": 0.9265734265734266,
        "vocab_size-2": 265,
        "unique-2": 247,
        "entropy-2": 8.003385716141501,
        "cond_entropy-2": 0.8797770478895233,
        "distinct-3": 0.9887218045112782,
        "vocab_size-3": 263,
        "unique-3": 260,
        "entropy-3": 8.032726044523798,
        "cond_entropy-3": 0.03358736752792599,
        "total_length-nopunct": 270,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 4.272001872658765,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6703703703703704,
        "vocab_size-1-nopunct": 181,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 7.0641398146824,
        "distinct-2-nopunct": 0.936,
        "vocab_size-2-nopunct": 234,
        "unique-2-nopunct": 221,
        "entropy-2-nopunct": 7.8267647346534455,
        "cond_entropy-2-nopunct": 0.8132991325576353,
        "distinct-3-nopunct": 0.9956521739130435,
        "vocab_size-3-nopunct": 229,
        "unique-3-nopunct": 228,
        "entropy-3-nopunct": 7.83679439877045,
        "cond_entropy-3-nopunct": 0.013422668465607607,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.39474604570617,
        "rouge1": {
            "precision": 0.82903,
            "recall": 0.79843,
            "fmeasure": 0.80546
        },
        "rouge2": {
            "precision": 0.65789,
            "recall": 0.64943,
            "fmeasure": 0.64625
        },
        "rougeL": {
            "precision": 0.74351,
            "recall": 0.71143,
            "fmeasure": 0.71981
        },
        "rougeLsum": {
            "precision": 0.74351,
            "recall": 0.71143,
            "fmeasure": 0.71981
        },
        "bleu": 56.72558,
        "local_recall": {
            "1": 0.20270270270270271,
            "2": 0.5846153846153846,
            "3": 0.8105263157894737
        },
        "bertscore": {
            "precision": 0.9496,
            "recall": 0.93905,
            "f1": 0.94263
        },
        "nubia": {
            "semantic_relation": 4.25646,
            "contradiction": 10.36087,
            "irrelevancy": 20.8249,
            "logical_agreement": 68.81422,
            "grammar_ref": 4.44035,
            "grammar_hyp": 4.43136,
            "nubia_score": 0.76083
        },
        "meteor": 0.44065757570377656,
        "bleurt": 0.38885
    },
    "totto_test_contrast_challenge_table_size-table_size_328": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 98,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 5.497474167490214,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.7040816326530612,
        "vocab_size-1": 69,
        "unique-1": 58,
        "entropy-1": 5.791799610297926,
        "distinct-2": 0.967391304347826,
        "vocab_size-2": 89,
        "unique-2": 86,
        "entropy-2": 6.458344564752678,
        "cond_entropy-2": 0.5940212688946023,
        "distinct-3": 0.9767441860465116,
        "vocab_size-3": 84,
        "unique-3": 82,
        "entropy-3": 6.379753126795122,
        "cond_entropy-3": -0.07404138740142663,
        "total_length-nopunct": 89,
        "mean_pred_length-nopunct": 14.833333333333334,
        "std_pred_length-nopunct": 5.335936864527374,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7415730337078652,
        "vocab_size-1-nopunct": 66,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.753478656387823,
        "distinct-2-nopunct": 0.963855421686747,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 77,
        "entropy-2-nopunct": 6.302750274720425,
        "cond_entropy-2-nopunct": 0.6014828068563578,
        "distinct-3-nopunct": 0.974025974025974,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 73,
        "entropy-3-nopunct": 6.214838488746852,
        "cond_entropy-3-nopunct": -0.0822788646779974,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.16509240946706,
        "rouge1": {
            "precision": 0.75128,
            "recall": 0.72434,
            "fmeasure": 0.72713
        },
        "rouge2": {
            "precision": 0.57199,
            "recall": 0.55114,
            "fmeasure": 0.553
        },
        "rougeL": {
            "precision": 0.69063,
            "recall": 0.64947,
            "fmeasure": 0.66004
        },
        "rougeLsum": {
            "precision": 0.69063,
            "recall": 0.64947,
            "fmeasure": 0.66004
        },
        "bleu": 49.92552,
        "local_recall": {
            "1": 0.25,
            "2": 0.3181818181818182,
            "3": 0.8260869565217391
        },
        "bertscore": {
            "precision": 0.93986,
            "recall": 0.92292,
            "f1": 0.93032
        },
        "nubia": {
            "semantic_relation": 4.41569,
            "contradiction": 1.80199,
            "irrelevancy": 27.85547,
            "logical_agreement": 70.34254,
            "grammar_ref": 4.71157,
            "grammar_hyp": 4.47657,
            "nubia_score": 0.82292
        },
        "meteor": 0.41793781183183193,
        "bleurt": 0.28495
    },
    "totto_test_contrast_challenge_table_size-table_size_399": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1975130101153098,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.7,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.72727,
            "fmeasure": 0.69565
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.72727,
            "fmeasure": 0.69565
        },
        "bleu": 49.47995,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.88044,
            "recall": 0.93027,
            "f1": 0.90467
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.10882,
            "irrelevancy": 95.57685,
            "logical_agreement": 4.31433,
            "grammar_ref": 4.20968,
            "grammar_hyp": 3.88261,
            "nubia_score": 1.0
        },
        "meteor": 0.4618659327219916,
        "bleurt": 0.30288
    },
    "totto_test_contrast_challenge_table_size-table_size_364": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 63,
        "mean_pred_length": 15.75,
        "std_pred_length": 5.2141634036535525,
        "median_pred_length": 14.5,
        "min_pred_length": 10,
        "max_pred_length": 24,
        "distinct-1": 0.7301587301587301,
        "vocab_size-1": 46,
        "unique-1": 37,
        "entropy-1": 5.304827098474517,
        "distinct-2": 0.9322033898305084,
        "vocab_size-2": 55,
        "unique-2": 51,
        "entropy-2": 5.7470498290228536,
        "cond_entropy-2": 0.40722143898797253,
        "distinct-3": 0.9636363636363636,
        "vocab_size-3": 53,
        "unique-3": 51,
        "entropy-3": 5.708632440797383,
        "cond_entropy-3": -0.028556063109908957,
        "total_length-nopunct": 59,
        "mean_pred_length-nopunct": 14.75,
        "std_pred_length-nopunct": 5.2141634036535525,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7457627118644068,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.245191515896807,
        "distinct-2-nopunct": 0.9272727272727272,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.635905168070111,
        "cond_entropy-2-nopunct": 0.4188919455162146,
        "distinct-3-nopunct": 0.9607843137254902,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.59399396942248,
        "cond_entropy-3-nopunct": -0.030502999004144403,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.361564923387761,
        "rouge1": {
            "precision": 0.66855,
            "recall": 0.67665,
            "fmeasure": 0.66262
        },
        "rouge2": {
            "precision": 0.41386,
            "recall": 0.42523,
            "fmeasure": 0.412
        },
        "rougeL": {
            "precision": 0.6006,
            "recall": 0.61693,
            "fmeasure": 0.6004
        },
        "rougeLsum": {
            "precision": 0.6006,
            "recall": 0.61693,
            "fmeasure": 0.6004
        },
        "bleu": 34.01107,
        "local_recall": {
            "1": 0.2,
            "2": 0.16666666666666666,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.93094,
            "recall": 0.92717,
            "f1": 0.92715
        },
        "nubia": {
            "semantic_relation": 4.12363,
            "contradiction": 11.26036,
            "irrelevancy": 44.07909,
            "logical_agreement": 44.66055,
            "grammar_ref": 4.84918,
            "grammar_hyp": 5.02153,
            "nubia_score": 0.6408
        },
        "meteor": 0.3219838495624351,
        "bleurt": 0.24372
    },
    "totto_test_contrast_challenge_table_size-table_size_400": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.71,
        "total_length": 156,
        "mean_pred_length": 15.6,
        "std_pred_length": 5.063595560468865,
        "median_pred_length": 16.5,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6474358974358975,
        "vocab_size-1": 101,
        "unique-1": 77,
        "entropy-1": 6.30573070383574,
        "distinct-2": 0.9315068493150684,
        "vocab_size-2": 136,
        "unique-2": 126,
        "entropy-2": 7.052838257510157,
        "cond_entropy-2": 0.6498247807310363,
        "distinct-3": 0.9411764705882353,
        "vocab_size-3": 128,
        "unique-3": 120,
        "entropy-3": 6.969815782426799,
        "cond_entropy-3": -0.07294995292379543,
        "total_length-nopunct": 139,
        "mean_pred_length-nopunct": 13.9,
        "std_pred_length-nopunct": 4.846648326421054,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.697841726618705,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.3334930735168005,
        "distinct-2-nopunct": 0.9224806201550387,
        "vocab_size-2-nopunct": 119,
        "unique-2-nopunct": 109,
        "entropy-2-nopunct": 6.856188495733314,
        "cond_entropy-2-nopunct": 0.5758309260310155,
        "distinct-3-nopunct": 0.9327731092436975,
        "vocab_size-3-nopunct": 111,
        "unique-3-nopunct": 103,
        "entropy-3-nopunct": 6.760363981795337,
        "cond_entropy-3-nopunct": -0.09119940808169723,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.728849980733557,
        "rouge1": {
            "precision": 0.74165,
            "recall": 0.74769,
            "fmeasure": 0.72107
        },
        "rouge2": {
            "precision": 0.54894,
            "recall": 0.52442,
            "fmeasure": 0.52536
        },
        "rougeL": {
            "precision": 0.62915,
            "recall": 0.60659,
            "fmeasure": 0.6029
        },
        "rougeLsum": {
            "precision": 0.62915,
            "recall": 0.60659,
            "fmeasure": 0.6029
        },
        "bleu": 51.93638,
        "local_recall": {
            "1": 0.30434782608695654,
            "2": 0.6666666666666666,
            "3": 0.7578947368421053
        },
        "bertscore": {
            "precision": 0.92428,
            "recall": 0.91688,
            "f1": 0.91946
        },
        "nubia": {
            "semantic_relation": 4.24115,
            "contradiction": 1.8514,
            "irrelevancy": 27.9386,
            "logical_agreement": 70.21001,
            "grammar_ref": 5.10223,
            "grammar_hyp": 5.17676,
            "nubia_score": 0.7281
        },
        "meteor": 0.40806132226793984,
        "bleurt": 0.33115
    },
    "totto_test_contrast_challenge_table_size-table_size_329": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.76,
        "total_length": 121,
        "mean_pred_length": 20.166666666666668,
        "std_pred_length": 7.289642576209679,
        "median_pred_length": 25.0,
        "min_pred_length": 8,
        "max_pred_length": 26,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 88,
        "unique-1": 71,
        "entropy-1": 6.205799808039113,
        "distinct-2": 0.9478260869565217,
        "vocab_size-2": 109,
        "unique-2": 103,
        "entropy-2": 6.74114222485743,
        "cond_entropy-2": 0.531198878324827,
        "distinct-3": 0.9724770642201835,
        "vocab_size-3": 106,
        "unique-3": 103,
        "entropy-3": 6.713138453217283,
        "cond_entropy-3": -0.022259854607816036,
        "total_length-nopunct": 110,
        "mean_pred_length-nopunct": 18.333333333333332,
        "std_pred_length-nopunct": 6.871842709362768,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7636363636363637,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 71,
        "entropy-1-nopunct": 6.149307100476206,
        "distinct-2-nopunct": 0.9711538461538461,
        "vocab_size-2-nopunct": 101,
        "unique-2-nopunct": 98,
        "entropy-2-nopunct": 6.642747410448792,
        "cond_entropy-2-nopunct": 0.520289499186918,
        "distinct-3-nopunct": 0.9897959183673469,
        "vocab_size-3-nopunct": 97,
        "unique-3-nopunct": 96,
        "entropy-3-nopunct": 6.594301680849911,
        "cond_entropy-3-nopunct": -0.04491354749527155,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.0914819553509725,
        "rouge1": {
            "precision": 0.56963,
            "recall": 0.57987,
            "fmeasure": 0.55747
        },
        "rouge2": {
            "precision": 0.31052,
            "recall": 0.31604,
            "fmeasure": 0.3015
        },
        "rougeL": {
            "precision": 0.44905,
            "recall": 0.44972,
            "fmeasure": 0.43531
        },
        "rougeLsum": {
            "precision": 0.44905,
            "recall": 0.44972,
            "fmeasure": 0.43531
        },
        "bleu": 26.3909,
        "local_recall": {
            "1": 0.2641509433962264,
            "2": 0.5945945945945946,
            "3": 0.5952380952380952
        },
        "bertscore": {
            "precision": 0.89061,
            "recall": 0.89998,
            "f1": 0.89462
        },
        "nubia": {
            "semantic_relation": 3.75354,
            "contradiction": 13.73243,
            "irrelevancy": 47.2025,
            "logical_agreement": 39.06508,
            "grammar_ref": 4.80564,
            "grammar_hyp": 4.83551,
            "nubia_score": 0.58503
        },
        "meteor": 0.31820705826884677,
        "bleurt": -0.17938
    },
    "totto_test_contrast_challenge_table_size-table_size_402": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 6.018490028422596,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.8392857142857143,
        "vocab_size-1": 47,
        "unique-1": 42,
        "entropy-1": 5.414497779200464,
        "distinct-2": 1.0,
        "vocab_size-2": 53,
        "unique-2": 53,
        "entropy-2": 5.727920454563195,
        "cond_entropy-2": 0.29792402307163257,
        "distinct-3": 1.0,
        "vocab_size-3": 50,
        "unique-3": 50,
        "entropy-3": 5.643856189774728,
        "cond_entropy-3": -0.08406426478847459,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 5.2493385826745405,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 45,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.403856189774728,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.55458885167764,
        "cond_entropy-2-nopunct": 0.16605181083908296,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.09515723304034036,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8364947287097557,
        "rouge1": {
            "precision": 0.79365,
            "recall": 0.5694,
            "fmeasure": 0.65693
        },
        "rouge2": {
            "precision": 0.5463,
            "recall": 0.40163,
            "fmeasure": 0.45829
        },
        "rougeL": {
            "precision": 0.74603,
            "recall": 0.54339,
            "fmeasure": 0.6233
        },
        "rougeLsum": {
            "precision": 0.74603,
            "recall": 0.54339,
            "fmeasure": 0.6233
        },
        "bleu": 31.58342,
        "local_recall": {
            "1": 0,
            "2": 0.25,
            "3": 0.6031746031746031
        },
        "bertscore": {
            "precision": 0.93661,
            "recall": 0.88721,
            "f1": 0.91068
        },
        "nubia": {
            "semantic_relation": 3.90611,
            "contradiction": 13.22117,
            "irrelevancy": 35.17231,
            "logical_agreement": 51.60652,
            "grammar_ref": 3.87101,
            "grammar_hyp": 3.98817,
            "nubia_score": 0.62135
        },
        "meteor": 0.317045947484228,
        "bleurt": 0.07285
    },
    "totto_test_contrast_challenge_table_size-table_size_330": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.66,
        "msttr-100_nopunct": 0.64,
        "total_length": 124,
        "mean_pred_length": 17.714285714285715,
        "std_pred_length": 4.681705602335411,
        "median_pred_length": 15.0,
        "min_pred_length": 14,
        "max_pred_length": 26,
        "distinct-1": 0.6209677419354839,
        "vocab_size-1": 77,
        "unique-1": 59,
        "entropy-1": 5.8728023763359145,
        "distinct-2": 0.9487179487179487,
        "vocab_size-2": 111,
        "unique-2": 105,
        "entropy-2": 6.767800617019283,
        "cond_entropy-2": 0.827134843538333,
        "distinct-3": 0.9818181818181818,
        "vocab_size-3": 108,
        "unique-3": 106,
        "entropy-3": 6.744996077161032,
        "cond_entropy-3": -0.03445955151329022,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 16.285714285714285,
        "std_pred_length-nopunct": 3.989782869648269,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6403508771929824,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.8102314806736,
        "distinct-2-nopunct": 0.9532710280373832,
        "vocab_size-2-nopunct": 102,
        "unique-2-nopunct": 97,
        "entropy-2-nopunct": 6.648009042475905,
        "cond_entropy-2-nopunct": 0.8486056901615562,
        "distinct-3-nopunct": 0.98,
        "vocab_size-3-nopunct": 98,
        "unique-3-nopunct": 96,
        "entropy-3-nopunct": 6.603856189774739,
        "cond_entropy-3-nopunct": -0.047610796626422335,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.600697760389262,
        "rouge1": {
            "precision": 0.7023,
            "recall": 0.6369,
            "fmeasure": 0.64588
        },
        "rouge2": {
            "precision": 0.45001,
            "recall": 0.39178,
            "fmeasure": 0.4034
        },
        "rougeL": {
            "precision": 0.53923,
            "recall": 0.50037,
            "fmeasure": 0.50217
        },
        "rougeLsum": {
            "precision": 0.53923,
            "recall": 0.50037,
            "fmeasure": 0.50217
        },
        "bleu": 35.59296,
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.7142857142857143,
            "3": 0.6376811594202898
        },
        "bertscore": {
            "precision": 0.90035,
            "recall": 0.88678,
            "f1": 0.89195
        },
        "nubia": {
            "semantic_relation": 4.004,
            "contradiction": 14.73336,
            "irrelevancy": 36.40127,
            "logical_agreement": 48.86537,
            "grammar_ref": 5.20043,
            "grammar_hyp": 4.63695,
            "nubia_score": 0.6657
        },
        "meteor": 0.3219722986775493,
        "bleurt": -0.02334
    },
    "totto_test_contrast_challenge_table_size-table_size_365": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.6739130434782609,
        "vocab_size-1": 31,
        "unique-1": 21,
        "entropy-1": 4.760096402170843,
        "distinct-2": 0.7906976744186046,
        "vocab_size-2": 34,
        "unique-2": 25,
        "entropy-2": 5.0076601035393065,
        "cond_entropy-2": 0.1902499608916031,
        "distinct-3": 0.825,
        "vocab_size-3": 33,
        "unique-3": 26,
        "entropy-3": 4.971928094887362,
        "cond_entropy-3": -0.054336659814735795,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6829268292682927,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.6169537612863705,
        "distinct-2-nopunct": 0.7894736842105263,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.826874881864638,
        "cond_entropy-2-nopunct": 0.21575782399919358,
        "distinct-3-nopunct": 0.8285714285714286,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.786425874087822,
        "cond_entropy-3-nopunct": -0.06150163935576179,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9644238917130004,
        "rouge1": {
            "precision": 0.72134,
            "recall": 0.78361,
            "fmeasure": 0.74998
        },
        "rouge2": {
            "precision": 0.60159,
            "recall": 0.66472,
            "fmeasure": 0.63012
        },
        "rougeL": {
            "precision": 0.70004,
            "recall": 0.76703,
            "fmeasure": 0.73051
        },
        "rougeLsum": {
            "precision": 0.70004,
            "recall": 0.76703,
            "fmeasure": 0.73051
        },
        "bleu": 53.10072,
        "local_recall": {
            "1": 0.8571428571428571,
            "2": 0.4,
            "3": 0.7586206896551724
        },
        "bertscore": {
            "precision": 0.93274,
            "recall": 0.9415,
            "f1": 0.93661
        },
        "nubia": {
            "semantic_relation": 4.09955,
            "contradiction": 0.48934,
            "irrelevancy": 54.64972,
            "logical_agreement": 44.86093,
            "grammar_ref": 4.37436,
            "grammar_hyp": 4.39795,
            "nubia_score": 0.71879
        },
        "meteor": 0.43623633811975115,
        "bleurt": 0.26908
    },
    "totto_test_contrast_challenge_table_size-table_size_332": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9404397126388635,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.83333,
            "fmeasure": 0.77143
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.32727,
            "fmeasure": 0.2963
        },
        "rougeL": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "rougeLsum": {
            "precision": 0.25,
            "recall": 0.33333,
            "fmeasure": 0.28571
        },
        "bleu": 13.87903,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.92248,
            "recall": 0.90786,
            "f1": 0.91511
        },
        "nubia": {
            "semantic_relation": 4.01303,
            "contradiction": 0.29614,
            "irrelevancy": 33.42763,
            "logical_agreement": 66.27624,
            "grammar_ref": 6.47099,
            "grammar_hyp": 6.71514,
            "nubia_score": 0.67271
        },
        "meteor": 0.3760109452536829,
        "bleurt": 0.19715
    },
    "totto_test_contrast_challenge_table_size-table_size_420": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 11,
        "msttr-100": 0.76,
        "msttr-100_nopunct": 0.81,
        "total_length": 166,
        "mean_pred_length": 15.090909090909092,
        "std_pred_length": 4.794969816087488,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7108433734939759,
        "vocab_size-1": 118,
        "unique-1": 100,
        "entropy-1": 6.511111755194496,
        "distinct-2": 0.967741935483871,
        "vocab_size-2": 150,
        "unique-2": 147,
        "entropy-2": 7.201867792343116,
        "cond_entropy-2": 0.5065589831657931,
        "distinct-3": 1.0,
        "vocab_size-3": 144,
        "unique-3": 144,
        "entropy-3": 7.169925001442332,
        "cond_entropy-3": -0.0262704107463213,
        "total_length-nopunct": 152,
        "mean_pred_length-nopunct": 13.818181818181818,
        "std_pred_length-nopunct": 4.549089455707929,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.756578947368421,
        "vocab_size-1-nopunct": 115,
        "unique-1-nopunct": 99,
        "entropy-1-nopunct": 6.567939050046919,
        "distinct-2-nopunct": 0.9645390070921985,
        "vocab_size-2-nopunct": 136,
        "unique-2-nopunct": 133,
        "entropy-2-nopunct": 7.057921742439007,
        "cond_entropy-2-nopunct": 0.5430314377634661,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 130,
        "unique-3-nopunct": 130,
        "entropy-3-nopunct": 7.022367813028455,
        "cond_entropy-3-nopunct": -0.02864680856782426,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.574746667609075,
        "rouge1": {
            "precision": 0.77485,
            "recall": 0.77662,
            "fmeasure": 0.77138
        },
        "rouge2": {
            "precision": 0.55034,
            "recall": 0.55623,
            "fmeasure": 0.5504
        },
        "rougeL": {
            "precision": 0.70536,
            "recall": 0.70099,
            "fmeasure": 0.69905
        },
        "rougeLsum": {
            "precision": 0.70536,
            "recall": 0.70099,
            "fmeasure": 0.69905
        },
        "bleu": 49.44757,
        "local_recall": {
            "1": 0.11538461538461539,
            "2": 0.3157894736842105,
            "3": 0.8225806451612904
        },
        "bertscore": {
            "precision": 0.94128,
            "recall": 0.93988,
            "f1": 0.9392
        },
        "nubia": {
            "semantic_relation": 4.46632,
            "contradiction": 3.24986,
            "irrelevancy": 32.47057,
            "logical_agreement": 64.27957,
            "grammar_ref": 4.45431,
            "grammar_hyp": 4.37901,
            "nubia_score": 0.85107
        },
        "meteor": 0.41317752864362695,
        "bleurt": 0.48542
    },
    "totto_test_contrast_challenge_table_size-table_size_403": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.7941176470588235,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.631292988181899,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": 0.33471762763487756,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.09310940439148141,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.456564762130954,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.3829562908893333,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.763007232882716,
        "rouge1": {
            "precision": 0.79861,
            "recall": 0.72705,
            "fmeasure": 0.75705
        },
        "rouge2": {
            "precision": 0.60588,
            "recall": 0.5675,
            "fmeasure": 0.58289
        },
        "rougeL": {
            "precision": 0.77083,
            "recall": 0.70561,
            "fmeasure": 0.73285
        },
        "rougeLsum": {
            "precision": 0.77083,
            "recall": 0.70561,
            "fmeasure": 0.73285
        },
        "bleu": 40.60968,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6785714285714286
        },
        "bertscore": {
            "precision": 0.94723,
            "recall": 0.92772,
            "f1": 0.93511
        },
        "nubia": {
            "semantic_relation": 4.48825,
            "contradiction": 45.86658,
            "irrelevancy": 1.77126,
            "logical_agreement": 52.36216,
            "grammar_ref": 3.82725,
            "grammar_hyp": 3.76762,
            "nubia_score": 0.83273
        },
        "meteor": 0.3613379905504825,
        "bleurt": 0.58208
    },
    "web_nlg_en_test_contrast_challenge_max_obj_same-some_objects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 125,
        "msttr-100": 0.51357,
        "msttr-100_nopunct": 0.49615,
        "total_length": 2843,
        "mean_pred_length": 22.744,
        "std_pred_length": 4.291207755399405,
        "median_pred_length": 24.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.15054519873373198,
        "vocab_size-1": 428,
        "unique-1": 147,
        "entropy-1": 7.216653753669673,
        "distinct-2": 0.3866813833701251,
        "vocab_size-2": 1051,
        "unique-2": 569,
        "entropy-2": 9.387233551959394,
        "cond_entropy-2": 2.1705576605967085,
        "distinct-3": 0.5541843424604705,
        "vocab_size-3": 1437,
        "unique-3": 974,
        "entropy-3": 10.039708989085023,
        "cond_entropy-3": 0.6955555075830128,
        "total_length-nopunct": 2634,
        "mean_pred_length-nopunct": 21.072,
        "std_pred_length-nopunct": 4.317732738370915,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.16059225512528474,
        "vocab_size-1-nopunct": 423,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 7.271745013119036,
        "distinct-2-nopunct": 0.3933838182542846,
        "vocab_size-2-nopunct": 987,
        "unique-2-nopunct": 555,
        "entropy-2-nopunct": 9.294571982624456,
        "cond_entropy-2-nopunct": 2.1147087832166505,
        "distinct-3-nopunct": 0.5595637583892618,
        "vocab_size-3-nopunct": 1334,
        "unique-3-nopunct": 923,
        "entropy-3-nopunct": 9.926576413883902,
        "cond_entropy-3-nopunct": 0.6681987091766459,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.4392229912586565,
        "rouge1": {
            "precision": 0.74593,
            "recall": 0.64086,
            "fmeasure": 0.67708
        },
        "rouge2": {
            "precision": 0.46145,
            "recall": 0.39131,
            "fmeasure": 0.41463
        },
        "rougeL": {
            "precision": 0.5768,
            "recall": 0.49229,
            "fmeasure": 0.52091
        },
        "rougeLsum": {
            "precision": 0.5768,
            "recall": 0.49229,
            "fmeasure": 0.52091
        },
        "bleu": 34.10902,
        "local_recall": {
            "1": 0.16319895968790638,
            "2": 0.4581772784019975,
            "3": 0.7571428571428571
        },
        "bertscore": {
            "precision": 0.90148,
            "recall": 0.87652,
            "f1": 0.88681
        },
        "nubia": {
            "semantic_relation": 3.87407,
            "contradiction": 6.13972,
            "irrelevancy": 15.5018,
            "logical_agreement": 78.35848,
            "grammar_ref": 4.33462,
            "grammar_hyp": 4.66683,
            "nubia_score": 0.58664
        },
        "meteor": 0.304945886318093,
        "bleurt": -0.10706
    },
    "totto_test_contrast_challenge_table_size-table_size_404": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 2.0,
        "median_pred_length": 15.0,
        "min_pred_length": 13,
        "max_pred_length": 17,
        "distinct-1": 0.9666666666666667,
        "vocab_size-1": 29,
        "unique-1": 28,
        "entropy-1": 4.840223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": -0.09953567355091442,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.754887502163471,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.11103131238874399,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.12029423371771175,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.645851282589505,
        "rouge1": {
            "precision": 0.97917,
            "recall": 0.92931,
            "fmeasure": 0.95289
        },
        "rouge2": {
            "precision": 0.86162,
            "recall": 0.81627,
            "fmeasure": 0.83763
        },
        "rougeL": {
            "precision": 0.84375,
            "recall": 0.81802,
            "fmeasure": 0.83023
        },
        "rougeLsum": {
            "precision": 0.84375,
            "recall": 0.81802,
            "fmeasure": 0.83023
        },
        "bleu": 81.97021,
        "local_recall": {
            "1": 0.4,
            "2": 0.625,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96363,
            "recall": 0.96834,
            "f1": 0.96465
        },
        "nubia": {
            "semantic_relation": 4.89694,
            "contradiction": 0.2395,
            "irrelevancy": 25.21283,
            "logical_agreement": 74.54767,
            "grammar_ref": 4.70227,
            "grammar_hyp": 4.5179,
            "nubia_score": 0.96328
        },
        "meteor": 0.5369092673914623,
        "bleurt": 0.56884
    },
    "totto_test_contrast_challenge_table_size-table_size_480": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.77,
        "total_length": 167,
        "mean_pred_length": 16.7,
        "std_pred_length": 3.407345007480164,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 21,
        "distinct-1": 0.6107784431137725,
        "vocab_size-1": 102,
        "unique-1": 79,
        "entropy-1": 6.192824300160737,
        "distinct-2": 0.8662420382165605,
        "vocab_size-2": 136,
        "unique-2": 116,
        "entropy-2": 7.022296624674022,
        "cond_entropy-2": 0.6937367765786194,
        "distinct-3": 0.8979591836734694,
        "vocab_size-3": 132,
        "unique-3": 117,
        "entropy-3": 6.995590712183295,
        "cond_entropy-3": -0.021785904040544972,
        "total_length-nopunct": 152,
        "mean_pred_length-nopunct": 15.2,
        "std_pred_length-nopunct": 3.4871191548325386,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6578947368421053,
        "vocab_size-1-nopunct": 100,
        "unique-1-nopunct": 79,
        "entropy-1-nopunct": 6.234453583884297,
        "distinct-2-nopunct": 0.8661971830985915,
        "vocab_size-2-nopunct": 123,
        "unique-2-nopunct": 105,
        "entropy-2-nopunct": 6.876825376531706,
        "cond_entropy-2-nopunct": 0.6996586890952297,
        "distinct-3-nopunct": 0.9015151515151515,
        "vocab_size-3-nopunct": 119,
        "unique-3-nopunct": 106,
        "entropy-3-nopunct": 6.847424422388749,
        "cond_entropy-3-nopunct": -0.023876579675293146,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.276097079048473,
        "rouge1": {
            "precision": 0.82577,
            "recall": 0.75347,
            "fmeasure": 0.77665
        },
        "rouge2": {
            "precision": 0.59597,
            "recall": 0.56442,
            "fmeasure": 0.57344
        },
        "rougeL": {
            "precision": 0.68781,
            "recall": 0.631,
            "fmeasure": 0.64899
        },
        "rougeLsum": {
            "precision": 0.68781,
            "recall": 0.631,
            "fmeasure": 0.64899
        },
        "bleu": 47.64787,
        "local_recall": {
            "1": 0.2,
            "2": 0.4166666666666667,
            "3": 0.7948717948717948
        },
        "bertscore": {
            "precision": 0.95038,
            "recall": 0.93311,
            "f1": 0.94098
        },
        "nubia": {
            "semantic_relation": 4.27802,
            "contradiction": 28.47944,
            "irrelevancy": 7.84066,
            "logical_agreement": 63.6799,
            "grammar_ref": 4.07874,
            "grammar_hyp": 4.26122,
            "nubia_score": 0.74275
        },
        "meteor": 0.40030353364485516,
        "bleurt": 0.36808
    },
    "totto_test_contrast_challenge_table_size-table_size_405": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9898332363522426,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9,
            "fmeasure": 0.94737
        },
        "bleu": 61.0195,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.99622,
            "recall": 0.98673,
            "f1": 0.99146
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.30005,
            "irrelevancy": 0.4565,
            "logical_agreement": 99.24345,
            "grammar_ref": 4.34196,
            "grammar_hyp": 4.46114,
            "nubia_score": 0.99737
        },
        "meteor": 0.5064321156600579,
        "bleurt": 0.83294
    },
    "totto_test_contrast_challenge_table_size-table_size_483": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 3.2998316455372216,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8157894736842105,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.839775539645509,
        "distinct-2": 1.0,
        "vocab_size-2": 35,
        "unique-2": 35,
        "entropy-2": 5.129283016944964,
        "cond_entropy-2": 0.18863800356319443,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.12928301694496638,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 3.39934634239519,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.7711426205984715,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.1814072595289058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9720698466395374,
        "rouge1": {
            "precision": 0.69071,
            "recall": 0.80019,
            "fmeasure": 0.72874
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.60962,
            "fmeasure": 0.57315
        },
        "rougeL": {
            "precision": 0.69071,
            "recall": 0.80019,
            "fmeasure": 0.72874
        },
        "rougeLsum": {
            "precision": 0.69071,
            "recall": 0.80019,
            "fmeasure": 0.72874
        },
        "bleu": 48.7696,
        "local_recall": {
            "1": 0.1875,
            "2": 0.7692307692307693,
            "3": 0.9166666666666666
        },
        "bertscore": {
            "precision": 0.91506,
            "recall": 0.95239,
            "f1": 0.93066
        },
        "nubia": {
            "semantic_relation": 4.59482,
            "contradiction": 0.3803,
            "irrelevancy": 33.60078,
            "logical_agreement": 66.01892,
            "grammar_ref": 5.27099,
            "grammar_hyp": 4.93745,
            "nubia_score": 0.91199
        },
        "meteor": 0.4737801617985089,
        "bleurt": 0.48933
    },
    "totto_test_contrast_challenge_table_size-table_size_485": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7735572622751845,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.04332146930622849,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6856265017985197,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.80828,
            "fmeasure": 0.86616
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.4902,
            "fmeasure": 0.5276
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.63508,
            "fmeasure": 0.68056
        },
        "bleu": 21.83001,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.95812,
            "recall": 0.93418,
            "f1": 0.946
        },
        "nubia": {
            "semantic_relation": 4.80086,
            "contradiction": 0.1395,
            "irrelevancy": 0.76855,
            "logical_agreement": 99.09195,
            "grammar_ref": 3.15249,
            "grammar_hyp": 3.4049,
            "nubia_score": 0.96253
        },
        "meteor": 0.41081248021664324,
        "bleurt": 0.42937
    },
    "totto_test_contrast_challenge_table_size-table_size_406": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 49,
        "mean_pred_length": 16.333333333333332,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 19,
        "distinct-1": 0.8163265306122449,
        "vocab_size-1": 40,
        "unique-1": 34,
        "entropy-1": 5.201145303166425,
        "distinct-2": 1.0,
        "vocab_size-2": 46,
        "unique-2": 46,
        "entropy-2": 5.5235619560570095,
        "cond_entropy-2": 0.24602113377499873,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.09729720135491506,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8444444444444444,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.147191429566853,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.2697446836949651,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.10691520391651191,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.183309486064184,
        "rouge1": {
            "precision": 0.68343,
            "recall": 0.57753,
            "fmeasure": 0.61635
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.28982,
            "fmeasure": 0.31454
        },
        "rougeL": {
            "precision": 0.50722,
            "recall": 0.43503,
            "fmeasure": 0.46195
        },
        "rougeLsum": {
            "precision": 0.50722,
            "recall": 0.43503,
            "fmeasure": 0.46195
        },
        "bleu": 34.89673,
        "local_recall": {
            "1": 0.8333333333333334,
            "2": 0.6190476190476191,
            "3": 0.6363636363636364
        },
        "bertscore": {
            "precision": 0.90822,
            "recall": 0.87959,
            "f1": 0.89235
        },
        "nubia": {
            "semantic_relation": 4.17539,
            "contradiction": 27.93056,
            "irrelevancy": 12.91284,
            "logical_agreement": 59.1566,
            "grammar_ref": 4.68806,
            "grammar_hyp": 4.83829,
            "nubia_score": 0.66742
        },
        "meteor": 0.31537431897250223,
        "bleurt": 0.14072
    },
    "totto_test_contrast_challenge_table_size-table_size_366": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.546060565661952,
        "median_pred_length": 15.0,
        "min_pred_length": 11,
        "max_pred_length": 22,
        "distinct-1": 0.875,
        "vocab_size-1": 42,
        "unique-1": 39,
        "entropy-1": 5.277569011092754,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.12911281783074044,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 43,
        "mean_pred_length-nopunct": 14.333333333333334,
        "std_pred_length-nopunct": 3.681787005729087,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9069767441860465,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.193706615167214,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.3219280948873635,
        "cond_entropy-2-nopunct": 0.14566334018526414,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.11247472925841272,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.965843000732898,
        "rouge1": {
            "precision": 0.84603,
            "recall": 0.78366,
            "fmeasure": 0.80365
        },
        "rouge2": {
            "precision": 0.65375,
            "recall": 0.60079,
            "fmeasure": 0.61734
        },
        "rougeL": {
            "precision": 0.72698,
            "recall": 0.66824,
            "fmeasure": 0.68632
        },
        "rougeLsum": {
            "precision": 0.72698,
            "recall": 0.66824,
            "fmeasure": 0.68632
        },
        "bleu": 57.16604,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.4,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.95431,
            "recall": 0.95196,
            "f1": 0.95303
        },
        "nubia": {
            "semantic_relation": 4.65965,
            "contradiction": 1.30141,
            "irrelevancy": 11.56879,
            "logical_agreement": 87.1298,
            "grammar_ref": 5.35172,
            "grammar_hyp": 5.05513,
            "nubia_score": 0.85066
        },
        "meteor": 0.46764631217496627,
        "bleurt": 0.38007
    },
    "totto_test_contrast_challenge_table_size-table_size_448": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 13.25,
        "std_pred_length": 0.4330127018922193,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.7735849056603774,
        "vocab_size-1": 41,
        "unique-1": 32,
        "entropy-1": 5.223111256409171,
        "distinct-2": 0.9183673469387755,
        "vocab_size-2": 45,
        "unique-2": 41,
        "entropy-2": 5.45144453799276,
        "cond_entropy-2": 0.10627688959616163,
        "distinct-3": 0.9555555555555556,
        "vocab_size-3": 43,
        "unique-3": 41,
        "entropy-3": 5.402964207440784,
        "cond_entropy-3": -0.03396785889664475,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.7071067811865476,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 5.194235677759418,
        "distinct-2-nopunct": 0.9090909090909091,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.277613436819113,
        "cond_entropy-2-nopunct": 0.11889837932894702,
        "distinct-3-nopunct": 0.95,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.221928094887364,
        "cond_entropy-3-nopunct": -0.037503523749935014,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.641670944612239,
        "rouge1": {
            "precision": 0.84509,
            "recall": 0.76059,
            "fmeasure": 0.79914
        },
        "rouge2": {
            "precision": 0.60985,
            "recall": 0.55554,
            "fmeasure": 0.58035
        },
        "rougeL": {
            "precision": 0.77101,
            "recall": 0.70251,
            "fmeasure": 0.73406
        },
        "rougeLsum": {
            "precision": 0.77101,
            "recall": 0.70251,
            "fmeasure": 0.73406
        },
        "bleu": 61.27049,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.4444444444444444,
            "3": 0.8043478260869565
        },
        "bertscore": {
            "precision": 0.96432,
            "recall": 0.95251,
            "f1": 0.9563
        },
        "nubia": {
            "semantic_relation": 4.69062,
            "contradiction": 10.76595,
            "irrelevancy": 3.34361,
            "logical_agreement": 85.89044,
            "grammar_ref": 4.9146,
            "grammar_hyp": 5.07441,
            "nubia_score": 0.82491
        },
        "meteor": 0.45682661453067824,
        "bleurt": 0.44407
    },
    "totto_test_contrast_challenge_table_size-table_size_486": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 5.722761571129799,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.7592592592592593,
        "vocab_size-1": 41,
        "unique-1": 32,
        "entropy-1": 5.208410187268523,
        "distinct-2": 0.92,
        "vocab_size-2": 46,
        "unique-2": 42,
        "entropy-2": 5.483856189774728,
        "cond_entropy-2": 0.1591641876977948,
        "distinct-3": 0.9347826086956522,
        "vocab_size-3": 43,
        "unique-3": 40,
        "entropy-3": 5.393127173448315,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 4.092676385936225,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.142914673354252,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.249460279921618,
        "cond_entropy-2-nopunct": 0.09517868111048415,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.142664355548852,
        "cond_entropy-3-nopunct": -0.14438990933517484,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.583581677318589,
        "rouge1": {
            "precision": 0.50369,
            "recall": 0.44315,
            "fmeasure": 0.4544
        },
        "rouge2": {
            "precision": 0.2146,
            "recall": 0.23207,
            "fmeasure": 0.21972
        },
        "rougeL": {
            "precision": 0.38734,
            "recall": 0.40056,
            "fmeasure": 0.3857
        },
        "rougeLsum": {
            "precision": 0.38734,
            "recall": 0.40056,
            "fmeasure": 0.3857
        },
        "bleu": 34.8511,
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.18421052631578946,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.85254,
            "recall": 0.84561,
            "f1": 0.84439
        },
        "nubia": {
            "semantic_relation": 3.70924,
            "contradiction": 22.23726,
            "irrelevancy": 52.85022,
            "logical_agreement": 24.91252,
            "grammar_ref": 4.83501,
            "grammar_hyp": 4.39591,
            "nubia_score": 0.59628
        },
        "meteor": 0.28068122303622334,
        "bleurt": -0.0238
    },
    "totto_test_contrast_challenge_table_size-table_size_423": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.0,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.9666666666666667,
        "vocab_size-1": 29,
        "unique-1": 28,
        "entropy-1": 4.840223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": -0.09953567355091442,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.70043971814109,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": -0.11547721741993584,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7849180068988484,
        "rouge1": {
            "precision": 0.63542,
            "recall": 0.7037,
            "fmeasure": 0.66133
        },
        "rouge2": {
            "precision": 0.43737,
            "recall": 0.47751,
            "fmeasure": 0.45294
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.59713,
            "fmeasure": 0.57325
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.59713,
            "fmeasure": 0.57325
        },
        "bleu": 46.21385,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.92748,
            "recall": 0.93993,
            "f1": 0.93138
        },
        "nubia": {
            "semantic_relation": 4.2905,
            "contradiction": 0.28352,
            "irrelevancy": 9.17235,
            "logical_agreement": 90.54413,
            "grammar_ref": 4.57807,
            "grammar_hyp": 3.88807,
            "nubia_score": 0.82534
        },
        "meteor": 0.43509982717380424,
        "bleurt": 0.41533
    },
    "totto_test_contrast_challenge_table_size-table_size_407": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6747049621140044,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.53788,
            "fmeasure": 0.59259
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.31905,
            "fmeasure": 0.34936
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.53788,
            "fmeasure": 0.59259
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.53788,
            "fmeasure": 0.59259
        },
        "bleu": 24.07857,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.85582,
            "recall": 0.85337,
            "f1": 0.85459
        },
        "nubia": {
            "semantic_relation": 3.53615,
            "contradiction": 0.60923,
            "irrelevancy": 96.03227,
            "logical_agreement": 3.3585,
            "grammar_ref": 4.68733,
            "grammar_hyp": 5.10762,
            "nubia_score": 0.54033
        },
        "meteor": 0.31213554306172964,
        "bleurt": 0.12436
    },
    "totto_test_contrast_challenge_table_size-table_size_333": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.056287299734322734,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.2776134368191165,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": 0.06249647625006499,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.00193538757769,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.83333,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.92308,
            "fmeasure": 0.96
        },
        "bleu": 81.96501,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.99614,
            "recall": 0.98503,
            "f1": 0.99055
        },
        "nubia": {
            "semantic_relation": 4.91472,
            "contradiction": 0.30946,
            "irrelevancy": 2.79721,
            "logical_agreement": 96.89333,
            "grammar_ref": 3.61542,
            "grammar_hyp": 3.03745,
            "nubia_score": 1.0
        },
        "meteor": 0.5249299242820813,
        "bleurt": 0.86304
    },
    "totto_test_contrast_challenge_table_size-table_size_488": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.03753715874966058,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6144838329894124,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.96078,
            "fmeasure": 0.94819
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.7619,
            "fmeasure": 0.769
        },
        "rougeL": {
            "precision": 0.89583,
            "recall": 0.87712,
            "fmeasure": 0.88563
        },
        "rougeLsum": {
            "precision": 0.89583,
            "recall": 0.87712,
            "fmeasure": 0.88563
        },
        "bleu": 78.93575,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97737,
            "recall": 0.97443,
            "f1": 0.97475
        },
        "nubia": {
            "semantic_relation": 4.80996,
            "contradiction": 0.22818,
            "irrelevancy": 0.49433,
            "logical_agreement": 99.27749,
            "grammar_ref": 4.24096,
            "grammar_hyp": 3.78167,
            "nubia_score": 0.97089
        },
        "meteor": 0.5305475968023703,
        "bleurt": 0.73059
    },
    "totto_test_contrast_challenge_table_size-table_size_368": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.76,
        "total_length": 128,
        "mean_pred_length": 18.285714285714285,
        "std_pred_length": 5.993193418115152,
        "median_pred_length": 18.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.6796875,
        "vocab_size-1": 87,
        "unique-1": 70,
        "entropy-1": 6.052248993975066,
        "distinct-2": 0.9338842975206612,
        "vocab_size-2": 113,
        "unique-2": 105,
        "entropy-2": 6.786631832315924,
        "cond_entropy-2": 0.6849995041899241,
        "distinct-3": 0.9473684210526315,
        "vocab_size-3": 108,
        "unique-3": 102,
        "entropy-3": 6.727626856270017,
        "cond_entropy-3": -0.05965743363616856,
        "total_length-nopunct": 114,
        "mean_pred_length-nopunct": 16.285714285714285,
        "std_pred_length-nopunct": 6.111214181773554,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7280701754385965,
        "vocab_size-1-nopunct": 83,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 6.00751415607424,
        "distinct-2-nopunct": 0.9252336448598131,
        "vocab_size-2-nopunct": 99,
        "unique-2-nopunct": 91,
        "entropy-2-nopunct": 6.5919342761207655,
        "cond_entropy-2-nopunct": 0.6197250827253591,
        "distinct-3-nopunct": 0.94,
        "vocab_size-3-nopunct": 94,
        "unique-3-nopunct": 88,
        "entropy-3-nopunct": 6.5238561897747385,
        "cond_entropy-3-nopunct": -0.07761079662642241,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.4732974104618135,
        "rouge1": {
            "precision": 0.76371,
            "recall": 0.84619,
            "fmeasure": 0.78899
        },
        "rouge2": {
            "precision": 0.58756,
            "recall": 0.67948,
            "fmeasure": 0.61726
        },
        "rougeL": {
            "precision": 0.69354,
            "recall": 0.77533,
            "fmeasure": 0.72022
        },
        "rougeLsum": {
            "precision": 0.69354,
            "recall": 0.77533,
            "fmeasure": 0.72022
        },
        "bleu": 52.60364,
        "local_recall": {
            "1": 0.21212121212121213,
            "2": 0.6,
            "3": 0.8441558441558441
        },
        "bertscore": {
            "precision": 0.93062,
            "recall": 0.94066,
            "f1": 0.93379
        },
        "nubia": {
            "semantic_relation": 4.31934,
            "contradiction": 7.77469,
            "irrelevancy": 27.11396,
            "logical_agreement": 65.11135,
            "grammar_ref": 4.94315,
            "grammar_hyp": 4.43952,
            "nubia_score": 0.79187
        },
        "meteor": 0.448632215130058,
        "bleurt": 0.26677
    },
    "totto_test_contrast_challenge_table_size-table_size_515": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.813953488372093,
        "vocab_size-1": 35,
        "unique-1": 28,
        "entropy-1": 5.036616208140156,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.14566334018526417,
        "distinct-3": 1.0,
        "vocab_size-3": 37,
        "unique-3": 37,
        "entropy-3": 5.209453365628954,
        "cond_entropy-3": -0.05842067520435854,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 1.632993161855452,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.97770991116994,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.058813890331199,
        "cond_entropy-2-nopunct": 0.10674500480228634,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.004318760871737871,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.263053586708178,
        "rouge1": {
            "precision": 0.88661,
            "recall": 0.95185,
            "fmeasure": 0.91149
        },
        "rouge2": {
            "precision": 0.83466,
            "recall": 0.92107,
            "fmeasure": 0.86619
        },
        "rougeL": {
            "precision": 0.85356,
            "recall": 0.96068,
            "fmeasure": 0.89735
        },
        "rougeLsum": {
            "precision": 0.85356,
            "recall": 0.96068,
            "fmeasure": 0.89735
        },
        "bleu": 80.21298,
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97153,
            "recall": 0.98561,
            "f1": 0.97798
        },
        "nubia": {
            "semantic_relation": 4.58576,
            "contradiction": 0.43884,
            "irrelevancy": 43.25261,
            "logical_agreement": 56.30855,
            "grammar_ref": 4.92539,
            "grammar_hyp": 4.86663,
            "nubia_score": 0.87126
        },
        "meteor": 0.5965846477944291,
        "bleurt": 0.64515
    },
    "totto_test_contrast_challenge_table_size-table_size_424": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 6.098155458825234,
        "median_pred_length": 10.5,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.7450980392156863,
        "vocab_size-1": 38,
        "unique-1": 29,
        "entropy-1": 5.084190047853852,
        "distinct-2": 1.0,
        "vocab_size-2": 47,
        "unique-2": 47,
        "entropy-2": 5.55458885167764,
        "cond_entropy-2": 0.35024861608912067,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.1283240969755395,
        "total_length-nopunct": 45,
        "mean_pred_length-nopunct": 11.25,
        "std_pred_length-nopunct": 5.7608593109014565,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.047408651885228,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.3291135424347503,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.14809863898913406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.648691685670685,
        "rouge1": {
            "precision": 0.78836,
            "recall": 0.73008,
            "fmeasure": 0.75316
        },
        "rouge2": {
            "precision": 0.54375,
            "recall": 0.48591,
            "fmeasure": 0.50814
        },
        "rougeL": {
            "precision": 0.65873,
            "recall": 0.59772,
            "fmeasure": 0.62177
        },
        "rougeLsum": {
            "precision": 0.65873,
            "recall": 0.59772,
            "fmeasure": 0.62177
        },
        "bleu": 41.2446,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.775
        },
        "bertscore": {
            "precision": 0.91106,
            "recall": 0.9009,
            "f1": 0.90558
        },
        "nubia": {
            "semantic_relation": 3.97403,
            "contradiction": 11.41056,
            "irrelevancy": 31.4285,
            "logical_agreement": 57.16094,
            "grammar_ref": 4.90076,
            "grammar_hyp": 5.0518,
            "nubia_score": 0.66425
        },
        "meteor": 0.3692332544588423,
        "bleurt": 0.00927
    },
    "totto_test_contrast_challenge_table_size-table_size_450": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 2.384848003542364,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.7636363636363637,
        "vocab_size-1": 42,
        "unique-1": 35,
        "entropy-1": 5.208454713445985,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.352041608923835,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.11783649029385802,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 2.48746859276655,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8163265306122449,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.175734844026904,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.3329160300883984,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.13430109171159124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.225728154721269,
        "rouge1": {
            "precision": 0.65428,
            "recall": 0.80173,
            "fmeasure": 0.71188
        },
        "rouge2": {
            "precision": 0.40521,
            "recall": 0.52785,
            "fmeasure": 0.45185
        },
        "rougeL": {
            "precision": 0.60772,
            "recall": 0.75535,
            "fmeasure": 0.66652
        },
        "rougeLsum": {
            "precision": 0.60772,
            "recall": 0.75535,
            "fmeasure": 0.66652
        },
        "bleu": 37.62872,
        "local_recall": {
            "1": 0.16,
            "2": 0.875,
            "3": 0.7619047619047619
        },
        "bertscore": {
            "precision": 0.89374,
            "recall": 0.91614,
            "f1": 0.90383
        },
        "nubia": {
            "semantic_relation": 3.85805,
            "contradiction": 3.78259,
            "irrelevancy": 53.23715,
            "logical_agreement": 42.98026,
            "grammar_ref": 4.75156,
            "grammar_hyp": 4.78517,
            "nubia_score": 0.59196
        },
        "meteor": 0.4046795787727027,
        "bleurt": 0.29013
    },
    "totto_test_contrast_challenge_table_size-table_size_490": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 77,
        "mean_pred_length": 15.4,
        "std_pred_length": 5.71314274283428,
        "median_pred_length": 16.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.7402597402597403,
        "vocab_size-1": 57,
        "unique-1": 48,
        "entropy-1": 5.565279885746805,
        "distinct-2": 0.9861111111111112,
        "vocab_size-2": 71,
        "unique-2": 70,
        "entropy-2": 6.14214722366454,
        "cond_entropy-2": 0.43062787492401516,
        "distinct-3": 1.0,
        "vocab_size-3": 67,
        "unique-3": 67,
        "entropy-3": 6.066089190457767,
        "cond_entropy-3": -0.07398506471588326,
        "total_length-nopunct": 67,
        "mean_pred_length-nopunct": 13.4,
        "std_pred_length-nopunct": 4.758150901348127,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7910447761194029,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.553185787821944,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 5.954196310386873,
        "cond_entropy-2-nopunct": 0.44237370019684974,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.832890014164737,
        "cond_entropy-3-nopunct": -0.12130629622213351,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.5004446568242695,
        "rouge1": {
            "precision": 0.79139,
            "recall": 0.77436,
            "fmeasure": 0.7821
        },
        "rouge2": {
            "precision": 0.59607,
            "recall": 0.59092,
            "fmeasure": 0.5931
        },
        "rougeL": {
            "precision": 0.67278,
            "recall": 0.66217,
            "fmeasure": 0.6671
        },
        "rougeLsum": {
            "precision": 0.67278,
            "recall": 0.66217,
            "fmeasure": 0.6671
        },
        "bleu": 44.61831,
        "local_recall": {
            "1": 0.13333333333333333,
            "2": 0.125,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.93469,
            "recall": 0.9301,
            "f1": 0.93162
        },
        "nubia": {
            "semantic_relation": 4.32208,
            "contradiction": 0.75679,
            "irrelevancy": 17.07956,
            "logical_agreement": 82.16366,
            "grammar_ref": 4.31899,
            "grammar_hyp": 4.46334,
            "nubia_score": 0.79794
        },
        "meteor": 0.37089348097653557,
        "bleurt": 0.33029
    },
    "totto_test_contrast_challenge_table_size-table_size_425": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.07574294699860606,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.522311975547979,
        "rouge1": {
            "precision": 0.56667,
            "recall": 0.74074,
            "fmeasure": 0.62916
        },
        "rouge2": {
            "precision": 0.50877,
            "recall": 0.67892,
            "fmeasure": 0.5679
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.55556,
            "fmeasure": 0.45372
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.55556,
            "fmeasure": 0.45372
        },
        "bleu": 56.97864,
        "local_recall": {
            "1": 0.6923076923076923,
            "2": 0.0,
            "3": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.87256,
            "recall": 0.91639,
            "f1": 0.89394
        },
        "nubia": {
            "semantic_relation": 1.85503,
            "contradiction": 89.52188,
            "irrelevancy": 7.24951,
            "logical_agreement": 3.22861,
            "grammar_ref": 4.13721,
            "grammar_hyp": 2.90119,
            "nubia_score": 0.26389
        },
        "meteor": 0.42773767566930343,
        "bleurt": -0.22065
    },
    "totto_test_contrast_challenge_table_size-table_size_369": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 2.680951323690902,
        "median_pred_length": 13.0,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.6727272727272727,
        "vocab_size-1": 37,
        "unique-1": 27,
        "entropy-1": 4.962822440640043,
        "distinct-2": 0.8431372549019608,
        "vocab_size-2": 43,
        "unique-2": 36,
        "entropy-2": 5.3438981360467235,
        "cond_entropy-2": 0.2884119521035108,
        "distinct-3": 0.9148936170212766,
        "vocab_size-3": 43,
        "unique-3": 39,
        "entropy-3": 5.384376085720193,
        "cond_entropy-3": 0.06843771187983275,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.692582403567252,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.903465189601648,
        "distinct-2-nopunct": 0.8260869565217391,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 5.15932527122737,
        "cond_entropy-2-nopunct": 0.29850277729294916,
        "distinct-3-nopunct": 0.9047619047619048,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.201841232302572,
        "cond_entropy-3-nopunct": 0.0533956453446873,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9491972291125568,
        "rouge1": {
            "precision": 0.70576,
            "recall": 0.77688,
            "fmeasure": 0.73115
        },
        "rouge2": {
            "precision": 0.54864,
            "recall": 0.56813,
            "fmeasure": 0.55286
        },
        "rougeL": {
            "precision": 0.6242,
            "recall": 0.66935,
            "fmeasure": 0.63908
        },
        "rougeLsum": {
            "precision": 0.6242,
            "recall": 0.66935,
            "fmeasure": 0.63908
        },
        "bleu": 46.15382,
        "local_recall": {
            "1": 0.07142857142857142,
            "2": 0.09090909090909091,
            "3": 0.9166666666666666
        },
        "bertscore": {
            "precision": 0.91863,
            "recall": 0.94415,
            "f1": 0.93077
        },
        "nubia": {
            "semantic_relation": 4.35689,
            "contradiction": 0.28814,
            "irrelevancy": 48.47556,
            "logical_agreement": 51.2363,
            "grammar_ref": 5.27719,
            "grammar_hyp": 5.05237,
            "nubia_score": 0.79262
        },
        "meteor": 0.4199701037391169,
        "bleurt": 0.31318
    },
    "totto_test_contrast_challenge_table_size-table_size_452": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 13,
        "entropy-1": 4.011365041826378,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.329610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.826874881864637,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.3108863768876157,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.071023450292653,
        "rouge1": {
            "precision": 0.68421,
            "recall": 0.54167,
            "fmeasure": 0.60465
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.30435,
            "fmeasure": 0.34146
        },
        "rougeL": {
            "precision": 0.47368,
            "recall": 0.375,
            "fmeasure": 0.4186
        },
        "rougeLsum": {
            "precision": 0.47368,
            "recall": 0.375,
            "fmeasure": 0.4186
        },
        "bleu": 25.55035,
        "local_recall": {
            "1": 0,
            "2": 0.625,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.90356,
            "recall": 0.85209,
            "f1": 0.87707
        },
        "nubia": {
            "semantic_relation": 3.08552,
            "contradiction": 95.20579,
            "irrelevancy": 2.13092,
            "logical_agreement": 2.66329,
            "grammar_ref": 4.791,
            "grammar_hyp": 4.52125,
            "nubia_score": 0.41857
        },
        "meteor": 0.2809454300342698,
        "bleurt": -0.1982
    },
    "totto_test_contrast_challenge_table_size-table_size_492": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 3.0912061651652345,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.825,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.93418371977919,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.17819790593519447,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8611111111111112,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.871178126382214,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.20037479979988243,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.13750352374993471,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7157926590593697,
        "rouge1": {
            "precision": 0.69878,
            "recall": 0.60205,
            "fmeasure": 0.63141
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.36841,
            "fmeasure": 0.38657
        },
        "rougeL": {
            "precision": 0.60583,
            "recall": 0.53641,
            "fmeasure": 0.55507
        },
        "rougeLsum": {
            "precision": 0.60583,
            "recall": 0.53641,
            "fmeasure": 0.55507
        },
        "bleu": 31.84527,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.8571428571428571,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.90795,
            "recall": 0.8779,
            "f1": 0.8921
        },
        "nubia": {
            "semantic_relation": 4.14155,
            "contradiction": 0.2677,
            "irrelevancy": 33.6414,
            "logical_agreement": 66.0909,
            "grammar_ref": 3.54742,
            "grammar_hyp": 4.12591,
            "nubia_score": 0.7544
        },
        "meteor": 0.333317782703232,
        "bleurt": 0.22321
    },
    "totto_test_contrast_challenge_table_size-table_size_426": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 65,
        "mean_pred_length": 21.666666666666668,
        "std_pred_length": 3.6817870057290873,
        "median_pred_length": 22.0,
        "min_pred_length": 17,
        "max_pred_length": 26,
        "distinct-1": 0.676923076923077,
        "vocab_size-1": 44,
        "unique-1": 29,
        "entropy-1": 5.278298151849991,
        "distinct-2": 0.7903225806451613,
        "vocab_size-2": 49,
        "unique-2": 37,
        "entropy-2": 5.5226658668035915,
        "cond_entropy-2": 0.2803710856557887,
        "distinct-3": 0.847457627118644,
        "vocab_size-3": 50,
        "unique-3": 41,
        "entropy-3": 5.577558303599125,
        "cond_entropy-3": 0.07683466274044852,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 19.333333333333332,
        "std_pred_length-nopunct": 4.109609335312651,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7068965517241379,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.19652361622067,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.3676344862125935,
        "cond_entropy-2-nopunct": 0.2071903633868477,
        "distinct-3-nopunct": 0.8653846153846154,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.431208948910325,
        "cond_entropy-3-nopunct": 0.08744322581188389,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2537540893204233,
        "rouge1": {
            "precision": 0.4504,
            "recall": 0.38102,
            "fmeasure": 0.40929
        },
        "rouge2": {
            "precision": 0.28857,
            "recall": 0.25308,
            "fmeasure": 0.26701
        },
        "rougeL": {
            "precision": 0.3879,
            "recall": 0.33484,
            "fmeasure": 0.35618
        },
        "rougeLsum": {
            "precision": 0.3879,
            "recall": 0.33484,
            "fmeasure": 0.35618
        },
        "bleu": 19.08937,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.22580645161290322,
            "3": 0.44
        },
        "bertscore": {
            "precision": 0.83425,
            "recall": 0.80343,
            "f1": 0.81791
        },
        "nubia": {
            "semantic_relation": 2.95008,
            "contradiction": 9.52234,
            "irrelevancy": 69.67642,
            "logical_agreement": 20.80124,
            "grammar_ref": 3.62435,
            "grammar_hyp": 3.18767,
            "nubia_score": 0.54359
        },
        "meteor": 0.15883687756751175,
        "bleurt": -0.39312
    },
    "totto_test_contrast_challenge_table_size-table_size_335": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 13.75,
        "std_pred_length": 4.264680527307995,
        "median_pred_length": 14.0,
        "min_pred_length": 9,
        "max_pred_length": 18,
        "distinct-1": 0.7272727272727273,
        "vocab_size-1": 40,
        "unique-1": 32,
        "entropy-1": 5.113089031667139,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.45488695201866897,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": -0.11783649029385802,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 12.25,
        "std_pred_length-nopunct": 4.264680527307995,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7755102040816326,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 5.068691731826158,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.491853096329673,
        "cond_entropy-2-nopunct": 0.4364749189131846,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.13430109171159124,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.677393875635004,
        "rouge1": {
            "precision": 0.7886,
            "recall": 0.87052,
            "fmeasure": 0.82058
        },
        "rouge2": {
            "precision": 0.54241,
            "recall": 0.61329,
            "fmeasure": 0.56997
        },
        "rougeL": {
            "precision": 0.75735,
            "recall": 0.84043,
            "fmeasure": 0.78994
        },
        "rougeLsum": {
            "precision": 0.75735,
            "recall": 0.84043,
            "fmeasure": 0.78994
        },
        "bleu": 50.62552,
        "local_recall": {
            "1": 0.0,
            "2": 0.8461538461538461,
            "3": 0.9166666666666666
        },
        "bertscore": {
            "precision": 0.9533,
            "recall": 0.96127,
            "f1": 0.95523
        },
        "nubia": {
            "semantic_relation": 4.39879,
            "contradiction": 11.82934,
            "irrelevancy": 42.62991,
            "logical_agreement": 45.54075,
            "grammar_ref": 5.05046,
            "grammar_hyp": 5.5297,
            "nubia_score": 0.70689
        },
        "meteor": 0.4578358144177449,
        "bleurt": 0.4023
    },
    "totto_test_contrast_challenge_table_size-table_size_516": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 84,
        "mean_pred_length": 21.0,
        "std_pred_length": 2.7386127875258306,
        "median_pred_length": 20.5,
        "min_pred_length": 18,
        "max_pred_length": 25,
        "distinct-1": 0.7857142857142857,
        "vocab_size-1": 66,
        "unique-1": 57,
        "entropy-1": 5.8610175360753,
        "distinct-2": 1.0,
        "vocab_size-2": 80,
        "unique-2": 80,
        "entropy-2": 6.321928094887356,
        "cond_entropy-2": 0.42803945937019217,
        "distinct-3": 1.0,
        "vocab_size-3": 76,
        "unique-3": 76,
        "entropy-3": 6.247927513443591,
        "cond_entropy-3": -0.07400058144377683,
        "total_length-nopunct": 76,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 3.24037034920393,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 64,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.876024059410822,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 72,
        "entropy-2-nopunct": 6.1699250014423175,
        "cond_entropy-2-nopunct": 0.3145622450333156,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 68,
        "entropy-3-nopunct": 6.087462841250345,
        "cond_entropy-3-nopunct": -0.08246216019197286,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.991128641034047,
        "rouge1": {
            "precision": 0.82935,
            "recall": 0.74458,
            "fmeasure": 0.77119
        },
        "rouge2": {
            "precision": 0.52809,
            "recall": 0.45874,
            "fmeasure": 0.4814
        },
        "rougeL": {
            "precision": 0.7288,
            "recall": 0.65724,
            "fmeasure": 0.67988
        },
        "rougeLsum": {
            "precision": 0.7288,
            "recall": 0.65724,
            "fmeasure": 0.67988
        },
        "bleu": 37.78319,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.6,
            "3": 0.7313432835820896
        },
        "bertscore": {
            "precision": 0.94302,
            "recall": 0.91665,
            "f1": 0.92951
        },
        "nubia": {
            "semantic_relation": 4.35464,
            "contradiction": 1.57223,
            "irrelevancy": 27.9244,
            "logical_agreement": 70.50337,
            "grammar_ref": 4.38942,
            "grammar_hyp": 4.10474,
            "nubia_score": 0.77838
        },
        "meteor": 0.38131724613060963,
        "bleurt": 0.216
    },
    "totto_test_contrast_challenge_table_size-table_size_455": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 19,
        "unique-1": 15,
        "entropy-1": 4.136842188131012,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.2724185498326623,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8095238095238095,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.9754180179138325,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.31639364341027093,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.773697852885129,
        "rouge1": {
            "precision": 0.89103,
            "recall": 0.7364,
            "fmeasure": 0.804
        },
        "rouge2": {
            "precision": 0.63095,
            "recall": 0.53558,
            "fmeasure": 0.57787
        },
        "rougeL": {
            "precision": 0.77404,
            "recall": 0.67188,
            "fmeasure": 0.7183
        },
        "rougeLsum": {
            "precision": 0.77404,
            "recall": 0.67188,
            "fmeasure": 0.7183
        },
        "bleu": 62.97962,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9411764705882353
        },
        "bertscore": {
            "precision": 0.95269,
            "recall": 0.92672,
            "f1": 0.93924
        },
        "nubia": {
            "semantic_relation": 4.40136,
            "contradiction": 0.81816,
            "irrelevancy": 0.65198,
            "logical_agreement": 98.52986,
            "grammar_ref": 5.06568,
            "grammar_hyp": 5.30794,
            "nubia_score": 0.75388
        },
        "meteor": 0.4455636432289685,
        "bleurt": 0.36649
    },
    "totto_test_contrast_challenge_table_size-table_size_495": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 73,
        "mean_pred_length": 18.25,
        "std_pred_length": 3.344772040064913,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.7808219178082192,
        "vocab_size-1": 57,
        "unique-1": 48,
        "entropy-1": 5.658935688987375,
        "distinct-2": 1.0,
        "vocab_size-2": 69,
        "unique-2": 69,
        "entropy-2": 6.108524456778164,
        "cond_entropy-2": 0.36442290517588355,
        "distinct-3": 1.0,
        "vocab_size-3": 65,
        "unique-3": 65,
        "entropy-3": 6.022367813028458,
        "cond_entropy-3": -0.08615664374971463,
        "total_length-nopunct": 65,
        "mean_pred_length-nopunct": 16.25,
        "std_pred_length-nopunct": 3.191786333700926,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8153846153846154,
        "vocab_size-1-nopunct": 53,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.579984928379789,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 61,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.930737337562883,
        "cond_entropy-2-nopunct": 0.37976112293055453,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 57,
        "unique-3-nopunct": 57,
        "entropy-3-nopunct": 5.832890014164737,
        "cond_entropy-3-nopunct": -0.09784732339814436,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.440784339784839,
        "rouge1": {
            "precision": 0.79469,
            "recall": 0.75362,
            "fmeasure": 0.76322
        },
        "rouge2": {
            "precision": 0.53997,
            "recall": 0.56511,
            "fmeasure": 0.54169
        },
        "rougeL": {
            "precision": 0.67173,
            "recall": 0.69266,
            "fmeasure": 0.6674
        },
        "rougeLsum": {
            "precision": 0.67173,
            "recall": 0.69266,
            "fmeasure": 0.6674
        },
        "bleu": 53.65797,
        "local_recall": {
            "1": 0.16,
            "2": 0.8333333333333334,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.93851,
            "recall": 0.95214,
            "f1": 0.93836
        },
        "nubia": {
            "semantic_relation": 4.1262,
            "contradiction": 12.52858,
            "irrelevancy": 50.51794,
            "logical_agreement": 36.95348,
            "grammar_ref": 4.35502,
            "grammar_hyp": 4.94302,
            "nubia_score": 0.62505
        },
        "meteor": 0.4632025926721962,
        "bleurt": 0.27856
    },
    "totto_test_contrast_challenge_table_size-table_size_496": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 58,
        "mean_pred_length": 19.333333333333332,
        "std_pred_length": 3.6817870057290873,
        "median_pred_length": 19.0,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 44,
        "unique-1": 35,
        "entropy-1": 5.31014586563072,
        "distinct-2": 1.0,
        "vocab_size-2": 55,
        "unique-2": 55,
        "entropy-2": 5.7813597135246555,
        "cond_entropy-2": 0.414643264008976,
        "distinct-3": 1.0,
        "vocab_size-3": 52,
        "unique-3": 52,
        "entropy-3": 5.700439718141095,
        "cond_entropy-3": -0.08091999538356742,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 3.7416573867739413,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.254525464966174,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 51,
        "entropy-2-nopunct": 5.6724253419715005,
        "cond_entropy-2-nopunct": 0.4277250948796714,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 48,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.5849625007211605,
        "cond_entropy-3-nopunct": -0.08746284125033933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.083427546959082,
        "rouge1": {
            "precision": 0.76901,
            "recall": 0.76815,
            "fmeasure": 0.74897
        },
        "rouge2": {
            "precision": 0.58072,
            "recall": 0.59439,
            "fmeasure": 0.57242
        },
        "rougeL": {
            "precision": 0.7452,
            "recall": 0.75227,
            "fmeasure": 0.72992
        },
        "rougeLsum": {
            "precision": 0.7452,
            "recall": 0.75227,
            "fmeasure": 0.72992
        },
        "bleu": 59.16454,
        "local_recall": {
            "1": 0.7,
            "2": 0.0,
            "3": 0.7857142857142857
        },
        "bertscore": {
            "precision": 0.9393,
            "recall": 0.92602,
            "f1": 0.93033
        },
        "nubia": {
            "semantic_relation": 4.22082,
            "contradiction": 0.53743,
            "irrelevancy": 41.09003,
            "logical_agreement": 58.37253,
            "grammar_ref": 4.0888,
            "grammar_hyp": 3.99877,
            "nubia_score": 0.74724
        },
        "meteor": 0.4551291301085404,
        "bleurt": 0.20829
    },
    "totto_test_contrast_challenge_table_size-table_size_519": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6330370023236713,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.69841,
            "fmeasure": 0.82222
        },
        "rouge2": {
            "precision": 0.74074,
            "recall": 0.50183,
            "fmeasure": 0.59816
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.62857,
            "fmeasure": 0.74
        },
        "bleu": 42.95749,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.98201,
            "recall": 0.93212,
            "f1": 0.95641
        },
        "nubia": {
            "semantic_relation": 4.97277,
            "contradiction": 0.35627,
            "irrelevancy": 0.48729,
            "logical_agreement": 99.15644,
            "grammar_ref": 5.37123,
            "grammar_hyp": 6.85358,
            "nubia_score": 0.74277
        },
        "meteor": 0.42350497485471644,
        "bleurt": 0.45492
    },
    "totto_test_contrast_challenge_table_size-table_size_498": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.268018045783755,
        "rouge1": {
            "precision": 0.78947,
            "recall": 0.6912,
            "fmeasure": 0.73699
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.53095,
            "fmeasure": 0.56815
        },
        "rougeL": {
            "precision": 0.57895,
            "recall": 0.50649,
            "fmeasure": 0.54024
        },
        "rougeLsum": {
            "precision": 0.57895,
            "recall": 0.50649,
            "fmeasure": 0.54024
        },
        "bleu": 39.6552,
        "local_recall": {
            "1": 0.2,
            "2": 0.25,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.9245,
            "recall": 0.91825,
            "f1": 0.92136
        },
        "nubia": {
            "semantic_relation": 4.38065,
            "contradiction": 5.24279,
            "irrelevancy": 60.89885,
            "logical_agreement": 33.85837,
            "grammar_ref": 4.70322,
            "grammar_hyp": 5.27953,
            "nubia_score": 0.65659
        },
        "meteor": 0.3815392570205316,
        "bleurt": -0.0162
    },
    "totto_test_contrast_challenge_table_size-table_size_456": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.0,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 20,
        "entropy-1": 4.378783493486177,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.2777001806988724,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.315824333525706,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.3011894492467307,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8202660983645833,
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.93124,
            "fmeasure": 0.86186
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.70833,
            "fmeasure": 0.67037
        },
        "rougeL": {
            "precision": 0.70833,
            "recall": 0.78904,
            "fmeasure": 0.74181
        },
        "rougeLsum": {
            "precision": 0.70833,
            "recall": 0.78904,
            "fmeasure": 0.74181
        },
        "bleu": 53.07074,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.75,
            "3": 0.8666666666666667
        },
        "bertscore": {
            "precision": 0.94806,
            "recall": 0.94988,
            "f1": 0.94896
        },
        "nubia": {
            "semantic_relation": 4.94596,
            "contradiction": 0.51786,
            "irrelevancy": 8.91574,
            "logical_agreement": 90.5664,
            "grammar_ref": 3.96214,
            "grammar_hyp": 4.09944,
            "nubia_score": 0.91782
        },
        "meteor": 0.5061259592850477,
        "bleurt": 0.64025
    },
    "totto_test_contrast_challenge_table_size-table_size_500": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 7.0,
        "median_pred_length": 19.0,
        "min_pred_length": 12,
        "max_pred_length": 26,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 32,
        "unique-1": 26,
        "entropy-1": 4.932138039759376,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.19977526577650456,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.90625,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.8125,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.1068905956085186,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.378726781045809,
        "rouge1": {
            "precision": 0.9504,
            "recall": 0.79159,
            "fmeasure": 0.86327
        },
        "rouge2": {
            "precision": 0.72652,
            "recall": 0.60576,
            "fmeasure": 0.65989
        },
        "rougeL": {
            "precision": 0.85913,
            "recall": 0.72447,
            "fmeasure": 0.7853
        },
        "rougeLsum": {
            "precision": 0.85913,
            "recall": 0.72447,
            "fmeasure": 0.7853
        },
        "bleu": 76.3648,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.8387096774193549
        },
        "bertscore": {
            "precision": 0.9701,
            "recall": 0.94738,
            "f1": 0.95861
        },
        "nubia": {
            "semantic_relation": 3.55786,
            "contradiction": 57.24795,
            "irrelevancy": 1.77183,
            "logical_agreement": 40.98022,
            "grammar_ref": 5.38335,
            "grammar_hyp": 5.72916,
            "nubia_score": 0.50989
        },
        "meteor": 0.4744390358621937,
        "bleurt": 0.35452
    },
    "totto_test_contrast_challenge_table_size-table_size_336": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 17,
        "msttr-100": 0.685,
        "msttr-100_nopunct": 0.76,
        "total_length": 289,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.167773442493505,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 25,
        "distinct-1": 0.6020761245674741,
        "vocab_size-1": 174,
        "unique-1": 135,
        "entropy-1": 6.867914527610438,
        "distinct-2": 0.8970588235294118,
        "vocab_size-2": 244,
        "unique-2": 221,
        "entropy-2": 7.862759107872542,
        "cond_entropy-2": 0.8064122715122671,
        "distinct-3": 0.9490196078431372,
        "vocab_size-3": 242,
        "unique-3": 230,
        "entropy-3": 7.889432309399406,
        "cond_entropy-3": 0.04165345041871575,
        "total_length-nopunct": 251,
        "mean_pred_length-nopunct": 14.764705882352942,
        "std_pred_length-nopunct": 4.426250727391084,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6772908366533864,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 135,
        "entropy-1-nopunct": 7.007127693725046,
        "distinct-2-nopunct": 0.8931623931623932,
        "vocab_size-2-nopunct": 209,
        "unique-2-nopunct": 189,
        "entropy-2-nopunct": 7.634811661981834,
        "cond_entropy-2-nopunct": 0.6806543512646495,
        "distinct-3-nopunct": 0.9447004608294931,
        "vocab_size-3-nopunct": 205,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 7.647473409853876,
        "cond_entropy-3-nopunct": 0.02189862335232041,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.524672803529387,
        "rouge1": {
            "precision": 0.73057,
            "recall": 0.65527,
            "fmeasure": 0.67391
        },
        "rouge2": {
            "precision": 0.49064,
            "recall": 0.44311,
            "fmeasure": 0.45424
        },
        "rougeL": {
            "precision": 0.62253,
            "recall": 0.5774,
            "fmeasure": 0.58243
        },
        "rougeLsum": {
            "precision": 0.62253,
            "recall": 0.5774,
            "fmeasure": 0.58243
        },
        "bleu": 39.56658,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.4,
            "3": 0.6721311475409836
        },
        "bertscore": {
            "precision": 0.91714,
            "recall": 0.90632,
            "f1": 0.90876
        },
        "nubia": {
            "semantic_relation": 4.06739,
            "contradiction": 5.82338,
            "irrelevancy": 29.41519,
            "logical_agreement": 64.76142,
            "grammar_ref": 4.33068,
            "grammar_hyp": 4.40248,
            "nubia_score": 0.6854
        },
        "meteor": 0.3573722725785565,
        "bleurt": 0.16323
    },
    "totto_test_contrast_challenge_table_size-table_size_370": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.7,
        "msttr-100_nopunct": NaN,
        "total_length": 110,
        "mean_pred_length": 15.714285714285714,
        "std_pred_length": 1.749635530559413,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7090909090909091,
        "vocab_size-1": 78,
        "unique-1": 67,
        "entropy-1": 5.959338037274026,
        "distinct-2": 0.9611650485436893,
        "vocab_size-2": 99,
        "unique-2": 96,
        "entropy-2": 6.601501619395239,
        "cond_entropy-2": 0.5072380217265535,
        "distinct-3": 0.9895833333333334,
        "vocab_size-3": 95,
        "unique-3": 94,
        "entropy-3": 6.5641291673878275,
        "cond_entropy-3": -0.031174614981192856,
        "total_length-nopunct": 94,
        "mean_pred_length-nopunct": 13.428571428571429,
        "std_pred_length-nopunct": 1.178030178747903,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.776595744680851,
        "vocab_size-1-nopunct": 73,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.94649034679752,
        "distinct-2-nopunct": 0.9540229885057471,
        "vocab_size-2-nopunct": 83,
        "unique-2-nopunct": 80,
        "entropy-2-nopunct": 6.342312605019259,
        "cond_entropy-2-nopunct": 0.4447497241316281,
        "distinct-3-nopunct": 0.9875,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.296928094887357,
        "cond_entropy-3-nopunct": -0.036579307184322826,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.076425374406398,
        "rouge1": {
            "precision": 0.90454,
            "recall": 0.86132,
            "fmeasure": 0.8792
        },
        "rouge2": {
            "precision": 0.7111,
            "recall": 0.67408,
            "fmeasure": 0.68992
        },
        "rougeL": {
            "precision": 0.7846,
            "recall": 0.75255,
            "fmeasure": 0.76556
        },
        "rougeLsum": {
            "precision": 0.7846,
            "recall": 0.75255,
            "fmeasure": 0.76556
        },
        "bleu": 62.21601,
        "local_recall": {
            "1": 0.07692307692307693,
            "2": 0.3333333333333333,
            "3": 0.8681318681318682
        },
        "bertscore": {
            "precision": 0.97645,
            "recall": 0.97389,
            "f1": 0.97496
        },
        "nubia": {
            "semantic_relation": 4.71466,
            "contradiction": 0.35395,
            "irrelevancy": 6.08284,
            "logical_agreement": 93.56321,
            "grammar_ref": 4.9924,
            "grammar_hyp": 5.09103,
            "nubia_score": 0.87919
        },
        "meteor": 0.46745376607119105,
        "bleurt": 0.57888
    },
    "totto_test_contrast_challenge_table_size-table_size_427": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.6792452830188679,
        "vocab_size-1": 36,
        "unique-1": 28,
        "entropy-1": 4.914346577605389,
        "distinct-2": 0.94,
        "vocab_size-2": 47,
        "unique-2": 44,
        "entropy-2": 5.523856189774728,
        "cond_entropy-2": 0.5632262947435311,
        "distinct-3": 1.0,
        "vocab_size-3": 47,
        "unique-3": 47,
        "entropy-3": 5.55458885167764,
        "cond_entropy-3": 0.03839223637099784,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6938775510204082,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.831760293572345,
        "distinct-2-nopunct": 0.9347826086956522,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 40,
        "entropy-2-nopunct": 5.393127173448314,
        "cond_entropy-2-nopunct": 0.6124288070852886,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": 0.042237682366015106,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.5299980789394825,
        "rouge1": {
            "precision": 0.65152,
            "recall": 0.69635,
            "fmeasure": 0.67106
        },
        "rouge2": {
            "precision": 0.3867,
            "recall": 0.44932,
            "fmeasure": 0.4124
        },
        "rougeL": {
            "precision": 0.46061,
            "recall": 0.54335,
            "fmeasure": 0.49545
        },
        "rougeLsum": {
            "precision": 0.46061,
            "recall": 0.54335,
            "fmeasure": 0.49545
        },
        "bleu": 42.30422,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.46153846153846156,
            "3": 0.7333333333333333
        },
        "bertscore": {
            "precision": 0.89778,
            "recall": 0.92259,
            "f1": 0.90904
        },
        "nubia": {
            "semantic_relation": 4.00918,
            "contradiction": 32.27956,
            "irrelevancy": 31.33241,
            "logical_agreement": 36.38804,
            "grammar_ref": 4.38609,
            "grammar_hyp": 3.80487,
            "nubia_score": 0.69523
        },
        "meteor": 0.39538054993504607,
        "bleurt": 0.30752
    },
    "totto_test_contrast_challenge_table_size-table_size_371": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.12385402685271857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.42447745543913,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.71282,
            "fmeasure": 0.71264
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.49405,
            "fmeasure": 0.4963
        },
        "rougeL": {
            "precision": 0.39286,
            "recall": 0.39231,
            "fmeasure": 0.39208
        },
        "rougeLsum": {
            "precision": 0.39286,
            "recall": 0.39231,
            "fmeasure": 0.39208
        },
        "bleu": 38.70605,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.7272727272727273
        },
        "bertscore": {
            "precision": 0.90059,
            "recall": 0.83669,
            "f1": 0.86746
        },
        "nubia": {
            "semantic_relation": 3.97151,
            "contradiction": 0.23985,
            "irrelevancy": 0.5844,
            "logical_agreement": 99.17575,
            "grammar_ref": 4.56931,
            "grammar_hyp": 4.64101,
            "nubia_score": 0.67986
        },
        "meteor": 0.3823328123841248,
        "bleurt": 0.0802
    },
    "totto_test_contrast_challenge_table_size-table_size_339": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1109184685925126,
        "rouge1": {
            "precision": 0.58824,
            "recall": 0.47619,
            "fmeasure": 0.52632
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.29524,
            "fmeasure": 0.33033
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.33333,
            "fmeasure": 0.36842
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.33333,
            "fmeasure": 0.36842
        },
        "bleu": 10.81119,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.4666666666666667
        },
        "bertscore": {
            "precision": 0.89046,
            "recall": 0.83972,
            "f1": 0.86434
        },
        "nubia": {
            "semantic_relation": 3.69586,
            "contradiction": 0.11362,
            "irrelevancy": 99.56948,
            "logical_agreement": 0.3169,
            "grammar_ref": 3.42286,
            "grammar_hyp": 5.01105,
            "nubia_score": 0.46867
        },
        "meteor": 0.27804235661321447,
        "bleurt": -0.1094
    },
    "totto_test_contrast_challenge_table_size-table_size_520": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.79,
        "msttr-100_nopunct": NaN,
        "total_length": 113,
        "mean_pred_length": 16.142857142857142,
        "std_pred_length": 3.6811710647786073,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 22,
        "distinct-1": 0.7699115044247787,
        "vocab_size-1": 87,
        "unique-1": 76,
        "entropy-1": 6.1875776928987065,
        "distinct-2": 1.0,
        "vocab_size-2": 106,
        "unique-2": 106,
        "entropy-2": 6.727920454563184,
        "cond_entropy-2": 0.3840051096514453,
        "distinct-3": 1.0,
        "vocab_size-3": 99,
        "unique-3": 99,
        "entropy-3": 6.62935662007962,
        "cond_entropy-3": -0.09856383448358966,
        "total_length-nopunct": 99,
        "mean_pred_length-nopunct": 14.142857142857142,
        "std_pred_length-nopunct": 3.870347766898305,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8484848484848485,
        "vocab_size-1-nopunct": 84,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.266989923302576,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 92,
        "entropy-2-nopunct": 6.523561956057027,
        "cond_entropy-2-nopunct": 0.28414341185704706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 85,
        "unique-3-nopunct": 85,
        "entropy-3-nopunct": 6.409390936137707,
        "cond_entropy-3-nopunct": -0.11417101991931088,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.838052114676569,
        "rouge1": {
            "precision": 0.73838,
            "recall": 0.73059,
            "fmeasure": 0.7253
        },
        "rouge2": {
            "precision": 0.52505,
            "recall": 0.53028,
            "fmeasure": 0.52317
        },
        "rougeL": {
            "precision": 0.65086,
            "recall": 0.64323,
            "fmeasure": 0.63923
        },
        "rougeLsum": {
            "precision": 0.65086,
            "recall": 0.64323,
            "fmeasure": 0.63923
        },
        "bleu": 43.49779,
        "local_recall": {
            "1": 0.2631578947368421,
            "2": 0.42857142857142855,
            "3": 0.782608695652174
        },
        "bertscore": {
            "precision": 0.92508,
            "recall": 0.92614,
            "f1": 0.91997
        },
        "nubia": {
            "semantic_relation": 3.89024,
            "contradiction": 17.67478,
            "irrelevancy": 56.92785,
            "logical_agreement": 25.39736,
            "grammar_ref": 4.63553,
            "grammar_hyp": 4.39637,
            "nubia_score": 0.666
        },
        "meteor": 0.3648244748417095,
        "bleurt": 0.33611
    },
    "totto_test_contrast_challenge_table_size-table_size_372": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.632993161855452,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8787878787878788,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.779094498080775,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": -0.004170190416601392,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.15200309344505,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.664497779200462,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": -0.04349873228287958,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9348000833356742,
        "rouge1": {
            "precision": 0.90606,
            "recall": 0.59865,
            "fmeasure": 0.68505
        },
        "rouge2": {
            "precision": 0.71852,
            "recall": 0.43512,
            "fmeasure": 0.50664
        },
        "rougeL": {
            "precision": 0.87273,
            "recall": 0.57843,
            "fmeasure": 0.65988
        },
        "rougeLsum": {
            "precision": 0.87273,
            "recall": 0.57843,
            "fmeasure": 0.65988
        },
        "bleu": 34.15579,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6153846153846154,
            "3": 0.5185185185185185
        },
        "bertscore": {
            "precision": 0.94621,
            "recall": 0.8729,
            "f1": 0.90577
        },
        "nubia": {
            "semantic_relation": 4.11933,
            "contradiction": 1.21153,
            "irrelevancy": 8.94315,
            "logical_agreement": 89.84531,
            "grammar_ref": 4.97796,
            "grammar_hyp": 5.79222,
            "nubia_score": 0.59473
        },
        "meteor": 0.31659916811838473,
        "bleurt": 0.23908
    },
    "totto_test_contrast_challenge_table_size-table_size_340": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 153,
        "mean_pred_length": 19.125,
        "std_pred_length": 6.450532923720334,
        "median_pred_length": 21.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.6535947712418301,
        "vocab_size-1": 100,
        "unique-1": 74,
        "entropy-1": 6.349480225564634,
        "distinct-2": 0.903448275862069,
        "vocab_size-2": 131,
        "unique-2": 119,
        "entropy-2": 6.973012538290816,
        "cond_entropy-2": 0.5380962884683609,
        "distinct-3": 0.9635036496350365,
        "vocab_size-3": 132,
        "unique-3": 127,
        "entropy-3": 7.025039382230585,
        "cond_entropy-3": 0.049509854259460945,
        "total_length-nopunct": 134,
        "mean_pred_length-nopunct": 16.75,
        "std_pred_length-nopunct": 5.80409338312195,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7089552238805971,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 73,
        "entropy-1-nopunct": 6.333708850999436,
        "distinct-2-nopunct": 0.9206349206349206,
        "vocab_size-2-nopunct": 116,
        "unique-2-nopunct": 108,
        "entropy-2-nopunct": 6.80267674889675,
        "cond_entropy-2-nopunct": 0.4916587131010143,
        "distinct-3-nopunct": 0.9745762711864406,
        "vocab_size-3-nopunct": 115,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 6.831795591734713,
        "cond_entropy-3-nopunct": 0.02400719365853496,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.578193653751509,
        "rouge1": {
            "precision": 0.80897,
            "recall": 0.83816,
            "fmeasure": 0.81624
        },
        "rouge2": {
            "precision": 0.62141,
            "recall": 0.62426,
            "fmeasure": 0.61624
        },
        "rougeL": {
            "precision": 0.70913,
            "recall": 0.74467,
            "fmeasure": 0.71826
        },
        "rougeLsum": {
            "precision": 0.70913,
            "recall": 0.74467,
            "fmeasure": 0.71826
        },
        "bleu": 53.00839,
        "local_recall": {
            "1": 0.125,
            "2": 0.55,
            "3": 0.8712871287128713
        },
        "bertscore": {
            "precision": 0.94425,
            "recall": 0.94855,
            "f1": 0.94572
        },
        "nubia": {
            "semantic_relation": 4.59383,
            "contradiction": 1.29295,
            "irrelevancy": 32.86861,
            "logical_agreement": 65.83844,
            "grammar_ref": 4.58534,
            "grammar_hyp": 4.34199,
            "nubia_score": 0.90409
        },
        "meteor": 0.4592224777969752,
        "bleurt": 0.52663
    },
    "totto_test_contrast_challenge_table_size-table_size_428": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.728440861296354,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.39683,
            "fmeasure": 0.41071
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.675,
            "fmeasure": 0.70833
        },
        "bleu": 51.3345,
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "bertscore": {
            "precision": 0.95461,
            "recall": 0.9542,
            "f1": 0.95441
        },
        "nubia": {
            "semantic_relation": 3.8356,
            "contradiction": 0.29358,
            "irrelevancy": 2.30585,
            "logical_agreement": 97.40056,
            "grammar_ref": 6.57359,
            "grammar_hyp": 6.42103,
            "nubia_score": 0.64627
        },
        "meteor": 0.4099828269763827,
        "bleurt": 0.49581
    },
    "totto_test_contrast_challenge_table_size-table_size_342": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 10.8,
        "std_pred_length": 2.9257477676655586,
        "median_pred_length": 11.0,
        "min_pred_length": 6,
        "max_pred_length": 15,
        "distinct-1": 0.7962962962962963,
        "vocab_size-1": 43,
        "unique-1": 36,
        "entropy-1": 5.266655502596796,
        "distinct-2": 1.0,
        "vocab_size-2": 49,
        "unique-2": 49,
        "entropy-2": 5.614709844115208,
        "cond_entropy-2": 0.16094249505711677,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.15527822547791104,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 9.4,
        "std_pred_length-nopunct": 2.5768197453450252,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8723404255319149,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.283208266525226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.3923174227787625,
        "cond_entropy-2-nopunct": 0.1414163687716816,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 37,
        "unique-3-nopunct": 37,
        "entropy-3-nopunct": 5.209453365628954,
        "cond_entropy-3-nopunct": -0.18286405714981083,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.2853986574711325,
        "rouge1": {
            "precision": 0.76611,
            "recall": 0.76328,
            "fmeasure": 0.76289
        },
        "rouge2": {
            "precision": 0.44648,
            "recall": 0.41721,
            "fmeasure": 0.43055
        },
        "rougeL": {
            "precision": 0.71716,
            "recall": 0.71302,
            "fmeasure": 0.71342
        },
        "rougeLsum": {
            "precision": 0.71716,
            "recall": 0.71302,
            "fmeasure": 0.71342
        },
        "bleu": 35.0951,
        "local_recall": {
            "1": 0.0,
            "2": 0.625,
            "3": 0.7894736842105263
        },
        "bertscore": {
            "precision": 0.93481,
            "recall": 0.9287,
            "f1": 0.93169
        },
        "nubia": {
            "semantic_relation": 4.23793,
            "contradiction": 10.55769,
            "irrelevancy": 42.89197,
            "logical_agreement": 46.55035,
            "grammar_ref": 5.90284,
            "grammar_hyp": 5.75963,
            "nubia_score": 0.73042
        },
        "meteor": 0.40529429862675076,
        "bleurt": 0.32634
    },
    "totto_test_contrast_challenge_table_size-table_size_375": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.68,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.123105625617661,
        "median_pred_length": 12.5,
        "min_pred_length": 7,
        "max_pred_length": 21,
        "distinct-1": 0.6826923076923077,
        "vocab_size-1": 71,
        "unique-1": 54,
        "entropy-1": 5.8794389682828845,
        "distinct-2": 0.8854166666666666,
        "vocab_size-2": 85,
        "unique-2": 75,
        "entropy-2": 6.347932422573624,
        "cond_entropy-2": 0.2869101834455924,
        "distinct-3": 0.9431818181818182,
        "vocab_size-3": 83,
        "unique-3": 78,
        "entropy-3": 6.345795255000941,
        "cond_entropy-3": 0.019411021349816676,
        "total_length-nopunct": 87,
        "mean_pred_length-nopunct": 10.875,
        "std_pred_length-nopunct": 3.6890886408434267,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7701149425287356,
        "vocab_size-1-nopunct": 67,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.916800535954272,
        "distinct-2-nopunct": 0.9113924050632911,
        "vocab_size-2-nopunct": 72,
        "unique-2-nopunct": 66,
        "entropy-2-nopunct": 6.117010020301618,
        "cond_entropy-2-nopunct": 0.24083155623538569,
        "distinct-3-nopunct": 0.9577464788732394,
        "vocab_size-3-nopunct": 68,
        "unique-3-nopunct": 65,
        "entropy-3-nopunct": 6.065240077251156,
        "cond_entropy-3-nopunct": -0.030725353994062225,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.550704966563306,
        "rouge1": {
            "precision": 0.89798,
            "recall": 0.76865,
            "fmeasure": 0.81133
        },
        "rouge2": {
            "precision": 0.63429,
            "recall": 0.54076,
            "fmeasure": 0.57046
        },
        "rougeL": {
            "precision": 0.73718,
            "recall": 0.63323,
            "fmeasure": 0.66531
        },
        "rougeLsum": {
            "precision": 0.73718,
            "recall": 0.63323,
            "fmeasure": 0.66531
        },
        "bleu": 45.66894,
        "local_recall": {
            "1": 0.21621621621621623,
            "2": 0.7666666666666667,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.95036,
            "recall": 0.93501,
            "f1": 0.94089
        },
        "nubia": {
            "semantic_relation": 4.44418,
            "contradiction": 4.60284,
            "irrelevancy": 6.24529,
            "logical_agreement": 89.15187,
            "grammar_ref": 5.34109,
            "grammar_hyp": 5.39516,
            "nubia_score": 0.78137
        },
        "meteor": 0.42406150690271877,
        "bleurt": 0.3824
    },
    "totto_test_contrast_challenge_table_size-table_size_545": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.92,
        "vocab_size-1": 23,
        "unique-1": 21,
        "entropy-1": 4.4838561897747224,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.03333771197858132,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9565217391304348,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.436605434317882,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.036006438040157185,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.162799217572684,
        "rouge1": {
            "precision": 0.91288,
            "recall": 0.92803,
            "fmeasure": 0.91958
        },
        "rouge2": {
            "precision": 0.79242,
            "recall": 0.8197,
            "fmeasure": 0.80541
        },
        "rougeL": {
            "precision": 0.91288,
            "recall": 0.92803,
            "fmeasure": 0.91958
        },
        "rougeLsum": {
            "precision": 0.91288,
            "recall": 0.92803,
            "fmeasure": 0.91958
        },
        "bleu": 81.13858,
        "local_recall": {
            "1": 0.1,
            "2": 1.0,
            "3": 0.9473684210526315
        },
        "bertscore": {
            "precision": 0.99039,
            "recall": 0.99213,
            "f1": 0.98844
        },
        "nubia": {
            "semantic_relation": 4.98412,
            "contradiction": 0.50193,
            "irrelevancy": 2.12591,
            "logical_agreement": 97.37216,
            "grammar_ref": 5.62679,
            "grammar_hyp": 5.44517,
            "nubia_score": 0.97207
        },
        "meteor": 0.5186741795198915,
        "bleurt": 0.81821
    },
    "totto_test_contrast_challenge_table_size-table_size_522": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.770721208389991,
        "rouge1": {
            "precision": 0.97222,
            "recall": 0.84455,
            "fmeasure": 0.9019
        },
        "rouge2": {
            "precision": 0.84848,
            "recall": 0.73333,
            "fmeasure": 0.78484
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.80288,
            "fmeasure": 0.85429
        },
        "bleu": 80.52254,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.9166666666666666
        },
        "bertscore": {
            "precision": 0.99811,
            "recall": 0.98882,
            "f1": 0.99345
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.11768,
            "irrelevancy": 0.47514,
            "logical_agreement": 99.40718,
            "grammar_ref": 4.55634,
            "grammar_hyp": 4.71917,
            "nubia_score": 0.98117
        },
        "meteor": 0.5469432736955866,
        "bleurt": 0.74939
    },
    "totto_test_contrast_challenge_table_size-table_size_343": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.75,
        "total_length": 112,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 19.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 80,
        "unique-1": 67,
        "entropy-1": 6.004556681001926,
        "distinct-2": 0.9716981132075472,
        "vocab_size-2": 103,
        "unique-2": 100,
        "entropy-2": 6.671316680978279,
        "cond_entropy-2": 0.5658827777311437,
        "distinct-3": 1.0,
        "vocab_size-3": 100,
        "unique-3": 100,
        "entropy-3": 6.6438561897747395,
        "cond_entropy-3": -0.024064264788474524,
        "total_length-nopunct": 101,
        "mean_pred_length-nopunct": 16.833333333333332,
        "std_pred_length-nopunct": 1.863389981249825,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7524752475247525,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 5.968619992734512,
        "distinct-2-nopunct": 0.968421052631579,
        "vocab_size-2-nopunct": 92,
        "unique-2-nopunct": 89,
        "entropy-2-nopunct": 6.5066977135941055,
        "cond_entropy-2-nopunct": 0.5711045518080425,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 89,
        "unique-3-nopunct": 89,
        "entropy-3-nopunct": 6.47573343096641,
        "cond_entropy-3-nopunct": -0.026706447027471325,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9591322580698436,
        "rouge1": {
            "precision": 0.62172,
            "recall": 0.81778,
            "fmeasure": 0.69658
        },
        "rouge2": {
            "precision": 0.3994,
            "recall": 0.53391,
            "fmeasure": 0.44816
        },
        "rougeL": {
            "precision": 0.47142,
            "recall": 0.61605,
            "fmeasure": 0.52539
        },
        "rougeLsum": {
            "precision": 0.47142,
            "recall": 0.61605,
            "fmeasure": 0.52539
        },
        "bleu": 33.40087,
        "local_recall": {
            "1": 0.4,
            "2": 0.5,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.87137,
            "recall": 0.91497,
            "f1": 0.89216
        },
        "nubia": {
            "semantic_relation": 3.98701,
            "contradiction": 3.11516,
            "irrelevancy": 61.92064,
            "logical_agreement": 34.9642,
            "grammar_ref": 4.25456,
            "grammar_hyp": 4.03061,
            "nubia_score": 0.69312
        },
        "meteor": 0.4207279883622006,
        "bleurt": -0.05586
    },
    "totto_test_contrast_challenge_table_size-table_size_524": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4656555564613205,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.7,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "bleu": 73.98067,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.98612,
            "recall": 0.93682,
            "f1": 0.96084
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24845,
            "irrelevancy": 0.45905,
            "logical_agreement": 99.29249,
            "grammar_ref": 4.055,
            "grammar_hyp": 4.62386,
            "nubia_score": 0.98742
        },
        "meteor": 0.45030454326165953,
        "bleurt": 0.65906
    },
    "totto_test_contrast_challenge_table_size-table_size_300": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 29,
        "msttr-100": 0.72,
        "msttr-100_nopunct": 0.79,
        "total_length": 478,
        "mean_pred_length": 16.482758620689655,
        "std_pred_length": 4.72426377884225,
        "median_pred_length": 17.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.5564853556485355,
        "vocab_size-1": 266,
        "unique-1": 207,
        "entropy-1": 7.293983904750476,
        "distinct-2": 0.9086859688195991,
        "vocab_size-2": 408,
        "unique-2": 381,
        "entropy-2": 8.596231253989444,
        "cond_entropy-2": 1.1201040121237587,
        "distinct-3": 0.9714285714285714,
        "vocab_size-3": 408,
        "unique-3": 397,
        "entropy-3": 8.65530530932765,
        "cond_entropy-3": 0.054826129247271316,
        "total_length-nopunct": 408,
        "mean_pred_length-nopunct": 14.068965517241379,
        "std_pred_length-nopunct": 3.947334626552878,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6372549019607843,
        "vocab_size-1-nopunct": 260,
        "unique-1-nopunct": 206,
        "entropy-1-nopunct": 7.475830113388299,
        "distinct-2-nopunct": 0.9261213720316622,
        "vocab_size-2-nopunct": 351,
        "unique-2-nopunct": 332,
        "entropy-2-nopunct": 8.393273184726821,
        "cond_entropy-2-nopunct": 0.9869982471328879,
        "distinct-3-nopunct": 0.9828571428571429,
        "vocab_size-3-nopunct": 344,
        "unique-3-nopunct": 338,
        "entropy-3-nopunct": 8.416925397546636,
        "cond_entropy-3-nopunct": 0.037968340676562726,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.9295554138945015,
        "rouge1": {
            "precision": 0.82692,
            "recall": 0.78278,
            "fmeasure": 0.79269
        },
        "rouge2": {
            "precision": 0.6453,
            "recall": 0.60975,
            "fmeasure": 0.61934
        },
        "rougeL": {
            "precision": 0.75821,
            "recall": 0.70553,
            "fmeasure": 0.72094
        },
        "rougeLsum": {
            "precision": 0.75821,
            "recall": 0.70553,
            "fmeasure": 0.72094
        },
        "bleu": 54.77529,
        "local_recall": {
            "1": 0.25,
            "2": 0.3880597014925373,
            "3": 0.8023598820058997
        },
        "bertscore": {
            "precision": 0.94615,
            "recall": 0.94121,
            "f1": 0.94237
        },
        "nubia": {
            "semantic_relation": 4.30933,
            "contradiction": 18.55165,
            "irrelevancy": 15.21276,
            "logical_agreement": 66.23559,
            "grammar_ref": 4.69712,
            "grammar_hyp": 4.71328,
            "nubia_score": 0.77443
        },
        "meteor": 0.430095522408955,
        "bleurt": 0.43863
    },
    "totto_test_contrast_challenge_table_size-table_size_429": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 9.333333333333334,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 10.0,
        "min_pred_length": 6,
        "max_pred_length": 12,
        "distinct-1": 0.8214285714285714,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.423251796980338,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.0765012677171204,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1844245711374276,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 7.666666666666667,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": -0.0016338611696506689,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.23446525363702278,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.62703863841022,
        "rouge1": {
            "precision": 0.89177,
            "recall": 0.80366,
            "fmeasure": 0.83208
        },
        "rouge2": {
            "precision": 0.64444,
            "recall": 0.54762,
            "fmeasure": 0.57958
        },
        "rougeL": {
            "precision": 0.73593,
            "recall": 0.64176,
            "fmeasure": 0.67335
        },
        "rougeLsum": {
            "precision": 0.73593,
            "recall": 0.64176,
            "fmeasure": 0.67335
        },
        "bleu": 44.96392,
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.8636363636363636
        },
        "bertscore": {
            "precision": 0.96124,
            "recall": 0.95045,
            "f1": 0.95467
        },
        "nubia": {
            "semantic_relation": 4.39462,
            "contradiction": 0.25576,
            "irrelevancy": 9.72085,
            "logical_agreement": 90.02338,
            "grammar_ref": 5.1114,
            "grammar_hyp": 5.28601,
            "nubia_score": 0.78012
        },
        "meteor": 0.41445848912733485,
        "bleurt": 0.35909
    },
    "totto_test_contrast_challenge_table_size-table_size_588": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.7058823529411765,
        "vocab_size-1": 12,
        "unique-1": 8,
        "entropy-1": 3.4548223999466066,
        "distinct-2": 0.9375,
        "vocab_size-2": 15,
        "unique-2": 14,
        "entropy-2": 3.875,
        "cond_entropy-2": 0.45971762763487756,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.189898095464287,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.5258134337464763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4464970654269704,
        "rouge1": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.69697,
            "fmeasure": 0.60399
        },
        "rougeL": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "rougeLsum": {
            "precision": 0.59375,
            "recall": 0.75962,
            "fmeasure": 0.66626
        },
        "bleu": 46.82569,
        "local_recall": {
            "1": 0,
            "2": 0.7
        },
        "bertscore": {
            "precision": 0.93185,
            "recall": 0.93448,
            "f1": 0.93316
        },
        "nubia": {
            "semantic_relation": 2.9959,
            "contradiction": 43.26576,
            "irrelevancy": 56.37678,
            "logical_agreement": 0.35746,
            "grammar_ref": 3.96979,
            "grammar_hyp": 2.9488,
            "nubia_score": 0.46831
        },
        "meteor": 0.41454417488944134,
        "bleurt": 0.45218
    },
    "totto_test_contrast_challenge_table_size-table_size_301": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 0.5,
        "median_pred_length": 15.5,
        "min_pred_length": 15,
        "max_pred_length": 16,
        "distinct-1": 0.8709677419354839,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.6717805845106355,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.06774632274633388,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.02901941889002935,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.625053839880556,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.0730134515604695,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743938,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.942597123095626,
        "rouge1": {
            "precision": 0.75972,
            "recall": 0.80096,
            "fmeasure": 0.77149
        },
        "rouge2": {
            "precision": 0.67619,
            "recall": 0.65,
            "fmeasure": 0.65793
        },
        "rougeL": {
            "precision": 0.72847,
            "recall": 0.76272,
            "fmeasure": 0.73779
        },
        "rougeLsum": {
            "precision": 0.72847,
            "recall": 0.76272,
            "fmeasure": 0.73779
        },
        "bleu": 67.63818,
        "local_recall": {
            "1": 0.375,
            "2": 0.5,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.94665,
            "recall": 0.95589,
            "f1": 0.94643
        },
        "nubia": {
            "semantic_relation": 4.09868,
            "contradiction": 42.81902,
            "irrelevancy": 14.41539,
            "logical_agreement": 42.7656,
            "grammar_ref": 4.37461,
            "grammar_hyp": 4.21449,
            "nubia_score": 0.6789
        },
        "meteor": 0.5006906498880889,
        "bleurt": 0.34254
    },
    "totto_test_contrast_challenge_table_size-table_size_549": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 0.5,
        "median_pred_length": 16.5,
        "min_pred_length": 16,
        "max_pred_length": 17,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 27,
        "unique-1": 22,
        "entropy-1": 4.6578823768686535,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.21899452976136247,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.640223928941852,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5132570955621936,
        "rouge1": {
            "precision": 0.69643,
            "recall": 0.71291,
            "fmeasure": 0.70437
        },
        "rouge2": {
            "precision": 0.28718,
            "recall": 0.35556,
            "fmeasure": 0.31365
        },
        "rougeL": {
            "precision": 0.53125,
            "recall": 0.63025,
            "fmeasure": 0.57057
        },
        "rougeLsum": {
            "precision": 0.53125,
            "recall": 0.63025,
            "fmeasure": 0.57057
        },
        "bleu": 18.64488,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.7391304347826086
        },
        "bertscore": {
            "precision": 0.91249,
            "recall": 0.94055,
            "f1": 0.9255
        },
        "nubia": {
            "semantic_relation": 4.06851,
            "contradiction": 0.22021,
            "irrelevancy": 70.22553,
            "logical_agreement": 29.55426,
            "grammar_ref": 4.72797,
            "grammar_hyp": 4.62585,
            "nubia_score": 0.68705
        },
        "meteor": 0.40156851316333825,
        "bleurt": 0.1656
    },
    "totto_test_contrast_challenge_table_size-table_size_525": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.666091017402172,
        "rouge1": {
            "precision": 0.41176,
            "recall": 0.53472,
            "fmeasure": 0.46325
        },
        "rouge2": {
            "precision": 0.0625,
            "recall": 0.08283,
            "fmeasure": 0.07089
        },
        "rougeL": {
            "precision": 0.23529,
            "recall": 0.30556,
            "fmeasure": 0.26472
        },
        "rougeLsum": {
            "precision": 0.23529,
            "recall": 0.30556,
            "fmeasure": 0.26472
        },
        "bleu": 9.10744,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.45454545454545453
        },
        "bertscore": {
            "precision": 0.84607,
            "recall": 0.85551,
            "f1": 0.84305
        },
        "nubia": {
            "semantic_relation": 4.03817,
            "contradiction": 0.3053,
            "irrelevancy": 26.40776,
            "logical_agreement": 73.28694,
            "grammar_ref": 5.53377,
            "grammar_hyp": 4.61852,
            "nubia_score": 0.75662
        },
        "meteor": 0.23161134863335364,
        "bleurt": -0.15531
    },
    "totto_test_contrast_challenge_table_size-table_size_590": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 17,
        "distinct-1": 0.7608695652173914,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 4.941933966879544,
        "distinct-2": 0.9767441860465116,
        "vocab_size-2": 42,
        "unique-2": 41,
        "entropy-2": 5.379753126795121,
        "cond_entropy-2": 0.36781907771485217,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.0543366598147358,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 1.4142135623730951,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 4.868507898969238,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.234120167580196,
        "cond_entropy-2-nopunct": 0.40590530890400106,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.059921661864380284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.065735998337085,
        "rouge1": {
            "precision": 0.64227,
            "recall": 0.8412,
            "fmeasure": 0.72287
        },
        "rouge2": {
            "precision": 0.37365,
            "recall": 0.5192,
            "fmeasure": 0.42854
        },
        "rougeL": {
            "precision": 0.55033,
            "recall": 0.7409,
            "fmeasure": 0.62533
        },
        "rougeLsum": {
            "precision": 0.55033,
            "recall": 0.7409,
            "fmeasure": 0.62533
        },
        "bleu": 35.96155,
        "local_recall": {
            "1": 0.5,
            "2": 0.8666666666666667,
            "3": 0.8461538461538461
        },
        "bertscore": {
            "precision": 0.87258,
            "recall": 0.93542,
            "f1": 0.90057
        },
        "nubia": {
            "semantic_relation": 4.12176,
            "contradiction": 10.51688,
            "irrelevancy": 46.05475,
            "logical_agreement": 43.42836,
            "grammar_ref": 4.63208,
            "grammar_hyp": 4.14549,
            "nubia_score": 0.72639
        },
        "meteor": 0.4209973122527729,
        "bleurt": 0.2694
    },
    "totto_test_contrast_challenge_table_size-table_size_459": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 17.5,
        "std_pred_length": 5.5,
        "median_pred_length": 17.5,
        "min_pred_length": 12,
        "max_pred_length": 23,
        "distinct-1": 0.7714285714285715,
        "vocab_size-1": 27,
        "unique-1": 20,
        "entropy-1": 4.65057194545458,
        "distinct-2": 0.9696969696969697,
        "vocab_size-2": 32,
        "unique-2": 31,
        "entropy-2": 4.9837880587523955,
        "cond_entropy-2": 0.3016228449032889,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.025681679939320093,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 5.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.481727678869737,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.24885316581206662,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.02999212699343525,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.2554159741812,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "rouge2": {
            "precision": 0.91503,
            "recall": 0.82105,
            "fmeasure": 0.8655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90455,
            "fmeasure": 0.94987
        },
        "bleu": 90.71221,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.9583333333333334
        },
        "bertscore": {
            "precision": 0.99403,
            "recall": 0.98475,
            "f1": 0.98936
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51628,
            "irrelevancy": 0.65538,
            "logical_agreement": 98.82834,
            "grammar_ref": 3.53925,
            "grammar_hyp": 3.52589,
            "nubia_score": 0.98378
        },
        "meteor": 0.5473198792718016,
        "bleurt": 0.79193
    },
    "totto_test_contrast_challenge_table_size-table_size_550": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 1.0,
        "median_pred_length": 21.0,
        "min_pred_length": 20,
        "max_pred_length": 22,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 36,
        "unique-1": 32,
        "entropy-1": 5.07065611315193,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.1673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.021369002496408353,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8717948717948718,
        "vocab_size-1-nopunct": 34,
        "unique-1-nopunct": 31,
        "entropy-1-nopunct": 4.9902797828538645,
        "distinct-2-nopunct": 0.972972972972973,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.155399311574899,
        "cond_entropy-2-nopunct": 0.1810720928295913,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 35,
        "entropy-3-nopunct": 5.129283016944964,
        "cond_entropy-3-nopunct": -0.0230274915411262,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.725586943117544,
        "rouge1": {
            "precision": 0.81537,
            "recall": 0.78356,
            "fmeasure": 0.79776
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.61299,
            "fmeasure": 0.62451
        },
        "rougeL": {
            "precision": 0.61445,
            "recall": 0.60246,
            "fmeasure": 0.60742
        },
        "rougeLsum": {
            "precision": 0.61445,
            "recall": 0.60246,
            "fmeasure": 0.60742
        },
        "bleu": 53.68568,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666,
            "3": 0.7857142857142857
        },
        "bertscore": {
            "precision": 0.95199,
            "recall": 0.93648,
            "f1": 0.94412
        },
        "nubia": {
            "semantic_relation": 4.25623,
            "contradiction": 0.33828,
            "irrelevancy": 16.46777,
            "logical_agreement": 83.19395,
            "grammar_ref": 4.42501,
            "grammar_hyp": 4.36966,
            "nubia_score": 0.70512
        },
        "meteor": 0.44495962927759947,
        "bleurt": 0.26603
    },
    "totto_test_contrast_challenge_table_size-table_size_592": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.35896469898143,
        "rouge1": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "rouge2": {
            "precision": 0.59259,
            "recall": 0.79365,
            "fmeasure": 0.67778
        },
        "rougeL": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "rougeLsum": {
            "precision": 0.76667,
            "recall": 1.0,
            "fmeasure": 0.8671
        },
        "bleu": 90.3602,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.94724,
            "recall": 0.95307,
            "f1": 0.93621
        },
        "nubia": {
            "semantic_relation": 4.66049,
            "contradiction": 0.15167,
            "irrelevancy": 97.75078,
            "logical_agreement": 2.09756,
            "grammar_ref": 5.97194,
            "grammar_hyp": 6.39823,
            "nubia_score": 0.81537
        },
        "meteor": 0.5330273631654674,
        "bleurt": 0.45305
    },
    "totto_test_contrast_challenge_table_size-table_size_460": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.272001872658765,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 20,
        "distinct-1": 0.7592592592592593,
        "vocab_size-1": 41,
        "unique-1": 33,
        "entropy-1": 5.194430789080312,
        "distinct-2": 0.88,
        "vocab_size-2": 44,
        "unique-2": 39,
        "entropy-2": 5.3887584397314585,
        "cond_entropy-2": 0.07916418769779475,
        "distinct-3": 0.9347826086956522,
        "vocab_size-3": 43,
        "unique-3": 40,
        "entropy-3": 5.393127173448315,
        "cond_entropy-3": 0.026551146764102772,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 4.02336923485777,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7872340425531915,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.080872628135291,
        "distinct-2-nopunct": 0.8604651162790697,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.12963946395411,
        "cond_entropy-2-nopunct": 0.05597386822459502,
        "distinct-3-nopunct": 0.9230769230769231,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.131556065016094,
        "cond_entropy-3-nopunct": 0.03233970780536746,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.537604765238799,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.92308,
            "fmeasure": 0.9375
        },
        "rouge2": {
            "precision": 0.9,
            "recall": 0.875,
            "fmeasure": 0.88636
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.92308,
            "fmeasure": 0.9375
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.92308,
            "fmeasure": 0.9375
        },
        "bleu": 88.00533,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9183673469387755
        },
        "bertscore": {
            "precision": 0.98846,
            "recall": 0.98393,
            "f1": 0.98617
        },
        "nubia": {
            "semantic_relation": 4.96909,
            "contradiction": 0.44813,
            "irrelevancy": 0.61624,
            "logical_agreement": 98.93563,
            "grammar_ref": 5.0449,
            "grammar_hyp": 5.1184,
            "nubia_score": 0.97505
        },
        "meteor": 0.626612410060972,
        "bleurt": 0.90967
    },
    "totto_test_contrast_challenge_table_size-table_size_528": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 5.0,
        "median_pred_length": 17.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 30,
        "unique-1": 26,
        "entropy-1": 4.852168723603279,
        "distinct-2": 0.96875,
        "vocab_size-2": 31,
        "unique-2": 30,
        "entropy-2": 4.9375,
        "cond_entropy-2": 0.10003715874966053,
        "distinct-3": 1.0,
        "vocab_size-3": 30,
        "unique-3": 30,
        "entropy-3": 4.906890595608519,
        "cond_entropy-3": -0.026442737724814775,
        "total_length-nopunct": 31,
        "mean_pred_length-nopunct": 15.5,
        "std_pred_length-nopunct": 6.5,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8709677419354839,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.696131794257844,
        "distinct-2-nopunct": 0.9655172413793104,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.789015477886192,
        "cond_entropy-2-nopunct": 0.11068123646483505,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 27,
        "unique-3-nopunct": 27,
        "entropy-3-nopunct": 4.754887502163471,
        "cond_entropy-3-nopunct": -0.029019418890029347,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.202078614084915,
        "rouge1": {
            "precision": 0.85507,
            "recall": 0.83307,
            "fmeasure": 0.843
        },
        "rouge2": {
            "precision": 0.67424,
            "recall": 0.65432,
            "fmeasure": 0.66311
        },
        "rougeL": {
            "precision": 0.72464,
            "recall": 0.7104,
            "fmeasure": 0.71682
        },
        "rougeLsum": {
            "precision": 0.72464,
            "recall": 0.7104,
            "fmeasure": 0.71682
        },
        "bleu": 49.21865,
        "local_recall": {
            "1": 0.6,
            "2": 0.0,
            "3": 0.8461538461538461
        },
        "bertscore": {
            "precision": 0.93463,
            "recall": 0.92493,
            "f1": 0.92595
        },
        "nubia": {
            "semantic_relation": 4.32343,
            "contradiction": 1.27846,
            "irrelevancy": 8.91965,
            "logical_agreement": 89.8019,
            "grammar_ref": 4.36539,
            "grammar_hyp": 4.32922,
            "nubia_score": 0.77954
        },
        "meteor": 0.40720477890579904,
        "bleurt": 0.35647
    },
    "totto_test_contrast_challenge_table_size-table_size_430": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.7,
        "msttr-100_nopunct": 0.76,
        "total_length": 115,
        "mean_pred_length": 14.375,
        "std_pred_length": 4.240798863421843,
        "median_pred_length": 13.0,
        "min_pred_length": 8,
        "max_pred_length": 24,
        "distinct-1": 0.6869565217391305,
        "vocab_size-1": 79,
        "unique-1": 61,
        "entropy-1": 6.011800459805888,
        "distinct-2": 0.9345794392523364,
        "vocab_size-2": 100,
        "unique-2": 93,
        "entropy-2": 6.610625864905812,
        "cond_entropy-2": 0.44073712686056676,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 96,
        "unique-3": 93,
        "entropy-3": 6.56875055947356,
        "cond_entropy-3": -0.03130228551345663,
        "total_length-nopunct": 100,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.427827300200522,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.76,
        "vocab_size-1-nopunct": 76,
        "unique-1-nopunct": 60,
        "entropy-1-nopunct": 6.0802109100087325,
        "distinct-2-nopunct": 0.9239130434782609,
        "vocab_size-2-nopunct": 85,
        "unique-2-nopunct": 78,
        "entropy-2-nopunct": 6.371388043013547,
        "cond_entropy-2-nopunct": 0.3401897660279434,
        "distinct-3-nopunct": 0.9642857142857143,
        "vocab_size-3-nopunct": 81,
        "unique-3-nopunct": 78,
        "entropy-3-nopunct": 6.320888851350189,
        "cond_entropy-3-nopunct": -0.036006438040157185,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.90703056266141,
        "rouge1": {
            "precision": 0.93942,
            "recall": 0.86049,
            "fmeasure": 0.89276
        },
        "rouge2": {
            "precision": 0.83174,
            "recall": 0.76815,
            "fmeasure": 0.79381
        },
        "rougeL": {
            "precision": 0.86058,
            "recall": 0.79074,
            "fmeasure": 0.8193
        },
        "rougeLsum": {
            "precision": 0.86058,
            "recall": 0.79074,
            "fmeasure": 0.8193
        },
        "bleu": 63.90528,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8679245283018868
        },
        "bertscore": {
            "precision": 0.97374,
            "recall": 0.95009,
            "f1": 0.96123
        },
        "nubia": {
            "semantic_relation": 4.41049,
            "contradiction": 0.28991,
            "irrelevancy": 12.96089,
            "logical_agreement": 86.7492,
            "grammar_ref": 5.14689,
            "grammar_hyp": 5.31385,
            "nubia_score": 0.78898
        },
        "meteor": 0.47394656715026673,
        "bleurt": 0.61305
    },
    "totto_test_contrast_challenge_table_size-table_size_529": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228516,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.624528534624885,
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.825,
            "fmeasure": 0.68599
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.56085,
            "fmeasure": 0.45781
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.825,
            "fmeasure": 0.68599
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.825,
            "fmeasure": 0.68599
        },
        "bleu": 34.79159,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.92602,
            "recall": 0.96345,
            "f1": 0.94043
        },
        "nubia": {
            "semantic_relation": 4.4114,
            "contradiction": 0.28063,
            "irrelevancy": 33.03435,
            "logical_agreement": 66.68503,
            "grammar_ref": 5.68329,
            "grammar_hyp": 4.90571,
            "nubia_score": 0.78556
        },
        "meteor": 0.39857703619888607,
        "bleurt": 0.56128
    },
    "totto_test_contrast_challenge_table_size-table_size_552": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.320493798938574,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 22,
        "distinct-1": 0.6875,
        "vocab_size-1": 33,
        "unique-1": 23,
        "entropy-1": 4.871115365169275,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 42,
        "unique-2": 39,
        "entropy-2": 5.358519762996339,
        "cond_entropy-2": 0.42933004014911674,
        "distinct-3": 0.9523809523809523,
        "vocab_size-3": 40,
        "unique-3": 38,
        "entropy-3": 5.297079327540667,
        "cond_entropy-3": -0.05191662593186679,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.559026084010437,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7380952380952381,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.802915339393917,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.131556065016094,
        "cond_entropy-2-nopunct": 0.3483383217799873,
        "distinct-3-nopunct": 0.9444444444444444,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.058813890331199,
        "cond_entropy-3-nopunct": -0.08769943964215804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.09003740191846,
        "rouge1": {
            "precision": 0.55196,
            "recall": 0.67499,
            "fmeasure": 0.60273
        },
        "rouge2": {
            "precision": 0.25617,
            "recall": 0.33149,
            "fmeasure": 0.28669
        },
        "rougeL": {
            "precision": 0.43185,
            "recall": 0.53218,
            "fmeasure": 0.4728
        },
        "rougeLsum": {
            "precision": 0.43185,
            "recall": 0.53218,
            "fmeasure": 0.4728
        },
        "bleu": 21.13235,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.25,
            "3": 0.6896551724137931
        },
        "bertscore": {
            "precision": 0.85495,
            "recall": 0.88854,
            "f1": 0.87064
        },
        "nubia": {
            "semantic_relation": 3.64988,
            "contradiction": 4.01677,
            "irrelevancy": 83.39721,
            "logical_agreement": 12.58602,
            "grammar_ref": 4.76688,
            "grammar_hyp": 4.32087,
            "nubia_score": 0.59994
        },
        "meteor": 0.3176222995732487,
        "bleurt": -0.10028
    },
    "totto_test_contrast_challenge_table_size-table_size_594": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.0,
        "median_pred_length": 16.0,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.78125,
        "vocab_size-1": 25,
        "unique-1": 20,
        "entropy-1": 4.5,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.3068905956085188,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.028107102122342915,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.307354922057605,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.35462325762194924,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660258,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.510083782781334,
        "rouge1": {
            "precision": 0.85606,
            "recall": 0.82659,
            "fmeasure": 0.83754
        },
        "rouge2": {
            "precision": 0.66569,
            "recall": 0.64055,
            "fmeasure": 0.64897
        },
        "rougeL": {
            "precision": 0.85606,
            "recall": 0.82659,
            "fmeasure": 0.83754
        },
        "rougeLsum": {
            "precision": 0.85606,
            "recall": 0.82659,
            "fmeasure": 0.83754
        },
        "bleu": 48.26014,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.8666666666666667,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.95452,
            "recall": 0.94766,
            "f1": 0.94382
        },
        "nubia": {
            "semantic_relation": 3.65723,
            "contradiction": 49.98355,
            "irrelevancy": 0.63212,
            "logical_agreement": 49.38433,
            "grammar_ref": 4.13759,
            "grammar_hyp": 4.18235,
            "nubia_score": 0.60471
        },
        "meteor": 0.4575590913654102,
        "bleurt": 0.50133
    },
    "totto_test_contrast_challenge_table_size-table_size_553": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 8.16496580927726,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.7962962962962963,
        "vocab_size-1": 43,
        "unique-1": 36,
        "entropy-1": 5.282484261342598,
        "distinct-2": 0.9803921568627451,
        "vocab_size-2": 50,
        "unique-2": 49,
        "entropy-2": 5.63320965569699,
        "cond_entropy-2": 0.28528073200731047,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.04579617458367275,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 5.557777333511022,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8863636363636364,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.186704345910024,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.19080331281005447,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5391815481346987,
        "rouge1": {
            "precision": 0.61944,
            "recall": 0.64417,
            "fmeasure": 0.6313
        },
        "rouge2": {
            "precision": 0.32749,
            "recall": 0.3366,
            "fmeasure": 0.33183
        },
        "rougeL": {
            "precision": 0.575,
            "recall": 0.59099,
            "fmeasure": 0.58253
        },
        "rougeLsum": {
            "precision": 0.575,
            "recall": 0.59099,
            "fmeasure": 0.58253
        },
        "bleu": 20.11739,
        "local_recall": {
            "1": 0.25,
            "2": 0.6086956521739131,
            "3": 0.5294117647058824
        },
        "bertscore": {
            "precision": 0.91132,
            "recall": 0.91753,
            "f1": 0.91437
        },
        "nubia": {
            "semantic_relation": 4.20579,
            "contradiction": 0.22038,
            "irrelevancy": 34.31622,
            "logical_agreement": 65.4634,
            "grammar_ref": 4.61531,
            "grammar_hyp": 5.02322,
            "nubia_score": 0.70185
        },
        "meteor": 0.3066577624829259,
        "bleurt": 0.21916
    },
    "totto_test_contrast_challenge_table_size-table_size_530": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 91,
        "mean_pred_length": 18.2,
        "std_pred_length": 3.3105890714493698,
        "median_pred_length": 19.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.6263736263736264,
        "vocab_size-1": 57,
        "unique-1": 38,
        "entropy-1": 5.545972800250013,
        "distinct-2": 0.8372093023255814,
        "vocab_size-2": 72,
        "unique-2": 60,
        "entropy-2": 6.083127836047135,
        "cond_entropy-2": 0.4580790907425493,
        "distinct-3": 0.9135802469135802,
        "vocab_size-3": 74,
        "unique-3": 67,
        "entropy-3": 6.167010496711774,
        "cond_entropy-3": 0.10506395193964932,
        "total_length-nopunct": 82,
        "mean_pred_length-nopunct": 16.4,
        "std_pred_length-nopunct": 3.0724582991474434,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6585365853658537,
        "vocab_size-1-nopunct": 54,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.480525822168162,
        "distinct-2-nopunct": 0.8311688311688312,
        "vocab_size-2-nopunct": 64,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.909516735443906,
        "cond_entropy-2-nopunct": 0.4729536523958655,
        "distinct-3-nopunct": 0.9166666666666666,
        "vocab_size-3-nopunct": 66,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 6.0032583347756505,
        "cond_entropy-3-nopunct": 0.10466311358528503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.523973553137466,
        "rouge1": {
            "precision": 0.83033,
            "recall": 0.90477,
            "fmeasure": 0.85273
        },
        "rouge2": {
            "precision": 0.69712,
            "recall": 0.7296,
            "fmeasure": 0.70763
        },
        "rougeL": {
            "precision": 0.73935,
            "recall": 0.80503,
            "fmeasure": 0.75737
        },
        "rougeLsum": {
            "precision": 0.73935,
            "recall": 0.80503,
            "fmeasure": 0.75737
        },
        "bleu": 66.86992,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2857142857142857,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.95502,
            "recall": 0.97217,
            "f1": 0.96238
        },
        "nubia": {
            "semantic_relation": 4.66138,
            "contradiction": 0.14711,
            "irrelevancy": 21.36529,
            "logical_agreement": 78.4876,
            "grammar_ref": 3.93665,
            "grammar_hyp": 3.63878,
            "nubia_score": 0.90641
        },
        "meteor": 0.5052946745446715,
        "bleurt": 0.66016
    },
    "totto_test_contrast_challenge_table_size-table_size_432": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 99,
        "mean_pred_length": 19.8,
        "std_pred_length": 9.431860898041277,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 30,
        "distinct-1": 0.7171717171717171,
        "vocab_size-1": 71,
        "unique-1": 60,
        "entropy-1": 5.857836009901801,
        "distinct-2": 0.9680851063829787,
        "vocab_size-2": 91,
        "unique-2": 89,
        "entropy-2": 6.482728346335461,
        "cond_entropy-2": 0.5854812792705731,
        "distinct-3": 1.0,
        "vocab_size-3": 89,
        "unique-3": 89,
        "entropy-3": 6.47573343096641,
        "cond_entropy-3": -0.002957808327380332,
        "total_length-nopunct": 81,
        "mean_pred_length-nopunct": 16.2,
        "std_pred_length-nopunct": 7.547184905645283,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.8024691358024691,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 58,
        "entropy-1-nopunct": 5.79644244200803,
        "distinct-2-nopunct": 0.9736842105263158,
        "vocab_size-2-nopunct": 74,
        "unique-2-nopunct": 73,
        "entropy-2-nopunct": 6.185363204204599,
        "cond_entropy-2-nopunct": 0.38773237906925634,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 71,
        "unique-3-nopunct": 71,
        "entropy-3-nopunct": 6.149747119504677,
        "cond_entropy-3-nopunct": -0.031210147429558993,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.044122430101864,
        "rouge1": {
            "precision": 0.82394,
            "recall": 0.74496,
            "fmeasure": 0.77331
        },
        "rouge2": {
            "precision": 0.6494,
            "recall": 0.57839,
            "fmeasure": 0.60328
        },
        "rougeL": {
            "precision": 0.63763,
            "recall": 0.58547,
            "fmeasure": 0.60053
        },
        "rougeLsum": {
            "precision": 0.63763,
            "recall": 0.58547,
            "fmeasure": 0.60053
        },
        "bleu": 49.75213,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.25,
            "3": 0.7662337662337663
        },
        "bertscore": {
            "precision": 0.94929,
            "recall": 0.93893,
            "f1": 0.94393
        },
        "nubia": {
            "semantic_relation": 4.22976,
            "contradiction": 3.03914,
            "irrelevancy": 19.91691,
            "logical_agreement": 77.04395,
            "grammar_ref": 4.65184,
            "grammar_hyp": 4.7685,
            "nubia_score": 0.74973
        },
        "meteor": 0.4219068886158715,
        "bleurt": 0.22591
    },
    "totto_test_contrast_challenge_table_size-table_size_302": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7574673462380614,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rouge2": {
            "precision": 0.625,
            "recall": 0.7,
            "fmeasure": 0.65385
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.87037,
            "fmeasure": 0.81481
        },
        "bleu": 65.8037,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97544,
            "recall": 0.97544,
            "f1": 0.97544
        },
        "nubia": {
            "semantic_relation": 4.11383,
            "contradiction": 0.4147,
            "irrelevancy": 35.64603,
            "logical_agreement": 63.93928,
            "grammar_ref": 4.09688,
            "grammar_hyp": 3.81746,
            "nubia_score": 0.76218
        },
        "meteor": 0.9555555555555555,
        "bleurt": 0.34708
    },
    "totto_test_contrast_challenge_table_size-table_size_531": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508582,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.955129287349138,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.81283,
            "fmeasure": 0.79808
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.53333,
            "fmeasure": 0.52222
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.73295,
            "fmeasure": 0.65509
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.73295,
            "fmeasure": 0.65509
        },
        "bleu": 29.75928,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.90601,
            "recall": 0.95224,
            "f1": 0.92017
        },
        "nubia": {
            "semantic_relation": 4.63996,
            "contradiction": 3.6767,
            "irrelevancy": 51.33356,
            "logical_agreement": 44.98974,
            "grammar_ref": 5.72031,
            "grammar_hyp": 5.13521,
            "nubia_score": 0.86063
        },
        "meteor": 0.4661003636292624,
        "bleurt": 0.32328
    },
    "totto_test_contrast_challenge_table_size-table_size_555": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.9375,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.875,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.04022392894185188,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.3764992953429935,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.23486,
            "irrelevancy": 0.53273,
            "logical_agreement": 99.23241,
            "grammar_ref": 4.18747,
            "grammar_hyp": 4.4235,
            "nubia_score": 0.98266
        },
        "meteor": 1.0,
        "bleurt": 0.91462
    },
    "totto_test_contrast_challenge_table_size-table_size_560": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 3.0912061651652345,
        "median_pred_length": 20.0,
        "min_pred_length": 14,
        "max_pred_length": 21,
        "distinct-1": 0.7636363636363637,
        "vocab_size-1": 42,
        "unique-1": 34,
        "entropy-1": 5.215552159365316,
        "distinct-2": 1.0,
        "vocab_size-2": 52,
        "unique-2": 52,
        "entropy-2": 5.700439718141095,
        "cond_entropy-2": 0.4260901580125923,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": -0.08572987402588379,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.156565630242722,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.55458885167764,
        "cond_entropy-2-nopunct": 0.4291268741710036,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 44,
        "entropy-3-nopunct": 5.4594316186372955,
        "cond_entropy-3-nopunct": -0.09515723304034036,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.577806830911386,
        "rouge1": {
            "precision": 0.69123,
            "recall": 0.67781,
            "fmeasure": 0.68263
        },
        "rouge2": {
            "precision": 0.4528,
            "recall": 0.42929,
            "fmeasure": 0.44036
        },
        "rougeL": {
            "precision": 0.50702,
            "recall": 0.50432,
            "fmeasure": 0.50402
        },
        "rougeLsum": {
            "precision": 0.50702,
            "recall": 0.50432,
            "fmeasure": 0.50402
        },
        "bleu": 33.97989,
        "local_recall": {
            "1": 0.35294117647058826,
            "2": 0.0,
            "3": 0.8055555555555556
        },
        "bertscore": {
            "precision": 0.93196,
            "recall": 0.91853,
            "f1": 0.9252
        },
        "nubia": {
            "semantic_relation": 4.34305,
            "contradiction": 11.94523,
            "irrelevancy": 23.74831,
            "logical_agreement": 64.30646,
            "grammar_ref": 4.73268,
            "grammar_hyp": 4.48041,
            "nubia_score": 0.75853
        },
        "meteor": 0.410370728966876,
        "bleurt": 0.21041
    },
    "totto_test_contrast_challenge_table_size-table_size_504": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": 0.68,
        "msttr-100_nopunct": NaN,
        "total_length": 102,
        "mean_pred_length": 20.4,
        "std_pred_length": 6.2801273872430325,
        "median_pred_length": 20.0,
        "min_pred_length": 10,
        "max_pred_length": 29,
        "distinct-1": 0.6862745098039216,
        "vocab_size-1": 70,
        "unique-1": 57,
        "entropy-1": 5.771169942109366,
        "distinct-2": 0.9381443298969072,
        "vocab_size-2": 91,
        "unique-2": 86,
        "entropy-2": 6.468419156597826,
        "cond_entropy-2": 0.6612314515947463,
        "distinct-3": 0.9891304347826086,
        "vocab_size-3": 91,
        "unique-3": 90,
        "entropy-3": 6.501822825622244,
        "cond_entropy-3": 0.04055006498035769,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 5.761944116355173,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7157894736842105,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 57,
        "entropy-1-nopunct": 5.7364538895543795,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 84,
        "unique-2-nopunct": 79,
        "entropy-2-nopunct": 6.350132124083403,
        "cond_entropy-2-nopunct": 0.6488672189055115,
        "distinct-3-nopunct": 0.9882352941176471,
        "vocab_size-3-nopunct": 84,
        "unique-3-nopunct": 83,
        "entropy-3-nopunct": 6.385861524373001,
        "cond_entropy-3-nopunct": 0.03230122218642077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.824826782852603,
        "rouge1": {
            "precision": 0.7566,
            "recall": 0.78771,
            "fmeasure": 0.76487
        },
        "rouge2": {
            "precision": 0.59302,
            "recall": 0.57886,
            "fmeasure": 0.58148
        },
        "rougeL": {
            "precision": 0.66054,
            "recall": 0.66848,
            "fmeasure": 0.65874
        },
        "rougeLsum": {
            "precision": 0.66054,
            "recall": 0.66848,
            "fmeasure": 0.65874
        },
        "bleu": 46.61821,
        "local_recall": {
            "1": 0.26666666666666666,
            "2": 0.0,
            "3": 0.8285714285714286
        },
        "bertscore": {
            "precision": 0.92151,
            "recall": 0.92828,
            "f1": 0.92176
        },
        "nubia": {
            "semantic_relation": 4.45861,
            "contradiction": 0.42463,
            "irrelevancy": 49.70875,
            "logical_agreement": 49.86662,
            "grammar_ref": 4.46418,
            "grammar_hyp": 4.18057,
            "nubia_score": 0.83549
        },
        "meteor": 0.40701939851754243,
        "bleurt": 0.3981
    },
    "totto_test_contrast_challenge_table_size-table_size_434": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 1.0,
        "median_pred_length": 19.0,
        "min_pred_length": 18,
        "max_pred_length": 20,
        "distinct-1": 0.868421052631579,
        "vocab_size-1": 33,
        "unique-1": 28,
        "entropy-1": 4.984769618706745,
        "distinct-2": 0.9722222222222222,
        "vocab_size-2": 35,
        "unique-2": 34,
        "entropy-2": 5.114369445886754,
        "cond_entropy-2": 0.08866415466539343,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.023638630780208267,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8787878787878788,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.801969876934213,
        "distinct-2-nopunct": 0.967741935483871,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.889680181354619,
        "cond_entropy-2-nopunct": 0.10335057812519613,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.02724979801792366,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2307137445136047,
        "rouge1": {
            "precision": 0.42057,
            "recall": 0.65242,
            "fmeasure": 0.50998
        },
        "rouge2": {
            "precision": 0.24346,
            "recall": 0.40035,
            "fmeasure": 0.30143
        },
        "rougeL": {
            "precision": 0.3845,
            "recall": 0.6223,
            "fmeasure": 0.47308
        },
        "rougeLsum": {
            "precision": 0.3845,
            "recall": 0.6223,
            "fmeasure": 0.47308
        },
        "bleu": 16.10161,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.8215,
            "recall": 0.89961,
            "f1": 0.85874
        },
        "nubia": {
            "semantic_relation": 3.7142,
            "contradiction": 0.74438,
            "irrelevancy": 56.63537,
            "logical_agreement": 42.62025,
            "grammar_ref": 4.76014,
            "grammar_hyp": 3.93285,
            "nubia_score": 0.65892
        },
        "meteor": 0.3430158319053697,
        "bleurt": 0.15367
    },
    "totto_test_contrast_challenge_table_size-table_size_532": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 18.0,
        "std_pred_length": 2.160246899469287,
        "median_pred_length": 19.0,
        "min_pred_length": 15,
        "max_pred_length": 20,
        "distinct-1": 0.8148148148148148,
        "vocab_size-1": 44,
        "unique-1": 39,
        "entropy-1": 5.305541900191423,
        "distinct-2": 1.0,
        "vocab_size-2": 51,
        "unique-2": 51,
        "entropy-2": 5.6724253419715005,
        "cond_entropy-2": 0.3000824477360059,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.08746284125033933,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8936170212765957,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.309700021798344,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 44,
        "entropy-2-nopunct": 5.4594316186372955,
        "cond_entropy-2-nopunct": 0.16642856251254454,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.10187961401921372,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.892148772137825,
        "rouge1": {
            "precision": 0.81905,
            "recall": 0.74976,
            "fmeasure": 0.77503
        },
        "rouge2": {
            "precision": 0.67857,
            "recall": 0.63828,
            "fmeasure": 0.65238
        },
        "rougeL": {
            "precision": 0.74921,
            "recall": 0.69695,
            "fmeasure": 0.71598
        },
        "rougeLsum": {
            "precision": 0.74921,
            "recall": 0.69695,
            "fmeasure": 0.71598
        },
        "bleu": 46.77335,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.6415094339622641
        },
        "bertscore": {
            "precision": 0.9377,
            "recall": 0.91137,
            "f1": 0.92387
        },
        "nubia": {
            "semantic_relation": 4.12024,
            "contradiction": 0.40457,
            "irrelevancy": 62.56923,
            "logical_agreement": 37.0262,
            "grammar_ref": 4.33326,
            "grammar_hyp": 4.11578,
            "nubia_score": 0.73188
        },
        "meteor": 0.3549598468578479,
        "bleurt": 0.4173
    },
    "totto_test_contrast_challenge_table_size-table_size_304": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.71,
        "msttr-100_nopunct": NaN,
        "total_length": 104,
        "mean_pred_length": 17.333333333333332,
        "std_pred_length": 3.681787005729087,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 25,
        "distinct-1": 0.6826923076923077,
        "vocab_size-1": 71,
        "unique-1": 55,
        "entropy-1": 5.879687348561374,
        "distinct-2": 0.8877551020408163,
        "vocab_size-2": 87,
        "unique-2": 76,
        "entropy-2": 6.39022004819685,
        "cond_entropy-2": 0.44231712558487607,
        "distinct-3": 0.9021739130434783,
        "vocab_size-3": 83,
        "unique-3": 74,
        "entropy-3": 6.327909782143979,
        "cond_entropy-3": -0.06940875762341286,
        "total_length-nopunct": 95,
        "mean_pred_length-nopunct": 15.833333333333334,
        "std_pred_length-nopunct": 3.5316033500695148,
        "median_pred_length-nopunct": 15.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7157894736842105,
        "vocab_size-1-nopunct": 68,
        "unique-1-nopunct": 54,
        "entropy-1-nopunct": 5.8436059403342,
        "distinct-2-nopunct": 0.8876404494382022,
        "vocab_size-2-nopunct": 79,
        "unique-2-nopunct": 69,
        "entropy-2-nopunct": 6.25101432984281,
        "cond_entropy-2-nopunct": 0.433897131171303,
        "distinct-3-nopunct": 0.9036144578313253,
        "vocab_size-3-nopunct": 75,
        "unique-3-nopunct": 67,
        "entropy-3-nopunct": 6.18226834700958,
        "cond_entropy-3-nopunct": -0.07659761407730444,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.8324192567801685,
        "rouge1": {
            "precision": 0.79402,
            "recall": 0.82214,
            "fmeasure": 0.80516
        },
        "rouge2": {
            "precision": 0.65155,
            "recall": 0.68127,
            "fmeasure": 0.66305
        },
        "rougeL": {
            "precision": 0.73291,
            "recall": 0.75845,
            "fmeasure": 0.74327
        },
        "rougeLsum": {
            "precision": 0.73291,
            "recall": 0.75845,
            "fmeasure": 0.74327
        },
        "bleu": 66.31617,
        "local_recall": {
            "1": 0.15789473684210525,
            "2": 0.75,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.94385,
            "recall": 0.95547,
            "f1": 0.94797
        },
        "nubia": {
            "semantic_relation": 4.14983,
            "contradiction": 16.96892,
            "irrelevancy": 40.32547,
            "logical_agreement": 42.70562,
            "grammar_ref": 4.63046,
            "grammar_hyp": 4.34564,
            "nubia_score": 0.72876
        },
        "meteor": 0.4925108101876205,
        "bleurt": 0.39461
    },
    "totto_test_contrast_challenge_table_size-table_size_595": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 4.0,
        "median_pred_length": 21.0,
        "min_pred_length": 17,
        "max_pred_length": 25,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 30,
        "unique-1": 20,
        "entropy-1": 4.773269803731141,
        "distinct-2": 0.85,
        "vocab_size-2": 34,
        "unique-2": 28,
        "entropy-2": 5.021928094887364,
        "cond_entropy-2": 0.22961067210860192,
        "distinct-3": 0.8947368421052632,
        "vocab_size-3": 34,
        "unique-3": 30,
        "entropy-3": 5.0374011976541135,
        "cond_entropy-3": 0.03126257645096005,
        "total_length-nopunct": 36,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.6944444444444444,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.503258334775644,
        "distinct-2-nopunct": 0.8235294117647058,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.73452166477975,
        "cond_entropy-2-nopunct": 0.2704790162786153,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.75,
        "cond_entropy-3-nopunct": 0.037537158749660605,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7347598759997647,
        "rouge1": {
            "precision": 0.73203,
            "recall": 0.80881,
            "fmeasure": 0.76567
        },
        "rouge2": {
            "precision": 0.3848,
            "recall": 0.48404,
            "fmeasure": 0.42779
        },
        "rougeL": {
            "precision": 0.55011,
            "recall": 0.67338,
            "fmeasure": 0.60408
        },
        "rougeLsum": {
            "precision": 0.55011,
            "recall": 0.67338,
            "fmeasure": 0.60408
        },
        "bleu": 27.27078,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.92326,
            "recall": 0.94459,
            "f1": 0.93214
        },
        "nubia": {
            "semantic_relation": 4.92237,
            "contradiction": 0.52939,
            "irrelevancy": 14.65189,
            "logical_agreement": 84.81871,
            "grammar_ref": 4.12394,
            "grammar_hyp": 3.52584,
            "nubia_score": 0.96652
        },
        "meteor": 0.4398549399842455,
        "bleurt": 0.3636
    },
    "totto_test_contrast_challenge_table_size-table_size_561": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5579098675041347,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.81818,
            "fmeasure": 0.81818
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.91667,
            "fmeasure": 0.91667
        },
        "bleu": 73.48889,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.98143,
            "recall": 0.98247,
            "f1": 0.98195
        },
        "nubia": {
            "semantic_relation": 4.61305,
            "contradiction": 1.00975,
            "irrelevancy": 33.27064,
            "logical_agreement": 65.71961,
            "grammar_ref": 4.85143,
            "grammar_hyp": 4.81815,
            "nubia_score": 0.82757
        },
        "meteor": 0.9384615384615386,
        "bleurt": 0.54425
    },
    "totto_test_contrast_challenge_table_size-table_size_305": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0818734482105152,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.625,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.5,
            "fmeasure": 0.57143
        },
        "bleu": 15.44788,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.97848,
            "recall": 0.92917,
            "f1": 0.95319
        },
        "nubia": {
            "semantic_relation": 4.92496,
            "contradiction": 0.36533,
            "irrelevancy": 0.46862,
            "logical_agreement": 99.16605,
            "grammar_ref": 5.02153,
            "grammar_hyp": 4.6683,
            "nubia_score": 0.99996
        },
        "meteor": 0.35772595517358696,
        "bleurt": 0.71323
    },
    "totto_test_contrast_challenge_table_size-table_size_564": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 3.5,
        "median_pred_length": 14.5,
        "min_pred_length": 11,
        "max_pred_length": 18,
        "distinct-1": 0.6551724137931034,
        "vocab_size-1": 19,
        "unique-1": 11,
        "entropy-1": 4.1162646156680225,
        "distinct-2": 0.8148148148148148,
        "vocab_size-2": 22,
        "unique-2": 17,
        "entropy-2": 4.384517131793101,
        "cond_entropy-2": 0.2491203960850423,
        "distinct-3": 0.84,
        "vocab_size-3": 21,
        "unique-3": 17,
        "entropy-3": 4.323856189774722,
        "cond_entropy-3": -0.031031312388743956,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.68,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.9434651896016453,
        "distinct-2-nopunct": 0.782608695652174,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 4.088779347361361,
        "cond_entropy-2-nopunct": 0.20621772299215504,
        "distinct-3-nopunct": 0.8095238095238095,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 4.011365041826378,
        "cond_entropy-3-nopunct": -0.03600643804015718,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.249121274719501,
        "rouge1": {
            "precision": 0.87473,
            "recall": 1.0,
            "fmeasure": 0.93078
        },
        "rouge2": {
            "precision": 0.8125,
            "recall": 0.93376,
            "fmeasure": 0.86617
        },
        "rougeL": {
            "precision": 0.8061,
            "recall": 0.91667,
            "fmeasure": 0.85551
        },
        "rougeLsum": {
            "precision": 0.8061,
            "recall": 0.91667,
            "fmeasure": 0.85551
        },
        "bleu": 66.87403,
        "local_recall": {
            "1": 0.4,
            "2": 1.0,
            "3": 0.9375
        },
        "bertscore": {
            "precision": 0.9735,
            "recall": 0.99115,
            "f1": 0.98103
        },
        "nubia": {
            "semantic_relation": 4.73834,
            "contradiction": 1.04595,
            "irrelevancy": 20.05832,
            "logical_agreement": 78.89573,
            "grammar_ref": 4.81259,
            "grammar_hyp": 4.04928,
            "nubia_score": 0.95114
        },
        "meteor": 0.5673216240016615,
        "bleurt": 0.67507
    },
    "totto_test_contrast_challenge_table_size-table_size_567": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 21.5,
        "std_pred_length": 1.5,
        "median_pred_length": 21.5,
        "min_pred_length": 20,
        "max_pred_length": 23,
        "distinct-1": 0.813953488372093,
        "vocab_size-1": 35,
        "unique-1": 29,
        "entropy-1": 5.0076601035393065,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": 0.32153115235501023,
        "distinct-3": 1.0,
        "vocab_size-3": 39,
        "unique-3": 39,
        "entropy-3": 5.285402218862247,
        "cond_entropy-3": -0.07214978575583503,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8648648648648649,
        "vocab_size-1-nopunct": 32,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.885129041304628,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 35,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.129283016944964,
        "cond_entropy-2-nopunct": 0.26268679417315943,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.08488889758651327,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.779964368316179,
        "rouge1": {
            "precision": 0.78284,
            "recall": 0.86343,
            "fmeasure": 0.82053
        },
        "rouge2": {
            "precision": 0.64309,
            "recall": 0.72157,
            "fmeasure": 0.67916
        },
        "rougeL": {
            "precision": 0.75784,
            "recall": 0.83449,
            "fmeasure": 0.79373
        },
        "rougeLsum": {
            "precision": 0.75784,
            "recall": 0.83449,
            "fmeasure": 0.79373
        },
        "bleu": 52.7689,
        "local_recall": {
            "1": 0,
            "2": 0.875,
            "3": 0.9047619047619048
        },
        "bertscore": {
            "precision": 0.92642,
            "recall": 0.95144,
            "f1": 0.93536
        },
        "nubia": {
            "semantic_relation": 3.51464,
            "contradiction": 48.01313,
            "irrelevancy": 47.10365,
            "logical_agreement": 4.88322,
            "grammar_ref": 3.41143,
            "grammar_hyp": 3.13192,
            "nubia_score": 0.64928
        },
        "meteor": 0.488549204665711,
        "bleurt": 0.3788
    },
    "totto_test_contrast_challenge_table_size-table_size_435": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 68,
        "mean_pred_length": 17.0,
        "std_pred_length": 4.743416490252569,
        "median_pred_length": 17.5,
        "min_pred_length": 10,
        "max_pred_length": 23,
        "distinct-1": 0.7794117647058824,
        "vocab_size-1": 53,
        "unique-1": 45,
        "entropy-1": 5.5415890842097,
        "distinct-2": 1.0,
        "vocab_size-2": 64,
        "unique-2": 64,
        "entropy-2": 6.0,
        "cond_entropy-2": 0.3675280256053444,
        "distinct-3": 1.0,
        "vocab_size-3": 60,
        "unique-3": 60,
        "entropy-3": 5.906890595608517,
        "cond_entropy-3": -0.09310940439148153,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.330127018922194,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8275862068965517,
        "vocab_size-1-nopunct": 48,
        "unique-1-nopunct": 42,
        "entropy-1-nopunct": 5.4379029265654975,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 54,
        "unique-2-nopunct": 54,
        "entropy-2-nopunct": 5.7548875021634665,
        "cond_entropy-2-nopunct": 0.3481014695655317,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.643856189774728,
        "cond_entropy-3-nopunct": -0.11103131238874385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.513442796542199,
        "rouge1": {
            "precision": 0.65375,
            "recall": 0.57399,
            "fmeasure": 0.60481
        },
        "rouge2": {
            "precision": 0.37292,
            "recall": 0.35034,
            "fmeasure": 0.35864
        },
        "rougeL": {
            "precision": 0.51633,
            "recall": 0.45298,
            "fmeasure": 0.47727
        },
        "rougeLsum": {
            "precision": 0.51633,
            "recall": 0.45298,
            "fmeasure": 0.47727
        },
        "bleu": 23.91822,
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.86678,
            "recall": 0.85496,
            "f1": 0.85808
        },
        "nubia": {
            "semantic_relation": 3.40526,
            "contradiction": 0.86227,
            "irrelevancy": 46.61548,
            "logical_agreement": 52.52226,
            "grammar_ref": 4.16687,
            "grammar_hyp": 4.56036,
            "nubia_score": 0.50718
        },
        "meteor": 0.27416044280583735,
        "bleurt": -0.3424
    },
    "totto_test_contrast_challenge_table_size-table_size_505": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 66,
        "mean_pred_length": 13.2,
        "std_pred_length": 5.3814496188294845,
        "median_pred_length": 11.0,
        "min_pred_length": 7,
        "max_pred_length": 23,
        "distinct-1": 0.6515151515151515,
        "vocab_size-1": 43,
        "unique-1": 31,
        "entropy-1": 5.17894843028628,
        "distinct-2": 0.8032786885245902,
        "vocab_size-2": 49,
        "unique-2": 41,
        "entropy-2": 5.479757419459163,
        "cond_entropy-2": 0.18142518541754743,
        "distinct-3": 0.8928571428571429,
        "vocab_size-3": 50,
        "unique-3": 45,
        "entropy-3": 5.57958907380469,
        "cond_entropy-3": 0.1400977184619228,
        "total_length-nopunct": 60,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 5.019960159204453,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.6833333333333333,
        "vocab_size-1-nopunct": 41,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.148394345536402,
        "distinct-2-nopunct": 0.7818181818181819,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 35,
        "entropy-2-nopunct": 5.281181986173258,
        "cond_entropy-2-nopunct": 0.16537820882523205,
        "distinct-3-nopunct": 0.88,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.3887584397314585,
        "cond_entropy-3-nopunct": 0.13759422629333434,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6469504576163105,
        "rouge1": {
            "precision": 0.84937,
            "recall": 0.82409,
            "fmeasure": 0.83029
        },
        "rouge2": {
            "precision": 0.71,
            "recall": 0.70526,
            "fmeasure": 0.70402
        },
        "rougeL": {
            "precision": 0.81301,
            "recall": 0.80187,
            "fmeasure": 0.80271
        },
        "rougeLsum": {
            "precision": 0.81301,
            "recall": 0.80187,
            "fmeasure": 0.80271
        },
        "bleu": 54.96588,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.0,
            "3": 0.8305084745762712
        },
        "bertscore": {
            "precision": 0.97684,
            "recall": 0.96262,
            "f1": 0.96949
        },
        "nubia": {
            "semantic_relation": 4.68055,
            "contradiction": 0.49177,
            "irrelevancy": 0.61452,
            "logical_agreement": 98.8937,
            "grammar_ref": 4.79762,
            "grammar_hyp": 4.80413,
            "nubia_score": 0.90337
        },
        "meteor": 0.443562045961036,
        "bleurt": 0.76599
    },
    "totto_test_contrast_challenge_table_size-table_size_570": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.904360462230019,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.80952,
            "fmeasure": 0.87179
        },
        "rouge2": {
            "precision": 0.72727,
            "recall": 0.61538,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.80556,
            "recall": 0.69048,
            "fmeasure": 0.74359
        },
        "rougeLsum": {
            "precision": 0.80556,
            "recall": 0.69048,
            "fmeasure": 0.74359
        },
        "bleu": 73.63897,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.25,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.97008,
            "recall": 0.95941,
            "f1": 0.96471
        },
        "nubia": {
            "semantic_relation": 4.57217,
            "contradiction": 0.2535,
            "irrelevancy": 0.45855,
            "logical_agreement": 99.28795,
            "grammar_ref": 5.70189,
            "grammar_hyp": 5.04993,
            "nubia_score": 0.91021
        },
        "meteor": 0.4778547483222343,
        "bleurt": 0.42742
    },
    "totto_test_contrast_challenge_table_size-table_size_436": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.251647869033911,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.82933,
            "contradiction": 1.12257,
            "irrelevancy": 0.76148,
            "logical_agreement": 98.11595,
            "grammar_ref": 6.06085,
            "grammar_hyp": 6.23781,
            "nubia_score": 0.91231
        },
        "meteor": 1.0,
        "bleurt": 0.89857
    },
    "totto_test_contrast_challenge_table_size-table_size_306": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 12,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.75,
        "total_length": 186,
        "mean_pred_length": 15.5,
        "std_pred_length": 3.685557397915997,
        "median_pred_length": 15.0,
        "min_pred_length": 9,
        "max_pred_length": 24,
        "distinct-1": 0.6397849462365591,
        "vocab_size-1": 119,
        "unique-1": 97,
        "entropy-1": 6.418357120007027,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 168,
        "unique-2": 162,
        "entropy-2": 7.3739779786073285,
        "cond_entropy-2": 0.8142178269233298,
        "distinct-3": 0.9938271604938271,
        "vocab_size-3": 161,
        "unique-3": 160,
        "entropy-3": 7.32750432387226,
        "cond_entropy-3": -0.041365097902374914,
        "total_length-nopunct": 166,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 3.912231531435167,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6987951807228916,
        "vocab_size-1-nopunct": 116,
        "unique-1-nopunct": 97,
        "entropy-1-nopunct": 6.478871465772367,
        "distinct-2-nopunct": 0.961038961038961,
        "vocab_size-2-nopunct": 148,
        "unique-2-nopunct": 142,
        "entropy-2-nopunct": 7.188864462772843,
        "cond_entropy-2-nopunct": 0.766837254058205,
        "distinct-3-nopunct": 0.9929577464788732,
        "vocab_size-3-nopunct": 141,
        "unique-3-nopunct": 140,
        "entropy-3-nopunct": 7.135662612462435,
        "cond_entropy-3-nopunct": -0.046616885978951646,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.851833692860813,
        "rouge1": {
            "precision": 0.65168,
            "recall": 0.66764,
            "fmeasure": 0.64932
        },
        "rouge2": {
            "precision": 0.41155,
            "recall": 0.42446,
            "fmeasure": 0.41101
        },
        "rougeL": {
            "precision": 0.56431,
            "recall": 0.59281,
            "fmeasure": 0.56892
        },
        "rougeLsum": {
            "precision": 0.56431,
            "recall": 0.59281,
            "fmeasure": 0.56892
        },
        "bleu": 30.14855,
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.5161290322580645,
            "3": 0.6442307692307693
        },
        "bertscore": {
            "precision": 0.89818,
            "recall": 0.89944,
            "f1": 0.89529
        },
        "nubia": {
            "semantic_relation": 3.81327,
            "contradiction": 4.89165,
            "irrelevancy": 51.50615,
            "logical_agreement": 43.60221,
            "grammar_ref": 4.84087,
            "grammar_hyp": 4.66103,
            "nubia_score": 0.62371
        },
        "meteor": 0.33573596958169477,
        "bleurt": 0.06931
    },
    "totto_test_contrast_challenge_table_size-table_size_510": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 3.5,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 17,
        "entropy-1": 4.323856189774722,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.14057533149967955,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.106603137064473,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.1713995643490357,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1971638521236168,
        "rouge1": {
            "precision": 0.73077,
            "recall": 0.58216,
            "fmeasure": 0.64789
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.37222,
            "fmeasure": 0.41887
        },
        "rougeL": {
            "precision": 0.62821,
            "recall": 0.50128,
            "fmeasure": 0.55747
        },
        "rougeLsum": {
            "precision": 0.62821,
            "recall": 0.50128,
            "fmeasure": 0.55747
        },
        "bleu": 33.33999,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.2,
            "3": 0.65
        },
        "bertscore": {
            "precision": 0.9408,
            "recall": 0.90919,
            "f1": 0.92472
        },
        "nubia": {
            "semantic_relation": 4.37008,
            "contradiction": 0.2006,
            "irrelevancy": 32.87319,
            "logical_agreement": 66.92621,
            "grammar_ref": 5.35082,
            "grammar_hyp": 5.30364,
            "nubia_score": 0.88121
        },
        "meteor": 0.36804402440939754,
        "bleurt": 0.1974
    },
    "totto_test_contrast_challenge_table_size-table_size_600": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 13.333333333333334,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.775,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.743942707918268,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.38386386470375694,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.12199052437861026,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 11.333333333333334,
        "std_pred_length-nopunct": 0.4714045207910317,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.6871792978845495,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.2734960650861104,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.14684138832927116,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.043127484178999,
        "rouge1": {
            "precision": 0.79293,
            "recall": 0.81481,
            "fmeasure": 0.781
        },
        "rouge2": {
            "precision": 0.5404,
            "recall": 0.59121,
            "fmeasure": 0.54598
        },
        "rougeL": {
            "precision": 0.68434,
            "recall": 0.72269,
            "fmeasure": 0.6833
        },
        "rougeLsum": {
            "precision": 0.68434,
            "recall": 0.72269,
            "fmeasure": 0.6833
        },
        "bleu": 34.6549,
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.78125
        },
        "bertscore": {
            "precision": 0.90797,
            "recall": 0.93291,
            "f1": 0.91829
        },
        "nubia": {
            "semantic_relation": 3.99254,
            "contradiction": 1.03252,
            "irrelevancy": 70.22784,
            "logical_agreement": 28.73963,
            "grammar_ref": 4.26152,
            "grammar_hyp": 4.6238,
            "nubia_score": 0.62485
        },
        "meteor": 0.415033841792029,
        "bleurt": 0.05886
    },
    "totto_test_contrast_challenge_table_size-table_size_438": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6546881823533726,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.82576,
            "fmeasure": 0.73293
        },
        "rouge2": {
            "precision": 0.5098,
            "recall": 0.63704,
            "fmeasure": 0.5609
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.68182,
            "fmeasure": 0.60852
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.68182,
            "fmeasure": 0.60852
        },
        "bleu": 56.79161,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.97195,
            "recall": 0.98325,
            "f1": 0.97757
        },
        "nubia": {
            "semantic_relation": 4.41894,
            "contradiction": 0.20898,
            "irrelevancy": 65.51088,
            "logical_agreement": 34.28014,
            "grammar_ref": 5.84412,
            "grammar_hyp": 4.50218,
            "nubia_score": 0.84968
        },
        "meteor": 0.48985416410830873,
        "bleurt": 0.12549
    },
    "totto_test_contrast_challenge_table_size-table_size_308": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.63,
        "msttr-100_nopunct": 0.67,
        "total_length": 158,
        "mean_pred_length": 19.75,
        "std_pred_length": 6.319612329882269,
        "median_pred_length": 17.5,
        "min_pred_length": 13,
        "max_pred_length": 32,
        "distinct-1": 0.6265822784810127,
        "vocab_size-1": 99,
        "unique-1": 77,
        "entropy-1": 6.195253332134004,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 140,
        "unique-2": 132,
        "entropy-2": 7.085420190467016,
        "cond_entropy-2": 0.8458898204931602,
        "distinct-3": 0.9788732394366197,
        "vocab_size-3": 139,
        "unique-3": 136,
        "entropy-3": 7.107493598377928,
        "cond_entropy-3": 0.030152196644906606,
        "total_length-nopunct": 140,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 5.123475382979799,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.6785714285714286,
        "vocab_size-1-nopunct": 95,
        "unique-1-nopunct": 77,
        "entropy-1-nopunct": 6.189014754584374,
        "distinct-2-nopunct": 0.946969696969697,
        "vocab_size-2-nopunct": 125,
        "unique-2-nopunct": 120,
        "entropy-2-nopunct": 6.926895823871119,
        "cond_entropy-2-nopunct": 0.779715509429829,
        "distinct-3-nopunct": 0.9919354838709677,
        "vocab_size-3-nopunct": 123,
        "unique-3-nopunct": 122,
        "entropy-3-nopunct": 6.938067278128796,
        "cond_entropy-3-nopunct": 0.018751989450413425,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.990916590538323,
        "rouge1": {
            "precision": 0.7773,
            "recall": 0.75896,
            "fmeasure": 0.75625
        },
        "rouge2": {
            "precision": 0.55861,
            "recall": 0.55036,
            "fmeasure": 0.54572
        },
        "rougeL": {
            "precision": 0.7511,
            "recall": 0.73174,
            "fmeasure": 0.73005
        },
        "rougeLsum": {
            "precision": 0.7511,
            "recall": 0.73174,
            "fmeasure": 0.73005
        },
        "bleu": 49.33775,
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.56,
            "3": 0.7789473684210526
        },
        "bertscore": {
            "precision": 0.94037,
            "recall": 0.94172,
            "f1": 0.9408
        },
        "nubia": {
            "semantic_relation": 4.10728,
            "contradiction": 4.00746,
            "irrelevancy": 54.79142,
            "logical_agreement": 41.20111,
            "grammar_ref": 4.94279,
            "grammar_hyp": 4.68474,
            "nubia_score": 0.70533
        },
        "meteor": 0.3884304359864133,
        "bleurt": 0.11374
    },
    "totto_test_contrast_challenge_table_size-table_size_574": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 13,
        "entropy-1": 4.011365041826378,
        "distinct-2": 0.9,
        "vocab_size-2": 18,
        "unique-2": 16,
        "entropy-2": 4.1219280948873624,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 0.9473684210526315,
        "vocab_size-3": 18,
        "unique-3": 17,
        "entropy-3": 4.142664355548846,
        "cond_entropy-3": 0.03126257645096008,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.8268748818646365,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.94770277922009,
        "cond_entropy-2-nopunct": 0.14421971022094907,
        "distinct-3-nopunct": 0.9411764705882353,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.969815782426811,
        "cond_entropy-3-nopunct": 0.03518489863155644,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.102243808584624,
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.67582,
            "fmeasure": 0.55682
        },
        "rouge2": {
            "precision": 0.14815,
            "recall": 0.21445,
            "fmeasure": 0.17501
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.46154,
            "fmeasure": 0.38699
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.46154,
            "fmeasure": 0.38699
        },
        "bleu": 14.29615,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.89202,
            "recall": 0.90834,
            "f1": 0.9001
        },
        "nubia": {
            "semantic_relation": 3.80939,
            "contradiction": 19.45459,
            "irrelevancy": 64.98844,
            "logical_agreement": 15.55697,
            "grammar_ref": 5.03839,
            "grammar_hyp": 4.32763,
            "nubia_score": 0.58641
        },
        "meteor": 0.2921404544665779,
        "bleurt": 0.18813
    },
    "totto_test_contrast_challenge_table_size-table_size_462": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 79,
        "mean_pred_length": 19.75,
        "std_pred_length": 5.2141634036535525,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 25,
        "distinct-1": 0.759493670886076,
        "vocab_size-1": 60,
        "unique-1": 46,
        "entropy-1": 5.757965362369968,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 70,
        "unique-2": 65,
        "entropy-2": 6.095485357162557,
        "cond_entropy-2": 0.30900444077046313,
        "distinct-3": 0.9436619718309859,
        "vocab_size-3": 67,
        "unique-3": 63,
        "entropy-3": 6.03707106316665,
        "cond_entropy-3": -0.05090255690669166,
        "total_length-nopunct": 71,
        "mean_pred_length-nopunct": 17.75,
        "std_pred_length-nopunct": 5.717298313014636,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7887323943661971,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.655107464874202,
        "distinct-2-nopunct": 0.9253731343283582,
        "vocab_size-2-nopunct": 62,
        "unique-2-nopunct": 57,
        "entropy-2-nopunct": 5.916835459114484,
        "cond_entropy-2-nopunct": 0.2566030766825888,
        "distinct-3-nopunct": 0.9365079365079365,
        "vocab_size-3-nopunct": 59,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.850295796515793,
        "cond_entropy-3-nopunct": -0.05706323521182427,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.331001559830038,
        "rouge1": {
            "precision": 0.77119,
            "recall": 0.67179,
            "fmeasure": 0.71503
        },
        "rouge2": {
            "precision": 0.60192,
            "recall": 0.52738,
            "fmeasure": 0.55919
        },
        "rougeL": {
            "precision": 0.65175,
            "recall": 0.57628,
            "fmeasure": 0.60932
        },
        "rougeLsum": {
            "precision": 0.65175,
            "recall": 0.57628,
            "fmeasure": 0.60932
        },
        "bleu": 35.2029,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.16666666666666666,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.93309,
            "recall": 0.89049,
            "f1": 0.91098
        },
        "nubia": {
            "semantic_relation": 3.63755,
            "contradiction": 49.58924,
            "irrelevancy": 24.13129,
            "logical_agreement": 26.27948,
            "grammar_ref": 4.59177,
            "grammar_hyp": 4.18098,
            "nubia_score": 0.57649
        },
        "meteor": 0.30741711561504087,
        "bleurt": 0.1497
    },
    "totto_test_contrast_challenge_table_size-table_size_512": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.8260869565217391,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.142914673354254,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.3338190944968058,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.142914673354254,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.3338190944968058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.5583366447214696,
        "rouge1": {
            "precision": 0.65217,
            "recall": 0.3526,
            "fmeasure": 0.45743
        },
        "rouge2": {
            "precision": 0.25758,
            "recall": 0.13056,
            "fmeasure": 0.17317
        },
        "rougeL": {
            "precision": 0.46377,
            "recall": 0.24072,
            "fmeasure": 0.31673
        },
        "rougeLsum": {
            "precision": 0.46377,
            "recall": 0.24072,
            "fmeasure": 0.31673
        },
        "bleu": 7.46798,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.08333333333333333,
            "3": 0.38461538461538464
        },
        "bertscore": {
            "precision": 0.87039,
            "recall": 0.8165,
            "f1": 0.84237
        },
        "nubia": {
            "semantic_relation": 3.35481,
            "contradiction": 62.46242,
            "irrelevancy": 30.56914,
            "logical_agreement": 6.96844,
            "grammar_ref": 4.78179,
            "grammar_hyp": 4.77423,
            "nubia_score": 0.30165
        },
        "meteor": 0.16579120573730538,
        "bleurt": -0.79294
    },
    "web_nlg_en_test_contrast_challenge_combinations-unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 1295,
        "msttr-100": 0.66837,
        "msttr-100_nopunct": 0.68888,
        "total_length": 28282,
        "mean_pred_length": 21.83938223938224,
        "std_pred_length": 4.3728357255292,
        "median_pred_length": 23.0,
        "min_pred_length": 8,
        "max_pred_length": 32,
        "distinct-1": 0.06276076656530656,
        "vocab_size-1": 1775,
        "unique-1": 610,
        "entropy-1": 8.142369250254976,
        "distinct-2": 0.2202541964649646,
        "vocab_size-2": 5944,
        "unique-2": 2991,
        "entropy-2": 11.167117168751025,
        "cond_entropy-2": 3.0246909810212532,
        "distinct-3": 0.3838159738439981,
        "vocab_size-3": 9861,
        "unique-3": 6080,
        "entropy-3": 12.355476798740895,
        "cond_entropy-3": 1.28332071674444,
        "total_length-nopunct": 25939,
        "mean_pred_length-nopunct": 20.03011583011583,
        "std_pred_length-nopunct": 4.282840457033834,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06812136165619338,
        "vocab_size-1-nopunct": 1767,
        "unique-1-nopunct": 610,
        "entropy-1-nopunct": 8.295139867647691,
        "distinct-2-nopunct": 0.22950819672131148,
        "vocab_size-2-nopunct": 5656,
        "unique-2-nopunct": 2954,
        "entropy-2-nopunct": 11.099886063381076,
        "cond_entropy-2-nopunct": 2.9603423280997547,
        "distinct-3-nopunct": 0.3930361043299499,
        "vocab_size-3-nopunct": 9177,
        "unique-3-nopunct": 5773,
        "entropy-3-nopunct": 12.247160464306033,
        "cond_entropy-3-nopunct": 1.2381110622581284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.209019772428223,
        "rouge1": {
            "precision": 0.7654,
            "recall": 0.6473,
            "fmeasure": 0.68692
        },
        "rouge2": {
            "precision": 0.49654,
            "recall": 0.41458,
            "fmeasure": 0.44125
        },
        "rougeL": {
            "precision": 0.60675,
            "recall": 0.51108,
            "fmeasure": 0.54275
        },
        "rougeLsum": {
            "precision": 0.60675,
            "recall": 0.51108,
            "fmeasure": 0.54275
        },
        "bleu": 37.03029,
        "local_recall": {
            "1": 0.184223053383203,
            "2": 0.47238474139948516,
            "3": 0.7327616586397275,
            "4": 0.7058823529411765,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.91322,
            "recall": 0.88608,
            "f1": 0.89773
        },
        "nubia": {
            "semantic_relation": 3.99353,
            "contradiction": 7.10998,
            "irrelevancy": 11.11658,
            "logical_agreement": 81.77344,
            "grammar_ref": 4.37017,
            "grammar_hyp": 4.64359,
            "nubia_score": 0.62802
        },
        "meteor": 0.3125545733210099,
        "bleurt": -0.04508
    },
    "totto_test_contrast_challenge_table_size-table_size_464": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 3.9841837197791885,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.28151981340693205,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6901165175936654,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.3347176276348775,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4107918909526207,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.67949,
            "fmeasure": 0.57586
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.81319,
            "fmeasure": 0.69758
        },
        "bleu": 39.67088,
        "local_recall": {
            "1": 1.0,
            "2": 0.875
        },
        "bertscore": {
            "precision": 0.90973,
            "recall": 0.96661,
            "f1": 0.93731
        },
        "nubia": {
            "semantic_relation": 2.94508,
            "contradiction": 73.29642,
            "irrelevancy": 26.01339,
            "logical_agreement": 0.6902,
            "grammar_ref": 3.57757,
            "grammar_hyp": 2.87188,
            "nubia_score": 0.51287
        },
        "meteor": 0.40718621833397906,
        "bleurt": 0.39707
    },
    "totto_test_contrast_challenge_table_size-table_size_465": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819113,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.1016411427814814,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3022488427024763,
        "rouge1": {
            "precision": 0.71023,
            "recall": 0.61971,
            "fmeasure": 0.65716
        },
        "rouge2": {
            "precision": 0.54524,
            "recall": 0.43996,
            "fmeasure": 0.48346
        },
        "rougeL": {
            "precision": 0.60417,
            "recall": 0.53363,
            "fmeasure": 0.56216
        },
        "rougeLsum": {
            "precision": 0.60417,
            "recall": 0.53363,
            "fmeasure": 0.56216
        },
        "bleu": 40.29727,
        "local_recall": {
            "1": 0.8,
            "2": 0.125,
            "3": 0.6875
        },
        "bertscore": {
            "precision": 0.90507,
            "recall": 0.89414,
            "f1": 0.89306
        },
        "nubia": {
            "semantic_relation": 3.3816,
            "contradiction": 50.36325,
            "irrelevancy": 2.9333,
            "logical_agreement": 46.70345,
            "grammar_ref": 5.19402,
            "grammar_hyp": 6.02107,
            "nubia_score": 0.3858
        },
        "meteor": 0.3107984600346024,
        "bleurt": -0.14677
    },
    "totto_test_contrast_challenge_table_size-table_size_513": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.3079575533002847,
        "rouge1": {
            "precision": 0.59091,
            "recall": 0.60317,
            "fmeasure": 0.59
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.32692,
            "fmeasure": 0.30918
        },
        "rougeL": {
            "precision": 0.59091,
            "recall": 0.60317,
            "fmeasure": 0.59
        },
        "rougeLsum": {
            "precision": 0.59091,
            "recall": 0.60317,
            "fmeasure": 0.59
        },
        "bleu": 28.0395,
        "local_recall": {
            "1": 0.125,
            "2": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.85989,
            "recall": 0.94238,
            "f1": 0.89925
        },
        "nubia": {
            "semantic_relation": 3.07609,
            "contradiction": 9.44279,
            "irrelevancy": 69.38784,
            "logical_agreement": 21.16937,
            "grammar_ref": 5.58883,
            "grammar_hyp": 4.55131,
            "nubia_score": 0.3772
        },
        "meteor": 0.34922228124742927,
        "bleurt": 0.26174
    },
    "totto_test_contrast_challenge_table_size-table_size_534": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 16.666666666666668,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 18.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.78,
        "vocab_size-1": 39,
        "unique-1": 34,
        "entropy-1": 5.086370130156182,
        "distinct-2": 0.9787234042553191,
        "vocab_size-2": 46,
        "unique-2": 45,
        "entropy-2": 5.512035660188278,
        "cond_entropy-2": 0.3600819274085244,
        "distinct-3": 1.0,
        "vocab_size-3": 44,
        "unique-3": 44,
        "entropy-3": 5.4594316186372955,
        "cond_entropy-3": -0.049702687585794866,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 15.666666666666666,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8085106382978723,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.0626863946826655,
        "distinct-2-nopunct": 0.9772727272727273,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 42,
        "entropy-2-nopunct": 5.41397707318275,
        "cond_entropy-2-nopunct": 0.34880760736971855,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 41,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.357552004618081,
        "cond_entropy-3-nopunct": -0.053099126214335574,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.281223492351315,
        "rouge1": {
            "precision": 0.64723,
            "recall": 0.52399,
            "fmeasure": 0.5619
        },
        "rouge2": {
            "precision": 0.379,
            "recall": 0.29528,
            "fmeasure": 0.32421
        },
        "rougeL": {
            "precision": 0.59254,
            "recall": 0.49002,
            "fmeasure": 0.52351
        },
        "rougeLsum": {
            "precision": 0.59254,
            "recall": 0.49002,
            "fmeasure": 0.52351
        },
        "bleu": 14.33682,
        "local_recall": {
            "1": 0.3,
            "2": 0.6,
            "3": 0.48484848484848486
        },
        "bertscore": {
            "precision": 0.90298,
            "recall": 0.88229,
            "f1": 0.89032
        },
        "nubia": {
            "semantic_relation": 3.63078,
            "contradiction": 47.81467,
            "irrelevancy": 17.41828,
            "logical_agreement": 34.76706,
            "grammar_ref": 3.79025,
            "grammar_hyp": 4.13845,
            "nubia_score": 0.49008
        },
        "meteor": 0.23155931570054572,
        "bleurt": 0.02149
    },
    "totto_test_contrast_challenge_table_size-table_size_535": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.33373,
            "irrelevancy": 0.59046,
            "logical_agreement": 99.07581,
            "grammar_ref": 6.68645,
            "grammar_hyp": 6.68645,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 1.00634
    },
    "totto_test_contrast_challenge_table_size-table_size_660": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 10.666666666666666,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 13,
        "distinct-1": 0.84375,
        "vocab_size-1": 27,
        "unique-1": 24,
        "entropy-1": 4.640319531114783,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.09090815037458831,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.15754127698647996,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 9.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.8928571428571429,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.5661089398374815,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.10669676780365919,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1844245711374276,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.056475362035024,
        "rouge1": {
            "precision": 0.7342,
            "recall": 0.53045,
            "fmeasure": 0.60809
        },
        "rouge2": {
            "precision": 0.50123,
            "recall": 0.33869,
            "fmeasure": 0.39784
        },
        "rougeL": {
            "precision": 0.62929,
            "recall": 0.45292,
            "fmeasure": 0.52109
        },
        "rougeLsum": {
            "precision": 0.62929,
            "recall": 0.45292,
            "fmeasure": 0.52109
        },
        "bleu": 36.6428,
        "local_recall": {
            "1": 0.1,
            "2": 0.5,
            "3": 0.5833333333333334
        },
        "bertscore": {
            "precision": 0.91056,
            "recall": 0.87243,
            "f1": 0.89103
        },
        "nubia": {
            "semantic_relation": 3.71739,
            "contradiction": 10.46211,
            "irrelevancy": 1.53256,
            "logical_agreement": 88.00534,
            "grammar_ref": 4.31237,
            "grammar_hyp": 4.77055,
            "nubia_score": 0.58689
        },
        "meteor": 0.31325015728878813,
        "bleurt": 0.08741
    },
    "totto_test_contrast_challenge_table_size-table_size_663": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 4.109609335312651,
        "median_pred_length": 14.0,
        "min_pred_length": 10,
        "max_pred_length": 20,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 28,
        "entropy-1": 4.925118550357138,
        "distinct-2": 0.975609756097561,
        "vocab_size-2": 40,
        "unique-2": 39,
        "entropy-2": 5.308771516813203,
        "cond_entropy-2": 0.3067761787164808,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.056992912227129475,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7837837837837838,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.702564514219128,
        "distinct-2-nopunct": 0.9705882352941176,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.028639311838573,
        "cond_entropy-2-nopunct": 0.3708002845085506,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.06875040183120606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.657493115221488,
        "rouge1": {
            "precision": 0.72113,
            "recall": 0.76263,
            "fmeasure": 0.72785
        },
        "rouge2": {
            "precision": 0.57828,
            "recall": 0.61111,
            "fmeasure": 0.5819
        },
        "rougeL": {
            "precision": 0.72113,
            "recall": 0.76263,
            "fmeasure": 0.72785
        },
        "rougeLsum": {
            "precision": 0.72113,
            "recall": 0.76263,
            "fmeasure": 0.72785
        },
        "bleu": 64.87068,
        "local_recall": {
            "1": 0.3888888888888889,
            "2": 0.0,
            "3": 0.7916666666666666
        },
        "bertscore": {
            "precision": 0.94565,
            "recall": 0.94046,
            "f1": 0.94147
        },
        "nubia": {
            "semantic_relation": 3.6463,
            "contradiction": 34.05004,
            "irrelevancy": 27.95984,
            "logical_agreement": 37.99013,
            "grammar_ref": 4.11451,
            "grammar_hyp": 3.62971,
            "nubia_score": 0.65548
        },
        "meteor": 0.4552706169789582,
        "bleurt": 0.32212
    },
    "totto_test_contrast_challenge_table_size-table_size_536": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 55,
        "mean_pred_length": 18.333333333333332,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 21,
        "distinct-1": 0.7454545454545455,
        "vocab_size-1": 41,
        "unique-1": 33,
        "entropy-1": 5.165463295689616,
        "distinct-2": 0.9423076923076923,
        "vocab_size-2": 49,
        "unique-2": 46,
        "entropy-2": 5.585055102756479,
        "cond_entropy-2": 0.3636841484388124,
        "distinct-3": 1.0,
        "vocab_size-3": 49,
        "unique-3": 49,
        "entropy-3": 5.614709844115208,
        "cond_entropy-3": 0.03671910556595299,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 17.333333333333332,
        "std_pred_length-nopunct": 2.0548046676563256,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.140450958934097,
        "distinct-2-nopunct": 0.9387755102040817,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.492260864523372,
        "cond_entropy-2-nopunct": 0.38609493166317266,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 46,
        "entropy-3-nopunct": 5.5235619560570095,
        "cond_entropy-3-nopunct": 0.03928689455050024,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.8642215476052,
        "rouge1": {
            "precision": 0.72392,
            "recall": 0.76987,
            "fmeasure": 0.74231
        },
        "rouge2": {
            "precision": 0.43734,
            "recall": 0.43122,
            "fmeasure": 0.42898
        },
        "rougeL": {
            "precision": 0.59738,
            "recall": 0.5872,
            "fmeasure": 0.58632
        },
        "rougeLsum": {
            "precision": 0.59738,
            "recall": 0.5872,
            "fmeasure": 0.58632
        },
        "bleu": 39.55698,
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0.25,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.92357,
            "recall": 0.92081,
            "f1": 0.91783
        },
        "nubia": {
            "semantic_relation": 4.46135,
            "contradiction": 0.46297,
            "irrelevancy": 17.55927,
            "logical_agreement": 81.97776,
            "grammar_ref": 4.10939,
            "grammar_hyp": 4.19301,
            "nubia_score": 0.81907
        },
        "meteor": 0.39214936959763524,
        "bleurt": 0.15546
    },
    "totto_test_contrast_challenge_table_size-table_size_665": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.09251370597287,
        "rouge1": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "rouge2": {
            "precision": 0.70833,
            "recall": 0.68506,
            "fmeasure": 0.69398
        },
        "rougeL": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "rougeLsum": {
            "precision": 0.84615,
            "recall": 0.81667,
            "fmeasure": 0.82857
        },
        "bleu": 67.29865,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.9565,
            "recall": 0.9669,
            "f1": 0.96167
        },
        "nubia": {
            "semantic_relation": 4.67622,
            "contradiction": 0.49994,
            "irrelevancy": 0.68259,
            "logical_agreement": 98.81746,
            "grammar_ref": 5.25223,
            "grammar_hyp": 5.20882,
            "nubia_score": 0.8468
        },
        "meteor": 0.5934341018717497,
        "bleurt": 0.67946
    },
    "totto_test_contrast_challenge_table_size-table_size_539": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.67298250033654,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.58333,
            "fmeasure": 0.56
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.27273,
            "fmeasure": 0.26087
        },
        "rougeL": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.38462,
            "recall": 0.41667,
            "fmeasure": 0.4
        },
        "bleu": 12.09034,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.84244,
            "recall": 0.8248,
            "f1": 0.83353
        },
        "nubia": {
            "semantic_relation": 4.31266,
            "contradiction": 0.41774,
            "irrelevancy": 79.83641,
            "logical_agreement": 19.74585,
            "grammar_ref": 5.68739,
            "grammar_hyp": 4.3585,
            "nubia_score": 0.83108
        },
        "meteor": 0.3066423912784973,
        "bleurt": 0.27519
    },
    "totto_test_contrast_challenge_table_size-table_size_540": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 71,
        "mean_pred_length": 14.2,
        "std_pred_length": 3.867815921162743,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 20,
        "distinct-1": 0.7605633802816901,
        "vocab_size-1": 54,
        "unique-1": 47,
        "entropy-1": 5.503630176111337,
        "distinct-2": 0.9393939393939394,
        "vocab_size-2": 62,
        "unique-2": 58,
        "entropy-2": 5.923181998146339,
        "cond_entropy-2": 0.29259643177029276,
        "distinct-3": 0.9672131147540983,
        "vocab_size-3": 59,
        "unique-3": 57,
        "entropy-3": 5.865163567071079,
        "cond_entropy-3": -0.048083011303763995,
        "total_length-nopunct": 62,
        "mean_pred_length-nopunct": 12.4,
        "std_pred_length-nopunct": 4.2708313008125245,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8064516129032258,
        "vocab_size-1-nopunct": 50,
        "unique-1-nopunct": 45,
        "entropy-1-nopunct": 5.433798528024125,
        "distinct-2-nopunct": 0.9298245614035088,
        "vocab_size-2-nopunct": 53,
        "unique-2-nopunct": 49,
        "entropy-2-nopunct": 5.692539136971755,
        "cond_entropy-2-nopunct": 0.30438953722506623,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 50,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.623516641218019,
        "cond_entropy-3-nopunct": -0.05552721910057283,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.273452025542286,
        "rouge1": {
            "precision": 0.86194,
            "recall": 0.80498,
            "fmeasure": 0.81903
        },
        "rouge2": {
            "precision": 0.60486,
            "recall": 0.55757,
            "fmeasure": 0.57166
        },
        "rougeL": {
            "precision": 0.77657,
            "recall": 0.73245,
            "fmeasure": 0.74151
        },
        "rougeLsum": {
            "precision": 0.77657,
            "recall": 0.73245,
            "fmeasure": 0.74151
        },
        "bleu": 54.52594,
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.93077,
            "recall": 0.93759,
            "f1": 0.93155
        },
        "nubia": {
            "semantic_relation": 4.08665,
            "contradiction": 21.55371,
            "irrelevancy": 31.60653,
            "logical_agreement": 46.83976,
            "grammar_ref": 4.71659,
            "grammar_hyp": 4.47449,
            "nubia_score": 0.74233
        },
        "meteor": 0.4328769180882381,
        "bleurt": 0.30068
    },
    "totto_test_contrast_challenge_table_size-table_size_468": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 87,
        "mean_pred_length": 14.5,
        "std_pred_length": 5.619905100029122,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.7011494252873564,
        "vocab_size-1": 61,
        "unique-1": 50,
        "entropy-1": 5.60486752592639,
        "distinct-2": 0.9382716049382716,
        "vocab_size-2": 76,
        "unique-2": 72,
        "entropy-2": 6.207073613969016,
        "cond_entropy-2": 0.5209568947722298,
        "distinct-3": 0.9866666666666667,
        "vocab_size-3": 74,
        "unique-3": 73,
        "entropy-3": 6.202152023829224,
        "cond_entropy-3": 0.005700520973435591,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 5.734883511361751,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7375,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 50,
        "entropy-1-nopunct": 5.580640983527277,
        "distinct-2-nopunct": 0.9324324324324325,
        "vocab_size-2-nopunct": 69,
        "unique-2-nopunct": 65,
        "entropy-2-nopunct": 6.064117048032151,
        "cond_entropy-2-nopunct": 0.5435804248854123,
        "distinct-3-nopunct": 0.9852941176470589,
        "vocab_size-3-nopunct": 67,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.058051076544463,
        "cond_entropy-3-nopunct": 0.00675782124144076,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.13900120057764,
        "rouge1": {
            "precision": 0.89144,
            "recall": 0.80012,
            "fmeasure": 0.83881
        },
        "rouge2": {
            "precision": 0.6608,
            "recall": 0.60066,
            "fmeasure": 0.62573
        },
        "rougeL": {
            "precision": 0.78729,
            "recall": 0.71422,
            "fmeasure": 0.74515
        },
        "rougeLsum": {
            "precision": 0.78729,
            "recall": 0.71422,
            "fmeasure": 0.74515
        },
        "bleu": 46.96251,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.7777777777777778,
            "3": 0.7536231884057971
        },
        "bertscore": {
            "precision": 0.95368,
            "recall": 0.92948,
            "f1": 0.9409
        },
        "nubia": {
            "semantic_relation": 4.26216,
            "contradiction": 8.36318,
            "irrelevancy": 15.83425,
            "logical_agreement": 75.80256,
            "grammar_ref": 4.9652,
            "grammar_hyp": 5.18609,
            "nubia_score": 0.71273
        },
        "meteor": 0.4155378753305161,
        "bleurt": 0.31554
    },
    "totto_test_contrast_challenge_table_size-table_size_667": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2341884037618829,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.41404,
            "fmeasure": 0.4801
        },
        "rouge2": {
            "precision": 0.15385,
            "recall": 0.10916,
            "fmeasure": 0.12769
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.20702,
            "fmeasure": 0.24005
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.20702,
            "fmeasure": 0.24005
        },
        "bleu": 5.82065,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.375
        },
        "bertscore": {
            "precision": 0.86216,
            "recall": 0.81349,
            "f1": 0.83712
        },
        "nubia": {
            "semantic_relation": 3.82257,
            "contradiction": 0.34472,
            "irrelevancy": 86.5056,
            "logical_agreement": 13.14969,
            "grammar_ref": 4.46991,
            "grammar_hyp": 4.25868,
            "nubia_score": 0.60744
        },
        "meteor": 0.2675554968273453,
        "bleurt": 0.1005
    },
    "totto_test_contrast_challenge_table_size-table_size_623": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1070901626504495,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.82143,
            "fmeasure": 0.73529
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.56566,
            "fmeasure": 0.5213
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.82143,
            "fmeasure": 0.73529
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.82143,
            "fmeasure": 0.73529
        },
        "bleu": 30.87819,
        "local_recall": {
            "1": 0.2,
            "2": 0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.94013,
            "recall": 0.97508,
            "f1": 0.95728
        },
        "nubia": {
            "semantic_relation": 4.39839,
            "contradiction": 0.19355,
            "irrelevancy": 58.504,
            "logical_agreement": 41.30245,
            "grammar_ref": 5.29735,
            "grammar_hyp": 4.51733,
            "nubia_score": 0.92645
        },
        "meteor": 0.5146997364109374,
        "bleurt": 0.55167
    },
    "totto_test_contrast_challenge_table_size-table_size_603": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8076923076923077,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.238901256602629,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.4234164716336324,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8181818181818182,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.40907628033193943,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.083331678200047,
        "rouge1": {
            "precision": 0.77273,
            "recall": 0.56142,
            "fmeasure": 0.64538
        },
        "rouge2": {
            "precision": 0.68254,
            "recall": 0.49573,
            "fmeasure": 0.56998
        },
        "rougeL": {
            "precision": 0.75758,
            "recall": 0.55309,
            "fmeasure": 0.63463
        },
        "rougeLsum": {
            "precision": 0.75758,
            "recall": 0.55309,
            "fmeasure": 0.63463
        },
        "bleu": 57.4708,
        "local_recall": {
            "1": 1.0,
            "2": 0.09090909090909091,
            "3": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.90701,
            "recall": 0.8792,
            "f1": 0.8928
        },
        "nubia": {
            "semantic_relation": 2.42156,
            "contradiction": 99.59214,
            "irrelevancy": 0.30958,
            "logical_agreement": 0.09828,
            "grammar_ref": 3.4256,
            "grammar_hyp": 3.56287,
            "nubia_score": 0.18361
        },
        "meteor": 0.3728777538653729,
        "bleurt": -0.48213
    },
    "totto_test_contrast_challenge_table_size-table_size_309": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.965773537549432,
        "rouge1": {
            "precision": 0.80769,
            "recall": 0.95833,
            "fmeasure": 0.87478
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.56061,
            "fmeasure": 0.50311
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.78333,
            "fmeasure": 0.7113
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.78333,
            "fmeasure": 0.7113
        },
        "bleu": 37.35942,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.89584,
            "recall": 0.95868,
            "f1": 0.9262
        },
        "nubia": {
            "semantic_relation": 4.34606,
            "contradiction": 0.39815,
            "irrelevancy": 69.48667,
            "logical_agreement": 30.11517,
            "grammar_ref": 4.59758,
            "grammar_hyp": 3.99934,
            "nubia_score": 0.81627
        },
        "meteor": 0.47333208206908045,
        "bleurt": 0.66997
    },
    "totto_test_contrast_challenge_table_size-table_size_604": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": 0.05628729973432272,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7557427659075784,
        "rouge1": {
            "precision": 0.8,
            "recall": 0.88889,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.625,
            "fmeasure": 0.58824
        },
        "rougeL": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "rougeLsum": {
            "precision": 0.7,
            "recall": 0.77778,
            "fmeasure": 0.73684
        },
        "bleu": 18.55329,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96197,
            "recall": 0.94041,
            "f1": 0.94986
        },
        "nubia": {
            "semantic_relation": 4.93198,
            "contradiction": 0.24987,
            "irrelevancy": 0.47729,
            "logical_agreement": 99.27284,
            "grammar_ref": 6.26263,
            "grammar_hyp": 5.96887,
            "nubia_score": 0.98236
        },
        "meteor": 0.375492664465321,
        "bleurt": 0.6057
    },
    "totto_test_contrast_challenge_table_size-table_size_543": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1055161915432032,
        "rouge1": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "bleu": 41.11336,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.93887,
            "recall": 0.95113,
            "f1": 0.94496
        },
        "nubia": {
            "semantic_relation": 4.01521,
            "contradiction": 10.23484,
            "irrelevancy": 37.69891,
            "logical_agreement": 52.06625,
            "grammar_ref": 7.84225,
            "grammar_hyp": 7.31486,
            "nubia_score": 0.66591
        },
        "meteor": 0.4231469901582543,
        "bleurt": 0.18287
    },
    "totto_test_contrast_challenge_table_size-table_size_624": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 78,
        "mean_pred_length": 19.5,
        "std_pred_length": 6.576473218982953,
        "median_pred_length": 19.5,
        "min_pred_length": 12,
        "max_pred_length": 27,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 60,
        "unique-1": 49,
        "entropy-1": 5.72630426406178,
        "distinct-2": 0.972972972972973,
        "vocab_size-2": 72,
        "unique-2": 70,
        "entropy-2": 6.155399311574901,
        "cond_entropy-2": 0.4322895315563882,
        "distinct-3": 0.9857142857142858,
        "vocab_size-3": 69,
        "unique-3": 68,
        "entropy-3": 6.100711588373543,
        "cond_entropy-3": -0.0515989201125547,
        "total_length-nopunct": 69,
        "mean_pred_length-nopunct": 17.25,
        "std_pred_length-nopunct": 6.015604707757983,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.8115942028985508,
        "vocab_size-1-nopunct": 56,
        "unique-1-nopunct": 47,
        "entropy-1-nopunct": 5.673741848082512,
        "distinct-2-nopunct": 0.9692307692307692,
        "vocab_size-2-nopunct": 63,
        "unique-2-nopunct": 61,
        "entropy-2-nopunct": 5.960829351489997,
        "cond_entropy-2-nopunct": 0.31384335625028537,
        "distinct-3-nopunct": 0.9836065573770492,
        "vocab_size-3-nopunct": 60,
        "unique-3-nopunct": 59,
        "entropy-3-nopunct": 5.897950452316982,
        "cond_entropy-3-nopunct": -0.05884359021966683,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.69316292770809,
        "rouge1": {
            "precision": 0.61886,
            "recall": 0.55344,
            "fmeasure": 0.56519
        },
        "rouge2": {
            "precision": 0.30155,
            "recall": 0.25845,
            "fmeasure": 0.2684
        },
        "rougeL": {
            "precision": 0.51832,
            "recall": 0.45494,
            "fmeasure": 0.46993
        },
        "rougeLsum": {
            "precision": 0.51832,
            "recall": 0.45494,
            "fmeasure": 0.46993
        },
        "bleu": 28.14769,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.42105263157894735,
            "3": 0.6111111111111112
        },
        "bertscore": {
            "precision": 0.85452,
            "recall": 0.84209,
            "f1": 0.84657
        },
        "nubia": {
            "semantic_relation": 3.27441,
            "contradiction": 23.96132,
            "irrelevancy": 67.32635,
            "logical_agreement": 8.71233,
            "grammar_ref": 4.54253,
            "grammar_hyp": 3.7693,
            "nubia_score": 0.49822
        },
        "meteor": 0.30559838451498994,
        "bleurt": -0.21872
    },
    "totto_test_contrast_challenge_table_size-table_size_575": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.7916666666666666,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.084962500721157,
        "distinct-2": 0.9565217391304348,
        "vocab_size-2": 22,
        "unique-2": 21,
        "entropy-2": 4.436605434317882,
        "cond_entropy-2": 0.37338206403150886,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": 0.02677875348937534,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.084962500721157,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.37338206403150886,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": 0.02677875348937534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.29913896279855,
        "rouge1": {
            "precision": 0.65278,
            "recall": 0.44762,
            "fmeasure": 0.53107
        },
        "rouge2": {
            "precision": 0.2029,
            "recall": 0.13725,
            "fmeasure": 0.16374
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.30476,
            "fmeasure": 0.36158
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.30476,
            "fmeasure": 0.36158
        },
        "bleu": 7.27565,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.5652173913043478
        },
        "bertscore": {
            "precision": 0.89687,
            "recall": 0.86209,
            "f1": 0.8787
        },
        "nubia": {
            "semantic_relation": 3.42841,
            "contradiction": 0.52772,
            "irrelevancy": 76.16461,
            "logical_agreement": 23.30767,
            "grammar_ref": 5.19058,
            "grammar_hyp": 5.67094,
            "nubia_score": 0.38391
        },
        "meteor": 0.24588859740560376,
        "bleurt": -0.25687
    },
    "web_nlg_en_test_contrast_challenge_combinations-seen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 115,
        "msttr-100": 0.64667,
        "msttr-100_nopunct": 0.68176,
        "total_length": 1899,
        "mean_pred_length": 16.51304347826087,
        "std_pred_length": 4.2943141728919825,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 26,
        "distinct-1": 0.26961558715113215,
        "vocab_size-1": 512,
        "unique-1": 267,
        "entropy-1": 7.377831819459119,
        "distinct-2": 0.5818385650224215,
        "vocab_size-2": 1038,
        "unique-2": 734,
        "entropy-2": 9.54024027118564,
        "cond_entropy-2": 1.9789374092556893,
        "distinct-3": 0.7357699221090473,
        "vocab_size-3": 1228,
        "unique-3": 976,
        "entropy-3": 10.024768709790246,
        "cond_entropy-3": 0.5335767128952921,
        "total_length-nopunct": 1700,
        "mean_pred_length-nopunct": 14.782608695652174,
        "std_pred_length-nopunct": 4.0470764728771425,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.2988235294117647,
        "vocab_size-1-nopunct": 508,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.563602653614994,
        "distinct-2-nopunct": 0.571608832807571,
        "vocab_size-2-nopunct": 906,
        "unique-2-nopunct": 636,
        "entropy-2-nopunct": 9.324254458244,
        "cond_entropy-2-nopunct": 1.899491721043169,
        "distinct-3-nopunct": 0.726530612244898,
        "vocab_size-3-nopunct": 1068,
        "unique-3-nopunct": 847,
        "entropy-3-nopunct": 9.807297472467875,
        "cond_entropy-3-nopunct": 0.5294436690931513,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 8.426886156964812,
        "rouge1": {
            "precision": 0.7973,
            "recall": 0.76592,
            "fmeasure": 0.77385
        },
        "rouge2": {
            "precision": 0.56387,
            "recall": 0.53854,
            "fmeasure": 0.54452
        },
        "rougeL": {
            "precision": 0.69691,
            "recall": 0.66846,
            "fmeasure": 0.67516
        },
        "rougeLsum": {
            "precision": 0.69691,
            "recall": 0.66846,
            "fmeasure": 0.67516
        },
        "bleu": 53.88988,
        "local_recall": {
            "1": 0.2535885167464115,
            "2": 0.5466666666666666,
            "3": 0.8657024793388429
        },
        "bertscore": {
            "precision": 0.94135,
            "recall": 0.93634,
            "f1": 0.93731
        },
        "nubia": {
            "semantic_relation": 4.61171,
            "contradiction": 2.93696,
            "irrelevancy": 5.36214,
            "logical_agreement": 91.7009,
            "grammar_ref": 4.68186,
            "grammar_hyp": 4.72836,
            "nubia_score": 0.83971
        },
        "meteor": 0.4179757423184087,
        "bleurt": 0.32634
    },
    "totto_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1850,
        "msttr-100": 0.69734,
        "msttr-100_nopunct": 0.74258,
        "total_length": 24419,
        "mean_pred_length": 13.19945945945946,
        "std_pred_length": 4.061779629899926,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.26090339489741593,
        "vocab_size-1": 6371,
        "unique-1": 4737,
        "entropy-1": 9.192341921750947,
        "distinct-2": 0.6091541494970978,
        "vocab_size-2": 13748,
        "unique-2": 12079,
        "entropy-2": 12.482266070230589,
        "cond_entropy-2": 2.852368606248476,
        "distinct-3": 0.7744582267483952,
        "vocab_size-3": 16046,
        "unique-3": 14923,
        "entropy-3": 13.275246638156599,
        "cond_entropy-3": 0.8188707498904249,
        "total_length-nopunct": 21341,
        "mean_pred_length-nopunct": 11.535675675675675,
        "std_pred_length-nopunct": 3.6309588790428653,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.29773675085516144,
        "vocab_size-1-nopunct": 6354,
        "unique-1-nopunct": 4735,
        "entropy-1-nopunct": 9.634183714290224,
        "distinct-2-nopunct": 0.6312144066492227,
        "vocab_size-2-nopunct": 12303,
        "unique-2-nopunct": 10993,
        "entropy-2-nopunct": 12.329057355556337,
        "cond_entropy-2-nopunct": 2.9210506752166667,
        "distinct-3-nopunct": 0.7831188708123122,
        "vocab_size-3-nopunct": 13815,
        "unique-3-nopunct": 12906,
        "entropy-3-nopunct": 13.076832891626763,
        "cond_entropy-3-nopunct": 0.8657225951801331,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 9.578678344569946,
        "rouge1": {
            "precision": 0.75567,
            "recall": 0.73456,
            "fmeasure": 0.73251
        },
        "rouge2": {
            "precision": 0.55828,
            "recall": 0.54415,
            "fmeasure": 0.54174
        },
        "rougeL": {
            "precision": 0.68754,
            "recall": 0.67098,
            "fmeasure": 0.66762
        },
        "rougeLsum": {
            "precision": 0.68754,
            "recall": 0.67098,
            "fmeasure": 0.66762
        },
        "bleu": 51.51791,
        "local_recall": {
            "1": 0.2187732342007435,
            "2": 0.4789996181748759,
            "3": 0.781376787495843
        },
        "bertscore": {
            "precision": 0.93152,
            "recall": 0.92775,
            "f1": 0.92806
        },
        "nubia": {
            "semantic_relation": 4.17184,
            "contradiction": 7.49233,
            "irrelevancy": 29.27589,
            "logical_agreement": 63.23178,
            "grammar_ref": 4.71357,
            "grammar_hyp": 4.65753,
            "nubia_score": 0.73704
        },
        "meteor": 0.40902287289017547,
        "bleurt": 0.33574
    },
    "totto_test_contrast_challenge_table_size-table_size_605": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.247927513443583,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.07800251200127316,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.89611256392227,
        "rouge1": {
            "precision": 0.63492,
            "recall": 0.775,
            "fmeasure": 0.69611
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.74386,
            "fmeasure": 0.66227
        },
        "rougeL": {
            "precision": 0.63492,
            "recall": 0.775,
            "fmeasure": 0.69611
        },
        "rougeLsum": {
            "precision": 0.63492,
            "recall": 0.775,
            "fmeasure": 0.69611
        },
        "bleu": 66.12116,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.89823,
            "recall": 0.89938,
            "f1": 0.88431
        },
        "nubia": {
            "semantic_relation": 3.64957,
            "contradiction": 0.06735,
            "irrelevancy": 99.33234,
            "logical_agreement": 0.6003,
            "grammar_ref": 3.95052,
            "grammar_hyp": 3.32435,
            "nubia_score": 0.75382
        },
        "meteor": 0.42105406313260596,
        "bleurt": 0.13307
    },
    "totto_test_contrast_challenge_table_size-table_size_670": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2075985142324197,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.64171,
            "fmeasure": 0.59871
        },
        "rouge2": {
            "precision": 0.35897,
            "recall": 0.42222,
            "fmeasure": 0.38509
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.48864,
            "fmeasure": 0.45333
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.48864,
            "fmeasure": 0.45333
        },
        "bleu": 27.80527,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.6666666666666666,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.88687,
            "recall": 0.9273,
            "f1": 0.90663
        },
        "nubia": {
            "semantic_relation": 4.34003,
            "contradiction": 0.41819,
            "irrelevancy": 65.75618,
            "logical_agreement": 33.82563,
            "grammar_ref": 4.84054,
            "grammar_hyp": 4.59275,
            "nubia_score": 0.76405
        },
        "meteor": 0.4011104429111581,
        "bleurt": 0.11235
    },
    "totto_test_contrast_challenge_table_size-table_size_469": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 35,
        "mean_pred_length": 11.666666666666666,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 13.0,
        "min_pred_length": 7,
        "max_pred_length": 15,
        "distinct-1": 0.8857142857142857,
        "vocab_size-1": 31,
        "unique-1": 28,
        "entropy-1": 4.8791433740260075,
        "distinct-2": 1.0,
        "vocab_size-2": 32,
        "unique-2": 32,
        "entropy-2": 5.0,
        "cond_entropy-2": -0.004283016944966456,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.14201900487242786,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 9.666666666666666,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9310344827586207,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.720049960644813,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": -0.0036951231403261845,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.523561956057013,
        "cond_entropy-3-nopunct": -0.17687776208407924,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3203952726624584,
        "rouge1": {
            "precision": 0.68077,
            "recall": 0.68452,
            "fmeasure": 0.64962
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.47757,
            "fmeasure": 0.46168
        },
        "rougeL": {
            "precision": 0.5953,
            "recall": 0.64352,
            "fmeasure": 0.5943
        },
        "rougeLsum": {
            "precision": 0.5953,
            "recall": 0.64352,
            "fmeasure": 0.5943
        },
        "bleu": 30.01731,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.35294117647058826,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.926,
            "recall": 0.92916,
            "f1": 0.92427
        },
        "nubia": {
            "semantic_relation": 3.86719,
            "contradiction": 2.58958,
            "irrelevancy": 44.02857,
            "logical_agreement": 53.38185,
            "grammar_ref": 6.27104,
            "grammar_hyp": 5.46677,
            "nubia_score": 0.67598
        },
        "meteor": 0.29909941382279315,
        "bleurt": 0.26772
    },
    "totto_test_contrast_challenge_table_size-table_size_544": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0286497677077553,
        "rouge1": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.875,
            "fmeasure": 0.82353
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 1.0,
            "fmeasure": 0.94737
        },
        "bleu": 70.16879,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98524,
            "recall": 0.9921,
            "f1": 0.98866
        },
        "nubia": {
            "semantic_relation": 4.89761,
            "contradiction": 0.83309,
            "irrelevancy": 31.2673,
            "logical_agreement": 67.89961,
            "grammar_ref": 5.45224,
            "grammar_hyp": 4.86831,
            "nubia_score": 0.98957
        },
        "meteor": 0.5613051214200641,
        "bleurt": 0.76221
    },
    "totto_test_contrast_challenge_table_size-table_size_606": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.7727272727272727,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.877394335127368,
        "distinct-2": 1.0,
        "vocab_size-2": 40,
        "unique-2": 40,
        "entropy-2": 5.3219280948873635,
        "cond_entropy-2": 0.30273748811098505,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.825,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.881687083026442,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.1699250014423095,
        "cond_entropy-2-nopunct": 0.3371535864004171,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 32,
        "entropy-3-nopunct": 5.0,
        "cond_entropy-3-nopunct": -0.16992500144231223,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.430791396579802,
        "rouge1": {
            "precision": 0.74653,
            "recall": 0.8131,
            "fmeasure": 0.76982
        },
        "rouge2": {
            "precision": 0.52895,
            "recall": 0.5472,
            "fmeasure": 0.53146
        },
        "rougeL": {
            "precision": 0.72569,
            "recall": 0.78717,
            "fmeasure": 0.74673
        },
        "rougeLsum": {
            "precision": 0.72569,
            "recall": 0.78717,
            "fmeasure": 0.74673
        },
        "bleu": 55.16704,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.7,
            "3": 0.84
        },
        "bertscore": {
            "precision": 0.93879,
            "recall": 0.95721,
            "f1": 0.94694
        },
        "nubia": {
            "semantic_relation": 4.32867,
            "contradiction": 0.91201,
            "irrelevancy": 45.63834,
            "logical_agreement": 53.44965,
            "grammar_ref": 4.98306,
            "grammar_hyp": 4.91049,
            "nubia_score": 0.76065
        },
        "meteor": 0.4801367645438559,
        "bleurt": 0.52535
    },
    "totto_test_contrast_challenge_table_size-table_size_780": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1699250014423126,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.22767,
            "irrelevancy": 0.5448,
            "logical_agreement": 99.22753,
            "grammar_ref": 5.18772,
            "grammar_hyp": 5.18772,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.99428
    },
    "totto_test_contrast_challenge_table_size-table_size_608": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 14.5,
        "std_pred_length": 2.5,
        "median_pred_length": 14.5,
        "min_pred_length": 12,
        "max_pred_length": 17,
        "distinct-1": 0.7586206896551724,
        "vocab_size-1": 22,
        "unique-1": 15,
        "entropy-1": 4.375222374437917,
        "distinct-2": 0.8518518518518519,
        "vocab_size-2": 23,
        "unique-2": 19,
        "entropy-2": 4.458591205867174,
        "cond_entropy-2": 0.04505465518404472,
        "distinct-3": 0.92,
        "vocab_size-3": 23,
        "unique-3": 21,
        "entropy-3": 4.4838561897747224,
        "cond_entropy-3": 0.04896868761125604,
        "total_length-nopunct": 27,
        "mean_pred_length-nopunct": 13.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 13.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.310443057719025,
        "distinct-2-nopunct": 0.84,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.323856189774723,
        "cond_entropy-2-nopunct": 0.008968687611256035,
        "distinct-3-nopunct": 0.9130434782608695,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.349648912578752,
        "cond_entropy-3-nopunct": 0.010140548890983897,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.434829413078659,
        "rouge1": {
            "precision": 0.69034,
            "recall": 0.78791,
            "fmeasure": 0.73547
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.52259,
            "fmeasure": 0.49609
        },
        "rougeL": {
            "precision": 0.67992,
            "recall": 0.74524,
            "fmeasure": 0.71101
        },
        "rougeLsum": {
            "precision": 0.67992,
            "recall": 0.74524,
            "fmeasure": 0.71101
        },
        "bleu": 44.20978,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.92859,
            "recall": 0.92859,
            "f1": 0.92858
        },
        "nubia": {
            "semantic_relation": 4.7593,
            "contradiction": 0.28663,
            "irrelevancy": 23.32403,
            "logical_agreement": 76.38933,
            "grammar_ref": 4.34398,
            "grammar_hyp": 4.84744,
            "nubia_score": 0.82495
        },
        "meteor": 0.4228755295950793,
        "bleurt": 0.46467
    },
    "totto_test_contrast_challenge_table_size-table_size_472": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910024,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.2186000898557489,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.433288378057127,
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.75,
            "fmeasure": 0.75
        },
        "rougeL": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "rougeLsum": {
            "precision": 0.88235,
            "recall": 0.88235,
            "fmeasure": 0.88235
        },
        "bleu": 78.39204,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96805,
            "recall": 0.97648,
            "f1": 0.97224
        },
        "nubia": {
            "semantic_relation": 4.85453,
            "contradiction": 0.33848,
            "irrelevancy": 2.11318,
            "logical_agreement": 97.54834,
            "grammar_ref": 5.82691,
            "grammar_hyp": 5.31084,
            "nubia_score": 0.99053
        },
        "meteor": 0.5347033086663171,
        "bleurt": 0.61374
    },
    "totto_test_contrast_challenge_table_size-table_size_609": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819113,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765365,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.956599148311473,
        "rouge1": {
            "precision": 0.69841,
            "recall": 0.7218,
            "fmeasure": 0.70952
        },
        "rouge2": {
            "precision": 0.55,
            "recall": 0.54127,
            "fmeasure": 0.54553
        },
        "rougeL": {
            "precision": 0.38095,
            "recall": 0.37518,
            "fmeasure": 0.378
        },
        "rougeLsum": {
            "precision": 0.38095,
            "recall": 0.37518,
            "fmeasure": 0.378
        },
        "bleu": 47.1548,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7222222222222222
        },
        "bertscore": {
            "precision": 0.91468,
            "recall": 0.91371,
            "f1": 0.91419
        },
        "nubia": {
            "semantic_relation": 4.40507,
            "contradiction": 0.35496,
            "irrelevancy": 6.86532,
            "logical_agreement": 92.77971,
            "grammar_ref": 5.09304,
            "grammar_hyp": 4.37804,
            "nubia_score": 0.84109
        },
        "meteor": 0.3651492865615115,
        "bleurt": -0.25382
    },
    "totto_test_contrast_challenge_table_size-table_size_473": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.747525402134557,
        "rouge1": {
            "precision": 0.88235,
            "recall": 0.74371,
            "fmeasure": 0.80556
        },
        "rouge2": {
            "precision": 0.60417,
            "recall": 0.50673,
            "fmeasure": 0.55005
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.59497,
            "fmeasure": 0.64444
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.59497,
            "fmeasure": 0.64444
        },
        "bleu": 40.47783,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8235294117647058
        },
        "bertscore": {
            "precision": 0.9387,
            "recall": 0.88414,
            "f1": 0.91061
        },
        "nubia": {
            "semantic_relation": 3.8234,
            "contradiction": 0.44694,
            "irrelevancy": 0.55898,
            "logical_agreement": 98.99409,
            "grammar_ref": 4.86737,
            "grammar_hyp": 5.78869,
            "nubia_score": 0.53539
        },
        "meteor": 0.41518726373638143,
        "bleurt": 0.06147
    },
    "totto_test_contrast_challenge_table_size-table_size_625": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7466357445501193,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.60513,
            "fmeasure": 0.6337
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.23737,
            "fmeasure": 0.29085
        },
        "rougeL": {
            "precision": 0.41026,
            "recall": 0.27648,
            "fmeasure": 0.32479
        },
        "rougeLsum": {
            "precision": 0.41026,
            "recall": 0.27648,
            "fmeasure": 0.32479
        },
        "bleu": 38.72016,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5833333333333334
        },
        "bertscore": {
            "precision": 0.84033,
            "recall": 0.7991,
            "f1": 0.8192
        },
        "nubia": {
            "semantic_relation": 3.0923,
            "contradiction": 4.20207,
            "irrelevancy": 32.23182,
            "logical_agreement": 63.56611,
            "grammar_ref": 4.61776,
            "grammar_hyp": 4.14307,
            "nubia_score": 0.42388
        },
        "meteor": 0.2728620586718552,
        "bleurt": -0.42603
    },
    "totto_test_contrast_challenge_table_size-table_size_576": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 60,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 21.0,
        "min_pred_length": 15,
        "max_pred_length": 24,
        "distinct-1": 0.75,
        "vocab_size-1": 45,
        "unique-1": 36,
        "entropy-1": 5.289898095464286,
        "distinct-2": 1.0,
        "vocab_size-2": 57,
        "unique-2": 57,
        "entropy-2": 5.832890014164737,
        "cond_entropy-2": 0.49204612919640617,
        "distinct-3": 1.0,
        "vocab_size-3": 54,
        "unique-3": 54,
        "entropy-3": 5.7548875021634665,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 53,
        "mean_pred_length-nopunct": 17.666666666666668,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7924528301886793,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.194624935572811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 50,
        "unique-2-nopunct": 50,
        "entropy-2-nopunct": 5.643856189774728,
        "cond_entropy-2-nopunct": 0.4812289853413335,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 47,
        "entropy-3-nopunct": 5.55458885167764,
        "cond_entropy-3-nopunct": -0.08926733809708727,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.898907557630832,
        "rouge1": {
            "precision": 0.79637,
            "recall": 0.79151,
            "fmeasure": 0.79053
        },
        "rouge2": {
            "precision": 0.5614,
            "recall": 0.57829,
            "fmeasure": 0.56714
        },
        "rougeL": {
            "precision": 0.73818,
            "recall": 0.74431,
            "fmeasure": 0.73833
        },
        "rougeLsum": {
            "precision": 0.73818,
            "recall": 0.74431,
            "fmeasure": 0.73833
        },
        "bleu": 50.80372,
        "local_recall": {
            "1": 0.4444444444444444,
            "2": 0.625,
            "3": 0.9642857142857143
        },
        "bertscore": {
            "precision": 0.93867,
            "recall": 0.94415,
            "f1": 0.93875
        },
        "nubia": {
            "semantic_relation": 4.21625,
            "contradiction": 16.26345,
            "irrelevancy": 8.43203,
            "logical_agreement": 75.30451,
            "grammar_ref": 4.44265,
            "grammar_hyp": 3.80356,
            "nubia_score": 0.80625
        },
        "meteor": 0.44586901396694484,
        "bleurt": 0.48236
    },
    "totto_test_contrast_challenge_table_size-table_size_474": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 0.5,
        "median_pred_length": 12.5,
        "min_pred_length": 12,
        "max_pred_length": 13,
        "distinct-1": 0.72,
        "vocab_size-1": 18,
        "unique-1": 11,
        "entropy-1": 4.083856189774723,
        "distinct-2": 0.8695652173913043,
        "vocab_size-2": 20,
        "unique-2": 17,
        "entropy-2": 4.2626923908396215,
        "cond_entropy-2": 0.14057533149967955,
        "distinct-3": 0.9047619047619048,
        "vocab_size-3": 19,
        "unique-3": 17,
        "entropy-3": 4.201841232302569,
        "cond_entropy-3": -0.03600643804015718,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7391304347826086,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 4.001822825622231,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.106603137064473,
        "cond_entropy-2-nopunct": 0.15446975243603328,
        "distinct-3-nopunct": 0.8947368421052632,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.03740119765411,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.5910365256860315,
        "rouge1": {
            "precision": 0.90152,
            "recall": 0.91667,
            "fmeasure": 0.90873
        },
        "rouge2": {
            "precision": 0.73939,
            "recall": 0.75421,
            "fmeasure": 0.74641
        },
        "rougeL": {
            "precision": 0.90152,
            "recall": 0.91667,
            "fmeasure": 0.90873
        },
        "rougeLsum": {
            "precision": 0.90152,
            "recall": 0.91667,
            "fmeasure": 0.90873
        },
        "bleu": 61.68604,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "bertscore": {
            "precision": 0.97841,
            "recall": 0.97422,
            "f1": 0.9763
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29693,
            "irrelevancy": 0.5435,
            "logical_agreement": 99.15957,
            "grammar_ref": 4.16906,
            "grammar_hyp": 4.45846,
            "nubia_score": 0.93134
        },
        "meteor": 0.5186556096806619,
        "bleurt": 0.85603
    },
    "totto_test_contrast_challenge_table_size-table_size_627": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.113811900368983,
        "rouge1": {
            "precision": 0.45,
            "recall": 0.55901,
            "fmeasure": 0.49248
        },
        "rouge2": {
            "precision": 0.21053,
            "recall": 0.26573,
            "fmeasure": 0.23171
        },
        "rougeL": {
            "precision": 0.35,
            "recall": 0.43478,
            "fmeasure": 0.38304
        },
        "rougeLsum": {
            "precision": 0.35,
            "recall": 0.43478,
            "fmeasure": 0.38304
        },
        "bleu": 6.65858,
        "local_recall": {
            "1": 0.0,
            "2": 0.1,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.82098,
            "recall": 0.84633,
            "f1": 0.83346
        },
        "nubia": {
            "semantic_relation": 3.86699,
            "contradiction": 0.06599,
            "irrelevancy": 98.98315,
            "logical_agreement": 0.95085,
            "grammar_ref": 4.57081,
            "grammar_hyp": 3.63188,
            "nubia_score": 0.76561
        },
        "meteor": 0.31212747272237856,
        "bleurt": -0.10017
    },
    "totto_test_contrast_challenge_table_size-table_size_610": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569684,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966062,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.476798555485602,
        "rouge1": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.9375,
            "fmeasure": 0.9375
        },
        "rougeL": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "rougeLsum": {
            "precision": 0.94118,
            "recall": 0.94118,
            "fmeasure": 0.94118
        },
        "bleu": 90.8655,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.9375
        },
        "bertscore": {
            "precision": 0.98484,
            "recall": 0.98886,
            "f1": 0.98685
        },
        "nubia": {
            "semantic_relation": 3.73924,
            "contradiction": 97.74814,
            "irrelevancy": 1.732,
            "logical_agreement": 0.51986,
            "grammar_ref": 5.25838,
            "grammar_hyp": 5.11348,
            "nubia_score": 0.53087
        },
        "meteor": 0.5772487688020834,
        "bleurt": 0.71432
    },
    "totto_test_contrast_challenge_table_size-table_size_708": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 12.666666666666666,
        "std_pred_length": 1.699673171197595,
        "median_pred_length": 12.0,
        "min_pred_length": 11,
        "max_pred_length": 15,
        "distinct-1": 0.7368421052631579,
        "vocab_size-1": 28,
        "unique-1": 19,
        "entropy-1": 4.701746263386654,
        "distinct-2": 0.8285714285714286,
        "vocab_size-2": 29,
        "unique-2": 23,
        "entropy-2": 4.78642587408782,
        "cond_entropy-2": -0.004358782212904647,
        "distinct-3": 0.84375,
        "vocab_size-3": 27,
        "unique-3": 22,
        "entropy-3": 4.6875,
        "cond_entropy-3": -0.06678301694496641,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.816496580927726,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7878787878787878,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.620151695116031,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.506890595608519,
        "cond_entropy-2-nopunct": -0.07083685708326805,
        "distinct-3-nopunct": 0.8148148148148148,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.384517131793101,
        "cond_entropy-3-nopunct": -0.07792901937097599,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.419878658270777,
        "rouge1": {
            "precision": 0.91111,
            "recall": 0.96667,
            "fmeasure": 0.93636
        },
        "rouge2": {
            "precision": 0.84175,
            "recall": 0.88889,
            "fmeasure": 0.86296
        },
        "rougeL": {
            "precision": 0.91111,
            "recall": 0.96667,
            "fmeasure": 0.93636
        },
        "rougeLsum": {
            "precision": 0.91111,
            "recall": 0.96667,
            "fmeasure": 0.93636
        },
        "bleu": 78.25423,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9523809523809523
        },
        "bertscore": {
            "precision": 0.98159,
            "recall": 0.99176,
            "f1": 0.98662
        },
        "nubia": {
            "semantic_relation": 4.63161,
            "contradiction": 23.76302,
            "irrelevancy": 22.10987,
            "logical_agreement": 54.12711,
            "grammar_ref": 5.72052,
            "grammar_hyp": 5.72558,
            "nubia_score": 0.78048
        },
        "meteor": 0.5655155935442364,
        "bleurt": 0.7991
    },
    "totto_test_contrast_challenge_table_size-table_size_785": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.5833333333333334,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.6682958340544896,
        "distinct-2": 0.7727272727272727,
        "vocab_size-2": 17,
        "unique-2": 12,
        "entropy-2": 4.004886164091841,
        "cond_entropy-2": 0.3290145724615955,
        "distinct-3": 0.8,
        "vocab_size-3": 16,
        "unique-3": 12,
        "entropy-3": 3.9219280948873623,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.5503407095463877,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.821928094887362,
        "cond_entropy-2-nopunct": 0.362496476250065,
        "distinct-3-nopunct": 0.7777777777777778,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.7254805569978675,
        "cond_entropy-3-nopunct": -0.04089198233393865,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.232198344961961,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.8323,
            "fmeasure": 0.864
        },
        "rouge2": {
            "precision": 0.76667,
            "recall": 0.70694,
            "fmeasure": 0.73147
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.8127,
            "fmeasure": 0.84019
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.8127,
            "fmeasure": 0.84019
        },
        "bleu": 74.31012,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98829,
            "recall": 0.98829,
            "f1": 0.98829
        },
        "nubia": {
            "semantic_relation": 4.98669,
            "contradiction": 0.38391,
            "irrelevancy": 0.51253,
            "logical_agreement": 99.10356,
            "grammar_ref": 4.6711,
            "grammar_hyp": 4.45721,
            "nubia_score": 0.98188
        },
        "meteor": 0.9692307692307691,
        "bleurt": 0.61954
    },
    "totto_test_contrast_challenge_table_size-table_size_630": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 71,
        "mean_pred_length": 17.75,
        "std_pred_length": 4.085033659592048,
        "median_pred_length": 19.5,
        "min_pred_length": 11,
        "max_pred_length": 21,
        "distinct-1": 0.5352112676056338,
        "vocab_size-1": 38,
        "unique-1": 22,
        "entropy-1": 4.860120037683032,
        "distinct-2": 0.7761194029850746,
        "vocab_size-2": 52,
        "unique-2": 37,
        "entropy-2": 5.6183279964279205,
        "cond_entropy-2": 0.7157976352715563,
        "distinct-3": 0.8253968253968254,
        "vocab_size-3": 52,
        "unique-3": 41,
        "entropy-3": 5.628073574293568,
        "cond_entropy-3": 0.006428828280239284,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 4.092676385936225,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.5454545454545454,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.778280137398802,
        "distinct-2-nopunct": 0.7741935483870968,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.502583407161069,
        "cond_entropy-2-nopunct": 0.7737299782757959,
        "distinct-3-nopunct": 0.8103448275862069,
        "vocab_size-3-nopunct": 47,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.478670650299984,
        "cond_entropy-3-nopunct": 0.0072329606027659935,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.218744479015068,
        "rouge1": {
            "precision": 0.75312,
            "recall": 0.79476,
            "fmeasure": 0.77028
        },
        "rouge2": {
            "precision": 0.58187,
            "recall": 0.62285,
            "fmeasure": 0.59879
        },
        "rougeL": {
            "precision": 0.69687,
            "recall": 0.73657,
            "fmeasure": 0.7132
        },
        "rougeLsum": {
            "precision": 0.69687,
            "recall": 0.73657,
            "fmeasure": 0.7132
        },
        "bleu": 47.0437,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7843137254901961
        },
        "bertscore": {
            "precision": 0.92942,
            "recall": 0.9449,
            "f1": 0.93706
        },
        "nubia": {
            "semantic_relation": 3.89122,
            "contradiction": 41.69965,
            "irrelevancy": 14.43655,
            "logical_agreement": 43.86379,
            "grammar_ref": 3.98368,
            "grammar_hyp": 3.81728,
            "nubia_score": 0.66413
        },
        "meteor": 0.40341940686835637,
        "bleurt": 0.48452
    },
    "totto_test_contrast_challenge_table_size-table_size_720": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 63,
        "mean_pred_length": 15.75,
        "std_pred_length": 4.9180788932265,
        "median_pred_length": 13.5,
        "min_pred_length": 12,
        "max_pred_length": 24,
        "distinct-1": 0.7301587301587301,
        "vocab_size-1": 46,
        "unique-1": 33,
        "entropy-1": 5.381886669462983,
        "distinct-2": 0.9491525423728814,
        "vocab_size-2": 56,
        "unique-2": 53,
        "entropy-2": 5.780948134107599,
        "cond_entropy-2": 0.35883579539011934,
        "distinct-3": 0.9818181818181818,
        "vocab_size-3": 54,
        "unique-3": 53,
        "entropy-3": 5.744996077161019,
        "cond_entropy-3": -0.02855606310990897,
        "total_length-nopunct": 58,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 44,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.327724314055787,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 51,
        "unique-2-nopunct": 48,
        "entropy-2-nopunct": 5.643776391052356,
        "cond_entropy-2-nopunct": 0.35533034966855354,
        "distinct-3-nopunct": 0.98,
        "vocab_size-3-nopunct": 49,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.603856189774728,
        "cond_entropy-3-nopunct": -0.031031312388743956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.757685787106591,
        "rouge1": {
            "precision": 0.72403,
            "recall": 0.76158,
            "fmeasure": 0.7267
        },
        "rouge2": {
            "precision": 0.50307,
            "recall": 0.53032,
            "fmeasure": 0.50865
        },
        "rougeL": {
            "precision": 0.56494,
            "recall": 0.61956,
            "fmeasure": 0.57814
        },
        "rougeLsum": {
            "precision": 0.56494,
            "recall": 0.61956,
            "fmeasure": 0.57814
        },
        "bleu": 55.1843,
        "local_recall": {
            "1": 0.3125,
            "2": 0.5,
            "3": 0.8421052631578947
        },
        "bertscore": {
            "precision": 0.92729,
            "recall": 0.92442,
            "f1": 0.92393
        },
        "nubia": {
            "semantic_relation": 4.44268,
            "contradiction": 9.2342,
            "irrelevancy": 20.87615,
            "logical_agreement": 69.88965,
            "grammar_ref": 4.54108,
            "grammar_hyp": 4.41011,
            "nubia_score": 0.75152
        },
        "meteor": 0.4192730936911592,
        "bleurt": 0.46181
    },
    "totto_test_contrast_challenge_table_size-table_size_632": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 11,
        "unique-1": 9,
        "entropy-1": 3.3927474104487847,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.21785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.2516291673878226,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.2381054815525046,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.3411038620047611,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.38384,
            "fmeasure": 0.50679
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.31197,
            "fmeasure": 0.41779
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.34119,
            "fmeasure": 0.45048
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.34119,
            "fmeasure": 0.45048
        },
        "bleu": 20.4264,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.88093,
            "recall": 0.83265,
            "f1": 0.85611
        },
        "nubia": {
            "semantic_relation": 3.2368,
            "contradiction": 7.90976,
            "irrelevancy": 1.56267,
            "logical_agreement": 90.52756,
            "grammar_ref": 5.07625,
            "grammar_hyp": 5.20401,
            "nubia_score": 0.34231
        },
        "meteor": 0.2559610186768102,
        "bleurt": -0.25713
    },
    "totto_test_contrast_challenge_table_size-table_size_845": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.36574524146641324,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.42222,
            "fmeasure": 0.54444
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.38571,
            "fmeasure": 0.50649
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.42222,
            "fmeasure": 0.54444
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.42222,
            "fmeasure": 0.54444
        },
        "bleu": 36.2563,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.94282,
            "recall": 0.85197,
            "f1": 0.89509
        },
        "nubia": {
            "semantic_relation": 4.11099,
            "contradiction": 0.43449,
            "irrelevancy": 0.63632,
            "logical_agreement": 98.92919,
            "grammar_ref": 2.70093,
            "grammar_hyp": 3.06131,
            "nubia_score": 0.85587
        },
        "meteor": 0.2907157047389913,
        "bleurt": -0.23154
    },
    "totto_test_contrast_challenge_table_size-table_size_635": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.482634504257068,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2983,
            "irrelevancy": 0.53829,
            "logical_agreement": 99.16341,
            "grammar_ref": 5.3705,
            "grammar_hyp": 5.33734,
            "nubia_score": 0.99191
        },
        "meteor": 1.0,
        "bleurt": 0.76845
    },
    "totto_test_contrast_challenge_table_size-table_size_721": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.9545454545454546,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.368522527728205,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.45193483039471,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.81843,
            "fmeasure": 0.8799
        },
        "rouge2": {
            "precision": 0.725,
            "recall": 0.60934,
            "fmeasure": 0.66095
        },
        "rougeL": {
            "precision": 0.88131,
            "recall": 0.75455,
            "fmeasure": 0.81178
        },
        "rougeLsum": {
            "precision": 0.88131,
            "recall": 0.75455,
            "fmeasure": 0.81178
        },
        "bleu": 63.82745,
        "local_recall": {
            "1": 0.1,
            "2": 0.7692307692307693,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.98978,
            "recall": 0.95077,
            "f1": 0.96988
        },
        "nubia": {
            "semantic_relation": 4.44566,
            "contradiction": 1.89347,
            "irrelevancy": 2.26282,
            "logical_agreement": 95.84371,
            "grammar_ref": 4.61516,
            "grammar_hyp": 4.67834,
            "nubia_score": 0.80478
        },
        "meteor": 0.4376641492357371,
        "bleurt": 0.52275
    },
    "totto_test_contrast_challenge_table_size-table_size_849": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983795,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.975039200866105,
        "rouge1": {
            "precision": 0.74603,
            "recall": 0.65278,
            "fmeasure": 0.6963
        },
        "rouge2": {
            "precision": 0.38333,
            "recall": 0.343,
            "fmeasure": 0.36188
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.58333,
            "fmeasure": 0.62222
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.58333,
            "fmeasure": 0.62222
        },
        "bleu": 41.52094,
        "local_recall": {
            "1": 0.75,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "bertscore": {
            "precision": 0.92945,
            "recall": 0.87829,
            "f1": 0.90315
        },
        "nubia": {
            "semantic_relation": 4.42166,
            "contradiction": 0.1908,
            "irrelevancy": 0.46076,
            "logical_agreement": 99.34845,
            "grammar_ref": 3.8277,
            "grammar_hyp": 3.54621,
            "nubia_score": 0.90738
        },
        "meteor": 0.3608119819628908,
        "bleurt": 0.43909
    },
    "totto_test_contrast_challenge_table_size-table_size_852": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7109047337507373,
        "rouge1": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rouge2": {
            "precision": 0.45833,
            "recall": 0.65278,
            "fmeasure": 0.5381
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.79444,
            "fmeasure": 0.66798
        },
        "bleu": 53.10725,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.91794,
            "recall": 0.99099,
            "f1": 0.95307
        },
        "nubia": {
            "semantic_relation": 4.03158,
            "contradiction": 0.1933,
            "irrelevancy": 99.65987,
            "logical_agreement": 0.14683,
            "grammar_ref": 5.68221,
            "grammar_hyp": 4.97464,
            "nubia_score": 0.75981
        },
        "meteor": 0.5033950705050299,
        "bleurt": 0.22576
    },
    "totto_test_contrast_challenge_table_size-table_size_854": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 16.0,
        "min_pred_length": 10,
        "max_pred_length": 18,
        "distinct-1": 0.6590909090909091,
        "vocab_size-1": 29,
        "unique-1": 19,
        "entropy-1": 4.669547811769944,
        "distinct-2": 0.8292682926829268,
        "vocab_size-2": 34,
        "unique-2": 29,
        "entropy-2": 4.967308102179057,
        "cond_entropy-2": 0.23958380061493256,
        "distinct-3": 0.868421052631579,
        "vocab_size-3": 33,
        "unique-3": 28,
        "entropy-3": 4.984769618706746,
        "cond_entropy-3": 0.04827024566760735,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.8284271247461903,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.516171449631479,
        "distinct-2-nopunct": 0.8055555555555556,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.725480556997866,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 0.8484848484848485,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.741363816328152,
        "cond_entropy-3-nopunct": -0.004318760871737878,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.310352183979021,
        "rouge1": {
            "precision": 0.57647,
            "recall": 0.47469,
            "fmeasure": 0.50748
        },
        "rouge2": {
            "precision": 0.31548,
            "recall": 0.23557,
            "fmeasure": 0.26282
        },
        "rougeL": {
            "precision": 0.45098,
            "recall": 0.37028,
            "fmeasure": 0.39678
        },
        "rougeLsum": {
            "precision": 0.45098,
            "recall": 0.37028,
            "fmeasure": 0.39678
        },
        "bleu": 10.22251,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.47368421052631576
        },
        "bertscore": {
            "precision": 0.87761,
            "recall": 0.83116,
            "f1": 0.85345
        },
        "nubia": {
            "semantic_relation": 3.24417,
            "contradiction": 1.55219,
            "irrelevancy": 55.59422,
            "logical_agreement": 42.85359,
            "grammar_ref": 3.73262,
            "grammar_hyp": 4.4093,
            "nubia_score": 0.44307
        },
        "meteor": 0.2616182992151852,
        "bleurt": -0.28024
    },
    "totto_test_contrast_challenge_table_size-table_size_672": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 38,
        "mean_pred_length": 19.0,
        "std_pred_length": 4.0,
        "median_pred_length": 19.0,
        "min_pred_length": 15,
        "max_pred_length": 23,
        "distinct-1": 0.8157894736842105,
        "vocab_size-1": 31,
        "unique-1": 26,
        "entropy-1": 4.826874881864639,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.3108863768876157,
        "distinct-3": 1.0,
        "vocab_size-3": 34,
        "unique-3": 34,
        "entropy-3": 5.087462841250338,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.8285714285714286,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.729283016944964,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.044394119358456,
        "cond_entropy-2-nopunct": 0.33935352665591095,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.09019780897157811,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.958213677682171,
        "rouge1": {
            "precision": 0.74118,
            "recall": 0.66941,
            "fmeasure": 0.70324
        },
        "rouge2": {
            "precision": 0.41815,
            "recall": 0.40741,
            "fmeasure": 0.41117
        },
        "rougeL": {
            "precision": 0.58301,
            "recall": 0.55322,
            "fmeasure": 0.56656
        },
        "rougeLsum": {
            "precision": 0.58301,
            "recall": 0.55322,
            "fmeasure": 0.56656
        },
        "bleu": 38.02301,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.8977,
            "recall": 0.86365,
            "f1": 0.87793
        },
        "nubia": {
            "semantic_relation": 3.26241,
            "contradiction": 0.15178,
            "irrelevancy": 50.19732,
            "logical_agreement": 49.65091,
            "grammar_ref": 4.36031,
            "grammar_hyp": 4.07629,
            "nubia_score": 0.52401
        },
        "meteor": 0.359014492875647,
        "bleurt": -0.04864
    },
    "totto_test_contrast_challenge_table_size-table_size_855": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 3.975418017913833,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.3673550472167754,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7946534735443413,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.3148841634647016,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.990371243018509,
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.79365,
            "fmeasure": 0.8547
        },
        "rouge2": {
            "precision": 0.56863,
            "recall": 0.64487,
            "fmeasure": 0.5982
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.60317,
            "fmeasure": 0.64957
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.60317,
            "fmeasure": 0.64957
        },
        "bleu": 55.25597,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.96851,
            "recall": 0.94997,
            "f1": 0.94548
        },
        "nubia": {
            "semantic_relation": 4.17184,
            "contradiction": 0.14477,
            "irrelevancy": 33.54059,
            "logical_agreement": 66.31464,
            "grammar_ref": 3.68983,
            "grammar_hyp": 3.36814,
            "nubia_score": 0.85832
        },
        "meteor": 0.484222175901938,
        "bleurt": 0.39828
    },
    "totto_test_contrast_challenge_table_size-table_size_612": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 48,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.559026084010437,
        "median_pred_length": 14.0,
        "min_pred_length": 13,
        "max_pred_length": 21,
        "distinct-1": 0.8541666666666666,
        "vocab_size-1": 41,
        "unique-1": 38,
        "entropy-1": 5.202368167875321,
        "distinct-2": 1.0,
        "vocab_size-2": 45,
        "unique-2": 45,
        "entropy-2": 5.491853096329673,
        "cond_entropy-2": 0.20932705059600273,
        "distinct-3": 1.0,
        "vocab_size-3": 42,
        "unique-3": 42,
        "entropy-3": 5.3923174227787625,
        "cond_entropy-3": -0.0995356735509143,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 14.666666666666666,
        "std_pred_length-nopunct": 3.0912061651652345,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8863636363636364,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 37,
        "entropy-1-nopunct": 5.150121607854642,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.357552004618081,
        "cond_entropy-2-nopunct": 0.23006283657680598,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.10962449117449787,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.094831109848609,
        "rouge1": {
            "precision": 0.52393,
            "recall": 0.54154,
            "fmeasure": 0.52783
        },
        "rouge2": {
            "precision": 0.30728,
            "recall": 0.32875,
            "fmeasure": 0.31326
        },
        "rougeL": {
            "precision": 0.49338,
            "recall": 0.5069,
            "fmeasure": 0.49561
        },
        "rougeLsum": {
            "precision": 0.49338,
            "recall": 0.5069,
            "fmeasure": 0.49561
        },
        "bleu": 26.01278,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.38461538461538464,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.88344,
            "recall": 0.89449,
            "f1": 0.8882
        },
        "nubia": {
            "semantic_relation": 3.87314,
            "contradiction": 0.21775,
            "irrelevancy": 67.56144,
            "logical_agreement": 32.2208,
            "grammar_ref": 4.28129,
            "grammar_hyp": 4.01519,
            "nubia_score": 0.70589
        },
        "meteor": 0.3082803605782259,
        "bleurt": 0.17521
    },
    "totto_test_contrast_challenge_table_size-table_size_580": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 72,
        "mean_pred_length": 14.4,
        "std_pred_length": 4.409081537009721,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.8194444444444444,
        "vocab_size-1": 59,
        "unique-1": 50,
        "entropy-1": 5.748195446211757,
        "distinct-2": 0.9402985074626866,
        "vocab_size-2": 63,
        "unique-2": 59,
        "entropy-2": 5.946686205383141,
        "cond_entropy-2": 0.05668489800297448,
        "distinct-3": 0.9516129032258065,
        "vocab_size-3": 59,
        "unique-3": 56,
        "entropy-3": 5.857422116838485,
        "cond_entropy-3": -0.0796348155547681,
        "total_length-nopunct": 66,
        "mean_pred_length-nopunct": 13.2,
        "std_pred_length-nopunct": 4.261455150532504,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8636363636363636,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.760229157204468,
        "distinct-2-nopunct": 0.9344262295081968,
        "vocab_size-2-nopunct": 57,
        "unique-2-nopunct": 53,
        "entropy-2-nopunct": 5.799589796579275,
        "cond_entropy-2-nopunct": 0.02986596414153877,
        "distinct-3-nopunct": 0.9464285714285714,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 50,
        "entropy-3-nopunct": 5.7002120649147505,
        "cond_entropy-3-nopunct": -0.10552527264813905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.213709063811574,
        "rouge1": {
            "precision": 0.65481,
            "recall": 0.76849,
            "fmeasure": 0.69759
        },
        "rouge2": {
            "precision": 0.47542,
            "recall": 0.56954,
            "fmeasure": 0.50882
        },
        "rougeL": {
            "precision": 0.56593,
            "recall": 0.67302,
            "fmeasure": 0.60564
        },
        "rougeLsum": {
            "precision": 0.56593,
            "recall": 0.67302,
            "fmeasure": 0.60564
        },
        "bleu": 41.99819,
        "local_recall": {
            "1": 0.2777777777777778,
            "2": 0.75,
            "3": 0.8222222222222222
        },
        "bertscore": {
            "precision": 0.91403,
            "recall": 0.94579,
            "f1": 0.9257
        },
        "nubia": {
            "semantic_relation": 4.10748,
            "contradiction": 20.60548,
            "irrelevancy": 35.76558,
            "logical_agreement": 43.62894,
            "grammar_ref": 5.55931,
            "grammar_hyp": 5.2423,
            "nubia_score": 0.69665
        },
        "meteor": 0.4432182697136018,
        "bleurt": 0.35846
    },
    "totto_test_contrast_challenge_table_size-table_size_726": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 14.666666666666666,
        "std_pred_length": 1.8856180831641267,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.9318181818181818,
        "vocab_size-1": 41,
        "unique-1": 39,
        "entropy-1": 5.30591144813358,
        "distinct-2": 1.0,
        "vocab_size-2": 41,
        "unique-2": 41,
        "entropy-2": 5.357552004618081,
        "cond_entropy-2": -0.05309912621433557,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.10962449117449787,
        "total_length-nopunct": 40,
        "mean_pred_length-nopunct": 13.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.975,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.271928094887364,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 37,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.209453365628954,
        "cond_entropy-2-nopunct": -0.05842067520435854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 34,
        "entropy-3-nopunct": 5.087462841250338,
        "cond_entropy-3-nopunct": -0.12199052437861026,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6098336704733915,
        "rouge1": {
            "precision": 0.8619,
            "recall": 0.83303,
            "fmeasure": 0.84422
        },
        "rouge2": {
            "precision": 0.67766,
            "recall": 0.66361,
            "fmeasure": 0.66747
        },
        "rougeL": {
            "precision": 0.68889,
            "recall": 0.67622,
            "fmeasure": 0.67965
        },
        "rougeLsum": {
            "precision": 0.68889,
            "recall": 0.67622,
            "fmeasure": 0.67965
        },
        "bleu": 55.92651,
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.9130434782608695
        },
        "bertscore": {
            "precision": 0.94461,
            "recall": 0.95693,
            "f1": 0.95
        },
        "nubia": {
            "semantic_relation": 4.24179,
            "contradiction": 3.95316,
            "irrelevancy": 62.39251,
            "logical_agreement": 33.65433,
            "grammar_ref": 4.8308,
            "grammar_hyp": 5.27361,
            "nubia_score": 0.65632
        },
        "meteor": 0.472545500415779,
        "bleurt": 0.33942
    },
    "totto_test_contrast_challenge_table_size-table_size_791": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846627,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.02961067210860201,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9181712229501409,
        "rouge1": {
            "precision": 0.39683,
            "recall": 0.35606,
            "fmeasure": 0.37519
        },
        "rouge2": {
            "precision": 0.08333,
            "recall": 0.07384,
            "fmeasure": 0.07828
        },
        "rougeL": {
            "precision": 0.36508,
            "recall": 0.32828,
            "fmeasure": 0.34556
        },
        "rougeLsum": {
            "precision": 0.36508,
            "recall": 0.32828,
            "fmeasure": 0.34556
        },
        "bleu": 5.36871,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0,
            "3": 0.3157894736842105
        },
        "bertscore": {
            "precision": 0.86092,
            "recall": 0.8785,
            "f1": 0.86962
        },
        "nubia": {
            "semantic_relation": 3.49373,
            "contradiction": 0.41542,
            "irrelevancy": 64.61329,
            "logical_agreement": 34.97129,
            "grammar_ref": 4.34096,
            "grammar_hyp": 5.58348,
            "nubia_score": 0.42729
        },
        "meteor": 0.21993925959762242,
        "bleurt": -0.18457
    },
    "totto_test_contrast_challenge_table_size-table_size_792": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.0,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.9,
        "vocab_size-1": 27,
        "unique-1": 25,
        "entropy-1": 4.681727678869737,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.07028173724063806,
        "distinct-3": 1.0,
        "vocab_size-3": 26,
        "unique-3": 26,
        "entropy-3": 4.70043971814109,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.517559429596341,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.08264309517020868,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.044728831387372,
        "rouge1": {
            "precision": 0.68998,
            "recall": 0.67222,
            "fmeasure": 0.67079
        },
        "rouge2": {
            "precision": 0.38611,
            "recall": 0.36937,
            "fmeasure": 0.37176
        },
        "rougeL": {
            "precision": 0.44406,
            "recall": 0.40833,
            "fmeasure": 0.42029
        },
        "rougeLsum": {
            "precision": 0.44406,
            "recall": 0.40833,
            "fmeasure": 0.42029
        },
        "bleu": 40.3364,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.0,
            "3": 0.7619047619047619
        },
        "bertscore": {
            "precision": 0.91381,
            "recall": 0.91424,
            "f1": 0.91395
        },
        "nubia": {
            "semantic_relation": 3.85209,
            "contradiction": 2.21719,
            "irrelevancy": 18.59773,
            "logical_agreement": 79.18508,
            "grammar_ref": 4.56769,
            "grammar_hyp": 4.82463,
            "nubia_score": 0.54056
        },
        "meteor": 0.35743429022447126,
        "bleurt": -0.00903
    },
    "totto_test_contrast_challenge_table_size-table_size_581": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9767769323620341,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.53704,
            "fmeasure": 0.61275
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.67879,
            "fmeasure": 0.76413
        },
        "bleu": 24.839,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.97642,
            "recall": 0.95148,
            "f1": 0.96379
        },
        "nubia": {
            "semantic_relation": 4.74089,
            "contradiction": 0.54392,
            "irrelevancy": 0.53393,
            "logical_agreement": 98.92214,
            "grammar_ref": 4.19474,
            "grammar_hyp": 4.75139,
            "nubia_score": 0.91626
        },
        "meteor": 0.41910267807653556,
        "bleurt": 0.604
    },
    "totto_test_contrast_challenge_table_size-table_size_728": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 4.001822825622231,
        "distinct-2": 0.9523809523809523,
        "vocab_size-2": 20,
        "unique-2": 19,
        "entropy-2": 4.297079327540665,
        "cond_entropy-2": 0.24970784767412843,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.03912675144043809,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.821928094887362,
        "distinct-2-nopunct": 0.9444444444444444,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.058813890331201,
        "cond_entropy-2-nopunct": 0.23688579544383911,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.10742500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9538925688280537,
        "rouge1": {
            "precision": 0.5625,
            "recall": 0.58226,
            "fmeasure": 0.52778
        },
        "rouge2": {
            "precision": 0.25758,
            "recall": 0.29848,
            "fmeasure": 0.24878
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.52422,
            "fmeasure": 0.46398
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.52422,
            "fmeasure": 0.46398
        },
        "bleu": 23.84077,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.88191,
            "recall": 0.90917,
            "f1": 0.89272
        },
        "nubia": {
            "semantic_relation": 3.55961,
            "contradiction": 2.64614,
            "irrelevancy": 62.80955,
            "logical_agreement": 34.54431,
            "grammar_ref": 5.09196,
            "grammar_hyp": 4.91675,
            "nubia_score": 0.53058
        },
        "meteor": 0.34888673430076783,
        "bleurt": -0.31216
    },
    "totto_test_contrast_challenge_table_size-table_size_856": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 3.975418017913832,
        "distinct-2": 0.95,
        "vocab_size-2": 19,
        "unique-2": 18,
        "entropy-2": 4.221928094887362,
        "cond_entropy-2": 0.26735504721677544,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": 0.03126257645096009,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.884183719779189,
        "distinct-2-nopunct": 0.9473684210526315,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.142664355548846,
        "cond_entropy-2-nopunct": 0.281519813406932,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": 0.03310859910983796,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7942883836897763,
        "rouge1": {
            "precision": 0.56522,
            "recall": 0.59325,
            "fmeasure": 0.57834
        },
        "rouge2": {
            "precision": 0.30303,
            "recall": 0.33333,
            "fmeasure": 0.31746
        },
        "rougeL": {
            "precision": 0.30435,
            "recall": 0.31944,
            "fmeasure": 0.31141
        },
        "rougeLsum": {
            "precision": 0.30435,
            "recall": 0.31944,
            "fmeasure": 0.31141
        },
        "bleu": 25.78733,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.87476,
            "recall": 0.86605,
            "f1": 0.86676
        },
        "nubia": {
            "semantic_relation": 3.33163,
            "contradiction": 6.32759,
            "irrelevancy": 91.75123,
            "logical_agreement": 1.92118,
            "grammar_ref": 6.02354,
            "grammar_hyp": 5.7104,
            "nubia_score": 0.46318
        },
        "meteor": 0.3196403503438288,
        "bleurt": -0.28052
    },
    "totto_test_contrast_challenge_table_size-table_size_795": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8599530403139946,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.375,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.55556,
            "fmeasure": 0.58824
        },
        "bleu": 16.09274,
        "local_recall": {
            "1": 0,
            "2": 0.6363636363636364
        },
        "bertscore": {
            "precision": 0.8496,
            "recall": 0.8345,
            "f1": 0.84198
        },
        "nubia": {
            "semantic_relation": 4.78328,
            "contradiction": 0.21453,
            "irrelevancy": 73.01595,
            "logical_agreement": 26.76953,
            "grammar_ref": 4.80739,
            "grammar_hyp": 5.65786,
            "nubia_score": 0.82894
        },
        "meteor": 0.3241648136372685,
        "bleurt": 0.07097
    },
    "totto_test_contrast_challenge_table_size-table_size_582": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 3.774917217635375,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 20,
        "distinct-1": 0.7407407407407407,
        "vocab_size-1": 40,
        "unique-1": 30,
        "entropy-1": 5.1713731502314895,
        "distinct-2": 0.84,
        "vocab_size-2": 42,
        "unique-2": 35,
        "entropy-2": 5.308758439731456,
        "cond_entropy-2": 0.024066437654525413,
        "distinct-3": 0.8913043478260869,
        "vocab_size-3": 41,
        "unique-3": 36,
        "entropy-3": 5.306170651709183,
        "cond_entropy-3": 0.026551146764102772,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 2.9154759474226504,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7708333333333334,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 5.095175521464346,
        "distinct-2-nopunct": 0.8181818181818182,
        "vocab_size-2-nopunct": 36,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 5.078638720860853,
        "cond_entropy-2-nopunct": 0.027989288419856123,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 35,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 5.071928094887363,
        "cond_entropy-3-nopunct": 0.0313686638041517,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.370638223410693,
        "rouge1": {
            "precision": 0.975,
            "recall": 0.92643,
            "fmeasure": 0.94807
        },
        "rouge2": {
            "precision": 0.89425,
            "recall": 0.86591,
            "fmeasure": 0.87912
        },
        "rougeL": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "rougeLsum": {
            "precision": 0.94167,
            "recall": 0.88839,
            "fmeasure": 0.91141
        },
        "bleu": 74.31053,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9024390243902439
        },
        "bertscore": {
            "precision": 0.98748,
            "recall": 0.98115,
            "f1": 0.98304
        },
        "nubia": {
            "semantic_relation": 4.80972,
            "contradiction": 0.2607,
            "irrelevancy": 8.77328,
            "logical_agreement": 90.96602,
            "grammar_ref": 5.18336,
            "grammar_hyp": 5.03931,
            "nubia_score": 0.94183
        },
        "meteor": 0.5559131802200744,
        "bleurt": 0.7087
    },
    "totto_test_contrast_challenge_table_size-table_size_675": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.283872384965209,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.86713,
            "fmeasure": 0.87652
        },
        "rouge2": {
            "precision": 0.69697,
            "recall": 0.67778,
            "fmeasure": 0.68599
        },
        "rougeL": {
            "precision": 0.86111,
            "recall": 0.79487,
            "fmeasure": 0.82667
        },
        "rougeLsum": {
            "precision": 0.86111,
            "recall": 0.79487,
            "fmeasure": 0.82667
        },
        "bleu": 58.47065,
        "local_recall": {
            "1": 0.2,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.9763,
            "recall": 0.97952,
            "f1": 0.97791
        },
        "nubia": {
            "semantic_relation": 4.88895,
            "contradiction": 0.44337,
            "irrelevancy": 46.31948,
            "logical_agreement": 53.23715,
            "grammar_ref": 4.43463,
            "grammar_hyp": 4.13239,
            "nubia_score": 0.9721
        },
        "meteor": 0.47380087540825894,
        "bleurt": 0.68098
    },
    "totto_test_contrast_challenge_table_size-table_size_858": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.4182958340544896,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.03462179117476819,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7943166624098033,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.81319,
            "fmeasure": 0.86154
        },
        "rouge2": {
            "precision": 0.86364,
            "recall": 0.75641,
            "fmeasure": 0.80616
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.81319,
            "fmeasure": 0.86154
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.81319,
            "fmeasure": 0.86154
        },
        "bleu": 86.68779,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.8
        },
        "bertscore": {
            "precision": 0.98454,
            "recall": 0.94641,
            "f1": 0.9651
        },
        "nubia": {
            "semantic_relation": 3.94852,
            "contradiction": 0.30589,
            "irrelevancy": 1.21482,
            "logical_agreement": 98.47929,
            "grammar_ref": 4.1674,
            "grammar_hyp": 4.19789,
            "nubia_score": 0.71132
        },
        "meteor": 0.5372424338373443,
        "bleurt": 0.42744
    },
    "totto_test_contrast_challenge_table_size-table_size_798": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 18.666666666666668,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 18.0,
        "min_pred_length": 16,
        "max_pred_length": 22,
        "distinct-1": 0.44642857142857145,
        "vocab_size-1": 25,
        "unique-1": 11,
        "entropy-1": 4.369792538771572,
        "distinct-2": 0.660377358490566,
        "vocab_size-2": 35,
        "unique-2": 23,
        "entropy-2": 4.9632162090352585,
        "cond_entropy-2": 0.5433652337579538,
        "distinct-3": 0.8,
        "vocab_size-3": 40,
        "unique-3": 34,
        "entropy-3": 5.183465189601649,
        "cond_entropy-3": 0.22613123529806428,
        "total_length-nopunct": 50,
        "mean_pred_length-nopunct": 16.666666666666668,
        "std_pred_length-nopunct": 2.494438257849294,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.46,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 4.265979129983102,
        "distinct-2-nopunct": 0.6595744680851063,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.777369170550387,
        "cond_entropy-2-nopunct": 0.48934123584244393,
        "distinct-3-nopunct": 0.7727272727272727,
        "vocab_size-3-nopunct": 34,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.936260027531526,
        "cond_entropy-3-nopunct": 0.13983935793431032,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.282038593995409,
        "rouge1": {
            "precision": 0.75377,
            "recall": 0.71782,
            "fmeasure": 0.71085
        },
        "rouge2": {
            "precision": 0.53963,
            "recall": 0.49691,
            "fmeasure": 0.49824
        },
        "rougeL": {
            "precision": 0.60714,
            "recall": 0.59026,
            "fmeasure": 0.58113
        },
        "rougeLsum": {
            "precision": 0.60714,
            "recall": 0.59026,
            "fmeasure": 0.58113
        },
        "bleu": 43.18469,
        "local_recall": {
            "1": 0.7,
            "2": 0.5,
            "3": 0.6842105263157895
        },
        "bertscore": {
            "precision": 0.90928,
            "recall": 0.88053,
            "f1": 0.89364
        },
        "nubia": {
            "semantic_relation": 3.57985,
            "contradiction": 33.5096,
            "irrelevancy": 36.44921,
            "logical_agreement": 30.04119,
            "grammar_ref": 5.76985,
            "grammar_hyp": 5.13381,
            "nubia_score": 0.51868
        },
        "meteor": 0.3661742175668655,
        "bleurt": -0.42541
    },
    "totto_test_contrast_challenge_table_size-table_size_800": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 12.333333333333334,
        "std_pred_length": 4.642796092394707,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 17,
        "distinct-1": 0.8648648648648649,
        "vocab_size-1": 32,
        "unique-1": 29,
        "entropy-1": 4.885129041304628,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.05448006385668386,
        "distinct-3": 1.0,
        "vocab_size-3": 31,
        "unique-3": 31,
        "entropy-3": 4.954196310386877,
        "cond_entropy-3": -0.13326653086346418,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 4.08248290463863,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.773557262275186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": -0.0038549452969019156,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2960023130648937,
        "rouge1": {
            "precision": 0.73939,
            "recall": 0.68215,
            "fmeasure": 0.7015
        },
        "rouge2": {
            "precision": 0.23095,
            "recall": 0.20293,
            "fmeasure": 0.21332
        },
        "rougeL": {
            "precision": 0.41616,
            "recall": 0.37328,
            "fmeasure": 0.38831
        },
        "rougeLsum": {
            "precision": 0.41616,
            "recall": 0.37328,
            "fmeasure": 0.38831
        },
        "bleu": 8.82908,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.92265,
            "recall": 0.91173,
            "f1": 0.91513
        },
        "nubia": {
            "semantic_relation": 3.98699,
            "contradiction": 24.02622,
            "irrelevancy": 51.41236,
            "logical_agreement": 24.56141,
            "grammar_ref": 5.969,
            "grammar_hyp": 5.75162,
            "nubia_score": 0.6
        },
        "meteor": 0.3128913478916019,
        "bleurt": 0.06282
    },
    "totto_test_contrast_challenge_table_size-table_size_615": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 46,
        "mean_pred_length": 15.333333333333334,
        "std_pred_length": 2.8674417556808756,
        "median_pred_length": 15.0,
        "min_pred_length": 12,
        "max_pred_length": 19,
        "distinct-1": 0.8043478260869565,
        "vocab_size-1": 37,
        "unique-1": 33,
        "entropy-1": 5.028890488618675,
        "distinct-2": 1.0,
        "vocab_size-2": 43,
        "unique-2": 43,
        "entropy-2": 5.426264754702098,
        "cond_entropy-2": 0.32130744980787534,
        "distinct-3": 1.0,
        "vocab_size-3": 40,
        "unique-3": 40,
        "entropy-3": 5.3219280948873635,
        "cond_entropy-3": -0.1043366598147359,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 35,
        "unique-1-nopunct": 32,
        "entropy-1-nopunct": 4.963745994207333,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 39,
        "entropy-2-nopunct": 5.285402218862247,
        "cond_entropy-2-nopunct": 0.3546232576219498,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.1154772174199358,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.357259225073189,
        "rouge1": {
            "precision": 0.78945,
            "recall": 0.71225,
            "fmeasure": 0.7477
        },
        "rouge2": {
            "precision": 0.51353,
            "recall": 0.45702,
            "fmeasure": 0.48205
        },
        "rougeL": {
            "precision": 0.59354,
            "recall": 0.53655,
            "fmeasure": 0.5628
        },
        "rougeLsum": {
            "precision": 0.59354,
            "recall": 0.53655,
            "fmeasure": 0.5628
        },
        "bleu": 34.87376,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.17647058823529413,
            "3": 0.7222222222222222
        },
        "bertscore": {
            "precision": 0.94182,
            "recall": 0.92034,
            "f1": 0.93095
        },
        "nubia": {
            "semantic_relation": 4.29009,
            "contradiction": 0.24421,
            "irrelevancy": 13.80852,
            "logical_agreement": 85.94727,
            "grammar_ref": 4.60968,
            "grammar_hyp": 4.50074,
            "nubia_score": 0.76287
        },
        "meteor": 0.3533884200203197,
        "bleurt": 0.1891
    },
    "totto_test_contrast_challenge_table_size-table_size_584": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7992518527004338,
        "rouge1": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95833,
            "recall": 1.0,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98039
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.50734,
            "irrelevancy": 0.72277,
            "logical_agreement": 97.76989,
            "grammar_ref": 5.94246,
            "grammar_hyp": 5.94702,
            "nubia_score": 0.97697
        },
        "meteor": 1.0,
        "bleurt": 0.79398
    },
    "totto_test_contrast_challenge_table_size-table_size_735": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.1176878443984663,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.03740119765411,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.14421971022094904,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5145236380319416,
        "rouge1": {
            "precision": 0.56667,
            "recall": 0.69281,
            "fmeasure": 0.62291
        },
        "rouge2": {
            "precision": 0.29825,
            "recall": 0.40152,
            "fmeasure": 0.33968
        },
        "rougeL": {
            "precision": 0.28333,
            "recall": 0.37418,
            "fmeasure": 0.32038
        },
        "rougeLsum": {
            "precision": 0.28333,
            "recall": 0.37418,
            "fmeasure": 0.32038
        },
        "bleu": 18.21604,
        "local_recall": {
            "1": 0,
            "2": 0.8333333333333334,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.85018,
            "recall": 0.88269,
            "f1": 0.86335
        },
        "nubia": {
            "semantic_relation": 3.58823,
            "contradiction": 99.04537,
            "irrelevancy": 0.54309,
            "logical_agreement": 0.41153,
            "grammar_ref": 4.69116,
            "grammar_hyp": 3.65199,
            "nubia_score": 0.6466
        },
        "meteor": 0.3387777094089547,
        "bleurt": -0.24686
    },
    "totto_test_contrast_challenge_table_size-table_size_860": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9669791651768762,
        "rouge1": {
            "precision": 0.75,
            "recall": 0.5,
            "fmeasure": 0.6
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.27273,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.41667,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.41667,
            "fmeasure": 0.5
        },
        "bleu": 17.3935,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.95438,
            "recall": 0.88575,
            "f1": 0.91824
        },
        "nubia": {
            "semantic_relation": 4.77921,
            "contradiction": 1.87906,
            "irrelevancy": 1.12407,
            "logical_agreement": 96.99688,
            "grammar_ref": 5.64121,
            "grammar_hyp": 6.71744,
            "nubia_score": 0.72009
        },
        "meteor": 0.3509395707573647,
        "bleurt": 0.44059
    },
    "totto_test_contrast_challenge_table_size-table_size_736": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 12,
        "entropy-1": 3.9219280948873623,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8365916681089787,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.04978793508525297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9880902017985154,
        "rouge1": {
            "precision": 0.65,
            "recall": 0.71481,
            "fmeasure": 0.67538
        },
        "rouge2": {
            "precision": 0.39683,
            "recall": 0.45899,
            "fmeasure": 0.42222
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.58981,
            "fmeasure": 0.56427
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.58981,
            "fmeasure": 0.56427
        },
        "bleu": 22.20375,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7058823529411765
        },
        "bertscore": {
            "precision": 0.93171,
            "recall": 0.92739,
            "f1": 0.92935
        },
        "nubia": {
            "semantic_relation": 4.84724,
            "contradiction": 0.59275,
            "irrelevancy": 19.24696,
            "logical_agreement": 80.16029,
            "grammar_ref": 4.99735,
            "grammar_hyp": 5.46772,
            "nubia_score": 0.84986
        },
        "meteor": 0.37935068540698735,
        "bleurt": 0.404
    },
    "totto_test_contrast_challenge_table_size-table_size_585": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 79,
        "mean_pred_length": 13.166666666666666,
        "std_pred_length": 5.66911711723165,
        "median_pred_length": 10.5,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.5569620253164557,
        "vocab_size-1": 44,
        "unique-1": 33,
        "entropy-1": 5.026643368562153,
        "distinct-2": 0.7534246575342466,
        "vocab_size-2": 55,
        "unique-2": 44,
        "entropy-2": 5.624287401138323,
        "cond_entropy-2": 0.5435780572782569,
        "distinct-3": 0.7910447761194029,
        "vocab_size-3": 53,
        "unique-3": 45,
        "entropy-3": 5.580576876831189,
        "cond_entropy-3": -0.06403387588493141,
        "total_length-nopunct": 70,
        "mean_pred_length-nopunct": 11.666666666666666,
        "std_pred_length-nopunct": 4.9216076867444665,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.5571428571428572,
        "vocab_size-1-nopunct": 39,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.853794266728621,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 48,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.429229296672176,
        "cond_entropy-2-nopunct": 0.6207169830550333,
        "distinct-3-nopunct": 0.7931034482758621,
        "vocab_size-3-nopunct": 46,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.379111382872098,
        "cond_entropy-3-nopunct": -0.07305348763104856,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.832613189221004,
        "rouge1": {
            "precision": 0.89089,
            "recall": 0.90551,
            "fmeasure": 0.8949
        },
        "rouge2": {
            "precision": 0.75335,
            "recall": 0.77604,
            "fmeasure": 0.76082
        },
        "rougeL": {
            "precision": 0.86816,
            "recall": 0.88226,
            "fmeasure": 0.87177
        },
        "rougeLsum": {
            "precision": 0.86816,
            "recall": 0.88226,
            "fmeasure": 0.87177
        },
        "bleu": 71.75342,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7692307692307693,
            "3": 0.9285714285714286
        },
        "bertscore": {
            "precision": 0.97507,
            "recall": 0.97834,
            "f1": 0.9767
        },
        "nubia": {
            "semantic_relation": 4.16495,
            "contradiction": 20.50469,
            "irrelevancy": 23.09643,
            "logical_agreement": 56.39887,
            "grammar_ref": 4.0718,
            "grammar_hyp": 3.93825,
            "nubia_score": 0.78409
        },
        "meteor": 0.5192933090776999,
        "bleurt": 0.63112
    },
    "totto_test_contrast_challenge_table_size-table_size_616": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 1.920286436967152,
        "median_pred_length": 13.0,
        "min_pred_length": 10,
        "max_pred_length": 15,
        "distinct-1": 0.7647058823529411,
        "vocab_size-1": 39,
        "unique-1": 31,
        "entropy-1": 5.133017988945481,
        "distinct-2": 0.9574468085106383,
        "vocab_size-2": 45,
        "unique-2": 43,
        "entropy-2": 5.469482468698917,
        "cond_entropy-2": 0.21215872256416193,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.03530084116158587,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.8027756377319946,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8043478260869565,
        "vocab_size-1-nopunct": 37,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.099436412484686,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.297079327540667,
        "cond_entropy-2-nopunct": 0.23803582396762712,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.03912675144043812,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.194947612837832,
        "rouge1": {
            "precision": 0.67917,
            "recall": 0.75625,
            "fmeasure": 0.7055
        },
        "rouge2": {
            "precision": 0.54206,
            "recall": 0.58958,
            "fmeasure": 0.55168
        },
        "rougeL": {
            "precision": 0.65298,
            "recall": 0.73467,
            "fmeasure": 0.68188
        },
        "rougeLsum": {
            "precision": 0.65298,
            "recall": 0.73467,
            "fmeasure": 0.68188
        },
        "bleu": 51.84726,
        "local_recall": {
            "1": 0.2222222222222222,
            "2": 0.3888888888888889,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.90846,
            "recall": 0.91686,
            "f1": 0.91241
        },
        "nubia": {
            "semantic_relation": 4.13114,
            "contradiction": 14.05717,
            "irrelevancy": 33.96335,
            "logical_agreement": 51.97947,
            "grammar_ref": 4.6519,
            "grammar_hyp": 4.89902,
            "nubia_score": 0.65958
        },
        "meteor": 0.374595113297734,
        "bleurt": 0.33599
    },
    "totto_test_contrast_challenge_table_size-table_size_740": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 22.0,
        "std_pred_length": 0.0,
        "median_pred_length": 22.0,
        "min_pred_length": 22,
        "max_pred_length": 22,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.12336199461765374,
        "distinct-3": 1.0,
        "vocab_size-3": 20,
        "unique-3": 20,
        "entropy-3": 4.321928094887363,
        "cond_entropy-3": -0.07038932789139804,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.022446956445717602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1184442318285222,
        "rouge1": {
            "precision": 0.24561,
            "recall": 0.42593,
            "fmeasure": 0.31029
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.15789,
            "recall": 0.30556,
            "fmeasure": 0.20737
        },
        "rougeLsum": {
            "precision": 0.15789,
            "recall": 0.30556,
            "fmeasure": 0.20737
        },
        "bleu": 2.70325,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.73971,
            "recall": 0.77859,
            "f1": 0.75865
        },
        "nubia": {
            "semantic_relation": 2.00731,
            "contradiction": 0.10022,
            "irrelevancy": 99.56466,
            "logical_agreement": 0.33512,
            "grammar_ref": 4.01628,
            "grammar_hyp": 3.95541,
            "nubia_score": 0.16134
        },
        "meteor": 0.1422924901185771,
        "bleurt": -0.49252
    },
    "totto_test_contrast_challenge_table_size-table_size_618": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 13.666666666666666,
        "std_pred_length": 2.0548046676563256,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.926829268292683,
        "vocab_size-1": 38,
        "unique-1": 36,
        "entropy-1": 5.192798650906777,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": -0.05699291222712945,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.11864449649861893,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 12.333333333333334,
        "std_pred_length-nopunct": 1.699673171197595,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.972972972972973,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 35,
        "entropy-1-nopunct": 5.1553993115749,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 34,
        "entropy-2-nopunct": 5.087462841250338,
        "cond_entropy-2-nopunct": -0.06316699496684557,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": -0.13326653086346418,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.147366441519974,
        "rouge1": {
            "precision": 0.73623,
            "recall": 0.78693,
            "fmeasure": 0.74451
        },
        "rouge2": {
            "precision": 0.58148,
            "recall": 0.59135,
            "fmeasure": 0.56997
        },
        "rougeL": {
            "precision": 0.7066,
            "recall": 0.74405,
            "fmeasure": 0.70496
        },
        "rougeLsum": {
            "precision": 0.7066,
            "recall": 0.74405,
            "fmeasure": 0.70496
        },
        "bleu": 56.30684,
        "local_recall": {
            "1": 0.1875,
            "2": 0.3333333333333333,
            "3": 0.8666666666666667
        },
        "bertscore": {
            "precision": 0.93203,
            "recall": 0.94345,
            "f1": 0.92781
        },
        "nubia": {
            "semantic_relation": 4.20196,
            "contradiction": 0.19232,
            "irrelevancy": 65.41027,
            "logical_agreement": 34.39741,
            "grammar_ref": 4.66623,
            "grammar_hyp": 4.40554,
            "nubia_score": 0.80669
        },
        "meteor": 0.422692439279182,
        "bleurt": 0.28768
    },
    "totto_test_contrast_challenge_table_size-table_size_864": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.0930692077718899,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4156844010247407,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.6374,
            "contradiction": 0.2158,
            "irrelevancy": 0.51722,
            "logical_agreement": 99.26698,
            "grammar_ref": 5.14316,
            "grammar_hyp": 5.20485,
            "nubia_score": 0.86208
        },
        "meteor": 1.0,
        "bleurt": 0.6432
    },
    "totto_test_contrast_challenge_table_size-table_size_742": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.456435556800404,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.8,
            "fmeasure": 0.72727
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "bleu": 50.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98601,
            "recall": 0.99497,
            "f1": 0.99047
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.14589,
            "irrelevancy": 0.6446,
            "logical_agreement": 98.20952,
            "grammar_ref": 4.87815,
            "grammar_hyp": 4.39193,
            "nubia_score": 1.0
        },
        "meteor": 0.5277006683854432,
        "bleurt": 0.93658
    },
    "totto_test_contrast_challenge_table_size-table_size_805": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.13652573434569687,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.21714470010083,
        "rouge1": {
            "precision": 0.50794,
            "recall": 0.88889,
            "fmeasure": 0.64646
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.63636,
            "fmeasure": 0.45161
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.83333,
            "fmeasure": 0.60606
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.83333,
            "fmeasure": 0.60606
        },
        "bleu": 26.15312,
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.82461,
            "recall": 0.91184,
            "f1": 0.86603
        },
        "nubia": {
            "semantic_relation": 3.56631,
            "contradiction": 0.73901,
            "irrelevancy": 99.09171,
            "logical_agreement": 0.16928,
            "grammar_ref": 5.08958,
            "grammar_hyp": 2.85643,
            "nubia_score": 0.67828
        },
        "meteor": 0.4316839821204472,
        "bleurt": 0.05227
    },
    "totto_test_contrast_challenge_table_size-table_size_868": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.5882352941176471,
        "vocab_size-1": 20,
        "unique-1": 10,
        "entropy-1": 4.160704752887782,
        "distinct-2": 0.78125,
        "vocab_size-2": 25,
        "unique-2": 18,
        "entropy-2": 4.5625,
        "cond_entropy-2": 0.3972176276348775,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 25,
        "unique-3": 20,
        "entropy-3": 4.573557262275186,
        "cond_entropy-3": 0.040223928941851894,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.59375,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 4.077819531114783,
        "distinct-2-nopunct": 0.7666666666666667,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.440223928941852,
        "cond_entropy-2-nopunct": 0.3710510123953779,
        "distinct-3-nopunct": 0.8214285714285714,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.450212064914748,
        "cond_entropy-3-nopunct": 0.0433214693062285,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.589012584133441,
        "rouge1": {
            "precision": 0.51852,
            "recall": 0.58524,
            "fmeasure": 0.53936
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.37753,
            "fmeasure": 0.3457
        },
        "rougeL": {
            "precision": 0.39815,
            "recall": 0.56822,
            "fmeasure": 0.46788
        },
        "rougeLsum": {
            "precision": 0.39815,
            "recall": 0.56822,
            "fmeasure": 0.46788
        },
        "bleu": 38.47149,
        "local_recall": {
            "1": 0.4117647058823529,
            "2": 0.2857142857142857,
            "3": 0.5625
        },
        "bertscore": {
            "precision": 0.89345,
            "recall": 0.90758,
            "f1": 0.89526
        },
        "nubia": {
            "semantic_relation": 3.85608,
            "contradiction": 23.96303,
            "irrelevancy": 56.56055,
            "logical_agreement": 19.47642,
            "grammar_ref": 3.56015,
            "grammar_hyp": 2.81571,
            "nubia_score": 0.80088
        },
        "meteor": 0.3752852711697391,
        "bleurt": 0.08719
    },
    "totto_test_contrast_challenge_table_size-table_size_636": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.033108599109837954,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7260345586866912,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.39618,
            "fmeasure": 0.42756
        },
        "rouge2": {
            "precision": 0.26316,
            "recall": 0.23449,
            "fmeasure": 0.24797
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.35837,
            "fmeasure": 0.378
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.35837,
            "fmeasure": 0.378
        },
        "bleu": 9.30724,
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.4117647058823529
        },
        "bertscore": {
            "precision": 0.87275,
            "recall": 0.85048,
            "f1": 0.86147
        },
        "nubia": {
            "semantic_relation": 2.85274,
            "contradiction": 98.10336,
            "irrelevancy": 1.67552,
            "logical_agreement": 0.22113,
            "grammar_ref": 3.0511,
            "grammar_hyp": 2.24921,
            "nubia_score": 0.49152
        },
        "meteor": 0.198349015153745,
        "bleurt": -0.17393
    },
    "totto_test_contrast_challenge_table_size-table_size_903": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.11475004073479991,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.423065265165703,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31517,
            "irrelevancy": 0.55477,
            "logical_agreement": 99.13006,
            "grammar_ref": 5.42428,
            "grammar_hyp": 5.51742,
            "nubia_score": 0.98965
        },
        "meteor": 1.0,
        "bleurt": 0.94038
    },
    "totto_test_contrast_challenge_table_size-table_size_808": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673076,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.976369318460957,
        "rouge1": {
            "precision": 0.79487,
            "recall": 0.61111,
            "fmeasure": 0.68571
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.45455,
            "fmeasure": 0.51584
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.59596,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.59596,
            "fmeasure": 0.66667
        },
        "bleu": 42.89308,
        "local_recall": {
            "1": 0.0,
            "2": 0.25,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.94829,
            "recall": 0.9328,
            "f1": 0.94048
        },
        "nubia": {
            "semantic_relation": 3.58774,
            "contradiction": 11.48307,
            "irrelevancy": 86.81382,
            "logical_agreement": 1.7031,
            "grammar_ref": 4.44297,
            "grammar_hyp": 4.66871,
            "nubia_score": 0.41685
        },
        "meteor": 0.3600988628001968,
        "bleurt": 0.06418
    },
    "totto_test_contrast_challenge_table_size-table_size_678": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.898626692302749,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.9,
            "fmeasure": 0.92105
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95455,
            "fmeasure": 0.97619
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.371,
            "irrelevancy": 0.46802,
            "logical_agreement": 99.16099,
            "grammar_ref": 5.30755,
            "grammar_hyp": 5.2666,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.90186
    },
    "totto_test_contrast_challenge_table_size-table_size_637": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.144271521936147,
        "rouge1": {
            "precision": 0.80556,
            "recall": 0.67521,
            "fmeasure": 0.73383
        },
        "rouge2": {
            "precision": 0.42424,
            "recall": 0.34921,
            "fmeasure": 0.38261
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.58803,
            "fmeasure": 0.6242
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.58803,
            "fmeasure": 0.6242
        },
        "bleu": 59.23033,
        "local_recall": {
            "1": 0.2,
            "2": 0.42857142857142855,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.92969,
            "recall": 0.9163,
            "f1": 0.91799
        },
        "nubia": {
            "semantic_relation": 4.48235,
            "contradiction": 0.10227,
            "irrelevancy": 66.5597,
            "logical_agreement": 33.33803,
            "grammar_ref": 5.94843,
            "grammar_hyp": 5.71582,
            "nubia_score": 0.85406
        },
        "meteor": 0.3689586354931066,
        "bleurt": 0.4052
    },
    "totto_test_contrast_challenge_table_size-table_size_748": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 4.0,
        "median_pred_length": 16.0,
        "min_pred_length": 12,
        "max_pred_length": 20,
        "distinct-1": 0.75,
        "vocab_size-1": 24,
        "unique-1": 17,
        "entropy-1": 4.476409765557392,
        "distinct-2": 0.8333333333333334,
        "vocab_size-2": 25,
        "unique-2": 20,
        "entropy-2": 4.573557262275185,
        "cond_entropy-2": 0.06538684568063416,
        "distinct-3": 0.8571428571428571,
        "vocab_size-3": 24,
        "unique-3": 20,
        "entropy-3": 4.521640636343321,
        "cond_entropy-3": -0.09953567355091439,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.351823225551768,
        "distinct-2-nopunct": 0.8461538461538461,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.392747410448783,
        "cond_entropy-2-nopunct": -0.0009579922948403236,
        "distinct-3-nopunct": 0.875,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.334962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993587,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.5317772050130385,
        "rouge1": {
            "precision": 0.87522,
            "recall": 0.83457,
            "fmeasure": 0.85387
        },
        "rouge2": {
            "precision": 0.67917,
            "recall": 0.69158,
            "fmeasure": 0.68112
        },
        "rougeL": {
            "precision": 0.68895,
            "recall": 0.75319,
            "fmeasure": 0.71447
        },
        "rougeLsum": {
            "precision": 0.68895,
            "recall": 0.75319,
            "fmeasure": 0.71447
        },
        "bleu": 59.09975,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.6363636363636364,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.97746,
            "recall": 0.97312,
            "f1": 0.97528
        },
        "nubia": {
            "semantic_relation": 4.70941,
            "contradiction": 0.52263,
            "irrelevancy": 17.13075,
            "logical_agreement": 82.34662,
            "grammar_ref": 3.87403,
            "grammar_hyp": 3.9114,
            "nubia_score": 0.9059
        },
        "meteor": 0.5484629991614198,
        "bleurt": 0.43595
    },
    "totto_test_contrast_challenge_table_size-table_size_620": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.739904445600376,
        "rouge1": {
            "precision": 0.55882,
            "recall": 0.72619,
            "fmeasure": 0.6307
        },
        "rouge2": {
            "precision": 0.28125,
            "recall": 0.37413,
            "fmeasure": 0.32056
        },
        "rougeL": {
            "precision": 0.41176,
            "recall": 0.53571,
            "fmeasure": 0.46496
        },
        "rougeLsum": {
            "precision": 0.41176,
            "recall": 0.53571,
            "fmeasure": 0.46496
        },
        "bleu": 25.40664,
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.87451,
            "recall": 0.89499,
            "f1": 0.88463
        },
        "nubia": {
            "semantic_relation": 4.37909,
            "contradiction": 1.09426,
            "irrelevancy": 45.30174,
            "logical_agreement": 53.604,
            "grammar_ref": 5.74657,
            "grammar_hyp": 4.5053,
            "nubia_score": 0.85115
        },
        "meteor": 0.33275204784491624,
        "bleurt": 0.16126
    },
    "totto_test_contrast_challenge_table_size-table_size_749": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6820662218835816,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.53846,
            "fmeasure": 0.51852
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.25,
            "fmeasure": 0.24
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.53846,
            "fmeasure": 0.51852
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.53846,
            "fmeasure": 0.51852
        },
        "bleu": 6.95958,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.86798,
            "recall": 0.89113,
            "f1": 0.8794
        },
        "nubia": {
            "semantic_relation": 4.88641,
            "contradiction": 1.15458,
            "irrelevancy": 36.87194,
            "logical_agreement": 61.97348,
            "grammar_ref": 4.23153,
            "grammar_hyp": 3.91303,
            "nubia_score": 0.94881
        },
        "meteor": 0.3212105288127927,
        "bleurt": 0.31019
    },
    "totto_test_contrast_challenge_table_size-table_size_680": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 6.5,
        "median_pred_length": 15.5,
        "min_pred_length": 9,
        "max_pred_length": 22,
        "distinct-1": 0.8387096774193549,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.567099536193328,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.24861227094759364,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.450212064914748,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.70043971814109,
        "cond_entropy-2-nopunct": 0.2777001806988724,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.11547721741993584,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3434700196960945,
        "rouge1": {
            "precision": 0.7125,
            "recall": 0.69417,
            "fmeasure": 0.68915
        },
        "rouge2": {
            "precision": 0.58647,
            "recall": 0.60979,
            "fmeasure": 0.58406
        },
        "rougeL": {
            "precision": 0.6125,
            "recall": 0.62356,
            "fmeasure": 0.60638
        },
        "rougeLsum": {
            "precision": 0.6125,
            "recall": 0.62356,
            "fmeasure": 0.60638
        },
        "bleu": 32.62929,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.44
        },
        "bertscore": {
            "precision": 0.92037,
            "recall": 0.89853,
            "f1": 0.90914
        },
        "nubia": {
            "semantic_relation": 4.0822,
            "contradiction": 0.1321,
            "irrelevancy": 79.25261,
            "logical_agreement": 20.61529,
            "grammar_ref": 5.14413,
            "grammar_hyp": 4.22041,
            "nubia_score": 0.81232
        },
        "meteor": 0.27239786731025545,
        "bleurt": 0.17498
    },
    "totto_test_contrast_challenge_table_size-table_size_909": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 43,
        "mean_pred_length": 14.333333333333334,
        "std_pred_length": 2.6246692913372702,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 18,
        "distinct-1": 0.7209302325581395,
        "vocab_size-1": 31,
        "unique-1": 23,
        "entropy-1": 4.786502545299146,
        "distinct-2": 0.875,
        "vocab_size-2": 35,
        "unique-2": 30,
        "entropy-2": 5.0719280948873635,
        "cond_entropy-2": 0.21453552773935095,
        "distinct-3": 0.918918918918919,
        "vocab_size-3": 34,
        "unique-3": 31,
        "entropy-3": 5.047291203466791,
        "cond_entropy-3": -0.05842067520435858,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 2.160246899469287,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7435897435897436,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.7019435649606205,
        "distinct-2-nopunct": 0.8888888888888888,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.947702779220088,
        "cond_entropy-2-nopunct": 0.238825213195716,
        "distinct-3-nopunct": 0.9393939393939394,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.923181998146335,
        "cond_entropy-3-nopunct": -0.06492482147779848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.475240333831268,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.96212,
            "fmeasure": 0.91874
        },
        "rouge2": {
            "precision": 0.73704,
            "recall": 0.76061,
            "fmeasure": 0.74584
        },
        "rougeL": {
            "precision": 0.82639,
            "recall": 0.87626,
            "fmeasure": 0.84643
        },
        "rougeLsum": {
            "precision": 0.82639,
            "recall": 0.87626,
            "fmeasure": 0.84643
        },
        "bleu": 66.2801,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9354838709677419
        },
        "bertscore": {
            "precision": 0.96766,
            "recall": 0.97647,
            "f1": 0.97034
        },
        "nubia": {
            "semantic_relation": 4.78451,
            "contradiction": 0.65135,
            "irrelevancy": 1.72198,
            "logical_agreement": 97.62667,
            "grammar_ref": 3.77014,
            "grammar_hyp": 3.80887,
            "nubia_score": 0.86654
        },
        "meteor": 0.5247217775732649,
        "bleurt": 0.66833
    },
    "totto_test_contrast_challenge_table_size-table_size_682": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.474416099899872,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.56614,
            "fmeasure": 0.56899
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.75556,
            "fmeasure": 0.75569
        },
        "bleu": 51.47302,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.96933,
            "recall": 0.95282,
            "f1": 0.95899
        },
        "nubia": {
            "semantic_relation": 4.58246,
            "contradiction": 0.86231,
            "irrelevancy": 56.25508,
            "logical_agreement": 42.88262,
            "grammar_ref": 4.75278,
            "grammar_hyp": 5.26027,
            "nubia_score": 0.74168
        },
        "meteor": 0.4748101853768951,
        "bleurt": 0.33863
    },
    "totto_test_contrast_challenge_table_size-table_size_640": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 8.093207028119323,
        "median_pred_length": 13.5,
        "min_pred_length": 4,
        "max_pred_length": 25,
        "distinct-1": 0.875,
        "vocab_size-1": 49,
        "unique-1": 44,
        "entropy-1": 5.5216406363433235,
        "distinct-2": 1.0,
        "vocab_size-2": 52,
        "unique-2": 52,
        "entropy-2": 5.700439718141095,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.11547721741993597,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 7.75806032459145,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9215686274509803,
        "vocab_size-1-nopunct": 47,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.515562596873459,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 47,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.55458885167764,
        "cond_entropy-2-nopunct": 0.031099679918907892,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.1283240969755395,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.457845847212468,
        "rouge1": {
            "precision": 0.9156,
            "recall": 0.76868,
            "fmeasure": 0.82303
        },
        "rouge2": {
            "precision": 0.63068,
            "recall": 0.52443,
            "fmeasure": 0.56178
        },
        "rougeL": {
            "precision": 0.86125,
            "recall": 0.71433,
            "fmeasure": 0.76868
        },
        "rougeLsum": {
            "precision": 0.86125,
            "recall": 0.71433,
            "fmeasure": 0.76868
        },
        "bleu": 49.10752,
        "local_recall": {
            "1": 0.0,
            "2": 0.6,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.95576,
            "recall": 0.9133,
            "f1": 0.93361
        },
        "nubia": {
            "semantic_relation": 4.33427,
            "contradiction": 3.62076,
            "irrelevancy": 11.38031,
            "logical_agreement": 84.99893,
            "grammar_ref": 4.34153,
            "grammar_hyp": 5.13502,
            "nubia_score": 0.71836
        },
        "meteor": 0.4266401256157322,
        "bleurt": 0.36235
    },
    "totto_test_contrast_challenge_table_size-table_size_910": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.7741935483870968,
        "vocab_size-1": 24,
        "unique-1": 18,
        "entropy-1": 4.478232197413861,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.27464287447047186,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.02901941889002935,
        "total_length-nopunct": 28,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.351823225551767,
        "distinct-2-nopunct": 0.9615384615384616,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.623516641218013,
        "cond_entropy-2-nopunct": 0.3067343153974674,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.03214388408660255,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2987104647191288,
        "rouge1": {
            "precision": 0.53241,
            "recall": 0.67873,
            "fmeasure": 0.59059
        },
        "rouge2": {
            "precision": 0.34492,
            "recall": 0.48525,
            "fmeasure": 0.40033
        },
        "rougeL": {
            "precision": 0.50463,
            "recall": 0.65077,
            "fmeasure": 0.56277
        },
        "rougeLsum": {
            "precision": 0.50463,
            "recall": 0.65077,
            "fmeasure": 0.56277
        },
        "bleu": 15.09426,
        "local_recall": {
            "1": 0.125,
            "2": 0.875,
            "3": 0.4
        },
        "bertscore": {
            "precision": 0.89738,
            "recall": 0.91104,
            "f1": 0.90206
        },
        "nubia": {
            "semantic_relation": 3.82245,
            "contradiction": 0.32191,
            "irrelevancy": 72.35159,
            "logical_agreement": 27.32651,
            "grammar_ref": 4.27476,
            "grammar_hyp": 3.90875,
            "nubia_score": 0.62749
        },
        "meteor": 0.3092629980094255,
        "bleurt": 0.11708
    },
    "totto_test_contrast_challenge_table_size-table_size_621": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.251192788981044,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.91667,
            "fmeasure": 0.93333
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.96296,
            "fmeasure": 0.98039
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.42679,
            "contradiction": 6.87785,
            "irrelevancy": 1.70123,
            "logical_agreement": 91.42092,
            "grammar_ref": 7.10682,
            "grammar_hyp": 7.20763,
            "nubia_score": 0.72464
        },
        "meteor": 1.0,
        "bleurt": 0.64779
    },
    "totto_test_contrast_challenge_table_size-table_size_810": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.8125,
        "vocab_size-1": 26,
        "unique-1": 21,
        "entropy-1": 4.601409765557392,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.19872017901396744,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.02810710212234293,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.548394345536403,
        "distinct-2-nopunct": 0.9642857142857143,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.735926350629034,
        "cond_entropy-2-nopunct": 0.21313888009778093,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.029992126993435266,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.203238489321068,
        "rouge1": {
            "precision": 0.7963,
            "recall": 0.95511,
            "fmeasure": 0.85869
        },
        "rouge2": {
            "precision": 0.63904,
            "recall": 0.77844,
            "fmeasure": 0.69394
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.95408,
            "fmeasure": 0.84891
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.95408,
            "fmeasure": 0.84891
        },
        "bleu": 61.31808,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.3333333333333333,
            "3": 0.9047619047619048
        },
        "bertscore": {
            "precision": 0.94205,
            "recall": 0.9588,
            "f1": 0.94907
        },
        "nubia": {
            "semantic_relation": 4.26846,
            "contradiction": 0.62199,
            "irrelevancy": 49.77071,
            "logical_agreement": 49.6073,
            "grammar_ref": 5.29605,
            "grammar_hyp": 4.87668,
            "nubia_score": 0.77543
        },
        "meteor": 0.514568255453899,
        "bleurt": 0.2628
    },
    "totto_test_contrast_challenge_table_size-table_size_812": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.098214829261011,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.2797,
            "irrelevancy": 0.5863,
            "logical_agreement": 99.13399,
            "grammar_ref": 4.58246,
            "grammar_hyp": 4.67996,
            "nubia_score": 0.98883
        },
        "meteor": 1.0,
        "bleurt": 0.94053
    },
    "totto_test_contrast_challenge_table_size-table_size_752": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9523809523809523,
        "vocab_size-1": 20,
        "unique-1": 19,
        "entropy-1": 4.297079327540665,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.029610672108601997,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.033108599109837954,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0961769012815985,
        "rouge1": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rouge2": {
            "precision": 0.44444,
            "recall": 0.67917,
            "fmeasure": 0.52564
        },
        "rougeL": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "rougeLsum": {
            "precision": 0.52632,
            "recall": 0.79514,
            "fmeasure": 0.62143
        },
        "bleu": 60.54783,
        "local_recall": {
            "1": 0.5454545454545454,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.90717,
            "recall": 0.95643,
            "f1": 0.93115
        },
        "nubia": {
            "semantic_relation": 2.9498,
            "contradiction": 0.88065,
            "irrelevancy": 98.13057,
            "logical_agreement": 0.98878,
            "grammar_ref": 4.24724,
            "grammar_hyp": 3.80836,
            "nubia_score": 0.37984
        },
        "meteor": 0.5158668426787606,
        "bleurt": -0.33838
    },
    "totto_test_contrast_challenge_table_size-table_size_912": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 56,
        "mean_pred_length": 14.0,
        "std_pred_length": 4.636809247747852,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 21,
        "distinct-1": 0.7678571428571429,
        "vocab_size-1": 43,
        "unique-1": 36,
        "entropy-1": 5.238170940255334,
        "distinct-2": 0.9807692307692307,
        "vocab_size-2": 51,
        "unique-2": 50,
        "entropy-2": 5.661978179679557,
        "cond_entropy-2": 0.37615047836740606,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": -0.07381055075326921,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 12.75,
        "std_pred_length-nopunct": 4.264680527307995,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7843137254901961,
        "vocab_size-1-nopunct": 40,
        "unique-1-nopunct": 34,
        "entropy-1-nopunct": 5.1406720972898565,
        "distinct-2-nopunct": 0.9787234042553191,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 45,
        "entropy-2-nopunct": 5.512035660188278,
        "cond_entropy-2-nopunct": 0.41661915819047696,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.08181246906856271,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8667241808914476,
        "rouge1": {
            "precision": 0.72202,
            "recall": 0.68717,
            "fmeasure": 0.69146
        },
        "rouge2": {
            "precision": 0.58675,
            "recall": 0.53739,
            "fmeasure": 0.54598
        },
        "rougeL": {
            "precision": 0.71012,
            "recall": 0.67606,
            "fmeasure": 0.67996
        },
        "rougeLsum": {
            "precision": 0.71012,
            "recall": 0.67606,
            "fmeasure": 0.67996
        },
        "bleu": 45.4611,
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.4,
            "3": 0.7407407407407407
        },
        "bertscore": {
            "precision": 0.91561,
            "recall": 0.93688,
            "f1": 0.92452
        },
        "nubia": {
            "semantic_relation": 3.67671,
            "contradiction": 23.42078,
            "irrelevancy": 31.0332,
            "logical_agreement": 45.54602,
            "grammar_ref": 4.43752,
            "grammar_hyp": 4.46484,
            "nubia_score": 0.61718
        },
        "meteor": 0.47479689494289967,
        "bleurt": 0.09749
    },
    "web_nlg_en_test_contrast_challenge_args-both_seen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 518,
        "msttr-100": 0.66611,
        "msttr-100_nopunct": 0.69071,
        "total_length": 10823,
        "mean_pred_length": 20.893822393822393,
        "std_pred_length": 4.815748022752966,
        "median_pred_length": 22.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.08777603252332994,
        "vocab_size-1": 950,
        "unique-1": 333,
        "entropy-1": 7.728645084030031,
        "distinct-2": 0.2490053372149442,
        "vocab_size-2": 2566,
        "unique-2": 1265,
        "entropy-2": 10.19603907206744,
        "cond_entropy-2": 2.4763963527185364,
        "distinct-3": 0.3914376213344232,
        "vocab_size-3": 3831,
        "unique-3": 2326,
        "entropy-3": 11.054685212878322,
        "cond_entropy-3": 0.9512124473183342,
        "total_length-nopunct": 9802,
        "mean_pred_length-nopunct": 18.922779922779924,
        "std_pred_length-nopunct": 4.589082056938097,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.09620485615180575,
        "vocab_size-1-nopunct": 943,
        "unique-1-nopunct": 333,
        "entropy-1-nopunct": 7.891722409025256,
        "distinct-2-nopunct": 0.259478672985782,
        "vocab_size-2-nopunct": 2409,
        "unique-2-nopunct": 1243,
        "entropy-2-nopunct": 10.091598874002324,
        "cond_entropy-2-nopunct": 2.345724622267704,
        "distinct-3-nopunct": 0.3965320556696327,
        "vocab_size-3-nopunct": 3476,
        "unique-3-nopunct": 2156,
        "entropy-3-nopunct": 10.895446301590326,
        "cond_entropy-3-nopunct": 0.8940537518106108,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 4.570587198809707,
        "rouge1": {
            "precision": 0.80681,
            "recall": 0.64011,
            "fmeasure": 0.69474
        },
        "rouge2": {
            "precision": 0.56838,
            "recall": 0.44427,
            "fmeasure": 0.48375
        },
        "rougeL": {
            "precision": 0.66602,
            "recall": 0.52683,
            "fmeasure": 0.57183
        },
        "rougeLsum": {
            "precision": 0.66602,
            "recall": 0.52683,
            "fmeasure": 0.57183
        },
        "bleu": 38.4429,
        "local_recall": {
            "1": 0.20007001575354455,
            "2": 0.4760254188330445,
            "3": 0.6914832809374107,
            "4": 0.9736842105263158
        },
        "bertscore": {
            "precision": 0.93189,
            "recall": 0.89551,
            "f1": 0.91166
        },
        "nubia": {
            "semantic_relation": 4.0259,
            "contradiction": 4.72122,
            "irrelevancy": 8.40558,
            "logical_agreement": 86.8732,
            "grammar_ref": 4.28317,
            "grammar_hyp": 4.55606,
            "nubia_score": 0.63874
        },
        "meteor": 0.31116160081772987,
        "bleurt": 0.01293
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-unique_properties": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 1510,
        "msttr-100": 0.50858,
        "msttr-100_nopunct": 0.50835,
        "total_length": 27447,
        "mean_pred_length": 18.17682119205298,
        "std_pred_length": 6.454619411668257,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.06550807009873574,
        "vocab_size-1": 1798,
        "unique-1": 595,
        "entropy-1": 8.124317658963161,
        "distinct-2": 0.22627906080117208,
        "vocab_size-2": 5869,
        "unique-2": 2931,
        "entropy-2": 11.16203697316535,
        "cond_entropy-2": 2.9582352559975815,
        "distinct-3": 0.39055143898145495,
        "vocab_size-3": 9540,
        "unique-3": 5942,
        "entropy-3": 12.30373696842264,
        "cond_entropy-3": 1.2489442011965632,
        "total_length-nopunct": 24939,
        "mean_pred_length-nopunct": 16.515894039735098,
        "std_pred_length-nopunct": 6.170057935641267,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.07173503348169534,
        "vocab_size-1-nopunct": 1789,
        "unique-1-nopunct": 594,
        "entropy-1-nopunct": 8.313735208525177,
        "distinct-2-nopunct": 0.23082504588330702,
        "vocab_size-2-nopunct": 5408,
        "unique-2-nopunct": 2796,
        "entropy-2-nopunct": 11.030355254072019,
        "cond_entropy-2-nopunct": 2.909483815940748,
        "distinct-3-nopunct": 0.39326611615493406,
        "vocab_size-3-nopunct": 8620,
        "unique-3-nopunct": 5429,
        "entropy-3-nopunct": 12.14200009694886,
        "cond_entropy-3-nopunct": 1.2161270478613049,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.100964003014071,
        "rouge1": {
            "precision": 0.79248,
            "recall": 0.69923,
            "fmeasure": 0.72947
        },
        "rouge2": {
            "precision": 0.54454,
            "recall": 0.47702,
            "fmeasure": 0.49831
        },
        "rougeL": {
            "precision": 0.66055,
            "recall": 0.58295,
            "fmeasure": 0.60776
        },
        "rougeLsum": {
            "precision": 0.66055,
            "recall": 0.58295,
            "fmeasure": 0.60776
        },
        "bleu": 41.66993,
        "local_recall": {
            "1": 0.19968687731283802,
            "2": 0.5150979004482189,
            "3": 0.7569493034794225,
            "4": 0.9215686274509803,
            "5": 0.7619047619047619
        },
        "bertscore": {
            "precision": 0.92786,
            "recall": 0.90801,
            "f1": 0.91629
        },
        "nubia": {
            "semantic_relation": 4.22137,
            "contradiction": 6.24781,
            "irrelevancy": 9.12761,
            "logical_agreement": 84.62458,
            "grammar_ref": 4.59892,
            "grammar_hyp": 4.81072,
            "nubia_score": 0.70561
        },
        "meteor": 0.3385166015958909,
        "bleurt": 0.11773
    },
    "totto_test_contrast_challenge_table_size-table_size_976": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 18,
        "unique-1": 15,
        "entropy-1": 4.106603137064473,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.22961067210860203,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8421052631578947,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.9321380397593733,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.25533082133206014,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.411374881128631,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.88889,
            "fmeasure": 0.88889
        },
        "rougeL": {
            "precision": 0.84211,
            "recall": 0.84211,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 0.84211,
            "recall": 0.84211,
            "fmeasure": 0.84211
        },
        "bleu": 78.65537,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.9861,
            "recall": 0.9861,
            "f1": 0.9861
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.10989,
            "irrelevancy": 0.45424,
            "logical_agreement": 99.43587,
            "grammar_ref": 3.47563,
            "grammar_hyp": 3.51842,
            "nubia_score": 0.99645
        },
        "meteor": 0.5693550193428092,
        "bleurt": 0.79293
    },
    "totto_test_contrast_challenge_table_size-table_size_915": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 8.73053390247253,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 28,
        "distinct-1": 0.7446808510638298,
        "vocab_size-1": 35,
        "unique-1": 27,
        "entropy-1": 4.969274489883449,
        "distinct-2": 0.9772727272727273,
        "vocab_size-2": 43,
        "unique-2": 42,
        "entropy-2": 5.413977073182751,
        "cond_entropy-2": 0.37654475564519296,
        "distinct-3": 1.0,
        "vocab_size-3": 41,
        "unique-3": 41,
        "entropy-3": 5.357552004618081,
        "cond_entropy-3": -0.05309912621433559,
        "total_length-nopunct": 42,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 7.788880963698615,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 4.898153434632012,
        "distinct-2-nopunct": 0.9743589743589743,
        "vocab_size-2-nopunct": 38,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.234120167580196,
        "cond_entropy-2-nopunct": 0.373979347421013,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 36,
        "unique-3-nopunct": 36,
        "entropy-3-nopunct": 5.1699250014423095,
        "cond_entropy-3-nopunct": -0.05992166186438029,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.489349129781606,
        "rouge1": {
            "precision": 0.77381,
            "recall": 0.88674,
            "fmeasure": 0.82412
        },
        "rouge2": {
            "precision": 0.5496,
            "recall": 0.653,
            "fmeasure": 0.59463
        },
        "rougeL": {
            "precision": 0.63624,
            "recall": 0.72135,
            "fmeasure": 0.67392
        },
        "rougeLsum": {
            "precision": 0.63624,
            "recall": 0.72135,
            "fmeasure": 0.67392
        },
        "bleu": 49.43739,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.967741935483871
        },
        "bertscore": {
            "precision": 0.93643,
            "recall": 0.94563,
            "f1": 0.94096
        },
        "nubia": {
            "semantic_relation": 4.46946,
            "contradiction": 0.9228,
            "irrelevancy": 62.61022,
            "logical_agreement": 36.46698,
            "grammar_ref": 5.15251,
            "grammar_hyp": 4.90585,
            "nubia_score": 0.80998
        },
        "meteor": 0.48262862364884873,
        "bleurt": 0.14688
    },
    "totto_test_contrast_challenge_table_size-table_size_980": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.659730184574296,
        "rouge1": {
            "precision": 0.70588,
            "recall": 0.48116,
            "fmeasure": 0.57021
        },
        "rouge2": {
            "precision": 0.47917,
            "recall": 0.32288,
            "fmeasure": 0.38441
        },
        "rougeL": {
            "precision": 0.70588,
            "recall": 0.48116,
            "fmeasure": 0.57021
        },
        "rougeLsum": {
            "precision": 0.70588,
            "recall": 0.48116,
            "fmeasure": 0.57021
        },
        "bleu": 31.78999,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6111111111111112
        },
        "bertscore": {
            "precision": 0.94593,
            "recall": 0.90583,
            "f1": 0.92545
        },
        "nubia": {
            "semantic_relation": 3.72228,
            "contradiction": 22.31113,
            "irrelevancy": 4.12126,
            "logical_agreement": 73.56761,
            "grammar_ref": 3.59602,
            "grammar_hyp": 3.85307,
            "nubia_score": 0.56298
        },
        "meteor": 0.3200716699342679,
        "bleurt": 0.12837
    },
    "totto_test_contrast_challenge_table_size-table_size_918": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.403856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.14943964427976503,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.12336199461765365,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3700421697603256,
        "rouge1": {
            "precision": 0.52174,
            "recall": 0.73694,
            "fmeasure": 0.59407
        },
        "rouge2": {
            "precision": 0.34848,
            "recall": 0.53778,
            "fmeasure": 0.41302
        },
        "rougeL": {
            "precision": 0.37681,
            "recall": 0.5641,
            "fmeasure": 0.44218
        },
        "rougeLsum": {
            "precision": 0.37681,
            "recall": 0.5641,
            "fmeasure": 0.44218
        },
        "bleu": 35.23219,
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.87776,
            "recall": 0.94723,
            "f1": 0.91117
        },
        "nubia": {
            "semantic_relation": 3.39227,
            "contradiction": 8.28529,
            "irrelevancy": 85.23528,
            "logical_agreement": 6.47943,
            "grammar_ref": 4.65446,
            "grammar_hyp": 4.34118,
            "nubia_score": 0.34272
        },
        "meteor": 0.42171182505221066,
        "bleurt": -0.37478
    },
    "totto_test_contrast_challenge_table_size-table_size_873": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.8,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.163856189774723,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.4411063109464316,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.91397707318275,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.5043143755700349,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.815188022196727,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.68627,
            "fmeasure": 0.65552
        },
        "rouge2": {
            "precision": 0.2619,
            "recall": 0.28668,
            "fmeasure": 0.2715
        },
        "rougeL": {
            "precision": 0.45455,
            "recall": 0.48529,
            "fmeasure": 0.466
        },
        "rougeLsum": {
            "precision": 0.45455,
            "recall": 0.48529,
            "fmeasure": 0.466
        },
        "bleu": 10.18554,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6428571428571429
        },
        "bertscore": {
            "precision": 0.91207,
            "recall": 0.89292,
            "f1": 0.89889
        },
        "nubia": {
            "semantic_relation": 4.464,
            "contradiction": 6.45287,
            "irrelevancy": 44.86506,
            "logical_agreement": 48.68207,
            "grammar_ref": 4.95035,
            "grammar_hyp": 4.78992,
            "nubia_score": 0.72912
        },
        "meteor": 0.3193728622692359,
        "bleurt": 0.19521
    },
    "web_nlg_en_test_contrast_challenge_max_prop_same-some_properties_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 269,
        "msttr-100": 0.55774,
        "msttr-100_nopunct": 0.5669,
        "total_length": 6277,
        "mean_pred_length": 23.33457249070632,
        "std_pred_length": 3.858023299092893,
        "median_pred_length": 24.0,
        "min_pred_length": 10,
        "max_pred_length": 31,
        "distinct-1": 0.13477776007646966,
        "vocab_size-1": 846,
        "unique-1": 370,
        "entropy-1": 7.705366891119279,
        "distinct-2": 0.3938082556591212,
        "vocab_size-2": 2366,
        "unique-2": 1475,
        "entropy-2": 10.361865229516052,
        "cond_entropy-2": 2.674613243430967,
        "distinct-3": 0.5927861996863565,
        "vocab_size-3": 3402,
        "unique-3": 2497,
        "entropy-3": 11.261870545077695,
        "cond_entropy-3": 0.9621688937235781,
        "total_length-nopunct": 5802,
        "mean_pred_length-nopunct": 21.568773234200744,
        "std_pred_length-nopunct": 3.8086077890201175,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.14460530851430542,
        "vocab_size-1-nopunct": 839,
        "unique-1-nopunct": 368,
        "entropy-1-nopunct": 7.794667390729439,
        "distinct-2-nopunct": 0.4032170612687511,
        "vocab_size-2-nopunct": 2231,
        "unique-2-nopunct": 1408,
        "entropy-2-nopunct": 10.298320621123894,
        "cond_entropy-2-nopunct": 2.619401829713208,
        "distinct-3-nopunct": 0.6060030395136778,
        "vocab_size-3-nopunct": 3190,
        "unique-3-nopunct": 2374,
        "entropy-3-nopunct": 11.177902376326799,
        "cond_entropy-3-nopunct": 0.9387679311886377,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 5.571921420689576,
        "rouge1": {
            "precision": 0.72759,
            "recall": 0.61305,
            "fmeasure": 0.65503
        },
        "rouge2": {
            "precision": 0.43293,
            "recall": 0.36075,
            "fmeasure": 0.38644
        },
        "rougeL": {
            "precision": 0.55156,
            "recall": 0.46385,
            "fmeasure": 0.49531
        },
        "rougeLsum": {
            "precision": 0.55156,
            "recall": 0.46385,
            "fmeasure": 0.49531
        },
        "bleu": 33.11198,
        "local_recall": {
            "1": 0.16197808705952027,
            "2": 0.434304562946674,
            "3": 0.7258534003704684,
            "4": 0.5,
            "5": 0.625
        },
        "bertscore": {
            "precision": 0.89692,
            "recall": 0.87098,
            "f1": 0.88218
        },
        "nubia": {
            "semantic_relation": 3.80333,
            "contradiction": 9.42857,
            "irrelevancy": 14.54485,
            "logical_agreement": 76.02658,
            "grammar_ref": 4.33889,
            "grammar_hyp": 4.65131,
            "nubia_score": 0.56612
        },
        "meteor": 0.2988027023677114,
        "bleurt": -0.17368
    },
    "totto_test_contrast_challenge_table_size-table_size_755": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6363636363636364,
        "vocab_size-1": 14,
        "unique-1": 6,
        "entropy-1": 3.73215889136457,
        "distinct-2": 0.75,
        "vocab_size-2": 15,
        "unique-2": 10,
        "entropy-2": 3.821928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 0.7777777777777778,
        "vocab_size-3": 14,
        "unique-3": 10,
        "entropy-3": 3.7254805569978675,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.65,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.621928094887362,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.7254805569978675,
        "cond_entropy-2-nopunct": 0.07021912877717248,
        "distinct-3-nopunct": 0.8125,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.625,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.490498678107601,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.91381,
            "contradiction": 0.28512,
            "irrelevancy": 0.56352,
            "logical_agreement": 99.15137,
            "grammar_ref": 5.78027,
            "grammar_hyp": 5.87845,
            "nubia_score": 0.96986
        },
        "meteor": 1.0,
        "bleurt": 0.92254
    },
    "totto_test_contrast_challenge_table_size-table_size_876": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5,
        "rouge1": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.3,
            "recall": 0.5,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.85714,
            "fmeasure": 0.66667
        },
        "bleu": 10.60031,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.88921,
            "recall": 0.94805,
            "f1": 0.91769
        },
        "nubia": {
            "semantic_relation": 4.7181,
            "contradiction": 0.18101,
            "irrelevancy": 42.50259,
            "logical_agreement": 57.31642,
            "grammar_ref": 5.74517,
            "grammar_hyp": 3.91475,
            "nubia_score": 1.0
        },
        "meteor": 0.44519131687853003,
        "bleurt": 0.68944
    },
    "totto_test_contrast_challenge_table_size-table_size_642": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 13.0,
        "std_pred_length": 3.265986323710904,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.7948717948717948,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.785151577725659,
        "distinct-2": 1.0,
        "vocab_size-2": 36,
        "unique-2": 36,
        "entropy-2": 5.1699250014423095,
        "cond_entropy-2": 0.2597943104780344,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 10.666666666666666,
        "std_pred_length-nopunct": 2.8674417556808756,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.84375,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.640319531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.857980995127571,
        "cond_entropy-2-nopunct": 0.2548697883802251,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.15754127698647996,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.091940351109706,
        "rouge1": {
            "precision": 0.78917,
            "recall": 0.60523,
            "fmeasure": 0.68298
        },
        "rouge2": {
            "precision": 0.6015,
            "recall": 0.45943,
            "fmeasure": 0.51934
        },
        "rougeL": {
            "precision": 0.68844,
            "recall": 0.52771,
            "fmeasure": 0.59507
        },
        "rougeLsum": {
            "precision": 0.68844,
            "recall": 0.52771,
            "fmeasure": 0.59507
        },
        "bleu": 36.49137,
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 0.6216216216216216
        },
        "bertscore": {
            "precision": 0.90441,
            "recall": 0.85086,
            "f1": 0.87654
        },
        "nubia": {
            "semantic_relation": 3.23567,
            "contradiction": 26.39327,
            "irrelevancy": 2.99954,
            "logical_agreement": 70.60719,
            "grammar_ref": 4.591,
            "grammar_hyp": 4.43965,
            "nubia_score": 0.5019
        },
        "meteor": 0.3221661707399511,
        "bleurt": 0.02563
    },
    "totto_test_contrast_challenge_table_size-table_size_990": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5384615384615384,
        "vocab_size-1": 14,
        "unique-1": 2,
        "entropy-1": 3.7773627950641693,
        "distinct-2": 0.5416666666666666,
        "vocab_size-2": 13,
        "unique-2": 2,
        "entropy-2": 3.6682958340544896,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 0.5454545454545454,
        "vocab_size-3": 12,
        "unique-3": 2,
        "entropy-3": 3.550340709546389,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5416666666666666,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 2,
        "entropy-1-nopunct": 3.6682958340544896,
        "distinct-2-nopunct": 0.5454545454545454,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 2,
        "entropy-2-nopunct": 3.550340709546389,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 0.55,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 2,
        "entropy-3-nopunct": 3.4219280948873623,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.080385572666509,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.78409,
            "fmeasure": 0.81988
        },
        "rouge2": {
            "precision": 0.74242,
            "recall": 0.65,
            "fmeasure": 0.6862
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.70644,
            "fmeasure": 0.73395
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.70644,
            "fmeasure": 0.73395
        },
        "bleu": 48.52176,
        "local_recall": {
            "1": 0.0,
            "2": 0.8571428571428571,
            "3": 0.7894736842105263
        },
        "bertscore": {
            "precision": 0.94847,
            "recall": 0.91658,
            "f1": 0.93223
        },
        "nubia": {
            "semantic_relation": 4.71451,
            "contradiction": 0.13227,
            "irrelevancy": 17.32627,
            "logical_agreement": 82.54146,
            "grammar_ref": 4.70595,
            "grammar_hyp": 5.84547,
            "nubia_score": 0.73273
        },
        "meteor": 0.4317910231432469,
        "bleurt": 0.28832
    },
    "totto_test_contrast_challenge_table_size-table_size_882": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 37,
        "mean_pred_length": 18.5,
        "std_pred_length": 5.5,
        "median_pred_length": 18.5,
        "min_pred_length": 13,
        "max_pred_length": 24,
        "distinct-1": 0.8108108108108109,
        "vocab_size-1": 30,
        "unique-1": 25,
        "entropy-1": 4.7902702574039004,
        "distinct-2": 0.9714285714285714,
        "vocab_size-2": 34,
        "unique-2": 33,
        "entropy-2": 5.072140159802107,
        "cond_entropy-2": 0.3058232228682149,
        "distinct-3": 1.0,
        "vocab_size-3": 33,
        "unique-3": 33,
        "entropy-3": 5.044394119358456,
        "cond_entropy-3": -0.024282836980452634,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.690116517593664,
        "distinct-2-nopunct": 0.96875,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.9375,
        "cond_entropy-2-nopunct": 0.2722176276348775,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.026442737724814758,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.90724111369707,
        "rouge1": {
            "precision": 0.85507,
            "recall": 0.85167,
            "fmeasure": 0.85239
        },
        "rouge2": {
            "precision": 0.70455,
            "recall": 0.72039,
            "fmeasure": 0.71156
        },
        "rougeL": {
            "precision": 0.69565,
            "recall": 0.71522,
            "fmeasure": 0.70475
        },
        "rougeLsum": {
            "precision": 0.69565,
            "recall": 0.71522,
            "fmeasure": 0.70475
        },
        "bleu": 61.13578,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.3333333333333333,
            "3": 0.88
        },
        "bertscore": {
            "precision": 0.93018,
            "recall": 0.94353,
            "f1": 0.93374
        },
        "nubia": {
            "semantic_relation": 4.44164,
            "contradiction": 26.91382,
            "irrelevancy": 11.99771,
            "logical_agreement": 61.08847,
            "grammar_ref": 4.2058,
            "grammar_hyp": 4.40431,
            "nubia_score": 0.80849
        },
        "meteor": 0.447872714617561,
        "bleurt": 0.35415
    },
    "totto_test_contrast_challenge_table_size-table_size_920": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 17.666666666666668,
        "std_pred_length": 3.299831645537222,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.7924528301886793,
        "vocab_size-1": 42,
        "unique-1": 33,
        "entropy-1": 5.2843397941041985,
        "distinct-2": 0.92,
        "vocab_size-2": 46,
        "unique-2": 42,
        "entropy-2": 5.483856189774728,
        "cond_entropy-2": 0.18613123529806413,
        "distinct-3": 0.9574468085106383,
        "vocab_size-3": 45,
        "unique-3": 43,
        "entropy-3": 5.469482468698917,
        "cond_entropy-3": -0.004160955118363874,
        "total_length-nopunct": 48,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 4.898979485566356,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.7916666666666666,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 30,
        "entropy-1-nopunct": 5.136842188131015,
        "distinct-2-nopunct": 0.9111111111111111,
        "vocab_size-2-nopunct": 41,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.314075318551895,
        "cond_entropy-2-nopunct": 0.20710781792689456,
        "distinct-3-nopunct": 0.9523809523809523,
        "vocab_size-3-nopunct": 40,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.297079327540667,
        "cond_entropy-3-nopunct": -0.004297578312819168,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.242387548917845,
        "rouge1": {
            "precision": 0.61069,
            "recall": 0.62531,
            "fmeasure": 0.61373
        },
        "rouge2": {
            "precision": 0.41508,
            "recall": 0.42882,
            "fmeasure": 0.41882
        },
        "rougeL": {
            "precision": 0.53872,
            "recall": 0.55617,
            "fmeasure": 0.54388
        },
        "rougeLsum": {
            "precision": 0.53872,
            "recall": 0.55617,
            "fmeasure": 0.54388
        },
        "bleu": 27.84742,
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.4,
            "3": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.8874,
            "recall": 0.86341,
            "f1": 0.87501
        },
        "nubia": {
            "semantic_relation": 3.74205,
            "contradiction": 3.66781,
            "irrelevancy": 43.10903,
            "logical_agreement": 53.22316,
            "grammar_ref": 4.46773,
            "grammar_hyp": 4.1105,
            "nubia_score": 0.63631
        },
        "meteor": 0.27891733043271055,
        "bleurt": 0.07296
    },
    "totto_test_contrast_challenge_table_size-table_size_815": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 2.0,
        "median_pred_length": 14.0,
        "min_pred_length": 12,
        "max_pred_length": 16,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.450212064914748,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.2007771037757955,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 25,
        "mean_pred_length-nopunct": 12.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 12.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.88,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.323856189774722,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.22753185323880998,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.1312445332782524,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.247909918727218,
        "rouge1": {
            "precision": 0.85833,
            "recall": 0.87454,
            "fmeasure": 0.86293
        },
        "rouge2": {
            "precision": 0.70563,
            "recall": 0.72863,
            "fmeasure": 0.71372
        },
        "rougeL": {
            "precision": 0.81667,
            "recall": 0.837,
            "fmeasure": 0.82344
        },
        "rougeLsum": {
            "precision": 0.81667,
            "recall": 0.837,
            "fmeasure": 0.82344
        },
        "bleu": 62.91194,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8947368421052632
        },
        "bertscore": {
            "precision": 0.9652,
            "recall": 0.96804,
            "f1": 0.96487
        },
        "nubia": {
            "semantic_relation": 4.7304,
            "contradiction": 0.17529,
            "irrelevancy": 0.43647,
            "logical_agreement": 99.38825,
            "grammar_ref": 4.97173,
            "grammar_hyp": 4.53748,
            "nubia_score": 0.90437
        },
        "meteor": 0.5255863400703223,
        "bleurt": 0.67071
    },
    "totto_test_contrast_challenge_table_size-table_size_888": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 13.5,
        "std_pred_length": 4.716990566028302,
        "median_pred_length": 12.0,
        "min_pred_length": 9,
        "max_pred_length": 21,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 42,
        "unique-1": 36,
        "entropy-1": 5.171373150231488,
        "distinct-2": 0.98,
        "vocab_size-2": 49,
        "unique-2": 48,
        "entropy-2": 5.603856189774728,
        "cond_entropy-2": 0.3191641876977949,
        "distinct-3": 1.0,
        "vocab_size-3": 46,
        "unique-3": 46,
        "entropy-3": 5.5235619560570095,
        "cond_entropy-3": -0.07681597284814654,
        "total_length-nopunct": 47,
        "mean_pred_length-nopunct": 11.75,
        "std_pred_length-nopunct": 3.897114317029974,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8085106382978723,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.054380872862172,
        "distinct-2-nopunct": 0.9767441860465116,
        "vocab_size-2-nopunct": 42,
        "unique-2-nopunct": 41,
        "entropy-2-nopunct": 5.379753126795121,
        "cond_entropy-2-nopunct": 0.3719032287064822,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 39,
        "entropy-3-nopunct": 5.285402218862247,
        "cond_entropy-3-nopunct": -0.0895804845577984,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.496543058893456,
        "rouge1": {
            "precision": 0.64904,
            "recall": 0.50508,
            "fmeasure": 0.55
        },
        "rouge2": {
            "precision": 0.3858,
            "recall": 0.34266,
            "fmeasure": 0.35706
        },
        "rougeL": {
            "precision": 0.49776,
            "recall": 0.43534,
            "fmeasure": 0.45595
        },
        "rougeLsum": {
            "precision": 0.49776,
            "recall": 0.43534,
            "fmeasure": 0.45595
        },
        "bleu": 28.81897,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 0.6818181818181818,
            "3": 0.35135135135135137
        },
        "bertscore": {
            "precision": 0.90062,
            "recall": 0.86739,
            "f1": 0.88175
        },
        "nubia": {
            "semantic_relation": 2.98141,
            "contradiction": 56.27433,
            "irrelevancy": 20.08758,
            "logical_agreement": 23.6381,
            "grammar_ref": 4.12218,
            "grammar_hyp": 4.15539,
            "nubia_score": 0.41163
        },
        "meteor": 0.2692443607224793,
        "bleurt": 0.0227
    },
    "totto_test_contrast_challenge_table_size-table_size_1000": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.657486658167695,
        "rouge1": {
            "precision": 0.60417,
            "recall": 0.59809,
            "fmeasure": 0.59189
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rougeL": {
            "precision": 0.5625,
            "recall": 0.563,
            "fmeasure": 0.55379
        },
        "rougeLsum": {
            "precision": 0.5625,
            "recall": 0.563,
            "fmeasure": 0.55379
        },
        "bleu": 11.72655,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.0,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.88431,
            "recall": 0.87967,
            "f1": 0.87482
        },
        "nubia": {
            "semantic_relation": 4.38715,
            "contradiction": 0.34361,
            "irrelevancy": 68.88161,
            "logical_agreement": 30.77478,
            "grammar_ref": 3.90557,
            "grammar_hyp": 4.01784,
            "nubia_score": 0.78116
        },
        "meteor": 0.3351574613160235,
        "bleurt": -0.48925
    },
    "totto_test_contrast_challenge_table_size-table_size_924": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.665981269484256,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.82895,
            "fmeasure": 0.85
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.62963,
            "fmeasure": 0.64646
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.71053,
            "fmeasure": 0.72857
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.71053,
            "fmeasure": 0.72857
        },
        "bleu": 49.5233,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.92408,
            "recall": 0.90479,
            "f1": 0.91434
        },
        "nubia": {
            "semantic_relation": 4.96647,
            "contradiction": 0.84117,
            "irrelevancy": 0.65915,
            "logical_agreement": 98.49968,
            "grammar_ref": 4.542,
            "grammar_hyp": 3.78894,
            "nubia_score": 0.99813
        },
        "meteor": 0.4340990261693778,
        "bleurt": 0.11242
    },
    "totto_test_contrast_challenge_table_size-table_size_1005": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8998572512287097,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.63333,
            "fmeasure": 0.7037
        },
        "rougeL": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "rougeLsum": {
            "precision": 0.96296,
            "recall": 0.78788,
            "fmeasure": 0.86667
        },
        "bleu": 70.97039,
        "local_recall": {
            "1": 0.25,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.98271,
            "recall": 0.9644,
            "f1": 0.97347
        },
        "nubia": {
            "semantic_relation": 4.54342,
            "contradiction": 0.48545,
            "irrelevancy": 0.54019,
            "logical_agreement": 98.97436,
            "grammar_ref": 4.98843,
            "grammar_hyp": 5.36395,
            "nubia_score": 0.7985
        },
        "meteor": 0.5047034859011716,
        "bleurt": 0.49536
    },
    "totto_test_contrast_challenge_table_size-table_size_816": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 91,
        "mean_pred_length": 18.2,
        "std_pred_length": 7.05407683541936,
        "median_pred_length": 19.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.7032967032967034,
        "vocab_size-1": 64,
        "unique-1": 52,
        "entropy-1": 5.721796976074187,
        "distinct-2": 0.9069767441860465,
        "vocab_size-2": 78,
        "unique-2": 71,
        "entropy-2": 6.231440481421129,
        "cond_entropy-2": 0.4623177881448786,
        "distinct-3": 0.9382716049382716,
        "vocab_size-3": 76,
        "unique-3": 71,
        "entropy-3": 6.216393212761157,
        "cond_entropy-3": -0.003021078951257661,
        "total_length-nopunct": 80,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 5.656854249492381,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.7375,
        "vocab_size-1-nopunct": 59,
        "unique-1-nopunct": 49,
        "entropy-1-nopunct": 5.627855751945727,
        "distinct-2-nopunct": 0.8933333333333333,
        "vocab_size-2-nopunct": 67,
        "unique-2-nopunct": 60,
        "entropy-2-nopunct": 6.005420190467045,
        "cond_entropy-2-nopunct": 0.4105025947174118,
        "distinct-3-nopunct": 0.9285714285714286,
        "vocab_size-3-nopunct": 65,
        "unique-3-nopunct": 60,
        "entropy-3-nopunct": 5.9864258740878284,
        "cond_entropy-3-nopunct": -0.017322994948579126,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.8206490803068673,
        "rouge1": {
            "precision": 0.76135,
            "recall": 0.74956,
            "fmeasure": 0.74184
        },
        "rouge2": {
            "precision": 0.59647,
            "recall": 0.59248,
            "fmeasure": 0.58336
        },
        "rougeL": {
            "precision": 0.68357,
            "recall": 0.66408,
            "fmeasure": 0.661
        },
        "rougeLsum": {
            "precision": 0.68357,
            "recall": 0.66408,
            "fmeasure": 0.661
        },
        "bleu": 44.54639,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.5490196078431373,
            "3": 0.8857142857142857
        },
        "bertscore": {
            "precision": 0.92958,
            "recall": 0.91444,
            "f1": 0.91803
        },
        "nubia": {
            "semantic_relation": 4.05796,
            "contradiction": 8.55709,
            "irrelevancy": 28.23401,
            "logical_agreement": 63.2089,
            "grammar_ref": 4.74118,
            "grammar_hyp": 4.91737,
            "nubia_score": 0.69993
        },
        "meteor": 0.3739695451553319,
        "bleurt": 0.05649
    },
    "totto_test_contrast_challenge_table_size-table_size_756": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.9473684210526315,
        "vocab_size-1": 18,
        "unique-1": 17,
        "entropy-1": 4.142664355548846,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.03310859910983796,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.03310859910983796,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9523786335715503,
        "rouge1": {
            "precision": 0.61364,
            "recall": 0.71449,
            "fmeasure": 0.65285
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.44156,
            "fmeasure": 0.40399
        },
        "rougeL": {
            "precision": 0.54545,
            "recall": 0.62609,
            "fmeasure": 0.57658
        },
        "rougeLsum": {
            "precision": 0.54545,
            "recall": 0.62609,
            "fmeasure": 0.57658
        },
        "bleu": 44.15212,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.75
        },
        "bertscore": {
            "precision": 0.91464,
            "recall": 0.93182,
            "f1": 0.92315
        },
        "nubia": {
            "semantic_relation": 3.59362,
            "contradiction": 5.05588,
            "irrelevancy": 91.07478,
            "logical_agreement": 3.86935,
            "grammar_ref": 5.51157,
            "grammar_hyp": 5.62161,
            "nubia_score": 0.50336
        },
        "meteor": 0.35504306864667695,
        "bleurt": -0.30093
    },
    "totto_test_contrast_challenge_table_size-table_size_822": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 3.0,
        "median_pred_length": 11.0,
        "min_pred_length": 8,
        "max_pred_length": 14,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2939540214368583,
        "rouge1": {
            "precision": 0.66484,
            "recall": 0.51891,
            "fmeasure": 0.58054
        },
        "rouge2": {
            "precision": 0.48611,
            "recall": 0.35577,
            "fmeasure": 0.40952
        },
        "rougeL": {
            "precision": 0.65201,
            "recall": 0.4902,
            "fmeasure": 0.55832
        },
        "rougeLsum": {
            "precision": 0.65201,
            "recall": 0.4902,
            "fmeasure": 0.55832
        },
        "bleu": 35.45321,
        "local_recall": {
            "1": 0.4,
            "2": 0.3333333333333333,
            "3": 0.5882352941176471
        },
        "bertscore": {
            "precision": 0.93714,
            "recall": 0.88977,
            "f1": 0.91266
        },
        "nubia": {
            "semantic_relation": 4.21211,
            "contradiction": 15.77281,
            "irrelevancy": 22.14293,
            "logical_agreement": 62.08426,
            "grammar_ref": 4.56502,
            "grammar_hyp": 6.17764,
            "nubia_score": 0.59299
        },
        "meteor": 0.343609637842483,
        "bleurt": 0.44736
    },
    "totto_test_contrast_challenge_table_size-table_size_1010": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5558007589002625,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.58333,
            "fmeasure": 0.63636
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.27273,
            "fmeasure": 0.3
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.5,
            "fmeasure": 0.54545
        },
        "bleu": 26.58156,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.36363636363636365
        },
        "bertscore": {
            "precision": 0.9044,
            "recall": 0.85931,
            "f1": 0.88119
        },
        "nubia": {
            "semantic_relation": 4.34677,
            "contradiction": 0.07166,
            "irrelevancy": 33.62393,
            "logical_agreement": 66.3044,
            "grammar_ref": 4.00353,
            "grammar_hyp": 5.48359,
            "nubia_score": 0.71994
        },
        "meteor": 0.2805237819380704,
        "bleurt": 0.36313
    },
    "totto_test_contrast_challenge_table_size-table_size_644": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 2.0,
        "median_pred_length": 16.0,
        "min_pred_length": 14,
        "max_pred_length": 18,
        "distinct-1": 0.90625,
        "vocab_size-1": 29,
        "unique-1": 26,
        "entropy-1": 4.8125,
        "distinct-2": 1.0,
        "vocab_size-2": 30,
        "unique-2": 30,
        "entropy-2": 4.906890595608519,
        "cond_entropy-2": 0.040223928941851936,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.09953567355091442,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.773557262275186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.536626171301248,
        "rouge1": {
            "precision": 0.8663,
            "recall": 0.87979,
            "fmeasure": 0.87288
        },
        "rouge2": {
            "precision": 0.61667,
            "recall": 0.62368,
            "fmeasure": 0.62009
        },
        "rougeL": {
            "precision": 0.74725,
            "recall": 0.75678,
            "fmeasure": 0.7519
        },
        "rougeLsum": {
            "precision": 0.74725,
            "recall": 0.75678,
            "fmeasure": 0.7519
        },
        "bleu": 43.8321,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.5,
            "3": 0.92
        },
        "bertscore": {
            "precision": 0.9644,
            "recall": 0.96611,
            "f1": 0.96525
        },
        "nubia": {
            "semantic_relation": 4.69297,
            "contradiction": 0.41697,
            "irrelevancy": 2.71071,
            "logical_agreement": 96.87231,
            "grammar_ref": 4.65278,
            "grammar_hyp": 4.4463,
            "nubia_score": 0.91345
        },
        "meteor": 0.4349194945887192,
        "bleurt": 0.55196
    },
    "totto_test_contrast_challenge_table_size-table_size_828": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 52,
        "mean_pred_length": 26.0,
        "std_pred_length": 3.0,
        "median_pred_length": 26.0,
        "min_pred_length": 23,
        "max_pred_length": 29,
        "distinct-1": 0.7884615384615384,
        "vocab_size-1": 41,
        "unique-1": 36,
        "entropy-1": 5.1329440449809605,
        "distinct-2": 0.96,
        "vocab_size-2": 48,
        "unique-2": 46,
        "entropy-2": 5.563856189774728,
        "cond_entropy-2": 0.4536119717201714,
        "distinct-3": 1.0,
        "vocab_size-3": 48,
        "unique-3": 48,
        "entropy-3": 5.5849625007211605,
        "cond_entropy-3": 0.024439644279765027,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 24.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 24.5,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.7755102040816326,
        "vocab_size-1-nopunct": 38,
        "unique-1-nopunct": 33,
        "entropy-1-nopunct": 5.012469537904455,
        "distinct-2-nopunct": 0.9574468085106383,
        "vocab_size-2-nopunct": 45,
        "unique-2-nopunct": 43,
        "entropy-2-nopunct": 5.469482468698917,
        "cond_entropy-2-nopunct": 0.46136358212257655,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 45,
        "entropy-3-nopunct": 5.491853096329673,
        "cond_entropy-3-nopunct": 0.003930911318703933,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.257929376134717,
        "rouge1": {
            "precision": 0.63384,
            "recall": 0.57341,
            "fmeasure": 0.60104
        },
        "rouge2": {
            "precision": 0.36325,
            "recall": 0.32564,
            "fmeasure": 0.34275
        },
        "rougeL": {
            "precision": 0.45932,
            "recall": 0.41546,
            "fmeasure": 0.43547
        },
        "rougeLsum": {
            "precision": 0.45932,
            "recall": 0.41546,
            "fmeasure": 0.43547
        },
        "bleu": 39.38452,
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 0,
            "3": 0.48717948717948717
        },
        "bertscore": {
            "precision": 0.88173,
            "recall": 0.84161,
            "f1": 0.86118
        },
        "nubia": {
            "semantic_relation": 2.88818,
            "contradiction": 49.49332,
            "irrelevancy": 3.67362,
            "logical_agreement": 46.83306,
            "grammar_ref": 3.79147,
            "grammar_hyp": 3.66384,
            "nubia_score": 0.41368
        },
        "meteor": 0.27793006941841686,
        "bleurt": -0.18522
    },
    "totto_test_contrast_challenge_table_size-table_size_760": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 12.75,
        "std_pred_length": 3.112474899497183,
        "median_pred_length": 13.5,
        "min_pred_length": 8,
        "max_pred_length": 16,
        "distinct-1": 0.7450980392156863,
        "vocab_size-1": 38,
        "unique-1": 30,
        "entropy-1": 5.069388332125157,
        "distinct-2": 0.9574468085106383,
        "vocab_size-2": 45,
        "unique-2": 43,
        "entropy-2": 5.469482468698916,
        "cond_entropy-2": 0.2812036693266413,
        "distinct-3": 1.0,
        "vocab_size-3": 43,
        "unique-3": 43,
        "entropy-3": 5.426264754702098,
        "cond_entropy-3": -0.03530084116158587,
        "total_length-nopunct": 46,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.2015621187164243,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.782608695652174,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 5.028890488618674,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 40,
        "unique-2-nopunct": 38,
        "entropy-2-nopunct": 5.297079327540667,
        "cond_entropy-2-nopunct": 0.2914908834399253,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 38,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.247927513443589,
        "cond_entropy-3-nopunct": -0.06544254091412231,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.124150001129441,
        "rouge1": {
            "precision": 0.54583,
            "recall": 0.54749,
            "fmeasure": 0.52499
        },
        "rouge2": {
            "precision": 0.31517,
            "recall": 0.32197,
            "fmeasure": 0.30522
        },
        "rougeL": {
            "precision": 0.46726,
            "recall": 0.48124,
            "fmeasure": 0.45653
        },
        "rougeLsum": {
            "precision": 0.46726,
            "recall": 0.48124,
            "fmeasure": 0.45653
        },
        "bleu": 23.9485,
        "local_recall": {
            "1": 0.35714285714285715,
            "2": 0.16666666666666666,
            "3": 0.7391304347826086
        },
        "bertscore": {
            "precision": 0.85931,
            "recall": 0.8493,
            "f1": 0.85036
        },
        "nubia": {
            "semantic_relation": 3.53852,
            "contradiction": 3.09543,
            "irrelevancy": 25.95288,
            "logical_agreement": 70.95169,
            "grammar_ref": 4.9362,
            "grammar_hyp": 4.5766,
            "nubia_score": 0.58405
        },
        "meteor": 0.22350139152286255,
        "bleurt": -0.00082
    },
    "totto_test_contrast_challenge_table_size-table_size_889": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9761440687863128,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.52381,
            "fmeasure": 0.4653
        },
        "rouge2": {
            "precision": 0.11905,
            "recall": 0.14444,
            "fmeasure": 0.12529
        },
        "rougeL": {
            "precision": 0.26667,
            "recall": 0.30357,
            "fmeasure": 0.27566
        },
        "rougeLsum": {
            "precision": 0.26667,
            "recall": 0.30357,
            "fmeasure": 0.27566
        },
        "bleu": 4.30078,
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.77636,
            "recall": 0.79045,
            "f1": 0.75124
        },
        "nubia": {
            "semantic_relation": 2.10837,
            "contradiction": 30.90046,
            "irrelevancy": 68.47934,
            "logical_agreement": 0.6202,
            "grammar_ref": 4.92688,
            "grammar_hyp": 3.43795,
            "nubia_score": 0.23287
        },
        "meteor": 0.24704253628256037,
        "bleurt": 0.00879
    },
    "totto_test_contrast_challenge_table_size-table_size_925": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.76984493924432,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.78571,
            "fmeasure": 0.75862
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.61538,
            "fmeasure": 0.59259
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.5,
            "fmeasure": 0.48276
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.5,
            "fmeasure": 0.48276
        },
        "bleu": 34.46073,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8461538461538461
        },
        "bertscore": {
            "precision": 0.89583,
            "recall": 0.92791,
            "f1": 0.91159
        },
        "nubia": {
            "semantic_relation": 4.22045,
            "contradiction": 0.10235,
            "irrelevancy": 99.77771,
            "logical_agreement": 0.11994,
            "grammar_ref": 5.0526,
            "grammar_hyp": 5.71222,
            "nubia_score": 0.61801
        },
        "meteor": 0.46508218314309463,
        "bleurt": 0.11996
    },
    "totto_test_contrast_challenge_table_size-table_size_764": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0919810101287672,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.47368,
            "fmeasure": 0.62069
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.38889,
            "fmeasure": 0.51852
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.47368,
            "fmeasure": 0.62069
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.47368,
            "fmeasure": 0.62069
        },
        "bleu": 34.67552,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.5625
        },
        "bertscore": {
            "precision": 0.9618,
            "recall": 0.79459,
            "f1": 0.87024
        },
        "nubia": {
            "semantic_relation": 3.91066,
            "contradiction": 0.07243,
            "irrelevancy": 3.63935,
            "logical_agreement": 96.28822,
            "grammar_ref": 4.21408,
            "grammar_hyp": 6.00597,
            "nubia_score": 0.47125
        },
        "meteor": 0.305432455862443,
        "bleurt": 0.08664
    },
    "totto_test_contrast_challenge_table_size-table_size_830": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.7777777777777778,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.6416041678685933,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.4769363694743175,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.4677201004745006,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6643779994262076,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.93333,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.71429,
            "fmeasure": 0.68966
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.53333,
            "fmeasure": 0.51613
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.53333,
            "fmeasure": 0.51613
        },
        "bleu": 55.64293,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.95759,
            "recall": 0.96381,
            "f1": 0.96069
        },
        "nubia": {
            "semantic_relation": 4.9347,
            "contradiction": 0.41479,
            "irrelevancy": 2.55872,
            "logical_agreement": 97.02649,
            "grammar_ref": 4.08392,
            "grammar_hyp": 3.79392,
            "nubia_score": 0.98378
        },
        "meteor": 0.49102193871620886,
        "bleurt": 0.50338
    },
    "totto_test_contrast_challenge_table_size-table_size_833": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966059,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.2434131920567095,
        "rouge1": {
            "precision": 0.87037,
            "recall": 0.83918,
            "fmeasure": 0.85435
        },
        "rouge2": {
            "precision": 0.78431,
            "recall": 0.6936,
            "fmeasure": 0.73455
        },
        "rougeL": {
            "precision": 0.87037,
            "recall": 0.83918,
            "fmeasure": 0.85435
        },
        "rougeLsum": {
            "precision": 0.87037,
            "recall": 0.83918,
            "fmeasure": 0.85435
        },
        "bleu": 79.40693,
        "local_recall": {
            "1": 0.1111111111111111,
            "2": 1.0,
            "3": 0.9285714285714286
        },
        "bertscore": {
            "precision": 0.96275,
            "recall": 0.94414,
            "f1": 0.94769
        },
        "nubia": {
            "semantic_relation": 4.25263,
            "contradiction": 44.44302,
            "irrelevancy": 10.13095,
            "logical_agreement": 45.42603,
            "grammar_ref": 4.95426,
            "grammar_hyp": 5.20986,
            "nubia_score": 0.63846
        },
        "meteor": 0.46466278035857306,
        "bleurt": 0.22695
    },
    "totto_test_contrast_challenge_table_size-table_size_1014": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.723308333814104,
        "rouge1": {
            "precision": 0.83333,
            "recall": 1.0,
            "fmeasure": 0.90909
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.75,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "bleu": 23.3569,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.90485,
            "recall": 0.94039,
            "f1": 0.92228
        },
        "nubia": {
            "semantic_relation": 4.89473,
            "contradiction": 0.54695,
            "irrelevancy": 62.29129,
            "logical_agreement": 37.16177,
            "grammar_ref": 6.34893,
            "grammar_hyp": 5.11194,
            "nubia_score": 1.0
        },
        "meteor": 0.45338137412288526,
        "bleurt": 0.65796
    },
    "totto_test_contrast_challenge_table_size-table_size_834": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.306797170061882,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.82353,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70238
        },
        "rougeL": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "rougeLsum": {
            "precision": 0.65385,
            "recall": 0.58145,
            "fmeasure": 0.61282
        },
        "bleu": 69.04427,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.97265,
            "recall": 0.97025,
            "f1": 0.97145
        },
        "nubia": {
            "semantic_relation": 4.27928,
            "contradiction": 0.25448,
            "irrelevancy": 0.49291,
            "logical_agreement": 99.25261,
            "grammar_ref": 4.29821,
            "grammar_hyp": 4.38971,
            "nubia_score": 0.78008
        },
        "meteor": 0.5500501807094148,
        "bleurt": 0.47554
    },
    "totto_test_contrast_challenge_table_size-table_size_645": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 24,
        "unique-1": 22,
        "entropy-1": 4.546593564294937,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.10341647163363248,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.459431618637295,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.06711419585853673,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3946761191937407,
        "rouge1": {
            "precision": 0.72727,
            "recall": 0.82807,
            "fmeasure": 0.77429
        },
        "rouge2": {
            "precision": 0.61905,
            "recall": 0.70955,
            "fmeasure": 0.66111
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.82807,
            "fmeasure": 0.77429
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.82807,
            "fmeasure": 0.77429
        },
        "bleu": 53.39293,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.93214,
            "recall": 0.95481,
            "f1": 0.94334
        },
        "nubia": {
            "semantic_relation": 3.87717,
            "contradiction": 94.22721,
            "irrelevancy": 4.03075,
            "logical_agreement": 1.74204,
            "grammar_ref": 3.98302,
            "grammar_hyp": 4.0065,
            "nubia_score": 0.60993
        },
        "meteor": 0.43789141498595213,
        "bleurt": -0.12787
    },
    "totto_test_contrast_challenge_table_size-table_size_684": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 96,
        "mean_pred_length": 16.0,
        "std_pred_length": 5.033222956847166,
        "median_pred_length": 14.5,
        "min_pred_length": 9,
        "max_pred_length": 23,
        "distinct-1": 0.6666666666666666,
        "vocab_size-1": 64,
        "unique-1": 48,
        "entropy-1": 5.6904385113365,
        "distinct-2": 0.8555555555555555,
        "vocab_size-2": 77,
        "unique-2": 64,
        "entropy-2": 6.202964207440777,
        "cond_entropy-2": 0.3998297953485217,
        "distinct-3": 0.8928571428571429,
        "vocab_size-3": 75,
        "unique-3": 66,
        "entropy-3": 6.178031708493046,
        "cond_entropy-3": -0.028107102122342967,
        "total_length-nopunct": 83,
        "mean_pred_length-nopunct": 13.833333333333334,
        "std_pred_length-nopunct": 3.8477987935383986,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.7228915662650602,
        "vocab_size-1-nopunct": 60,
        "unique-1-nopunct": 46,
        "entropy-1-nopunct": 5.66714922047749,
        "distinct-2-nopunct": 0.8571428571428571,
        "vocab_size-2-nopunct": 66,
        "unique-2-nopunct": 55,
        "entropy-2-nopunct": 5.981072254980619,
        "cond_entropy-2-nopunct": 0.34310928470074914,
        "distinct-3-nopunct": 0.8873239436619719,
        "vocab_size-3-nopunct": 63,
        "unique-3-nopunct": 55,
        "entropy-3-nopunct": 5.92439500682862,
        "cond_entropy-3-nopunct": -0.032532378936698005,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.3355736976942,
        "rouge1": {
            "precision": 0.81534,
            "recall": 0.79999,
            "fmeasure": 0.78926
        },
        "rouge2": {
            "precision": 0.6201,
            "recall": 0.61494,
            "fmeasure": 0.60578
        },
        "rougeL": {
            "precision": 0.7336,
            "recall": 0.73896,
            "fmeasure": 0.72134
        },
        "rougeLsum": {
            "precision": 0.7336,
            "recall": 0.73896,
            "fmeasure": 0.72134
        },
        "bleu": 50.33178,
        "local_recall": {
            "1": 0.35,
            "2": 0.55,
            "3": 0.7419354838709677
        },
        "bertscore": {
            "precision": 0.92828,
            "recall": 0.93303,
            "f1": 0.93037
        },
        "nubia": {
            "semantic_relation": 4.41635,
            "contradiction": 3.53054,
            "irrelevancy": 27.76123,
            "logical_agreement": 68.70824,
            "grammar_ref": 4.51194,
            "grammar_hyp": 4.20083,
            "nubia_score": 0.82687
        },
        "meteor": 0.4223717701663899,
        "bleurt": 0.29508
    },
    "totto_test_contrast_challenge_table_size-table_size_648": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.11768784439846627,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 22,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.9090909090909091,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.277613436819114,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.12336199461765374,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.07038932789139804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3822005139526872,
        "rouge1": {
            "precision": 0.40909,
            "recall": 0.52941,
            "fmeasure": 0.46154
        },
        "rouge2": {
            "precision": 0.14286,
            "recall": 0.1875,
            "fmeasure": 0.16216
        },
        "rougeL": {
            "precision": 0.22727,
            "recall": 0.29412,
            "fmeasure": 0.25641
        },
        "rougeLsum": {
            "precision": 0.22727,
            "recall": 0.29412,
            "fmeasure": 0.25641
        },
        "bleu": 6.12957,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5333333333333333
        },
        "bertscore": {
            "precision": 0.8232,
            "recall": 0.8791,
            "f1": 0.85023
        },
        "nubia": {
            "semantic_relation": 3.13414,
            "contradiction": 99.56989,
            "irrelevancy": 0.3285,
            "logical_agreement": 0.1016,
            "grammar_ref": 3.58521,
            "grammar_hyp": 4.4427,
            "nubia_score": 0.42829
        },
        "meteor": 0.23033839373428233,
        "bleurt": -0.3647
    },
    "totto_test_contrast_challenge_table_size-table_size_686": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9701201394757433,
        "rouge1": {
            "precision": 0.92593,
            "recall": 0.7641,
            "fmeasure": 0.83413
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.57407,
            "fmeasure": 0.66275
        },
        "rougeL": {
            "precision": 0.92593,
            "recall": 0.7641,
            "fmeasure": 0.83413
        },
        "rougeLsum": {
            "precision": 0.92593,
            "recall": 0.7641,
            "fmeasure": 0.83413
        },
        "bleu": 71.89393,
        "local_recall": {
            "1": 0.1,
            "2": 0.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.97666,
            "recall": 0.96558,
            "f1": 0.97109
        },
        "nubia": {
            "semantic_relation": 4.36339,
            "contradiction": 0.32693,
            "irrelevancy": 0.51164,
            "logical_agreement": 99.16143,
            "grammar_ref": 4.05789,
            "grammar_hyp": 4.04889,
            "nubia_score": 0.86891
        },
        "meteor": 0.48117686361121714,
        "bleurt": 0.43409
    },
    "totto_test_contrast_challenge_table_size-table_size_650": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 0.875,
        "vocab_size-1": 7,
        "unique-1": 6,
        "entropy-1": 2.75,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": 0.0930692077718899,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.5216406363433186,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": 0.11094091199688534,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.50789957099271,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.97499,
            "contradiction": 0.89945,
            "irrelevancy": 0.58957,
            "logical_agreement": 98.51098,
            "grammar_ref": 4.12966,
            "grammar_hyp": 4.39551,
            "nubia_score": 0.98513
        },
        "meteor": 1.0,
        "bleurt": 0.89367
    },
    "totto_test_contrast_challenge_table_size-table_size_840": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 77,
        "mean_pred_length": 15.4,
        "std_pred_length": 5.425863986500215,
        "median_pred_length": 14.0,
        "min_pred_length": 8,
        "max_pred_length": 23,
        "distinct-1": 0.7012987012987013,
        "vocab_size-1": 54,
        "unique-1": 37,
        "entropy-1": 5.58672773580399,
        "distinct-2": 0.875,
        "vocab_size-2": 63,
        "unique-2": 54,
        "entropy-2": 5.919925001442312,
        "cond_entropy-2": 0.21917856494412585,
        "distinct-3": 0.9104477611940298,
        "vocab_size-3": 61,
        "unique-3": 55,
        "entropy-3": 5.886984712845829,
        "cond_entropy-3": -0.014283572178569771,
        "total_length-nopunct": 68,
        "mean_pred_length-nopunct": 13.6,
        "std_pred_length-nopunct": 5.314132102234569,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 51,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 5.558051076544457,
        "distinct-2-nopunct": 0.873015873015873,
        "vocab_size-2-nopunct": 55,
        "unique-2-nopunct": 47,
        "entropy-2-nopunct": 5.723311669531662,
        "cond_entropy-2-nopunct": 0.20727739970989445,
        "distinct-3-nopunct": 0.9137931034482759,
        "vocab_size-3-nopunct": 53,
        "unique-3-nopunct": 48,
        "entropy-3-nopunct": 5.685567202024123,
        "cond_entropy-3-nopunct": -0.01585065251027546,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.454038742997074,
        "rouge1": {
            "precision": 0.75238,
            "recall": 0.75849,
            "fmeasure": 0.7552
        },
        "rouge2": {
            "precision": 0.59731,
            "recall": 0.60181,
            "fmeasure": 0.5994
        },
        "rougeL": {
            "precision": 0.69071,
            "recall": 0.75037,
            "fmeasure": 0.70936
        },
        "rougeLsum": {
            "precision": 0.69071,
            "recall": 0.75037,
            "fmeasure": 0.70936
        },
        "bleu": 54.92326,
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855,
            "3": 0.8478260869565217
        },
        "bertscore": {
            "precision": 0.91831,
            "recall": 0.93495,
            "f1": 0.92552
        },
        "nubia": {
            "semantic_relation": 3.98104,
            "contradiction": 19.86765,
            "irrelevancy": 6.64217,
            "logical_agreement": 73.49019,
            "grammar_ref": 5.02868,
            "grammar_hyp": 4.73441,
            "nubia_score": 0.76003
        },
        "meteor": 0.4398103356357903,
        "bleurt": 0.38234
    },
    "totto_test_contrast_challenge_table_size-table_size_693": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964164,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.05628729973432272,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.259466968861382,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.85714,
            "fmeasure": 0.88889
        },
        "rouge2": {
            "precision": 0.72222,
            "recall": 0.66667,
            "fmeasure": 0.69333
        },
        "rougeL": {
            "precision": 0.87179,
            "recall": 0.80952,
            "fmeasure": 0.83951
        },
        "rougeLsum": {
            "precision": 0.87179,
            "recall": 0.80952,
            "fmeasure": 0.83951
        },
        "bleu": 59.82478,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.9
        },
        "bertscore": {
            "precision": 0.97432,
            "recall": 0.96889,
            "f1": 0.9716
        },
        "nubia": {
            "semantic_relation": 4.95681,
            "contradiction": 2.96079,
            "irrelevancy": 11.47546,
            "logical_agreement": 85.56375,
            "grammar_ref": 4.18993,
            "grammar_hyp": 4.11551,
            "nubia_score": 0.94116
        },
        "meteor": 0.46036015895471294,
        "bleurt": 0.5837
    },
    "totto_test_contrast_challenge_table_size-table_size_890": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2349851365001359,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.40179,
            "fmeasure": 0.36397
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.59028,
            "fmeasure": 0.54094
        },
        "bleu": 16.78446,
        "local_recall": {
            "1": 0.0,
            "2": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.85831,
            "recall": 0.87683,
            "f1": 0.86747
        },
        "nubia": {
            "semantic_relation": 4.2029,
            "contradiction": 7.06447,
            "irrelevancy": 12.79331,
            "logical_agreement": 80.14222,
            "grammar_ref": 4.73918,
            "grammar_hyp": 4.01995,
            "nubia_score": 0.76232
        },
        "meteor": 0.27858768568166986,
        "bleurt": 0.52303
    },
    "totto_test_contrast_challenge_table_size-table_size_1100": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 50,
        "mean_pred_length": 25.0,
        "std_pred_length": 1.0,
        "median_pred_length": 25.0,
        "min_pred_length": 24,
        "max_pred_length": 26,
        "distinct-1": 0.74,
        "vocab_size-1": 37,
        "unique-1": 28,
        "entropy-1": 5.03656563024272,
        "distinct-2": 0.9375,
        "vocab_size-2": 45,
        "unique-2": 42,
        "entropy-2": 5.4599625007211605,
        "cond_entropy-2": 0.4278673104589376,
        "distinct-3": 0.9782608695652174,
        "vocab_size-3": 45,
        "unique-3": 44,
        "entropy-3": 5.480083695187445,
        "cond_entropy-3": 0.003816846640204568,
        "total_length-nopunct": 44,
        "mean_pred_length-nopunct": 22.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.8602378009872895,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 39,
        "unique-2-nopunct": 36,
        "entropy-2-nopunct": 5.249460279921619,
        "cond_entropy-2-nopunct": 0.3939459940605177,
        "distinct-3-nopunct": 0.975,
        "vocab_size-3-nopunct": 39,
        "unique-3-nopunct": 38,
        "entropy-3-nopunct": 5.271928094887364,
        "cond_entropy-3-nopunct": 0.0046106721086019795,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.304805736582064,
        "rouge1": {
            "precision": 0.47817,
            "recall": 0.61991,
            "fmeasure": 0.51449
        },
        "rouge2": {
            "precision": 0.2058,
            "recall": 0.32331,
            "fmeasure": 0.24085
        },
        "rougeL": {
            "precision": 0.26786,
            "recall": 0.42376,
            "fmeasure": 0.31476
        },
        "rougeLsum": {
            "precision": 0.26786,
            "recall": 0.42376,
            "fmeasure": 0.31476
        },
        "bleu": 11.46738,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.8,
            "3": 0.5217391304347826
        },
        "bertscore": {
            "precision": 0.85328,
            "recall": 0.90254,
            "f1": 0.87352
        },
        "nubia": {
            "semantic_relation": 3.79379,
            "contradiction": 50.08069,
            "irrelevancy": 44.689,
            "logical_agreement": 5.23031,
            "grammar_ref": 4.39403,
            "grammar_hyp": 3.54253,
            "nubia_score": 0.50096
        },
        "meteor": 0.3118532345753496,
        "bleurt": 0.2327
    },
    "totto_test_contrast_challenge_table_size-table_size_895": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 1.5,
        "median_pred_length": 11.5,
        "min_pred_length": 10,
        "max_pred_length": 13,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.03600643804015717,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9523809523809523,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.297079327540665,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.03912675144043812,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.793155897267586,
        "rouge1": {
            "precision": 0.47222,
            "recall": 0.5277,
            "fmeasure": 0.47479
        },
        "rouge2": {
            "precision": 0.21212,
            "recall": 0.29167,
            "fmeasure": 0.24561
        },
        "rougeL": {
            "precision": 0.47222,
            "recall": 0.5277,
            "fmeasure": 0.47479
        },
        "rougeLsum": {
            "precision": 0.47222,
            "recall": 0.5277,
            "fmeasure": 0.47479
        },
        "bleu": 27.07138,
        "local_recall": {
            "1": 0.23076923076923078,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.89615,
            "recall": 0.89432,
            "f1": 0.89477
        },
        "nubia": {
            "semantic_relation": 3.29193,
            "contradiction": 4.1161,
            "irrelevancy": 36.74427,
            "logical_agreement": 59.13962,
            "grammar_ref": 4.46901,
            "grammar_hyp": 4.87242,
            "nubia_score": 0.46031
        },
        "meteor": 0.2768403230188996,
        "bleurt": 0.26582
    },
    "totto_test_contrast_challenge_table_size-table_size_1015": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 3.0,
        "median_pred_length": 20.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.875,
        "vocab_size-1": 35,
        "unique-1": 31,
        "entropy-1": 5.053055907333277,
        "distinct-2": 1.0,
        "vocab_size-2": 38,
        "unique-2": 38,
        "entropy-2": 5.247927513443589,
        "cond_entropy-2": 0.12560369489099044,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": -0.0780025120012732,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 16.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 16.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9393939393939394,
        "vocab_size-1-nopunct": 31,
        "unique-1-nopunct": 29,
        "entropy-1-nopunct": 4.923181998146335,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 31,
        "entropy-2-nopunct": 4.954196310386877,
        "cond_entropy-2-nopunct": 0.03883444909293794,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 29,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.857980995127571,
        "cond_entropy-3-nopunct": -0.09621531525930291,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.250153438354546,
        "rouge1": {
            "precision": 0.51316,
            "recall": 0.47825,
            "fmeasure": 0.48283
        },
        "rouge2": {
            "precision": 0.20016,
            "recall": 0.19294,
            "fmeasure": 0.19122
        },
        "rougeL": {
            "precision": 0.36404,
            "recall": 0.33748,
            "fmeasure": 0.34098
        },
        "rougeLsum": {
            "precision": 0.36404,
            "recall": 0.33748,
            "fmeasure": 0.34098
        },
        "bleu": 13.73635,
        "local_recall": {
            "1": 0.25925925925925924,
            "2": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.87737,
            "recall": 0.86596,
            "f1": 0.86412
        },
        "nubia": {
            "semantic_relation": 3.52935,
            "contradiction": 9.38764,
            "irrelevancy": 77.72624,
            "logical_agreement": 12.88612,
            "grammar_ref": 4.87596,
            "grammar_hyp": 4.56079,
            "nubia_score": 0.53392
        },
        "meteor": 0.19466496626526272,
        "bleurt": -0.3698
    },
    "totto_test_contrast_challenge_table_size-table_size_651": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.567345697000919,
        "rouge1": {
            "precision": 0.61538,
            "recall": 1.0,
            "fmeasure": 0.7619
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.71429,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.57692,
            "recall": 0.9375,
            "fmeasure": 0.71429
        },
        "rougeLsum": {
            "precision": 0.57692,
            "recall": 0.9375,
            "fmeasure": 0.71429
        },
        "bleu": 37.59664,
        "local_recall": {
            "1": 1.0,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.86436,
            "recall": 0.96197,
            "f1": 0.91056
        },
        "nubia": {
            "semantic_relation": 3.77266,
            "contradiction": 0.39731,
            "irrelevancy": 99.22321,
            "logical_agreement": 0.37948,
            "grammar_ref": 5.1072,
            "grammar_hyp": 5.23176,
            "nubia_score": 0.4782
        },
        "meteor": 0.47249523163783624,
        "bleurt": -0.85851
    },
    "totto_test_contrast_challenge_table_size-table_size_1020": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 5.5,
        "median_pred_length": 15.5,
        "min_pred_length": 10,
        "max_pred_length": 21,
        "distinct-1": 0.8387096774193549,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.607264455478377,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.20567735722909258,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 4.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.363713275750188,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.2493097618368752,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.28400485500188,
        "rouge1": {
            "precision": 0.75926,
            "recall": 0.80708,
            "fmeasure": 0.77429
        },
        "rouge2": {
            "precision": 0.59069,
            "recall": 0.58187,
            "fmeasure": 0.56572
        },
        "rougeL": {
            "precision": 0.68519,
            "recall": 0.72283,
            "fmeasure": 0.6795
        },
        "rougeLsum": {
            "precision": 0.68519,
            "recall": 0.72283,
            "fmeasure": 0.6795
        },
        "bleu": 61.37942,
        "local_recall": {
            "1": 0.23529411764705882,
            "2": 0.7272727272727273,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.94655,
            "recall": 0.95626,
            "f1": 0.95134
        },
        "nubia": {
            "semantic_relation": 4.29347,
            "contradiction": 11.90604,
            "irrelevancy": 18.27849,
            "logical_agreement": 69.81547,
            "grammar_ref": 4.3679,
            "grammar_hyp": 3.98235,
            "nubia_score": 0.78697
        },
        "meteor": 0.42491665810423224,
        "bleurt": 0.19509
    },
    "totto_test_contrast_challenge_table_size-table_size_654": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 29,
        "mean_pred_length": 29.0,
        "std_pred_length": 0.0,
        "median_pred_length": 29.0,
        "min_pred_length": 29,
        "max_pred_length": 29,
        "distinct-1": 0.896551724137931,
        "vocab_size-1": 26,
        "unique-1": 23,
        "entropy-1": 4.651084443403434,
        "distinct-2": 1.0,
        "vocab_size-2": 28,
        "unique-2": 28,
        "entropy-2": 4.807354922057606,
        "cond_entropy-2": 0.16365964121574642,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.05246741989413545,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 25,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.643856189774723,
        "cond_entropy-2-nopunct": 0.10341647163363246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": -0.058893689053568274,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.7263436661111604,
        "rouge1": {
            "precision": 0.5303,
            "recall": 0.59298,
            "fmeasure": 0.55981
        },
        "rouge2": {
            "precision": 0.2381,
            "recall": 0.30093,
            "fmeasure": 0.26565
        },
        "rougeL": {
            "precision": 0.40909,
            "recall": 0.46579,
            "fmeasure": 0.43554
        },
        "rougeLsum": {
            "precision": 0.40909,
            "recall": 0.46579,
            "fmeasure": 0.43554
        },
        "bleu": 22.86868,
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.83312,
            "recall": 0.83277,
            "f1": 0.83294
        },
        "nubia": {
            "semantic_relation": 2.1902,
            "contradiction": 60.25565,
            "irrelevancy": 39.46539,
            "logical_agreement": 0.27896,
            "grammar_ref": 3.79365,
            "grammar_hyp": 3.21493,
            "nubia_score": 0.26155
        },
        "meteor": 0.2635503722713774,
        "bleurt": -0.72314
    },
    "totto_test_contrast_challenge_table_size-table_size_765": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.768492245572466,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.373,
            "irrelevancy": 0.51156,
            "logical_agreement": 99.11544,
            "grammar_ref": 5.07856,
            "grammar_hyp": 5.22425,
            "nubia_score": 0.9763
        },
        "meteor": 1.0,
        "bleurt": 0.97268
    },
    "totto_test_contrast_challenge_table_size-table_size_1113": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750188,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": 0.2536119717201712,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.058893689053568274,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.07223329894392083,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4892120784752443,
        "rouge1": {
            "precision": 0.94203,
            "recall": 0.67025,
            "fmeasure": 0.78307
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.57863,
            "fmeasure": 0.68297
        },
        "rougeL": {
            "precision": 0.94203,
            "recall": 0.66319,
            "fmeasure": 0.77835
        },
        "rougeLsum": {
            "precision": 0.94203,
            "recall": 0.66319,
            "fmeasure": 0.77835
        },
        "bleu": 43.62219,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.96736,
            "recall": 0.86702,
            "f1": 0.91445
        },
        "nubia": {
            "semantic_relation": 3.03656,
            "contradiction": 96.12211,
            "irrelevancy": 1.30631,
            "logical_agreement": 2.57159,
            "grammar_ref": 3.7645,
            "grammar_hyp": 3.50972,
            "nubia_score": 0.38837
        },
        "meteor": 0.3799788642865042,
        "bleurt": 0.01991
    },
    "totto_test_contrast_challenge_table_size-table_size_695": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 12.0,
        "std_pred_length": 2.0,
        "median_pred_length": 12.0,
        "min_pred_length": 10,
        "max_pred_length": 14,
        "distinct-1": 0.75,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.084962500721156,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 18,
        "unique-2": 14,
        "entropy-2": 4.095795255000932,
        "cond_entropy-2": -0.034621791174768185,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": -0.037503523749935014,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7727272727272727,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 4.004886164091841,
        "distinct-2-nopunct": 0.8,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.9219280948873623,
        "cond_entropy-2-nopunct": -0.08750352374993502,
        "distinct-3-nopunct": 0.8333333333333334,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.8365916681089787,
        "cond_entropy-3-nopunct": -0.09644753788949419,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.6530437207411035,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34259,
            "irrelevancy": 0.55688,
            "logical_agreement": 99.10053,
            "grammar_ref": 6.12532,
            "grammar_hyp": 6.14583,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.9828
    },
    "totto_test_contrast_challenge_table_size-table_size_656": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.777635134940872,
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.8125,
            "fmeasure": 0.8125
        },
        "rouge2": {
            "precision": 0.55556,
            "recall": 0.68485,
            "fmeasure": 0.61026
        },
        "rougeL": {
            "precision": 0.8125,
            "recall": 0.8125,
            "fmeasure": 0.8125
        },
        "rougeLsum": {
            "precision": 0.8125,
            "recall": 0.8125,
            "fmeasure": 0.8125
        },
        "bleu": 25.85977,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.9090909090909091
        },
        "bertscore": {
            "precision": 0.92387,
            "recall": 0.96994,
            "f1": 0.94006
        },
        "nubia": {
            "semantic_relation": 4.34045,
            "contradiction": 5.11193,
            "irrelevancy": 39.94008,
            "logical_agreement": 54.94798,
            "grammar_ref": 4.67419,
            "grammar_hyp": 4.26997,
            "nubia_score": 0.76005
        },
        "meteor": 0.46876275781550386,
        "bleurt": 0.6721
    },
    "totto_test_contrast_challenge_table_size-table_size_1122": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 8,
        "unique-1": 7,
        "entropy-1": 2.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": 0.08007499855768763,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": 0.09306920777188989,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.9989534834466038,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.51515,
            "fmeasure": 0.63902
        },
        "rouge2": {
            "precision": 0.3125,
            "recall": 0.18398,
            "fmeasure": 0.22686
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.29545,
            "fmeasure": 0.35023
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.29545,
            "fmeasure": 0.35023
        },
        "bleu": 17.06602,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.625
        },
        "bertscore": {
            "precision": 0.9352,
            "recall": 0.91458,
            "f1": 0.92478
        },
        "nubia": {
            "semantic_relation": 3.78864,
            "contradiction": 1.22689,
            "irrelevancy": 40.33739,
            "logical_agreement": 58.43571,
            "grammar_ref": 4.87259,
            "grammar_hyp": 5.76414,
            "nubia_score": 0.45836
        },
        "meteor": 0.3519526879730223,
        "bleurt": 0.03106
    },
    "totto_test_contrast_challenge_table_size-table_size_657": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 3.0,
        "median_pred_length": 22.0,
        "min_pred_length": 19,
        "max_pred_length": 25,
        "distinct-1": 0.7045454545454546,
        "vocab_size-1": 31,
        "unique-1": 19,
        "entropy-1": 4.851365993588125,
        "distinct-2": 0.8571428571428571,
        "vocab_size-2": 36,
        "unique-2": 30,
        "entropy-2": 5.106603137064476,
        "cond_entropy-2": 0.23657360181202208,
        "distinct-3": 0.925,
        "vocab_size-3": 37,
        "unique-3": 34,
        "entropy-3": 5.171928094887363,
        "cond_entropy-3": 0.079610672108602,
        "total_length-nopunct": 39,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.6923076923076923,
        "vocab_size-1-nopunct": 27,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.650661513678569,
        "distinct-2-nopunct": 0.8378378378378378,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.885129041304629,
        "cond_entropy-2-nopunct": 0.24175080898733547,
        "distinct-3-nopunct": 0.9142857142857143,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 29,
        "entropy-3-nopunct": 4.957854445516392,
        "cond_entropy-3-nopunct": 0.0912582227445881,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2846087087572484,
        "rouge1": {
            "precision": 0.83188,
            "recall": 0.69921,
            "fmeasure": 0.75474
        },
        "rouge2": {
            "precision": 0.56494,
            "recall": 0.48129,
            "fmeasure": 0.51689
        },
        "rougeL": {
            "precision": 0.73043,
            "recall": 0.62823,
            "fmeasure": 0.67226
        },
        "rougeLsum": {
            "precision": 0.73043,
            "recall": 0.62823,
            "fmeasure": 0.67226
        },
        "bleu": 41.34043,
        "local_recall": {
            "1": 0.2857142857142857,
            "2": 0.06666666666666667,
            "3": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.95674,
            "recall": 0.9268,
            "f1": 0.94146
        },
        "nubia": {
            "semantic_relation": 4.37015,
            "contradiction": 0.45825,
            "irrelevancy": 4.28281,
            "logical_agreement": 95.25894,
            "grammar_ref": 3.5955,
            "grammar_hyp": 3.78146,
            "nubia_score": 0.76518
        },
        "meteor": 0.4215434982646213,
        "bleurt": 0.38581
    },
    "totto_test_contrast_challenge_table_size-table_size_696": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 51,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.7416573867739413,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 22,
        "distinct-1": 0.8431372549019608,
        "vocab_size-1": 43,
        "unique-1": 40,
        "entropy-1": 5.235863332040315,
        "distinct-2": 1.0,
        "vocab_size-2": 48,
        "unique-2": 48,
        "entropy-2": 5.5849625007211605,
        "cond_entropy-2": 0.33471762763487767,
        "distinct-3": 1.0,
        "vocab_size-3": 45,
        "unique-3": 45,
        "entropy-3": 5.491853096329673,
        "cond_entropy-3": -0.09310940439148176,
        "total_length-nopunct": 49,
        "mean_pred_length-nopunct": 16.333333333333332,
        "std_pred_length-nopunct": 4.189935029992178,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 42,
        "unique-1-nopunct": 40,
        "entropy-1-nopunct": 5.201145303166425,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 46,
        "unique-2-nopunct": 46,
        "entropy-2-nopunct": 5.5235619560570095,
        "cond_entropy-2-nopunct": 0.349388253387248,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 43,
        "unique-3-nopunct": 43,
        "entropy-3-nopunct": 5.426264754702098,
        "cond_entropy-3-nopunct": -0.09729720135491506,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4208564394652496,
        "rouge1": {
            "precision": 0.7279,
            "recall": 0.66185,
            "fmeasure": 0.68771
        },
        "rouge2": {
            "precision": 0.5419,
            "recall": 0.50372,
            "fmeasure": 0.51868
        },
        "rougeL": {
            "precision": 0.62311,
            "recall": 0.58224,
            "fmeasure": 0.59861
        },
        "rougeLsum": {
            "precision": 0.62311,
            "recall": 0.58224,
            "fmeasure": 0.59861
        },
        "bleu": 43.32321,
        "local_recall": {
            "1": 0.08333333333333333,
            "2": 0.07692307692307693,
            "3": 0.7560975609756098
        },
        "bertscore": {
            "precision": 0.91957,
            "recall": 0.90602,
            "f1": 0.91212
        },
        "nubia": {
            "semantic_relation": 3.84404,
            "contradiction": 2.18812,
            "irrelevancy": 27.34436,
            "logical_agreement": 70.46752,
            "grammar_ref": 4.54005,
            "grammar_hyp": 4.62037,
            "nubia_score": 0.62031
        },
        "meteor": 0.3699298641783358,
        "bleurt": -0.00121
    },
    "totto_test_contrast_challenge_table_size-table_size_700": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 7.5,
        "std_pred_length": 1.5,
        "median_pred_length": 7.5,
        "min_pred_length": 6,
        "max_pred_length": 9,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.2064508774674265,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.24100809950379498,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 5.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 5.5,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.2895066171949847,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.36257007938470837,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0842627482246168,
        "rouge1": {
            "precision": 0.52778,
            "recall": 0.50556,
            "fmeasure": 0.51389
        },
        "rouge2": {
            "precision": 0.43333,
            "recall": 0.43333,
            "fmeasure": 0.43333
        },
        "rougeL": {
            "precision": 0.52778,
            "recall": 0.50556,
            "fmeasure": 0.51389
        },
        "rougeLsum": {
            "precision": 0.52778,
            "recall": 0.50556,
            "fmeasure": 0.51389
        },
        "bleu": 57.89081,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.45454545454545453
        },
        "bertscore": {
            "precision": 0.88292,
            "recall": 0.86521,
            "f1": 0.87385
        },
        "nubia": {
            "semantic_relation": 3.32285,
            "contradiction": 34.46778,
            "irrelevancy": 14.53397,
            "logical_agreement": 50.99825,
            "grammar_ref": 5.35128,
            "grammar_hyp": 6.00233,
            "nubia_score": 0.50991
        },
        "meteor": 0.33290245060948126,
        "bleurt": 0.03743
    },
    "totto_test_contrast_challenge_table_size-table_size_1194": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9422077838189056,
        "rouge1": {
            "precision": 0.58974,
            "recall": 0.76667,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.47222,
            "recall": 0.62963,
            "fmeasure": 0.53968
        },
        "rougeL": {
            "precision": 0.58974,
            "recall": 0.76667,
            "fmeasure": 0.66667
        },
        "rougeLsum": {
            "precision": 0.58974,
            "recall": 0.76667,
            "fmeasure": 0.66667
        },
        "bleu": 46.04629,
        "local_recall": {
            "1": 1.0,
            "2": 0.5,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.93659,
            "recall": 0.96101,
            "f1": 0.94864
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32197,
            "irrelevancy": 0.43441,
            "logical_agreement": 99.24362,
            "grammar_ref": 4.16465,
            "grammar_hyp": 3.40041,
            "nubia_score": 0.94248
        },
        "meteor": 0.4392315476523066,
        "bleurt": 0.72347
    },
    "totto_test_contrast_challenge_table_size-table_size_1022": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6602052017991762,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.66667,
            "fmeasure": 0.52174
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.28571,
            "recall": 0.44444,
            "fmeasure": 0.34783
        },
        "rougeLsum": {
            "precision": 0.28571,
            "recall": 0.44444,
            "fmeasure": 0.34783
        },
        "bleu": 7.18896,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.8602,
            "recall": 0.88677,
            "f1": 0.87222
        },
        "nubia": {
            "semantic_relation": 3.38553,
            "contradiction": 3.44806,
            "irrelevancy": 95.66821,
            "logical_agreement": 0.88372,
            "grammar_ref": 5.49813,
            "grammar_hyp": 6.41202,
            "nubia_score": 0.31338
        },
        "meteor": 0.20099097687447257,
        "bleurt": 0.08871
    },
    "totto_test_contrast_challenge_table_size-table_size_770": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8421052631578947,
        "vocab_size-1": 16,
        "unique-1": 13,
        "entropy-1": 3.9321380397593733,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.14421971022094907,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": 0.03518489863155644,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8365916681089787,
        "distinct-2-nopunct": 0.9411764705882353,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.969815782426811,
        "cond_entropy-2-nopunct": 0.09400842804332114,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.02496284125033941,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.056042779423138,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.5693,
            "fmeasure": 0.58938
        },
        "rouge2": {
            "precision": 0.27451,
            "recall": 0.25536,
            "fmeasure": 0.26455
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.48421,
            "fmeasure": 0.50071
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.48421,
            "fmeasure": 0.50071
        },
        "bleu": 15.31651,
        "local_recall": {
            "1": 0.1,
            "2": 0.25,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.87534,
            "recall": 0.87719,
            "f1": 0.87626
        },
        "nubia": {
            "semantic_relation": 4.07351,
            "contradiction": 0.46424,
            "irrelevancy": 2.12178,
            "logical_agreement": 97.41398,
            "grammar_ref": 5.26752,
            "grammar_hyp": 5.07219,
            "nubia_score": 0.67625
        },
        "meteor": 0.2867738313288682,
        "bleurt": -0.21312
    },
    "totto_test_contrast_challenge_table_size-table_size_931": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 20,
        "entropy-1": 4.316827716832514,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.15200091267862392,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 20.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.321928094887363,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": -0.07400058144377676,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.169925001442312,
        "cond_entropy-3-nopunct": -0.07800251200127316,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1565812505658084,
        "rouge1": {
            "precision": 0.2,
            "recall": 0.34231,
            "fmeasure": 0.25152
        },
        "rouge2": {
            "precision": 0.02632,
            "recall": 0.04167,
            "fmeasure": 0.03226
        },
        "rougeL": {
            "precision": 0.15,
            "recall": 0.25385,
            "fmeasure": 0.18788
        },
        "rougeLsum": {
            "precision": 0.15,
            "recall": 0.25385,
            "fmeasure": 0.18788
        },
        "bleu": 4.33426,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "bertscore": {
            "precision": 0.72637,
            "recall": 0.72589,
            "f1": 0.72613
        },
        "nubia": {
            "semantic_relation": 1.43452,
            "contradiction": 2.31454,
            "irrelevancy": 97.14458,
            "logical_agreement": 0.54088,
            "grammar_ref": 4.19915,
            "grammar_hyp": 5.33946,
            "nubia_score": 0.07799
        },
        "meteor": 0.14364494088556143,
        "bleurt": -1.2823
    },
    "totto_test_contrast_challenge_table_size-table_size_1206": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 21.0,
        "std_pred_length": 1.0,
        "median_pred_length": 21.0,
        "min_pred_length": 20,
        "max_pred_length": 22,
        "distinct-1": 0.8095238095238095,
        "vocab_size-1": 34,
        "unique-1": 29,
        "entropy-1": 4.94577248225106,
        "distinct-2": 0.975,
        "vocab_size-2": 39,
        "unique-2": 38,
        "entropy-2": 5.271928094887364,
        "cond_entropy-2": 0.3484828596626887,
        "distinct-3": 1.0,
        "vocab_size-3": 38,
        "unique-3": 38,
        "entropy-3": 5.247927513443589,
        "cond_entropy-3": -0.021369002496408343,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 18.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 18.5,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7837837837837838,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.702564514219128,
        "distinct-2-nopunct": 0.9714285714285714,
        "vocab_size-2-nopunct": 34,
        "unique-2-nopunct": 33,
        "entropy-2-nopunct": 5.072140159802107,
        "cond_entropy-2-nopunct": 0.3985407228064017,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 33,
        "unique-3-nopunct": 33,
        "entropy-3-nopunct": 5.044394119358456,
        "cond_entropy-3-nopunct": -0.02428283698045265,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9266761191514936,
        "rouge1": {
            "precision": 0.7076,
            "recall": 0.72831,
            "fmeasure": 0.71294
        },
        "rouge2": {
            "precision": 0.52037,
            "recall": 0.51661,
            "fmeasure": 0.51233
        },
        "rougeL": {
            "precision": 0.65915,
            "recall": 0.68466,
            "fmeasure": 0.66765
        },
        "rougeLsum": {
            "precision": 0.65915,
            "recall": 0.68466,
            "fmeasure": 0.66765
        },
        "bleu": 38.60974,
        "local_recall": {
            "1": 0.0,
            "2": 0.5714285714285714,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.89916,
            "recall": 0.89891,
            "f1": 0.8936
        },
        "nubia": {
            "semantic_relation": 4.42607,
            "contradiction": 2.32198,
            "irrelevancy": 34.12903,
            "logical_agreement": 63.54899,
            "grammar_ref": 4.16263,
            "grammar_hyp": 4.19477,
            "nubia_score": 0.77417
        },
        "meteor": 0.3198158529254455,
        "bleurt": -0.00688
    },
    "totto_test_contrast_challenge_table_size-table_size_1128": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4699874668497483,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.37143,
            "fmeasure": 0.41111
        },
        "rouge2": {
            "precision": 0.11111,
            "recall": 0.08625,
            "fmeasure": 0.09697
        },
        "rougeL": {
            "precision": 0.36667,
            "recall": 0.29048,
            "fmeasure": 0.32222
        },
        "rougeLsum": {
            "precision": 0.36667,
            "recall": 0.29048,
            "fmeasure": 0.32222
        },
        "bleu": 8.18219,
        "local_recall": {
            "1": 0.0,
            "2": 0.36363636363636365,
            "3": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.85919,
            "recall": 0.83746,
            "f1": 0.84503
        },
        "nubia": {
            "semantic_relation": 2.86363,
            "contradiction": 64.91939,
            "irrelevancy": 15.15832,
            "logical_agreement": 19.9223,
            "grammar_ref": 4.72922,
            "grammar_hyp": 4.16972,
            "nubia_score": 0.33303
        },
        "meteor": 0.20162027801914273,
        "bleurt": -0.00084
    },
    "totto_test_contrast_challenge_table_size-table_size_702": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.3648189689631285,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.84175,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.39167,
            "fmeasure": 0.34242
        },
        "rougeL": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.4359,
            "recall": 0.54882,
            "fmeasure": 0.48485
        },
        "bleu": 10.88697,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.86868,
            "recall": 0.91473,
            "f1": 0.89111
        },
        "nubia": {
            "semantic_relation": 4.07833,
            "contradiction": 3.27619,
            "irrelevancy": 90.91923,
            "logical_agreement": 5.80458,
            "grammar_ref": 6.0554,
            "grammar_hyp": 5.9572,
            "nubia_score": 0.5147
        },
        "meteor": 0.37885739133291024,
        "bleurt": -0.504
    },
    "totto_test_contrast_challenge_table_size-table_size_1032": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0877627602658655,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.54545,
            "fmeasure": 0.57143
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.3,
            "fmeasure": 0.31579
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.36364,
            "fmeasure": 0.38095
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.36364,
            "fmeasure": 0.38095
        },
        "bleu": 23.46235,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.83615,
            "recall": 0.83891,
            "f1": 0.83082
        },
        "nubia": {
            "semantic_relation": 2.69442,
            "contradiction": 94.85539,
            "irrelevancy": 3.49065,
            "logical_agreement": 1.65396,
            "grammar_ref": 4.59968,
            "grammar_hyp": 4.66606,
            "nubia_score": 0.24931
        },
        "meteor": 0.2674224366953142,
        "bleurt": -0.36271
    },
    "totto_test_contrast_challenge_table_size-table_size_896": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 8,
        "msttr-100": 0.56,
        "msttr-100_nopunct": 0.61,
        "total_length": 120,
        "mean_pred_length": 15.0,
        "std_pred_length": 3.5,
        "median_pred_length": 15.0,
        "min_pred_length": 7,
        "max_pred_length": 19,
        "distinct-1": 0.575,
        "vocab_size-1": 69,
        "unique-1": 46,
        "entropy-1": 5.717866109874354,
        "distinct-2": 0.8035714285714286,
        "vocab_size-2": 90,
        "unique-2": 71,
        "entropy-2": 6.389900569359706,
        "cond_entropy-2": 0.5426790656092418,
        "distinct-3": 0.8653846153846154,
        "vocab_size-3": 90,
        "unique-3": 77,
        "entropy-3": 6.423950415235682,
        "cond_entropy-3": 0.04693094992964165,
        "total_length-nopunct": 109,
        "mean_pred_length-nopunct": 13.625,
        "std_pred_length-nopunct": 3.276335605520289,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.5963302752293578,
        "vocab_size-1-nopunct": 65,
        "unique-1-nopunct": 43,
        "entropy-1-nopunct": 5.679350028555812,
        "distinct-2-nopunct": 0.7920792079207921,
        "vocab_size-2-nopunct": 80,
        "unique-2-nopunct": 62,
        "entropy-2-nopunct": 6.215093784710558,
        "cond_entropy-2-nopunct": 0.5724831063504866,
        "distinct-3-nopunct": 0.8494623655913979,
        "vocab_size-3-nopunct": 79,
        "unique-3-nopunct": 66,
        "entropy-3-nopunct": 6.229966472375096,
        "cond_entropy-3-nopunct": 0.020732274592795592,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.489657077461324,
        "rouge1": {
            "precision": 0.73743,
            "recall": 0.63482,
            "fmeasure": 0.66201
        },
        "rouge2": {
            "precision": 0.53797,
            "recall": 0.48041,
            "fmeasure": 0.49335
        },
        "rougeL": {
            "precision": 0.64304,
            "recall": 0.56591,
            "fmeasure": 0.58448
        },
        "rougeLsum": {
            "precision": 0.64304,
            "recall": 0.56591,
            "fmeasure": 0.58448
        },
        "bleu": 46.13867,
        "local_recall": {
            "1": 0.38461538461538464,
            "2": 0.6216216216216216,
            "3": 0.6438356164383562
        },
        "bertscore": {
            "precision": 0.90965,
            "recall": 0.87967,
            "f1": 0.89256
        },
        "nubia": {
            "semantic_relation": 3.60946,
            "contradiction": 33.01595,
            "irrelevancy": 26.14905,
            "logical_agreement": 40.835,
            "grammar_ref": 4.28101,
            "grammar_hyp": 4.19567,
            "nubia_score": 0.54407
        },
        "meteor": 0.3385439565554093,
        "bleurt": 0.0254
    },
    "totto_test_contrast_challenge_table_size-table_size_1135": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.84,
        "vocab_size-1": 21,
        "unique-1": 18,
        "entropy-1": 4.293660689688184,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.30589329020324296,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.061400544664143256,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.220175521464345,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.523561956057013,
        "cond_entropy-2-nopunct": 0.31924673803861614,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.06413033741971555,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.519927908537216,
        "rouge1": {
            "precision": 0.56944,
            "recall": 0.76206,
            "fmeasure": 0.65078
        },
        "rouge2": {
            "precision": 0.27536,
            "recall": 0.37037,
            "fmeasure": 0.31536
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.59211,
            "fmeasure": 0.48837
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.59211,
            "fmeasure": 0.48837
        },
        "bleu": 16.97363,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.8814,
            "recall": 0.88912,
            "f1": 0.87572
        },
        "nubia": {
            "semantic_relation": 4.23847,
            "contradiction": 0.08962,
            "irrelevancy": 0.648,
            "logical_agreement": 99.26238,
            "grammar_ref": 5.46955,
            "grammar_hyp": 4.37212,
            "nubia_score": 0.83727
        },
        "meteor": 0.3510669134006223,
        "bleurt": 0.21775
    },
    "totto_test_contrast_challenge_table_size-table_size_705": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8783382238532793,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.6337,
            "fmeasure": 0.64957
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.32479,
            "fmeasure": 0.32889
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.52564,
            "fmeasure": 0.53181
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.52564,
            "fmeasure": 0.53181
        },
        "bleu": 17.99653,
        "local_recall": {
            "1": 0.25,
            "2": 0.3333333333333333,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.92021,
            "recall": 0.90935,
            "f1": 0.91474
        },
        "nubia": {
            "semantic_relation": 4.1074,
            "contradiction": 0.36318,
            "irrelevancy": 94.50418,
            "logical_agreement": 5.13264,
            "grammar_ref": 5.35534,
            "grammar_hyp": 4.93654,
            "nubia_score": 0.69839
        },
        "meteor": 0.3155960258007732,
        "bleurt": 0.08083
    },
    "totto_test_contrast_challenge_table_size-table_size_1210": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.092460335968241,
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.66826,
            "fmeasure": 0.7018
        },
        "rouge2": {
            "precision": 0.64706,
            "recall": 0.58201,
            "fmeasure": 0.61203
        },
        "rougeL": {
            "precision": 0.64815,
            "recall": 0.54705,
            "fmeasure": 0.59279
        },
        "rougeLsum": {
            "precision": 0.64815,
            "recall": 0.54705,
            "fmeasure": 0.59279
        },
        "bleu": 56.45815,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.96601,
            "recall": 0.94603,
            "f1": 0.95591
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 5.41004,
            "irrelevancy": 5.96227,
            "logical_agreement": 88.6277,
            "grammar_ref": 3.4928,
            "grammar_hyp": 3.73226,
            "nubia_score": 0.97125
        },
        "meteor": 0.5058232983087838,
        "bleurt": 0.59631
    },
    "totto_test_contrast_challenge_table_size-table_size_1216": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1208060405775977,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.43826,
            "fmeasure": 0.52866
        },
        "rouge2": {
            "precision": 0.31111,
            "recall": 0.19949,
            "fmeasure": 0.24301
        },
        "rougeL": {
            "precision": 0.47917,
            "recall": 0.31478,
            "fmeasure": 0.37982
        },
        "rougeLsum": {
            "precision": 0.47917,
            "recall": 0.31478,
            "fmeasure": 0.37982
        },
        "bleu": 15.09039,
        "local_recall": {
            "1": 0.0,
            "2": 0.5454545454545454,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.92193,
            "recall": 0.87294,
            "f1": 0.89677
        },
        "nubia": {
            "semantic_relation": 3.36192,
            "contradiction": 9.06558,
            "irrelevancy": 47.74007,
            "logical_agreement": 43.19434,
            "grammar_ref": 3.96534,
            "grammar_hyp": 3.67067,
            "nubia_score": 0.49075
        },
        "meteor": 0.2673734848966146,
        "bleurt": -0.17591
    },
    "totto_test_contrast_challenge_table_size-table_size_1140": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.23331430181648,
        "rouge1": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rouge2": {
            "precision": 0.91667,
            "recall": 0.88462,
            "fmeasure": 0.9
        },
        "rougeL": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "rougeLsum": {
            "precision": 0.96154,
            "recall": 0.92857,
            "fmeasure": 0.94444
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 3.77055,
            "contradiction": 48.79365,
            "irrelevancy": 1.17603,
            "logical_agreement": 50.03032,
            "grammar_ref": 2.33019,
            "grammar_hyp": 2.40036,
            "nubia_score": 0.71443
        },
        "meteor": 1.0,
        "bleurt": 0.56405
    },
    "totto_test_contrast_challenge_table_size-table_size_707": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.090634124990776,
        "rouge1": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rouge2": {
            "precision": 0.78788,
            "recall": 0.8963,
            "fmeasure": 0.8381
        },
        "rougeL": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "rougeLsum": {
            "precision": 0.88889,
            "recall": 1.0,
            "fmeasure": 0.94071
        },
        "bleu": 76.11606,
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98299,
            "recall": 0.99732,
            "f1": 0.9901
        },
        "nubia": {
            "semantic_relation": 4.3761,
            "contradiction": 0.09394,
            "irrelevancy": 99.63689,
            "logical_agreement": 0.26917,
            "grammar_ref": 5.85321,
            "grammar_hyp": 5.83654,
            "nubia_score": 0.79202
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.48581
    },
    "totto_test_contrast_challenge_table_size-table_size_774": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 7.0,
        "median_pred_length": 18.0,
        "min_pred_length": 11,
        "max_pred_length": 25,
        "distinct-1": 0.8611111111111112,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.871178126382214,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.2338580604598937,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 7.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8529411764705882,
        "vocab_size-1-nopunct": 29,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.7711426205984715,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 32,
        "unique-2-nopunct": 32,
        "entropy-2-nopunct": 5.0,
        "cond_entropy-2-nopunct": 0.248627393192269,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 30,
        "entropy-3-nopunct": 4.906890595608519,
        "cond_entropy-3-nopunct": -0.09310940439148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.709360274464146,
        "rouge1": {
            "precision": 0.67639,
            "recall": 0.7133,
            "fmeasure": 0.69397
        },
        "rouge2": {
            "precision": 0.40902,
            "recall": 0.42956,
            "fmeasure": 0.41875
        },
        "rougeL": {
            "precision": 0.48889,
            "recall": 0.52744,
            "fmeasure": 0.50721
        },
        "rougeLsum": {
            "precision": 0.48889,
            "recall": 0.52744,
            "fmeasure": 0.50721
        },
        "bleu": 27.29201,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.6,
            "3": 0.64
        },
        "bertscore": {
            "precision": 0.85774,
            "recall": 0.88578,
            "f1": 0.86858
        },
        "nubia": {
            "semantic_relation": 4.29554,
            "contradiction": 0.21946,
            "irrelevancy": 44.95695,
            "logical_agreement": 54.82359,
            "grammar_ref": 4.18803,
            "grammar_hyp": 4.14728,
            "nubia_score": 0.77559
        },
        "meteor": 0.30837292577296677,
        "bleurt": -0.00033
    },
    "totto_test_contrast_challenge_table_size-table_size_1036": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393865,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.3891951714906563,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.67576,
            "fmeasure": 0.69697
        },
        "rouge2": {
            "precision": 0.38889,
            "recall": 0.37143,
            "fmeasure": 0.37488
        },
        "rougeL": {
            "precision": 0.53333,
            "recall": 0.51044,
            "fmeasure": 0.51689
        },
        "rougeLsum": {
            "precision": 0.53333,
            "recall": 0.51044,
            "fmeasure": 0.51689
        },
        "bleu": 28.08705,
        "local_recall": {
            "1": 0.5,
            "2": 0.14285714285714285,
            "3": 0.631578947368421
        },
        "bertscore": {
            "precision": 0.90522,
            "recall": 0.88607,
            "f1": 0.89479
        },
        "nubia": {
            "semantic_relation": 3.96704,
            "contradiction": 0.54862,
            "irrelevancy": 11.31473,
            "logical_agreement": 88.13666,
            "grammar_ref": 4.70186,
            "grammar_hyp": 4.94537,
            "nubia_score": 0.63123
        },
        "meteor": 0.32589790725758244,
        "bleurt": 0.29102
    },
    "totto_test_contrast_challenge_table_size-table_size_1441": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 59,
        "mean_pred_length": 19.666666666666668,
        "std_pred_length": 2.494438257849294,
        "median_pred_length": 19.0,
        "min_pred_length": 17,
        "max_pred_length": 23,
        "distinct-1": 0.6610169491525424,
        "vocab_size-1": 39,
        "unique-1": 27,
        "entropy-1": 5.051803218706688,
        "distinct-2": 0.875,
        "vocab_size-2": 49,
        "unique-2": 42,
        "entropy-2": 5.557354922057608,
        "cond_entropy-2": 0.465152274597377,
        "distinct-3": 0.9433962264150944,
        "vocab_size-3": 50,
        "unique-3": 47,
        "entropy-3": 5.614712907393384,
        "cond_entropy-3": 0.07150892873201009,
        "total_length-nopunct": 54,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 2.943920288775949,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 25,
        "entropy-1-nopunct": 4.935171529821054,
        "distinct-2-nopunct": 0.8627450980392157,
        "vocab_size-2-nopunct": 44,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.39791553804993,
        "cond_entropy-2-nopunct": 0.46027705560742393,
        "distinct-3-nopunct": 0.9375,
        "vocab_size-3-nopunct": 45,
        "unique-3-nopunct": 42,
        "entropy-3-nopunct": 5.4599625007211605,
        "cond_entropy-3-nopunct": 0.058370492082993976,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4687879117451144,
        "rouge1": {
            "precision": 0.59334,
            "recall": 0.68516,
            "fmeasure": 0.62849
        },
        "rouge2": {
            "precision": 0.43154,
            "recall": 0.48716,
            "fmeasure": 0.45198
        },
        "rougeL": {
            "precision": 0.53816,
            "recall": 0.61487,
            "fmeasure": 0.56721
        },
        "rougeLsum": {
            "precision": 0.53816,
            "recall": 0.61487,
            "fmeasure": 0.56721
        },
        "bleu": 36.43897,
        "local_recall": {
            "1": 0.45,
            "2": 0.5,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.89956,
            "recall": 0.90326,
            "f1": 0.89836
        },
        "nubia": {
            "semantic_relation": 4.11862,
            "contradiction": 1.18587,
            "irrelevancy": 69.73815,
            "logical_agreement": 29.07598,
            "grammar_ref": 4.27064,
            "grammar_hyp": 4.5336,
            "nubia_score": 0.66399
        },
        "meteor": 0.4098584016958064,
        "bleurt": -0.21769
    },
    "totto_test_contrast_challenge_table_size-table_size_1773": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 0.9166666666666666,
        "vocab_size-1": 11,
        "unique-1": 10,
        "entropy-1": 3.418295834054489,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.03462179117476822,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3593609677607044,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.58333,
            "fmeasure": 0.42222
        },
        "rouge2": {
            "precision": 0.09091,
            "recall": 0.2,
            "fmeasure": 0.125
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.375,
            "fmeasure": 0.26667
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.375,
            "fmeasure": 0.26667
        },
        "bleu": 16.94357,
        "local_recall": {
            "1": 0.0,
            "2": 0.8
        },
        "bertscore": {
            "precision": 0.69423,
            "recall": 0.81247,
            "f1": 0.74871
        },
        "nubia": {
            "semantic_relation": 2.73945,
            "contradiction": 21.09372,
            "irrelevancy": 78.39167,
            "logical_agreement": 0.51461,
            "grammar_ref": 7.18676,
            "grammar_hyp": 5.61787,
            "nubia_score": 0.2903
        },
        "meteor": 0.21148658206002868,
        "bleurt": -0.84091
    },
    "totto_test_contrast_challenge_table_size-table_size_1043": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 16,
        "unique-2": 15,
        "entropy-2": 3.969815782426811,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": 0.03753715874966059,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.773557262275185,
        "cond_entropy-2-nopunct": -0.02644273772481478,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.02810710212234294,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9473989521353194,
        "rouge1": {
            "precision": 0.35294,
            "recall": 0.5303,
            "fmeasure": 0.42365
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.33766,
            "fmeasure": 0.28642
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.46667,
            "fmeasure": 0.40086
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.46667,
            "fmeasure": 0.40086
        },
        "bleu": 27.40863,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.74678,
            "recall": 0.80317,
            "f1": 0.76974
        },
        "nubia": {
            "semantic_relation": 2.96346,
            "contradiction": 1.46111,
            "irrelevancy": 96.80283,
            "logical_agreement": 1.73606,
            "grammar_ref": 5.20931,
            "grammar_hyp": 4.62654,
            "nubia_score": 0.40715
        },
        "meteor": 0.25762360922227817,
        "bleurt": -0.687
    },
    "totto_test_contrast_challenge_table_size-table_size_1446": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 13,
        "entropy-1": 3.8521687236032816,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.16253715874966052,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.1714647646529177,
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.93333,
            "fmeasure": 0.74242
        },
        "rouge2": {
            "precision": 0.53846,
            "recall": 0.92593,
            "fmeasure": 0.67879
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.93333,
            "fmeasure": 0.70707
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.93333,
            "fmeasure": 0.70707
        },
        "bleu": 22.04887,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.87932,
            "recall": 0.94547,
            "f1": 0.88408
        },
        "nubia": {
            "semantic_relation": 3.94633,
            "contradiction": 0.12271,
            "irrelevancy": 98.91227,
            "logical_agreement": 0.96502,
            "grammar_ref": 3.90726,
            "grammar_hyp": 2.75176,
            "nubia_score": 0.8236
        },
        "meteor": 0.5576032645578614,
        "bleurt": 0.21729
    },
    "totto_test_contrast_challenge_table_size-table_size_1141": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5708514565692293,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.57071,
            "fmeasure": 0.61472
        },
        "rouge2": {
            "precision": 0.25926,
            "recall": 0.21515,
            "fmeasure": 0.23509
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.44192,
            "fmeasure": 0.46898
        },
        "bleu": 23.02104,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.92577,
            "recall": 0.9082,
            "f1": 0.91649
        },
        "nubia": {
            "semantic_relation": 4.75868,
            "contradiction": 0.67843,
            "irrelevancy": 47.31477,
            "logical_agreement": 52.0068,
            "grammar_ref": 4.53537,
            "grammar_hyp": 4.55186,
            "nubia_score": 0.89352
        },
        "meteor": 0.2904516730189926,
        "bleurt": 0.30229
    },
    "totto_test_contrast_challenge_table_size-table_size_1152": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6609640474436813,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.25,
            "fmeasure": 0.23529
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.44444,
            "fmeasure": 0.42105
        },
        "bleu": 12.54931,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.87812,
            "recall": 0.89982,
            "f1": 0.88884
        },
        "nubia": {
            "semantic_relation": 4.54442,
            "contradiction": 0.20734,
            "irrelevancy": 93.12515,
            "logical_agreement": 6.66752,
            "grammar_ref": 3.99081,
            "grammar_hyp": 3.01283,
            "nubia_score": 0.99397
        },
        "meteor": 0.2737256369746567,
        "bleurt": 0.30322
    },
    "totto_test_contrast_challenge_table_size-table_size_1260": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 28,
        "mean_pred_length": 14.0,
        "std_pred_length": 3.0,
        "median_pred_length": 14.0,
        "min_pred_length": 11,
        "max_pred_length": 17,
        "distinct-1": 0.8928571428571429,
        "vocab_size-1": 25,
        "unique-1": 22,
        "entropy-1": 4.593069207771892,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": -0.11547721741993584,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.546593564294937,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 24,
        "entropy-2-nopunct": 4.584962500721156,
        "cond_entropy-2-nopunct": 0.051189449246730766,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2282103937255753,
        "rouge1": {
            "precision": 0.85098,
            "recall": 0.50803,
            "fmeasure": 0.61731
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.33811,
            "fmeasure": 0.40306
        },
        "rougeL": {
            "precision": 0.75098,
            "recall": 0.50019,
            "fmeasure": 0.59139
        },
        "rougeLsum": {
            "precision": 0.75098,
            "recall": 0.50019,
            "fmeasure": 0.59139
        },
        "bleu": 36.18899,
        "local_recall": {
            "1": 0.0,
            "2": 0.29411764705882354,
            "3": 0.6071428571428571
        },
        "bertscore": {
            "precision": 0.95077,
            "recall": 0.90398,
            "f1": 0.92101
        },
        "nubia": {
            "semantic_relation": 3.9751,
            "contradiction": 49.8509,
            "irrelevancy": 0.91289,
            "logical_agreement": 49.23621,
            "grammar_ref": 3.63495,
            "grammar_hyp": 4.29958,
            "nubia_score": 0.60357
        },
        "meteor": 0.30593999383504716,
        "bleurt": 0.23103
    },
    "totto_test_contrast_challenge_table_size-table_size_1782": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5822711379709873,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.58021,
            "fmeasure": 0.64527
        },
        "rouge2": {
            "precision": 0.53571,
            "recall": 0.42411,
            "fmeasure": 0.47143
        },
        "rougeL": {
            "precision": 0.56667,
            "recall": 0.46658,
            "fmeasure": 0.51014
        },
        "rougeLsum": {
            "precision": 0.56667,
            "recall": 0.46658,
            "fmeasure": 0.51014
        },
        "bleu": 26.30533,
        "local_recall": {
            "1": 0.17647058823529413,
            "2": 0.6
        },
        "bertscore": {
            "precision": 0.90608,
            "recall": 0.88646,
            "f1": 0.89616
        },
        "nubia": {
            "semantic_relation": 3.26055,
            "contradiction": 1.11153,
            "irrelevancy": 87.47533,
            "logical_agreement": 11.41314,
            "grammar_ref": 3.66593,
            "grammar_hyp": 3.68086,
            "nubia_score": 0.48338
        },
        "meteor": 0.4263722956010133,
        "bleurt": -0.56827
    },
    "totto_test_contrast_challenge_table_size-table_size_900": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 2.0,
        "median_pred_length": 11.0,
        "min_pred_length": 9,
        "max_pred_length": 13,
        "distinct-1": 0.8636363636363636,
        "vocab_size-1": 19,
        "unique-1": 16,
        "entropy-1": 4.186704345910023,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 2.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.1219280948873624,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9916727451441534,
        "rouge1": {
            "precision": 0.86111,
            "recall": 0.8661,
            "fmeasure": 0.86187
        },
        "rouge2": {
            "precision": 0.73864,
            "recall": 0.74405,
            "fmeasure": 0.73949
        },
        "rougeL": {
            "precision": 0.86111,
            "recall": 0.8661,
            "fmeasure": 0.86187
        },
        "rougeLsum": {
            "precision": 0.86111,
            "recall": 0.8661,
            "fmeasure": 0.86187
        },
        "bleu": 58.90353,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0,
            "3": 0.8421052631578947
        },
        "bertscore": {
            "precision": 0.96334,
            "recall": 0.94778,
            "f1": 0.95271
        },
        "nubia": {
            "semantic_relation": 4.25204,
            "contradiction": 1.28981,
            "irrelevancy": 34.38178,
            "logical_agreement": 64.32841,
            "grammar_ref": 5.10267,
            "grammar_hyp": 5.61154,
            "nubia_score": 0.70633
        },
        "meteor": 0.4884245068131174,
        "bleurt": 0.40912
    },
    "totto_test_contrast_challenge_table_size-table_size_1470": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 41,
        "mean_pred_length": 10.25,
        "std_pred_length": 5.261891294962297,
        "median_pred_length": 8.5,
        "min_pred_length": 5,
        "max_pred_length": 19,
        "distinct-1": 0.7317073170731707,
        "vocab_size-1": 30,
        "unique-1": 22,
        "entropy-1": 4.7329266271927946,
        "distinct-2": 0.9459459459459459,
        "vocab_size-2": 35,
        "unique-2": 33,
        "entropy-2": 5.101345257520846,
        "cond_entropy-2": 0.1849264446564703,
        "distinct-3": 0.9696969696969697,
        "vocab_size-3": 32,
        "unique-3": 31,
        "entropy-3": 4.9837880587523955,
        "cond_entropy-3": -0.10445318566443551,
        "total_length-nopunct": 34,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 4.031128874149275,
        "median_pred_length-nopunct": 7.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.73452166477975,
        "distinct-2-nopunct": 0.9333333333333333,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.773557262275185,
        "cond_entropy-2-nopunct": 0.05276108769151251,
        "distinct-3-nopunct": 0.9615384615384616,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.623516641218013,
        "cond_entropy-3-nopunct": -0.12952780054434954,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.6159020467556502,
        "rouge1": {
            "precision": 0.66438,
            "recall": 0.40979,
            "fmeasure": 0.47621
        },
        "rouge2": {
            "precision": 0.34524,
            "recall": 0.22211,
            "fmeasure": 0.2505
        },
        "rougeL": {
            "precision": 0.58313,
            "recall": 0.34372,
            "fmeasure": 0.40662
        },
        "rougeLsum": {
            "precision": 0.58313,
            "recall": 0.34372,
            "fmeasure": 0.40662
        },
        "bleu": 13.79024,
        "local_recall": {
            "1": 0.05,
            "2": 0.18518518518518517,
            "3": 0.4482758620689655
        },
        "bertscore": {
            "precision": 0.89198,
            "recall": 0.83372,
            "f1": 0.85912
        },
        "nubia": {
            "semantic_relation": 3.9713,
            "contradiction": 0.72528,
            "irrelevancy": 10.50915,
            "logical_agreement": 88.76557,
            "grammar_ref": 5.44243,
            "grammar_hyp": 6.61396,
            "nubia_score": 0.53971
        },
        "meteor": 0.18492938117745056,
        "bleurt": -0.15756
    },
    "totto_test_contrast_challenge_table_size-table_size_1788": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.171275104503226,
        "rouge1": {
            "precision": 0.64286,
            "recall": 0.52941,
            "fmeasure": 0.58065
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.25,
            "fmeasure": 0.27586
        },
        "rougeL": {
            "precision": 0.64286,
            "recall": 0.52941,
            "fmeasure": 0.58065
        },
        "rougeLsum": {
            "precision": 0.64286,
            "recall": 0.52941,
            "fmeasure": 0.58065
        },
        "bleu": 19.92393,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.94283,
            "recall": 0.89652,
            "f1": 0.91909
        },
        "nubia": {
            "semantic_relation": 3.68935,
            "contradiction": 0.25824,
            "irrelevancy": 6.23956,
            "logical_agreement": 93.5022,
            "grammar_ref": 4.8802,
            "grammar_hyp": 5.62738,
            "nubia_score": 0.49909
        },
        "meteor": 0.3245919174496938,
        "bleurt": 0.4298
    },
    "totto_test_contrast_challenge_table_size-table_size_1272": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518528,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.914598155193438,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.39732,
            "fmeasure": 0.4119
        },
        "rouge2": {
            "precision": 0.26923,
            "recall": 0.24359,
            "fmeasure": 0.25549
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.39732,
            "fmeasure": 0.4119
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.39732,
            "fmeasure": 0.4119
        },
        "bleu": 9.10353,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.375
        },
        "bertscore": {
            "precision": 0.91149,
            "recall": 0.91002,
            "f1": 0.91076
        },
        "nubia": {
            "semantic_relation": 4.87324,
            "contradiction": 0.0792,
            "irrelevancy": 1.61493,
            "logical_agreement": 98.30587,
            "grammar_ref": 3.06207,
            "grammar_hyp": 3.26229,
            "nubia_score": 0.97995
        },
        "meteor": 0.3167777678320534,
        "bleurt": 0.44469
    },
    "totto_test_contrast_challenge_table_size-table_size_1503": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 17,
        "entropy-1": 4.201841232302569,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.129610672108602,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6764674813571263,
        "rouge1": {
            "precision": 0.61905,
            "recall": 0.79657,
            "fmeasure": 0.69654
        },
        "rouge2": {
            "precision": 0.35,
            "recall": 0.45694,
            "fmeasure": 0.3963
        },
        "rougeL": {
            "precision": 0.47619,
            "recall": 0.61275,
            "fmeasure": 0.5358
        },
        "rougeLsum": {
            "precision": 0.47619,
            "recall": 0.61275,
            "fmeasure": 0.5358
        },
        "bleu": 16.74109,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.8125
        },
        "bertscore": {
            "precision": 0.85583,
            "recall": 0.89913,
            "f1": 0.87695
        },
        "nubia": {
            "semantic_relation": 4.09161,
            "contradiction": 0.44914,
            "irrelevancy": 20.09215,
            "logical_agreement": 79.45871,
            "grammar_ref": 4.86284,
            "grammar_hyp": 5.67244,
            "nubia_score": 0.58015
        },
        "meteor": 0.33877356283995214,
        "bleurt": -0.19616
    },
    "totto_test_contrast_challenge_table_size-table_size_1552": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.668906062536221,
        "rouge1": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "rouge2": {
            "precision": 0.61111,
            "recall": 0.71515,
            "fmeasure": 0.65876
        },
        "rougeL": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "rougeLsum": {
            "precision": 0.74359,
            "recall": 0.85606,
            "fmeasure": 0.79556
        },
        "bleu": 56.3756,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.95874,
            "recall": 0.98132,
            "f1": 0.9699
        },
        "nubia": {
            "semantic_relation": 4.78062,
            "contradiction": 0.18549,
            "irrelevancy": 2.52911,
            "logical_agreement": 97.28539,
            "grammar_ref": 6.27756,
            "grammar_hyp": 6.12631,
            "nubia_score": 0.87631
        },
        "meteor": 0.4816573593726147,
        "bleurt": 0.49448
    },
    "totto_test_contrast_challenge_table_size-table_size_1560": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 1.0,
        "median_pred_length": 13.0,
        "min_pred_length": 12,
        "max_pred_length": 14,
        "distinct-1": 0.6923076923076923,
        "vocab_size-1": 18,
        "unique-1": 12,
        "entropy-1": 4.008132025833399,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.46785611591339743,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.0346217911747682,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6956521739130435,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.8279097821439705,
        "distinct-2-nopunct": 0.9523809523809523,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.297079327540665,
        "cond_entropy-2-nopunct": 0.4878030857693667,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.09175833038780654,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.234781620250216,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.85872,
            "fmeasure": 0.82559
        },
        "rouge2": {
            "precision": 0.69048,
            "recall": 0.76293,
            "fmeasure": 0.70194
        },
        "rougeL": {
            "precision": 0.72222,
            "recall": 0.8855,
            "fmeasure": 0.76507
        },
        "rougeLsum": {
            "precision": 0.72222,
            "recall": 0.8855,
            "fmeasure": 0.76507
        },
        "bleu": 58.4047,
        "local_recall": {
            "1": 0.25,
            "2": 0.25,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.91571,
            "recall": 0.97464,
            "f1": 0.93946
        },
        "nubia": {
            "semantic_relation": 3.81519,
            "contradiction": 29.23208,
            "irrelevancy": 21.03862,
            "logical_agreement": 49.7293,
            "grammar_ref": 4.07172,
            "grammar_hyp": 4.68033,
            "nubia_score": 0.59214
        },
        "meteor": 0.5488225845729657,
        "bleurt": 0.07189
    },
    "totto_test_contrast_challenge_table_size-table_size_1792": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 1.0,
        "vocab_size-1": 17,
        "unique-1": 17,
        "entropy-1": 4.08746284125034,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": -0.08746284125033939,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6802905608267666,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "rouge2": {
            "precision": 0.93333,
            "recall": 0.66667,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.72727,
            "fmeasure": 0.84211
        },
        "bleu": 60.87321,
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.8125
        },
        "bertscore": {
            "precision": 0.97169,
            "recall": 0.92153,
            "f1": 0.94594
        },
        "nubia": {
            "semantic_relation": 3.49435,
            "contradiction": 1.4858,
            "irrelevancy": 31.07626,
            "logical_agreement": 67.43794,
            "grammar_ref": 3.23206,
            "grammar_hyp": 3.60738,
            "nubia_score": 0.57637
        },
        "meteor": 0.4651459436411745,
        "bleurt": -0.36735
    },
    "totto_test_contrast_challenge_table_size-table_size_1980": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5138039015607525,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.89167,
            "fmeasure": 0.85926
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.51323,
            "fmeasure": 0.49537
        },
        "rougeL": {
            "precision": 0.73333,
            "recall": 0.78333,
            "fmeasure": 0.75556
        },
        "rougeLsum": {
            "precision": 0.73333,
            "recall": 0.78333,
            "fmeasure": 0.75556
        },
        "bleu": 24.38418,
        "local_recall": {
            "1": 1.0,
            "2": 1.0,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.97051,
            "recall": 0.92756,
            "f1": 0.94855
        },
        "nubia": {
            "semantic_relation": 4.84068,
            "contradiction": 1.00439,
            "irrelevancy": 54.96337,
            "logical_agreement": 44.03224,
            "grammar_ref": 6.57473,
            "grammar_hyp": 4.79844,
            "nubia_score": 1.0
        },
        "meteor": 0.4293370916987086,
        "bleurt": 0.47101
    },
    "totto_test_contrast_challenge_table_size-table_size_1800": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 32,
        "mean_pred_length": 16.0,
        "std_pred_length": 3.0,
        "median_pred_length": 16.0,
        "min_pred_length": 13,
        "max_pred_length": 19,
        "distinct-1": 0.8125,
        "vocab_size-1": 26,
        "unique-1": 22,
        "entropy-1": 4.5625,
        "distinct-2": 0.9666666666666667,
        "vocab_size-2": 29,
        "unique-2": 28,
        "entropy-2": 4.840223928941852,
        "cond_entropy-2": 0.24022392894185185,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.02810710212234293,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 2.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8275862068965517,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.444187891679296,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.2672768774062671,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743945,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.058221679700374,
        "rouge1": {
            "precision": 0.68382,
            "recall": 0.62404,
            "fmeasure": 0.58034
        },
        "rouge2": {
            "precision": 0.44034,
            "recall": 0.24845,
            "fmeasure": 0.29287
        },
        "rougeL": {
            "precision": 0.51225,
            "recall": 0.42308,
            "fmeasure": 0.41363
        },
        "rougeLsum": {
            "precision": 0.51225,
            "recall": 0.42308,
            "fmeasure": 0.41363
        },
        "bleu": 21.6757,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.89794,
            "recall": 0.88515,
            "f1": 0.88933
        },
        "nubia": {
            "semantic_relation": 3.41245,
            "contradiction": 3.07467,
            "irrelevancy": 47.179,
            "logical_agreement": 49.74633,
            "grammar_ref": 4.38763,
            "grammar_hyp": 4.65091,
            "nubia_score": 0.46217
        },
        "meteor": 0.2887591943815432,
        "bleurt": -0.05275
    },
    "totto_test_contrast_challenge_table_size-table_size_1155": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.577819531114783,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.7735572622751845,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.04332146930622849,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7857142857142857,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3248629576173574,
        "distinct-2-nopunct": 0.9230769230769231,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.5465935642949384,
        "cond_entropy-2-nopunct": 0.2588453731729854,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": 0.05118944924673077,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.503310677983855,
        "rouge1": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rouge2": {
            "precision": 0.9375,
            "recall": 0.97619,
            "fmeasure": 0.95556
        },
        "rougeL": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "rougeLsum": {
            "precision": 0.96078,
            "recall": 1.0,
            "fmeasure": 0.97917
        },
        "bleu": 81.53551,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.99266,
            "recall": 0.99927,
            "f1": 0.99595
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.16036,
            "irrelevancy": 2.58913,
            "logical_agreement": 97.25051,
            "grammar_ref": 3.50326,
            "grammar_hyp": 3.06363,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.83419
    },
    "totto_test_contrast_challenge_table_size-table_size_2040": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 34,
        "mean_pred_length": 17.0,
        "std_pred_length": 3.0,
        "median_pred_length": 17.0,
        "min_pred_length": 14,
        "max_pred_length": 20,
        "distinct-1": 0.6764705882352942,
        "vocab_size-1": 23,
        "unique-1": 14,
        "entropy-1": 4.3815804883091625,
        "distinct-2": 0.78125,
        "vocab_size-2": 25,
        "unique-2": 18,
        "entropy-2": 4.5625,
        "cond_entropy-2": 0.16253715874966068,
        "distinct-3": 0.8333333333333334,
        "vocab_size-3": 25,
        "unique-3": 20,
        "entropy-3": 4.573557262275186,
        "cond_entropy-3": 0.04022392894185191,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.6875,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 4.3125,
        "distinct-2-nopunct": 0.7666666666666667,
        "vocab_size-2-nopunct": 23,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.440223928941852,
        "cond_entropy-2-nopunct": 0.14022392894185184,
        "distinct-3-nopunct": 0.8214285714285714,
        "vocab_size-3-nopunct": 23,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.450212064914748,
        "cond_entropy-3-nopunct": 0.007607183591942774,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.906339938403358,
        "rouge1": {
            "precision": 0.90823,
            "recall": 0.97059,
            "fmeasure": 0.93778
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.9375,
            "fmeasure": 0.90452
        },
        "rougeL": {
            "precision": 0.90823,
            "recall": 0.97059,
            "fmeasure": 0.93778
        },
        "rougeLsum": {
            "precision": 0.90823,
            "recall": 0.97059,
            "fmeasure": 0.93778
        },
        "bleu": 82.55059,
        "local_recall": {
            "1": 0.25,
            "2": 1.0,
            "3": 0.9565217391304348
        },
        "bertscore": {
            "precision": 0.98476,
            "recall": 0.99213,
            "f1": 0.98842
        },
        "nubia": {
            "semantic_relation": 4.79636,
            "contradiction": 0.23226,
            "irrelevancy": 32.83639,
            "logical_agreement": 66.93135,
            "grammar_ref": 4.08754,
            "grammar_hyp": 4.0116,
            "nubia_score": 0.92114
        },
        "meteor": 0.6225332647582079,
        "bleurt": 0.62667
    },
    "totto_test_contrast_challenge_table_size-table_size_1164": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.7419354838709677,
        "vocab_size-1": 23,
        "unique-1": 18,
        "entropy-1": 4.321627262824397,
        "distinct-2": 0.9655172413793104,
        "vocab_size-2": 28,
        "unique-2": 27,
        "entropy-2": 4.789015477886192,
        "cond_entropy-2": 0.4420481493764492,
        "distinct-3": 1.0,
        "vocab_size-3": 27,
        "unique-3": 27,
        "entropy-3": 4.754887502163471,
        "cond_entropy-3": -0.029019418890029344,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7586206896551724,
        "vocab_size-1-nopunct": 22,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.250752013250441,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.47504133942244525,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.031031312388743945,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7699043637299807,
        "rouge1": {
            "precision": 0.63575,
            "recall": 0.73974,
            "fmeasure": 0.67386
        },
        "rouge2": {
            "precision": 0.44792,
            "recall": 0.52262,
            "fmeasure": 0.47479
        },
        "rougeL": {
            "precision": 0.62293,
            "recall": 0.74091,
            "fmeasure": 0.66745
        },
        "rougeLsum": {
            "precision": 0.62293,
            "recall": 0.74091,
            "fmeasure": 0.66745
        },
        "bleu": 38.87541,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8235294117647058
        },
        "bertscore": {
            "precision": 0.93103,
            "recall": 0.95102,
            "f1": 0.93693
        },
        "nubia": {
            "semantic_relation": 3.79407,
            "contradiction": 49.58684,
            "irrelevancy": 39.32345,
            "logical_agreement": 11.08971,
            "grammar_ref": 4.30067,
            "grammar_hyp": 3.8534,
            "nubia_score": 0.6646
        },
        "meteor": 0.4376222992840778,
        "bleurt": 0.35057
    },
    "totto_test_contrast_challenge_table_size-table_size_1296": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 12,
        "entropy-1": 3.9219280948873623,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 17,
        "unique-2": 15,
        "entropy-2": 4.03740119765411,
        "cond_entropy-2": 0.13652573434569693,
        "distinct-3": 0.9444444444444444,
        "vocab_size-3": 17,
        "unique-3": 16,
        "entropy-3": 4.058813890331201,
        "cond_entropy-3": 0.03310859910983795,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.11475004073479993,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.672984537492482,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.76781,
            "fmeasure": 0.74603
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.65278,
            "fmeasure": 0.56177
        },
        "rougeL": {
            "precision": 0.71111,
            "recall": 0.74929,
            "fmeasure": 0.72583
        },
        "rougeLsum": {
            "precision": 0.71111,
            "recall": 0.74929,
            "fmeasure": 0.72583
        },
        "bleu": 48.127,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.9403,
            "recall": 0.96291,
            "f1": 0.95147
        },
        "nubia": {
            "semantic_relation": 3.76613,
            "contradiction": 0.2298,
            "irrelevancy": 98.99632,
            "logical_agreement": 0.77388,
            "grammar_ref": 5.3293,
            "grammar_hyp": 4.91671,
            "nubia_score": 0.5905
        },
        "meteor": 0.45424233670678776,
        "bleurt": 0.06596
    },
    "totto_test_contrast_challenge_table_size-table_size_1573": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2664701027584293,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.28571,
            "fmeasure": 0.22222
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "bleu": 9.67915,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.79855,
            "recall": 0.79027,
            "f1": 0.79439
        },
        "nubia": {
            "semantic_relation": 1.95339,
            "contradiction": 62.73552,
            "irrelevancy": 37.05471,
            "logical_agreement": 0.20978,
            "grammar_ref": 5.51883,
            "grammar_hyp": 4.4456,
            "nubia_score": 0.14574
        },
        "meteor": 0.21811400092343627,
        "bleurt": -0.36815
    },
    "totto_test_contrast_challenge_table_size-table_size_1165": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0476314089081704,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.69841,
            "fmeasure": 0.77273
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "bleu": 86.68779,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.8333333333333334
        },
        "bertscore": {
            "precision": 0.99092,
            "recall": 0.97079,
            "f1": 0.98075
        },
        "nubia": {
            "semantic_relation": 4.22675,
            "contradiction": 0.58601,
            "irrelevancy": 0.55339,
            "logical_agreement": 98.8606,
            "grammar_ref": 4.24352,
            "grammar_hyp": 4.5844,
            "nubia_score": 0.77636
        },
        "meteor": 0.5570133484098374,
        "bleurt": 0.30208
    },
    "totto_test_contrast_challenge_table_size-table_size_2080": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.7333333333333333,
        "vocab_size-1": 22,
        "unique-1": 16,
        "entropy-1": 4.32323142879762,
        "distinct-2": 0.9310344827586207,
        "vocab_size-2": 27,
        "unique-2": 25,
        "entropy-2": 4.720049960644813,
        "cond_entropy-2": 0.38246195139239614,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": 0.056516784072889334,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8260869565217391,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.142914673354254,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.28836454904226033,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.044872000874067,
        "rouge1": {
            "precision": 0.57333,
            "recall": 0.45,
            "fmeasure": 0.50333
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.1619,
            "fmeasure": 0.18688
        },
        "rougeL": {
            "precision": 0.37333,
            "recall": 0.27407,
            "fmeasure": 0.31555
        },
        "rougeLsum": {
            "precision": 0.37333,
            "recall": 0.27407,
            "fmeasure": 0.31555
        },
        "bleu": 14.46565,
        "local_recall": {
            "1": 0.3,
            "2": 0.4,
            "3": 0.45
        },
        "bertscore": {
            "precision": 0.81745,
            "recall": 0.76451,
            "f1": 0.78888
        },
        "nubia": {
            "semantic_relation": 2.43834,
            "contradiction": 14.72072,
            "irrelevancy": 20.89045,
            "logical_agreement": 64.38882,
            "grammar_ref": 5.53052,
            "grammar_hyp": 4.21784,
            "nubia_score": 0.35686
        },
        "meteor": 0.19410085674882321,
        "bleurt": -0.53838
    },
    "totto_test_contrast_challenge_table_size-table_size_1168": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 0.9047619047619048,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.165894208390023,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": 0.16735504721677538,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8947368421052632,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 3.9976702764876113,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": 0.1861579047855862,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.08246216019197297,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.332129130757091,
        "rouge1": {
            "precision": 0.65,
            "recall": 0.48148,
            "fmeasure": 0.55319
        },
        "rouge2": {
            "precision": 0.36842,
            "recall": 0.26923,
            "fmeasure": 0.31111
        },
        "rougeL": {
            "precision": 0.55,
            "recall": 0.40741,
            "fmeasure": 0.46809
        },
        "rougeLsum": {
            "precision": 0.55,
            "recall": 0.40741,
            "fmeasure": 0.46809
        },
        "bleu": 21.90538,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6111111111111112
        },
        "bertscore": {
            "precision": 0.89581,
            "recall": 0.87205,
            "f1": 0.88339
        },
        "nubia": {
            "semantic_relation": 3.02311,
            "contradiction": 1.19615,
            "irrelevancy": 40.67705,
            "logical_agreement": 58.1268,
            "grammar_ref": 4.95946,
            "grammar_hyp": 6.48155,
            "nubia_score": 0.28293
        },
        "meteor": 0.2202305829821403,
        "bleurt": -0.38722
    },
    "totto_test_contrast_challenge_table_size-table_size_1582": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 36,
        "mean_pred_length": 18.0,
        "std_pred_length": 4.0,
        "median_pred_length": 18.0,
        "min_pred_length": 14,
        "max_pred_length": 22,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 30,
        "unique-1": 25,
        "entropy-1": 4.815622570826658,
        "distinct-2": 1.0,
        "vocab_size-2": 34,
        "unique-2": 34,
        "entropy-2": 5.087462841250338,
        "cond_entropy-2": 0.23385806045989374,
        "distinct-3": 1.0,
        "vocab_size-3": 32,
        "unique-3": 32,
        "entropy-3": 5.0,
        "cond_entropy-3": -0.08746284125033942,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 4.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.896551724137931,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.651084443403434,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 27,
        "unique-2-nopunct": 27,
        "entropy-2-nopunct": 4.754887502163471,
        "cond_entropy-2-nopunct": 0.08209169222108177,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.081675740734367,
        "rouge1": {
            "precision": 0.81176,
            "recall": 0.8303,
            "fmeasure": 0.81845
        },
        "rouge2": {
            "precision": 0.45486,
            "recall": 0.49286,
            "fmeasure": 0.47193
        },
        "rougeL": {
            "precision": 0.55294,
            "recall": 0.58182,
            "fmeasure": 0.56548
        },
        "rougeLsum": {
            "precision": 0.55294,
            "recall": 0.58182,
            "fmeasure": 0.56548
        },
        "bleu": 49.97684,
        "local_recall": {
            "1": 0.5,
            "2": 0,
            "3": 0.8461538461538461
        },
        "bertscore": {
            "precision": 0.93512,
            "recall": 0.94705,
            "f1": 0.94105
        },
        "nubia": {
            "semantic_relation": 4.8585,
            "contradiction": 0.13751,
            "irrelevancy": 49.81906,
            "logical_agreement": 50.04343,
            "grammar_ref": 3.76682,
            "grammar_hyp": 3.56879,
            "nubia_score": 0.98975
        },
        "meteor": 0.4668178988174989,
        "bleurt": 0.50741
    },
    "totto_test_contrast_challenge_table_size-table_size_2104": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.2841455313229504,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.39167,
            "fmeasure": 0.53755
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.20952,
            "fmeasure": 0.29524
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.38431,
            "fmeasure": 0.5303
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.38431,
            "fmeasure": 0.5303
        },
        "bleu": 7.56238,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.89426,
            "recall": 0.7758,
            "f1": 0.83082
        },
        "nubia": {
            "semantic_relation": 3.65233,
            "contradiction": 0.32311,
            "irrelevancy": 1.26008,
            "logical_agreement": 98.41681,
            "grammar_ref": 4.68072,
            "grammar_hyp": 5.64189,
            "nubia_score": 0.52633
        },
        "meteor": 0.18866647190206598,
        "bleurt": -0.36155
    },
    "totto_test_contrast_challenge_table_size-table_size_1170": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0909514646162273,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.3125,
            "fmeasure": 0.40724
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.47009,
            "fmeasure": 0.59649
        },
        "bleu": 31.85036,
        "local_recall": {
            "1": 0.0,
            "2": 0.625
        },
        "bertscore": {
            "precision": 0.94653,
            "recall": 0.89087,
            "f1": 0.91786
        },
        "nubia": {
            "semantic_relation": 3.4502,
            "contradiction": 1.65058,
            "irrelevancy": 0.74865,
            "logical_agreement": 97.60076,
            "grammar_ref": 4.45494,
            "grammar_hyp": 5.46862,
            "nubia_score": 0.42783
        },
        "meteor": 0.3769465296142278,
        "bleurt": 0.09535
    },
    "totto_test_contrast_challenge_table_size-table_size_2112": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0881978509745025,
        "rouge1": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.5873,
            "fmeasure": 0.65152
        },
        "rougeL": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "rougeLsum": {
            "precision": 0.94444,
            "recall": 0.77976,
            "fmeasure": 0.85348
        },
        "bleu": 68.94026,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.3333333333333333,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.98644,
            "recall": 0.96366,
            "f1": 0.97491
        },
        "nubia": {
            "semantic_relation": 4.6318,
            "contradiction": 0.66466,
            "irrelevancy": 0.56229,
            "logical_agreement": 98.77305,
            "grammar_ref": 5.07671,
            "grammar_hyp": 5.29413,
            "nubia_score": 0.85198
        },
        "meteor": 0.81809314801268,
        "bleurt": 0.64449
    },
    "totto_test_contrast_challenge_table_size-table_size_1638": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.513321309731279,
        "rouge1": {
            "precision": 0.96667,
            "recall": 1.0,
            "fmeasure": 0.98246
        },
        "rouge2": {
            "precision": 0.96296,
            "recall": 1.0,
            "fmeasure": 0.98039
        },
        "rougeL": {
            "precision": 0.96667,
            "recall": 1.0,
            "fmeasure": 0.98246
        },
        "rougeLsum": {
            "precision": 0.96667,
            "recall": 1.0,
            "fmeasure": 0.98246
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 1.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.34129,
            "irrelevancy": 0.58866,
            "logical_agreement": 99.07005,
            "grammar_ref": 4.6206,
            "grammar_hyp": 4.2408,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.88359
    },
    "totto_test_contrast_challenge_table_size-table_size_1050": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7990385038524417,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.56667,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.82222,
            "fmeasure": 0.68132
        },
        "bleu": 20.16495,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.94225,
            "recall": 0.97743,
            "f1": 0.95951
        },
        "nubia": {
            "semantic_relation": 4.21377,
            "contradiction": 0.17851,
            "irrelevancy": 33.78877,
            "logical_agreement": 66.03272,
            "grammar_ref": 5.27628,
            "grammar_hyp": 4.69427,
            "nubia_score": 0.81239
        },
        "meteor": 0.861811391223156,
        "bleurt": 0.49066
    },
    "totto_test_contrast_challenge_table_size-table_size_1172": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6676442232526503,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.57778,
            "fmeasure": 0.56712
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.17037,
            "fmeasure": 0.16566
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.57778,
            "fmeasure": 0.56712
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.57778,
            "fmeasure": 0.56712
        },
        "bleu": 16.51582,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6
        },
        "bertscore": {
            "precision": 0.92167,
            "recall": 0.93562,
            "f1": 0.92859
        },
        "nubia": {
            "semantic_relation": 4.25694,
            "contradiction": 20.57668,
            "irrelevancy": 3.81431,
            "logical_agreement": 75.60901,
            "grammar_ref": 7.45181,
            "grammar_hyp": 6.74107,
            "nubia_score": 0.72697
        },
        "meteor": 0.4116727517898151,
        "bleurt": 0.1097
    },
    "totto_test_contrast_challenge_table_size-table_size_1055": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8483609718589222,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.21732,
            "irrelevancy": 0.45505,
            "logical_agreement": 99.32763,
            "grammar_ref": 5.4078,
            "grammar_hyp": 5.46881,
            "nubia_score": 0.9943
        },
        "meteor": 1.0,
        "bleurt": 0.96931
    },
    "totto_test_contrast_challenge_table_size-table_size_1174": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 10.5,
        "std_pred_length": 3.5,
        "median_pred_length": 10.5,
        "min_pred_length": 7,
        "max_pred_length": 14,
        "distinct-1": 0.7619047619047619,
        "vocab_size-1": 16,
        "unique-1": 11,
        "entropy-1": 3.916126946588283,
        "distinct-2": 0.8421052631578947,
        "vocab_size-2": 16,
        "unique-2": 13,
        "entropy-2": 3.932138039759373,
        "cond_entropy-2": -0.03912675144043809,
        "distinct-3": 0.8823529411764706,
        "vocab_size-3": 15,
        "unique-3": 13,
        "entropy-3": 3.8521687236032816,
        "cond_entropy-3": -0.04281761336971672,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.7894736842105263,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.826874881864636,
        "distinct-2-nopunct": 0.8235294117647058,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.734521664779752,
        "cond_entropy-2-nopunct": -0.10164114278148138,
        "distinct-3-nopunct": 0.8666666666666667,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.640223928941851,
        "cond_entropy-3-nopunct": -0.11390557897515413,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.41607145067997,
        "rouge1": {
            "precision": 0.82143,
            "recall": 0.85119,
            "fmeasure": 0.83333
        },
        "rouge2": {
            "precision": 0.69744,
            "recall": 0.71717,
            "fmeasure": 0.70455
        },
        "rougeL": {
            "precision": 0.82143,
            "recall": 0.85119,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.82143,
            "recall": 0.85119,
            "fmeasure": 0.83333
        },
        "bleu": 61.40212,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8125
        },
        "bertscore": {
            "precision": 0.96014,
            "recall": 0.97122,
            "f1": 0.96562
        },
        "nubia": {
            "semantic_relation": 4.44129,
            "contradiction": 0.59216,
            "irrelevancy": 48.55534,
            "logical_agreement": 50.8525,
            "grammar_ref": 4.94813,
            "grammar_hyp": 5.43961,
            "nubia_score": 0.73822
        },
        "meteor": 0.4794180632180367,
        "bleurt": 0.55259
    },
    "totto_test_contrast_challenge_table_size-table_size_2123": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.043321469306228495,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6494004551426125,
        "rouge1": {
            "precision": 0.7381,
            "recall": 0.69188,
            "fmeasure": 0.71275
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.58013,
            "fmeasure": 0.61892
        },
        "rougeL": {
            "precision": 0.7381,
            "recall": 0.69188,
            "fmeasure": 0.71275
        },
        "rougeLsum": {
            "precision": 0.7381,
            "recall": 0.69188,
            "fmeasure": 0.71275
        },
        "bleu": 58.28234,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.9569,
            "recall": 0.92882,
            "f1": 0.92474
        },
        "nubia": {
            "semantic_relation": 4.05904,
            "contradiction": 17.51726,
            "irrelevancy": 70.116,
            "logical_agreement": 12.36674,
            "grammar_ref": 4.48877,
            "grammar_hyp": 4.36926,
            "nubia_score": 0.69046
        },
        "meteor": 0.43592078179231536,
        "bleurt": 0.17574
    },
    "totto_test_contrast_challenge_table_size-table_size_1176": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 0.5,
        "median_pred_length": 11.5,
        "min_pred_length": 11,
        "max_pred_length": 12,
        "distinct-1": 0.8695652173913043,
        "vocab_size-1": 20,
        "unique-1": 17,
        "entropy-1": 4.2626923908396215,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": 0.059231657197938034,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 19,
        "entropy-2-nopunct": 4.247927513443583,
        "cond_entropy-2-nopunct": 0.06613640645429873,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 17,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.08746284125034,
        "cond_entropy-3-nopunct": -0.1604646721932461,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4191029553863226,
        "rouge1": {
            "precision": 0.6803,
            "recall": 0.775,
            "fmeasure": 0.7176
        },
        "rouge2": {
            "precision": 0.46296,
            "recall": 0.46296,
            "fmeasure": 0.46296
        },
        "rougeL": {
            "precision": 0.6197,
            "recall": 0.73333,
            "fmeasure": 0.6598
        },
        "rougeLsum": {
            "precision": 0.6197,
            "recall": 0.73333,
            "fmeasure": 0.6598
        },
        "bleu": 52.92464,
        "local_recall": {
            "1": 0.3,
            "2": 0,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.92376,
            "recall": 0.9301,
            "f1": 0.92691
        },
        "nubia": {
            "semantic_relation": 4.16852,
            "contradiction": 0.25379,
            "irrelevancy": 49.95497,
            "logical_agreement": 49.79125,
            "grammar_ref": 5.47595,
            "grammar_hyp": 4.93821,
            "nubia_score": 0.79298
        },
        "meteor": 0.4446440218830372,
        "bleurt": 0.31353
    },
    "totto_test_contrast_challenge_table_size-table_size_1302": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.259375898165659,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.56173,
            "fmeasure": 0.68372
        },
        "rouge2": {
            "precision": 0.57778,
            "recall": 0.38785,
            "fmeasure": 0.46394
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.5303,
            "fmeasure": 0.62105
        },
        "bleu": 23.09472,
        "local_recall": {
            "1": 0.2,
            "2": 0.0,
            "3": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.96471,
            "recall": 0.89731,
            "f1": 0.92814
        },
        "nubia": {
            "semantic_relation": 3.85327,
            "contradiction": 0.17167,
            "irrelevancy": 33.45547,
            "logical_agreement": 66.37286,
            "grammar_ref": 3.86337,
            "grammar_hyp": 3.58191,
            "nubia_score": 0.72381
        },
        "meteor": 0.32038272111982113,
        "bleurt": 0.18008
    },
    "totto_test_contrast_challenge_table_size-table_size_2148": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.16916029185586146,
        "rouge1": {
            "precision": 0.90909,
            "recall": 0.41806,
            "fmeasure": 0.57234
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.26182,
            "fmeasure": 0.36429
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.37625,
            "fmeasure": 0.5151
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.37625,
            "fmeasure": 0.5151
        },
        "bleu": 13.53478,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.38095238095238093
        },
        "bertscore": {
            "precision": 0.94312,
            "recall": 0.76732,
            "f1": 0.8459
        },
        "nubia": {
            "semantic_relation": 3.59355,
            "contradiction": 0.11709,
            "irrelevancy": 0.85004,
            "logical_agreement": 99.03287,
            "grammar_ref": 3.26294,
            "grammar_hyp": 3.27801,
            "nubia_score": 0.65524
        },
        "meteor": 0.2726771323971795,
        "bleurt": 0.12432
    },
    "totto_test_contrast_challenge_table_size-table_size_1180": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.7741935483870968,
        "vocab_size-1": 24,
        "unique-1": 18,
        "entropy-1": 4.478232197413861,
        "distinct-2": 0.9310344827586207,
        "vocab_size-2": 27,
        "unique-2": 25,
        "entropy-2": 4.720049960644813,
        "cond_entropy-2": 0.2056773572290925,
        "distinct-3": 0.9629629629629629,
        "vocab_size-3": 26,
        "unique-3": 25,
        "entropy-3": 4.6808134280893965,
        "cond_entropy-3": -0.10309349296410335,
        "total_length-nopunct": 29,
        "mean_pred_length-nopunct": 14.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.7931034482758621,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.418157288156418,
        "distinct-2-nopunct": 0.9629629629629629,
        "vocab_size-2-nopunct": 26,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.6808134280893965,
        "cond_entropy-2-nopunct": 0.22116159970861757,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 25,
        "unique-3-nopunct": 25,
        "entropy-3-nopunct": 4.643856189774723,
        "cond_entropy-3-nopunct": -0.11103131238874399,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.371482239384177,
        "rouge1": {
            "precision": 0.46635,
            "recall": 0.59768,
            "fmeasure": 0.52281
        },
        "rouge2": {
            "precision": 0.30556,
            "recall": 0.39637,
            "fmeasure": 0.34427
        },
        "rougeL": {
            "precision": 0.4351,
            "recall": 0.56013,
            "fmeasure": 0.48871
        },
        "rougeLsum": {
            "precision": 0.4351,
            "recall": 0.56013,
            "fmeasure": 0.48871
        },
        "bleu": 24.42573,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.89728,
            "recall": 0.92344,
            "f1": 0.91016
        },
        "nubia": {
            "semantic_relation": 4.53238,
            "contradiction": 0.42974,
            "irrelevancy": 47.50671,
            "logical_agreement": 52.06355,
            "grammar_ref": 5.01983,
            "grammar_hyp": 4.71972,
            "nubia_score": 0.77646
        },
        "meteor": 0.37599095748946654,
        "bleurt": 0.24647
    },
    "totto_test_contrast_challenge_table_size-table_size_1640": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 1.0,
        "vocab_size-1": 19,
        "unique-1": 19,
        "entropy-1": 4.247927513443583,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": -0.07800251200127316,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.140728366791319,
        "rouge1": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "rouge2": {
            "precision": 0.77778,
            "recall": 0.73684,
            "fmeasure": 0.75676
        },
        "rougeL": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "rougeLsum": {
            "precision": 0.92105,
            "recall": 0.875,
            "fmeasure": 0.89744
        },
        "bleu": 74.70143,
        "local_recall": {
            "1": 0.5,
            "2": 0.9375
        },
        "bertscore": {
            "precision": 0.97682,
            "recall": 0.97908,
            "f1": 0.97794
        },
        "nubia": {
            "semantic_relation": 4.89024,
            "contradiction": 0.23433,
            "irrelevancy": 0.50131,
            "logical_agreement": 99.26436,
            "grammar_ref": 4.55046,
            "grammar_hyp": 4.62026,
            "nubia_score": 0.92817
        },
        "meteor": 0.5349776347145982,
        "bleurt": 0.60943
    },
    "totto_test_contrast_challenge_table_size-table_size_1056": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.8571428571428571,
        "vocab_size-1": 12,
        "unique-1": 10,
        "entropy-1": 3.521640636343319,
        "distinct-2": 0.9230769230769231,
        "vocab_size-2": 12,
        "unique-2": 11,
        "entropy-2": 3.5465935642949384,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": 0.05118944924673077,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.418295834054489,
        "cond_entropy-2-nopunct": 0.05118944924673078,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": 0.056287299734322706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.333361941695811,
        "rouge1": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.46875,
            "fmeasure": 0.40714
        },
        "rougeL": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "rougeLsum": {
            "precision": 0.53846,
            "recall": 0.62092,
            "fmeasure": 0.56364
        },
        "bleu": 31.61488,
        "local_recall": {
            "1": 0.18181818181818182,
            "2": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.87901,
            "recall": 0.91528,
            "f1": 0.89678
        },
        "nubia": {
            "semantic_relation": 4.21805,
            "contradiction": 0.26553,
            "irrelevancy": 84.0294,
            "logical_agreement": 15.70508,
            "grammar_ref": 5.6106,
            "grammar_hyp": 4.19382,
            "nubia_score": 0.77504
        },
        "meteor": 0.4361381544346885,
        "bleurt": 0.18823
    },
    "totto_test_contrast_challenge_table_size-table_size_1072": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 33,
        "mean_pred_length": 16.5,
        "std_pred_length": 0.5,
        "median_pred_length": 16.5,
        "min_pred_length": 16,
        "max_pred_length": 17,
        "distinct-1": 0.8181818181818182,
        "vocab_size-1": 27,
        "unique-1": 23,
        "entropy-1": 4.620151695116031,
        "distinct-2": 1.0,
        "vocab_size-2": 31,
        "unique-2": 31,
        "entropy-2": 4.954196310386877,
        "cond_entropy-2": 0.29689896522197035,
        "distinct-3": 1.0,
        "vocab_size-3": 29,
        "unique-3": 29,
        "entropy-3": 4.857980995127571,
        "cond_entropy-3": -0.09621531525930291,
        "total_length-nopunct": 30,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 25,
        "unique-1-nopunct": 22,
        "entropy-1-nopunct": 4.506890595608519,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 28,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.807354922057606,
        "cond_entropy-2-nopunct": 0.32903575502051413,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.70043971814109,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9365471072072578,
        "rouge1": {
            "precision": 0.61204,
            "recall": 0.69048,
            "fmeasure": 0.64603
        },
        "rouge2": {
            "precision": 0.33093,
            "recall": 0.3985,
            "fmeasure": 0.36033
        },
        "rougeL": {
            "precision": 0.5049,
            "recall": 0.59615,
            "fmeasure": 0.54506
        },
        "rougeLsum": {
            "precision": 0.5049,
            "recall": 0.59615,
            "fmeasure": 0.54506
        },
        "bleu": 29.61323,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.88795,
            "recall": 0.9097,
            "f1": 0.89797
        },
        "nubia": {
            "semantic_relation": 4.34928,
            "contradiction": 0.12254,
            "irrelevancy": 49.98985,
            "logical_agreement": 49.88761,
            "grammar_ref": 4.47266,
            "grammar_hyp": 4.25161,
            "nubia_score": 0.83072
        },
        "meteor": 0.3570890172061635,
        "bleurt": 0.06239
    },
    "totto_test_contrast_challenge_table_size-table_size_2205": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.515160478176624,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92308
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.6,
            "fmeasure": 0.54545
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.83333,
            "fmeasure": 0.76923
        },
        "bleu": 39.76354,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.94724,
            "recall": 0.98304,
            "f1": 0.96481
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.17299,
            "irrelevancy": 0.9738,
            "logical_agreement": 98.85322,
            "grammar_ref": 6.21263,
            "grammar_hyp": 6.03316,
            "nubia_score": 0.98174
        },
        "meteor": 0.45894279564872403,
        "bleurt": 0.7152
    },
    "totto_test_contrast_challenge_table_size-table_size_1080": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.95,
        "vocab_size-1": 19,
        "unique-1": 18,
        "entropy-1": 4.221928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.03126257645096008,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.572482935608266,
        "rouge1": {
            "precision": 0.85185,
            "recall": 0.72222,
            "fmeasure": 0.78028
        },
        "rouge2": {
            "precision": 0.52941,
            "recall": 0.55789,
            "fmeasure": 0.54167
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.425,
            "fmeasure": 0.45865
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.425,
            "fmeasure": 0.45865
        },
        "bleu": 48.38056,
        "local_recall": {
            "1": 0.25,
            "2": 0.75,
            "3": 0.7857142857142857
        },
        "bertscore": {
            "precision": 0.91407,
            "recall": 0.89941,
            "f1": 0.90055
        },
        "nubia": {
            "semantic_relation": 4.01208,
            "contradiction": 1.75175,
            "irrelevancy": 36.43363,
            "logical_agreement": 61.81463,
            "grammar_ref": 4.75667,
            "grammar_hyp": 4.31574,
            "nubia_score": 0.72102
        },
        "meteor": 0.4108172620560928,
        "bleurt": -0.18175
    },
    "totto_test_contrast_challenge_table_size-table_size_1656": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.3613918038597497,
        "rouge1": {
            "precision": 0.4,
            "recall": 0.30769,
            "fmeasure": 0.34783
        },
        "rouge2": {
            "precision": 0.22222,
            "recall": 0.16667,
            "fmeasure": 0.19048
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.30769,
            "fmeasure": 0.34783
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.30769,
            "fmeasure": 0.34783
        },
        "bleu": 8.53301,
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.86183,
            "recall": 0.85336,
            "f1": 0.85757
        },
        "nubia": {
            "semantic_relation": 3.54145,
            "contradiction": 0.06207,
            "irrelevancy": 99.70862,
            "logical_agreement": 0.22931,
            "grammar_ref": 3.76485,
            "grammar_hyp": 4.96867,
            "nubia_score": 0.4782
        },
        "meteor": 0.17844114017190563,
        "bleurt": 0.10745
    },
    "totto_test_contrast_challenge_table_size-table_size_1182": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 26.0,
        "std_pred_length": 0.0,
        "median_pred_length": 26.0,
        "min_pred_length": 26,
        "max_pred_length": 26,
        "distinct-1": 0.7692307692307693,
        "vocab_size-1": 20,
        "unique-1": 16,
        "entropy-1": 4.18083298720544,
        "distinct-2": 0.96,
        "vocab_size-2": 24,
        "unique-2": 23,
        "entropy-2": 4.5638561897747225,
        "cond_entropy-2": 0.40380747180670995,
        "distinct-3": 1.0,
        "vocab_size-3": 24,
        "unique-3": 24,
        "entropy-3": 4.584962500721156,
        "cond_entropy-3": 0.02443964427976503,
        "total_length-nopunct": 26,
        "mean_pred_length-nopunct": 26.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 26.0,
        "min_pred_length-nopunct": 26,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7692307692307693,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.18083298720544,
        "distinct-2-nopunct": 0.96,
        "vocab_size-2-nopunct": 24,
        "unique-2-nopunct": 23,
        "entropy-2-nopunct": 4.5638561897747225,
        "cond_entropy-2-nopunct": 0.40380747180670995,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 24,
        "unique-3-nopunct": 24,
        "entropy-3-nopunct": 4.584962500721156,
        "cond_entropy-3-nopunct": 0.02443964427976503,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8692294055344714,
        "rouge1": {
            "precision": 0.25926,
            "recall": 0.66111,
            "fmeasure": 0.37191
        },
        "rouge2": {
            "precision": 0.11538,
            "recall": 0.31313,
            "fmeasure": 0.16834
        },
        "rougeL": {
            "precision": 0.25926,
            "recall": 0.66111,
            "fmeasure": 0.37191
        },
        "rougeLsum": {
            "precision": 0.25926,
            "recall": 0.66111,
            "fmeasure": 0.37191
        },
        "bleu": 4.52178,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.78837,
            "recall": 0.89173,
            "f1": 0.83687
        },
        "nubia": {
            "semantic_relation": 3.18145,
            "contradiction": 0.07403,
            "irrelevancy": 99.75583,
            "logical_agreement": 0.17014,
            "grammar_ref": 4.40566,
            "grammar_hyp": 3.51397,
            "nubia_score": 0.1594
        },
        "meteor": 0.28950433614641263,
        "bleurt": 0.01361
    },
    "totto_test_contrast_challenge_table_size-table_size_1680": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6961650890339652,
        "rouge1": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rouge2": {
            "precision": 0.73333,
            "recall": 0.81481,
            "fmeasure": 0.77193
        },
        "rougeL": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "rougeLsum": {
            "precision": 0.87879,
            "recall": 0.96667,
            "fmeasure": 0.92063
        },
        "bleu": 76.11606,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97599,
            "recall": 0.99403,
            "f1": 0.98493
        },
        "nubia": {
            "semantic_relation": 4.94183,
            "contradiction": 0.26546,
            "irrelevancy": 2.07729,
            "logical_agreement": 97.65725,
            "grammar_ref": 4.2439,
            "grammar_hyp": 4.255,
            "nubia_score": 0.96846
        },
        "meteor": 0.5715186082473627,
        "bleurt": 0.74566
    },
    "totto_test_contrast_challenge_table_size-table_size_1098": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.875,
        "vocab_size-1": 14,
        "unique-1": 12,
        "entropy-1": 3.75,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": 0.17355726227518528,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.5857990746720625,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77576
        },
        "rouge2": {
            "precision": 0.63636,
            "recall": 0.92593,
            "fmeasure": 0.75185
        },
        "rougeL": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77576
        },
        "rougeLsum": {
            "precision": 0.66667,
            "recall": 0.93333,
            "fmeasure": 0.77576
        },
        "bleu": 51.82114,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.90755,
            "recall": 0.96974,
            "f1": 0.93762
        },
        "nubia": {
            "semantic_relation": 3.59541,
            "contradiction": 5.08262,
            "irrelevancy": 94.29493,
            "logical_agreement": 0.62246,
            "grammar_ref": 5.1757,
            "grammar_hyp": 4.23408,
            "nubia_score": 0.51234
        },
        "meteor": 0.5257043737612862,
        "bleurt": 0.12075
    },
    "totto_test_contrast_challenge_table_size-table_size_1188": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.8947368421052632,
        "vocab_size-1": 17,
        "unique-1": 15,
        "entropy-1": 4.03740119765411,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.14421971022094904,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8823529411764706,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.8521687236032816,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.1625371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.820436051992473,
        "rouge1": {
            "precision": 0.47059,
            "recall": 0.54762,
            "fmeasure": 0.50605
        },
        "rouge2": {
            "precision": 0.1875,
            "recall": 0.21703,
            "fmeasure": 0.20115
        },
        "rougeL": {
            "precision": 0.29412,
            "recall": 0.34048,
            "fmeasure": 0.31552
        },
        "rougeLsum": {
            "precision": 0.29412,
            "recall": 0.34048,
            "fmeasure": 0.31552
        },
        "bleu": 28.05155,
        "local_recall": {
            "1": 0.5714285714285714,
            "2": 0.5454545454545454
        },
        "bertscore": {
            "precision": 0.88401,
            "recall": 0.90639,
            "f1": 0.89506
        },
        "nubia": {
            "semantic_relation": 3.9387,
            "contradiction": 91.18074,
            "irrelevancy": 7.54864,
            "logical_agreement": 1.27062,
            "grammar_ref": 4.95834,
            "grammar_hyp": 4.56412,
            "nubia_score": 0.63016
        },
        "meteor": 0.3430776578060902,
        "bleurt": 0.22402
    },
    "totto_test_contrast_challenge_table_size-table_size_2385": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.9444444444444444,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.058813890331201,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.03518489863155644,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.668579595566943,
        "rouge1": {
            "precision": 0.88889,
            "recall": 0.93333,
            "fmeasure": 0.91057
        },
        "rouge2": {
            "precision": 0.71667,
            "recall": 0.77709,
            "fmeasure": 0.74521
        },
        "rougeL": {
            "precision": 0.80952,
            "recall": 0.87778,
            "fmeasure": 0.84178
        },
        "rougeLsum": {
            "precision": 0.80952,
            "recall": 0.87778,
            "fmeasure": 0.84178
        },
        "bleu": 72.20778,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "bertscore": {
            "precision": 0.95206,
            "recall": 0.95249,
            "f1": 0.95228
        },
        "nubia": {
            "semantic_relation": 4.29191,
            "contradiction": 6.96257,
            "irrelevancy": 86.12044,
            "logical_agreement": 6.91699,
            "grammar_ref": 4.59116,
            "grammar_hyp": 4.75607,
            "nubia_score": 0.6614
        },
        "meteor": 0.5172758559269609,
        "bleurt": -0.0934
    },
    "totto_test_contrast_challenge_table_size-table_size_2232": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.081505319833173,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.4697,
            "fmeasure": 0.5258
        },
        "rouge2": {
            "precision": 0.40476,
            "recall": 0.29464,
            "fmeasure": 0.33968
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.34641,
            "fmeasure": 0.37121
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.34641,
            "fmeasure": 0.37121
        },
        "bleu": 30.42149,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.2222222222222222,
            "3": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.89098,
            "recall": 0.88116,
            "f1": 0.88437
        },
        "nubia": {
            "semantic_relation": 2.99227,
            "contradiction": 56.07935,
            "irrelevancy": 42.41394,
            "logical_agreement": 1.50672,
            "grammar_ref": 5.24053,
            "grammar_hyp": 5.73434,
            "nubia_score": 0.26697
        },
        "meteor": 0.22971797994687648,
        "bleurt": -0.58889
    },
    "totto_test_contrast_challenge_table_size-table_size_936": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 2.5,
        "median_pred_length": 13.5,
        "min_pred_length": 11,
        "max_pred_length": 16,
        "distinct-1": 0.9629629629629629,
        "vocab_size-1": 26,
        "unique-1": 25,
        "entropy-1": 4.6808134280893965,
        "distinct-2": 1.0,
        "vocab_size-2": 25,
        "unique-2": 25,
        "entropy-2": 4.643856189774723,
        "cond_entropy-2": -0.11103131238874399,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": -0.12029423371771175,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 24,
        "unique-1-nopunct": 24,
        "entropy-1-nopunct": 4.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 20,
        "entropy-3-nopunct": 4.321928094887363,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8855436342174086,
        "rouge1": {
            "precision": 0.91111,
            "recall": 0.77738,
            "fmeasure": 0.82935
        },
        "rouge2": {
            "precision": 0.79762,
            "recall": 0.69591,
            "fmeasure": 0.73479
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.72619,
            "fmeasure": 0.768
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.72619,
            "fmeasure": 0.768
        },
        "bleu": 64.80458,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.9688,
            "recall": 0.9428,
            "f1": 0.94945
        },
        "nubia": {
            "semantic_relation": 4.20115,
            "contradiction": 36.90965,
            "irrelevancy": 5.03113,
            "logical_agreement": 58.05922,
            "grammar_ref": 4.54027,
            "grammar_hyp": 4.69267,
            "nubia_score": 0.68472
        },
        "meteor": 0.42881621383824753,
        "bleurt": 0.4424
    },
    "totto_test_contrast_challenge_table_size-table_size_1683": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 24,
        "mean_pred_length": 24.0,
        "std_pred_length": 0.0,
        "median_pred_length": 24.0,
        "min_pred_length": 24,
        "max_pred_length": 24,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.1887218755408675,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": 0.28315652071002123,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.06413033741971555,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.963208447979705,
        "rouge1": {
            "precision": 0.89583,
            "recall": 0.74579,
            "fmeasure": 0.81218
        },
        "rouge2": {
            "precision": 0.51111,
            "recall": 0.42484,
            "fmeasure": 0.46296
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.62626,
            "fmeasure": 0.68111
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.62626,
            "fmeasure": 0.68111
        },
        "bleu": 45.23203,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.625
        },
        "bertscore": {
            "precision": 0.96744,
            "recall": 0.9069,
            "f1": 0.93619
        },
        "nubia": {
            "semantic_relation": 3.27125,
            "contradiction": 97.00458,
            "irrelevancy": 1.53866,
            "logical_agreement": 1.45677,
            "grammar_ref": 4.78465,
            "grammar_hyp": 4.75511,
            "nubia_score": 0.39419
        },
        "meteor": 0.37313556425638483,
        "bleurt": -0.01184
    },
    "totto_test_contrast_challenge_table_size-table_size_2392": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.30952380952380953,
        "vocab_size-1": 13,
        "unique-1": 0,
        "entropy-1": 3.6052067078749124,
        "distinct-2": 0.5128205128205128,
        "vocab_size-2": 20,
        "unique-2": 12,
        "entropy-2": 4.034274333747602,
        "cond_entropy-2": 0.4446174885021272,
        "distinct-3": 0.6666666666666666,
        "vocab_size-3": 24,
        "unique-3": 18,
        "entropy-3": 4.377443751081733,
        "cond_entropy-3": 0.31534986603359005,
        "total_length-nopunct": 33,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.30303030303030304,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 3.2021520733138717,
        "distinct-2-nopunct": 0.5666666666666667,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.755913095175825,
        "cond_entropy-2-nopunct": 0.5794889763942963,
        "distinct-3-nopunct": 0.7037037037037037,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 4.0504597240651785,
        "cond_entropy-3-nopunct": 0.24632607330174533,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.402063778276956,
        "rouge1": {
            "precision": 0.9697,
            "recall": 0.82828,
            "fmeasure": 0.87738
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.76859,
            "fmeasure": 0.80163
        },
        "rougeL": {
            "precision": 0.9697,
            "recall": 0.82828,
            "fmeasure": 0.87738
        },
        "rougeLsum": {
            "precision": 0.9697,
            "recall": 0.82828,
            "fmeasure": 0.87738
        },
        "bleu": 76.20958,
        "local_recall": {
            "1": 0.0,
            "2": 0.6428571428571429,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.98848,
            "recall": 0.95443,
            "f1": 0.9705
        },
        "nubia": {
            "semantic_relation": 4.52146,
            "contradiction": 0.43858,
            "irrelevancy": 0.59338,
            "logical_agreement": 98.96804,
            "grammar_ref": 4.141,
            "grammar_hyp": 4.09336,
            "nubia_score": 0.84845
        },
        "meteor": 0.5295259054143824,
        "bleurt": 0.73853
    },
    "totto_test_contrast_challenge_table_size-table_size_1809": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.07475536180041005,
        "rouge1": {
            "precision": 0.57143,
            "recall": 0.21429,
            "fmeasure": 0.30476
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.11396,
            "fmeasure": 0.16587
        },
        "rougeL": {
            "precision": 0.57143,
            "recall": 0.21429,
            "fmeasure": 0.30476
        },
        "rougeLsum": {
            "precision": 0.57143,
            "recall": 0.21429,
            "fmeasure": 0.30476
        },
        "bleu": 16.05295,
        "local_recall": {
            "1": 0.0,
            "2": 0.4444444444444444
        },
        "bertscore": {
            "precision": 0.84317,
            "recall": 0.79349,
            "f1": 0.81758
        },
        "nubia": {
            "semantic_relation": 3.11978,
            "contradiction": 6.30794,
            "irrelevancy": 35.87276,
            "logical_agreement": 57.8193,
            "grammar_ref": 3.10421,
            "grammar_hyp": 3.53142,
            "nubia_score": 0.40227
        },
        "meteor": 0.1639346022909572,
        "bleurt": -0.24864
    },
    "totto_test_contrast_challenge_table_size-table_size_1820": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 21,
        "mean_pred_length": 21.0,
        "std_pred_length": 0.0,
        "median_pred_length": 21.0,
        "min_pred_length": 21,
        "max_pred_length": 21,
        "distinct-1": 1.0,
        "vocab_size-1": 21,
        "unique-1": 21,
        "entropy-1": 4.39231742277876,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.07038932789139804,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.07400058144377676,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.08246216019197297,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5793179973700684,
        "rouge1": {
            "precision": 0.35185,
            "recall": 0.65556,
            "fmeasure": 0.44911
        },
        "rouge2": {
            "precision": 0.11765,
            "recall": 0.2381,
            "fmeasure": 0.15412
        },
        "rougeL": {
            "precision": 0.2963,
            "recall": 0.55,
            "fmeasure": 0.37762
        },
        "rougeLsum": {
            "precision": 0.2963,
            "recall": 0.55,
            "fmeasure": 0.37762
        },
        "bleu": 6.10856,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.125,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.8447,
            "recall": 0.91294,
            "f1": 0.85524
        },
        "nubia": {
            "semantic_relation": 3.77469,
            "contradiction": 0.08234,
            "irrelevancy": 99.20021,
            "logical_agreement": 0.71746,
            "grammar_ref": 4.70243,
            "grammar_hyp": 4.66433,
            "nubia_score": 0.53654
        },
        "meteor": 0.26771224043348657,
        "bleurt": -0.243
    },
    "totto_test_contrast_challenge_table_size-table_size_2400": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4933241858860513,
        "rouge1": {
            "precision": 0.61538,
            "recall": 0.72727,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.41667,
            "recall": 0.5,
            "fmeasure": 0.45455
        },
        "rougeL": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "rougeLsum": {
            "precision": 0.46154,
            "recall": 0.54545,
            "fmeasure": 0.5
        },
        "bleu": 24.73998,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.88843,
            "recall": 0.93138,
            "f1": 0.9094
        },
        "nubia": {
            "semantic_relation": 4.42066,
            "contradiction": 0.81449,
            "irrelevancy": 98.13663,
            "logical_agreement": 1.04888,
            "grammar_ref": 5.42176,
            "grammar_hyp": 4.79244,
            "nubia_score": 0.74274
        },
        "meteor": 0.371818303440354,
        "bleurt": 0.17623
    },
    "totto_test_contrast_challenge_table_size-table_size_2422": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8666666666666667,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.640223928941851,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.18617861216337128,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.6770275517773454,
        "rouge1": {
            "precision": 0.75556,
            "recall": 0.727,
            "fmeasure": 0.7381
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.36111,
            "fmeasure": 0.36923
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.53243,
            "fmeasure": 0.54167
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.53243,
            "fmeasure": 0.54167
        },
        "bleu": 36.92326,
        "local_recall": {
            "1": 0.5,
            "2": 1.0,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.93249,
            "recall": 0.91213,
            "f1": 0.91841
        },
        "nubia": {
            "semantic_relation": 4.40013,
            "contradiction": 7.0063,
            "irrelevancy": 56.38929,
            "logical_agreement": 36.60441,
            "grammar_ref": 5.01319,
            "grammar_hyp": 4.57365,
            "nubia_score": 0.73728
        },
        "meteor": 0.32148994470991454,
        "bleurt": 0.19326
    },
    "totto_test_contrast_challenge_table_size-table_size_3204": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.925938214656137,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.67194,
            "irrelevancy": 0.62656,
            "logical_agreement": 98.70151,
            "grammar_ref": 3.94537,
            "grammar_hyp": 3.94537,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.92236
    },
    "totto_test_contrast_challenge_table_size-table_size_1685": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.04022392894185188,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3359255591449823,
        "rouge1": {
            "precision": 0.70833,
            "recall": 0.61319,
            "fmeasure": 0.65497
        },
        "rouge2": {
            "precision": 0.53333,
            "recall": 0.46032,
            "fmeasure": 0.49223
        },
        "rougeL": {
            "precision": 0.625,
            "recall": 0.54367,
            "fmeasure": 0.57948
        },
        "rougeLsum": {
            "precision": 0.625,
            "recall": 0.54367,
            "fmeasure": 0.57948
        },
        "bleu": 53.07894,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.92897,
            "recall": 0.92408,
            "f1": 0.92302
        },
        "nubia": {
            "semantic_relation": 4.4599,
            "contradiction": 27.90364,
            "irrelevancy": 11.17242,
            "logical_agreement": 60.92394,
            "grammar_ref": 3.28677,
            "grammar_hyp": 3.71481,
            "nubia_score": 0.81184
        },
        "meteor": 0.40785516903312163,
        "bleurt": 0.28767
    },
    "totto_test_contrast_challenge_table_size-table_size_2233": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.354990287206174,
        "rouge1": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rouge2": {
            "precision": 0.85,
            "recall": 0.81818,
            "fmeasure": 0.83333
        },
        "rougeL": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "rougeLsum": {
            "precision": 0.95455,
            "recall": 0.91667,
            "fmeasure": 0.93478
        },
        "bleu": 69.97522,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.95106,
            "recall": 0.98284,
            "f1": 0.96669
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.37452,
            "irrelevancy": 0.52123,
            "logical_agreement": 99.10425,
            "grammar_ref": 4.19853,
            "grammar_hyp": 3.27977,
            "nubia_score": 1.0
        },
        "meteor": 0.5740797318313066,
        "bleurt": 0.72733
    },
    "totto_test_contrast_challenge_table_size-table_size_1824": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 30,
        "mean_pred_length": 30.0,
        "std_pred_length": 0.0,
        "median_pred_length": 30.0,
        "min_pred_length": 30,
        "max_pred_length": 30,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 25,
        "unique-1": 21,
        "entropy-1": 4.548394345536403,
        "distinct-2": 1.0,
        "vocab_size-2": 29,
        "unique-2": 29,
        "entropy-2": 4.857980995127571,
        "cond_entropy-2": 0.32194858924882835,
        "distinct-3": 1.0,
        "vocab_size-3": 28,
        "unique-3": 28,
        "entropy-3": 4.807354922057606,
        "cond_entropy-3": -0.0506260730699678,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.9130434782608695,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.349648912578752,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.1176878443984663,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3518267643404203,
        "rouge1": {
            "precision": 0.6,
            "recall": 0.76842,
            "fmeasure": 0.67374
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.48538,
            "fmeasure": 0.42303
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.64079,
            "fmeasure": 0.56162
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.64079,
            "fmeasure": 0.56162
        },
        "bleu": 38.93836,
        "local_recall": {
            "1": 0.6666666666666666,
            "2": 0.7857142857142857
        },
        "bertscore": {
            "precision": 0.90923,
            "recall": 0.9297,
            "f1": 0.91935
        },
        "nubia": {
            "semantic_relation": 3.85626,
            "contradiction": 0.36158,
            "irrelevancy": 99.03101,
            "logical_agreement": 0.60741,
            "grammar_ref": 4.38153,
            "grammar_hyp": 4.65398,
            "nubia_score": 0.59977
        },
        "meteor": 0.3855762420207116,
        "bleurt": -0.05124
    },
    "totto_test_contrast_challenge_table_size-table_size_1304": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.458591205867174,
        "distinct-2": 0.8846153846153846,
        "vocab_size-2": 23,
        "unique-2": 20,
        "entropy-2": 4.46967048737186,
        "cond_entropy-2": 0.022475292900700425,
        "distinct-3": 0.92,
        "vocab_size-3": 23,
        "unique-3": 21,
        "entropy-3": 4.4838561897747224,
        "cond_entropy-3": 0.023416471633632495,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.251629167387823,
        "distinct-2-nopunct": 0.8695652173913043,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.2626923908396215,
        "cond_entropy-2-nopunct": 0.025555977074987163,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 20,
        "unique-3-nopunct": 18,
        "entropy-3-nopunct": 4.277613436819113,
        "cond_entropy-3-nopunct": 0.02677875348937534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6628239806414147,
        "rouge1": {
            "precision": 0.54321,
            "recall": 0.87619,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.29487,
            "recall": 0.49762,
            "fmeasure": 0.36812
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.72381,
            "fmeasure": 0.54762
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.72381,
            "fmeasure": 0.54762
        },
        "bleu": 28.75584,
        "local_recall": {
            "1": 0.0,
            "2": 0.4,
            "3": 0.8
        },
        "bertscore": {
            "precision": 0.7892,
            "recall": 0.94243,
            "f1": 0.84609
        },
        "nubia": {
            "semantic_relation": 3.68634,
            "contradiction": 43.87114,
            "irrelevancy": 49.49485,
            "logical_agreement": 6.63401,
            "grammar_ref": 3.44293,
            "grammar_hyp": 3.33529,
            "nubia_score": 0.56443
        },
        "meteor": 0.34832261539000003,
        "bleurt": -0.17524
    },
    "totto_test_contrast_challenge_table_size-table_size_1836": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.8662073121969907,
        "rouge1": {
            "precision": 0.60784,
            "recall": 0.4297,
            "fmeasure": 0.50305
        },
        "rouge2": {
            "precision": 0.22917,
            "recall": 0.15873,
            "fmeasure": 0.18739
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.25874,
            "fmeasure": 0.29815
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.25874,
            "fmeasure": 0.29815
        },
        "bleu": 10.18433,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 0.42105263157894735
        },
        "bertscore": {
            "precision": 0.87327,
            "recall": 0.83077,
            "f1": 0.85149
        },
        "nubia": {
            "semantic_relation": 3.40532,
            "contradiction": 0.3434,
            "irrelevancy": 99.31353,
            "logical_agreement": 0.34306,
            "grammar_ref": 4.82125,
            "grammar_hyp": 4.5097,
            "nubia_score": 0.43983
        },
        "meteor": 0.21214824805269494,
        "bleurt": -0.52304
    },
    "totto_test_contrast_challenge_table_size-table_size_3222": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.9,
        "vocab_size-1": 9,
        "unique-1": 8,
        "entropy-1": 3.121928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.8888888888888888,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.94770277922009,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": 0.08007499855768763,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8949781272722037,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.59524,
            "fmeasure": 0.74396
        },
        "rouge2": {
            "precision": 0.79167,
            "recall": 0.40271,
            "fmeasure": 0.53206
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.45333,
            "fmeasure": 0.62092
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.45333,
            "fmeasure": 0.62092
        },
        "bleu": 52.66231,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.93317,
            "recall": 0.8486,
            "f1": 0.88888
        },
        "nubia": {
            "semantic_relation": 3.20552,
            "contradiction": 24.62843,
            "irrelevancy": 4.66576,
            "logical_agreement": 70.70582,
            "grammar_ref": 3.09217,
            "grammar_hyp": 4.40114,
            "nubia_score": 0.35615
        },
        "meteor": 0.32549891790277724,
        "bleurt": -0.56343
    },
    "totto_test_contrast_challenge_table_size-table_size_2490": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.782608695652174,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 3.9318384571684564,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.554489684145594,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6461961952602273,
        "rouge1": {
            "precision": 0.29412,
            "recall": 0.16129,
            "fmeasure": 0.20833
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.13725,
            "recall": 0.16559,
            "fmeasure": 0.14043
        },
        "rougeLsum": {
            "precision": 0.13725,
            "recall": 0.16559,
            "fmeasure": 0.14043
        },
        "bleu": 4.79665,
        "local_recall": {
            "1": 0.0,
            "2": 0.21428571428571427,
            "3": 0.2222222222222222
        },
        "bertscore": {
            "precision": 0.82205,
            "recall": 0.78916,
            "f1": 0.78715
        },
        "nubia": {
            "semantic_relation": 1.75534,
            "contradiction": 64.96058,
            "irrelevancy": 32.06776,
            "logical_agreement": 2.97166,
            "grammar_ref": 4.34568,
            "grammar_hyp": 3.11132,
            "nubia_score": 0.15494
        },
        "meteor": 0.10346366664144258,
        "bleurt": -0.73841
    },
    "totto_test_contrast_challenge_table_size-table_size_2247": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 8.666666666666666,
        "std_pred_length": 0.4714045207910317,
        "median_pred_length": 9.0,
        "min_pred_length": 8,
        "max_pred_length": 9,
        "distinct-1": 0.5384615384615384,
        "vocab_size-1": 14,
        "unique-1": 7,
        "entropy-1": 3.632192121571194,
        "distinct-2": 0.6956521739130435,
        "vocab_size-2": 16,
        "unique-2": 11,
        "entropy-2": 3.8492239123906247,
        "cond_entropy-2": 0.1496341946257877,
        "distinct-3": 0.85,
        "vocab_size-3": 17,
        "unique-3": 14,
        "entropy-3": 4.021928094887363,
        "cond_entropy-3": 0.03611051393852278,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 0.5714285714285714,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.3913864699857177,
        "distinct-2-nopunct": 0.7777777777777778,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.68354236243323,
        "cond_entropy-2-nopunct": 0.19481730112615964,
        "distinct-3-nopunct": 0.8666666666666667,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.640223928941851,
        "cond_entropy-3-nopunct": 0.05395809431043744,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.108493809105611,
        "rouge1": {
            "precision": 0.81852,
            "recall": 0.64973,
            "fmeasure": 0.71602
        },
        "rouge2": {
            "precision": 0.58333,
            "recall": 0.46667,
            "fmeasure": 0.51273
        },
        "rougeL": {
            "precision": 0.81852,
            "recall": 0.64973,
            "fmeasure": 0.71602
        },
        "rougeLsum": {
            "precision": 0.81852,
            "recall": 0.64973,
            "fmeasure": 0.71602
        },
        "bleu": 29.72413,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333,
            "3": 0.5925925925925926
        },
        "bertscore": {
            "precision": 0.9548,
            "recall": 0.90701,
            "f1": 0.9292
        },
        "nubia": {
            "semantic_relation": 3.73202,
            "contradiction": 79.86892,
            "irrelevancy": 14.31338,
            "logical_agreement": 5.8177,
            "grammar_ref": 4.42296,
            "grammar_hyp": 4.40913,
            "nubia_score": 0.53064
        },
        "meteor": 0.4032486420694466,
        "bleurt": 0.33933
    },
    "totto_test_contrast_challenge_table_size-table_size_1310": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 10,
        "unique-1": 9,
        "entropy-1": 3.2776134368191165,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": 0.06249647625006499,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.9,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.121928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": 0.07021912877717246,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.548645758111165,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rouge2": {
            "precision": 0.88889,
            "recall": 0.8,
            "fmeasure": 0.84211
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.90909,
            "fmeasure": 0.95238
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98951,
            "recall": 0.9715,
            "f1": 0.98042
        },
        "nubia": {
            "semantic_relation": 4.65439,
            "contradiction": 0.55881,
            "irrelevancy": 1.76619,
            "logical_agreement": 97.675,
            "grammar_ref": 4.67316,
            "grammar_hyp": 4.54703,
            "nubia_score": 0.85279
        },
        "meteor": 0.5161210442123606,
        "bleurt": 0.7198
    },
    "totto_test_contrast_challenge_table_size-table_size_1688": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.4393391687433206,
        "rouge1": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "rouge2": {
            "precision": 0.30769,
            "recall": 0.25,
            "fmeasure": 0.27586
        },
        "rougeL": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "rougeLsum": {
            "precision": 0.35714,
            "recall": 0.29412,
            "fmeasure": 0.32258
        },
        "bleu": 20.23303,
        "local_recall": {
            "1": 0,
            "2": 0.4
        },
        "bertscore": {
            "precision": 0.83042,
            "recall": 0.80138,
            "f1": 0.81564
        },
        "nubia": {
            "semantic_relation": 2.2186,
            "contradiction": 83.60095,
            "irrelevancy": 15.37269,
            "logical_agreement": 1.02636,
            "grammar_ref": 4.28272,
            "grammar_hyp": 5.02915,
            "nubia_score": 0.13573
        },
        "meteor": 0.21934554315268176,
        "bleurt": -0.35456
    },
    "totto_test_contrast_challenge_table_size-table_size_938": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.09400842804332116,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.206852187050286,
        "rouge1": {
            "precision": 0.9375,
            "recall": 0.57692,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.86667,
            "recall": 0.52,
            "fmeasure": 0.65
        },
        "rougeL": {
            "precision": 0.9375,
            "recall": 0.57692,
            "fmeasure": 0.71429
        },
        "rougeLsum": {
            "precision": 0.9375,
            "recall": 0.57692,
            "fmeasure": 0.71429
        },
        "bleu": 38.35299,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.5833333333333334
        },
        "bertscore": {
            "precision": 0.98262,
            "recall": 0.84431,
            "f1": 0.90823
        },
        "nubia": {
            "semantic_relation": 3.4477,
            "contradiction": 0.2143,
            "irrelevancy": 0.40147,
            "logical_agreement": 99.38423,
            "grammar_ref": 4.59074,
            "grammar_hyp": 4.45038,
            "nubia_score": 0.52911
        },
        "meteor": 0.33185849235501275,
        "bleurt": -0.05737
    },
    "totto_test_contrast_challenge_table_size-table_size_2248": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.046930949929641655,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.546593564294939,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9991662387674958,
        "rouge1": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.90909,
            "fmeasure": 0.86957
        },
        "rougeL": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "rougeLsum": {
            "precision": 0.92308,
            "recall": 1.0,
            "fmeasure": 0.96
        },
        "bleu": 54.45179,
        "local_recall": {
            "1": 0,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97343,
            "recall": 0.97664,
            "f1": 0.97503
        },
        "nubia": {
            "semantic_relation": 4.31239,
            "contradiction": 11.29198,
            "irrelevancy": 84.38835,
            "logical_agreement": 4.31966,
            "grammar_ref": 4.85772,
            "grammar_hyp": 5.14735,
            "nubia_score": 0.58383
        },
        "meteor": 0.5777337135978416,
        "bleurt": 0.49208
    },
    "totto_test_contrast_challenge_table_size-table_size_940": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.0433214693062285,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.4870502775872776,
        "rouge1": {
            "precision": 0.77778,
            "recall": 0.69975,
            "fmeasure": 0.73656
        },
        "rouge2": {
            "precision": 0.42857,
            "recall": 0.39167,
            "fmeasure": 0.4092
        },
        "rougeL": {
            "precision": 0.6,
            "recall": 0.55147,
            "fmeasure": 0.5746
        },
        "rougeLsum": {
            "precision": 0.6,
            "recall": 0.55147,
            "fmeasure": 0.5746
        },
        "bleu": 24.79116,
        "local_recall": {
            "1": 0.0,
            "2": 0.14285714285714285,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.93417,
            "recall": 0.92565,
            "f1": 0.92989
        },
        "nubia": {
            "semantic_relation": 4.38623,
            "contradiction": 0.19646,
            "irrelevancy": 18.93279,
            "logical_agreement": 80.87075,
            "grammar_ref": 3.5564,
            "grammar_hyp": 3.72051,
            "nubia_score": 0.85291
        },
        "meteor": 0.3796239448790309,
        "bleurt": 0.36464
    },
    "totto_test_contrast_challenge_table_size-table_size_3432": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.8823529411764706,
        "vocab_size-1": 15,
        "unique-1": 14,
        "entropy-1": 3.807763576417195,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.20971762763487733,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.702819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.22388309575274976,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.793211425018427,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.81111,
            "fmeasure": 0.72989
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.61905,
            "fmeasure": 0.57778
        },
        "rougeL": {
            "precision": 0.5098,
            "recall": 0.67778,
            "fmeasure": 0.58046
        },
        "rougeLsum": {
            "precision": 0.5098,
            "recall": 0.67778,
            "fmeasure": 0.58046
        },
        "bleu": 37.08164,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.92699,
            "recall": 0.94638,
            "f1": 0.93659
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.17944,
            "irrelevancy": 32.83587,
            "logical_agreement": 66.98469,
            "grammar_ref": 4.47457,
            "grammar_hyp": 3.33025,
            "nubia_score": 1.0
        },
        "meteor": 0.46187159024588426,
        "bleurt": 0.54861
    },
    "totto_test_contrast_challenge_table_size-table_size_1315": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4750342424108394,
        "rouge1": {
            "precision": 0.56667,
            "recall": 0.80556,
            "fmeasure": 0.65152
        },
        "rouge2": {
            "precision": 0.2963,
            "recall": 0.46061,
            "fmeasure": 0.35238
        },
        "rougeL": {
            "precision": 0.43333,
            "recall": 0.58333,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.43333,
            "recall": 0.58333,
            "fmeasure": 0.48485
        },
        "bleu": 13.49277,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.3333333333333333,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.85921,
            "recall": 0.91534,
            "f1": 0.87223
        },
        "nubia": {
            "semantic_relation": 4.41602,
            "contradiction": 4.30121,
            "irrelevancy": 64.9026,
            "logical_agreement": 30.79619,
            "grammar_ref": 5.75818,
            "grammar_hyp": 4.90912,
            "nubia_score": 0.79964
        },
        "meteor": 0.42919650333815856,
        "bleurt": 0.09151
    },
    "totto_test_contrast_challenge_table_size-table_size_1692": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 12.5,
        "std_pred_length": 3.5,
        "median_pred_length": 12.5,
        "min_pred_length": 9,
        "max_pred_length": 16,
        "distinct-1": 0.96,
        "vocab_size-1": 24,
        "unique-1": 23,
        "entropy-1": 4.5638561897747225,
        "distinct-2": 1.0,
        "vocab_size-2": 23,
        "unique-2": 23,
        "entropy-2": 4.523561956057013,
        "cond_entropy-2": -0.12029423371771175,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.1312445332782524,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 23,
        "unique-1-nopunct": 23,
        "entropy-1-nopunct": 4.523561956057013,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": -0.1312445332782524,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8461935620361927,
        "rouge1": {
            "precision": 0.60294,
            "recall": 0.52424,
            "fmeasure": 0.55923
        },
        "rouge2": {
            "precision": 0.42411,
            "recall": 0.37026,
            "fmeasure": 0.39405
        },
        "rougeL": {
            "precision": 0.60294,
            "recall": 0.52424,
            "fmeasure": 0.55923
        },
        "rougeLsum": {
            "precision": 0.60294,
            "recall": 0.52424,
            "fmeasure": 0.55923
        },
        "bleu": 28.36464,
        "local_recall": {
            "1": 0.0,
            "2": 0.3684210526315789,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.89422,
            "recall": 0.87927,
            "f1": 0.88664
        },
        "nubia": {
            "semantic_relation": 3.97499,
            "contradiction": 7.21352,
            "irrelevancy": 54.85626,
            "logical_agreement": 37.93022,
            "grammar_ref": 5.11675,
            "grammar_hyp": 5.07295,
            "nubia_score": 0.58704
        },
        "meteor": 0.28235427069602365,
        "bleurt": -0.03534
    },
    "totto_test_contrast_challenge_table_size-table_size_945": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 4.0,
        "median_pred_length": 13.0,
        "min_pred_length": 9,
        "max_pred_length": 17,
        "distinct-1": 0.8461538461538461,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.363713275750188,
        "distinct-2": 1.0,
        "vocab_size-2": 24,
        "unique-2": 24,
        "entropy-2": 4.584962500721156,
        "cond_entropy-2": 0.165976428503542,
        "distinct-3": 1.0,
        "vocab_size-3": 22,
        "unique-3": 22,
        "entropy-3": 4.459431618637295,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.229871195093384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 21,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.39231742277876,
        "cond_entropy-2-nopunct": 0.19041677634857931,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.14438990933517493,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.672656058903618,
        "rouge1": {
            "precision": 0.68333,
            "recall": 0.65801,
            "fmeasure": 0.66597
        },
        "rouge2": {
            "precision": 0.35714,
            "recall": 0.33578,
            "fmeasure": 0.34215
        },
        "rougeL": {
            "precision": 0.425,
            "recall": 0.40747,
            "fmeasure": 0.41298
        },
        "rougeLsum": {
            "precision": 0.425,
            "recall": 0.40747,
            "fmeasure": 0.41298
        },
        "bleu": 42.31179,
        "local_recall": {
            "1": 0.0,
            "2": 0.125,
            "3": 0.7894736842105263
        },
        "bertscore": {
            "precision": 0.92162,
            "recall": 0.91215,
            "f1": 0.91683
        },
        "nubia": {
            "semantic_relation": 3.45644,
            "contradiction": 18.58465,
            "irrelevancy": 5.56896,
            "logical_agreement": 75.84639,
            "grammar_ref": 4.25678,
            "grammar_hyp": 4.08447,
            "nubia_score": 0.52246
        },
        "meteor": 0.3810013408025768,
        "bleurt": 0.27994
    },
    "totto_test_contrast_challenge_table_size-table_size_2260": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.614827668236417,
        "rouge1": {
            "precision": 0.61111,
            "recall": 0.6875,
            "fmeasure": 0.64706
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.57143,
            "fmeasure": 0.53333
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.6875,
            "fmeasure": 0.64706
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.6875,
            "fmeasure": 0.64706
        },
        "bleu": 78.25423,
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.93983,
            "recall": 0.98617,
            "f1": 0.96244
        },
        "nubia": {
            "semantic_relation": 3.99913,
            "contradiction": 37.37163,
            "irrelevancy": 61.33586,
            "logical_agreement": 1.29251,
            "grammar_ref": 5.57872,
            "grammar_hyp": 5.35509,
            "nubia_score": 0.57615
        },
        "meteor": 0.5430106152849822,
        "bleurt": 0.41772
    },
    "totto_test_contrast_challenge_table_size-table_size_2640": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1566687205209765,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.81818,
            "fmeasure": 0.9
        },
        "rouge2": {
            "precision": 0.875,
            "recall": 0.7,
            "fmeasure": 0.77778
        },
        "rougeL": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "rougeLsum": {
            "precision": 0.77778,
            "recall": 0.63636,
            "fmeasure": 0.7
        },
        "bleu": 59.2065,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.96496,
            "recall": 0.93489,
            "f1": 0.94969
        },
        "nubia": {
            "semantic_relation": 4.26096,
            "contradiction": 0.80225,
            "irrelevancy": 0.51437,
            "logical_agreement": 98.68338,
            "grammar_ref": 5.20642,
            "grammar_hyp": 4.89549,
            "nubia_score": 0.76313
        },
        "meteor": 0.4603105469113841,
        "bleurt": 0.46434
    },
    "totto_test_contrast_challenge_table_size-table_size_3479": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.2948525163479814,
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.46579,
            "fmeasure": 0.4955
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.1462,
            "fmeasure": 0.15574
        },
        "rougeL": {
            "precision": 0.47059,
            "recall": 0.41404,
            "fmeasure": 0.44044
        },
        "rougeLsum": {
            "precision": 0.47059,
            "recall": 0.41404,
            "fmeasure": 0.44044
        },
        "bleu": 10.87406,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.80902,
            "recall": 0.77916,
            "f1": 0.79381
        },
        "nubia": {
            "semantic_relation": 3.75615,
            "contradiction": 0.14988,
            "irrelevancy": 99.24648,
            "logical_agreement": 0.60364,
            "grammar_ref": 4.62058,
            "grammar_hyp": 5.10592,
            "nubia_score": 0.51566
        },
        "meteor": 0.2656647705110374,
        "bleurt": -0.16342
    },
    "totto_test_contrast_challenge_table_size-table_size_952": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7609861280393986,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.46154,
            "fmeasure": 0.48
        },
        "rouge2": {
            "precision": 0.18182,
            "recall": 0.2037,
            "fmeasure": 0.1913
        },
        "rougeL": {
            "precision": 0.41667,
            "recall": 0.38462,
            "fmeasure": 0.4
        },
        "rougeLsum": {
            "precision": 0.41667,
            "recall": 0.38462,
            "fmeasure": 0.4
        },
        "bleu": 8.13085,
        "local_recall": {
            "1": 0.0,
            "2": 0.16666666666666666,
            "3": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.8866,
            "recall": 0.86039,
            "f1": 0.8733
        },
        "nubia": {
            "semantic_relation": 3.55137,
            "contradiction": 2.8639,
            "irrelevancy": 96.0266,
            "logical_agreement": 1.1095,
            "grammar_ref": 5.35395,
            "grammar_hyp": 4.15651,
            "nubia_score": 0.57012
        },
        "meteor": 0.25360827784083245,
        "bleurt": -0.16593
    },
    "totto_test_contrast_challenge_table_size-table_size_2262": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.726653922371403,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.76667,
            "fmeasure": 0.77571
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.66667,
            "fmeasure": 0.63158
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "bleu": 42.48182,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.95104,
            "recall": 0.91636,
            "f1": 0.93338
        },
        "nubia": {
            "semantic_relation": 3.72635,
            "contradiction": 63.88918,
            "irrelevancy": 2.07709,
            "logical_agreement": 34.03374,
            "grammar_ref": 5.64952,
            "grammar_hyp": 5.0353,
            "nubia_score": 0.5001
        },
        "meteor": 0.3974055482569606,
        "bleurt": 0.37449
    },
    "totto_test_contrast_challenge_table_size-table_size_1700": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.002050234128916,
        "rouge1": {
            "precision": 0.78788,
            "recall": 0.86667,
            "fmeasure": 0.8254
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.55556,
            "fmeasure": 0.52632
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.8,
            "fmeasure": 0.7619
        },
        "bleu": 47.71897,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.97616,
            "recall": 0.98622,
            "f1": 0.98117
        },
        "nubia": {
            "semantic_relation": 4.98105,
            "contradiction": 0.76963,
            "irrelevancy": 2.33909,
            "logical_agreement": 96.89127,
            "grammar_ref": 5.6957,
            "grammar_hyp": 4.92831,
            "nubia_score": 0.97643
        },
        "meteor": 0.5065961021026699,
        "bleurt": 0.26752
    },
    "totto_test_contrast_challenge_table_size-table_size_2667": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.65,
        "vocab_size-1": 13,
        "unique-1": 6,
        "entropy-1": 3.621928094887362,
        "distinct-2": 0.7222222222222222,
        "vocab_size-2": 13,
        "unique-2": 8,
        "entropy-2": 3.6143694458867563,
        "cond_entropy-2": -0.040891982333938655,
        "distinct-3": 0.8125,
        "vocab_size-3": 13,
        "unique-3": 10,
        "entropy-3": 3.625,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.6666666666666666,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 3.503258334775645,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.5,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.521640636343319,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9641745672222544,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.89899,
            "fmeasure": 0.94678
        },
        "rouge2": {
            "precision": 0.70635,
            "recall": 0.64352,
            "fmeasure": 0.6729
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.80808,
            "fmeasure": 0.85154
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.80808,
            "fmeasure": 0.85154
        },
        "bleu": 59.92675,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 0.9411764705882353
        },
        "bertscore": {
            "precision": 0.98234,
            "recall": 0.96872,
            "f1": 0.97417
        },
        "nubia": {
            "semantic_relation": 4.9709,
            "contradiction": 0.94785,
            "irrelevancy": 5.9241,
            "logical_agreement": 93.12805,
            "grammar_ref": 4.57714,
            "grammar_hyp": 4.6621,
            "nubia_score": 0.97614
        },
        "meteor": 0.45456107609179663,
        "bleurt": 0.79429
    },
    "totto_test_contrast_challenge_table_size-table_size_1730": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 3,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 47,
        "mean_pred_length": 15.666666666666666,
        "std_pred_length": 3.39934634239519,
        "median_pred_length": 17.0,
        "min_pred_length": 11,
        "max_pred_length": 19,
        "distinct-1": 0.5957446808510638,
        "vocab_size-1": 28,
        "unique-1": 18,
        "entropy-1": 4.580664649319822,
        "distinct-2": 0.8181818181818182,
        "vocab_size-2": 36,
        "unique-2": 30,
        "entropy-2": 5.061482186720774,
        "cond_entropy-2": 0.4391558352398174,
        "distinct-3": 0.8536585365853658,
        "vocab_size-3": 35,
        "unique-3": 30,
        "entropy-3": 5.046457187492143,
        "cond_entropy-3": -0.03468723591766563,
        "total_length-nopunct": 41,
        "mean_pred_length-nopunct": 13.666666666666666,
        "std_pred_length-nopunct": 2.6246692913372702,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.6341463414634146,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.473048041045146,
        "distinct-2-nopunct": 0.8157894736842105,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 4.83977553964551,
        "cond_entropy-2-nopunct": 0.3839251799350668,
        "distinct-3-nopunct": 0.8571428571428571,
        "vocab_size-3-nopunct": 30,
        "unique-3-nopunct": 26,
        "entropy-3-nopunct": 4.822000516883151,
        "cond_entropy-3-nopunct": -0.039933425008234144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.599719022129696,
        "rouge1": {
            "precision": 0.73009,
            "recall": 0.65415,
            "fmeasure": 0.68887
        },
        "rouge2": {
            "precision": 0.53545,
            "recall": 0.49101,
            "fmeasure": 0.51109
        },
        "rougeL": {
            "precision": 0.65139,
            "recall": 0.61095,
            "fmeasure": 0.62965
        },
        "rougeLsum": {
            "precision": 0.65139,
            "recall": 0.61095,
            "fmeasure": 0.62965
        },
        "bleu": 45.37889,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.5,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.89801,
            "recall": 0.88929,
            "f1": 0.8917
        },
        "nubia": {
            "semantic_relation": 3.58818,
            "contradiction": 45.82485,
            "irrelevancy": 13.93868,
            "logical_agreement": 40.23647,
            "grammar_ref": 4.73012,
            "grammar_hyp": 4.28293,
            "nubia_score": 0.53225
        },
        "meteor": 0.31080045655730676,
        "bleurt": 0.0562
    },
    "totto_test_contrast_challenge_table_size-table_size_960": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 4,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 42,
        "mean_pred_length": 10.5,
        "std_pred_length": 2.5,
        "median_pred_length": 10.5,
        "min_pred_length": 8,
        "max_pred_length": 13,
        "distinct-1": 0.7142857142857143,
        "vocab_size-1": 30,
        "unique-1": 21,
        "entropy-1": 4.755296291774869,
        "distinct-2": 0.8947368421052632,
        "vocab_size-2": 34,
        "unique-2": 30,
        "entropy-2": 5.0374011976541135,
        "cond_entropy-2": 0.13863344598491642,
        "distinct-3": 0.9117647058823529,
        "vocab_size-3": 31,
        "unique-3": 28,
        "entropy-3": 4.910992253015044,
        "cond_entropy-3": -0.10164114278148137,
        "total_length-nopunct": 37,
        "mean_pred_length-nopunct": 9.25,
        "std_pred_length-nopunct": 2.277608394786075,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.7567567567567568,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.702564514219129,
        "distinct-2-nopunct": 0.8787878787878788,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 25,
        "entropy-2-nopunct": 4.801969876934213,
        "cond_entropy-2-nopunct": 0.13054340531021497,
        "distinct-3-nopunct": 0.896551724137931,
        "vocab_size-3-nopunct": 26,
        "unique-3-nopunct": 23,
        "entropy-3-nopunct": 4.651084443403434,
        "cond_entropy-3-nopunct": -0.1519303656101918,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.278841376843744,
        "rouge1": {
            "precision": 0.95486,
            "recall": 0.87106,
            "fmeasure": 0.90097
        },
        "rouge2": {
            "precision": 0.94156,
            "recall": 0.81944,
            "fmeasure": 0.85167
        },
        "rougeL": {
            "precision": 0.95486,
            "recall": 0.83797,
            "fmeasure": 0.87077
        },
        "rougeLsum": {
            "precision": 0.95486,
            "recall": 0.83797,
            "fmeasure": 0.87077
        },
        "bleu": 83.14507,
        "local_recall": {
            "1": 0.3,
            "2": 0.16666666666666666,
            "3": 0.9166666666666666
        },
        "bertscore": {
            "precision": 0.99244,
            "recall": 0.98117,
            "f1": 0.98667
        },
        "nubia": {
            "semantic_relation": 4.8368,
            "contradiction": 7.19856,
            "irrelevancy": 8.39973,
            "logical_agreement": 84.40171,
            "grammar_ref": 4.5734,
            "grammar_hyp": 4.74109,
            "nubia_score": 0.92798
        },
        "meteor": 0.586342198391051,
        "bleurt": 0.68064
    },
    "totto_test_contrast_challenge_table_size-table_size_2681": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.6693473839796296,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.51961,
            "fmeasure": 0.65873
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.36765,
            "fmeasure": 0.47385
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.51961,
            "fmeasure": 0.65873
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.51961,
            "fmeasure": 0.65873
        },
        "bleu": 34.3148,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5294117647058824
        },
        "bertscore": {
            "precision": 0.97125,
            "recall": 0.91047,
            "f1": 0.93988
        },
        "nubia": {
            "semantic_relation": 3.80589,
            "contradiction": 0.11994,
            "irrelevancy": 0.46188,
            "logical_agreement": 99.41818,
            "grammar_ref": 4.84215,
            "grammar_hyp": 6.11156,
            "nubia_score": 0.45645
        },
        "meteor": 0.40726559253575056,
        "bleurt": 0.15013
    },
    "totto_test_contrast_challenge_table_size-table_size_3492": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0088906840841796,
        "rouge1": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.63636,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "rougeLsum": {
            "precision": 0.81818,
            "recall": 0.75,
            "fmeasure": 0.78261
        },
        "bleu": 58.33511,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.97213,
            "recall": 0.96481,
            "f1": 0.96846
        },
        "nubia": {
            "semantic_relation": 4.98921,
            "contradiction": 0.42473,
            "irrelevancy": 22.33974,
            "logical_agreement": 77.23553,
            "grammar_ref": 4.14586,
            "grammar_hyp": 3.79251,
            "nubia_score": 1.0
        },
        "meteor": 0.4630505936482093,
        "bleurt": 0.7528
    },
    "totto_test_contrast_challenge_table_size-table_size_1320": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 10,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 10,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.321928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 9,
        "entropy-2-nopunct": 3.169925001442312,
        "cond_entropy-2-nopunct": -0.15200309344504973,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 8,
        "entropy-3-nopunct": 3.0,
        "cond_entropy-3-nopunct": -0.16992500144231237,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2860710481699047,
        "rouge1": {
            "precision": 0.63636,
            "recall": 0.76282,
            "fmeasure": 0.68567
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.58286,
            "fmeasure": 0.54454
        },
        "rougeL": {
            "precision": 0.72727,
            "recall": 0.71154,
            "fmeasure": 0.67141
        },
        "rougeLsum": {
            "precision": 0.72727,
            "recall": 0.71154,
            "fmeasure": 0.67141
        },
        "bleu": 75.33808,
        "local_recall": {
            "1": 0.21052631578947367,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96671,
            "recall": 0.96947,
            "f1": 0.94794
        },
        "nubia": {
            "semantic_relation": 4.13404,
            "contradiction": 0.15948,
            "irrelevancy": 0.41726,
            "logical_agreement": 99.42326,
            "grammar_ref": 4.62626,
            "grammar_hyp": 4.25404,
            "nubia_score": 0.74012
        },
        "meteor": 0.506755908421319,
        "bleurt": 0.29806
    },
    "totto_test_contrast_challenge_table_size-table_size_3540": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.462425934400558,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rouge2": {
            "precision": 0.94444,
            "recall": 0.90476,
            "fmeasure": 0.92308
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.95833,
            "fmeasure": 0.97778
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.21715,
            "contradiction": 0.42269,
            "irrelevancy": 0.62596,
            "logical_agreement": 98.95136,
            "grammar_ref": 6.37596,
            "grammar_hyp": 6.07415,
            "nubia_score": 0.84205
        },
        "meteor": 1.0,
        "bleurt": 0.45919
    },
    "totto_test_contrast_challenge_table_size-table_size_2682": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.981172011364361,
        "rouge1": {
            "precision": 0.73333,
            "recall": 0.74762,
            "fmeasure": 0.74023
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.38828,
            "fmeasure": 0.38448
        },
        "rougeL": {
            "precision": 0.42222,
            "recall": 0.43016,
            "fmeasure": 0.42605
        },
        "rougeLsum": {
            "precision": 0.42222,
            "recall": 0.43016,
            "fmeasure": 0.42605
        },
        "bleu": 27.05411,
        "local_recall": {
            "1": 0.5555555555555556,
            "2": 1.0,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.90048,
            "recall": 0.87141,
            "f1": 0.88571
        },
        "nubia": {
            "semantic_relation": 3.5017,
            "contradiction": 3.40721,
            "irrelevancy": 78.53402,
            "logical_agreement": 18.05877,
            "grammar_ref": 4.11472,
            "grammar_hyp": 3.67311,
            "nubia_score": 0.59414
        },
        "meteor": 0.36188763549829,
        "bleurt": -0.07604
    },
    "totto_test_contrast_challenge_table_size-table_size_1330": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 3.5,
        "median_pred_length": 11.5,
        "min_pred_length": 8,
        "max_pred_length": 15,
        "distinct-1": 0.7391304347826086,
        "vocab_size-1": 17,
        "unique-1": 11,
        "entropy-1": 4.001822825622231,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 19,
        "unique-2": 17,
        "entropy-2": 4.201841232302569,
        "cond_entropy-2": 0.15446975243603328,
        "distinct-3": 0.9473684210526315,
        "vocab_size-3": 18,
        "unique-3": 17,
        "entropy-3": 4.142664355548846,
        "cond_entropy-3": -0.03912675144043809,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 10.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 10.5,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.7619047619047619,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.916126946588283,
        "distinct-2-nopunct": 0.8947368421052632,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 4.03740119765411,
        "cond_entropy-2-nopunct": 0.11876798540166715,
        "distinct-3-nopunct": 0.9411764705882353,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.969815782426811,
        "cond_entropy-3-nopunct": -0.10164114278148141,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8919595281085853,
        "rouge1": {
            "precision": 0.80952,
            "recall": 0.6835,
            "fmeasure": 0.73515
        },
        "rouge2": {
            "precision": 0.61325,
            "recall": 0.51083,
            "fmeasure": 0.55225
        },
        "rougeL": {
            "precision": 0.71429,
            "recall": 0.63399,
            "fmeasure": 0.66839
        },
        "rougeLsum": {
            "precision": 0.71429,
            "recall": 0.63399,
            "fmeasure": 0.66839
        },
        "bleu": 19.49896,
        "local_recall": {
            "1": 0.2,
            "2": 0.5,
            "3": 0.7368421052631579
        },
        "bertscore": {
            "precision": 0.92093,
            "recall": 0.88323,
            "f1": 0.90051
        },
        "nubia": {
            "semantic_relation": 4.49893,
            "contradiction": 1.39334,
            "irrelevancy": 15.82596,
            "logical_agreement": 82.7807,
            "grammar_ref": 6.00658,
            "grammar_hyp": 6.42918,
            "nubia_score": 0.76498
        },
        "meteor": 0.37431362575608035,
        "bleurt": -0.13008
    },
    "totto_test_contrast_challenge_table_size-table_size_1359": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 1.0,
        "vocab_size-1": 20,
        "unique-1": 20,
        "entropy-1": 4.321928094887363,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": -0.07400058144377676,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 17,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.08746284125034,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": -0.08746284125033939,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5392322670837686,
        "rouge1": {
            "precision": 0.61765,
            "recall": 0.72619,
            "fmeasure": 0.66734
        },
        "rouge2": {
            "precision": 0.28125,
            "recall": 0.33791,
            "fmeasure": 0.3069
        },
        "rougeL": {
            "precision": 0.61765,
            "recall": 0.72619,
            "fmeasure": 0.66734
        },
        "rougeLsum": {
            "precision": 0.61765,
            "recall": 0.72619,
            "fmeasure": 0.66734
        },
        "bleu": 34.35599,
        "local_recall": {
            "1": 0.6,
            "2": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.8917,
            "recall": 0.91141,
            "f1": 0.90145
        },
        "nubia": {
            "semantic_relation": 4.50916,
            "contradiction": 0.25282,
            "irrelevancy": 66.94093,
            "logical_agreement": 32.80625,
            "grammar_ref": 5.03823,
            "grammar_hyp": 4.25714,
            "nubia_score": 0.91106
        },
        "meteor": 0.4358052291427772,
        "bleurt": 0.30026
    },
    "totto_test_contrast_challenge_table_size-table_size_966": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.773557262275185,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.0433214693062285,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.355696015088277,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.76923,
            "recall": 0.76923,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "bleu": 72.41577,
        "local_recall": {
            "1": 0,
            "2": 0.6,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96978,
            "recall": 0.99535,
            "f1": 0.9686
        },
        "nubia": {
            "semantic_relation": 4.63886,
            "contradiction": 5.37019,
            "irrelevancy": 35.26091,
            "logical_agreement": 59.3689,
            "grammar_ref": 6.35753,
            "grammar_hyp": 6.48212,
            "nubia_score": 0.76823
        },
        "meteor": 0.5257043737612862,
        "bleurt": 0.52375
    },
    "totto_test_contrast_challenge_table_size-table_size_2280": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.051189449246730745,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322734,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.867976246918685,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.77875,
            "contradiction": 0.20639,
            "irrelevancy": 0.55532,
            "logical_agreement": 99.23829,
            "grammar_ref": 4.35803,
            "grammar_hyp": 4.93905,
            "nubia_score": 0.9019
        },
        "meteor": 1.0,
        "bleurt": 0.73788
    },
    "totto_test_contrast_challenge_table_size-table_size_2718": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3219280948873626,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.29478,
            "irrelevancy": 0.49577,
            "logical_agreement": 99.20945,
            "grammar_ref": 4.98947,
            "grammar_hyp": 4.98947,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.97683
    },
    "totto_test_contrast_challenge_table_size-table_size_1379": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 25,
        "mean_pred_length": 25.0,
        "std_pred_length": 0.0,
        "median_pred_length": 25.0,
        "min_pred_length": 25,
        "max_pred_length": 25,
        "distinct-1": 0.88,
        "vocab_size-1": 22,
        "unique-1": 19,
        "entropy-1": 4.403856189774722,
        "distinct-2": 0.9583333333333334,
        "vocab_size-2": 23,
        "unique-2": 22,
        "entropy-2": 4.501629167387823,
        "cond_entropy-2": 0.10777297761309831,
        "distinct-3": 1.0,
        "vocab_size-3": 23,
        "unique-3": 23,
        "entropy-3": 4.523561956057013,
        "cond_entropy-3": 0.02555597707498716,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 24.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 24,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 21,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.334962500721156,
        "distinct-2-nopunct": 0.9565217391304348,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 21,
        "entropy-2-nopunct": 4.436605434317882,
        "cond_entropy-2-nopunct": 0.11251249881411754,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 22,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.459431618637295,
        "cond_entropy-3-nopunct": 0.02677875348937534,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.128438342382429,
        "rouge1": {
            "precision": 0.83333,
            "recall": 0.74074,
            "fmeasure": 0.78431
        },
        "rouge2": {
            "precision": 0.69565,
            "recall": 0.61538,
            "fmeasure": 0.65306
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 0.66667,
            "fmeasure": 0.70588
        },
        "bleu": 45.72098,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8095238095238095
        },
        "bertscore": {
            "precision": 0.95419,
            "recall": 0.92743,
            "f1": 0.939
        },
        "nubia": {
            "semantic_relation": 4.24469,
            "contradiction": 0.12411,
            "irrelevancy": 3.95521,
            "logical_agreement": 95.92067,
            "grammar_ref": 4.19464,
            "grammar_hyp": 4.58259,
            "nubia_score": 0.69082
        },
        "meteor": 0.40912829062781597,
        "bleurt": 0.22586
    },
    "totto_test_contrast_challenge_table_size-table_size_1840": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.625,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.66667,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.85714,
            "fmeasure": 0.85714
        },
        "bleu": 59.46036,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.97522,
            "recall": 0.97522,
            "f1": 0.97522
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.78492,
            "irrelevancy": 0.54406,
            "logical_agreement": 98.67101,
            "grammar_ref": 4.38626,
            "grammar_hyp": 4.3113,
            "nubia_score": 1.0
        },
        "meteor": 0.9555555555555555,
        "bleurt": 0.90115
    },
    "totto_test_contrast_challenge_table_size-table_size_2282": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9844191482520275,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.41176,
            "fmeasure": 0.45161
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.1875,
            "fmeasure": 0.2069
        },
        "rougeL": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "rougeLsum": {
            "precision": 0.42857,
            "recall": 0.35294,
            "fmeasure": 0.3871
        },
        "bleu": 10.94033,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.87488,
            "recall": 0.83537,
            "f1": 0.85467
        },
        "nubia": {
            "semantic_relation": 2.78557,
            "contradiction": 98.89006,
            "irrelevancy": 0.97274,
            "logical_agreement": 0.1372,
            "grammar_ref": 3.64996,
            "grammar_hyp": 3.76829,
            "nubia_score": 0.33104
        },
        "meteor": 0.2094071498957641,
        "bleurt": -0.24626
    },
    "totto_test_contrast_challenge_table_size-table_size_968": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2679466535934152,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.47826,
            "fmeasure": 0.62857
        },
        "rouge2": {
            "precision": 0.54545,
            "recall": 0.34091,
            "fmeasure": 0.41751
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 0.47826,
            "fmeasure": 0.62857
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 0.47826,
            "fmeasure": 0.62857
        },
        "bleu": 33.51193,
        "local_recall": {
            "1": 0,
            "2": 0.6666666666666666,
            "3": 0.5625
        },
        "bertscore": {
            "precision": 0.9768,
            "recall": 0.91895,
            "f1": 0.93958
        },
        "nubia": {
            "semantic_relation": 3.82609,
            "contradiction": 36.72159,
            "irrelevancy": 2.19958,
            "logical_agreement": 61.07883,
            "grammar_ref": 4.20692,
            "grammar_hyp": 4.82471,
            "nubia_score": 0.49648
        },
        "meteor": 0.3510855547863479,
        "bleurt": 0.37571
    },
    "totto_test_contrast_challenge_table_size-table_size_2884": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941851,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337128,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.2007771037757955,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0480981409606436,
        "rouge1": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "rouge2": {
            "precision": 0.07692,
            "recall": 0.07143,
            "fmeasure": 0.07407
        },
        "rougeL": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "rougeLsum": {
            "precision": 0.21429,
            "recall": 0.2,
            "fmeasure": 0.2069
        },
        "bleu": 5.84728,
        "local_recall": {
            "1": 0.0,
            "2": 0.25
        },
        "bertscore": {
            "precision": 0.78357,
            "recall": 0.77779,
            "f1": 0.77822
        },
        "nubia": {
            "semantic_relation": 2.25701,
            "contradiction": 0.40226,
            "irrelevancy": 99.05462,
            "logical_agreement": 0.54312,
            "grammar_ref": 5.48676,
            "grammar_hyp": 4.71865,
            "nubia_score": 0.22654
        },
        "meteor": 0.11564440949896566,
        "bleurt": -0.38075
    },
    "totto_test_contrast_challenge_table_size-table_size_2290": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.8125,
        "vocab_size-1": 13,
        "unique-1": 10,
        "entropy-1": 3.625,
        "distinct-2": 0.9333333333333333,
        "vocab_size-2": 14,
        "unique-2": 13,
        "entropy-2": 3.773557262275185,
        "cond_entropy-2": 0.17355726227518525,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": 0.043321469306228495,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.8,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.5068905956085183,
        "distinct-2-nopunct": 0.9285714285714286,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.6644977792004623,
        "cond_entropy-2-nopunct": 0.11475004073479993,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": 0.04693094992964167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9647115390227494,
        "rouge1": {
            "precision": 0.93651,
            "recall": 0.86759,
            "fmeasure": 0.90063
        },
        "rouge2": {
            "precision": 0.71667,
            "recall": 0.66089,
            "fmeasure": 0.68757
        },
        "rougeL": {
            "precision": 0.55556,
            "recall": 0.51449,
            "fmeasure": 0.53418
        },
        "rougeLsum": {
            "precision": 0.55556,
            "recall": 0.51449,
            "fmeasure": 0.53418
        },
        "bleu": 62.41996,
        "local_recall": {
            "1": 0.0,
            "2": 0.6666666666666666,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96068,
            "recall": 0.96427,
            "f1": 0.96247
        },
        "nubia": {
            "semantic_relation": 4.53126,
            "contradiction": 2.77295,
            "irrelevancy": 0.81033,
            "logical_agreement": 96.41671,
            "grammar_ref": 3.13705,
            "grammar_hyp": 3.17326,
            "nubia_score": 0.90966
        },
        "meteor": 0.5183078342947554,
        "bleurt": 0.40627
    },
    "totto_test_contrast_challenge_table_size-table_size_1878": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 22,
        "mean_pred_length": 11.0,
        "std_pred_length": 1.0,
        "median_pred_length": 11.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.9090909090909091,
        "vocab_size-1": 20,
        "unique-1": 18,
        "entropy-1": 4.277613436819114,
        "distinct-2": 1.0,
        "vocab_size-2": 20,
        "unique-2": 20,
        "entropy-2": 4.321928094887363,
        "cond_entropy-2": -0.037503523749935014,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 20,
        "mean_pred_length-nopunct": 10.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.95,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 18,
        "entropy-1-nopunct": 4.221928094887362,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 18,
        "unique-2-nopunct": 18,
        "entropy-2-nopunct": 4.169925001442312,
        "cond_entropy-2-nopunct": -0.04089198233393866,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.16992500144231232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.8764905674296216,
        "rouge1": {
            "precision": 0.81364,
            "recall": 0.45906,
            "fmeasure": 0.58621
        },
        "rouge2": {
            "precision": 0.53889,
            "recall": 0.28268,
            "fmeasure": 0.37037
        },
        "rougeL": {
            "precision": 0.67727,
            "recall": 0.37573,
            "fmeasure": 0.48276
        },
        "rougeLsum": {
            "precision": 0.67727,
            "recall": 0.37573,
            "fmeasure": 0.48276
        },
        "bleu": 20.97954,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.5333333333333333
        },
        "bertscore": {
            "precision": 0.93128,
            "recall": 0.81643,
            "f1": 0.86892
        },
        "nubia": {
            "semantic_relation": 3.67375,
            "contradiction": 13.53507,
            "irrelevancy": 3.44976,
            "logical_agreement": 83.01517,
            "grammar_ref": 4.13564,
            "grammar_hyp": 5.09331,
            "nubia_score": 0.46453
        },
        "meteor": 0.2832290768309684,
        "bleurt": 0.13414
    },
    "totto_test_contrast_challenge_table_size-table_size_3546": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.7004397181410926,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": -0.1154772174199359,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.9427950465634054,
        "rouge1": {
            "precision": 0.93333,
            "recall": 0.875,
            "fmeasure": 0.90323
        },
        "rouge2": {
            "precision": 0.47619,
            "recall": 0.49231,
            "fmeasure": 0.48361
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.375,
            "fmeasure": 0.3871
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.375,
            "fmeasure": 0.3871
        },
        "bleu": 29.61517,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.8181818181818182
        },
        "bertscore": {
            "precision": 0.94318,
            "recall": 0.91474,
            "f1": 0.92875
        },
        "nubia": {
            "semantic_relation": 4.69599,
            "contradiction": 0.53975,
            "irrelevancy": 33.71513,
            "logical_agreement": 65.74513,
            "grammar_ref": 4.41465,
            "grammar_hyp": 5.08154,
            "nubia_score": 0.78999
        },
        "meteor": 0.43170776462300553,
        "bleurt": 0.23524
    },
    "totto_test_contrast_challenge_table_size-table_size_1384": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 0.9285714285714286,
        "vocab_size-1": 13,
        "unique-1": 12,
        "entropy-1": 3.6644977792004623,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": 0.04693094992964167,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9230769230769231,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.5465935642949384,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.05118944924673077,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.5484412322516041,
        "rouge1": {
            "precision": 0.34615,
            "recall": 0.57937,
            "fmeasure": 0.43182
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.45833,
            "fmeasure": 0.32222
        },
        "rougeL": {
            "precision": 0.34615,
            "recall": 0.57937,
            "fmeasure": 0.43182
        },
        "rougeLsum": {
            "precision": 0.34615,
            "recall": 0.57937,
            "fmeasure": 0.43182
        },
        "bleu": 27.82462,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.83833,
            "recall": 0.91019,
            "f1": 0.86408
        },
        "nubia": {
            "semantic_relation": 3.52491,
            "contradiction": 0.1453,
            "irrelevancy": 88.65474,
            "logical_agreement": 11.19996,
            "grammar_ref": 4.8549,
            "grammar_hyp": 4.36437,
            "nubia_score": 0.50714
        },
        "meteor": 0.35149642178137297,
        "bleurt": 0.13167
    },
    "totto_test_contrast_challenge_table_size-table_size_1400": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.9333333333333333,
        "vocab_size-1": 14,
        "unique-1": 13,
        "entropy-1": 3.7735572622751845,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.04332146930622849,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.9285714285714286,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.6644977792004623,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.04693094992964167,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.628777959750465,
        "rouge1": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92148
        },
        "rouge2": {
            "precision": 0.73077,
            "recall": 0.85833,
            "fmeasure": 0.78783
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92148
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 1.0,
            "fmeasure": 0.92148
        },
        "bleu": 63.89431,
        "local_recall": {
            "1": 1.0,
            "2": 0.9
        },
        "bertscore": {
            "precision": 0.95542,
            "recall": 0.98682,
            "f1": 0.97086
        },
        "nubia": {
            "semantic_relation": 4.44531,
            "contradiction": 0.7367,
            "irrelevancy": 95.63058,
            "logical_agreement": 3.63271,
            "grammar_ref": 4.75081,
            "grammar_hyp": 3.83535,
            "nubia_score": 0.87282
        },
        "meteor": 0.550672869305321,
        "bleurt": 0.4722
    },
    "totto_test_contrast_challenge_table_size-table_size_972": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 23.0,
        "std_pred_length": 0.0,
        "median_pred_length": 23.0,
        "min_pred_length": 23,
        "max_pred_length": 23,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 22,
        "unique-2": 22,
        "entropy-2": 4.459431618637295,
        "cond_entropy-2": 0.1176878443984663,
        "distinct-3": 1.0,
        "vocab_size-3": 21,
        "unique-3": 21,
        "entropy-3": 4.39231742277876,
        "cond_entropy-3": -0.06711419585853673,
        "total_length-nopunct": 21,
        "mean_pred_length-nopunct": 21.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 21,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.9047619047619048,
        "vocab_size-1-nopunct": 19,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.201841232302569,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 20,
        "unique-2-nopunct": 20,
        "entropy-2-nopunct": 4.321928094887363,
        "cond_entropy-2-nopunct": 0.129610672108602,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 19,
        "unique-3-nopunct": 19,
        "entropy-3-nopunct": 4.247927513443583,
        "cond_entropy-3-nopunct": -0.07400058144377676,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1533266862947302,
        "rouge1": {
            "precision": 0.65278,
            "recall": 0.7995,
            "fmeasure": 0.71835
        },
        "rouge2": {
            "precision": 0.44928,
            "recall": 0.60741,
            "fmeasure": 0.51562
        },
        "rougeL": {
            "precision": 0.59722,
            "recall": 0.73266,
            "fmeasure": 0.65771
        },
        "rougeLsum": {
            "precision": 0.59722,
            "recall": 0.73266,
            "fmeasure": 0.65771
        },
        "bleu": 36.23886,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.93384,
            "recall": 0.97178,
            "f1": 0.95243
        },
        "nubia": {
            "semantic_relation": 4.46977,
            "contradiction": 1.53551,
            "irrelevancy": 38.81908,
            "logical_agreement": 59.64541,
            "grammar_ref": 4.42639,
            "grammar_hyp": 3.59882,
            "nubia_score": 0.89978
        },
        "meteor": 0.48163547760568437,
        "bleurt": 0.57782
    },
    "totto_test_contrast_challenge_table_size-table_size_3591": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 0.6875,
        "vocab_size-1": 11,
        "unique-1": 7,
        "entropy-1": 3.327819531114783,
        "distinct-2": 0.8,
        "vocab_size-2": 12,
        "unique-2": 9,
        "entropy-2": 3.5068905956085183,
        "cond_entropy-2": 0.22388309575274978,
        "distinct-3": 0.9285714285714286,
        "vocab_size-3": 13,
        "unique-3": 12,
        "entropy-3": 3.6644977792004623,
        "cond_entropy-3": 0.18617861216337128,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.6153846153846154,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 2.873140679513133,
        "distinct-2-nopunct": 0.75,
        "vocab_size-2-nopunct": 9,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 3.084962500721156,
        "cond_entropy-2-nopunct": 0.2807634077603532,
        "distinct-3-nopunct": 0.9090909090909091,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.2776134368191165,
        "cond_entropy-3-nopunct": 0.23810548155250458,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.335875509205763,
        "rouge1": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 1.0,
            "fmeasure": 0.8
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 1.0,
            "fmeasure": 0.81818
        },
        "bleu": 48.41525,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.94806,
            "recall": 0.97904,
            "f1": 0.9633
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 2.80225,
            "irrelevancy": 2.20481,
            "logical_agreement": 94.99294,
            "grammar_ref": 7.00423,
            "grammar_hyp": 4.8462,
            "nubia_score": 1.0
        },
        "meteor": 0.5158883169898099,
        "bleurt": 0.72955
    },
    "totto_test_contrast_challenge_table_size-table_size_2940": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 22,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 0.5909090909090909,
        "vocab_size-1-nopunct": 13,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.6412498004554794,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.521928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 0.6111111111111112,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.392147223664534,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.854285871987245,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.32615,
            "irrelevancy": 0.47325,
            "logical_agreement": 99.2006,
            "grammar_ref": 5.00662,
            "grammar_hyp": 5.00662,
            "nubia_score": 1.0
        },
        "meteor": 1.0,
        "bleurt": 0.94692
    },
    "totto_test_contrast_challenge_table_size-table_size_1890": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.9444444444444444,
        "vocab_size-1": 17,
        "unique-1": 16,
        "entropy-1": 4.058813890331201,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.03518489863155644,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.819383617925176,
        "rouge1": {
            "precision": 0.6875,
            "recall": 0.64706,
            "fmeasure": 0.66667
        },
        "rouge2": {
            "precision": 0.26667,
            "recall": 0.25,
            "fmeasure": 0.25806
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.47059,
            "fmeasure": 0.48485
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.47059,
            "fmeasure": 0.48485
        },
        "bleu": 16.31615,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.91535,
            "recall": 0.90395,
            "f1": 0.9096
        },
        "nubia": {
            "semantic_relation": 3.39148,
            "contradiction": 98.63032,
            "irrelevancy": 1.14865,
            "logical_agreement": 0.22103,
            "grammar_ref": 4.71038,
            "grammar_hyp": 4.47246,
            "nubia_score": 0.45502
        },
        "meteor": 0.2890501961858157,
        "bleurt": 0.00247
    },
    "totto_test_contrast_challenge_table_size-table_size_2304": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.85,
        "vocab_size-1": 17,
        "unique-1": 14,
        "entropy-1": 4.021928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.07021912877717246,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.16992500144231232,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.75,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.09306920777188989,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.685018456734738,
        "rouge1": {
            "precision": 0.87857,
            "recall": 0.65065,
            "fmeasure": 0.72857
        },
        "rouge2": {
            "precision": 0.63889,
            "recall": 0.46325,
            "fmeasure": 0.52047
        },
        "rougeL": {
            "precision": 0.87857,
            "recall": 0.65065,
            "fmeasure": 0.72857
        },
        "rougeLsum": {
            "precision": 0.87857,
            "recall": 0.65065,
            "fmeasure": 0.72857
        },
        "bleu": 34.45382,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6470588235294118
        },
        "bertscore": {
            "precision": 0.96028,
            "recall": 0.91146,
            "f1": 0.93448
        },
        "nubia": {
            "semantic_relation": 4.17601,
            "contradiction": 53.52686,
            "irrelevancy": 17.41523,
            "logical_agreement": 29.05791,
            "grammar_ref": 3.80999,
            "grammar_hyp": 4.65715,
            "nubia_score": 0.59509
        },
        "meteor": 0.38156891175014923,
        "bleurt": 0.33547
    },
    "totto_test_contrast_challenge_table_size-table_size_3612": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 27.0,
        "std_pred_length": 0.0,
        "median_pred_length": 27.0,
        "min_pred_length": 27,
        "max_pred_length": 27,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 24,
        "unique-1": 21,
        "entropy-1": 4.532665279941249,
        "distinct-2": 1.0,
        "vocab_size-2": 26,
        "unique-2": 26,
        "entropy-2": 4.70043971814109,
        "cond_entropy-2": 0.1763214467468543,
        "distinct-3": 1.0,
        "vocab_size-3": 25,
        "unique-3": 25,
        "entropy-3": 4.643856189774723,
        "cond_entropy-3": -0.05658352836636749,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 23.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 23,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.262692390839622,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 22,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.459431618637295,
        "cond_entropy-2-nopunct": 0.20859693530755724,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 21,
        "unique-3-nopunct": 21,
        "entropy-3-nopunct": 4.39231742277876,
        "cond_entropy-3-nopunct": -0.06711419585853673,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.684135732888986,
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.48254,
            "fmeasure": 0.44714
        },
        "rouge2": {
            "precision": 0.11594,
            "recall": 0.14693,
            "fmeasure": 0.12943
        },
        "rougeL": {
            "precision": 0.20833,
            "recall": 0.24603,
            "fmeasure": 0.22559
        },
        "rougeLsum": {
            "precision": 0.20833,
            "recall": 0.24603,
            "fmeasure": 0.22559
        },
        "bleu": 9.18667,
        "local_recall": {
            "1": 0.25,
            "2": 0.0,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.84622,
            "recall": 0.8741,
            "f1": 0.8591
        },
        "nubia": {
            "semantic_relation": 3.24987,
            "contradiction": 15.46216,
            "irrelevancy": 60.71458,
            "logical_agreement": 23.82327,
            "grammar_ref": 5.50536,
            "grammar_hyp": 4.59828,
            "nubia_score": 0.54088
        },
        "meteor": 0.26506875442853,
        "bleurt": -0.16628
    },
    "totto_test_contrast_challenge_table_size-table_size_2313": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 39,
        "mean_pred_length": 19.5,
        "std_pred_length": 6.5,
        "median_pred_length": 19.5,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.7948717948717948,
        "vocab_size-1": 31,
        "unique-1": 27,
        "entropy-1": 4.7977214494095834,
        "distinct-2": 1.0,
        "vocab_size-2": 37,
        "unique-2": 37,
        "entropy-2": 5.209453365628954,
        "cond_entropy-2": 0.43809303889248147,
        "distinct-3": 1.0,
        "vocab_size-3": 35,
        "unique-3": 35,
        "entropy-3": 5.129283016944964,
        "cond_entropy-3": -0.08017034868398329,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 6.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.875,
        "vocab_size-1-nopunct": 28,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.702819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 30,
        "unique-2-nopunct": 30,
        "entropy-2-nopunct": 4.906890595608519,
        "cond_entropy-2-nopunct": 0.22388309575274956,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.09953567355091442,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.4906759421688145,
        "rouge1": {
            "precision": 0.47694,
            "recall": 0.29827,
            "fmeasure": 0.32642
        },
        "rouge2": {
            "precision": 0.14545,
            "recall": 0.0843,
            "fmeasure": 0.09461
        },
        "rougeL": {
            "precision": 0.43149,
            "recall": 0.28504,
            "fmeasure": 0.30594
        },
        "rougeLsum": {
            "precision": 0.43149,
            "recall": 0.28504,
            "fmeasure": 0.30594
        },
        "bleu": 2.29172,
        "local_recall": {
            "1": 0.09090909090909091,
            "2": 0.0,
            "3": 0.23529411764705882
        },
        "bertscore": {
            "precision": 0.83817,
            "recall": 0.807,
            "f1": 0.81979
        },
        "nubia": {
            "semantic_relation": 1.3652,
            "contradiction": 95.40026,
            "irrelevancy": 3.75342,
            "logical_agreement": 0.84632,
            "grammar_ref": 3.44707,
            "grammar_hyp": 3.7665,
            "nubia_score": 0.20215
        },
        "meteor": 0.0896951094265773,
        "bleurt": -0.6349
    },
    "totto_test_contrast_challenge_table_size-table_size_2960": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1439774686768684,
        "rouge1": {
            "precision": 0.7,
            "recall": 0.79545,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.48148,
            "recall": 0.60119,
            "fmeasure": 0.53431
        },
        "rougeL": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "rougeLsum": {
            "precision": 0.63333,
            "recall": 0.76852,
            "fmeasure": 0.69396
        },
        "bleu": 39.28147,
        "local_recall": {
            "1": 0.5,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.91675,
            "recall": 0.92378,
            "f1": 0.92025
        },
        "nubia": {
            "semantic_relation": 2.68766,
            "contradiction": 26.50481,
            "irrelevancy": 71.49975,
            "logical_agreement": 1.99544,
            "grammar_ref": 3.66596,
            "grammar_hyp": 2.72658,
            "nubia_score": 0.46158
        },
        "meteor": 0.49043387317825937,
        "bleurt": 0.07163
    },
    "totto_test_contrast_challenge_table_size-table_size_1408": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 19.0,
        "std_pred_length": 0.0,
        "median_pred_length": 19.0,
        "min_pred_length": 19,
        "max_pred_length": 19,
        "distinct-1": 0.7894736842105263,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.7871439606981383,
        "distinct-2": 1.0,
        "vocab_size-2": 18,
        "unique-2": 18,
        "entropy-2": 4.169925001442312,
        "cond_entropy-2": 0.40838012700780835,
        "distinct-3": 1.0,
        "vocab_size-3": 17,
        "unique-3": 17,
        "entropy-3": 4.08746284125034,
        "cond_entropy-3": -0.08246216019197297,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.452819531114783,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.4905497624194164,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0492695860968664,
        "rouge1": {
            "precision": 0.25,
            "recall": 0.28356,
            "fmeasure": 0.26472
        },
        "rouge2": {
            "precision": 0.06667,
            "recall": 0.07639,
            "fmeasure": 0.07089
        },
        "rougeL": {
            "precision": 0.22917,
            "recall": 0.23379,
            "fmeasure": 0.23058
        },
        "rougeLsum": {
            "precision": 0.22917,
            "recall": 0.23379,
            "fmeasure": 0.23058
        },
        "bleu": 5.09121,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.64186,
            "recall": 0.62649,
            "f1": 0.63408
        },
        "nubia": {
            "semantic_relation": 0.94354,
            "contradiction": 44.5465,
            "irrelevancy": 50.01547,
            "logical_agreement": 5.43804,
            "grammar_ref": 4.12033,
            "grammar_hyp": 3.54688,
            "nubia_score": 0.09829
        },
        "meteor": 0.11015333541717581,
        "bleurt": -0.93364
    },
    "totto_test_contrast_challenge_table_size-table_size_1770": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 1.0,
        "vocab_size-1": 15,
        "unique-1": 15,
        "entropy-1": 3.906890595608518,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": -0.09953567355091435,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.8073549220576055,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": -0.1069152039165122,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.7052281266567761,
        "rouge1": {
            "precision": 0.46667,
            "recall": 0.60985,
            "fmeasure": 0.52849
        },
        "rouge2": {
            "precision": 0.28571,
            "recall": 0.38182,
            "fmeasure": 0.32667
        },
        "rougeL": {
            "precision": 0.46667,
            "recall": 0.60985,
            "fmeasure": 0.52849
        },
        "rougeLsum": {
            "precision": 0.46667,
            "recall": 0.60985,
            "fmeasure": 0.52849
        },
        "bleu": 18.92241,
        "local_recall": {
            "1": 0.0,
            "2": 0.75
        },
        "bertscore": {
            "precision": 0.87549,
            "recall": 0.90682,
            "f1": 0.89088
        },
        "nubia": {
            "semantic_relation": 4.58785,
            "contradiction": 0.18388,
            "irrelevancy": 98.41835,
            "logical_agreement": 1.39777,
            "grammar_ref": 5.10481,
            "grammar_hyp": 4.60327,
            "nubia_score": 0.83894
        },
        "meteor": 0.31457276651850663,
        "bleurt": 0.11334
    },
    "totto_test_contrast_challenge_table_size-table_size_5166": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.006676565273293,
        "rouge1": {
            "precision": 0.44444,
            "recall": 0.35354,
            "fmeasure": 0.39365
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.19394,
            "fmeasure": 0.21832
        },
        "rougeL": {
            "precision": 0.44444,
            "recall": 0.35354,
            "fmeasure": 0.39365
        },
        "rougeLsum": {
            "precision": 0.44444,
            "recall": 0.35354,
            "fmeasure": 0.39365
        },
        "bleu": 9.28753,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.2222222222222222
        },
        "bertscore": {
            "precision": 0.79627,
            "recall": 0.77676,
            "f1": 0.78639
        },
        "nubia": {
            "semantic_relation": 2.77452,
            "contradiction": 0.24955,
            "irrelevancy": 98.16296,
            "logical_agreement": 1.58748,
            "grammar_ref": 4.79209,
            "grammar_hyp": 4.19033,
            "nubia_score": 0.38473
        },
        "meteor": 0.23454852278385876,
        "bleurt": -0.56566
    },
    "totto_test_contrast_challenge_table_size-table_size_3720": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 31,
        "mean_pred_length": 15.5,
        "std_pred_length": 1.5,
        "median_pred_length": 15.5,
        "min_pred_length": 14,
        "max_pred_length": 17,
        "distinct-1": 0.6129032258064516,
        "vocab_size-1": 19,
        "unique-1": 9,
        "entropy-1": 4.11548663296752,
        "distinct-2": 0.7241379310344828,
        "vocab_size-2": 21,
        "unique-2": 13,
        "entropy-2": 4.306256857196538,
        "cond_entropy-2": 0.1796467537062143,
        "distinct-3": 0.8148148148148148,
        "vocab_size-3": 22,
        "unique-3": 17,
        "entropy-3": 4.3845171317931,
        "cond_entropy-3": 0.04505465518404472,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6521739130434783,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 3.82790978214397,
        "distinct-2-nopunct": 0.7619047619047619,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.916126946588283,
        "cond_entropy-2-nopunct": 0.059231657197938034,
        "distinct-3-nopunct": 0.8421052631578947,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.9321380397593733,
        "cond_entropy-3-nopunct": -0.03912675144043809,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.725958657424895,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 88.23314,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.9565217391304348
        },
        "bertscore": {
            "precision": 0.99215,
            "recall": 0.94723,
            "f1": 0.96862
        },
        "nubia": {
            "semantic_relation": 4.59491,
            "contradiction": 0.51227,
            "irrelevancy": 10.44657,
            "logical_agreement": 89.04116,
            "grammar_ref": 4.1188,
            "grammar_hyp": 4.00862,
            "nubia_score": 0.9067
        },
        "meteor": 0.5463176402057991,
        "bleurt": 0.56181
    },
    "totto_test_contrast_challenge_table_size-table_size_2976": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.0978468357247135,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.69841,
            "fmeasure": 0.63492
        },
        "rouge2": {
            "precision": 0.38095,
            "recall": 0.46667,
            "fmeasure": 0.4188
        },
        "rougeL": {
            "precision": 0.58333,
            "recall": 0.69841,
            "fmeasure": 0.63492
        },
        "rougeLsum": {
            "precision": 0.58333,
            "recall": 0.69841,
            "fmeasure": 0.63492
        },
        "bleu": 25.84866,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.75
        },
        "bertscore": {
            "precision": 0.88463,
            "recall": 0.91731,
            "f1": 0.90067
        },
        "nubia": {
            "semantic_relation": 3.10241,
            "contradiction": 48.64686,
            "irrelevancy": 35.04811,
            "logical_agreement": 16.30503,
            "grammar_ref": 6.44614,
            "grammar_hyp": 5.72914,
            "nubia_score": 0.39062
        },
        "meteor": 0.3209999318453433,
        "bleurt": -0.70689
    },
    "totto_test_contrast_challenge_table_size-table_size_3908": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.6402239289418516,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337137,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 14,
        "mean_pred_length-nopunct": 14.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 14.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 14,
        "distinct-1-nopunct": 0.8571428571428571,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.521640636343319,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 13,
        "entropy-2-nopunct": 3.7004397181410926,
        "cond_entropy-2-nopunct": 0.12385402685271857,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.1154772174199359,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9561795686432486,
        "rouge1": {
            "precision": 0.60714,
            "recall": 0.7735,
            "fmeasure": 0.67472
        },
        "rouge2": {
            "precision": 0.23077,
            "recall": 0.29167,
            "fmeasure": 0.25524
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.64103,
            "fmeasure": 0.55717
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.64103,
            "fmeasure": 0.55717
        },
        "bleu": 24.072,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 1.0
        },
        "bertscore": {
            "precision": 0.88025,
            "recall": 0.89396,
            "f1": 0.8859
        },
        "nubia": {
            "semantic_relation": 3.75932,
            "contradiction": 0.50432,
            "irrelevancy": 89.71649,
            "logical_agreement": 9.7792,
            "grammar_ref": 4.60771,
            "grammar_hyp": 4.81304,
            "nubia_score": 0.5167
        },
        "meteor": 0.33203693370255255,
        "bleurt": 0.05717
    },
    "totto_test_contrast_challenge_table_size-table_size_1908": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 11,
        "mean_pred_length-nopunct": 11.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 11,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.459431618637298,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 10,
        "unique-2-nopunct": 10,
        "entropy-2-nopunct": 3.321928094887362,
        "cond_entropy-2-nopunct": -0.13750352374993502,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 9,
        "unique-3-nopunct": 9,
        "entropy-3-nopunct": 3.169925001442312,
        "cond_entropy-3-nopunct": -0.15200309344504973,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.633889665336505,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.64133,
            "fmeasure": 0.59498
        },
        "rouge2": {
            "precision": 0.27273,
            "recall": 0.30556,
            "fmeasure": 0.27949
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.54971,
            "fmeasure": 0.50998
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.54971,
            "fmeasure": 0.50998
        },
        "bleu": 17.82753,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.91827,
            "recall": 0.94188,
            "f1": 0.92993
        },
        "nubia": {
            "semantic_relation": 4.44448,
            "contradiction": 0.08769,
            "irrelevancy": 10.45922,
            "logical_agreement": 89.45309,
            "grammar_ref": 3.44041,
            "grammar_hyp": 4.37196,
            "nubia_score": 0.7914
        },
        "meteor": 0.43354573280686926,
        "bleurt": 0.26395
    },
    "totto_test_contrast_challenge_table_size-table_size_1914": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 0.4762470591647922,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.37778,
            "fmeasure": 0.48148
        },
        "rouge2": {
            "precision": 0.25,
            "recall": 0.1369,
            "fmeasure": 0.17677
        },
        "rougeL": {
            "precision": 0.51852,
            "recall": 0.2963,
            "fmeasure": 0.37654
        },
        "rougeLsum": {
            "precision": 0.51852,
            "recall": 0.2963,
            "fmeasure": 0.37654
        },
        "bleu": 6.77869,
        "local_recall": {
            "1": 0.0,
            "2": 0.5,
            "3": 0.38461538461538464
        },
        "bertscore": {
            "precision": 0.89358,
            "recall": 0.84319,
            "f1": 0.86571
        },
        "nubia": {
            "semantic_relation": 4.10534,
            "contradiction": 0.3817,
            "irrelevancy": 46.32713,
            "logical_agreement": 53.29118,
            "grammar_ref": 4.4151,
            "grammar_hyp": 7.09505,
            "nubia_score": 0.38496
        },
        "meteor": 0.22887808656375963,
        "bleurt": -0.25247
    },
    "totto_test_contrast_challenge_table_size-table_size_5360": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.140204368901255,
        "rouge1": {
            "precision": 0.81481,
            "recall": 0.61481,
            "fmeasure": 0.68876
        },
        "rouge2": {
            "precision": 0.5,
            "recall": 0.37473,
            "fmeasure": 0.42039
        },
        "rougeL": {
            "precision": 0.7037,
            "recall": 0.52963,
            "fmeasure": 0.59389
        },
        "rougeLsum": {
            "precision": 0.7037,
            "recall": 0.52963,
            "fmeasure": 0.59389
        },
        "bleu": 37.25177,
        "local_recall": {
            "1": 0,
            "2": 0.14285714285714285,
            "3": 0.7
        },
        "bertscore": {
            "precision": 0.95956,
            "recall": 0.90472,
            "f1": 0.93133
        },
        "nubia": {
            "semantic_relation": 3.90425,
            "contradiction": 0.23632,
            "irrelevancy": 2.91639,
            "logical_agreement": 96.84729,
            "grammar_ref": 3.74426,
            "grammar_hyp": 3.79136,
            "nubia_score": 0.72975
        },
        "meteor": 0.32661173471612,
        "bleurt": 0.33005
    },
    "totto_test_contrast_challenge_table_size-table_size_3944": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2980010892226004,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.28636,
            "fmeasure": 0.30789
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.10556,
            "fmeasure": 0.11438
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.28636,
            "fmeasure": 0.30789
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.28636,
            "fmeasure": 0.30789
        },
        "bleu": 9.03037,
        "local_recall": {
            "1": 0.0,
            "2": 0.3333333333333333
        },
        "bertscore": {
            "precision": 0.87051,
            "recall": 0.84849,
            "f1": 0.85936
        },
        "nubia": {
            "semantic_relation": 3.19182,
            "contradiction": 35.9514,
            "irrelevancy": 49.25493,
            "logical_agreement": 14.79367,
            "grammar_ref": 4.7527,
            "grammar_hyp": 5.03917,
            "nubia_score": 0.3155
        },
        "meteor": 0.21212144608032588,
        "bleurt": 0.30741
    },
    "totto_test_contrast_challenge_table_size-table_size_3000": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.821928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.4523152080299074,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 18.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.614369445886757,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": 0.5057731339256741,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 16,
        "unique-3-nopunct": 16,
        "entropy-3-nopunct": 4.0,
        "cond_entropy-3-nopunct": -0.08746284125033939,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9365926474409003,
        "rouge1": {
            "precision": 0.47368,
            "recall": 0.6,
            "fmeasure": 0.52941
        },
        "rouge2": {
            "precision": 0.16667,
            "recall": 0.21429,
            "fmeasure": 0.1875
        },
        "rougeL": {
            "precision": 0.26316,
            "recall": 0.33333,
            "fmeasure": 0.29412
        },
        "rougeLsum": {
            "precision": 0.26316,
            "recall": 0.33333,
            "fmeasure": 0.29412
        },
        "bleu": 10.58033,
        "local_recall": {
            "1": 0.2,
            "2": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.84702,
            "recall": 0.86457,
            "f1": 0.85571
        },
        "nubia": {
            "semantic_relation": 2.8083,
            "contradiction": 31.91355,
            "irrelevancy": 56.69365,
            "logical_agreement": 11.3928,
            "grammar_ref": 5.62728,
            "grammar_hyp": 4.68155,
            "nubia_score": 0.39552
        },
        "meteor": 0.2594982995254499,
        "bleurt": -0.57438
    },
    "totto_test_contrast_challenge_table_size-table_size_5418": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8333333333333334,
        "vocab_size-1": 15,
        "unique-1": 12,
        "entropy-1": 3.8365916681089787,
        "distinct-2": 0.9411764705882353,
        "vocab_size-2": 16,
        "unique-2": 15,
        "entropy-2": 3.969815782426811,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": 0.037537158749660585,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.8235294117647058,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 11,
        "entropy-1-nopunct": 3.734521664779752,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.1625371587496606,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": 0.04022392894185189,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.01318440616249,
        "rouge1": {
            "precision": 0.52941,
            "recall": 0.34565,
            "fmeasure": 0.41649
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.07994,
            "fmeasure": 0.09708
        },
        "rougeL": {
            "precision": 0.35294,
            "recall": 0.23043,
            "fmeasure": 0.27766
        },
        "rougeLsum": {
            "precision": 0.35294,
            "recall": 0.23043,
            "fmeasure": 0.27766
        },
        "bleu": 7.53898,
        "local_recall": {
            "1": 0.0,
            "2": 0.3684210526315789
        },
        "bertscore": {
            "precision": 0.85727,
            "recall": 0.80791,
            "f1": 0.83186
        },
        "nubia": {
            "semantic_relation": 3.94524,
            "contradiction": 1.01437,
            "irrelevancy": 3.57274,
            "logical_agreement": 95.41289,
            "grammar_ref": 4.294,
            "grammar_hyp": 4.54194,
            "nubia_score": 0.57695
        },
        "meteor": 0.18752822551056947,
        "bleurt": -0.19659
    },
    "totto_test_contrast_challenge_table_size-table_size_4050": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 20.0,
        "std_pred_length": 0.0,
        "median_pred_length": 20.0,
        "min_pred_length": 20,
        "max_pred_length": 20,
        "distinct-1": 0.9,
        "vocab_size-1": 18,
        "unique-1": 16,
        "entropy-1": 4.1219280948873624,
        "distinct-2": 1.0,
        "vocab_size-2": 19,
        "unique-2": 19,
        "entropy-2": 4.247927513443583,
        "cond_entropy-2": 0.13652573434569684,
        "distinct-3": 1.0,
        "vocab_size-3": 18,
        "unique-3": 18,
        "entropy-3": 4.169925001442312,
        "cond_entropy-3": -0.07800251200127316,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 17.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 17,
        "distinct-1-nopunct": 0.9411764705882353,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.969815782426811,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 16,
        "unique-2-nopunct": 16,
        "entropy-2-nopunct": 4.0,
        "cond_entropy-2-nopunct": 0.03753715874966058,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.09310940439148144,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.782318411932623,
        "rouge1": {
            "precision": 0.56863,
            "recall": 0.57966,
            "fmeasure": 0.57398
        },
        "rouge2": {
            "precision": 0.22917,
            "recall": 0.23333,
            "fmeasure": 0.23118
        },
        "rougeL": {
            "precision": 0.33333,
            "recall": 0.33946,
            "fmeasure": 0.3363
        },
        "rougeLsum": {
            "precision": 0.33333,
            "recall": 0.33946,
            "fmeasure": 0.3363
        },
        "bleu": 17.92334,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6923076923076923
        },
        "bertscore": {
            "precision": 0.90347,
            "recall": 0.89041,
            "f1": 0.89689
        },
        "nubia": {
            "semantic_relation": 4.52367,
            "contradiction": 0.08889,
            "irrelevancy": 0.97123,
            "logical_agreement": 98.93988,
            "grammar_ref": 5.85115,
            "grammar_hyp": 4.9339,
            "nubia_score": 0.95348
        },
        "meteor": 0.32225852808079297,
        "bleurt": 0.27102
    },
    "totto_test_contrast_challenge_table_size-table_size_3008": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 16,
        "mean_pred_length": 16.0,
        "std_pred_length": 0.0,
        "median_pred_length": 16.0,
        "min_pred_length": 16,
        "max_pred_length": 16,
        "distinct-1": 1.0,
        "vocab_size-1": 16,
        "unique-1": 16,
        "entropy-1": 4.0,
        "distinct-2": 1.0,
        "vocab_size-2": 15,
        "unique-2": 15,
        "entropy-2": 3.906890595608518,
        "cond_entropy-2": -0.09310940439148144,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.09953567355091435,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 3.906890595608518,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": -0.09953567355091435,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.557533649399047,
        "rouge1": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "rouge2": {
            "precision": 0.71429,
            "recall": 0.625,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "rougeLsum": {
            "precision": 0.82222,
            "recall": 0.82633,
            "fmeasure": 0.82256
        },
        "bleu": 61.28081,
        "local_recall": {
            "1": 0,
            "2": 0.3333333333333333,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.98135,
            "recall": 0.98613,
            "f1": 0.98373
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.31478,
            "irrelevancy": 0.53733,
            "logical_agreement": 99.14789,
            "grammar_ref": 5.90677,
            "grammar_hyp": 6.43696,
            "nubia_score": 0.88323
        },
        "meteor": 0.4907863019777329,
        "bleurt": 0.67301
    },
    "totto_test_contrast_challenge_table_size-table_size_4060": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 44,
        "mean_pred_length": 22.0,
        "std_pred_length": 6.0,
        "median_pred_length": 22.0,
        "min_pred_length": 16,
        "max_pred_length": 28,
        "distinct-1": 0.6590909090909091,
        "vocab_size-1": 29,
        "unique-1": 20,
        "entropy-1": 4.550340709546387,
        "distinct-2": 0.9047619047619048,
        "vocab_size-2": 38,
        "unique-2": 34,
        "entropy-2": 5.201841232302572,
        "cond_entropy-2": 0.6471715184271769,
        "distinct-3": 0.975,
        "vocab_size-3": 39,
        "unique-3": 38,
        "entropy-3": 5.271928094887364,
        "cond_entropy-3": 0.07961067210860198,
        "total_length-nopunct": 32,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 3.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.8125,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 20,
        "entropy-1-nopunct": 4.625,
        "distinct-2-nopunct": 0.9666666666666667,
        "vocab_size-2-nopunct": 29,
        "unique-2-nopunct": 28,
        "entropy-2-nopunct": 4.840223928941852,
        "cond_entropy-2-nopunct": 0.20689059560851852,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 28,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 4.807354922057606,
        "cond_entropy-3-nopunct": -0.02810710212234293,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1399889884112735,
        "rouge1": {
            "precision": 0.74038,
            "recall": 0.93483,
            "fmeasure": 0.81506
        },
        "rouge2": {
            "precision": 0.55263,
            "recall": 0.7303,
            "fmeasure": 0.62183
        },
        "rougeL": {
            "precision": 0.60962,
            "recall": 0.82576,
            "fmeasure": 0.69032
        },
        "rougeLsum": {
            "precision": 0.60962,
            "recall": 0.82576,
            "fmeasure": 0.69032
        },
        "bleu": 38.06429,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.9545454545454546
        },
        "bertscore": {
            "precision": 0.86448,
            "recall": 0.95585,
            "f1": 0.90556
        },
        "nubia": {
            "semantic_relation": 3.99493,
            "contradiction": 0.66762,
            "irrelevancy": 82.02981,
            "logical_agreement": 17.30257,
            "grammar_ref": 6.50157,
            "grammar_hyp": 6.33055,
            "nubia_score": 0.65086
        },
        "meteor": 0.45207610811068494,
        "bleurt": -0.19086
    },
    "totto_test_contrast_challenge_table_size-table_size_4320": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 40,
        "mean_pred_length": 20.0,
        "std_pred_length": 2.0,
        "median_pred_length": 20.0,
        "min_pred_length": 18,
        "max_pred_length": 22,
        "distinct-1": 0.725,
        "vocab_size-1": 29,
        "unique-1": 21,
        "entropy-1": 4.703055907333276,
        "distinct-2": 0.9473684210526315,
        "vocab_size-2": 36,
        "unique-2": 34,
        "entropy-2": 5.142664355548852,
        "cond_entropy-2": 0.4721806686131566,
        "distinct-3": 1.0,
        "vocab_size-3": 36,
        "unique-3": 36,
        "entropy-3": 5.1699250014423095,
        "cond_entropy-3": 0.03310859910983796,
        "total_length-nopunct": 35,
        "mean_pred_length-nopunct": 17.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 17.5,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.7428571428571429,
        "vocab_size-1-nopunct": 26,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.5578544455163925,
        "distinct-2-nopunct": 0.9393939393939394,
        "vocab_size-2-nopunct": 31,
        "unique-2-nopunct": 29,
        "entropy-2-nopunct": 4.923181998146335,
        "cond_entropy-2-nopunct": 0.3999595872619716,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 31,
        "unique-3-nopunct": 31,
        "entropy-3-nopunct": 4.954196310386877,
        "cond_entropy-3-nopunct": 0.03883444909293797,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.0118469607536897,
        "rouge1": {
            "precision": 0.76974,
            "recall": 0.60869,
            "fmeasure": 0.67401
        },
        "rouge2": {
            "precision": 0.50185,
            "recall": 0.37333,
            "fmeasure": 0.42174
        },
        "rougeL": {
            "precision": 0.57456,
            "recall": 0.43695,
            "fmeasure": 0.49085
        },
        "rougeLsum": {
            "precision": 0.57456,
            "recall": 0.43695,
            "fmeasure": 0.49085
        },
        "bleu": 27.61771,
        "local_recall": {
            "1": 0.0,
            "2": 0.0,
            "3": 0.6857142857142857
        },
        "bertscore": {
            "precision": 0.90842,
            "recall": 0.86628,
            "f1": 0.88411
        },
        "nubia": {
            "semantic_relation": 4.54025,
            "contradiction": 0.64217,
            "irrelevancy": 1.08835,
            "logical_agreement": 98.26948,
            "grammar_ref": 4.56621,
            "grammar_hyp": 4.6418,
            "nubia_score": 0.78134
        },
        "meteor": 0.31877548779648784,
        "bleurt": 0.12294
    },
    "totto_test_contrast_challenge_table_size-table_size_4340": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.3046173095544535,
        "rouge1": {
            "precision": 0.66667,
            "recall": 0.61616,
            "fmeasure": 0.63889
        },
        "rouge2": {
            "precision": 0.375,
            "recall": 0.3625,
            "fmeasure": 0.36806
        },
        "rougeL": {
            "precision": 0.61111,
            "recall": 0.57071,
            "fmeasure": 0.58889
        },
        "rougeLsum": {
            "precision": 0.61111,
            "recall": 0.57071,
            "fmeasure": 0.58889
        },
        "bleu": 52.5382,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.7142857142857143
        },
        "bertscore": {
            "precision": 0.9586,
            "recall": 0.95779,
            "f1": 0.95819
        },
        "nubia": {
            "semantic_relation": 3.31508,
            "contradiction": 98.2765,
            "irrelevancy": 1.13182,
            "logical_agreement": 0.59168,
            "grammar_ref": 5.60099,
            "grammar_hyp": 5.32713,
            "nubia_score": 0.36599
        },
        "meteor": 0.4461422973110841,
        "bleurt": 0.20361
    },
    "totto_test_contrast_challenge_table_size-table_size_1926": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 15,
        "mean_pred_length": 15.0,
        "std_pred_length": 0.0,
        "median_pred_length": 15.0,
        "min_pred_length": 15,
        "max_pred_length": 15,
        "distinct-1": 0.8666666666666667,
        "vocab_size-1": 13,
        "unique-1": 11,
        "entropy-1": 3.640223928941852,
        "distinct-2": 1.0,
        "vocab_size-2": 14,
        "unique-2": 14,
        "entropy-2": 3.8073549220576055,
        "cond_entropy-2": 0.18617861216337134,
        "distinct-3": 1.0,
        "vocab_size-3": 13,
        "unique-3": 13,
        "entropy-3": 3.7004397181410926,
        "cond_entropy-3": -0.1069152039165122,
        "total_length-nopunct": 13,
        "mean_pred_length-nopunct": 13.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8461538461538461,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.3927474104487847,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 12,
        "unique-2-nopunct": 12,
        "entropy-2-nopunct": 3.584962500721156,
        "cond_entropy-2-nopunct": 0.21785611591339743,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 11,
        "unique-3-nopunct": 11,
        "entropy-3-nopunct": 3.459431618637298,
        "cond_entropy-3-nopunct": -0.1255308820838591,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.766329012715601,
        "rouge1": {
            "precision": 0.92308,
            "recall": 0.83419,
            "fmeasure": 0.87546
        },
        "rouge2": {
            "precision": 0.75,
            "recall": 0.6627,
            "fmeasure": 0.70299
        },
        "rougeL": {
            "precision": 0.87179,
            "recall": 0.78291,
            "fmeasure": 0.82418
        },
        "rougeLsum": {
            "precision": 0.87179,
            "recall": 0.78291,
            "fmeasure": 0.82418
        },
        "bleu": 81.42442,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8888888888888888
        },
        "bertscore": {
            "precision": 0.98573,
            "recall": 0.95537,
            "f1": 0.96627
        },
        "nubia": {
            "semantic_relation": 4.94744,
            "contradiction": 0.308,
            "irrelevancy": 0.49541,
            "logical_agreement": 99.1966,
            "grammar_ref": 4.20051,
            "grammar_hyp": 4.4586,
            "nubia_score": 0.95267
        },
        "meteor": 0.4894845842304888,
        "bleurt": 0.59254
    },
    "totto_test_contrast_challenge_table_size-table_size_4352": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 0.8888888888888888,
        "vocab_size-1": 16,
        "unique-1": 14,
        "entropy-1": 3.94770277922009,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": 0.15283195745508585,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 15,
        "mean_pred_length-nopunct": 15.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 15,
        "distinct-1-nopunct": 0.9333333333333333,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 13,
        "entropy-1-nopunct": 3.773557262275185,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.043321469306228516,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 13,
        "unique-3-nopunct": 13,
        "entropy-3-nopunct": 3.7004397181410926,
        "cond_entropy-3-nopunct": -0.1069152039165122,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.373609831586596,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rouge2": {
            "precision": 0.92857,
            "recall": 0.86667,
            "fmeasure": 0.89655
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.9375,
            "fmeasure": 0.96774
        },
        "bleu": 85.22457,
        "local_recall": {
            "1": 0,
            "2": 1.0,
            "3": 0.9230769230769231
        },
        "bertscore": {
            "precision": 0.99784,
            "recall": 0.98969,
            "f1": 0.99375
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.35488,
            "irrelevancy": 10.42506,
            "logical_agreement": 89.22006,
            "grammar_ref": 4.10709,
            "grammar_hyp": 4.15345,
            "nubia_score": 0.98846
        },
        "meteor": 0.5747920211718521,
        "bleurt": 0.78906
    },
    "totto_test_contrast_challenge_table_size-table_size_1928": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 18.0,
        "std_pred_length": 0.0,
        "median_pred_length": 18.0,
        "min_pred_length": 18,
        "max_pred_length": 18,
        "distinct-1": 1.0,
        "vocab_size-1": 18,
        "unique-1": 18,
        "entropy-1": 4.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 17,
        "unique-2": 17,
        "entropy-2": 4.08746284125034,
        "cond_entropy-2": -0.08246216019197297,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.08746284125033939,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 16,
        "unique-1-nopunct": 16,
        "entropy-1-nopunct": 4.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": -0.09310940439148144,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.824880507153789,
        "rouge1": {
            "precision": 0.87719,
            "recall": 0.8631,
            "fmeasure": 0.86667
        },
        "rouge2": {
            "precision": 0.75926,
            "recall": 0.74444,
            "fmeasure": 0.74854
        },
        "rougeL": {
            "precision": 0.84211,
            "recall": 0.82143,
            "fmeasure": 0.82857
        },
        "rougeLsum": {
            "precision": 0.84211,
            "recall": 0.82143,
            "fmeasure": 0.82857
        },
        "bleu": 73.07717,
        "local_recall": {
            "1": 0.5,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.98923,
            "recall": 0.97729,
            "f1": 0.98323
        },
        "nubia": {
            "semantic_relation": 4.32268,
            "contradiction": 0.19584,
            "irrelevancy": 64.51964,
            "logical_agreement": 35.28452,
            "grammar_ref": 3.89472,
            "grammar_hyp": 3.68203,
            "nubia_score": 0.84215
        },
        "meteor": 0.5485086554805835,
        "bleurt": 0.29453
    },
    "totto_test_contrast_challenge_table_size-table_size_1936": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 18,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 0.7222222222222222,
        "vocab_size-1": 13,
        "unique-1": 8,
        "entropy-1": 3.614369445886757,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.3300749985576878,
        "distinct-3": 1.0,
        "vocab_size-3": 14,
        "unique-3": 14,
        "entropy-3": 3.8073549220576055,
        "cond_entropy-3": -0.19264507794239588,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 0.75,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.5,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 14,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.8073549220576055,
        "cond_entropy-2-nopunct": 0.3073549220576041,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 12,
        "entropy-3-nopunct": 3.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644807,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.2365972673111516,
        "rouge1": {
            "precision": 0.9,
            "recall": 0.57407,
            "fmeasure": 0.68842
        },
        "rouge2": {
            "precision": 0.53968,
            "recall": 0.34557,
            "fmeasure": 0.41288
        },
        "rougeL": {
            "precision": 0.9,
            "recall": 0.57407,
            "fmeasure": 0.68842
        },
        "rougeLsum": {
            "precision": 0.9,
            "recall": 0.57407,
            "fmeasure": 0.68842
        },
        "bleu": 12.474,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.94259,
            "recall": 0.88426,
            "f1": 0.9118
        },
        "nubia": {
            "semantic_relation": 4.36823,
            "contradiction": 1.32765,
            "irrelevancy": 3.49691,
            "logical_agreement": 95.17545,
            "grammar_ref": 3.22845,
            "grammar_hyp": 3.71742,
            "nubia_score": 0.75384
        },
        "meteor": 0.3298849611676232,
        "bleurt": 0.3511
    },
    "totto_test_contrast_challenge_table_size-table_size_5455": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 14,
        "mean_pred_length": 14.0,
        "std_pred_length": 0.0,
        "median_pred_length": 14.0,
        "min_pred_length": 14,
        "max_pred_length": 14,
        "distinct-1": 1.0,
        "vocab_size-1": 14,
        "unique-1": 14,
        "entropy-1": 3.8073549220576055,
        "distinct-2": 1.0,
        "vocab_size-2": 13,
        "unique-2": 13,
        "entropy-2": 3.7004397181410926,
        "cond_entropy-2": -0.1069152039165122,
        "distinct-3": 1.0,
        "vocab_size-3": 12,
        "unique-3": 12,
        "entropy-3": 3.584962500721156,
        "cond_entropy-3": -0.1154772174199359,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.616961879953846,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 0.90909,
            "recall": 0.90909,
            "fmeasure": 0.90909
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.83333,
            "fmeasure": 0.83333
        },
        "bleu": 74.19447,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.96124,
            "recall": 0.96353,
            "f1": 0.96239
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.24117,
            "irrelevancy": 0.43431,
            "logical_agreement": 99.32451,
            "grammar_ref": 4.72684,
            "grammar_hyp": 4.55935,
            "nubia_score": 0.9976
        },
        "meteor": 0.549453875996166,
        "bleurt": 0.65172
    },
    "totto_test_contrast_challenge_table_size-table_size_3016": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 0.8,
        "vocab_size-1": 8,
        "unique-1": 6,
        "entropy-1": 2.9219280948873623,
        "distinct-2": 0.8888888888888888,
        "vocab_size-2": 8,
        "unique-2": 7,
        "entropy-2": 2.94770277922009,
        "cond_entropy-2": 0.07021912877717243,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": 0.08007499855768763,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.7777777777777778,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 5,
        "entropy-1-nopunct": 2.725480556997868,
        "distinct-2-nopunct": 0.875,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.75,
        "cond_entropy-2-nopunct": -0.04492500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.47872969366552,
        "rouge1": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rouge2": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 1.0,
            "fmeasure": 1.0
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 1.20451,
            "irrelevancy": 0.76191,
            "logical_agreement": 98.03358,
            "grammar_ref": 4.07249,
            "grammar_hyp": 4.01604,
            "nubia_score": 0.98068
        },
        "meteor": 1.0,
        "bleurt": 0.9148
    },
    "totto_test_contrast_challenge_table_size-table_size_3047": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 26,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.5769230769230769,
        "vocab_size-1": 15,
        "unique-1": 4,
        "entropy-1": 3.854285871987246,
        "distinct-2": 0.5833333333333334,
        "vocab_size-2": 14,
        "unique-2": 4,
        "entropy-2": 3.751629167387823,
        "cond_entropy-2": -0.11547721741993588,
        "distinct-3": 0.5909090909090909,
        "vocab_size-3": 13,
        "unique-3": 4,
        "entropy-3": 3.6412498004554794,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 24,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.5833333333333334,
        "vocab_size-1-nopunct": 14,
        "unique-1-nopunct": 4,
        "entropy-1-nopunct": 3.751629167387823,
        "distinct-2-nopunct": 0.5909090909090909,
        "vocab_size-2-nopunct": 13,
        "unique-2-nopunct": 4,
        "entropy-2-nopunct": 3.6412498004554794,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 0.6,
        "vocab_size-3-nopunct": 12,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 3.521928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.2544789837508556,
        "rouge1": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rouge2": {
            "precision": 0.81818,
            "recall": 0.9,
            "fmeasure": 0.85714
        },
        "rougeL": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "rougeLsum": {
            "precision": 0.91667,
            "recall": 1.0,
            "fmeasure": 0.95652
        },
        "bleu": 82.65168,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.94318,
            "recall": 0.98431,
            "f1": 0.9633
        },
        "nubia": {
            "semantic_relation": 4.37248,
            "contradiction": 0.31688,
            "irrelevancy": 96.54524,
            "logical_agreement": 3.13788,
            "grammar_ref": 3.76088,
            "grammar_hyp": 3.47724,
            "nubia_score": 0.89041
        },
        "meteor": 0.5690637876265101,
        "bleurt": 0.56358
    },
    "totto_test_contrast_challenge_table_size-table_size_1969": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6908624231460283,
        "rouge1": {
            "precision": 0.41667,
            "recall": 0.46296,
            "fmeasure": 0.42857
        },
        "rouge2": {
            "precision": 0.30303,
            "recall": 0.37255,
            "fmeasure": 0.32832
        },
        "rougeL": {
            "precision": 0.38889,
            "recall": 0.44444,
            "fmeasure": 0.40635
        },
        "rougeLsum": {
            "precision": 0.38889,
            "recall": 0.44444,
            "fmeasure": 0.40635
        },
        "bleu": 31.4556,
        "local_recall": {
            "1": 0.2,
            "2": 0.1111111111111111,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.83164,
            "recall": 0.79747,
            "f1": 0.8142
        },
        "nubia": {
            "semantic_relation": 3.53107,
            "contradiction": 0.09322,
            "irrelevancy": 64.92257,
            "logical_agreement": 34.98421,
            "grammar_ref": 4.62828,
            "grammar_hyp": 4.74479,
            "nubia_score": 0.52254
        },
        "meteor": 0.31715797350293634,
        "bleurt": -0.23253
    },
    "totto_test_contrast_challenge_table_size-table_size_5538": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.32249814589546,
        "rouge1": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rouge2": {
            "precision": 0.66667,
            "recall": 0.47222,
            "fmeasure": 0.55238
        },
        "rougeL": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "rougeLsum": {
            "precision": 0.85714,
            "recall": 0.63333,
            "fmeasure": 0.72794
        },
        "bleu": 41.10546,
        "local_recall": {
            "1": 0.0,
            "2": 0.5555555555555556
        },
        "bertscore": {
            "precision": 0.96587,
            "recall": 0.9307,
            "f1": 0.94796
        },
        "nubia": {
            "semantic_relation": 4.62868,
            "contradiction": 0.5038,
            "irrelevancy": 0.54324,
            "logical_agreement": 98.95296,
            "grammar_ref": 4.24503,
            "grammar_hyp": 4.03961,
            "nubia_score": 0.96227
        },
        "meteor": 0.8569614896318238,
        "bleurt": 0.65075
    },
    "totto_test_contrast_challenge_table_size-table_size_3141": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 0.9230769230769231,
        "vocab_size-1": 12,
        "unique-1": 11,
        "entropy-1": 3.5465935642949384,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": 0.05118944924673077,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.9166666666666666,
        "vocab_size-1-nopunct": 11,
        "unique-1-nopunct": 10,
        "entropy-1-nopunct": 3.418295834054489,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": 0.056287299734322706,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.4803731939169826,
        "rouge1": {
            "precision": 0.58333,
            "recall": 0.63636,
            "fmeasure": 0.6087
        },
        "rouge2": {
            "precision": 0.31818,
            "recall": 0.35,
            "fmeasure": 0.33333
        },
        "rougeL": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "rougeLsum": {
            "precision": 0.5,
            "recall": 0.54545,
            "fmeasure": 0.52174
        },
        "bleu": 40.89601,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.8799,
            "recall": 0.89403,
            "f1": 0.88691
        },
        "nubia": {
            "semantic_relation": 3.24604,
            "contradiction": 0.10739,
            "irrelevancy": 99.54121,
            "logical_agreement": 0.35139,
            "grammar_ref": 4.25346,
            "grammar_hyp": 4.26479,
            "nubia_score": 0.4916
        },
        "meteor": 0.3155536125220693,
        "bleurt": -0.16022
    },
    "totto_test_contrast_challenge_table_size-table_size_1428": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.6449508967673327,
        "rouge1": {
            "precision": 0.5,
            "recall": 0.35714,
            "fmeasure": 0.41667
        },
        "rouge2": {
            "precision": 0.18519,
            "recall": 0.12821,
            "fmeasure": 0.15152
        },
        "rougeL": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "rougeLsum": {
            "precision": 0.4,
            "recall": 0.28571,
            "fmeasure": 0.33333
        },
        "bleu": 6.97142,
        "local_recall": {
            "1": 0.16666666666666666,
            "2": 0.2,
            "3": 0.42857142857142855
        },
        "bertscore": {
            "precision": 0.77637,
            "recall": 0.78045,
            "f1": 0.7784
        },
        "nubia": {
            "semantic_relation": 3.10004,
            "contradiction": 0.35242,
            "irrelevancy": 99.20395,
            "logical_agreement": 0.44363,
            "grammar_ref": 3.90604,
            "grammar_hyp": 4.77201,
            "nubia_score": 0.31901
        },
        "meteor": 0.22774597660352036,
        "bleurt": -0.24248
    },
    "totto_test_contrast_challenge_table_size-table_size_5550": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.6459952152162507,
        "rouge1": {
            "precision": 0.74074,
            "recall": 0.74074,
            "fmeasure": 0.74074
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.54167,
            "fmeasure": 0.54167
        },
        "rougeL": {
            "precision": 0.74074,
            "recall": 0.74074,
            "fmeasure": 0.74074
        },
        "rougeLsum": {
            "precision": 0.74074,
            "recall": 0.74074,
            "fmeasure": 0.74074
        },
        "bleu": 43.01464,
        "local_recall": {
            "1": 1.0,
            "2": 0.0,
            "3": 0.8571428571428571
        },
        "bertscore": {
            "precision": 0.95268,
            "recall": 0.91533,
            "f1": 0.93364
        },
        "nubia": {
            "semantic_relation": 4.73332,
            "contradiction": 0.4221,
            "irrelevancy": 3.95366,
            "logical_agreement": 95.62424,
            "grammar_ref": 4.6877,
            "grammar_hyp": 5.45275,
            "nubia_score": 0.77983
        },
        "meteor": 0.4575818433959837,
        "bleurt": 0.40015
    },
    "totto_test_contrast_challenge_table_size-table_size_1974": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 19,
        "mean_pred_length": 9.5,
        "std_pred_length": 0.5,
        "median_pred_length": 9.5,
        "min_pred_length": 9,
        "max_pred_length": 10,
        "distinct-1": 0.47368421052631576,
        "vocab_size-1": 9,
        "unique-1": 3,
        "entropy-1": 2.9847696187067436,
        "distinct-2": 0.5294117647058824,
        "vocab_size-2": 9,
        "unique-2": 3,
        "entropy-2": 3.0286393118385755,
        "cond_entropy-2": 0.0748294454538127,
        "distinct-3": 0.6,
        "vocab_size-3": 9,
        "unique-3": 3,
        "entropy-3": 3.106890595608519,
        "cond_entropy-3": 0.08609442102484582,
        "total_length-nopunct": 17,
        "mean_pred_length-nopunct": 8.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 0.47058823529411764,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 3,
        "entropy-1-nopunct": 2.793345194191516,
        "distinct-2-nopunct": 0.5333333333333333,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 3,
        "entropy-2-nopunct": 2.8402239289418523,
        "cond_entropy-2-nopunct": -0.0472389123084875,
        "distinct-3-nopunct": 0.6153846153846154,
        "vocab_size-3-nopunct": 8,
        "unique-3-nopunct": 3,
        "entropy-3-nopunct": 2.931208948910323,
        "cond_entropy-3-nopunct": -0.05260472362127268,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.451815875634701,
        "rouge1": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rouge2": {
            "precision": 0.79464,
            "recall": 0.72685,
            "fmeasure": 0.75776
        },
        "rougeL": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "rougeLsum": {
            "precision": 0.90046,
            "recall": 0.82593,
            "fmeasure": 0.86028
        },
        "bleu": 69.05636,
        "local_recall": {
            "1": 0.4,
            "2": 0.0,
            "3": 0.7692307692307693
        },
        "bertscore": {
            "precision": 0.98549,
            "recall": 0.97733,
            "f1": 0.98137
        },
        "nubia": {
            "semantic_relation": 4.99611,
            "contradiction": 0.40178,
            "irrelevancy": 0.5141,
            "logical_agreement": 99.08412,
            "grammar_ref": 4.85767,
            "grammar_hyp": 5.20195,
            "nubia_score": 0.97201
        },
        "meteor": 0.9489775258149422,
        "bleurt": 0.78257
    },
    "totto_test_contrast_challenge_table_size-table_size_5082": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7456398254417365,
        "rouge1": {
            "precision": 0.96296,
            "recall": 0.8963,
            "fmeasure": 0.92788
        },
        "rouge2": {
            "precision": 0.54167,
            "recall": 0.49537,
            "fmeasure": 0.51716
        },
        "rougeL": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "rougeLsum": {
            "precision": 0.85185,
            "recall": 0.79259,
            "fmeasure": 0.82066
        },
        "bleu": 55.62833,
        "local_recall": {
            "1": 0.0,
            "2": 1.0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.97269,
            "recall": 0.95351,
            "f1": 0.963
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.18796,
            "irrelevancy": 0.48475,
            "logical_agreement": 99.32729,
            "grammar_ref": 4.96639,
            "grammar_hyp": 5.58474,
            "nubia_score": 0.95724
        },
        "meteor": 0.46736318340128513,
        "bleurt": 0.70029
    },
    "totto_test_contrast_challenge_table_size-table_size_5094": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 9,
        "mean_pred_length": 9.0,
        "std_pred_length": 0.0,
        "median_pred_length": 9.0,
        "min_pred_length": 9,
        "max_pred_length": 9,
        "distinct-1": 1.0,
        "vocab_size-1": 9,
        "unique-1": 9,
        "entropy-1": 3.169925001442312,
        "distinct-2": 1.0,
        "vocab_size-2": 8,
        "unique-2": 8,
        "entropy-2": 3.0,
        "cond_entropy-2": -0.16992500144231237,
        "distinct-3": 1.0,
        "vocab_size-3": 7,
        "unique-3": 7,
        "entropy-3": 2.807354922057604,
        "cond_entropy-3": -0.19264507794239583,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.036680632058506,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96296
        },
        "rouge2": {
            "precision": 0.95238,
            "recall": 0.88889,
            "fmeasure": 0.91667
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96296
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.93333,
            "fmeasure": 0.96296
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0,
            "2": 0.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 4.48528,
            "contradiction": 2.29987,
            "irrelevancy": 0.99674,
            "logical_agreement": 96.70339,
            "grammar_ref": 4.01433,
            "grammar_hyp": 4.43425,
            "nubia_score": 0.78188
        },
        "meteor": 1.0,
        "bleurt": 0.67104
    },
    "totto_test_contrast_challenge_table_size-table_size_5656": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 23,
        "mean_pred_length": 11.5,
        "std_pred_length": 4.5,
        "median_pred_length": 11.5,
        "min_pred_length": 7,
        "max_pred_length": 16,
        "distinct-1": 0.9130434782608695,
        "vocab_size-1": 21,
        "unique-1": 19,
        "entropy-1": 4.349648912578752,
        "distinct-2": 1.0,
        "vocab_size-2": 21,
        "unique-2": 21,
        "entropy-2": 4.39231742277876,
        "cond_entropy-2": -0.03600643804015718,
        "distinct-3": 1.0,
        "vocab_size-3": 19,
        "unique-3": 19,
        "entropy-3": 4.247927513443583,
        "cond_entropy-3": -0.14438990933517493,
        "total_length-nopunct": 19,
        "mean_pred_length-nopunct": 9.5,
        "std_pred_length-nopunct": 3.5,
        "median_pred_length-nopunct": 9.5,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.9473684210526315,
        "vocab_size-1-nopunct": 18,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.142664355548846,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 17,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.08746284125034,
        "cond_entropy-2-nopunct": -0.04281761336971671,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 15,
        "unique-3-nopunct": 15,
        "entropy-3-nopunct": 3.906890595608518,
        "cond_entropy-3-nopunct": -0.18057224564182078,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.877371624575593,
        "rouge1": {
            "precision": 0.98611,
            "recall": 0.82222,
            "fmeasure": 0.88442
        },
        "rouge2": {
            "precision": 0.7697,
            "recall": 0.66389,
            "fmeasure": 0.70147
        },
        "rougeL": {
            "precision": 0.90278,
            "recall": 0.76852,
            "fmeasure": 0.81914
        },
        "rougeLsum": {
            "precision": 0.90278,
            "recall": 0.76852,
            "fmeasure": 0.81914
        },
        "bleu": 65.50602,
        "local_recall": {
            "1": 0.14285714285714285,
            "2": 0.0,
            "3": 0.8947368421052632
        },
        "bertscore": {
            "precision": 0.97651,
            "recall": 0.93466,
            "f1": 0.95376
        },
        "nubia": {
            "semantic_relation": 4.5277,
            "contradiction": 25.23861,
            "irrelevancy": 2.36379,
            "logical_agreement": 72.3976,
            "grammar_ref": 6.17452,
            "grammar_hyp": 6.51778,
            "nubia_score": 0.72143
        },
        "meteor": 0.4532957403133561,
        "bleurt": 0.4634
    },
    "totto_test_contrast_challenge_table_size-table_size_6225": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 13,
        "mean_pred_length": 13.0,
        "std_pred_length": 0.0,
        "median_pred_length": 13.0,
        "min_pred_length": 13,
        "max_pred_length": 13,
        "distinct-1": 1.0,
        "vocab_size-1": 13,
        "unique-1": 13,
        "entropy-1": 3.7004397181410926,
        "distinct-2": 1.0,
        "vocab_size-2": 12,
        "unique-2": 12,
        "entropy-2": 3.584962500721156,
        "cond_entropy-2": -0.1154772174199359,
        "distinct-3": 1.0,
        "vocab_size-3": 11,
        "unique-3": 11,
        "entropy-3": 3.459431618637298,
        "cond_entropy-3": -0.1255308820838591,
        "total_length-nopunct": 12,
        "mean_pred_length-nopunct": 12.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 12,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 11,
        "unique-2-nopunct": 11,
        "entropy-2-nopunct": 3.459431618637298,
        "cond_entropy-2-nopunct": -0.1255308820838591,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 10,
        "unique-3-nopunct": 10,
        "entropy-3-nopunct": 3.321928094887362,
        "cond_entropy-3-nopunct": -0.13750352374993502,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.0981975091179785,
        "rouge1": {
            "precision": 0.76923,
            "recall": 0.47619,
            "fmeasure": 0.58824
        },
        "rouge2": {
            "precision": 0.52778,
            "recall": 0.29286,
            "fmeasure": 0.375
        },
        "rougeL": {
            "precision": 0.76923,
            "recall": 0.47619,
            "fmeasure": 0.58824
        },
        "rougeLsum": {
            "precision": 0.76923,
            "recall": 0.47619,
            "fmeasure": 0.58824
        },
        "bleu": 26.03338,
        "local_recall": {
            "1": 0.25,
            "2": 0.1,
            "3": 0.6363636363636364
        },
        "bertscore": {
            "precision": 0.96612,
            "recall": 0.88009,
            "f1": 0.9211
        },
        "nubia": {
            "semantic_relation": 4.16208,
            "contradiction": 0.09927,
            "irrelevancy": 66.60413,
            "logical_agreement": 33.29661,
            "grammar_ref": 3.9898,
            "grammar_hyp": 5.65139,
            "nubia_score": 0.4993
        },
        "meteor": 0.35173481544534596,
        "bleurt": 0.29084
    },
    "totto_test_contrast_challenge_table_size-table_size_6643": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.1229419688230418,
        "rouge1": {
            "precision": 0.33333,
            "recall": 0.5,
            "fmeasure": 0.4
        },
        "rouge2": {
            "precision": 0.125,
            "recall": 0.2,
            "fmeasure": 0.15385
        },
        "rougeL": {
            "precision": 0.22222,
            "recall": 0.33333,
            "fmeasure": 0.26667
        },
        "rougeLsum": {
            "precision": 0.22222,
            "recall": 0.33333,
            "fmeasure": 0.26667
        },
        "bleu": 9.9801,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.5
        },
        "bertscore": {
            "precision": 0.84638,
            "recall": 0.8931,
            "f1": 0.86911
        },
        "nubia": {
            "semantic_relation": 4.79456,
            "contradiction": 0.37121,
            "irrelevancy": 0.94757,
            "logical_agreement": 98.68123,
            "grammar_ref": 5.72796,
            "grammar_hyp": 4.10067,
            "nubia_score": 1.0
        },
        "meteor": 0.2806132642220446,
        "bleurt": 0.59675
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-4": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73476,
        "msttr-100_nopunct": 0.747,
        "total_length": 2176,
        "mean_pred_length": 20.528301886792452,
        "std_pred_length": 3.4180639647840017,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.42784926470588236,
        "vocab_size-1": 931,
        "unique-1": 700,
        "entropy-1": 8.329976385613982,
        "distinct-2": 0.8531400966183574,
        "vocab_size-2": 1766,
        "unique-2": 1633,
        "entropy-2": 10.579400577460307,
        "cond_entropy-2": 2.1504945493777528,
        "distinct-3": 0.9689409368635438,
        "vocab_size-3": 1903,
        "unique-3": 1863,
        "entropy-3": 10.862721983767795,
        "cond_entropy-3": 0.2951586403798023,
        "total_length-nopunct": 2061,
        "mean_pred_length-nopunct": 19.443396226415093,
        "std_pred_length-nopunct": 3.550392454201885,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4483260553129549,
        "vocab_size-1-nopunct": 924,
        "unique-1-nopunct": 700,
        "entropy-1-nopunct": 8.395600162362102,
        "distinct-2-nopunct": 0.8588235294117647,
        "vocab_size-2-nopunct": 1679,
        "unique-2-nopunct": 1557,
        "entropy-2-nopunct": 10.513197438327357,
        "cond_entropy-2-nopunct": 2.2189710213819427,
        "distinct-3-nopunct": 0.9756625202812331,
        "vocab_size-3-nopunct": 1804,
        "unique-3-nopunct": 1770,
        "entropy-3-nopunct": 10.798371064035184,
        "cond_entropy-3-nopunct": 0.29568885378993187,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.3991188158261076,
        "rouge1": {
            "precision": 0.4466,
            "recall": 0.39852,
            "fmeasure": 0.41537
        },
        "rouge2": {
            "precision": 0.17675,
            "recall": 0.15586,
            "fmeasure": 0.1632
        },
        "rougeL": {
            "precision": 0.34364,
            "recall": 0.30817,
            "fmeasure": 0.32052
        },
        "rougeLsum": {
            "precision": 0.34364,
            "recall": 0.30817,
            "fmeasure": 0.32052
        },
        "bleu": 10.32664,
        "local_recall": {
            "1": 0.3633469758981355
        },
        "bertscore": {
            "precision": 0.83768,
            "recall": 0.8232,
            "f1": 0.83008
        },
        "nubia": {
            "semantic_relation": 3.05451,
            "contradiction": 20.38569,
            "irrelevancy": 67.28478,
            "logical_agreement": 12.32953,
            "grammar_ref": 3.83852,
            "grammar_hyp": 3.6931,
            "nubia_score": 0.44974
        },
        "meteor": 0.17446720752042802,
        "bleurt": -0.32437
    },
    "totto_test_contrast_challenge_table_size-table_size_8082": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 17,
        "mean_pred_length": 17.0,
        "std_pred_length": 0.0,
        "median_pred_length": 17.0,
        "min_pred_length": 17,
        "max_pred_length": 17,
        "distinct-1": 0.9411764705882353,
        "vocab_size-1": 16,
        "unique-1": 15,
        "entropy-1": 3.969815782426811,
        "distinct-2": 1.0,
        "vocab_size-2": 16,
        "unique-2": 16,
        "entropy-2": 4.0,
        "cond_entropy-2": 0.037537158749660585,
        "distinct-3": 1.0,
        "vocab_size-3": 15,
        "unique-3": 15,
        "entropy-3": 3.906890595608518,
        "cond_entropy-3": -0.09310940439148144,
        "total_length-nopunct": 16,
        "mean_pred_length-nopunct": 16.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 16,
        "max_pred_length-nopunct": 16,
        "distinct-1-nopunct": 0.9375,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 14,
        "entropy-1-nopunct": 3.875,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 15,
        "entropy-2-nopunct": 3.906890595608518,
        "cond_entropy-2-nopunct": 0.040223928941851894,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.09953567355091435,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 1.9783935498526977,
        "rouge1": {
            "precision": 0.625,
            "recall": 0.83333,
            "fmeasure": 0.71429
        },
        "rouge2": {
            "precision": 0.33333,
            "recall": 0.45455,
            "fmeasure": 0.38462
        },
        "rougeL": {
            "precision": 0.375,
            "recall": 0.5,
            "fmeasure": 0.42857
        },
        "rougeLsum": {
            "precision": 0.375,
            "recall": 0.5,
            "fmeasure": 0.42857
        },
        "bleu": 17.53482,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.86657,
            "recall": 0.90638,
            "f1": 0.88321
        },
        "nubia": {
            "semantic_relation": 4.00225,
            "contradiction": 0.46067,
            "irrelevancy": 95.08463,
            "logical_agreement": 4.4547,
            "grammar_ref": 4.44512,
            "grammar_hyp": 4.83486,
            "nubia_score": 0.60516
        },
        "meteor": 0.37546483857181184,
        "bleurt": -0.2125
    },
    "totto_test_contrast_challenge_table_size-table_size_8822": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 27,
        "mean_pred_length": 13.5,
        "std_pred_length": 0.5,
        "median_pred_length": 13.5,
        "min_pred_length": 13,
        "max_pred_length": 14,
        "distinct-1": 0.8518518518518519,
        "vocab_size-1": 23,
        "unique-1": 19,
        "entropy-1": 4.458591205867174,
        "distinct-2": 0.92,
        "vocab_size-2": 23,
        "unique-2": 21,
        "entropy-2": 4.4838561897747224,
        "cond_entropy-2": -0.031031312388743952,
        "distinct-3": 0.9565217391304348,
        "vocab_size-3": 22,
        "unique-3": 21,
        "entropy-3": 4.436605434317882,
        "cond_entropy-3": -0.03333771197858132,
        "total_length-nopunct": 23,
        "mean_pred_length-nopunct": 11.5,
        "std_pred_length-nopunct": 1.5,
        "median_pred_length-nopunct": 11.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 13,
        "distinct-1-nopunct": 0.8695652173913043,
        "vocab_size-1-nopunct": 20,
        "unique-1-nopunct": 17,
        "entropy-1-nopunct": 4.2626923908396215,
        "distinct-2-nopunct": 0.9047619047619048,
        "vocab_size-2-nopunct": 19,
        "unique-2-nopunct": 17,
        "entropy-2-nopunct": 4.201841232302569,
        "cond_entropy-2-nopunct": -0.03600643804015718,
        "distinct-3-nopunct": 0.9473684210526315,
        "vocab_size-3-nopunct": 18,
        "unique-3-nopunct": 17,
        "entropy-3-nopunct": 4.142664355548846,
        "cond_entropy-3-nopunct": -0.0391267514404381,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.033811857640783,
        "rouge1": {
            "precision": 0.59829,
            "recall": 0.62222,
            "fmeasure": 0.60287
        },
        "rouge2": {
            "precision": 0.35417,
            "recall": 0.34028,
            "fmeasure": 0.34412
        },
        "rougeL": {
            "precision": 0.58547,
            "recall": 0.6037,
            "fmeasure": 0.58772
        },
        "rougeLsum": {
            "precision": 0.58547,
            "recall": 0.6037,
            "fmeasure": 0.58772
        },
        "bleu": 28.96563,
        "local_recall": {
            "1": 0.0,
            "2": 0.75,
            "3": 0.6666666666666666
        },
        "bertscore": {
            "precision": 0.8917,
            "recall": 0.89843,
            "f1": 0.89499
        },
        "nubia": {
            "semantic_relation": 4.19596,
            "contradiction": 45.59844,
            "irrelevancy": 44.02801,
            "logical_agreement": 10.37355,
            "grammar_ref": 5.12311,
            "grammar_hyp": 5.09553,
            "nubia_score": 0.58967
        },
        "meteor": 0.31988961661779736,
        "bleurt": 0.18789
    },
    "totto_test_contrast_challenge_table_size-table_size_8946": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 11,
        "mean_pred_length": 11.0,
        "std_pred_length": 0.0,
        "median_pred_length": 11.0,
        "min_pred_length": 11,
        "max_pred_length": 11,
        "distinct-1": 1.0,
        "vocab_size-1": 11,
        "unique-1": 11,
        "entropy-1": 3.459431618637298,
        "distinct-2": 1.0,
        "vocab_size-2": 10,
        "unique-2": 10,
        "entropy-2": 3.321928094887362,
        "cond_entropy-2": -0.13750352374993502,
        "distinct-3": 1.0,
        "vocab_size-3": 9,
        "unique-3": 9,
        "entropy-3": 3.169925001442312,
        "cond_entropy-3": -0.15200309344504973,
        "total_length-nopunct": 8,
        "mean_pred_length-nopunct": 8.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 8,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 8,
        "unique-1-nopunct": 8,
        "entropy-1-nopunct": 3.0,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 7,
        "unique-2-nopunct": 7,
        "entropy-2-nopunct": 2.807354922057604,
        "cond_entropy-2-nopunct": -0.19264507794239583,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 6,
        "unique-3-nopunct": 6,
        "entropy-3-nopunct": 2.584962500721156,
        "cond_entropy-3-nopunct": -0.22239242133644804,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.1566687205209765,
        "rouge1": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.5,
            "fmeasure": 0.53333
        },
        "rougeL": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "rougeLsum": {
            "precision": 0.875,
            "recall": 0.77778,
            "fmeasure": 0.82353
        },
        "bleu": 47.0852,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.96017,
            "recall": 0.94001,
            "f1": 0.94998
        },
        "nubia": {
            "semantic_relation": 4.8718,
            "contradiction": 0.95834,
            "irrelevancy": 0.67672,
            "logical_agreement": 98.36494,
            "grammar_ref": 5.69157,
            "grammar_hyp": 5.45667,
            "nubia_score": 0.93365
        },
        "meteor": 0.506392260197945,
        "bleurt": 0.6985
    },
    "totto_test_contrast_challenge_table_size-table_size_10500": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 7,
        "mean_pred_length": 7.0,
        "std_pred_length": 0.0,
        "median_pred_length": 7.0,
        "min_pred_length": 7,
        "max_pred_length": 7,
        "distinct-1": 1.0,
        "vocab_size-1": 7,
        "unique-1": 7,
        "entropy-1": 2.807354922057604,
        "distinct-2": 1.0,
        "vocab_size-2": 6,
        "unique-2": 6,
        "entropy-2": 2.584962500721156,
        "cond_entropy-2": -0.22239242133644804,
        "distinct-3": 1.0,
        "vocab_size-3": 5,
        "unique-3": 5,
        "entropy-3": 2.321928094887362,
        "cond_entropy-3": -0.26303440583379406,
        "total_length-nopunct": 6,
        "mean_pred_length-nopunct": 6.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 6,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 6,
        "unique-1-nopunct": 6,
        "entropy-1-nopunct": 2.584962500721156,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 5,
        "unique-2-nopunct": 5,
        "entropy-2-nopunct": 2.321928094887362,
        "cond_entropy-2-nopunct": -0.26303440583379406,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 4,
        "unique-3-nopunct": 4,
        "entropy-3-nopunct": 2.0,
        "cond_entropy-3-nopunct": -0.32192809488736235,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.721565937283315,
        "rouge1": {
            "precision": 0.91667,
            "recall": 0.85714,
            "fmeasure": 0.88462
        },
        "rouge2": {
            "precision": 0.7,
            "recall": 0.66667,
            "fmeasure": 0.68182
        },
        "rougeL": {
            "precision": 0.83333,
            "recall": 0.78571,
            "fmeasure": 0.80769
        },
        "rougeLsum": {
            "precision": 0.83333,
            "recall": 0.78571,
            "fmeasure": 0.80769
        },
        "bleu": 100.0,
        "local_recall": {
            "1": 0.5,
            "2": 1.0
        },
        "bertscore": {
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.50935,
            "irrelevancy": 0.55819,
            "logical_agreement": 98.93246,
            "grammar_ref": 7.77345,
            "grammar_hyp": 8.12356,
            "nubia_score": 0.95487
        },
        "meteor": 1.0,
        "bleurt": 0.794
    },
    "totto_test_contrast_challenge_table_size-table_size_13590": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 20,
        "mean_pred_length": 10.0,
        "std_pred_length": 1.0,
        "median_pred_length": 10.0,
        "min_pred_length": 9,
        "max_pred_length": 11,
        "distinct-1": 0.8,
        "vocab_size-1": 16,
        "unique-1": 12,
        "entropy-1": 3.9219280948873623,
        "distinct-2": 0.9444444444444444,
        "vocab_size-2": 17,
        "unique-2": 16,
        "entropy-2": 4.058813890331201,
        "cond_entropy-2": 0.07021912877717244,
        "distinct-3": 1.0,
        "vocab_size-3": 16,
        "unique-3": 16,
        "entropy-3": 4.0,
        "cond_entropy-3": -0.04492500144231237,
        "total_length-nopunct": 18,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 1.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.8333333333333334,
        "vocab_size-1-nopunct": 15,
        "unique-1-nopunct": 12,
        "entropy-1-nopunct": 3.8365916681089787,
        "distinct-2-nopunct": 0.9375,
        "vocab_size-2-nopunct": 15,
        "unique-2-nopunct": 14,
        "entropy-2-nopunct": 3.875,
        "cond_entropy-2-nopunct": 0.017574998557687627,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 14,
        "unique-3-nopunct": 14,
        "entropy-3-nopunct": 3.8073549220576055,
        "cond_entropy-3-nopunct": -0.04978793508525296,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7504634308253633,
        "rouge1": {
            "precision": 0.8125,
            "recall": 0.75694,
            "fmeasure": 0.78064
        },
        "rouge2": {
            "precision": 0.52381,
            "recall": 0.5006,
            "fmeasure": 0.51064
        },
        "rougeL": {
            "precision": 0.72917,
            "recall": 0.68908,
            "fmeasure": 0.70682
        },
        "rougeLsum": {
            "precision": 0.72917,
            "recall": 0.68908,
            "fmeasure": 0.70682
        },
        "bleu": 40.45534,
        "local_recall": {
            "1": 0.42857142857142855,
            "2": 0.5,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.90508,
            "recall": 0.90286,
            "f1": 0.90269
        },
        "nubia": {
            "semantic_relation": 4.02163,
            "contradiction": 12.85213,
            "irrelevancy": 32.87888,
            "logical_agreement": 54.269,
            "grammar_ref": 5.40028,
            "grammar_hyp": 5.41626,
            "nubia_score": 0.62812
        },
        "meteor": 0.42993058096762327,
        "bleurt": 0.0792
    },
    "totto_test_contrast_challenge_table_size-table_size_14710": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 12,
        "mean_pred_length": 12.0,
        "std_pred_length": 0.0,
        "median_pred_length": 12.0,
        "min_pred_length": 12,
        "max_pred_length": 12,
        "distinct-1": 1.0,
        "vocab_size-1": 12,
        "unique-1": 12,
        "entropy-1": 3.584962500721156,
        "distinct-2": 1.0,
        "vocab_size-2": 11,
        "unique-2": 11,
        "entropy-2": 3.459431618637298,
        "cond_entropy-2": -0.1255308820838591,
        "distinct-3": 1.0,
        "vocab_size-3": 10,
        "unique-3": 10,
        "entropy-3": 3.321928094887362,
        "cond_entropy-3": -0.13750352374993502,
        "total_length-nopunct": 9,
        "mean_pred_length-nopunct": 9.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 9,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 9,
        "unique-1-nopunct": 9,
        "entropy-1-nopunct": 3.169925001442312,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 8,
        "unique-2-nopunct": 8,
        "entropy-2-nopunct": 3.0,
        "cond_entropy-2-nopunct": -0.16992500144231237,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 7,
        "unique-3-nopunct": 7,
        "entropy-3-nopunct": 2.807354922057604,
        "cond_entropy-3-nopunct": -0.19264507794239583,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.486926369228986,
        "rouge1": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rouge2": {
            "precision": 0.57143,
            "recall": 0.8,
            "fmeasure": 0.66667
        },
        "rougeL": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "rougeLsum": {
            "precision": 0.75,
            "recall": 1.0,
            "fmeasure": 0.85714
        },
        "bleu": 77.10956,
        "local_recall": {
            "1": 0.3333333333333333,
            "2": 1.0,
            "3": 1.0
        },
        "bertscore": {
            "precision": 0.92709,
            "recall": 0.97648,
            "f1": 0.94289
        },
        "nubia": {
            "semantic_relation": 4.35593,
            "contradiction": 7.93939,
            "irrelevancy": 60.79307,
            "logical_agreement": 31.26754,
            "grammar_ref": 5.78237,
            "grammar_hyp": 5.23835,
            "nubia_score": 0.73081
        },
        "meteor": 0.5076314091757458,
        "bleurt": 0.27053
    },
    "totto_test_contrast_challenge_table_size-table_size_15144": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 8,
        "mean_pred_length": 8.0,
        "std_pred_length": 0.0,
        "median_pred_length": 8.0,
        "min_pred_length": 8,
        "max_pred_length": 8,
        "distinct-1": 1.0,
        "vocab_size-1": 8,
        "unique-1": 8,
        "entropy-1": 3.0,
        "distinct-2": 1.0,
        "vocab_size-2": 7,
        "unique-2": 7,
        "entropy-2": 2.807354922057604,
        "cond_entropy-2": -0.19264507794239583,
        "distinct-3": 1.0,
        "vocab_size-3": 6,
        "unique-3": 6,
        "entropy-3": 2.584962500721156,
        "cond_entropy-3": -0.22239242133644804,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.9898332363522426,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rouge2": {
            "precision": 0.83333,
            "recall": 0.71429,
            "fmeasure": 0.76923
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.875,
            "fmeasure": 0.93333
        },
        "bleu": 61.0195,
        "local_recall": {
            "1": 0,
            "2": 0,
            "3": 0.875
        },
        "bertscore": {
            "precision": 0.99164,
            "recall": 0.97723,
            "f1": 0.98438
        },
        "nubia": {
            "semantic_relation": 5.0,
            "contradiction": 0.51812,
            "irrelevancy": 0.46692,
            "logical_agreement": 99.01496,
            "grammar_ref": 5.85687,
            "grammar_hyp": 6.57356,
            "nubia_score": 0.90444
        },
        "meteor": 0.5230551846972475,
        "bleurt": 0.84839
    },
    "web_nlg_en_test_contrast_challenge_args-both_unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 1177,
        "msttr-100": 0.65118,
        "msttr-100_nopunct": 0.66995,
        "total_length": 22024,
        "mean_pred_length": 18.71197960917587,
        "std_pred_length": 6.607541910562437,
        "median_pred_length": 20.0,
        "min_pred_length": 6,
        "max_pred_length": 31,
        "distinct-1": 0.058073011260443154,
        "vocab_size-1": 1279,
        "unique-1": 405,
        "entropy-1": 7.782133949644583,
        "distinct-2": 0.21605027102220942,
        "vocab_size-2": 4504,
        "unique-2": 2237,
        "entropy-2": 10.768211495072881,
        "cond_entropy-2": 2.921952069358907,
        "distinct-3": 0.38734112862226744,
        "vocab_size-3": 7619,
        "unique-3": 4754,
        "entropy-3": 11.964082500807544,
        "cond_entropy-3": 1.2981521323075453,
        "total_length-nopunct": 20170,
        "mean_pred_length-nopunct": 17.13678844519966,
        "std_pred_length-nopunct": 6.394226438122952,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06301437778879523,
        "vocab_size-1-nopunct": 1271,
        "unique-1-nopunct": 404,
        "entropy-1-nopunct": 7.913431710525105,
        "distinct-2-nopunct": 0.22134470594429526,
        "vocab_size-2-nopunct": 4204,
        "unique-2-nopunct": 2173,
        "entropy-2-nopunct": 10.644412255056677,
        "cond_entropy-2-nopunct": 2.9115850339953337,
        "distinct-3-nopunct": 0.39419622810956445,
        "vocab_size-3-nopunct": 7023,
        "unique-3-nopunct": 4473,
        "entropy-3-nopunct": 11.827964926058609,
        "cond_entropy-3-nopunct": 1.2765542261223195,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.296595900929852,
        "rouge1": {
            "precision": 0.76777,
            "recall": 0.70009,
            "fmeasure": 0.72275
        },
        "rouge2": {
            "precision": 0.50343,
            "recall": 0.45819,
            "fmeasure": 0.47294
        },
        "rougeL": {
            "precision": 0.62746,
            "recall": 0.57332,
            "fmeasure": 0.59109
        },
        "rougeLsum": {
            "precision": 0.62746,
            "recall": 0.57332,
            "fmeasure": 0.59109
        },
        "bleu": 39.9146,
        "local_recall": {
            "1": 0.18782856633698655,
            "2": 0.5075584058634907,
            "3": 0.782234720039699,
            "4": 0.5,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.91738,
            "recall": 0.90262,
            "f1": 0.90848
        },
        "nubia": {
            "semantic_relation": 4.192,
            "contradiction": 7.5085,
            "irrelevancy": 11.01651,
            "logical_agreement": 81.47499,
            "grammar_ref": 4.6454,
            "grammar_hyp": 4.85393,
            "nubia_score": 0.69622
        },
        "meteor": 0.33937180030548736,
        "bleurt": 0.07876
    },
    "totto_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 2221,
        "msttr-100": 0.73547,
        "msttr-100_nopunct": 0.78941,
        "total_length": 33338,
        "mean_pred_length": 15.010355695632597,
        "std_pred_length": 4.00903761880531,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 33,
        "distinct-1": 0.2573939648449217,
        "vocab_size-1": 8581,
        "unique-1": 6203,
        "entropy-1": 9.720458329697088,
        "distinct-2": 0.6609570331330141,
        "vocab_size-2": 20567,
        "unique-2": 17909,
        "entropy-2": 13.517113781433086,
        "cond_entropy-2": 3.3999681370599704,
        "distinct-3": 0.853405315614618,
        "vocab_size-3": 24660,
        "unique-3": 23050,
        "entropy-3": 14.336873875816087,
        "cond_entropy-3": 0.8252209351528098,
        "total_length-nopunct": 29074,
        "mean_pred_length-nopunct": 13.090499774876182,
        "std_pred_length-nopunct": 3.7390578492238338,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.29459310724358534,
        "vocab_size-1-nopunct": 8565,
        "unique-1-nopunct": 6202,
        "entropy-1-nopunct": 10.243007698926696,
        "distinct-2-nopunct": 0.6999217964473243,
        "vocab_size-2-nopunct": 18795,
        "unique-2-nopunct": 16705,
        "entropy-2-nopunct": 13.446468386654654,
        "cond_entropy-2-nopunct": 3.3947903705971565,
        "distinct-3-nopunct": 0.8803994803507632,
        "vocab_size-3-nopunct": 21686,
        "unique-3-nopunct": 20432,
        "entropy-3-nopunct": 14.223214312929354,
        "cond_entropy-3-nopunct": 0.8452829825378745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 10.503603692611714,
        "rouge1": {
            "precision": 0.78959,
            "recall": 0.76152,
            "fmeasure": 0.76499
        },
        "rouge2": {
            "precision": 0.56796,
            "recall": 0.5477,
            "fmeasure": 0.54977
        },
        "rougeL": {
            "precision": 0.68777,
            "recall": 0.66612,
            "fmeasure": 0.66752
        },
        "rougeLsum": {
            "precision": 0.68777,
            "recall": 0.66612,
            "fmeasure": 0.66752
        },
        "bleu": 50.39406,
        "local_recall": {
            "1": 0.20333520179372197,
            "2": 0.4612430167597765,
            "3": 0.8019071608492263
        },
        "bertscore": {
            "precision": 0.93779,
            "recall": 0.93441,
            "f1": 0.93447
        },
        "nubia": {
            "semantic_relation": 4.34964,
            "contradiction": 5.80437,
            "irrelevancy": 27.56517,
            "logical_agreement": 66.63046,
            "grammar_ref": 4.79644,
            "grammar_hyp": 4.75848,
            "nubia_score": 0.77093
        },
        "meteor": 0.41657861209618247,
        "bleurt": 0.34065
    },
    "totto_test_contrast_challenge_table_size-table_size_15834": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 10,
        "mean_pred_length": 10.0,
        "std_pred_length": 0.0,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 10,
        "distinct-1": 1.0,
        "vocab_size-1": 10,
        "unique-1": 10,
        "entropy-1": 3.321928094887362,
        "distinct-2": 1.0,
        "vocab_size-2": 9,
        "unique-2": 9,
        "entropy-2": 3.169925001442312,
        "cond_entropy-2": -0.15200309344504973,
        "distinct-3": 1.0,
        "vocab_size-3": 8,
        "unique-3": 8,
        "entropy-3": 3.0,
        "cond_entropy-3": -0.16992500144231237,
        "total_length-nopunct": 7,
        "mean_pred_length-nopunct": 7.0,
        "std_pred_length-nopunct": 0.0,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 7,
        "distinct-1-nopunct": 1.0,
        "vocab_size-1-nopunct": 7,
        "unique-1-nopunct": 7,
        "entropy-1-nopunct": 2.807354922057604,
        "distinct-2-nopunct": 1.0,
        "vocab_size-2-nopunct": 6,
        "unique-2-nopunct": 6,
        "entropy-2-nopunct": 2.584962500721156,
        "cond_entropy-2-nopunct": -0.22239242133644804,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 5,
        "unique-3-nopunct": 5,
        "entropy-3-nopunct": 2.321928094887362,
        "cond_entropy-3-nopunct": -0.26303440583379406,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.31524196457992,
        "rouge1": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "rouge2": {
            "precision": 0.6,
            "recall": 0.41071,
            "fmeasure": 0.48718
        },
        "rougeL": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "rougeLsum": {
            "precision": 1.0,
            "recall": 0.72222,
            "fmeasure": 0.8381
        },
        "bleu": 55.31346,
        "local_recall": {
            "1": 0.0,
            "2": 0,
            "3": 0.7777777777777778
        },
        "bertscore": {
            "precision": 0.98405,
            "recall": 0.95755,
            "f1": 0.97062
        },
        "nubia": {
            "semantic_relation": 4.60143,
            "contradiction": 1.74221,
            "irrelevancy": 1.04658,
            "logical_agreement": 97.21121,
            "grammar_ref": 5.6187,
            "grammar_hyp": 6.09601,
            "nubia_score": 0.77855
        },
        "meteor": 0.45766768780018025,
        "bleurt": 0.52933
    },
    "web_nlg_en_test_contrast_challenge_args-arg1_unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 56,
        "msttr-100": 0.612,
        "msttr-100_nopunct": 0.63,
        "total_length": 598,
        "mean_pred_length": 10.678571428571429,
        "std_pred_length": 4.400110156320532,
        "median_pred_length": 9.0,
        "min_pred_length": 5,
        "max_pred_length": 25,
        "distinct-1": 0.31270903010033446,
        "vocab_size-1": 187,
        "unique-1": 112,
        "entropy-1": 6.352634031424011,
        "distinct-2": 0.6070110701107011,
        "vocab_size-2": 329,
        "unique-2": 237,
        "entropy-2": 8.010912602122843,
        "cond_entropy-2": 1.3549293315107869,
        "distinct-3": 0.7551440329218106,
        "vocab_size-3": 367,
        "unique-3": 298,
        "entropy-3": 8.330392339027416,
        "cond_entropy-3": 0.3565477865875191,
        "total_length-nopunct": 525,
        "mean_pred_length-nopunct": 9.375,
        "std_pred_length-nopunct": 4.108190860081496,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.3466666666666667,
        "vocab_size-1-nopunct": 182,
        "unique-1-nopunct": 110,
        "entropy-1-nopunct": 6.475999255919513,
        "distinct-2-nopunct": 0.5970149253731343,
        "vocab_size-2-nopunct": 280,
        "unique-2-nopunct": 203,
        "entropy-2-nopunct": 7.756991166665637,
        "cond_entropy-2-nopunct": 1.4241630950034483,
        "distinct-3-nopunct": 0.7627118644067796,
        "vocab_size-3-nopunct": 315,
        "unique-3-nopunct": 261,
        "entropy-3-nopunct": 8.104359593752536,
        "cond_entropy-3-nopunct": 0.37000245606579185,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.8655783394549905,
        "rouge1": {
            "precision": 0.83043,
            "recall": 0.7693,
            "fmeasure": 0.78965
        },
        "rouge2": {
            "precision": 0.59636,
            "recall": 0.56087,
            "fmeasure": 0.5711
        },
        "rougeL": {
            "precision": 0.73688,
            "recall": 0.68697,
            "fmeasure": 0.70287
        },
        "rougeLsum": {
            "precision": 0.73688,
            "recall": 0.68697,
            "fmeasure": 0.70287
        },
        "bleu": 54.42317,
        "local_recall": {
            "1": 0.22832369942196531,
            "2": 0.625,
            "3": 0.8405797101449275
        },
        "bertscore": {
            "precision": 0.95154,
            "recall": 0.94583,
            "f1": 0.94749
        },
        "nubia": {
            "semantic_relation": 4.6027,
            "contradiction": 3.72533,
            "irrelevancy": 4.77152,
            "logical_agreement": 91.50315,
            "grammar_ref": 5.25554,
            "grammar_hyp": 5.39189,
            "nubia_score": 0.83033
        },
        "meteor": 0.43607427474067495,
        "bleurt": 0.39604
    },
    "web_nlg_en_test_contrast_challenge_args-arg2_unseen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 28,
        "msttr-100": 0.505,
        "msttr-100_nopunct": 0.55,
        "total_length": 279,
        "mean_pred_length": 9.964285714285714,
        "std_pred_length": 3.7175466454672077,
        "median_pred_length": 9.5,
        "min_pred_length": 5,
        "max_pred_length": 27,
        "distinct-1": 0.3835125448028674,
        "vocab_size-1": 107,
        "unique-1": 72,
        "entropy-1": 5.6997549907785,
        "distinct-2": 0.7211155378486056,
        "vocab_size-2": 181,
        "unique-2": 145,
        "entropy-2": 7.25221408846789,
        "cond_entropy-2": 1.3003346758606091,
        "distinct-3": 0.8654708520179372,
        "vocab_size-3": 193,
        "unique-3": 170,
        "entropy-3": 7.499915974006573,
        "cond_entropy-3": 0.2953765493467142,
        "total_length-nopunct": 244,
        "mean_pred_length-nopunct": 8.714285714285714,
        "std_pred_length-nopunct": 3.068935865562976,
        "median_pred_length-nopunct": 8.5,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.42213114754098363,
        "vocab_size-1-nopunct": 103,
        "unique-1-nopunct": 70,
        "entropy-1-nopunct": 5.768783424798765,
        "distinct-2-nopunct": 0.6990740740740741,
        "vocab_size-2-nopunct": 151,
        "unique-2-nopunct": 118,
        "entropy-2-nopunct": 6.972286016830709,
        "cond_entropy-2-nopunct": 1.3757010158954117,
        "distinct-3-nopunct": 0.8563829787234043,
        "vocab_size-3-nopunct": 161,
        "unique-3-nopunct": 141,
        "entropy-3-nopunct": 7.229485577854439,
        "cond_entropy-3-nopunct": 0.31010944030379184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.7403635115571126,
        "rouge1": {
            "precision": 0.86668,
            "recall": 0.78838,
            "fmeasure": 0.81851
        },
        "rouge2": {
            "precision": 0.65568,
            "recall": 0.58967,
            "fmeasure": 0.61333
        },
        "rougeL": {
            "precision": 0.7502,
            "recall": 0.67343,
            "fmeasure": 0.70283
        },
        "rougeLsum": {
            "precision": 0.7502,
            "recall": 0.67343,
            "fmeasure": 0.70283
        },
        "bleu": 60.82213,
        "local_recall": {
            "1": 0.1564625850340136,
            "2": 0.6914893617021277,
            "3": 0.8444444444444444,
            "4": 1.0
        },
        "bertscore": {
            "precision": 0.94921,
            "recall": 0.93445,
            "f1": 0.94044
        },
        "nubia": {
            "semantic_relation": 4.29332,
            "contradiction": 17.09878,
            "irrelevancy": 3.84028,
            "logical_agreement": 79.06094,
            "grammar_ref": 4.67502,
            "grammar_hyp": 5.01165,
            "nubia_score": 0.74777
        },
        "meteor": 0.4230500891432889,
        "bleurt": 0.33843
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-no_subject/object_overlap": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 1322,
        "msttr-100": 0.52388,
        "msttr-100_nopunct": 0.52917,
        "total_length": 23794,
        "mean_pred_length": 17.998487140695914,
        "std_pred_length": 6.785005993700724,
        "median_pred_length": 19.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.06758006220055476,
        "vocab_size-1": 1608,
        "unique-1": 561,
        "entropy-1": 8.037418198727279,
        "distinct-2": 0.2326005695977216,
        "vocab_size-2": 5227,
        "unique-2": 2634,
        "entropy-2": 11.054447702673622,
        "cond_entropy-2": 2.923209574015303,
        "distinct-3": 0.399290780141844,
        "vocab_size-3": 8445,
        "unique-3": 5261,
        "entropy-3": 12.176568244517375,
        "cond_entropy-3": 1.2249829373084573,
        "total_length-nopunct": 21711,
        "mean_pred_length-nopunct": 16.42284417549168,
        "std_pred_length-nopunct": 6.530542122437851,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07364930219704298,
        "vocab_size-1-nopunct": 1599,
        "unique-1-nopunct": 560,
        "entropy-1-nopunct": 8.209847529180553,
        "distinct-2-nopunct": 0.23679434989455098,
        "vocab_size-2-nopunct": 4828,
        "unique-2-nopunct": 2500,
        "entropy-2-nopunct": 10.929770339034828,
        "cond_entropy-2-nopunct": 2.9062855625362003,
        "distinct-3-nopunct": 0.4047306865264593,
        "vocab_size-3-nopunct": 7717,
        "unique-3-nopunct": 4898,
        "entropy-3-nopunct": 12.03370757064072,
        "cond_entropy-3-nopunct": 1.2020315187524284,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.747284683881421,
        "rouge1": {
            "precision": 0.78687,
            "recall": 0.71572,
            "fmeasure": 0.73931
        },
        "rouge2": {
            "precision": 0.53563,
            "recall": 0.48577,
            "fmeasure": 0.50182
        },
        "rougeL": {
            "precision": 0.65301,
            "recall": 0.59529,
            "fmeasure": 0.61406
        },
        "rougeLsum": {
            "precision": 0.65301,
            "recall": 0.59529,
            "fmeasure": 0.61406
        },
        "bleu": 43.27238,
        "local_recall": {
            "1": 0.19994920849911116,
            "2": 0.5238229093464511,
            "3": 0.7803177934342678,
            "4": 0.9215686274509803,
            "5": 0.7619047619047619
        },
        "bertscore": {
            "precision": 0.92583,
            "recall": 0.91063,
            "f1": 0.91669
        },
        "nubia": {
            "semantic_relation": 4.25494,
            "contradiction": 6.18115,
            "irrelevancy": 9.80337,
            "logical_agreement": 84.01548,
            "grammar_ref": 4.6229,
            "grammar_hyp": 4.82522,
            "nubia_score": 0.7181
        },
        "meteor": 0.351222329054899,
        "bleurt": 0.14443
    },
    "web_nlg_en_test_contrast_challenge_max_entity_subj_obj-some_entities_as_both_subj_and_obj": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 457,
        "msttr-100": 0.49444,
        "msttr-100_nopunct": 0.49356,
        "total_length": 9930,
        "mean_pred_length": 21.728665207877462,
        "std_pred_length": 4.024638148045903,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.12336354481369587,
        "vocab_size-1": 1225,
        "unique-1": 543,
        "entropy-1": 7.915023713935391,
        "distinct-2": 0.34265808086139554,
        "vocab_size-2": 3246,
        "unique-2": 1959,
        "entropy-2": 10.612727055972591,
        "cond_entropy-2": 2.7123511863523553,
        "distinct-3": 0.5177462289263531,
        "vocab_size-3": 4668,
        "unique-3": 3301,
        "entropy-3": 11.541242695119637,
        "cond_entropy-3": 1.0041376855335136,
        "total_length-nopunct": 9030,
        "mean_pred_length-nopunct": 19.759299781181618,
        "std_pred_length-nopunct": 3.9292214405591377,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.13477297895902546,
        "vocab_size-1-nopunct": 1217,
        "unique-1-nopunct": 541,
        "entropy-1-nopunct": 8.06847349468626,
        "distinct-2-nopunct": 0.3500524903767643,
        "vocab_size-2-nopunct": 3001,
        "unique-2-nopunct": 1826,
        "entropy-2-nopunct": 10.512316242951975,
        "cond_entropy-2-nopunct": 2.5859927570763435,
        "distinct-3-nopunct": 0.5195909314933465,
        "vocab_size-3-nopunct": 4217,
        "unique-3-nopunct": 2993,
        "entropy-3-nopunct": 11.390792258839944,
        "cond_entropy-3-nopunct": 0.9529628271103905,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 4.440255973149615,
        "rouge1": {
            "precision": 0.7705,
            "recall": 0.60078,
            "fmeasure": 0.65718
        },
        "rouge2": {
            "precision": 0.50464,
            "recall": 0.38328,
            "fmeasure": 0.42228
        },
        "rougeL": {
            "precision": 0.6182,
            "recall": 0.47714,
            "fmeasure": 0.52337
        },
        "rougeLsum": {
            "precision": 0.6182,
            "recall": 0.47714,
            "fmeasure": 0.52337
        },
        "bleu": 33.30344,
        "local_recall": {
            "1": 0.17646011396011396,
            "2": 0.44940289126335636,
            "3": 0.6872361156219552,
            "4": 0.5,
            "5": 0.625
        },
        "bertscore": {
            "precision": 0.91551,
            "recall": 0.87865,
            "f1": 0.89506
        },
        "nubia": {
            "semantic_relation": 3.8782,
            "contradiction": 8.31289,
            "irrelevancy": 10.36151,
            "logical_agreement": 81.3256,
            "grammar_ref": 4.37649,
            "grammar_hyp": 4.67493,
            "nubia_score": 0.58737
        },
        "meteor": 0.289761010256157,
        "bleurt": -0.13103
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 5,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 54,
        "mean_pred_length": 10.8,
        "std_pred_length": 0.9797958971132713,
        "median_pred_length": 10.0,
        "min_pred_length": 10,
        "max_pred_length": 12,
        "distinct-1": 0.6296296296296297,
        "vocab_size-1": 34,
        "unique-1": 21,
        "entropy-1": 4.866476975292414,
        "distinct-2": 0.7142857142857143,
        "vocab_size-2": 35,
        "unique-2": 24,
        "entropy-2": 4.969615140555275,
        "cond_entropy-2": 0.11215964759664347,
        "distinct-3": 0.7727272727272727,
        "vocab_size-3": 34,
        "unique-3": 24,
        "entropy-3": 5.004886164091843,
        "cond_entropy-3": 0.06312269439565281,
        "total_length-nopunct": 52,
        "mean_pred_length-nopunct": 10.4,
        "std_pred_length-nopunct": 1.0198039027185568,
        "median_pred_length-nopunct": 10.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 12,
        "distinct-1-nopunct": 0.6346153846153846,
        "vocab_size-1-nopunct": 33,
        "unique-1-nopunct": 21,
        "entropy-1-nopunct": 4.816321094082685,
        "distinct-2-nopunct": 0.7021276595744681,
        "vocab_size-2-nopunct": 33,
        "unique-2-nopunct": 22,
        "entropy-2-nopunct": 4.88204330966834,
        "cond_entropy-2-nopunct": 0.11722419686846625,
        "distinct-3-nopunct": 0.7619047619047619,
        "vocab_size-3-nopunct": 32,
        "unique-3-nopunct": 22,
        "entropy-3-nopunct": 4.916126946588286,
        "cond_entropy-3-nopunct": 0.06652953477818983,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 1.6570572200710099,
        "rouge1": {
            "precision": 0.43333,
            "recall": 0.46124,
            "fmeasure": 0.40177
        },
        "rouge2": {
            "precision": 0.23232,
            "recall": 0.25985,
            "fmeasure": 0.20942
        },
        "rougeL": {
            "precision": 0.39667,
            "recall": 0.42919,
            "fmeasure": 0.36771
        },
        "rougeLsum": {
            "precision": 0.39667,
            "recall": 0.42919,
            "fmeasure": 0.36771
        },
        "bleu": 6.10958,
        "local_recall": {
            "1": 0.4107142857142857
        },
        "bertscore": {
            "precision": 0.83366,
            "recall": 0.82116,
            "f1": 0.82634
        },
        "nubia": {
            "semantic_relation": 3.07113,
            "contradiction": 35.97175,
            "irrelevancy": 63.45542,
            "logical_agreement": 0.57283,
            "grammar_ref": 5.06674,
            "grammar_hyp": 5.61912,
            "nubia_score": 0.34459
        },
        "meteor": 0.1865246136262281,
        "bleurt": -0.6182
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-5": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73333,
        "msttr-100_nopunct": 0.7535,
        "total_length": 2139,
        "mean_pred_length": 20.17924528301887,
        "std_pred_length": 3.597161275467508,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 26,
        "distinct-1": 0.4329125759700795,
        "vocab_size-1": 926,
        "unique-1": 710,
        "entropy-1": 8.316303561389372,
        "distinct-2": 0.8460403344810624,
        "vocab_size-2": 1720,
        "unique-2": 1584,
        "entropy-2": 10.521009459943341,
        "cond_entropy-2": 2.060689290738866,
        "distinct-3": 0.9636741048261547,
        "vocab_size-3": 1857,
        "unique-3": 1802,
        "entropy-3": 10.832595338644083,
        "cond_entropy-3": 0.3270990736810587,
        "total_length-nopunct": 2019,
        "mean_pred_length-nopunct": 19.047169811320753,
        "std_pred_length-nopunct": 3.5565036770860194,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.4551758296186231,
        "vocab_size-1-nopunct": 919,
        "unique-1-nopunct": 709,
        "entropy-1-nopunct": 8.395903486200528,
        "distinct-2-nopunct": 0.8457919498170413,
        "vocab_size-2-nopunct": 1618,
        "unique-2-nopunct": 1491,
        "entropy-2-nopunct": 10.429341023156573,
        "cond_entropy-2-nopunct": 2.127219066039381,
        "distinct-3-nopunct": 0.9651355838406198,
        "vocab_size-3-nopunct": 1744,
        "unique-3-nopunct": 1694,
        "entropy-3-nopunct": 10.743407236622803,
        "cond_entropy-3-nopunct": 0.3305143840953716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.5500154121031495,
        "rouge1": {
            "precision": 0.4699,
            "recall": 0.41247,
            "fmeasure": 0.43149
        },
        "rouge2": {
            "precision": 0.19181,
            "recall": 0.16763,
            "fmeasure": 0.17578
        },
        "rougeL": {
            "precision": 0.36783,
            "recall": 0.32051,
            "fmeasure": 0.33622
        },
        "rougeLsum": {
            "precision": 0.36783,
            "recall": 0.32051,
            "fmeasure": 0.33622
        },
        "bleu": 11.05453,
        "local_recall": {
            "1": 0.38130155820348305
        },
        "bertscore": {
            "precision": 0.84687,
            "recall": 0.83125,
            "f1": 0.83865
        },
        "nubia": {
            "semantic_relation": 3.06053,
            "contradiction": 17.37858,
            "irrelevancy": 64.08091,
            "logical_agreement": 18.54051,
            "grammar_ref": 3.63886,
            "grammar_hyp": 3.60242,
            "nubia_score": 0.46216
        },
        "meteor": 0.18419971208241903,
        "bleurt": -0.28764
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 120,
        "msttr-100": 0.33167,
        "msttr-100_nopunct": 0.34,
        "total_length": 1899,
        "mean_pred_length": 15.825,
        "std_pred_length": 5.105001632386288,
        "median_pred_length": 16.0,
        "min_pred_length": 9,
        "max_pred_length": 25,
        "distinct-1": 0.09268035808320169,
        "vocab_size-1": 176,
        "unique-1": 27,
        "entropy-1": 6.08105953244052,
        "distinct-2": 0.20067453625632378,
        "vocab_size-2": 357,
        "unique-2": 85,
        "entropy-2": 7.5649540721673185,
        "cond_entropy-2": 1.3866058011772426,
        "distinct-3": 0.26702833031946954,
        "vocab_size-3": 443,
        "unique-3": 121,
        "entropy-3": 8.19144679879763,
        "cond_entropy-3": 0.6851823252752499,
        "total_length-nopunct": 1743,
        "mean_pred_length-nopunct": 14.525,
        "std_pred_length-nopunct": 4.722221405228687,
        "median_pred_length-nopunct": 14.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.09982788296041308,
        "vocab_size-1-nopunct": 174,
        "unique-1-nopunct": 27,
        "entropy-1-nopunct": 6.120768422327651,
        "distinct-2-nopunct": 0.19839802834257547,
        "vocab_size-2-nopunct": 322,
        "unique-2-nopunct": 82,
        "entropy-2-nopunct": 7.383250659981791,
        "cond_entropy-2-nopunct": 1.3888753839795496,
        "distinct-3-nopunct": 0.2661343978709248,
        "vocab_size-3-nopunct": 400,
        "unique-3-nopunct": 112,
        "entropy-3-nopunct": 8.042748901323227,
        "cond_entropy-3-nopunct": 0.711826085956716,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 3.4628873735841275,
        "rouge1": {
            "precision": 0.56238,
            "recall": 0.62197,
            "fmeasure": 0.56646
        },
        "rouge2": {
            "precision": 0.32147,
            "recall": 0.35714,
            "fmeasure": 0.32137
        },
        "rougeL": {
            "precision": 0.4572,
            "recall": 0.50573,
            "fmeasure": 0.45931
        },
        "rougeLsum": {
            "precision": 0.4572,
            "recall": 0.50573,
            "fmeasure": 0.45931
        },
        "bleu": 19.37863,
        "local_recall": {
            "1": 0.5822784810126582
        },
        "bertscore": {
            "precision": 0.87106,
            "recall": 0.88001,
            "f1": 0.87456
        },
        "nubia": {
            "semantic_relation": 3.63372,
            "contradiction": 4.88904,
            "irrelevancy": 71.63403,
            "logical_agreement": 23.47693,
            "grammar_ref": 5.42765,
            "grammar_hyp": 5.02238,
            "nubia_score": 0.58483
        },
        "meteor": 0.28790172282412163,
        "bleurt": -0.29424
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-unique_subjects": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 453,
        "msttr-100": 0.54592,
        "msttr-100_nopunct": 0.56558,
        "total_length": 4969,
        "mean_pred_length": 10.969094922737307,
        "std_pred_length": 4.040514285703792,
        "median_pred_length": 10.0,
        "min_pred_length": 5,
        "max_pred_length": 26,
        "distinct-1": 0.18212920104648822,
        "vocab_size-1": 905,
        "unique-1": 462,
        "entropy-1": 7.595767862257372,
        "distinct-2": 0.4685562444641275,
        "vocab_size-2": 2116,
        "unique-2": 1412,
        "entropy-2": 10.322528021656684,
        "cond_entropy-2": 2.3231318579614744,
        "distinct-3": 0.6628107309869554,
        "vocab_size-3": 2693,
        "unique-3": 2113,
        "entropy-3": 11.017744844960392,
        "cond_entropy-3": 0.7924645703331494,
        "total_length-nopunct": 4366,
        "mean_pred_length-nopunct": 9.637969094922738,
        "std_pred_length-nopunct": 3.7027008016335783,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.2054512139257902,
        "vocab_size-1-nopunct": 897,
        "unique-1-nopunct": 460,
        "entropy-1-nopunct": 7.873749981710623,
        "distinct-2-nopunct": 0.44824942499361103,
        "vocab_size-2-nopunct": 1754,
        "unique-2-nopunct": 1144,
        "entropy-2-nopunct": 10.013955312461984,
        "cond_entropy-2-nopunct": 2.417095153026261,
        "distinct-3-nopunct": 0.6494219653179191,
        "vocab_size-3-nopunct": 2247,
        "unique-3-nopunct": 1740,
        "entropy-3-nopunct": 10.73896113205105,
        "cond_entropy-3-nopunct": 0.8358979163557091,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 9.404685099551665,
        "rouge1": {
            "precision": 0.82903,
            "recall": 0.79198,
            "fmeasure": 0.80297
        },
        "rouge2": {
            "precision": 0.61367,
            "recall": 0.58286,
            "fmeasure": 0.59199
        },
        "rougeL": {
            "precision": 0.74208,
            "recall": 0.70755,
            "fmeasure": 0.7177
        },
        "rougeLsum": {
            "precision": 0.74208,
            "recall": 0.70755,
            "fmeasure": 0.7177
        },
        "bleu": 60.91878,
        "local_recall": {
            "1": 0.22615384615384615,
            "2": 0.6429471032745592,
            "3": 0.8868266183793572,
            "4": 0.9736842105263158
        },
        "bertscore": {
            "precision": 0.9487,
            "recall": 0.94501,
            "f1": 0.94598
        },
        "nubia": {
            "semantic_relation": 4.59149,
            "contradiction": 6.3998,
            "irrelevancy": 7.27371,
            "logical_agreement": 86.32649,
            "grammar_ref": 5.12238,
            "grammar_hyp": 5.22319,
            "nubia_score": 0.83279
        },
        "meteor": 0.45560026432322714,
        "bleurt": 0.37369
    },
    "totto_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 1369,
        "msttr-100": 0.7261,
        "msttr-100_nopunct": 0.77801,
        "total_length": 24638,
        "mean_pred_length": 17.99707815924032,
        "std_pred_length": 4.508573790893366,
        "median_pred_length": 18.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.2585437129637146,
        "vocab_size-1": 6370,
        "unique-1": 4550,
        "entropy-1": 9.549333266739358,
        "distinct-2": 0.66414542954145,
        "vocab_size-2": 15454,
        "unique-2": 13391,
        "entropy-2": 13.167909465194708,
        "cond_entropy-2": 3.3495936871208913,
        "distinct-3": 0.8565296803652968,
        "vocab_size-3": 18758,
        "unique-3": 17488,
        "entropy-3": 13.962047968455693,
        "cond_entropy-3": 0.8028068361321483,
        "total_length-nopunct": 21675,
        "mean_pred_length-nopunct": 15.8327246165084,
        "std_pred_length-nopunct": 4.0318938428431474,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.2932410611303345,
        "vocab_size-1-nopunct": 6356,
        "unique-1-nopunct": 4549,
        "entropy-1-nopunct": 9.982179010093743,
        "distinct-2-nopunct": 0.7004826159755737,
        "vocab_size-2-nopunct": 14224,
        "unique-2-nopunct": 12595,
        "entropy-2-nopunct": 13.087142606577899,
        "cond_entropy-2-nopunct": 3.2532547043722575,
        "distinct-3-nopunct": 0.8779109679463484,
        "vocab_size-3-nopunct": 16625,
        "unique-3-nopunct": 15647,
        "entropy-3-nopunct": 13.8294091269497,
        "cond_entropy-3-nopunct": 0.7936849452474628,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 10.032603977466374,
        "rouge1": {
            "precision": 0.77357,
            "recall": 0.7419,
            "fmeasure": 0.74847
        },
        "rouge2": {
            "precision": 0.54379,
            "recall": 0.52305,
            "fmeasure": 0.52665
        },
        "rougeL": {
            "precision": 0.66021,
            "recall": 0.63805,
            "fmeasure": 0.64098
        },
        "rougeLsum": {
            "precision": 0.66021,
            "recall": 0.63805,
            "fmeasure": 0.64098
        },
        "bleu": 48.92186,
        "local_recall": {
            "1": 0.22695187165775402,
            "2": 0.4417297825555827,
            "3": 0.7819235645716356
        },
        "bertscore": {
            "precision": 0.93315,
            "recall": 0.92789,
            "f1": 0.92903
        },
        "nubia": {
            "semantic_relation": 4.22543,
            "contradiction": 8.61944,
            "irrelevancy": 29.89303,
            "logical_agreement": 61.48753,
            "grammar_ref": 4.49662,
            "grammar_hyp": 4.43214,
            "nubia_score": 0.7468
        },
        "meteor": 0.40393910911286846,
        "bleurt": 0.27368
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-6": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73048,
        "msttr-100_nopunct": 0.74,
        "total_length": 2173,
        "mean_pred_length": 20.5,
        "std_pred_length": 3.0660957904518273,
        "median_pred_length": 21.0,
        "min_pred_length": 13,
        "max_pred_length": 27,
        "distinct-1": 0.40957202024850436,
        "vocab_size-1": 890,
        "unique-1": 698,
        "entropy-1": 8.173073750699649,
        "distinct-2": 0.8132559264634737,
        "vocab_size-2": 1681,
        "unique-2": 1543,
        "entropy-2": 10.416012020235438,
        "cond_entropy-2": 2.114593105965562,
        "distinct-3": 0.942886282508924,
        "vocab_size-3": 1849,
        "unique-3": 1788,
        "entropy-3": 10.788249440338108,
        "cond_entropy-3": 0.38799380135638195,
        "total_length-nopunct": 2055,
        "mean_pred_length-nopunct": 19.38679245283019,
        "std_pred_length-nopunct": 3.178853343513299,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.43017031630170316,
        "vocab_size-1-nopunct": 884,
        "unique-1-nopunct": 697,
        "entropy-1-nopunct": 8.243287947302896,
        "distinct-2-nopunct": 0.8132375577219086,
        "vocab_size-2-nopunct": 1585,
        "unique-2-nopunct": 1459,
        "entropy-2-nopunct": 10.32476005140838,
        "cond_entropy-2-nopunct": 2.180861087889137,
        "distinct-3-nopunct": 0.9451980466630494,
        "vocab_size-3-nopunct": 1742,
        "unique-3-nopunct": 1685,
        "entropy-3-nopunct": 10.706076031466612,
        "cond_entropy-3-nopunct": 0.40326260813340103,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.365883176511148,
        "rouge1": {
            "precision": 0.4433,
            "recall": 0.39699,
            "fmeasure": 0.41098
        },
        "rouge2": {
            "precision": 0.16606,
            "recall": 0.14341,
            "fmeasure": 0.15064
        },
        "rougeL": {
            "precision": 0.34124,
            "recall": 0.30641,
            "fmeasure": 0.31663
        },
        "rougeLsum": {
            "precision": 0.34124,
            "recall": 0.30641,
            "fmeasure": 0.31663
        },
        "bleu": 8.89402,
        "local_recall": {
            "1": 0.366079703429101
        },
        "bertscore": {
            "precision": 0.83834,
            "recall": 0.82685,
            "f1": 0.83216
        },
        "nubia": {
            "semantic_relation": 3.01383,
            "contradiction": 22.0593,
            "irrelevancy": 60.94215,
            "logical_agreement": 16.99855,
            "grammar_ref": 3.80483,
            "grammar_hyp": 3.60472,
            "nubia_score": 0.44967
        },
        "meteor": 0.1714587179348902,
        "bleurt": -0.31245
    },
    "totto_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 483,
        "msttr-100": 0.73684,
        "msttr-100_nopunct": 0.77563,
        "total_length": 9809,
        "mean_pred_length": 20.308488612836438,
        "std_pred_length": 4.0862936064698205,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.32266286063818944,
        "vocab_size-1": 3165,
        "unique-1": 2346,
        "entropy-1": 9.214090480556576,
        "distinct-2": 0.7345056830366716,
        "vocab_size-2": 6850,
        "unique-2": 5973,
        "entropy-2": 12.271831933945517,
        "cond_entropy-2": 2.884431505320158,
        "distinct-3": 0.9060273662784123,
        "vocab_size-3": 8012,
        "unique-3": 7536,
        "entropy-3": 12.866807488895624,
        "cond_entropy-3": 0.6022165861697015,
        "total_length-nopunct": 8720,
        "mean_pred_length-nopunct": 18.053830227743273,
        "std_pred_length-nopunct": 3.8157894732952333,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.3614678899082569,
        "vocab_size-1-nopunct": 3152,
        "unique-1-nopunct": 2343,
        "entropy-1-nopunct": 9.549068880233612,
        "distinct-2-nopunct": 0.7593784144712881,
        "vocab_size-2-nopunct": 6255,
        "unique-2-nopunct": 5562,
        "entropy-2-nopunct": 12.151412480897026,
        "cond_entropy-2-nopunct": 2.708546765998325,
        "distinct-3-nopunct": 0.918622646376064,
        "vocab_size-3-nopunct": 7123,
        "unique-3-nopunct": 6760,
        "entropy-3-nopunct": 12.707888992442074,
        "cond_entropy-3-nopunct": 0.5856429263421113,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.85505161219523,
        "rouge1": {
            "precision": 0.75583,
            "recall": 0.71841,
            "fmeasure": 0.7276
        },
        "rouge2": {
            "precision": 0.50817,
            "recall": 0.48416,
            "fmeasure": 0.48958
        },
        "rougeL": {
            "precision": 0.62125,
            "recall": 0.59356,
            "fmeasure": 0.59924
        },
        "rougeLsum": {
            "precision": 0.62125,
            "recall": 0.59356,
            "fmeasure": 0.59924
        },
        "bleu": 42.3762,
        "local_recall": {
            "1": 0.22047702152414195,
            "2": 0.4103225806451613,
            "3": 0.7507297139521307
        },
        "bertscore": {
            "precision": 0.92374,
            "recall": 0.91722,
            "f1": 0.91864
        },
        "nubia": {
            "semantic_relation": 4.10743,
            "contradiction": 9.12148,
            "irrelevancy": 34.66919,
            "logical_agreement": 56.20933,
            "grammar_ref": 4.32701,
            "grammar_hyp": 4.29474,
            "nubia_score": 0.71241
        },
        "meteor": 0.3821626531774154,
        "bleurt": 0.16617
    },
    "totto_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 379,
        "msttr-100": 0.71487,
        "msttr-100_nopunct": 0.75451,
        "total_length": 8092,
        "mean_pred_length": 21.350923482849606,
        "std_pred_length": 4.107502363277448,
        "median_pred_length": 22.0,
        "min_pred_length": 9,
        "max_pred_length": 31,
        "distinct-1": 0.34762728620860106,
        "vocab_size-1": 2813,
        "unique-1": 2102,
        "entropy-1": 9.174527623776168,
        "distinct-2": 0.7771295215869312,
        "vocab_size-2": 5994,
        "unique-2": 5303,
        "entropy-2": 12.164988789572838,
        "cond_entropy-2": 2.8522263994448696,
        "distinct-3": 0.9344150531769839,
        "vocab_size-3": 6853,
        "unique-3": 6531,
        "entropy-3": 12.683952983269307,
        "cond_entropy-3": 0.5135297113337147,
        "total_length-nopunct": 7134,
        "mean_pred_length-nopunct": 18.823218997361476,
        "std_pred_length-nopunct": 3.825051320752928,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.39234650967199325,
        "vocab_size-1-nopunct": 2799,
        "unique-1-nopunct": 2102,
        "entropy-1-nopunct": 9.501351613274618,
        "distinct-2-nopunct": 0.8060695780903034,
        "vocab_size-2-nopunct": 5445,
        "unique-2-nopunct": 4910,
        "entropy-2-nopunct": 12.064616782306532,
        "cond_entropy-2-nopunct": 2.655307934529203,
        "distinct-3-nopunct": 0.9443224592220828,
        "vocab_size-3-nopunct": 6021,
        "unique-3-nopunct": 5777,
        "entropy-3-nopunct": 12.506758947580757,
        "cond_entropy-3-nopunct": 0.46445590965558436,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 8.269863662959136,
        "rouge1": {
            "precision": 0.7635,
            "recall": 0.69568,
            "fmeasure": 0.71966
        },
        "rouge2": {
            "precision": 0.50283,
            "recall": 0.45768,
            "fmeasure": 0.47346
        },
        "rougeL": {
            "precision": 0.6101,
            "recall": 0.56127,
            "fmeasure": 0.57733
        },
        "rougeLsum": {
            "precision": 0.6101,
            "recall": 0.56127,
            "fmeasure": 0.57733
        },
        "bleu": 39.29315,
        "local_recall": {
            "1": 0.2105654761904762,
            "2": 0.4109396914446003,
            "3": 0.7373371924746743
        },
        "bertscore": {
            "precision": 0.92211,
            "recall": 0.91017,
            "f1": 0.91464
        },
        "nubia": {
            "semantic_relation": 3.98905,
            "contradiction": 11.54274,
            "irrelevancy": 29.229,
            "logical_agreement": 59.22825,
            "grammar_ref": 4.27824,
            "grammar_hyp": 4.30134,
            "nubia_score": 0.67257
        },
        "meteor": 0.36326027126227756,
        "bleurt": 0.12399
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-2_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 414,
        "msttr-100": 0.52895,
        "msttr-100_nopunct": 0.53441,
        "total_length": 7610,
        "mean_pred_length": 18.381642512077295,
        "std_pred_length": 4.960155366871761,
        "median_pred_length": 18.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.15203679369250986,
        "vocab_size-1": 1157,
        "unique-1": 484,
        "entropy-1": 8.01493618345019,
        "distinct-2": 0.41953863257365204,
        "vocab_size-2": 3019,
        "unique-2": 1858,
        "entropy-2": 10.76767797813771,
        "cond_entropy-2": 2.608336376874044,
        "distinct-3": 0.6104393984075493,
        "vocab_size-3": 4140,
        "unique-3": 3037,
        "entropy-3": 11.585985210187728,
        "cond_entropy-3": 0.8919292678724342,
        "total_length-nopunct": 6884,
        "mean_pred_length-nopunct": 16.6280193236715,
        "std_pred_length-nopunct": 4.677708204659176,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.1669087739686229,
        "vocab_size-1-nopunct": 1149,
        "unique-1-nopunct": 483,
        "entropy-1-nopunct": 8.195914783245737,
        "distinct-2-nopunct": 0.4132921174652241,
        "vocab_size-2-nopunct": 2674,
        "unique-2-nopunct": 1648,
        "entropy-2-nopunct": 10.580044676413086,
        "cond_entropy-2-nopunct": 2.555177455298887,
        "distinct-3-nopunct": 0.6030383091149274,
        "vocab_size-3-nopunct": 3652,
        "unique-3-nopunct": 2681,
        "entropy-3-nopunct": 11.388464845562709,
        "cond_entropy-3-nopunct": 0.8758464223069548,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 8.720539406939624,
        "rouge1": {
            "precision": 0.77945,
            "recall": 0.74982,
            "fmeasure": 0.75668
        },
        "rouge2": {
            "precision": 0.53176,
            "recall": 0.5088,
            "fmeasure": 0.51394
        },
        "rougeL": {
            "precision": 0.64657,
            "recall": 0.62042,
            "fmeasure": 0.62632
        },
        "rougeLsum": {
            "precision": 0.64657,
            "recall": 0.62042,
            "fmeasure": 0.62632
        },
        "bleu": 48.2489,
        "local_recall": {
            "1": 0.21909633418584826,
            "2": 0.5590155700652938,
            "3": 0.8614012738853504,
            "4": 0.8181818181818182,
            "5": 0.625
        },
        "bertscore": {
            "precision": 0.92819,
            "recall": 0.92327,
            "f1": 0.92421
        },
        "nubia": {
            "semantic_relation": 4.48232,
            "contradiction": 6.92438,
            "irrelevancy": 8.9842,
            "logical_agreement": 84.09141,
            "grammar_ref": 4.63681,
            "grammar_hyp": 4.77041,
            "nubia_score": 0.78337
        },
        "meteor": 0.39114860355264874,
        "bleurt": 0.20244
    },
    "web_nlg_en_test_contrast_challenge_max_subj_same-3_subjects_same": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 382,
        "msttr-100": 0.50726,
        "msttr-100_nopunct": 0.51052,
        "total_length": 8441,
        "mean_pred_length": 22.096858638743456,
        "std_pred_length": 3.6543799405166544,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.12972396635469732,
        "vocab_size-1": 1095,
        "unique-1": 363,
        "entropy-1": 7.96194187998991,
        "distinct-2": 0.3698970095545353,
        "vocab_size-2": 2981,
        "unique-2": 1689,
        "entropy-2": 10.698413818505042,
        "cond_entropy-2": 2.7124149523620127,
        "distinct-3": 0.5657157743910382,
        "vocab_size-3": 4343,
        "unique-3": 3040,
        "entropy-3": 11.6178884213573,
        "cond_entropy-3": 0.9870060315113119,
        "total_length-nopunct": 7716,
        "mean_pred_length-nopunct": 20.198952879581153,
        "std_pred_length-nopunct": 3.597148223708526,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.14087610160705027,
        "vocab_size-1-nopunct": 1087,
        "unique-1-nopunct": 362,
        "entropy-1-nopunct": 8.114862146287901,
        "distinct-2-nopunct": 0.3786473956913008,
        "vocab_size-2-nopunct": 2777,
        "unique-2-nopunct": 1611,
        "entropy-2-nopunct": 10.615373174944313,
        "cond_entropy-2-nopunct": 2.6351266026308915,
        "distinct-3-nopunct": 0.571921749136939,
        "vocab_size-3-nopunct": 3976,
        "unique-3-nopunct": 2827,
        "entropy-3-nopunct": 11.487541027621045,
        "cond_entropy-3-nopunct": 0.9327858046895857,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 7.673032084647472,
        "rouge1": {
            "precision": 0.75166,
            "recall": 0.6896,
            "fmeasure": 0.7099
        },
        "rouge2": {
            "precision": 0.48519,
            "recall": 0.43925,
            "fmeasure": 0.45412
        },
        "rougeL": {
            "precision": 0.59493,
            "recall": 0.54264,
            "fmeasure": 0.55968
        },
        "rougeLsum": {
            "precision": 0.59493,
            "recall": 0.54264,
            "fmeasure": 0.55968
        },
        "bleu": 41.30248,
        "local_recall": {
            "1": 0.20094503854762497,
            "2": 0.5143229166666666,
            "3": 0.7902912621359224,
            "4": 0.5,
            "5": 0.7619047619047619
        },
        "bertscore": {
            "precision": 0.91371,
            "recall": 0.89795,
            "f1": 0.90427
        },
        "nubia": {
            "semantic_relation": 4.15106,
            "contradiction": 7.39814,
            "irrelevancy": 10.56105,
            "logical_agreement": 82.04081,
            "grammar_ref": 4.39371,
            "grammar_hyp": 4.60045,
            "nubia_score": 0.68273
        },
        "meteor": 0.34552950420276846,
        "bleurt": 0.03237
    },
    "totto_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 124,
        "msttr-100": 0.71643,
        "msttr-100_nopunct": 0.7528,
        "total_length": 2845,
        "mean_pred_length": 22.943548387096776,
        "std_pred_length": 4.185810168149974,
        "median_pred_length": 23.5,
        "min_pred_length": 10,
        "max_pred_length": 36,
        "distinct-1": 0.43936731107205623,
        "vocab_size-1": 1250,
        "unique-1": 982,
        "entropy-1": 8.62587684237965,
        "distinct-2": 0.8493201029033444,
        "vocab_size-2": 2311,
        "unique-2": 2118,
        "entropy-2": 10.956484231870425,
        "cond_entropy-2": 2.2883168438287953,
        "distinct-3": 0.9668848671544089,
        "vocab_size-3": 2511,
        "unique-3": 2442,
        "entropy-3": 11.270703464823727,
        "cond_entropy-3": 0.32462916368939726,
        "total_length-nopunct": 2548,
        "mean_pred_length-nopunct": 20.548387096774192,
        "std_pred_length-nopunct": 3.974423956454565,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.48665620094191525,
        "vocab_size-1-nopunct": 1240,
        "unique-1-nopunct": 981,
        "entropy-1-nopunct": 8.84203974195528,
        "distinct-2-nopunct": 0.8638613861386139,
        "vocab_size-2-nopunct": 2094,
        "unique-2-nopunct": 1937,
        "entropy-2-nopunct": 10.822626007546353,
        "cond_entropy-2-nopunct": 2.0604012024501115,
        "distinct-3-nopunct": 0.9708695652173913,
        "vocab_size-3-nopunct": 2233,
        "unique-3-nopunct": 2179,
        "entropy-3-nopunct": 11.104251096911977,
        "cond_entropy-3-nopunct": 0.29280388826725684,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.9547562184828005,
        "rouge1": {
            "precision": 0.7274,
            "recall": 0.6686,
            "fmeasure": 0.68707
        },
        "rouge2": {
            "precision": 0.45846,
            "recall": 0.42483,
            "fmeasure": 0.43326
        },
        "rougeL": {
            "precision": 0.5798,
            "recall": 0.53647,
            "fmeasure": 0.54914
        },
        "rougeLsum": {
            "precision": 0.5798,
            "recall": 0.53647,
            "fmeasure": 0.54914
        },
        "bleu": 35.25886,
        "local_recall": {
            "1": 0.19254658385093168,
            "2": 0.39954853273137697,
            "3": 0.6978744939271255
        },
        "bertscore": {
            "precision": 0.90973,
            "recall": 0.90018,
            "f1": 0.90294
        },
        "nubia": {
            "semantic_relation": 3.81891,
            "contradiction": 11.87016,
            "irrelevancy": 34.27096,
            "logical_agreement": 53.85888,
            "grammar_ref": 4.3248,
            "grammar_hyp": 4.35979,
            "nubia_score": 0.61274
        },
        "meteor": 0.33239609963483213,
        "bleurt": 0.00098
    },
    "totto_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 128,
        "msttr-100": 0.705,
        "msttr-100_nopunct": 0.74731,
        "total_length": 3026,
        "mean_pred_length": 23.640625,
        "std_pred_length": 3.987743673980939,
        "median_pred_length": 24.0,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.4239920687376074,
        "vocab_size-1": 1283,
        "unique-1": 1032,
        "entropy-1": 8.497422330353851,
        "distinct-2": 0.7957211870255348,
        "vocab_size-2": 2306,
        "unique-2": 2123,
        "entropy-2": 10.770940337890245,
        "cond_entropy-2": 2.2498753199760326,
        "distinct-3": 0.9104693140794223,
        "vocab_size-3": 2522,
        "unique-3": 2439,
        "entropy-3": 11.136290054307066,
        "cond_entropy-3": 0.3818780084511144,
        "total_length-nopunct": 2648,
        "mean_pred_length-nopunct": 20.6875,
        "std_pred_length-nopunct": 3.3997931922397866,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4807401812688822,
        "vocab_size-1-nopunct": 1273,
        "unique-1-nopunct": 1029,
        "entropy-1-nopunct": 8.773220163972157,
        "distinct-2-nopunct": 0.8218253968253968,
        "vocab_size-2-nopunct": 2071,
        "unique-2-nopunct": 1928,
        "entropy-2-nopunct": 10.66212725596943,
        "cond_entropy-2-nopunct": 1.9604306202869592,
        "distinct-3-nopunct": 0.9260033444816054,
        "vocab_size-3-nopunct": 2215,
        "unique-3-nopunct": 2152,
        "entropy-3-nopunct": 10.980864841149302,
        "cond_entropy-3-nopunct": 0.33961007145255756,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 6.032969092510181,
        "rouge1": {
            "precision": 0.74802,
            "recall": 0.62145,
            "fmeasure": 0.66491
        },
        "rouge2": {
            "precision": 0.50215,
            "recall": 0.40608,
            "fmeasure": 0.43906
        },
        "rougeL": {
            "precision": 0.62557,
            "recall": 0.51441,
            "fmeasure": 0.55209
        },
        "rougeLsum": {
            "precision": 0.62557,
            "recall": 0.51441,
            "fmeasure": 0.55209
        },
        "bleu": 36.93036,
        "local_recall": {
            "1": 0.21315192743764172,
            "2": 0.39728682170542634,
            "3": 0.6662131519274377
        },
        "bertscore": {
            "precision": 0.91279,
            "recall": 0.8918,
            "f1": 0.90073
        },
        "nubia": {
            "semantic_relation": 3.66889,
            "contradiction": 15.51638,
            "irrelevancy": 28.2602,
            "logical_agreement": 56.22342,
            "grammar_ref": 4.11595,
            "grammar_hyp": 4.31431,
            "nubia_score": 0.54401
        },
        "meteor": 0.32147155468410527,
        "bleurt": -0.04828
    },
    "totto_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 61,
        "msttr-100": 0.71538,
        "msttr-100_nopunct": 0.76455,
        "total_length": 1350,
        "mean_pred_length": 22.131147540983605,
        "std_pred_length": 4.809401345916195,
        "median_pred_length": 23.0,
        "min_pred_length": 12,
        "max_pred_length": 33,
        "distinct-1": 0.5066666666666667,
        "vocab_size-1": 684,
        "unique-1": 562,
        "entropy-1": 8.120060026118196,
        "distinct-2": 0.8774243599689682,
        "vocab_size-2": 1131,
        "unique-2": 1056,
        "entropy-2": 9.97967998104383,
        "cond_entropy-2": 1.8072348259876019,
        "distinct-3": 0.9690553745928339,
        "vocab_size-3": 1190,
        "unique-3": 1158,
        "entropy-3": 10.196517219138153,
        "cond_entropy-3": 0.21645005892758332,
        "total_length-nopunct": 1176,
        "mean_pred_length-nopunct": 19.278688524590162,
        "std_pred_length-nopunct": 4.512754774755817,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5748299319727891,
        "vocab_size-1-nopunct": 676,
        "unique-1-nopunct": 559,
        "entropy-1-nopunct": 8.37413576927602,
        "distinct-2-nopunct": 0.9130044843049328,
        "vocab_size-2-nopunct": 1018,
        "unique-2-nopunct": 968,
        "entropy-2-nopunct": 9.881446547196079,
        "cond_entropy-2-nopunct": 1.5423418139176501,
        "distinct-3-nopunct": 0.9800759013282733,
        "vocab_size-3-nopunct": 1033,
        "unique-3-nopunct": 1016,
        "entropy-3-nopunct": 9.998946106088244,
        "cond_entropy-3-nopunct": 0.1262897265256851,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.908248527231796,
        "rouge1": {
            "precision": 0.73461,
            "recall": 0.62399,
            "fmeasure": 0.6668
        },
        "rouge2": {
            "precision": 0.44133,
            "recall": 0.37745,
            "fmeasure": 0.40062
        },
        "rougeL": {
            "precision": 0.59656,
            "recall": 0.51029,
            "fmeasure": 0.54175
        },
        "rougeLsum": {
            "precision": 0.59656,
            "recall": 0.51029,
            "fmeasure": 0.54175
        },
        "bleu": 33.14971,
        "local_recall": {
            "1": 0.15591397849462366,
            "2": 0.45248868778280543,
            "3": 0.6691022964509394
        },
        "bertscore": {
            "precision": 0.91407,
            "recall": 0.89612,
            "f1": 0.90357
        },
        "nubia": {
            "semantic_relation": 3.69475,
            "contradiction": 14.03459,
            "irrelevancy": 28.52696,
            "logical_agreement": 57.43846,
            "grammar_ref": 4.28842,
            "grammar_hyp": 4.50255,
            "nubia_score": 0.56638
        },
        "meteor": 0.3181149442649125,
        "bleurt": 0.02254
    },
    "totto_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 40,
        "msttr-100": 0.7125,
        "msttr-100_nopunct": 0.75,
        "total_length": 881,
        "mean_pred_length": 22.025,
        "std_pred_length": 4.274853798669611,
        "median_pred_length": 22.0,
        "min_pred_length": 12,
        "max_pred_length": 31,
        "distinct-1": 0.5141884222474461,
        "vocab_size-1": 453,
        "unique-1": 361,
        "entropy-1": 7.756867794308704,
        "distinct-2": 0.8525564803804994,
        "vocab_size-2": 717,
        "unique-2": 657,
        "entropy-2": 9.306890508899295,
        "cond_entropy-2": 1.519732687188653,
        "distinct-3": 0.9525593008739076,
        "vocab_size-3": 763,
        "unique-3": 736,
        "entropy-3": 9.535465345634028,
        "cond_entropy-3": 0.24650599685229493,
        "total_length-nopunct": 787,
        "mean_pred_length-nopunct": 19.675,
        "std_pred_length-nopunct": 3.7642230273988817,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.5641677255400254,
        "vocab_size-1-nopunct": 444,
        "unique-1-nopunct": 356,
        "entropy-1-nopunct": 7.88064991921595,
        "distinct-2-nopunct": 0.8647925033467202,
        "vocab_size-2-nopunct": 646,
        "unique-2-nopunct": 597,
        "entropy-2-nopunct": 9.16462578639136,
        "cond_entropy-2-nopunct": 1.3400900117790224,
        "distinct-3-nopunct": 0.958981612446959,
        "vocab_size-3-nopunct": 678,
        "unique-3-nopunct": 656,
        "entropy-3-nopunct": 9.371839866610532,
        "cond_entropy-3-nopunct": 0.22448925116130836,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 5.275686635253262,
        "rouge1": {
            "precision": 0.74222,
            "recall": 0.63077,
            "fmeasure": 0.67153
        },
        "rouge2": {
            "precision": 0.46665,
            "recall": 0.4015,
            "fmeasure": 0.42454
        },
        "rougeL": {
            "precision": 0.58293,
            "recall": 0.50341,
            "fmeasure": 0.53178
        },
        "rougeLsum": {
            "precision": 0.58293,
            "recall": 0.50341,
            "fmeasure": 0.53178
        },
        "bleu": 33.94717,
        "local_recall": {
            "1": 0.136986301369863,
            "2": 0.3727810650887574,
            "3": 0.6785714285714286
        },
        "bertscore": {
            "precision": 0.91091,
            "recall": 0.89136,
            "f1": 0.89958
        },
        "nubia": {
            "semantic_relation": 3.68463,
            "contradiction": 18.49184,
            "irrelevancy": 26.59477,
            "logical_agreement": 54.91339,
            "grammar_ref": 4.29053,
            "grammar_hyp": 4.29142,
            "nubia_score": 0.564
        },
        "meteor": 0.32255956132783836,
        "bleurt": -0.00116
    },
    "totto_test_contrast_challenge_input_size-input_length_11": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 20,
        "msttr-100": 0.69,
        "msttr-100_nopunct": 0.77667,
        "total_length": 452,
        "mean_pred_length": 22.6,
        "std_pred_length": 5.686826883245172,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.5685840707964602,
        "vocab_size-1": 257,
        "unique-1": 210,
        "entropy-1": 7.149002733260593,
        "distinct-2": 0.8981481481481481,
        "vocab_size-2": 388,
        "unique-2": 359,
        "entropy-2": 8.51117404726725,
        "cond_entropy-2": 1.3705155106569364,
        "distinct-3": 0.9757281553398058,
        "vocab_size-3": 402,
        "unique-3": 393,
        "entropy-3": 8.636124586643957,
        "cond_entropy-3": 0.13678128961436492,
        "total_length-nopunct": 377,
        "mean_pred_length-nopunct": 18.85,
        "std_pred_length-nopunct": 4.881342028581893,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.6631299734748011,
        "vocab_size-1-nopunct": 250,
        "unique-1-nopunct": 209,
        "entropy-1-nopunct": 7.394815395200953,
        "distinct-2-nopunct": 0.9299719887955182,
        "vocab_size-2-nopunct": 332,
        "unique-2-nopunct": 313,
        "entropy-2-nopunct": 8.325663877450298,
        "cond_entropy-2-nopunct": 0.9763042588374867,
        "distinct-3-nopunct": 0.9910979228486647,
        "vocab_size-3-nopunct": 334,
        "unique-3-nopunct": 331,
        "entropy-3-nopunct": 8.378800626879173,
        "cond_entropy-3-nopunct": 0.062283122519684396,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.7465610285610884,
        "rouge1": {
            "precision": 0.7094,
            "recall": 0.54971,
            "fmeasure": 0.60198
        },
        "rouge2": {
            "precision": 0.45155,
            "recall": 0.35282,
            "fmeasure": 0.38265
        },
        "rougeL": {
            "precision": 0.55578,
            "recall": 0.45446,
            "fmeasure": 0.48243
        },
        "rougeLsum": {
            "precision": 0.55578,
            "recall": 0.45446,
            "fmeasure": 0.48243
        },
        "bleu": 32.80328,
        "local_recall": {
            "1": 0.16091954022988506,
            "2": 0.3076923076923077,
            "3": 0.6174698795180723
        },
        "bertscore": {
            "precision": 0.9003,
            "recall": 0.88585,
            "f1": 0.88682
        },
        "nubia": {
            "semantic_relation": 3.39124,
            "contradiction": 22.82998,
            "irrelevancy": 24.54026,
            "logical_agreement": 52.62977,
            "grammar_ref": 4.38156,
            "grammar_hyp": 4.65747,
            "nubia_score": 0.45233
        },
        "meteor": 0.27929194428426324,
        "bleurt": -0.19677
    },
    "totto_test_contrast_challenge_input_size-input_length_12": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 26,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.74,
        "total_length": 669,
        "mean_pred_length": 25.73076923076923,
        "std_pred_length": 4.735769714935409,
        "median_pred_length": 27.0,
        "min_pred_length": 14,
        "max_pred_length": 32,
        "distinct-1": 0.5067264573991032,
        "vocab_size-1": 339,
        "unique-1": 257,
        "entropy-1": 7.385785358312873,
        "distinct-2": 0.8538102643856921,
        "vocab_size-2": 549,
        "unique-2": 489,
        "entropy-2": 8.963552055109782,
        "cond_entropy-2": 1.6031587637087517,
        "distinct-3": 0.9546191247974068,
        "vocab_size-3": 589,
        "unique-3": 566,
        "entropy-3": 9.170658466017892,
        "cond_entropy-3": 0.21068468069538876,
        "total_length-nopunct": 559,
        "mean_pred_length-nopunct": 21.5,
        "std_pred_length-nopunct": 3.905124837953327,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.5957066189624329,
        "vocab_size-1-nopunct": 333,
        "unique-1-nopunct": 256,
        "entropy-1-nopunct": 7.6992109137810685,
        "distinct-2-nopunct": 0.9061913696060038,
        "vocab_size-2-nopunct": 483,
        "unique-2-nopunct": 447,
        "entropy-2-nopunct": 8.845263621473482,
        "cond_entropy-2-nopunct": 1.1860171567438051,
        "distinct-3-nopunct": 0.9704142011834319,
        "vocab_size-3-nopunct": 492,
        "unique-3-nopunct": 481,
        "entropy-3-nopunct": 8.918780793019232,
        "cond_entropy-3-nopunct": 0.08048153176932081,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.766116264503394,
        "rouge1": {
            "precision": 0.74067,
            "recall": 0.58209,
            "fmeasure": 0.63714
        },
        "rouge2": {
            "precision": 0.48313,
            "recall": 0.37201,
            "fmeasure": 0.41065
        },
        "rougeL": {
            "precision": 0.585,
            "recall": 0.46184,
            "fmeasure": 0.50394
        },
        "rougeLsum": {
            "precision": 0.585,
            "recall": 0.46184,
            "fmeasure": 0.50394
        },
        "bleu": 29.68914,
        "local_recall": {
            "1": 0.175,
            "2": 0.29411764705882354,
            "3": 0.6563876651982379
        },
        "bertscore": {
            "precision": 0.90249,
            "recall": 0.88768,
            "f1": 0.8924
        },
        "nubia": {
            "semantic_relation": 3.35865,
            "contradiction": 13.66999,
            "irrelevancy": 29.54802,
            "logical_agreement": 56.78199,
            "grammar_ref": 4.04917,
            "grammar_hyp": 4.18594,
            "nubia_score": 0.46946
        },
        "meteor": 0.30179435541770316,
        "bleurt": -0.07494
    },
    "totto_test_contrast_challenge_input_size-input_length_13": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 10,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.725,
        "total_length": 233,
        "mean_pred_length": 23.3,
        "std_pred_length": 6.403905058634146,
        "median_pred_length": 24.5,
        "min_pred_length": 11,
        "max_pred_length": 31,
        "distinct-1": 0.6137339055793991,
        "vocab_size-1": 143,
        "unique-1": 119,
        "entropy-1": 6.572625379012174,
        "distinct-2": 0.9103139013452914,
        "vocab_size-2": 203,
        "unique-2": 191,
        "entropy-2": 7.592248218247753,
        "cond_entropy-2": 1.0094031292861008,
        "distinct-3": 0.9765258215962441,
        "vocab_size-3": 208,
        "unique-3": 204,
        "entropy-3": 7.684217190638255,
        "cond_entropy-3": 0.09706999030937122,
        "total_length-nopunct": 201,
        "mean_pred_length-nopunct": 20.1,
        "std_pred_length-nopunct": 5.804308744372581,
        "median_pred_length-nopunct": 21.5,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.6915422885572139,
        "vocab_size-1-nopunct": 139,
        "unique-1-nopunct": 119,
        "entropy-1-nopunct": 6.657513835569991,
        "distinct-2-nopunct": 0.9528795811518325,
        "vocab_size-2-nopunct": 182,
        "unique-2-nopunct": 177,
        "entropy-2-nopunct": 7.467378827990442,
        "cond_entropy-2-nopunct": 0.8378776419249976,
        "distinct-3-nopunct": 0.9834254143646409,
        "vocab_size-3-nopunct": 178,
        "unique-3-nopunct": 176,
        "entropy-3-nopunct": 7.462526066629234,
        "cond_entropy-3-nopunct": -0.007529349760447889,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.046409217226422,
        "rouge1": {
            "precision": 0.65355,
            "recall": 0.54784,
            "fmeasure": 0.5864
        },
        "rouge2": {
            "precision": 0.40966,
            "recall": 0.34302,
            "fmeasure": 0.36743
        },
        "rougeL": {
            "precision": 0.50395,
            "recall": 0.42745,
            "fmeasure": 0.45461
        },
        "rougeLsum": {
            "precision": 0.50395,
            "recall": 0.42745,
            "fmeasure": 0.45461
        },
        "bleu": 34.70951,
        "local_recall": {
            "1": 0.1095890410958904,
            "2": 0.3220338983050847,
            "3": 0.6575342465753424
        },
        "bertscore": {
            "precision": 0.89445,
            "recall": 0.85789,
            "f1": 0.87478
        },
        "nubia": {
            "semantic_relation": 3.1662,
            "contradiction": 21.92631,
            "irrelevancy": 30.20812,
            "logical_agreement": 47.86557,
            "grammar_ref": 4.57725,
            "grammar_hyp": 4.5999,
            "nubia_score": 0.43837
        },
        "meteor": 0.273662566009189,
        "bleurt": -0.27393
    },
    "totto_test_contrast_challenge_input_size-input_length_14": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.77,
        "total_length": 303,
        "mean_pred_length": 21.642857142857142,
        "std_pred_length": 5.393211908860763,
        "median_pred_length": 22.0,
        "min_pred_length": 10,
        "max_pred_length": 30,
        "distinct-1": 0.6270627062706271,
        "vocab_size-1": 190,
        "unique-1": 162,
        "entropy-1": 6.883990988008906,
        "distinct-2": 0.916955017301038,
        "vocab_size-2": 265,
        "unique-2": 251,
        "entropy-2": 7.965907094415655,
        "cond_entropy-2": 1.0713065023633328,
        "distinct-3": 0.9854545454545455,
        "vocab_size-3": 271,
        "unique-3": 267,
        "entropy-3": 8.074196899321116,
        "cond_entropy-3": 0.11893075120794933,
        "total_length-nopunct": 266,
        "mean_pred_length-nopunct": 19.0,
        "std_pred_length-nopunct": 4.535573676110727,
        "median_pred_length-nopunct": 20.5,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.6917293233082706,
        "vocab_size-1-nopunct": 184,
        "unique-1-nopunct": 162,
        "entropy-1-nopunct": 6.9362809989565655,
        "distinct-2-nopunct": 0.9166666666666666,
        "vocab_size-2-nopunct": 231,
        "unique-2-nopunct": 220,
        "entropy-2-nopunct": 7.76138162208498,
        "cond_entropy-2-nopunct": 0.8674260997618704,
        "distinct-3-nopunct": 0.9873949579831933,
        "vocab_size-3-nopunct": 235,
        "unique-3-nopunct": 232,
        "entropy-3-nopunct": 7.869607679274376,
        "cond_entropy-3-nopunct": 0.12092595727259275,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.772928219586188,
        "rouge1": {
            "precision": 0.69785,
            "recall": 0.58165,
            "fmeasure": 0.61585
        },
        "rouge2": {
            "precision": 0.38326,
            "recall": 0.32344,
            "fmeasure": 0.33817
        },
        "rougeL": {
            "precision": 0.58343,
            "recall": 0.49715,
            "fmeasure": 0.51962
        },
        "rougeLsum": {
            "precision": 0.58343,
            "recall": 0.49715,
            "fmeasure": 0.51962
        },
        "bleu": 24.84537,
        "local_recall": {
            "1": 0.22857142857142856,
            "2": 0.36231884057971014,
            "3": 0.5847457627118644
        },
        "bertscore": {
            "precision": 0.90273,
            "recall": 0.88491,
            "f1": 0.89277
        },
        "nubia": {
            "semantic_relation": 3.37942,
            "contradiction": 28.74065,
            "irrelevancy": 30.62326,
            "logical_agreement": 40.63609,
            "grammar_ref": 4.37064,
            "grammar_hyp": 4.42341,
            "nubia_score": 0.45047
        },
        "meteor": 0.2819520129846992,
        "bleurt": -0.13373
    },
    "totto_test_contrast_challenge_input_size-input_length_15": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 14,
        "msttr-100": 0.72333,
        "msttr-100_nopunct": 0.795,
        "total_length": 302,
        "mean_pred_length": 21.571428571428573,
        "std_pred_length": 5.136901313247201,
        "median_pred_length": 22.5,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.6357615894039735,
        "vocab_size-1": 192,
        "unique-1": 160,
        "entropy-1": 6.980244321621516,
        "distinct-2": 0.9756944444444444,
        "vocab_size-2": 281,
        "unique-2": 274,
        "entropy-2": 8.12131389033117,
        "cond_entropy-2": 1.090742212428708,
        "distinct-3": 1.0,
        "vocab_size-3": 274,
        "unique-3": 274,
        "entropy-3": 8.098032082960483,
        "cond_entropy-3": -0.020798027970836883,
        "total_length-nopunct": 258,
        "mean_pred_length-nopunct": 18.428571428571427,
        "std_pred_length-nopunct": 4.386900723652596,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.7248062015503876,
        "vocab_size-1-nopunct": 187,
        "unique-1-nopunct": 160,
        "entropy-1-nopunct": 7.147649326437154,
        "distinct-2-nopunct": 0.9877049180327869,
        "vocab_size-2-nopunct": 241,
        "unique-2-nopunct": 238,
        "entropy-2-nopunct": 7.906147173628417,
        "cond_entropy-2-nopunct": 0.7868591832747343,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 230,
        "unique-3-nopunct": 230,
        "entropy-3-nopunct": 7.845490050944362,
        "cond_entropy-3-nopunct": -0.05916033009677157,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 2.8628287587389125,
        "rouge1": {
            "precision": 0.65857,
            "recall": 0.50461,
            "fmeasure": 0.55312
        },
        "rouge2": {
            "precision": 0.3318,
            "recall": 0.25397,
            "fmeasure": 0.27901
        },
        "rougeL": {
            "precision": 0.5245,
            "recall": 0.40649,
            "fmeasure": 0.44194
        },
        "rougeLsum": {
            "precision": 0.5245,
            "recall": 0.40649,
            "fmeasure": 0.44194
        },
        "bleu": 20.34686,
        "local_recall": {
            "1": 0.21428571428571427,
            "2": 0.14705882352941177,
            "3": 0.49049429657794674
        },
        "bertscore": {
            "precision": 0.88445,
            "recall": 0.85488,
            "f1": 0.86854
        },
        "nubia": {
            "semantic_relation": 3.33641,
            "contradiction": 25.90299,
            "irrelevancy": 36.4437,
            "logical_agreement": 37.65331,
            "grammar_ref": 3.91022,
            "grammar_hyp": 3.95905,
            "nubia_score": 0.5076
        },
        "meteor": 0.22607660172166794,
        "bleurt": -0.17421
    },
    "totto_test_contrast_challenge_input_size-input_length_16": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7,
        "msttr-100": 0.68,
        "msttr-100_nopunct": 0.69,
        "total_length": 167,
        "mean_pred_length": 23.857142857142858,
        "std_pred_length": 4.356557337707688,
        "median_pred_length": 24.0,
        "min_pred_length": 16,
        "max_pred_length": 30,
        "distinct-1": 0.6107784431137725,
        "vocab_size-1": 102,
        "unique-1": 79,
        "entropy-1": 6.154626686489534,
        "distinct-2": 0.925,
        "vocab_size-2": 148,
        "unique-2": 137,
        "entropy-2": 7.167210047998845,
        "cond_entropy-2": 1.0663555067711166,
        "distinct-3": 0.9803921568627451,
        "vocab_size-3": 150,
        "unique-3": 147,
        "entropy-3": 7.218172156418123,
        "cond_entropy-3": 0.05804071187171735,
        "total_length-nopunct": 144,
        "mean_pred_length-nopunct": 20.571428571428573,
        "std_pred_length-nopunct": 4.499433070863892,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 14,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.6736111111111112,
        "vocab_size-1-nopunct": 97,
        "unique-1-nopunct": 75,
        "entropy-1-nopunct": 6.30502682474799,
        "distinct-2-nopunct": 0.948905109489051,
        "vocab_size-2-nopunct": 130,
        "unique-2-nopunct": 123,
        "entropy-2-nopunct": 6.995842301938614,
        "cond_entropy-2-nopunct": 0.727708084758977,
        "distinct-3-nopunct": 0.9846153846153847,
        "vocab_size-3-nopunct": 128,
        "unique-3-nopunct": 126,
        "entropy-3-nopunct": 6.991598582259225,
        "cond_entropy-3-nopunct": -0.006433500701303018,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 3.5436298062730365,
        "rouge1": {
            "precision": 0.68304,
            "recall": 0.53388,
            "fmeasure": 0.58853
        },
        "rouge2": {
            "precision": 0.42437,
            "recall": 0.36659,
            "fmeasure": 0.3849
        },
        "rougeL": {
            "precision": 0.56129,
            "recall": 0.45025,
            "fmeasure": 0.48843
        },
        "rougeLsum": {
            "precision": 0.56129,
            "recall": 0.45025,
            "fmeasure": 0.48843
        },
        "bleu": 29.09902,
        "local_recall": {
            "1": 0.3157894736842105,
            "2": 0.4166666666666667,
            "3": 0.6521739130434783
        },
        "bertscore": {
            "precision": 0.90094,
            "recall": 0.86826,
            "f1": 0.88366
        },
        "nubia": {
            "semantic_relation": 3.12242,
            "contradiction": 11.94026,
            "irrelevancy": 53.4937,
            "logical_agreement": 34.56605,
            "grammar_ref": 3.5611,
            "grammar_hyp": 3.82934,
            "nubia_score": 0.39744
        },
        "meteor": 0.28800505613405136,
        "bleurt": -0.22405
    },
    "totto_test_contrast_challenge_input_size-input_length_17": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 6,
        "msttr-100": 0.71,
        "msttr-100_nopunct": 0.81,
        "total_length": 149,
        "mean_pred_length": 24.833333333333332,
        "std_pred_length": 4.946940693218609,
        "median_pred_length": 23.5,
        "min_pred_length": 20,
        "max_pred_length": 33,
        "distinct-1": 0.7046979865771812,
        "vocab_size-1": 105,
        "unique-1": 91,
        "entropy-1": 6.363309168296584,
        "distinct-2": 0.951048951048951,
        "vocab_size-2": 136,
        "unique-2": 131,
        "entropy-2": 7.0479832248902845,
        "cond_entropy-2": 0.687333277648454,
        "distinct-3": 0.9927007299270073,
        "vocab_size-3": 136,
        "unique-3": 135,
        "entropy-3": 7.083433542814526,
        "cond_entropy-3": 0.04035052720403507,
        "total_length-nopunct": 127,
        "mean_pred_length-nopunct": 21.166666666666668,
        "std_pred_length-nopunct": 4.775516260631467,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 17,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.7952755905511811,
        "vocab_size-1-nopunct": 101,
        "unique-1-nopunct": 91,
        "entropy-1-nopunct": 6.429475631585904,
        "distinct-2-nopunct": 0.9752066115702479,
        "vocab_size-2-nopunct": 118,
        "unique-2-nopunct": 115,
        "entropy-2-nopunct": 6.869276460415098,
        "cond_entropy-2-nopunct": 0.46753020346650986,
        "distinct-3-nopunct": 1.0,
        "vocab_size-3-nopunct": 115,
        "unique-3-nopunct": 115,
        "entropy-3-nopunct": 6.84549005094439,
        "cond_entropy-3-nopunct": -0.02119927328674085,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 4.562264191826989,
        "rouge1": {
            "precision": 0.78159,
            "recall": 0.55191,
            "fmeasure": 0.63977
        },
        "rouge2": {
            "precision": 0.65348,
            "recall": 0.45538,
            "fmeasure": 0.5309
        },
        "rougeL": {
            "precision": 0.74863,
            "recall": 0.5296,
            "fmeasure": 0.61335
        },
        "rougeLsum": {
            "precision": 0.74863,
            "recall": 0.5296,
            "fmeasure": 0.61335
        },
        "bleu": 49.00688,
        "local_recall": {
            "1": 0.15151515151515152,
            "2": 0.3888888888888889,
            "3": 0.6017699115044248
        },
        "bertscore": {
            "precision": 0.92482,
            "recall": 0.88295,
            "f1": 0.90258
        },
        "nubia": {
            "semantic_relation": 3.16681,
            "contradiction": 25.0908,
            "irrelevancy": 27.40274,
            "logical_agreement": 47.50646,
            "grammar_ref": 3.81267,
            "grammar_hyp": 3.56647,
            "nubia_score": 0.45826
        },
        "meteor": 0.3451731077040065,
        "bleurt": -0.02516
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-7": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72238,
        "msttr-100_nopunct": 0.73263,
        "total_length": 2117,
        "mean_pred_length": 19.971698113207548,
        "std_pred_length": 3.8226177614788797,
        "median_pred_length": 20.0,
        "min_pred_length": 9,
        "max_pred_length": 29,
        "distinct-1": 0.4166273027869627,
        "vocab_size-1": 882,
        "unique-1": 682,
        "entropy-1": 8.159833807083098,
        "distinct-2": 0.8274490303331675,
        "vocab_size-2": 1664,
        "unique-2": 1526,
        "entropy-2": 10.44596634837996,
        "cond_entropy-2": 2.1539928063098923,
        "distinct-3": 0.9553805774278216,
        "vocab_size-3": 1820,
        "unique-3": 1764,
        "entropy-3": 10.790237597078246,
        "cond_entropy-3": 0.3508843772003714,
        "total_length-nopunct": 1995,
        "mean_pred_length-nopunct": 18.82075471698113,
        "std_pred_length-nopunct": 3.8943528777015897,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.4380952380952381,
        "vocab_size-1-nopunct": 874,
        "unique-1-nopunct": 680,
        "entropy-1-nopunct": 8.234332485639191,
        "distinct-2-nopunct": 0.8295394388565378,
        "vocab_size-2-nopunct": 1567,
        "unique-2-nopunct": 1438,
        "entropy-2-nopunct": 10.35879798580081,
        "cond_entropy-2-nopunct": 2.230839354694488,
        "distinct-3-nopunct": 0.9590577678070668,
        "vocab_size-3-nopunct": 1710,
        "unique-3-nopunct": 1661,
        "entropy-3-nopunct": 10.703397982580514,
        "cond_entropy-3-nopunct": 0.35884342312814066,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.168623480392696,
        "rouge1": {
            "precision": 0.42382,
            "recall": 0.37183,
            "fmeasure": 0.38869
        },
        "rouge2": {
            "precision": 0.15425,
            "recall": 0.1365,
            "fmeasure": 0.14183
        },
        "rougeL": {
            "precision": 0.31465,
            "recall": 0.27956,
            "fmeasure": 0.29034
        },
        "rougeLsum": {
            "precision": 0.31465,
            "recall": 0.27956,
            "fmeasure": 0.29034
        },
        "bleu": 7.90204,
        "local_recall": {
            "1": 0.34344377041530566
        },
        "bertscore": {
            "precision": 0.83353,
            "recall": 0.81772,
            "f1": 0.82519
        },
        "nubia": {
            "semantic_relation": 2.94188,
            "contradiction": 19.11492,
            "irrelevancy": 61.09373,
            "logical_agreement": 19.79134,
            "grammar_ref": 3.75874,
            "grammar_hyp": 3.62823,
            "nubia_score": 0.44318
        },
        "meteor": 0.1636461107404089,
        "bleurt": -0.34708
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 389,
        "msttr-100": 0.29775,
        "msttr-100_nopunct": 0.30338,
        "total_length": 7138,
        "mean_pred_length": 18.34961439588689,
        "std_pred_length": 4.736352995403513,
        "median_pred_length": 17.0,
        "min_pred_length": 10,
        "max_pred_length": 28,
        "distinct-1": 0.032502101428971704,
        "vocab_size-1": 232,
        "unique-1": 36,
        "entropy-1": 6.172048229194864,
        "distinct-2": 0.09631056452807824,
        "vocab_size-2": 650,
        "unique-2": 149,
        "entropy-2": 7.995705808606815,
        "cond_entropy-2": 1.7297362035499664,
        "distinct-3": 0.15927672955974842,
        "vocab_size-3": 1013,
        "unique-3": 300,
        "entropy-3": 8.913297604880277,
        "cond_entropy-3": 0.9449527922142974,
        "total_length-nopunct": 6589,
        "mean_pred_length-nopunct": 16.938303341902312,
        "std_pred_length-nopunct": 4.428964980381291,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.03490666261951738,
        "vocab_size-1-nopunct": 230,
        "unique-1-nopunct": 36,
        "entropy-1-nopunct": 6.237654965107743,
        "distinct-2-nopunct": 0.0996774193548387,
        "vocab_size-2-nopunct": 618,
        "unique-2-nopunct": 144,
        "entropy-2-nopunct": 7.91254718213123,
        "cond_entropy-2-nopunct": 1.7523719581732682,
        "distinct-3-nopunct": 0.16589227327482362,
        "vocab_size-3-nopunct": 964,
        "unique-3-nopunct": 286,
        "entropy-3-nopunct": 8.885793435783892,
        "cond_entropy-3-nopunct": 0.9769485460579421,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.254413981476833,
        "rouge1": {
            "precision": 0.63402,
            "recall": 0.63539,
            "fmeasure": 0.61948
        },
        "rouge2": {
            "precision": 0.37401,
            "recall": 0.37547,
            "fmeasure": 0.3651
        },
        "rougeL": {
            "precision": 0.49492,
            "recall": 0.49623,
            "fmeasure": 0.48366
        },
        "rougeLsum": {
            "precision": 0.49492,
            "recall": 0.49623,
            "fmeasure": 0.48366
        },
        "bleu": 26.35347,
        "local_recall": {
            "1": 0.6196129451943405
        },
        "bertscore": {
            "precision": 0.8961,
            "recall": 0.89137,
            "f1": 0.89323
        },
        "nubia": {
            "semantic_relation": 3.89038,
            "contradiction": 7.57889,
            "irrelevancy": 43.50282,
            "logical_agreement": 48.91829,
            "grammar_ref": 5.31197,
            "grammar_hyp": 4.91006,
            "nubia_score": 0.65283
        },
        "meteor": 0.32020926315033293,
        "bleurt": -0.03379
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-8": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72429,
        "msttr-100_nopunct": 0.7435,
        "total_length": 2172,
        "mean_pred_length": 20.49056603773585,
        "std_pred_length": 3.7397540102204276,
        "median_pred_length": 21.0,
        "min_pred_length": 11,
        "max_pred_length": 28,
        "distinct-1": 0.40423572744014735,
        "vocab_size-1": 878,
        "unique-1": 642,
        "entropy-1": 8.187279475223942,
        "distinct-2": 0.8262342691190707,
        "vocab_size-2": 1707,
        "unique-2": 1534,
        "entropy-2": 10.516506745000845,
        "cond_entropy-2": 2.179758971088775,
        "distinct-3": 0.9520408163265306,
        "vocab_size-3": 1866,
        "unique-3": 1800,
        "entropy-3": 10.822824335708107,
        "cond_entropy-3": 0.3182175007293644,
        "total_length-nopunct": 2040,
        "mean_pred_length-nopunct": 19.245283018867923,
        "std_pred_length-nopunct": 3.63891783819144,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.42696078431372547,
        "vocab_size-1-nopunct": 871,
        "unique-1-nopunct": 640,
        "entropy-1-nopunct": 8.27867878325198,
        "distinct-2-nopunct": 0.8324715615305067,
        "vocab_size-2-nopunct": 1610,
        "unique-2-nopunct": 1455,
        "entropy-2-nopunct": 10.436227358613207,
        "cond_entropy-2-nopunct": 2.2567513357891027,
        "distinct-3-nopunct": 0.9578774617067833,
        "vocab_size-3-nopunct": 1751,
        "unique-3-nopunct": 1693,
        "entropy-3-nopunct": 10.7402978591938,
        "cond_entropy-3-nopunct": 0.31408943555786184,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.0664524560981503,
        "rouge1": {
            "precision": 0.39924,
            "recall": 0.35968,
            "fmeasure": 0.3718
        },
        "rouge2": {
            "precision": 0.13081,
            "recall": 0.11878,
            "fmeasure": 0.12195
        },
        "rougeL": {
            "precision": 0.31104,
            "recall": 0.28096,
            "fmeasure": 0.28981
        },
        "rougeLsum": {
            "precision": 0.31104,
            "recall": 0.28096,
            "fmeasure": 0.28981
        },
        "bleu": 6.99237,
        "local_recall": {
            "1": 0.3262672811059908
        },
        "bertscore": {
            "precision": 0.82782,
            "recall": 0.81535,
            "f1": 0.82127
        },
        "nubia": {
            "semantic_relation": 2.80786,
            "contradiction": 21.62175,
            "irrelevancy": 65.37602,
            "logical_agreement": 13.00223,
            "grammar_ref": 3.78639,
            "grammar_hyp": 3.60367,
            "nubia_score": 0.40021
        },
        "meteor": 0.1530393165234817,
        "bleurt": -0.34911
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-9": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72762,
        "msttr-100_nopunct": 0.7385,
        "total_length": 2145,
        "mean_pred_length": 20.235849056603772,
        "std_pred_length": 3.635651266026417,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.4027972027972028,
        "vocab_size-1": 864,
        "unique-1": 671,
        "entropy-1": 8.14635409137596,
        "distinct-2": 0.8258950465914664,
        "vocab_size-2": 1684,
        "unique-2": 1540,
        "entropy-2": 10.466361952292008,
        "cond_entropy-2": 2.1713885106423194,
        "distinct-3": 0.9518882565959649,
        "vocab_size-3": 1840,
        "unique-3": 1778,
        "entropy-3": 10.801329566100806,
        "cond_entropy-3": 0.3464587754293609,
        "total_length-nopunct": 2033,
        "mean_pred_length-nopunct": 19.17924528301887,
        "std_pred_length-nopunct": 3.6336923624763915,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.42154451549434335,
        "vocab_size-1-nopunct": 857,
        "unique-1-nopunct": 667,
        "entropy-1-nopunct": 8.229206527500379,
        "distinct-2-nopunct": 0.826673585884795,
        "vocab_size-2-nopunct": 1593,
        "unique-2-nopunct": 1463,
        "entropy-2-nopunct": 10.380759934556831,
        "cond_entropy-2-nopunct": 2.2532652078154944,
        "distinct-3-nopunct": 0.9549697968149369,
        "vocab_size-3-nopunct": 1739,
        "unique-3-nopunct": 1683,
        "entropy-3-nopunct": 10.724410664469257,
        "cond_entropy-3-nopunct": 0.3579039711299147,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.005074432238124,
        "rouge1": {
            "precision": 0.39064,
            "recall": 0.34837,
            "fmeasure": 0.36064
        },
        "rouge2": {
            "precision": 0.13771,
            "recall": 0.1174,
            "fmeasure": 0.12455
        },
        "rougeL": {
            "precision": 0.29827,
            "recall": 0.26551,
            "fmeasure": 0.27486
        },
        "rougeLsum": {
            "precision": 0.29827,
            "recall": 0.26551,
            "fmeasure": 0.27486
        },
        "bleu": 7.83352,
        "local_recall": {
            "1": 0.3220657276995305
        },
        "bertscore": {
            "precision": 0.82743,
            "recall": 0.81066,
            "f1": 0.81863
        },
        "nubia": {
            "semantic_relation": 2.67634,
            "contradiction": 24.41316,
            "irrelevancy": 63.37663,
            "logical_agreement": 12.21021,
            "grammar_ref": 3.81724,
            "grammar_hyp": 3.61737,
            "nubia_score": 0.3713
        },
        "meteor": 0.14942361550691619,
        "bleurt": -0.34174
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-10": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.73947,
        "msttr-100_nopunct": 0.74889,
        "total_length": 1975,
        "mean_pred_length": 18.632075471698112,
        "std_pred_length": 4.241140536566525,
        "median_pred_length": 19.0,
        "min_pred_length": 8,
        "max_pred_length": 27,
        "distinct-1": 0.419746835443038,
        "vocab_size-1": 829,
        "unique-1": 638,
        "entropy-1": 8.185600985547001,
        "distinct-2": 0.8330658105939005,
        "vocab_size-2": 1557,
        "unique-2": 1421,
        "entropy-2": 10.375595404809912,
        "cond_entropy-2": 2.05223869371144,
        "distinct-3": 0.9546228020419739,
        "vocab_size-3": 1683,
        "unique-3": 1627,
        "entropy-3": 10.678415375382075,
        "cond_entropy-3": 0.31133432257241306,
        "total_length-nopunct": 1867,
        "mean_pred_length-nopunct": 17.61320754716981,
        "std_pred_length-nopunct": 4.353638154846963,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.44081414033208355,
        "vocab_size-1-nopunct": 823,
        "unique-1-nopunct": 635,
        "entropy-1-nopunct": 8.275475590212011,
        "distinct-2-nopunct": 0.8330494037478705,
        "vocab_size-2-nopunct": 1467,
        "unique-2-nopunct": 1338,
        "entropy-2-nopunct": 10.287508539916068,
        "cond_entropy-2-nopunct": 2.116219479364962,
        "distinct-3-nopunct": 0.9564954682779456,
        "vocab_size-3-nopunct": 1583,
        "unique-3-nopunct": 1532,
        "entropy-3-nopunct": 10.59166821928908,
        "cond_entropy-3-nopunct": 0.31864756573800757,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 2.614397175584515,
        "rouge1": {
            "precision": 0.36958,
            "recall": 0.32463,
            "fmeasure": 0.33514
        },
        "rouge2": {
            "precision": 0.12338,
            "recall": 0.10785,
            "fmeasure": 0.11208
        },
        "rougeL": {
            "precision": 0.2924,
            "recall": 0.25479,
            "fmeasure": 0.26384
        },
        "rougeLsum": {
            "precision": 0.2924,
            "recall": 0.25479,
            "fmeasure": 0.26384
        },
        "bleu": 6.9698,
        "local_recall": {
            "1": 0.28745136186770426
        },
        "bertscore": {
            "precision": 0.81982,
            "recall": 0.8036,
            "f1": 0.8112
        },
        "nubia": {
            "semantic_relation": 2.68567,
            "contradiction": 22.13322,
            "irrelevancy": 66.46852,
            "logical_agreement": 11.39826,
            "grammar_ref": 3.93729,
            "grammar_hyp": 3.76484,
            "nubia_score": 0.37604
        },
        "meteor": 0.13668632819181098,
        "bleurt": -0.45836
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1328,
        "msttr-100": 0.6931,
        "msttr-100_nopunct": 0.71567,
        "total_length": 25274,
        "mean_pred_length": 19.031626506024097,
        "std_pred_length": 4.681309903725571,
        "median_pred_length": 19.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.07917227189997626,
        "vocab_size-1": 2001,
        "unique-1": 965,
        "entropy-1": 7.999581849190419,
        "distinct-2": 0.24872630084356467,
        "vocab_size-2": 5956,
        "unique-2": 3528,
        "entropy-2": 10.896134547177988,
        "cond_entropy-2": 2.7437732485438096,
        "distinct-3": 0.40865682200017683,
        "vocab_size-3": 9243,
        "unique-3": 6358,
        "entropy-3": 12.0845456888901,
        "cond_entropy-3": 1.246253629160218,
        "total_length-nopunct": 22499,
        "mean_pred_length-nopunct": 16.942018072289155,
        "std_pred_length-nopunct": 4.202026851690026,
        "median_pred_length-nopunct": 17.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.08835948264367305,
        "vocab_size-1-nopunct": 1988,
        "unique-1-nopunct": 963,
        "entropy-1-nopunct": 8.18614806118283,
        "distinct-2-nopunct": 0.262906806480563,
        "vocab_size-2-nopunct": 5566,
        "unique-2-nopunct": 3370,
        "entropy-2-nopunct": 10.832005887544096,
        "cond_entropy-2-nopunct": 2.7823798951036394,
        "distinct-3-nopunct": 0.42800987753867864,
        "vocab_size-3-nopunct": 8493,
        "unique-3-nopunct": 5961,
        "entropy-3-nopunct": 12.009696835296257,
        "cond_entropy-3-nopunct": 1.263653229212283,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.859434997772775,
        "rouge1": {
            "precision": 0.64893,
            "recall": 0.62712,
            "fmeasure": 0.62696
        },
        "rouge2": {
            "precision": 0.42687,
            "recall": 0.4134,
            "fmeasure": 0.41272
        },
        "rougeL": {
            "precision": 0.55657,
            "recall": 0.53894,
            "fmeasure": 0.53855
        },
        "rougeLsum": {
            "precision": 0.55657,
            "recall": 0.53894,
            "fmeasure": 0.53855
        },
        "bleu": 32.76504,
        "local_recall": {
            "1": 0.6053063457330415
        },
        "bertscore": {
            "precision": 0.89165,
            "recall": 0.88155,
            "f1": 0.88616
        },
        "nubia": {
            "semantic_relation": 4.25392,
            "contradiction": 3.60574,
            "irrelevancy": 17.65824,
            "logical_agreement": 78.73602,
            "grammar_ref": 4.79322,
            "grammar_hyp": 4.61272,
            "nubia_score": 0.76048
        },
        "meteor": 0.333877643575716,
        "bleurt": 0.00025
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 737,
        "msttr-100": 0.29253,
        "msttr-100_nopunct": 0.28688,
        "total_length": 15075,
        "mean_pred_length": 20.454545454545453,
        "std_pred_length": 3.756988471926908,
        "median_pred_length": 20.0,
        "min_pred_length": 12,
        "max_pred_length": 31,
        "distinct-1": 0.018175787728026534,
        "vocab_size-1": 274,
        "unique-1": 61,
        "entropy-1": 6.061857315299507,
        "distinct-2": 0.0625610266424885,
        "vocab_size-2": 897,
        "unique-2": 240,
        "entropy-2": 8.004555785623074,
        "cond_entropy-2": 1.9024071529300914,
        "distinct-3": 0.11462392471141827,
        "vocab_size-3": 1559,
        "unique-3": 497,
        "entropy-3": 9.072896186813162,
        "cond_entropy-3": 1.1074514417955066,
        "total_length-nopunct": 13896,
        "mean_pred_length-nopunct": 18.85481682496608,
        "std_pred_length-nopunct": 3.6955849195015738,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.01957397812320092,
        "vocab_size-1-nopunct": 272,
        "unique-1-nopunct": 61,
        "entropy-1-nopunct": 6.0895608521789715,
        "distinct-2-nopunct": 0.06550649745421384,
        "vocab_size-2-nopunct": 862,
        "unique-2-nopunct": 232,
        "entropy-2-nopunct": 7.920955553691449,
        "cond_entropy-2-nopunct": 1.9160894415253775,
        "distinct-3-nopunct": 0.11946546449847045,
        "vocab_size-3-nopunct": 1484,
        "unique-3-nopunct": 463,
        "entropy-3-nopunct": 9.028266151596974,
        "cond_entropy-3-nopunct": 1.1233508639065013,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.579058869663511,
        "rouge1": {
            "precision": 0.68509,
            "recall": 0.66478,
            "fmeasure": 0.66306
        },
        "rouge2": {
            "precision": 0.39847,
            "recall": 0.3869,
            "fmeasure": 0.38527
        },
        "rougeL": {
            "precision": 0.51645,
            "recall": 0.50411,
            "fmeasure": 0.50158
        },
        "rougeLsum": {
            "precision": 0.51645,
            "recall": 0.50411,
            "fmeasure": 0.50158
        },
        "bleu": 26.61401,
        "local_recall": {
            "1": 0.6517620310723758
        },
        "bertscore": {
            "precision": 0.90318,
            "recall": 0.89546,
            "f1": 0.89884
        },
        "nubia": {
            "semantic_relation": 4.10467,
            "contradiction": 3.42472,
            "irrelevancy": 33.50189,
            "logical_agreement": 63.07339,
            "grammar_ref": 4.94689,
            "grammar_hyp": 4.76281,
            "nubia_score": 0.7045
        },
        "meteor": 0.3336633591184658,
        "bleurt": 0.09644
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 469,
        "msttr-100": 0.69598,
        "msttr-100_nopunct": 0.70636,
        "total_length": 9766,
        "mean_pred_length": 20.823027718550108,
        "std_pred_length": 4.008070563112697,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.1179602703256195,
        "vocab_size-1": 1152,
        "unique-1": 582,
        "entropy-1": 7.826082410200307,
        "distinct-2": 0.31784446595676025,
        "vocab_size-2": 2955,
        "unique-2": 1839,
        "entropy-2": 10.259942395820538,
        "cond_entropy-2": 2.331345979314271,
        "distinct-3": 0.4840280924331672,
        "vocab_size-3": 4273,
        "unique-3": 3013,
        "entropy-3": 11.289285431699481,
        "cond_entropy-3": 1.0727856786409566,
        "total_length-nopunct": 8882,
        "mean_pred_length-nopunct": 18.93816631130064,
        "std_pred_length-nopunct": 3.747694905761261,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.1287998198603918,
        "vocab_size-1-nopunct": 1144,
        "unique-1-nopunct": 582,
        "entropy-1-nopunct": 7.945374878252021,
        "distinct-2-nopunct": 0.3280637109235707,
        "vocab_size-2-nopunct": 2760,
        "unique-2-nopunct": 1742,
        "entropy-2-nopunct": 10.183257368900671,
        "cond_entropy-2-nopunct": 2.33193659057204,
        "distinct-3-nopunct": 0.5013846928499497,
        "vocab_size-3-nopunct": 3983,
        "unique-3-nopunct": 2841,
        "entropy-3-nopunct": 11.231664253389232,
        "cond_entropy-3-nopunct": 1.0924297733736685,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.75736057852479,
        "rouge1": {
            "precision": 0.67668,
            "recall": 0.66474,
            "fmeasure": 0.66106
        },
        "rouge2": {
            "precision": 0.44552,
            "recall": 0.43651,
            "fmeasure": 0.43447
        },
        "rougeL": {
            "precision": 0.5781,
            "recall": 0.56982,
            "fmeasure": 0.56595
        },
        "rougeLsum": {
            "precision": 0.5781,
            "recall": 0.56982,
            "fmeasure": 0.56595
        },
        "bleu": 34.39148,
        "local_recall": {
            "1": 0.6467863346844238
        },
        "bertscore": {
            "precision": 0.89473,
            "recall": 0.88794,
            "f1": 0.89096
        },
        "nubia": {
            "semantic_relation": 4.34213,
            "contradiction": 3.15684,
            "irrelevancy": 20.09203,
            "logical_agreement": 76.75113,
            "grammar_ref": 4.86994,
            "grammar_hyp": 4.76128,
            "nubia_score": 0.76473
        },
        "meteor": 0.35005710528189826,
        "bleurt": 0.01586
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 335,
        "msttr-100": 0.63793,
        "msttr-100_nopunct": 0.64132,
        "total_length": 8231,
        "mean_pred_length": 24.570149253731344,
        "std_pred_length": 2.74710240426424,
        "median_pred_length": 25.0,
        "min_pred_length": 15,
        "max_pred_length": 32,
        "distinct-1": 0.10654841453043373,
        "vocab_size-1": 877,
        "unique-1": 434,
        "entropy-1": 7.402687301234152,
        "distinct-2": 0.2726697061803445,
        "vocab_size-2": 2153,
        "unique-2": 1275,
        "entropy-2": 9.668029830304084,
        "cond_entropy-2": 2.250341103388488,
        "distinct-3": 0.42666313979632325,
        "vocab_size-3": 3226,
        "unique-3": 2231,
        "entropy-3": 10.683266768075313,
        "cond_entropy-3": 1.0342697507805108,
        "total_length-nopunct": 7619,
        "mean_pred_length-nopunct": 22.743283582089553,
        "std_pred_length-nopunct": 2.3613317694791105,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.11353195957474735,
        "vocab_size-1-nopunct": 865,
        "unique-1-nopunct": 432,
        "entropy-1-nopunct": 7.408882092795491,
        "distinct-2-nopunct": 0.2818506315211422,
        "vocab_size-2-nopunct": 2053,
        "unique-2-nopunct": 1233,
        "entropy-2-nopunct": 9.610583775171516,
        "cond_entropy-2-nopunct": 2.2469437418968665,
        "distinct-3-nopunct": 0.4393437904734494,
        "vocab_size-3-nopunct": 3053,
        "unique-3-nopunct": 2161,
        "entropy-3-nopunct": 10.598137296633098,
        "cond_entropy-3-nopunct": 1.0329457448846617,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.7853711856091525,
        "rouge1": {
            "precision": 0.74524,
            "recall": 0.67487,
            "fmeasure": 0.70134
        },
        "rouge2": {
            "precision": 0.53707,
            "recall": 0.48737,
            "fmeasure": 0.50586
        },
        "rougeL": {
            "precision": 0.64188,
            "recall": 0.58152,
            "fmeasure": 0.60424
        },
        "rougeLsum": {
            "precision": 0.64188,
            "recall": 0.58152,
            "fmeasure": 0.60424
        },
        "bleu": 39.23779,
        "local_recall": {
            "1": 0.6570700636942676
        },
        "bertscore": {
            "precision": 0.90932,
            "recall": 0.89113,
            "f1": 0.89985
        },
        "nubia": {
            "semantic_relation": 4.35585,
            "contradiction": 1.32594,
            "irrelevancy": 9.35071,
            "logical_agreement": 89.32335,
            "grammar_ref": 4.45968,
            "grammar_hyp": 4.46736,
            "nubia_score": 0.77514
        },
        "meteor": 0.3668815712785908,
        "bleurt": 0.01214
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 256,
        "msttr-100": 0.62,
        "msttr-100_nopunct": 0.6165,
        "total_length": 6457,
        "mean_pred_length": 25.22265625,
        "std_pred_length": 2.6869974775455105,
        "median_pred_length": 26.0,
        "min_pred_length": 14,
        "max_pred_length": 31,
        "distinct-1": 0.08610809973671985,
        "vocab_size-1": 556,
        "unique-1": 245,
        "entropy-1": 7.036905281422079,
        "distinct-2": 0.24141267537493952,
        "vocab_size-2": 1497,
        "unique-2": 775,
        "entropy-2": 9.238892915826986,
        "cond_entropy-2": 2.25255554580631,
        "distinct-3": 0.4094196804037006,
        "vocab_size-3": 2434,
        "unique-3": 1561,
        "entropy-3": 10.32126422862734,
        "cond_entropy-3": 1.156035188579231,
        "total_length-nopunct": 6038,
        "mean_pred_length-nopunct": 23.5859375,
        "std_pred_length-nopunct": 2.5016474064291616,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.09092414706856575,
        "vocab_size-1-nopunct": 549,
        "unique-1-nopunct": 245,
        "entropy-1-nopunct": 7.025052479005043,
        "distinct-2-nopunct": 0.24852992044275338,
        "vocab_size-2-nopunct": 1437,
        "unique-2-nopunct": 759,
        "entropy-2-nopunct": 9.189295822535016,
        "cond_entropy-2-nopunct": 2.261109977895807,
        "distinct-3-nopunct": 0.417119073470865,
        "vocab_size-3-nopunct": 2305,
        "unique-3-nopunct": 1492,
        "entropy-3-nopunct": 10.273693305225958,
        "cond_entropy-3-nopunct": 1.1676721455768921,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 5.0829056702269355,
        "rouge1": {
            "precision": 0.71363,
            "recall": 0.58544,
            "fmeasure": 0.63432
        },
        "rouge2": {
            "precision": 0.45406,
            "recall": 0.37364,
            "fmeasure": 0.40409
        },
        "rougeL": {
            "precision": 0.57569,
            "recall": 0.47402,
            "fmeasure": 0.51289
        },
        "rougeLsum": {
            "precision": 0.57569,
            "recall": 0.47402,
            "fmeasure": 0.51289
        },
        "bleu": 28.15576,
        "local_recall": {
            "1": 0.5800949273212697
        },
        "bertscore": {
            "precision": 0.89569,
            "recall": 0.86775,
            "f1": 0.88119
        },
        "nubia": {
            "semantic_relation": 3.80091,
            "contradiction": 1.78318,
            "irrelevancy": 12.68861,
            "logical_agreement": 85.52821,
            "grammar_ref": 4.19274,
            "grammar_hyp": 4.33539,
            "nubia_score": 0.59621
        },
        "meteor": 0.3061983695982208,
        "bleurt": -0.17418
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 46,
        "msttr-100": 0.53182,
        "msttr-100_nopunct": 0.535,
        "total_length": 1163,
        "mean_pred_length": 25.282608695652176,
        "std_pred_length": 2.122990543285793,
        "median_pred_length": 26.0,
        "min_pred_length": 19,
        "max_pred_length": 29,
        "distinct-1": 0.14961306964746346,
        "vocab_size-1": 174,
        "unique-1": 69,
        "entropy-1": 6.199620416144826,
        "distinct-2": 0.37242614145031333,
        "vocab_size-2": 416,
        "unique-2": 228,
        "entropy-2": 7.884180444919442,
        "cond_entropy-2": 1.7281900510546642,
        "distinct-3": 0.5387488328664799,
        "vocab_size-3": 577,
        "unique-3": 386,
        "entropy-3": 8.635049420693223,
        "cond_entropy-3": 0.8101517739717125,
        "total_length-nopunct": 1099,
        "mean_pred_length-nopunct": 23.891304347826086,
        "std_pred_length-nopunct": 2.0665899329210577,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 18,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.15468607825295724,
        "vocab_size-1-nopunct": 170,
        "unique-1-nopunct": 69,
        "entropy-1-nopunct": 6.145991388728657,
        "distinct-2-nopunct": 0.37606837606837606,
        "vocab_size-2-nopunct": 396,
        "unique-2-nopunct": 216,
        "entropy-2-nopunct": 7.826509129394844,
        "cond_entropy-2-nopunct": 1.7412482156091211,
        "distinct-3-nopunct": 0.5441906653426017,
        "vocab_size-3-nopunct": 548,
        "unique-3-nopunct": 365,
        "entropy-3-nopunct": 8.590095107428445,
        "cond_entropy-3-nopunct": 0.8195408166538505,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 4.22928070261569,
        "rouge1": {
            "precision": 0.6536,
            "recall": 0.57301,
            "fmeasure": 0.59781
        },
        "rouge2": {
            "precision": 0.40487,
            "recall": 0.3629,
            "fmeasure": 0.37456
        },
        "rougeL": {
            "precision": 0.54519,
            "recall": 0.47904,
            "fmeasure": 0.49916
        },
        "rougeLsum": {
            "precision": 0.54519,
            "recall": 0.47904,
            "fmeasure": 0.49916
        },
        "bleu": 27.20184,
        "local_recall": {
            "1": 0.5582163501238646
        },
        "bertscore": {
            "precision": 0.88671,
            "recall": 0.86083,
            "f1": 0.87316
        },
        "nubia": {
            "semantic_relation": 3.61007,
            "contradiction": 52.24834,
            "irrelevancy": 18.10725,
            "logical_agreement": 29.64441,
            "grammar_ref": 4.5797,
            "grammar_hyp": 4.65485,
            "nubia_score": 0.50448
        },
        "meteor": 0.27760663350622133,
        "bleurt": -0.21704
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 1187,
        "msttr-100": 0.28806,
        "msttr-100_nopunct": 0.28203,
        "total_length": 25365,
        "mean_pred_length": 21.368997472620052,
        "std_pred_length": 3.485483085528459,
        "median_pred_length": 22.0,
        "min_pred_length": 13,
        "max_pred_length": 31,
        "distinct-1": 0.011827321111768185,
        "vocab_size-1": 300,
        "unique-1": 63,
        "entropy-1": 5.937570766352666,
        "distinct-2": 0.044296467863346844,
        "vocab_size-2": 1071,
        "unique-2": 316,
        "entropy-2": 7.876432491802882,
        "cond_entropy-2": 1.934651410297096,
        "distinct-3": 0.08825192466617372,
        "vocab_size-3": 2029,
        "unique-3": 698,
        "entropy-3": 9.052727709566955,
        "cond_entropy-3": 1.2246707423550287,
        "total_length-nopunct": 23754,
        "mean_pred_length-nopunct": 20.01179443976411,
        "std_pred_length-nopunct": 3.314952324153349,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.012461059190031152,
        "vocab_size-1-nopunct": 296,
        "unique-1-nopunct": 63,
        "entropy-1-nopunct": 5.938476969114167,
        "distinct-2-nopunct": 0.046616741259361015,
        "vocab_size-2-nopunct": 1052,
        "unique-2-nopunct": 320,
        "entropy-2-nopunct": 7.831966593722072,
        "cond_entropy-2-nopunct": 1.972438947662626,
        "distinct-3-nopunct": 0.09172123479887745,
        "vocab_size-3-nopunct": 1961,
        "unique-3-nopunct": 672,
        "entropy-3-nopunct": 9.050641787573154,
        "cond_entropy-3-nopunct": 1.2425689924809922,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.756030566240933,
        "rouge1": {
            "precision": 0.75632,
            "recall": 0.69034,
            "fmeasure": 0.71206
        },
        "rouge2": {
            "precision": 0.42635,
            "recall": 0.38746,
            "fmeasure": 0.40025
        },
        "rougeL": {
            "precision": 0.53221,
            "recall": 0.4855,
            "fmeasure": 0.50087
        },
        "rougeLsum": {
            "precision": 0.53221,
            "recall": 0.4855,
            "fmeasure": 0.50087
        },
        "bleu": 26.48599,
        "local_recall": {
            "1": 0.6798332420937382
        },
        "bertscore": {
            "precision": 0.9149,
            "recall": 0.89919,
            "f1": 0.90668
        },
        "nubia": {
            "semantic_relation": 4.31267,
            "contradiction": 1.97238,
            "irrelevancy": 19.31202,
            "logical_agreement": 78.7156,
            "grammar_ref": 4.92209,
            "grammar_hyp": 4.83901,
            "nubia_score": 0.75396
        },
        "meteor": 0.3430692162728132,
        "bleurt": 0.09845
    },
    "schema_guided_dialog_test_contrast_challenge_acts-2": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1397,
        "msttr-100": 0.61098,
        "msttr-100_nopunct": 0.61012,
        "total_length": 27625,
        "mean_pred_length": 19.774516821760916,
        "std_pred_length": 4.962852182840951,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.06298642533936652,
        "vocab_size-1": 1740,
        "unique-1": 820,
        "entropy-1": 7.371082743385012,
        "distinct-2": 0.1921229220680189,
        "vocab_size-2": 5039,
        "unique-2": 2955,
        "entropy-2": 9.936819095969556,
        "cond_entropy-2": 2.5165596644390322,
        "distinct-3": 0.3377632797712537,
        "vocab_size-3": 8387,
        "unique-3": 5803,
        "entropy-3": 11.283055433949784,
        "cond_entropy-3": 1.4121893736331197,
        "total_length-nopunct": 25174,
        "mean_pred_length-nopunct": 18.02004294917681,
        "std_pred_length-nopunct": 4.859326670323914,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06860252641614364,
        "vocab_size-1-nopunct": 1727,
        "unique-1-nopunct": 817,
        "entropy-1-nopunct": 7.4092989594222045,
        "distinct-2-nopunct": 0.202843083652269,
        "vocab_size-2-nopunct": 4823,
        "unique-2-nopunct": 2880,
        "entropy-2-nopunct": 9.878366960604218,
        "cond_entropy-2-nopunct": 2.5767642920779545,
        "distinct-3-nopunct": 0.35406613047363716,
        "vocab_size-3-nopunct": 7924,
        "unique-3-nopunct": 5567,
        "entropy-3-nopunct": 11.24582847459254,
        "cond_entropy-3-nopunct": 1.4516912568040352,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.823411248370918,
        "rouge1": {
            "precision": 0.66923,
            "recall": 0.66155,
            "fmeasure": 0.65383
        },
        "rouge2": {
            "precision": 0.45708,
            "recall": 0.45381,
            "fmeasure": 0.44744
        },
        "rougeL": {
            "precision": 0.58133,
            "recall": 0.57714,
            "fmeasure": 0.56934
        },
        "rougeLsum": {
            "precision": 0.58133,
            "recall": 0.57714,
            "fmeasure": 0.56934
        },
        "bleu": 36.23161,
        "local_recall": {
            "1": 0.6446929646197641
        },
        "bertscore": {
            "precision": 0.88457,
            "recall": 0.88233,
            "f1": 0.88302
        },
        "nubia": {
            "semantic_relation": 4.17805,
            "contradiction": 3.3988,
            "irrelevancy": 18.74029,
            "logical_agreement": 77.86091,
            "grammar_ref": 4.97201,
            "grammar_hyp": 4.8512,
            "nubia_score": 0.71999
        },
        "meteor": 0.3456416552655941,
        "bleurt": -0.00845
    },
    "schema_guided_dialog_test_contrast_challenge_acts-3": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 983,
        "msttr-100": 0.1725,
        "msttr-100_nopunct": 0.15714,
        "total_length": 5294,
        "mean_pred_length": 5.385554425228891,
        "std_pred_length": 1.4812750799567118,
        "median_pred_length": 5.0,
        "min_pred_length": 2,
        "max_pred_length": 12,
        "distinct-1": 0.011333585190782017,
        "vocab_size-1": 60,
        "unique-1": 19,
        "entropy-1": 3.4781408323449226,
        "distinct-2": 0.02180468568777546,
        "vocab_size-2": 94,
        "unique-2": 29,
        "entropy-2": 3.9266837174464224,
        "cond_entropy-2": 0.433541446150983,
        "distinct-3": 0.03275240384615385,
        "vocab_size-3": 109,
        "unique-3": 33,
        "entropy-3": 4.350078498618862,
        "cond_entropy-3": 0.420964819791258,
        "total_length-nopunct": 4289,
        "mean_pred_length-nopunct": 4.363173957273652,
        "std_pred_length-nopunct": 1.1523547907821454,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 10,
        "distinct-1-nopunct": 0.013289811144788995,
        "vocab_size-1-nopunct": 57,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 3.1419733329088255,
        "distinct-2-nopunct": 0.022988505747126436,
        "vocab_size-2-nopunct": 76,
        "unique-2-nopunct": 26,
        "entropy-2-nopunct": 3.4759856182791036,
        "cond_entropy-2-nopunct": 0.21679794779728523,
        "distinct-3-nopunct": 0.03314679294016358,
        "vocab_size-3-nopunct": 77,
        "unique-3-nopunct": 28,
        "entropy-3-nopunct": 3.627527579057969,
        "cond_entropy-3-nopunct": 0.24927777599892606,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 2.8178689342266066,
        "rouge1": {
            "precision": 0.54961,
            "recall": 0.51716,
            "fmeasure": 0.52493
        },
        "rouge2": {
            "precision": 0.37393,
            "recall": 0.34922,
            "fmeasure": 0.35504
        },
        "rougeL": {
            "precision": 0.54884,
            "recall": 0.51655,
            "fmeasure": 0.52426
        },
        "rougeLsum": {
            "precision": 0.54884,
            "recall": 0.51655,
            "fmeasure": 0.52426
        },
        "bleu": 30.70713,
        "local_recall": {
            "1": 0.5009633911368016
        },
        "bertscore": {
            "precision": 0.86139,
            "recall": 0.8557,
            "f1": 0.85809
        },
        "nubia": {
            "semantic_relation": 3.15098,
            "contradiction": 2.30256,
            "irrelevancy": 22.39564,
            "logical_agreement": 75.3018,
            "grammar_ref": 4.77701,
            "grammar_hyp": 4.44379,
            "nubia_score": 0.61039
        },
        "meteor": 0.2741691483526321,
        "bleurt": 0.14646
    },
    "schema_guided_dialog_test_contrast_challenge_acts-4": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1027,
        "msttr-100": 0.61981,
        "msttr-100_nopunct": 0.65785,
        "total_length": 10797,
        "mean_pred_length": 10.513145082765336,
        "std_pred_length": 4.299472640538682,
        "median_pred_length": 9.0,
        "min_pred_length": 3,
        "max_pred_length": 26,
        "distinct-1": 0.1060479762897101,
        "vocab_size-1": 1145,
        "unique-1": 611,
        "entropy-1": 7.299443112560141,
        "distinct-2": 0.2955987717502559,
        "vocab_size-2": 2888,
        "unique-2": 1771,
        "entropy-2": 10.08004381904523,
        "cond_entropy-2": 2.409791077477271,
        "distinct-3": 0.47192039345762327,
        "vocab_size-3": 4126,
        "unique-3": 2899,
        "entropy-3": 11.136159407369895,
        "cond_entropy-3": 1.109372953392356,
        "total_length-nopunct": 9330,
        "mean_pred_length-nopunct": 9.084712755598831,
        "std_pred_length-nopunct": 4.050031554117874,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.12186495176848874,
        "vocab_size-1-nopunct": 1137,
        "unique-1-nopunct": 611,
        "entropy-1-nopunct": 7.574315932087163,
        "distinct-2-nopunct": 0.3047091412742382,
        "vocab_size-2-nopunct": 2530,
        "unique-2-nopunct": 1550,
        "entropy-2-nopunct": 9.920408763338722,
        "cond_entropy-2-nopunct": 2.5943425675844063,
        "distinct-3-nopunct": 0.4868059373282023,
        "vocab_size-3-nopunct": 3542,
        "unique-3-nopunct": 2511,
        "entropy-3-nopunct": 10.933044911683012,
        "cond_entropy-3-nopunct": 1.1554142759717956,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.556229661903773,
        "rouge1": {
            "precision": 0.69479,
            "recall": 0.68906,
            "fmeasure": 0.68258
        },
        "rouge2": {
            "precision": 0.49564,
            "recall": 0.49337,
            "fmeasure": 0.48635
        },
        "rougeL": {
            "precision": 0.63527,
            "recall": 0.62866,
            "fmeasure": 0.62327
        },
        "rougeLsum": {
            "precision": 0.63527,
            "recall": 0.62866,
            "fmeasure": 0.62327
        },
        "bleu": 47.64194,
        "local_recall": {
            "1": 0.6602295299050982
        },
        "bertscore": {
            "precision": 0.91291,
            "recall": 0.90886,
            "f1": 0.91055
        },
        "nubia": {
            "semantic_relation": 4.25097,
            "contradiction": 3.82151,
            "irrelevancy": 15.34432,
            "logical_agreement": 80.83416,
            "grammar_ref": 4.86642,
            "grammar_hyp": 4.68318,
            "nubia_score": 0.80251
        },
        "meteor": 0.393558423627785,
        "bleurt": 0.28624
    },
    "schema_guided_dialog_test_contrast_challenge_acts-5": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 958,
        "msttr-100": 0.65426,
        "msttr-100_nopunct": 0.67572,
        "total_length": 20262,
        "mean_pred_length": 21.150313152400834,
        "std_pred_length": 4.611453801675085,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 31,
        "distinct-1": 0.07797848188727667,
        "vocab_size-1": 1580,
        "unique-1": 728,
        "entropy-1": 7.6280644659459655,
        "distinct-2": 0.22772482387070037,
        "vocab_size-2": 4396,
        "unique-2": 2542,
        "entropy-2": 10.261391709370944,
        "cond_entropy-2": 2.5332327549859825,
        "distinct-3": 0.3719611904502344,
        "vocab_size-3": 6824,
        "unique-3": 4496,
        "entropy-3": 11.487724719534715,
        "cond_entropy-3": 1.3046370054540222,
        "total_length-nopunct": 18059,
        "mean_pred_length-nopunct": 18.850730688935283,
        "std_pred_length-nopunct": 4.380833955616012,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.08682651309596323,
        "vocab_size-1-nopunct": 1568,
        "unique-1-nopunct": 727,
        "entropy-1-nopunct": 7.799248754262554,
        "distinct-2-nopunct": 0.24133091632068301,
        "vocab_size-2-nopunct": 4127,
        "unique-2-nopunct": 2471,
        "entropy-2-nopunct": 10.247472709355947,
        "cond_entropy-2-nopunct": 2.5843965809735376,
        "distinct-3-nopunct": 0.39236820913089265,
        "vocab_size-3-nopunct": 6334,
        "unique-3-nopunct": 4240,
        "entropy-3-nopunct": 11.503801027893825,
        "cond_entropy-3-nopunct": 1.3556947591734385,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 6.570756937676246,
        "rouge1": {
            "precision": 0.63827,
            "recall": 0.62165,
            "fmeasure": 0.62007
        },
        "rouge2": {
            "precision": 0.40692,
            "recall": 0.39567,
            "fmeasure": 0.39474
        },
        "rougeL": {
            "precision": 0.55505,
            "recall": 0.54151,
            "fmeasure": 0.53994
        },
        "rougeLsum": {
            "precision": 0.55505,
            "recall": 0.54151,
            "fmeasure": 0.53994
        },
        "bleu": 31.90658,
        "local_recall": {
            "1": 0.6081042788325305
        },
        "bertscore": {
            "precision": 0.88504,
            "recall": 0.87909,
            "f1": 0.88166
        },
        "nubia": {
            "semantic_relation": 4.3479,
            "contradiction": 4.07102,
            "irrelevancy": 17.35604,
            "logical_agreement": 78.57294,
            "grammar_ref": 4.83769,
            "grammar_hyp": 4.72074,
            "nubia_score": 0.76646
        },
        "meteor": 0.3344939389763902,
        "bleurt": -0.03562
    },
    "schema_guided_dialog_test_contrast_challenge_acts-9": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 72,
        "msttr-100": 0.62647,
        "msttr-100_nopunct": 0.635,
        "total_length": 1797,
        "mean_pred_length": 24.958333333333332,
        "std_pred_length": 3.326816546389857,
        "median_pred_length": 25.0,
        "min_pred_length": 15,
        "max_pred_length": 32,
        "distinct-1": 0.2020033388981636,
        "vocab_size-1": 363,
        "unique-1": 218,
        "entropy-1": 6.952207602380866,
        "distinct-2": 0.4255072463768116,
        "vocab_size-2": 734,
        "unique-2": 505,
        "entropy-2": 8.654950898034906,
        "cond_entropy-2": 1.7389290926736602,
        "distinct-3": 0.573502722323049,
        "vocab_size-3": 948,
        "unique-3": 734,
        "entropy-3": 9.285420631305053,
        "cond_entropy-3": 0.6688178284138154,
        "total_length-nopunct": 1622,
        "mean_pred_length-nopunct": 22.52777777777778,
        "std_pred_length-nopunct": 3.2014416120025877,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 13,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.21948212083847102,
        "vocab_size-1-nopunct": 356,
        "unique-1-nopunct": 217,
        "entropy-1-nopunct": 6.997184273905924,
        "distinct-2-nopunct": 0.4483870967741935,
        "vocab_size-2-nopunct": 695,
        "unique-2-nopunct": 486,
        "entropy-2-nopunct": 8.604848633122206,
        "cond_entropy-2-nopunct": 1.6830862813930851,
        "distinct-3-nopunct": 0.5981055480378891,
        "vocab_size-3-nopunct": 884,
        "unique-3-nopunct": 690,
        "entropy-3-nopunct": 9.225686458513014,
        "cond_entropy-3-nopunct": 0.6723923099372995,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 3.5731800232997775,
        "rouge1": {
            "precision": 0.66107,
            "recall": 0.49984,
            "fmeasure": 0.56033
        },
        "rouge2": {
            "precision": 0.41175,
            "recall": 0.31128,
            "fmeasure": 0.34881
        },
        "rougeL": {
            "precision": 0.53266,
            "recall": 0.40459,
            "fmeasure": 0.45256
        },
        "rougeLsum": {
            "precision": 0.53266,
            "recall": 0.40459,
            "fmeasure": 0.45256
        },
        "bleu": 24.73245,
        "local_recall": {
            "1": 0.4967645594823295
        },
        "bertscore": {
            "precision": 0.89182,
            "recall": 0.84527,
            "f1": 0.86753
        },
        "nubia": {
            "semantic_relation": 3.66296,
            "contradiction": 3.13529,
            "irrelevancy": 12.40816,
            "logical_agreement": 84.45655,
            "grammar_ref": 4.20036,
            "grammar_hyp": 4.37736,
            "nubia_score": 0.54474
        },
        "meteor": 0.2720907042209754,
        "bleurt": -0.28784
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 1406,
        "msttr-100": 0.30662,
        "msttr-100_nopunct": 0.29842,
        "total_length": 33766,
        "mean_pred_length": 24.01564722617354,
        "std_pred_length": 2.452051679772114,
        "median_pred_length": 24.0,
        "min_pred_length": 16,
        "max_pred_length": 32,
        "distinct-1": 0.00838121186992833,
        "vocab_size-1": 283,
        "unique-1": 39,
        "entropy-1": 5.915266718272317,
        "distinct-2": 0.034703337453646475,
        "vocab_size-2": 1123,
        "unique-2": 239,
        "entropy-2": 7.9356240351981,
        "cond_entropy-2": 2.086502698175665,
        "distinct-3": 0.07494992569619435,
        "vocab_size-3": 2320,
        "unique-3": 571,
        "entropy-3": 9.258532607960602,
        "cond_entropy-3": 1.4055119320982785,
        "total_length-nopunct": 31758,
        "mean_pred_length-nopunct": 22.587482219061165,
        "std_pred_length-nopunct": 2.510679846363454,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 15,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.00881667611310536,
        "vocab_size-1-nopunct": 280,
        "unique-1-nopunct": 39,
        "entropy-1-nopunct": 5.903198230200125,
        "distinct-2-nopunct": 0.03690036900369004,
        "vocab_size-2-nopunct": 1120,
        "unique-2-nopunct": 252,
        "entropy-2-nopunct": 7.91211647537743,
        "cond_entropy-2-nopunct": 2.117263159512126,
        "distinct-3-nopunct": 0.07842188903475437,
        "vocab_size-3-nopunct": 2270,
        "unique-3-nopunct": 581,
        "entropy-3-nopunct": 9.265098213525373,
        "cond_entropy-3-nopunct": 1.4277154876142049,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.469315962464615,
        "rouge1": {
            "precision": 0.76774,
            "recall": 0.65787,
            "fmeasure": 0.70198
        },
        "rouge2": {
            "precision": 0.44711,
            "recall": 0.3827,
            "fmeasure": 0.40837
        },
        "rougeL": {
            "precision": 0.5293,
            "recall": 0.45505,
            "fmeasure": 0.48482
        },
        "rougeLsum": {
            "precision": 0.5293,
            "recall": 0.45505,
            "fmeasure": 0.48482
        },
        "bleu": 25.58761,
        "local_recall": {
            "1": 0.643458185242565
        },
        "bertscore": {
            "precision": 0.91433,
            "recall": 0.89114,
            "f1": 0.90238
        },
        "nubia": {
            "semantic_relation": 4.21805,
            "contradiction": 3.42633,
            "irrelevancy": 11.74181,
            "logical_agreement": 84.83187,
            "grammar_ref": 4.68084,
            "grammar_hyp": 4.78262,
            "nubia_score": 0.70829
        },
        "meteor": 0.3280352471752962,
        "bleurt": 0.04173
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 5049,
        "msttr-100": 0.55375,
        "msttr-100_nopunct": 0.57269,
        "total_length": 37975,
        "mean_pred_length": 7.521291344820757,
        "std_pred_length": 2.7281228390020207,
        "median_pred_length": 7.0,
        "min_pred_length": 2,
        "max_pred_length": 26,
        "distinct-1": 0.028518762343647135,
        "vocab_size-1": 1083,
        "unique-1": 440,
        "entropy-1": 6.72546920993051,
        "distinct-2": 0.10277592176395553,
        "vocab_size-2": 3384,
        "unique-2": 1629,
        "entropy-2": 9.047630461814212,
        "cond_entropy-2": 1.9590628105639671,
        "distinct-3": 0.17559278258062203,
        "vocab_size-3": 4895,
        "unique-3": 2773,
        "entropy-3": 9.820297667640839,
        "cond_entropy-3": 0.8150390928740542,
        "total_length-nopunct": 32481,
        "mean_pred_length-nopunct": 6.433155080213904,
        "std_pred_length-nopunct": 2.516087664605869,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 23,
        "distinct-1-nopunct": 0.03303469720759829,
        "vocab_size-1-nopunct": 1073,
        "unique-1-nopunct": 439,
        "entropy-1-nopunct": 6.878750167641112,
        "distinct-2-nopunct": 0.10487751531058617,
        "vocab_size-2-nopunct": 2877,
        "unique-2-nopunct": 1418,
        "entropy-2-nopunct": 8.721577351646538,
        "cond_entropy-2-nopunct": 2.0418412429818456,
        "distinct-3-nopunct": 0.17832573930134907,
        "vocab_size-3-nopunct": 3992,
        "unique-3-nopunct": 2329,
        "entropy-3-nopunct": 9.430578257008689,
        "cond_entropy-3-nopunct": 0.8407656117340766,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 4.861477560763127,
        "rouge1": {
            "precision": 0.51662,
            "recall": 0.49971,
            "fmeasure": 0.49575
        },
        "rouge2": {
            "precision": 0.30477,
            "recall": 0.29737,
            "fmeasure": 0.29341
        },
        "rougeL": {
            "precision": 0.49216,
            "recall": 0.47465,
            "fmeasure": 0.47187
        },
        "rougeLsum": {
            "precision": 0.49216,
            "recall": 0.47465,
            "fmeasure": 0.47187
        },
        "bleu": 27.55201,
        "local_recall": {
            "1": 0.479446038531358
        },
        "bertscore": {
            "precision": 0.86287,
            "recall": 0.85729,
            "f1": 0.85951
        },
        "nubia": {
            "semantic_relation": 3.28048,
            "contradiction": 5.32605,
            "irrelevancy": 25.40311,
            "logical_agreement": 69.27084,
            "grammar_ref": 4.77787,
            "grammar_hyp": 4.45141,
            "nubia_score": 0.61398
        },
        "meteor": 0.2720393071242132,
        "bleurt": -0.05149
    },
    "schema_guided_dialog_test_contrast_challenge_acts-10": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1024,
        "msttr-100": 0.4832,
        "msttr-100_nopunct": 0.51085,
        "total_length": 9717,
        "mean_pred_length": 9.4892578125,
        "std_pred_length": 5.8035786572086465,
        "median_pred_length": 6.0,
        "min_pred_length": 3,
        "max_pred_length": 28,
        "distinct-1": 0.07553771740249048,
        "vocab_size-1": 734,
        "unique-1": 422,
        "entropy-1": 6.219509903518554,
        "distinct-2": 0.20246175083400436,
        "vocab_size-2": 1760,
        "unique-2": 1058,
        "entropy-2": 8.629996433117974,
        "cond_entropy-2": 2.091260084566662,
        "distinct-3": 0.33433302907810664,
        "vocab_size-3": 2564,
        "unique-3": 1745,
        "entropy-3": 9.654149813607354,
        "cond_entropy-3": 1.0056423730510573,
        "total_length-nopunct": 8276,
        "mean_pred_length-nopunct": 8.08203125,
        "std_pred_length-nopunct": 5.156639130676437,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 25,
        "distinct-1-nopunct": 0.08772353794103431,
        "vocab_size-1-nopunct": 726,
        "unique-1-nopunct": 421,
        "entropy-1-nopunct": 6.441110183992819,
        "distinct-2-nopunct": 0.22021511307225594,
        "vocab_size-2-nopunct": 1597,
        "unique-2-nopunct": 982,
        "entropy-2-nopunct": 8.526556771222046,
        "cond_entropy-2-nopunct": 2.265278864711998,
        "distinct-3-nopunct": 0.371868978805395,
        "vocab_size-3-nopunct": 2316,
        "unique-3-nopunct": 1614,
        "entropy-3-nopunct": 9.607466300910568,
        "cond_entropy-3-nopunct": 1.0632967356872103,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 4.332713524694276,
        "rouge1": {
            "precision": 0.42323,
            "recall": 0.38453,
            "fmeasure": 0.39319
        },
        "rouge2": {
            "precision": 0.20206,
            "recall": 0.1919,
            "fmeasure": 0.193
        },
        "rougeL": {
            "precision": 0.3813,
            "recall": 0.34632,
            "fmeasure": 0.35398
        },
        "rougeLsum": {
            "precision": 0.3813,
            "recall": 0.34632,
            "fmeasure": 0.35398
        },
        "bleu": 23.72292,
        "local_recall": {
            "1": 0.4131125973029273
        },
        "bertscore": {
            "precision": 0.85147,
            "recall": 0.83691,
            "f1": 0.84374
        },
        "nubia": {
            "semantic_relation": 2.55332,
            "contradiction": 7.95351,
            "irrelevancy": 27.37228,
            "logical_agreement": 64.67421,
            "grammar_ref": 5.2128,
            "grammar_hyp": 5.14559,
            "nubia_score": 0.42731
        },
        "meteor": 0.24243650454744248,
        "bleurt": -0.53842
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_8": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 774,
        "msttr-100": 0.31912,
        "msttr-100_nopunct": 0.31201,
        "total_length": 19475,
        "mean_pred_length": 25.161498708010335,
        "std_pred_length": 1.801812417104633,
        "median_pred_length": 25.0,
        "min_pred_length": 21,
        "max_pred_length": 31,
        "distinct-1": 0.011861360718870347,
        "vocab_size-1": 231,
        "unique-1": 28,
        "entropy-1": 6.060499780699578,
        "distinct-2": 0.046628522538901665,
        "vocab_size-2": 872,
        "unique-2": 150,
        "entropy-2": 8.058996879501397,
        "cond_entropy-2": 2.1034321461192387,
        "distinct-3": 0.09488481062085123,
        "vocab_size-3": 1701,
        "unique-3": 340,
        "entropy-3": 9.34828567379243,
        "cond_entropy-3": 1.3852255827055664,
        "total_length-nopunct": 18454,
        "mean_pred_length-nopunct": 23.842377260981912,
        "std_pred_length-nopunct": 1.6021505354660985,
        "median_pred_length-nopunct": 24.0,
        "min_pred_length-nopunct": 19,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.012355044976698818,
        "vocab_size-1-nopunct": 228,
        "unique-1-nopunct": 28,
        "entropy-1-nopunct": 6.034100429086375,
        "distinct-2-nopunct": 0.04909502262443439,
        "vocab_size-2-nopunct": 868,
        "unique-2-nopunct": 156,
        "entropy-2-nopunct": 8.052731363800406,
        "cond_entropy-2-nopunct": 2.130464197116558,
        "distinct-3-nopunct": 0.0991364012776529,
        "vocab_size-3-nopunct": 1676,
        "unique-3-nopunct": 350,
        "entropy-3-nopunct": 9.358377663091474,
        "cond_entropy-3-nopunct": 1.4029685811049444,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 3.5201751264544456,
        "rouge1": {
            "precision": 0.77976,
            "recall": 0.588,
            "fmeasure": 0.66645
        },
        "rouge2": {
            "precision": 0.44454,
            "recall": 0.33237,
            "fmeasure": 0.37802
        },
        "rougeL": {
            "precision": 0.52781,
            "recall": 0.3994,
            "fmeasure": 0.45204
        },
        "rougeLsum": {
            "precision": 0.52781,
            "recall": 0.3994,
            "fmeasure": 0.45204
        },
        "bleu": 22.06185,
        "local_recall": {
            "1": 0.579020913875821
        },
        "bertscore": {
            "precision": 0.91048,
            "recall": 0.8696,
            "f1": 0.88939
        },
        "nubia": {
            "semantic_relation": 3.7225,
            "contradiction": 3.74253,
            "irrelevancy": 13.4608,
            "logical_agreement": 82.79667,
            "grammar_ref": 4.52626,
            "grammar_hyp": 4.71799,
            "nubia_score": 0.557
        },
        "meteor": 0.2925803569996926,
        "bleurt": -0.10904
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_9": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 73,
        "msttr-100": 0.40833,
        "msttr-100_nopunct": 0.39882,
        "total_length": 1801,
        "mean_pred_length": 24.671232876712327,
        "std_pred_length": 1.894872638366877,
        "median_pred_length": 25.0,
        "min_pred_length": 21,
        "max_pred_length": 28,
        "distinct-1": 0.07662409772348695,
        "vocab_size-1": 138,
        "unique-1": 38,
        "entropy-1": 5.896420185613724,
        "distinct-2": 0.2222222222222222,
        "vocab_size-2": 384,
        "unique-2": 131,
        "entropy-2": 7.650672150791579,
        "cond_entropy-2": 1.8624351569583846,
        "distinct-3": 0.3794561933534743,
        "vocab_size-3": 628,
        "unique-3": 301,
        "entropy-3": 8.629137282648708,
        "cond_entropy-3": 1.0467989698882387,
        "total_length-nopunct": 1709,
        "mean_pred_length-nopunct": 23.410958904109588,
        "std_pred_length-nopunct": 1.5862043645074113,
        "median_pred_length-nopunct": 23.0,
        "min_pred_length-nopunct": 20,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.07957870099473376,
        "vocab_size-1-nopunct": 136,
        "unique-1-nopunct": 38,
        "entropy-1-nopunct": 5.870029720459956,
        "distinct-2-nopunct": 0.22860635696821516,
        "vocab_size-2-nopunct": 374,
        "unique-2-nopunct": 132,
        "entropy-2-nopunct": 7.673327130065134,
        "cond_entropy-2-nopunct": 1.915366429840008,
        "distinct-3-nopunct": 0.39539347408829173,
        "vocab_size-3-nopunct": 618,
        "unique-3-nopunct": 299,
        "entropy-3-nopunct": 8.675733939235547,
        "cond_entropy-3-nopunct": 1.0700183025813566,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 3.789022206605965,
        "rouge1": {
            "precision": 0.78482,
            "recall": 0.6083,
            "fmeasure": 0.68187
        },
        "rouge2": {
            "precision": 0.48416,
            "recall": 0.37485,
            "fmeasure": 0.42011
        },
        "rougeL": {
            "precision": 0.55194,
            "recall": 0.43088,
            "fmeasure": 0.48134
        },
        "rougeLsum": {
            "precision": 0.55194,
            "recall": 0.43088,
            "fmeasure": 0.48134
        },
        "bleu": 26.23386,
        "local_recall": {
            "1": 0.5929878048780488
        },
        "bertscore": {
            "precision": 0.91694,
            "recall": 0.87824,
            "f1": 0.897
        },
        "nubia": {
            "semantic_relation": 3.75347,
            "contradiction": 5.81373,
            "irrelevancy": 10.27957,
            "logical_agreement": 83.9067,
            "grammar_ref": 4.71083,
            "grammar_hyp": 4.76616,
            "nubia_score": 0.57702
        },
        "meteor": 0.3100170135462803,
        "bleurt": -0.1014
    },
    "e2e_nlg_test_contrast_challenge_input_size-input_length_10": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 2,
        "msttr-100": NaN,
        "msttr-100_nopunct": NaN,
        "total_length": 53,
        "mean_pred_length": 26.5,
        "std_pred_length": 0.5,
        "median_pred_length": 26.5,
        "min_pred_length": 26,
        "max_pred_length": 27,
        "distinct-1": 0.6981132075471698,
        "vocab_size-1": 37,
        "unique-1": 26,
        "entropy-1": 5.034432011126151,
        "distinct-2": 0.8627450980392157,
        "vocab_size-2": 44,
        "unique-2": 37,
        "entropy-2": 5.39791553804993,
        "cond_entropy-2": 0.39067915215659976,
        "distinct-3": 0.9183673469387755,
        "vocab_size-3": 45,
        "unique-3": 41,
        "entropy-3": 5.45144453799276,
        "cond_entropy-3": 0.06473348173554959,
        "total_length-nopunct": 51,
        "mean_pred_length-nopunct": 25.5,
        "std_pred_length-nopunct": 0.5,
        "median_pred_length-nopunct": 25.5,
        "min_pred_length-nopunct": 25,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.7058823529411765,
        "vocab_size-1-nopunct": 36,
        "unique-1-nopunct": 26,
        "entropy-1-nopunct": 4.9909569595761365,
        "distinct-2-nopunct": 0.8775510204081632,
        "vocab_size-2-nopunct": 43,
        "unique-2-nopunct": 37,
        "entropy-2-nopunct": 5.3698118849315355,
        "cond_entropy-2-nopunct": 0.40666996137153877,
        "distinct-3-nopunct": 0.9361702127659575,
        "vocab_size-3-nopunct": 44,
        "unique-3-nopunct": 41,
        "entropy-3-nopunct": 5.426929277209555,
        "cond_entropy-3-nopunct": 0.06753858203051422,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 2.1082878268266336,
        "rouge1": {
            "precision": 0.90385,
            "recall": 0.57895,
            "fmeasure": 0.70565
        },
        "rouge2": {
            "precision": 0.72,
            "recall": 0.45847,
            "fmeasure": 0.56011
        },
        "rougeL": {
            "precision": 0.69231,
            "recall": 0.44799,
            "fmeasure": 0.54388
        },
        "rougeLsum": {
            "precision": 0.69231,
            "recall": 0.44799,
            "fmeasure": 0.54388
        },
        "bleu": 37.37688,
        "local_recall": {
            "1": 0.5714285714285714
        },
        "bertscore": {
            "precision": 0.93934,
            "recall": 0.87753,
            "f1": 0.90727
        },
        "nubia": {
            "semantic_relation": 3.49711,
            "contradiction": 22.25155,
            "irrelevancy": 2.13086,
            "logical_agreement": 75.61758,
            "grammar_ref": 4.16331,
            "grammar_hyp": 4.695,
            "nubia_score": 0.42126
        },
        "meteor": 0.32803829179897354,
        "bleurt": -0.07307
    },
    "schema_guided_dialog_test_contrast_challenge_acts-11": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 1246,
        "msttr-100": 0.65527,
        "msttr-100_nopunct": 0.67339,
        "total_length": 18278,
        "mean_pred_length": 14.669341894060995,
        "std_pred_length": 4.733997192905198,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 29,
        "distinct-1": 0.0983149141043878,
        "vocab_size-1": 1797,
        "unique-1": 832,
        "entropy-1": 7.837664115370538,
        "distinct-2": 0.26544152184124004,
        "vocab_size-2": 4521,
        "unique-2": 2678,
        "entropy-2": 10.36755784507646,
        "cond_entropy-2": 2.3354452612617096,
        "distinct-3": 0.40890662612441403,
        "vocab_size-3": 6455,
        "unique-3": 4396,
        "entropy-3": 11.462976033631401,
        "cond_entropy-3": 1.15480702439224,
        "total_length-nopunct": 16535,
        "mean_pred_length-nopunct": 13.270465489566613,
        "std_pred_length-nopunct": 4.410138357134145,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.10777139401270033,
        "vocab_size-1-nopunct": 1782,
        "unique-1-nopunct": 829,
        "entropy-1-nopunct": 7.962809879119104,
        "distinct-2-nopunct": 0.2690169402838642,
        "vocab_size-2-nopunct": 4113,
        "unique-2-nopunct": 2498,
        "entropy-2-nopunct": 10.190367249877733,
        "cond_entropy-2-nopunct": 2.384002822399553,
        "distinct-3-nopunct": 0.4148686178167058,
        "vocab_size-3-nopunct": 5826,
        "unique-3-nopunct": 4046,
        "entropy-3-nopunct": 11.283200651988915,
        "cond_entropy-3-nopunct": 1.1944801739099802,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.566331500630667,
        "rouge1": {
            "precision": 0.72121,
            "recall": 0.68362,
            "fmeasure": 0.69153
        },
        "rouge2": {
            "precision": 0.51106,
            "recall": 0.48456,
            "fmeasure": 0.48951
        },
        "rougeL": {
            "precision": 0.63426,
            "recall": 0.60206,
            "fmeasure": 0.60877
        },
        "rougeLsum": {
            "precision": 0.63426,
            "recall": 0.60206,
            "fmeasure": 0.60877
        },
        "bleu": 40.4655,
        "local_recall": {
            "1": 0.6576184226225987
        },
        "bertscore": {
            "precision": 0.91047,
            "recall": 0.89659,
            "f1": 0.90306
        },
        "nubia": {
            "semantic_relation": 4.43558,
            "contradiction": 4.01338,
            "irrelevancy": 19.24446,
            "logical_agreement": 76.74215,
            "grammar_ref": 4.92094,
            "grammar_hyp": 4.75957,
            "nubia_score": 0.8205
        },
        "meteor": 0.3807194576550315,
        "bleurt": 0.0866
    },
    "schema_guided_dialog_test_contrast_challenge_acts-12": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 500,
        "msttr-100": 0.31537,
        "msttr-100_nopunct": 0.31611,
        "total_length": 4195,
        "mean_pred_length": 8.39,
        "std_pred_length": 1.7360587547660937,
        "median_pred_length": 8.0,
        "min_pred_length": 5,
        "max_pred_length": 21,
        "distinct-1": 0.01835518474374255,
        "vocab_size-1": 77,
        "unique-1": 16,
        "entropy-1": 4.829400295552769,
        "distinct-2": 0.05872801082543978,
        "vocab_size-2": 217,
        "unique-2": 72,
        "entropy-2": 6.2191420475623165,
        "cond_entropy-2": 1.1567512004074338,
        "distinct-3": 0.10579029733959311,
        "vocab_size-3": 338,
        "unique-3": 136,
        "entropy-3": 6.836855812295768,
        "cond_entropy-3": 0.6852489350601397,
        "total_length-nopunct": 3697,
        "mean_pred_length-nopunct": 7.394,
        "std_pred_length-nopunct": 1.7340023068035404,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.020286718961319988,
        "vocab_size-1-nopunct": 75,
        "unique-1-nopunct": 15,
        "entropy-1-nopunct": 4.880669171195832,
        "distinct-2-nopunct": 0.060369096027525805,
        "vocab_size-2-nopunct": 193,
        "unique-2-nopunct": 67,
        "entropy-2-nopunct": 5.943976057660226,
        "cond_entropy-2-nopunct": 1.2191458587364403,
        "distinct-3-nopunct": 0.10493140526510938,
        "vocab_size-3-nopunct": 283,
        "unique-3-nopunct": 119,
        "entropy-3-nopunct": 6.487224589429765,
        "cond_entropy-3-nopunct": 0.7477812039924635,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 3.7081794443500398,
        "rouge1": {
            "precision": 0.55673,
            "recall": 0.54132,
            "fmeasure": 0.53994
        },
        "rouge2": {
            "precision": 0.32225,
            "recall": 0.31496,
            "fmeasure": 0.3125
        },
        "rougeL": {
            "precision": 0.53432,
            "recall": 0.5201,
            "fmeasure": 0.51863
        },
        "rougeLsum": {
            "precision": 0.53432,
            "recall": 0.5201,
            "fmeasure": 0.51863
        },
        "bleu": 27.87453,
        "local_recall": {
            "1": 0.5242898858508097
        },
        "bertscore": {
            "precision": 0.89059,
            "recall": 0.8865,
            "f1": 0.88824
        },
        "nubia": {
            "semantic_relation": 3.7876,
            "contradiction": 2.59651,
            "irrelevancy": 27.19692,
            "logical_agreement": 70.20657,
            "grammar_ref": 4.43492,
            "grammar_hyp": 4.08251,
            "nubia_score": 0.73423
        },
        "meteor": 0.292222116900501,
        "bleurt": 0.09727
    },
    "schema_guided_dialog_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 2517,
        "msttr-100": 0.68511,
        "msttr-100_nopunct": 0.7044,
        "total_length": 37400,
        "mean_pred_length": 14.858959078267779,
        "std_pred_length": 4.2049656813960254,
        "median_pred_length": 14.0,
        "min_pred_length": 4,
        "max_pred_length": 31,
        "distinct-1": 0.06532085561497326,
        "vocab_size-1": 2443,
        "unique-1": 1147,
        "entropy-1": 8.042292078015002,
        "distinct-2": 0.22850672247226442,
        "vocab_size-2": 7971,
        "unique-2": 4593,
        "entropy-2": 11.20406811470582,
        "cond_entropy-2": 2.944896605593915,
        "distinct-3": 0.38728913056911574,
        "vocab_size-3": 12535,
        "unique-3": 8511,
        "entropy-3": 12.388481022065541,
        "cond_entropy-3": 1.2563920752847146,
        "total_length-nopunct": 33222,
        "mean_pred_length-nopunct": 13.199046483909417,
        "std_pred_length-nopunct": 3.807822788260288,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07308410089699596,
        "vocab_size-1-nopunct": 2428,
        "unique-1-nopunct": 1144,
        "entropy-1-nopunct": 8.218786250096185,
        "distinct-2-nopunct": 0.23794170330565054,
        "vocab_size-2-nopunct": 7306,
        "unique-2-nopunct": 4335,
        "entropy-2-nopunct": 11.038406854898298,
        "cond_entropy-2-nopunct": 3.00081596872757,
        "distinct-3-nopunct": 0.3992833829998581,
        "vocab_size-3-nopunct": 11255,
        "unique-3-nopunct": 7821,
        "entropy-3-nopunct": 12.214210696601247,
        "cond_entropy-3-nopunct": 1.279479807197142,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.053704295006503,
        "rouge1": {
            "precision": 0.64408,
            "recall": 0.63617,
            "fmeasure": 0.62913
        },
        "rouge2": {
            "precision": 0.41388,
            "recall": 0.4107,
            "fmeasure": 0.40493
        },
        "rougeL": {
            "precision": 0.56114,
            "recall": 0.55536,
            "fmeasure": 0.54883
        },
        "rougeLsum": {
            "precision": 0.56114,
            "recall": 0.55536,
            "fmeasure": 0.54883
        },
        "bleu": 34.97087,
        "local_recall": {
            "1": 0.6119253726678958
        },
        "bertscore": {
            "precision": 0.88873,
            "recall": 0.8844,
            "f1": 0.88613
        },
        "nubia": {
            "semantic_relation": 4.15709,
            "contradiction": 3.99061,
            "irrelevancy": 19.94346,
            "logical_agreement": 76.06593,
            "grammar_ref": 4.80017,
            "grammar_hyp": 4.56124,
            "nubia_score": 0.75286
        },
        "meteor": 0.34040515507127833,
        "bleurt": 0.02509
    },
    "schema_guided_dialog_test_contrast_challenge_acts-13": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 2078,
        "msttr-100": 0.48333,
        "msttr-100_nopunct": 0.50238,
        "total_length": 21604,
        "mean_pred_length": 10.396535129932628,
        "std_pred_length": 4.9828992961952245,
        "median_pred_length": 9.0,
        "min_pred_length": 2,
        "max_pred_length": 32,
        "distinct-1": 0.02106091464543603,
        "vocab_size-1": 455,
        "unique-1": 148,
        "entropy-1": 6.0744358417118836,
        "distinct-2": 0.09131414524224112,
        "vocab_size-2": 1783,
        "unique-2": 741,
        "entropy-2": 8.567398614405711,
        "cond_entropy-2": 2.2178228580721684,
        "distinct-3": 0.1856373223292068,
        "vocab_size-3": 3239,
        "unique-3": 1734,
        "entropy-3": 9.717608727210022,
        "cond_entropy-3": 1.2349430183385175,
        "total_length-nopunct": 18962,
        "mean_pred_length-nopunct": 9.12512030798845,
        "std_pred_length-nopunct": 4.554422737045871,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.023731673874063917,
        "vocab_size-1-nopunct": 450,
        "unique-1-nopunct": 147,
        "entropy-1-nopunct": 6.221989556384568,
        "distinct-2-nopunct": 0.09867330016583747,
        "vocab_size-2-nopunct": 1666,
        "unique-2-nopunct": 761,
        "entropy-2-nopunct": 8.296106195208013,
        "cond_entropy-2-nopunct": 2.285414811755561,
        "distinct-3-nopunct": 0.19386859342291848,
        "vocab_size-3-nopunct": 2871,
        "unique-3-nopunct": 1623,
        "entropy-3-nopunct": 9.432801328648646,
        "cond_entropy-3-nopunct": 1.2704253447770313,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 3.812410545676103,
        "rouge1": {
            "precision": 0.49449,
            "recall": 0.46802,
            "fmeasure": 0.46501
        },
        "rouge2": {
            "precision": 0.25028,
            "recall": 0.23965,
            "fmeasure": 0.23611
        },
        "rougeL": {
            "precision": 0.4539,
            "recall": 0.43102,
            "fmeasure": 0.42806
        },
        "rougeLsum": {
            "precision": 0.4539,
            "recall": 0.43102,
            "fmeasure": 0.42806
        },
        "bleu": 18.57128,
        "local_recall": {
            "1": 0.4527345164795364
        },
        "bertscore": {
            "precision": 0.85432,
            "recall": 0.84589,
            "f1": 0.84935
        },
        "nubia": {
            "semantic_relation": 3.34032,
            "contradiction": 7.66898,
            "irrelevancy": 26.53866,
            "logical_agreement": 65.79236,
            "grammar_ref": 4.54436,
            "grammar_hyp": 4.19801,
            "nubia_score": 0.59123
        },
        "meteor": 0.24388858254198295,
        "bleurt": -0.1837
    },
    "schema_guided_dialog_test_contrast_challenge_acts-15": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 715,
        "msttr-100": 0.22348,
        "msttr-100_nopunct": 0.21448,
        "total_length": 6697,
        "mean_pred_length": 9.366433566433566,
        "std_pred_length": 3.0675368596720594,
        "median_pred_length": 10.0,
        "min_pred_length": 3,
        "max_pred_length": 25,
        "distinct-1": 0.01224428848738241,
        "vocab_size-1": 82,
        "unique-1": 20,
        "entropy-1": 4.276974874480894,
        "distinct-2": 0.032932129722500834,
        "vocab_size-2": 197,
        "unique-2": 59,
        "entropy-2": 5.07441179291628,
        "cond_entropy-2": 0.6736367290934808,
        "distinct-3": 0.05126257831782798,
        "vocab_size-3": 270,
        "unique-3": 103,
        "entropy-3": 5.29300820248805,
        "cond_entropy-3": 0.21765601751289704,
        "total_length-nopunct": 5896,
        "mean_pred_length-nopunct": 8.246153846153845,
        "std_pred_length-nopunct": 2.708359739736925,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.013229308005427409,
        "vocab_size-1-nopunct": 78,
        "unique-1-nopunct": 19,
        "entropy-1-nopunct": 4.171400604192582,
        "distinct-2-nopunct": 0.03512835359969118,
        "vocab_size-2-nopunct": 182,
        "unique-2-nopunct": 63,
        "entropy-2-nopunct": 4.809403141780375,
        "cond_entropy-2-nopunct": 0.6005792141514165,
        "distinct-3-nopunct": 0.05463502015226153,
        "vocab_size-3-nopunct": 244,
        "unique-3-nopunct": 104,
        "entropy-3-nopunct": 5.006935700024557,
        "cond_entropy-3-nopunct": 0.16907329593667839,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 2.9636738808241794,
        "rouge1": {
            "precision": 0.53901,
            "recall": 0.57432,
            "fmeasure": 0.54363
        },
        "rouge2": {
            "precision": 0.29599,
            "recall": 0.31235,
            "fmeasure": 0.29561
        },
        "rougeL": {
            "precision": 0.46125,
            "recall": 0.48593,
            "fmeasure": 0.46249
        },
        "rougeLsum": {
            "precision": 0.46125,
            "recall": 0.48593,
            "fmeasure": 0.46249
        },
        "bleu": 26.73132,
        "local_recall": {
            "1": 0.564148573479275
        },
        "bertscore": {
            "precision": 0.8573,
            "recall": 0.86236,
            "f1": 0.85924
        },
        "nubia": {
            "semantic_relation": 3.64374,
            "contradiction": 1.49255,
            "irrelevancy": 22.82129,
            "logical_agreement": 75.68616,
            "grammar_ref": 4.09289,
            "grammar_hyp": 3.32619,
            "nubia_score": 0.75515
        },
        "meteor": 0.2928496465670476,
        "bleurt": 0.23172
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-0": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74333,
        "msttr-100_nopunct": 0.758,
        "total_length": 2141,
        "mean_pred_length": 20.19811320754717,
        "std_pred_length": 3.1635298273157035,
        "median_pred_length": 20.0,
        "min_pred_length": 13,
        "max_pred_length": 26,
        "distinct-1": 0.4297057449789818,
        "vocab_size-1": 920,
        "unique-1": 711,
        "entropy-1": 8.346824389430443,
        "distinct-2": 0.8540540540540541,
        "vocab_size-2": 1738,
        "unique-2": 1607,
        "entropy-2": 10.568557735505292,
        "cond_entropy-2": 2.0806045950334324,
        "distinct-3": 0.9725246241575947,
        "vocab_size-3": 1876,
        "unique-3": 1845,
        "entropy-3": 10.84354911313184,
        "cond_entropy-3": 0.2803927339893045,
        "total_length-nopunct": 2015,
        "mean_pred_length-nopunct": 19.00943396226415,
        "std_pred_length-nopunct": 3.1398091608239085,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 12,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4531017369727047,
        "vocab_size-1-nopunct": 913,
        "unique-1-nopunct": 709,
        "entropy-1-nopunct": 8.442690477478617,
        "distinct-2-nopunct": 0.8601361969617601,
        "vocab_size-2-nopunct": 1642,
        "unique-2-nopunct": 1524,
        "entropy-2-nopunct": 10.492241644448036,
        "cond_entropy-2-nopunct": 2.135255649017737,
        "distinct-3-nopunct": 0.978369384359401,
        "vocab_size-3-nopunct": 1764,
        "unique-3-nopunct": 1738,
        "entropy-3-nopunct": 10.764785437138174,
        "cond_entropy-3-nopunct": 0.2796483241635706,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 4.529400056229135,
        "rouge1": {
            "precision": 0.50229,
            "recall": 0.49528,
            "fmeasure": 0.4904
        },
        "rouge2": {
            "precision": 0.27048,
            "recall": 0.26587,
            "fmeasure": 0.26327
        },
        "rougeL": {
            "precision": 0.41707,
            "recall": 0.4116,
            "fmeasure": 0.40727
        },
        "rougeLsum": {
            "precision": 0.41707,
            "recall": 0.4116,
            "fmeasure": 0.40727
        },
        "bleu": 19.31287,
        "local_recall": {
            "1": 0.46274708565636086
        },
        "bertscore": {
            "precision": 0.85288,
            "recall": 0.85219,
            "f1": 0.85213
        },
        "nubia": {
            "semantic_relation": 3.37792,
            "contradiction": 11.82056,
            "irrelevancy": 69.68022,
            "logical_agreement": 18.49922,
            "grammar_ref": 3.74062,
            "grammar_hyp": 3.58043,
            "nubia_score": 0.56009
        },
        "meteor": 0.2329830717883643,
        "bleurt": -0.23984
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-1": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74095,
        "msttr-100_nopunct": 0.751,
        "total_length": 2190,
        "mean_pred_length": 20.660377358490567,
        "std_pred_length": 3.8507210607611206,
        "median_pred_length": 21.0,
        "min_pred_length": 10,
        "max_pred_length": 27,
        "distinct-1": 0.4269406392694064,
        "vocab_size-1": 935,
        "unique-1": 717,
        "entropy-1": 8.328221874652016,
        "distinct-2": 0.8421305182341651,
        "vocab_size-2": 1755,
        "unique-2": 1615,
        "entropy-2": 10.54883878792719,
        "cond_entropy-2": 2.1125734346503946,
        "distinct-3": 0.967644084934277,
        "vocab_size-3": 1914,
        "unique-3": 1865,
        "entropy-3": 10.87718233033833,
        "cond_entropy-3": 0.340731902314353,
        "total_length-nopunct": 2078,
        "mean_pred_length-nopunct": 19.60377358490566,
        "std_pred_length-nopunct": 3.8722019606688782,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.44706448508180946,
        "vocab_size-1-nopunct": 929,
        "unique-1-nopunct": 716,
        "entropy-1-nopunct": 8.400608076526266,
        "distinct-2-nopunct": 0.8453346855983773,
        "vocab_size-2-nopunct": 1667,
        "unique-2-nopunct": 1537,
        "entropy-2-nopunct": 10.475702386676977,
        "cond_entropy-2-nopunct": 2.175083494234543,
        "distinct-3-nopunct": 0.9715969989281886,
        "vocab_size-3-nopunct": 1813,
        "unique-3-nopunct": 1770,
        "entropy-3-nopunct": 10.804619069341536,
        "cond_entropy-3-nopunct": 0.3384034589430848,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.9993067121267494,
        "rouge1": {
            "precision": 0.48047,
            "recall": 0.44139,
            "fmeasure": 0.45342
        },
        "rouge2": {
            "precision": 0.23483,
            "recall": 0.21115,
            "fmeasure": 0.21871
        },
        "rougeL": {
            "precision": 0.38237,
            "recall": 0.35185,
            "fmeasure": 0.3611
        },
        "rougeLsum": {
            "precision": 0.38237,
            "recall": 0.35185,
            "fmeasure": 0.3611
        },
        "bleu": 14.19146,
        "local_recall": {
            "1": 0.4102321174798674
        },
        "bertscore": {
            "precision": 0.85185,
            "recall": 0.83825,
            "f1": 0.84469
        },
        "nubia": {
            "semantic_relation": 3.26373,
            "contradiction": 19.72601,
            "irrelevancy": 62.58669,
            "logical_agreement": 17.6873,
            "grammar_ref": 3.75111,
            "grammar_hyp": 3.73928,
            "nubia_score": 0.50987
        },
        "meteor": 0.20728051751829316,
        "bleurt": -0.21476
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-2": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.74571,
        "msttr-100_nopunct": 0.756,
        "total_length": 2196,
        "mean_pred_length": 20.71698113207547,
        "std_pred_length": 3.3045272461274573,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 29,
        "distinct-1": 0.43397085610200364,
        "vocab_size-1": 953,
        "unique-1": 738,
        "entropy-1": 8.359837155361733,
        "distinct-2": 0.8444976076555024,
        "vocab_size-2": 1765,
        "unique-2": 1626,
        "entropy-2": 10.562570357444919,
        "cond_entropy-2": 2.080137610054726,
        "distinct-3": 0.9672379032258065,
        "vocab_size-3": 1919,
        "unique-3": 1878,
        "entropy-3": 10.875159012025073,
        "cond_entropy-3": 0.31943026905380456,
        "total_length-nopunct": 2080,
        "mean_pred_length-nopunct": 19.62264150943396,
        "std_pred_length-nopunct": 3.349043316476432,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.45528846153846153,
        "vocab_size-1-nopunct": 947,
        "unique-1-nopunct": 735,
        "entropy-1-nopunct": 8.448016183199556,
        "distinct-2-nopunct": 0.8520770010131712,
        "vocab_size-2-nopunct": 1682,
        "unique-2-nopunct": 1555,
        "entropy-2-nopunct": 10.500347967510491,
        "cond_entropy-2-nopunct": 2.1431556267492886,
        "distinct-3-nopunct": 0.974304068522484,
        "vocab_size-3-nopunct": 1820,
        "unique-3-nopunct": 1785,
        "entropy-3-nopunct": 10.809388501226307,
        "cond_entropy-3-nopunct": 0.31536058485243035,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.8584702064863228,
        "rouge1": {
            "precision": 0.47472,
            "recall": 0.43042,
            "fmeasure": 0.44485
        },
        "rouge2": {
            "precision": 0.21654,
            "recall": 0.19207,
            "fmeasure": 0.20078
        },
        "rougeL": {
            "precision": 0.37833,
            "recall": 0.3406,
            "fmeasure": 0.35361
        },
        "rougeLsum": {
            "precision": 0.37833,
            "recall": 0.3406,
            "fmeasure": 0.35361
        },
        "bleu": 13.20163,
        "local_recall": {
            "1": 0.4059907834101382
        },
        "bertscore": {
            "precision": 0.85084,
            "recall": 0.83572,
            "f1": 0.84292
        },
        "nubia": {
            "semantic_relation": 3.17388,
            "contradiction": 23.67483,
            "irrelevancy": 58.33224,
            "logical_agreement": 17.99293,
            "grammar_ref": 3.66018,
            "grammar_hyp": 3.69152,
            "nubia_score": 0.47306
        },
        "meteor": 0.2022005613014515,
        "bleurt": -0.27563
    },
    "xsum_test_contrast_challenge_novelty_levels0To10-3": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 106,
        "msttr-100": 0.72857,
        "msttr-100_nopunct": 0.7375,
        "total_length": 2187,
        "mean_pred_length": 20.632075471698112,
        "std_pred_length": 3.4128654250348585,
        "median_pred_length": 21.0,
        "min_pred_length": 12,
        "max_pred_length": 28,
        "distinct-1": 0.3996342021033379,
        "vocab_size-1": 874,
        "unique-1": 652,
        "entropy-1": 8.211077712851024,
        "distinct-2": 0.817876021143681,
        "vocab_size-2": 1702,
        "unique-2": 1549,
        "entropy-2": 10.478425215617987,
        "cond_entropy-2": 2.147730264896992,
        "distinct-3": 0.949873417721519,
        "vocab_size-3": 1876,
        "unique-3": 1819,
        "entropy-3": 10.820531713406828,
        "cond_entropy-3": 0.34199867860087846,
        "total_length-nopunct": 2067,
        "mean_pred_length-nopunct": 19.5,
        "std_pred_length-nopunct": 3.396029868526561,
        "median_pred_length-nopunct": 19.5,
        "min_pred_length-nopunct": 11,
        "max_pred_length-nopunct": 27,
        "distinct-1-nopunct": 0.4189646831156265,
        "vocab_size-1-nopunct": 866,
        "unique-1-nopunct": 650,
        "entropy-1-nopunct": 8.279995652505555,
        "distinct-2-nopunct": 0.8266190719020907,
        "vocab_size-2-nopunct": 1621,
        "unique-2-nopunct": 1480,
        "entropy-2-nopunct": 10.417063296493591,
        "cond_entropy-2-nopunct": 2.219033651088645,
        "distinct-3-nopunct": 0.9590296495956874,
        "vocab_size-3-nopunct": 1779,
        "unique-3-nopunct": 1734,
        "entropy-3-nopunct": 10.755780848603948,
        "cond_entropy-3-nopunct": 0.34030455507143076,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 3.8919098654284303,
        "rouge1": {
            "precision": 0.47021,
            "recall": 0.42934,
            "fmeasure": 0.4424
        },
        "rouge2": {
            "precision": 0.21245,
            "recall": 0.19205,
            "fmeasure": 0.19866
        },
        "rougeL": {
            "precision": 0.3883,
            "recall": 0.35348,
            "fmeasure": 0.36472
        },
        "rougeLsum": {
            "precision": 0.3883,
            "recall": 0.35348,
            "fmeasure": 0.36472
        },
        "bleu": 13.2829,
        "local_recall": {
            "1": 0.4065573770491803
        },
        "bertscore": {
            "precision": 0.84201,
            "recall": 0.82907,
            "f1": 0.83518
        },
        "nubia": {
            "semantic_relation": 3.12568,
            "contradiction": 12.03239,
            "irrelevancy": 69.08431,
            "logical_agreement": 18.8833,
            "grammar_ref": 3.68583,
            "grammar_hyp": 3.52293,
            "nubia_score": 0.49624
        },
        "meteor": 0.19682468836784983,
        "bleurt": -0.29373
    },
    "mlsum_de_validation": {
        "predictions_file": "ByT5-xl (Baseline)/mlsum_de_validation",
        "N": 11392,
        "msttr-100": 0.75908,
        "msttr-100_nopunct": 0.78576,
        "total_length": 231621,
        "mean_pred_length": 20.331899578651687,
        "std_pred_length": 2.556800109297619,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 30,
        "distinct-1": 0.13560946546297614,
        "vocab_size-1": 31410,
        "unique-1": 19756,
        "entropy-1": 10.418298142429672,
        "distinct-2": 0.525194229642781,
        "vocab_size-2": 115663,
        "unique-2": 94201,
        "entropy-2": 15.381999134532913,
        "cond_entropy-2": 5.094256708227259,
        "distinct-3": 0.8164693038111063,
        "vocab_size-3": 170509,
        "unique-3": 155768,
        "entropy-3": 17.024792681141285,
        "cond_entropy-3": 1.7075419082781877,
        "total_length-nopunct": 212795,
        "mean_pred_length-nopunct": 18.679336376404493,
        "std_pred_length-nopunct": 2.2321706151433274,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 9,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.1475457600037595,
        "vocab_size-1-nopunct": 31397,
        "unique-1-nopunct": 19754,
        "entropy-1-nopunct": 10.751352568311141,
        "distinct-2-nopunct": 0.5753389969364905,
        "vocab_size-2-nopunct": 115875,
        "unique-2-nopunct": 95718,
        "entropy-2-nopunct": 15.736676536022278,
        "cond_entropy-2-nopunct": 5.134296046423353,
        "distinct-3-nopunct": 0.8567293472483172,
        "vocab_size-3-nopunct": 162788,
        "unique-3-nopunct": 151158,
        "entropy-3-nopunct": 17.06334551647576,
        "cond_entropy-3-nopunct": 1.3930483881546318,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_validation.json",
        "nist": 5.388865017960434,
        "rouge1": {
            "precision": 0.45929,
            "recall": 0.36249,
            "fmeasure": 0.39885
        },
        "rouge2": {
            "precision": 0.33416,
            "recall": 0.25109,
            "fmeasure": 0.28271
        },
        "rougeL": {
            "precision": 0.41727,
            "recall": 0.3268,
            "fmeasure": 0.36093
        },
        "rougeLsum": {
            "precision": 0.41727,
            "recall": 0.3268,
            "fmeasure": 0.36093
        },
        "bleu": 25.50343,
        "local_recall": {
            "1": 0.35942366350939153
        },
        "bertscore": {
            "precision": 0.89167,
            "recall": 0.87293,
            "f1": 0.88201
        },
        "nubia": {
            "semantic_relation": 2.39852,
            "contradiction": 24.58684,
            "irrelevancy": 42.78513,
            "logical_agreement": 32.62804,
            "grammar_ref": 5.04919,
            "grammar_hyp": 5.11942,
            "nubia_score": 0.28388
        },
        "meteor": 0.3088200399830636,
        "bleurt": -0.45914
    },
    "mlsum_de_test": {
        "predictions_file": "ByT5-xl (Baseline)/mlsum_de_test",
        "N": 10695,
        "msttr-100": 0.76101,
        "msttr-100_nopunct": 0.78846,
        "total_length": 217661,
        "mean_pred_length": 20.351659654043946,
        "std_pred_length": 2.6008666883807106,
        "median_pred_length": 20.0,
        "min_pred_length": 11,
        "max_pred_length": 32,
        "distinct-1": 0.1403420916011596,
        "vocab_size-1": 30547,
        "unique-1": 19197,
        "entropy-1": 10.428870439891588,
        "distinct-2": 0.536479421740769,
        "vocab_size-2": 111033,
        "unique-2": 90873,
        "entropy-2": 15.370911482604559,
        "cond_entropy-2": 5.071687048857356,
        "distinct-3": 0.8247117505897458,
        "vocab_size-3": 161867,
        "unique-3": 148467,
        "entropy-3": 16.96966935092677,
        "cond_entropy-3": 1.6611237851063292,
        "total_length-nopunct": 200083,
        "mean_pred_length-nopunct": 18.708087891538103,
        "std_pred_length-nopunct": 2.26934879121172,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 10,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.15260666823268343,
        "vocab_size-1-nopunct": 30534,
        "unique-1-nopunct": 19197,
        "entropy-1-nopunct": 10.75889800506221,
        "distinct-2-nopunct": 0.5866580775973135,
        "vocab_size-2-nopunct": 111106,
        "unique-2-nopunct": 92266,
        "entropy-2-nopunct": 15.714095771548072,
        "cond_entropy-2-nopunct": 5.099974511860331,
        "distinct-3-nopunct": 0.8636824050186633,
        "vocab_size-3-nopunct": 154334,
        "unique-3-nopunct": 143915,
        "entropy-3-nopunct": 16.99907512402185,
        "cond_entropy-3-nopunct": 1.3500377764880778,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_de_test.json",
        "nist": 5.500187043788391,
        "rouge1": {
            "precision": 0.47395,
            "recall": 0.37163,
            "fmeasure": 0.41034
        },
        "rouge2": {
            "precision": 0.35196,
            "recall": 0.26319,
            "fmeasure": 0.29715
        },
        "rougeL": {
            "precision": 0.43267,
            "recall": 0.33653,
            "fmeasure": 0.37308
        },
        "rougeLsum": {
            "precision": 0.43267,
            "recall": 0.33653,
            "fmeasure": 0.37308
        },
        "bleu": 26.5757,
        "local_recall": {
            "1": 0.3687318133108563
        },
        "bertscore": {
            "precision": 0.89382,
            "recall": 0.87404,
            "f1": 0.88363
        },
        "nubia": {
            "semantic_relation": 2.42072,
            "contradiction": 24.19045,
            "irrelevancy": 42.20265,
            "logical_agreement": 33.6069,
            "grammar_ref": 5.03454,
            "grammar_hyp": 5.12418,
            "nubia_score": 0.28832
        },
        "meteor": 0.3182552834574161,
        "bleurt": -0.45016
    },
    "mlsum_es_validation": {
        "predictions_file": "ByT5-xl (Baseline)/mlsum_es_validation",
        "N": 9977,
        "msttr-100": 0.56773,
        "msttr-100_nopunct": 0.61784,
        "total_length": 268784,
        "mean_pred_length": 26.940362834519394,
        "std_pred_length": 5.641946843624314,
        "median_pred_length": 27.0,
        "min_pred_length": 3,
        "max_pred_length": 104,
        "distinct-1": 0.07720697660575034,
        "vocab_size-1": 20752,
        "unique-1": 10923,
        "entropy-1": 9.02597179991162,
        "distinct-2": 0.300007341377938,
        "vocab_size-2": 77644,
        "unique-2": 53217,
        "entropy-2": 13.511215965110228,
        "cond_entropy-2": 4.60202398032934,
        "distinct-3": 0.5269903146726681,
        "vocab_size-3": 131131,
        "unique-3": 102918,
        "entropy-3": 15.680101958422474,
        "cond_entropy-3": 2.2506684680446307,
        "total_length-nopunct": 212898,
        "mean_pred_length-nopunct": 21.338879422672147,
        "std_pred_length-nopunct": 4.779085276093087,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 45,
        "distinct-1-nopunct": 0.09735178348317035,
        "vocab_size-1-nopunct": 20726,
        "unique-1-nopunct": 10923,
        "entropy-1-nopunct": 9.643964984769633,
        "distinct-2-nopunct": 0.38980194262791923,
        "vocab_size-2-nopunct": 79099,
        "unique-2-nopunct": 56725,
        "entropy-2-nopunct": 14.329323375255447,
        "cond_entropy-2-nopunct": 4.821908860696622,
        "distinct-3-nopunct": 0.6512580001554686,
        "vocab_size-3-nopunct": 125670,
        "unique-3-nopunct": 103479,
        "entropy-3-nopunct": 16.23173382169065,
        "cond_entropy-3-nopunct": 1.991466417591897,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_validation.json",
        "nist": 0.9192745492024452,
        "rouge1": {
            "precision": 0.16057,
            "recall": 0.16366,
            "fmeasure": 0.15754
        },
        "rouge2": {
            "precision": 0.0259,
            "recall": 0.02647,
            "fmeasure": 0.02539
        },
        "rougeL": {
            "precision": 0.12239,
            "recall": 0.12577,
            "fmeasure": 0.12046
        },
        "rougeLsum": {
            "precision": 0.12239,
            "recall": 0.12577,
            "fmeasure": 0.12046
        },
        "bleu": 1.1833,
        "local_recall": {
            "1": 0.14353761314096175
        },
        "bertscore": {
            "precision": 0.74514,
            "recall": 0.77913,
            "f1": 0.76099
        },
        "nubia": {
            "semantic_relation": 1.46505,
            "contradiction": 36.18627,
            "irrelevancy": 42.64927,
            "logical_agreement": 21.16447,
            "grammar_ref": 5.2776,
            "grammar_hyp": 4.45687,
            "nubia_score": 0.20354
        },
        "meteor": 0.0917986243165772,
        "bleurt": -0.8602
    },
    "wiki_auto_asset_turk_validation": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_auto_asset_turk_validation",
        "N": 20000,
        "msttr-100": 0.23637,
        "msttr-100_nopunct": 0.22462,
        "total_length": 347296,
        "mean_pred_length": 17.3648,
        "std_pred_length": 5.814062345726953,
        "median_pred_length": 17.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.023896042568874964,
        "vocab_size-1": 8299,
        "unique-1": 0,
        "entropy-1": 9.80917789705462,
        "distinct-2": 0.07289120551427454,
        "vocab_size-2": 23857,
        "unique-2": 0,
        "entropy-2": 13.873335345197548,
        "cond_entropy-2": 3.85091082039556,
        "distinct-3": 0.09303407789232532,
        "vocab_size-3": 28589,
        "unique-3": 0,
        "entropy-3": 14.659295734109902,
        "cond_entropy-3": 0.8178092830560271,
        "total_length-nopunct": 308308,
        "mean_pred_length-nopunct": 15.4154,
        "std_pred_length-nopunct": 5.23828625029217,
        "median_pred_length-nopunct": 15.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 28,
        "distinct-1-nopunct": 0.026859504132231406,
        "vocab_size-1-nopunct": 8281,
        "unique-1-nopunct": 0,
        "entropy-1-nopunct": 10.200129248305252,
        "distinct-2-nopunct": 0.07592227756427154,
        "vocab_size-2-nopunct": 21889,
        "unique-2-nopunct": 0,
        "entropy-2-nopunct": 13.848551724609463,
        "cond_entropy-2-nopunct": 3.834344123863218,
        "distinct-3-nopunct": 0.09484622150662671,
        "vocab_size-3-nopunct": 25448,
        "unique-3-nopunct": 0,
        "entropy-3-nopunct": 14.563944184403486,
        "cond_entropy-3-nopunct": 0.7641965999284129,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_auto_asset_turk_validation.json",
        "nist": 9.613349971492553,
        "rouge1": {
            "precision": 0.74493,
            "recall": 0.69926,
            "fmeasure": 0.70186
        },
        "rouge2": {
            "precision": 0.56424,
            "recall": 0.52345,
            "fmeasure": 0.52683
        },
        "rougeL": {
            "precision": 0.69993,
            "recall": 0.65634,
            "fmeasure": 0.65917
        },
        "rougeLsum": {
            "precision": 0.69993,
            "recall": 0.65634,
            "fmeasure": 0.65917
        },
        "bleu": 43.0989,
        "local_recall": {
            "1": 0.6697350042361377
        },
        "sari": 45.82342,
        "bertscore": {
            "precision": 0.92149,
            "recall": 0.91368,
            "f1": 0.91664
        },
        "nubia": {
            "semantic_relation": 4.21869,
            "contradiction": 2.77757,
            "irrelevancy": 24.65439,
            "logical_agreement": 72.56804,
            "grammar_ref": 4.53224,
            "grammar_hyp": 4.8221,
            "nubia_score": 0.68199
        },
        "meteor": 0.3661278597830652,
        "bleurt": 0.21993
    },
    "cs_restaurants_validation": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_validation",
        "N": 781,
        "msttr-100": 0.62756,
        "msttr-100_nopunct": 0.66582,
        "total_length": 7893,
        "mean_pred_length": 10.106274007682458,
        "std_pred_length": 4.344065853555701,
        "median_pred_length": 9.0,
        "min_pred_length": 4,
        "max_pred_length": 25,
        "distinct-1": 0.0601799062460408,
        "vocab_size-1": 475,
        "unique-1": 141,
        "entropy-1": 7.003863495764831,
        "distinct-2": 0.21048931383577052,
        "vocab_size-2": 1497,
        "unique-2": 656,
        "entropy-2": 9.40626670894059,
        "cond_entropy-2": 2.0762782973331007,
        "distinct-3": 0.3612383509714105,
        "vocab_size-3": 2287,
        "unique-3": 1299,
        "entropy-3": 10.281511834868482,
        "cond_entropy-3": 0.7808189731137332,
        "total_length-nopunct": 6751,
        "mean_pred_length-nopunct": 8.64404609475032,
        "std_pred_length-nopunct": 3.903943443515442,
        "median_pred_length-nopunct": 8.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.06976744186046512,
        "vocab_size-1-nopunct": 471,
        "unique-1-nopunct": 141,
        "entropy-1-nopunct": 7.246647382845006,
        "distinct-2-nopunct": 0.2304857621440536,
        "vocab_size-2-nopunct": 1376,
        "unique-2-nopunct": 639,
        "entropy-2-nopunct": 9.322493635241518,
        "cond_entropy-2-nopunct": 2.0800168344818273,
        "distinct-3-nopunct": 0.39236847176719986,
        "vocab_size-3-nopunct": 2036,
        "unique-3-nopunct": 1207,
        "entropy-3-nopunct": 10.178439159448757,
        "cond_entropy-3-nopunct": 0.7861247922686768,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_validation.json",
        "nist": 3.5929426955076846,
        "rouge1": {
            "precision": 0.46363,
            "recall": 0.45346,
            "fmeasure": 0.44686
        },
        "rouge2": {
            "precision": 0.27129,
            "recall": 0.26476,
            "fmeasure": 0.2608
        },
        "rougeL": {
            "precision": 0.41775,
            "recall": 0.40868,
            "fmeasure": 0.40283
        },
        "rougeLsum": {
            "precision": 0.41775,
            "recall": 0.40868,
            "fmeasure": 0.40283
        },
        "bleu": 15.14132,
        "local_recall": {
            "1": 0.4068047337278107
        },
        "bertscore": {
            "precision": 0.89247,
            "recall": 0.88758,
            "f1": 0.88979
        },
        "nubia": {
            "semantic_relation": 3.06263,
            "contradiction": 22.51976,
            "irrelevancy": 28.93485,
            "logical_agreement": 48.54539,
            "grammar_ref": 6.54085,
            "grammar_hyp": 6.54705,
            "nubia_score": 0.41305
        },
        "meteor": 0.21276244139888845,
        "bleurt": -0.22446
    },
    "cs_restaurants_test": {
        "predictions_file": "ByT5-xl (Baseline)/cs_restaurants_test",
        "N": 842,
        "msttr-100": 0.6019,
        "msttr-100_nopunct": 0.645,
        "total_length": 10099,
        "mean_pred_length": 11.994061757719715,
        "std_pred_length": 4.144791871028415,
        "median_pred_length": 13.0,
        "min_pred_length": 4,
        "max_pred_length": 25,
        "distinct-1": 0.0704030101990296,
        "vocab_size-1": 711,
        "unique-1": 249,
        "entropy-1": 7.024713875920519,
        "distinct-2": 0.21864534946526953,
        "vocab_size-2": 2024,
        "unique-2": 1082,
        "entropy-2": 9.096508284413598,
        "cond_entropy-2": 1.878581567636469,
        "distinct-3": 0.34652406417112297,
        "vocab_size-3": 2916,
        "unique-3": 1959,
        "entropy-3": 9.75272480637687,
        "cond_entropy-3": 0.7336492775266168,
        "total_length-nopunct": 8469,
        "mean_pred_length-nopunct": 10.058194774346793,
        "std_pred_length-nopunct": 3.5097672429707036,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 22,
        "distinct-1-nopunct": 0.08348093045223758,
        "vocab_size-1-nopunct": 707,
        "unique-1-nopunct": 249,
        "entropy-1-nopunct": 7.3194054275610725,
        "distinct-2-nopunct": 0.23443031336043005,
        "vocab_size-2-nopunct": 1788,
        "unique-2-nopunct": 993,
        "entropy-2-nopunct": 8.993930539427605,
        "cond_entropy-2-nopunct": 1.8550562144080283,
        "distinct-3-nopunct": 0.37302873986735446,
        "vocab_size-3-nopunct": 2531,
        "unique-3-nopunct": 1743,
        "entropy-3-nopunct": 9.670686392122871,
        "cond_entropy-3-nopunct": 0.797487803084717,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/cs_restaurants_test.json",
        "nist": 3.398558860960902,
        "rouge1": {
            "precision": 0.44294,
            "recall": 0.46794,
            "fmeasure": 0.44165
        },
        "rouge2": {
            "precision": 0.24289,
            "recall": 0.25455,
            "fmeasure": 0.24135
        },
        "rougeL": {
            "precision": 0.39443,
            "recall": 0.41606,
            "fmeasure": 0.3933
        },
        "rougeLsum": {
            "precision": 0.39443,
            "recall": 0.41606,
            "fmeasure": 0.3933
        },
        "bleu": 13.42765,
        "local_recall": {
            "1": 0.43793294541424216
        },
        "bertscore": {
            "precision": 0.88248,
            "recall": 0.89052,
            "f1": 0.8862
        },
        "nubia": {
            "semantic_relation": 2.98006,
            "contradiction": 26.74957,
            "irrelevancy": 32.20911,
            "logical_agreement": 41.04132,
            "grammar_ref": 6.8707,
            "grammar_hyp": 6.73254,
            "nubia_score": 0.42125
        },
        "meteor": 0.21873771127175248,
        "bleurt": -0.25264
    },
    "totto_validation": {
        "predictions_file": "ByT5-xl (Baseline)/totto_validation",
        "N": 7700,
        "msttr-100": 0.73018,
        "msttr-100_nopunct": 0.78029,
        "total_length": 121868,
        "mean_pred_length": 15.827012987012987,
        "std_pred_length": 5.361207235856991,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 38,
        "distinct-1": 0.17658450126366232,
        "vocab_size-1": 21520,
        "unique-1": 14821,
        "entropy-1": 10.105643050474104,
        "distinct-2": 0.5518446499894891,
        "vocab_size-2": 63003,
        "unique-2": 52859,
        "entropy-2": 14.59365910714687,
        "cond_entropy-2": 4.133145982857855,
        "distinct-3": 0.7763365518277793,
        "vocab_size-3": 82655,
        "unique-3": 75330,
        "entropy-3": 15.830414641680646,
        "cond_entropy-3": 1.23057392309029,
        "total_length-nopunct": 106628,
        "mean_pred_length-nopunct": 13.847792207792208,
        "std_pred_length-nopunct": 4.786447486522544,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.20162621450275725,
        "vocab_size-1-nopunct": 21499,
        "unique-1-nopunct": 14817,
        "entropy-1-nopunct": 10.638011466160275,
        "distinct-2-nopunct": 0.5934012615235322,
        "vocab_size-2-nopunct": 58704,
        "unique-2-nopunct": 50321,
        "entropy-2-nopunct": 14.578641003309395,
        "cond_entropy-2-nopunct": 4.128884888063958,
        "distinct-3-nopunct": 0.8017494628842022,
        "vocab_size-3-nopunct": 73142,
        "unique-3-nopunct": 67411,
        "entropy-3-nopunct": 15.717193821275702,
        "cond_entropy-3-nopunct": 1.2203280129300482,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_validation.json",
        "nist": 10.837973251962834,
        "rouge1": {
            "precision": 0.7657,
            "recall": 0.73074,
            "fmeasure": 0.73661
        },
        "rouge2": {
            "precision": 0.54695,
            "recall": 0.52411,
            "fmeasure": 0.52695
        },
        "rougeL": {
            "precision": 0.6707,
            "recall": 0.64442,
            "fmeasure": 0.64733
        },
        "rougeLsum": {
            "precision": 0.6707,
            "recall": 0.64442,
            "fmeasure": 0.64733
        },
        "bleu": 47.43039,
        "local_recall": {
            "1": 0.21959431715529276,
            "2": 0.45486305801164545,
            "3": 0.7655092911649354
        },
        "bertscore": {
            "precision": 0.93077,
            "recall": 0.92506,
            "f1": 0.92628
        },
        "nubia": {
            "semantic_relation": 4.16829,
            "contradiction": 8.12599,
            "irrelevancy": 29.84012,
            "logical_agreement": 62.0339,
            "grammar_ref": 4.66172,
            "grammar_hyp": 4.61771,
            "nubia_score": 0.7278
        },
        "meteor": 0.39356673685468424,
        "bleurt": 0.27817
    },
    "totto_test": {
        "predictions_file": "ByT5-xl (Baseline)/totto_test",
        "N": 7700,
        "msttr-100": 0.7303,
        "msttr-100_nopunct": 0.78031,
        "total_length": 121710,
        "mean_pred_length": 15.806493506493506,
        "std_pred_length": 5.3118304048564875,
        "median_pred_length": 15.0,
        "min_pred_length": 4,
        "max_pred_length": 36,
        "distinct-1": 0.17614000492975104,
        "vocab_size-1": 21438,
        "unique-1": 14868,
        "entropy-1": 10.090326350829834,
        "distinct-2": 0.5508815016226647,
        "vocab_size-2": 62806,
        "unique-2": 52712,
        "entropy-2": 14.582005687147845,
        "cond_entropy-2": 4.137966448436155,
        "distinct-3": 0.775684319443138,
        "vocab_size-3": 82463,
        "unique-3": 75103,
        "entropy-3": 15.828149293417383,
        "cond_entropy-3": 1.2412292892755243,
        "total_length-nopunct": 106638,
        "mean_pred_length-nopunct": 13.84909090909091,
        "std_pred_length-nopunct": 4.791288681085891,
        "median_pred_length-nopunct": 13.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.20085710534706203,
        "vocab_size-1-nopunct": 21419,
        "unique-1-nopunct": 14866,
        "entropy-1-nopunct": 10.61770186370789,
        "distinct-2-nopunct": 0.5922395843861813,
        "vocab_size-2-nopunct": 58595,
        "unique-2-nopunct": 50228,
        "entropy-2-nopunct": 14.56993684038362,
        "cond_entropy-2-nopunct": 4.142233868027235,
        "distinct-3-nopunct": 0.8009601262631798,
        "vocab_size-3-nopunct": 73078,
        "unique-3-nopunct": 67298,
        "entropy-3-nopunct": 15.71755285717256,
        "cond_entropy-3-nopunct": 1.2311880018291665,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/totto_test.json",
        "nist": 10.825567727804446,
        "rouge1": {
            "precision": 0.76482,
            "recall": 0.73201,
            "fmeasure": 0.73677
        },
        "rouge2": {
            "precision": 0.54553,
            "recall": 0.52355,
            "fmeasure": 0.52587
        },
        "rougeL": {
            "precision": 0.67002,
            "recall": 0.64528,
            "fmeasure": 0.64719
        },
        "rougeLsum": {
            "precision": 0.67002,
            "recall": 0.64528,
            "fmeasure": 0.64719
        },
        "bleu": 47.17786,
        "local_recall": {
            "1": 0.21565527585228425,
            "2": 0.45806171229900045,
            "3": 0.7673247431743401
        },
        "bertscore": {
            "precision": 0.93086,
            "recall": 0.92556,
            "f1": 0.92659
        },
        "nubia": {
            "semantic_relation": 4.16886,
            "contradiction": 8.52864,
            "irrelevancy": 29.6123,
            "logical_agreement": 61.85906,
            "grammar_ref": 4.66736,
            "grammar_hyp": 4.62289,
            "nubia_score": 0.72733
        },
        "meteor": 0.3937142238548399,
        "bleurt": 0.27927
    },
    "mlsum_es_test": {
        "predictions_file": "ByT5-xl (Baseline)/mlsum_es_test",
        "N": 13366,
        "msttr-100": 0.57376,
        "msttr-100_nopunct": 0.62454,
        "total_length": 361025,
        "mean_pred_length": 27.010698787969474,
        "std_pred_length": 5.72551269244077,
        "median_pred_length": 27.0,
        "min_pred_length": 3,
        "max_pred_length": 125,
        "distinct-1": 0.07012810747178173,
        "vocab_size-1": 25318,
        "unique-1": 13135,
        "entropy-1": 9.109081720864378,
        "distinct-2": 0.28612519739169706,
        "vocab_size-2": 99474,
        "unique-2": 68065,
        "entropy-2": 13.709544252479176,
        "cond_entropy-2": 4.7166532391110305,
        "distinct-3": 0.5135823962811067,
        "vocab_size-3": 171687,
        "unique-3": 134775,
        "entropy-3": 15.954806023479144,
        "cond_entropy-3": 2.3274209619981105,
        "total_length-nopunct": 286390,
        "mean_pred_length-nopunct": 21.426754451593595,
        "std_pred_length-nopunct": 4.848380430952208,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 124,
        "distinct-1-nopunct": 0.08830964768322916,
        "vocab_size-1-nopunct": 25291,
        "unique-1-nopunct": 13134,
        "entropy-1-nopunct": 9.744712533348634,
        "distinct-2-nopunct": 0.37309770167567075,
        "vocab_size-2-nopunct": 101865,
        "unique-2-nopunct": 72866,
        "entropy-2-nopunct": 14.568713683473211,
        "cond_entropy-2-nopunct": 4.961558310389651,
        "distinct-3-nopunct": 0.6390634627233518,
        "vocab_size-3-nopunct": 165952,
        "unique-3-nopunct": 136723,
        "entropy-3-nopunct": 16.563405365007114,
        "cond_entropy-3-nopunct": 2.085224092602711,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/mlsum_es_test.json",
        "nist": 0.9265575466818893,
        "rouge1": {
            "precision": 0.16344,
            "recall": 0.16577,
            "fmeasure": 0.15999
        },
        "rouge2": {
            "precision": 0.02654,
            "recall": 0.02666,
            "fmeasure": 0.02579
        },
        "rougeL": {
            "precision": 0.12408,
            "recall": 0.12702,
            "fmeasure": 0.12192
        },
        "rougeLsum": {
            "precision": 0.12408,
            "recall": 0.12702,
            "fmeasure": 0.12192
        },
        "bleu": 1.16386,
        "local_recall": {
            "1": 0.14453706572752212
        },
        "bertscore": {
            "precision": 0.74666,
            "recall": 0.78062,
            "f1": 0.76252
        },
        "nubia": {
            "semantic_relation": 1.4322,
            "contradiction": 36.41266,
            "irrelevancy": 42.70297,
            "logical_agreement": 20.88437,
            "grammar_ref": 5.26998,
            "grammar_hyp": 4.51864,
            "nubia_score": 0.19616
        },
        "meteor": 0.09250537210998609,
        "bleurt": -0.86452
    },
    "schema_guided_dialog_validation": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_validation",
        "N": 10000,
        "msttr-100": 0.69095,
        "msttr-100_nopunct": 0.71589,
        "total_length": 122073,
        "mean_pred_length": 12.2073,
        "std_pred_length": 6.676220990200968,
        "median_pred_length": 10.0,
        "min_pred_length": 2,
        "max_pred_length": 32,
        "distinct-1": 0.03393870880538694,
        "vocab_size-1": 4143,
        "unique-1": 1781,
        "entropy-1": 8.055955014268509,
        "distinct-2": 0.13138757773950907,
        "vocab_size-2": 14725,
        "unique-2": 7747,
        "entropy-2": 11.335360582201902,
        "cond_entropy-2": 3.0463266559233757,
        "distinct-3": 0.25796243864685076,
        "vocab_size-3": 26331,
        "unique-3": 16440,
        "entropy-3": 12.754652790481092,
        "cond_entropy-3": 1.4641227400190886,
        "total_length-nopunct": 107994,
        "mean_pred_length-nopunct": 10.7994,
        "std_pred_length-nopunct": 6.230101093882828,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.03821508602329759,
        "vocab_size-1-nopunct": 4127,
        "unique-1-nopunct": 1778,
        "entropy-1-nopunct": 8.254734381975886,
        "distinct-2-nopunct": 0.14126375084188827,
        "vocab_size-2-nopunct": 13843,
        "unique-2-nopunct": 7523,
        "entropy-2-nopunct": 11.212010760257614,
        "cond_entropy-2-nopunct": 3.116703214267107,
        "distinct-3-nopunct": 0.27415286016226903,
        "vocab_size-3-nopunct": 24126,
        "unique-3-nopunct": 15485,
        "entropy-3-nopunct": 12.640660254629442,
        "cond_entropy-3-nopunct": 1.483215958309638,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_validation.json",
        "nist": 7.435345716467556,
        "rouge1": {
            "precision": 0.62072,
            "recall": 0.61356,
            "fmeasure": 0.60392
        },
        "rouge2": {
            "precision": 0.40258,
            "recall": 0.40099,
            "fmeasure": 0.39258
        },
        "rougeL": {
            "precision": 0.56314,
            "recall": 0.55696,
            "fmeasure": 0.54816
        },
        "rougeLsum": {
            "precision": 0.56314,
            "recall": 0.55696,
            "fmeasure": 0.54816
        },
        "bleu": 35.2386,
        "local_recall": {
            "1": 0.6100342287372572
        },
        "bertscore": {
            "precision": 0.88419,
            "recall": 0.87979,
            "f1": 0.88142
        },
        "nubia": {
            "semantic_relation": 3.88135,
            "contradiction": 3.00812,
            "irrelevancy": 19.80932,
            "logical_agreement": 77.18256,
            "grammar_ref": 4.88727,
            "grammar_hyp": 4.59671,
            "nubia_score": 0.71946
        },
        "meteor": 0.3399775687916672,
        "bleurt": 0.04456
    },
    "schema_guided_dialog_test": {
        "predictions_file": "ByT5-xl (Baseline)/schema_guided_dialog_test",
        "N": 10000,
        "msttr-100": 0.68323,
        "msttr-100_nopunct": 0.70687,
        "total_length": 126266,
        "mean_pred_length": 12.6266,
        "std_pred_length": 6.702281137045805,
        "median_pred_length": 11.0,
        "min_pred_length": 2,
        "max_pred_length": 32,
        "distinct-1": 0.03308887586523688,
        "vocab_size-1": 4178,
        "unique-1": 1815,
        "entropy-1": 8.024469127446922,
        "distinct-2": 0.13388264840968125,
        "vocab_size-2": 15566,
        "unique-2": 8348,
        "entropy-2": 11.376824852803745,
        "cond_entropy-2": 3.119135537044578,
        "distinct-3": 0.2648165923249205,
        "vocab_size-3": 28141,
        "unique-3": 17864,
        "entropy-3": 12.834394093069912,
        "cond_entropy-3": 1.4948004170945504,
        "total_length-nopunct": 111840,
        "mean_pred_length-nopunct": 11.184,
        "std_pred_length-nopunct": 6.24606628206906,
        "median_pred_length-nopunct": 9.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.037204935622317595,
        "vocab_size-1-nopunct": 4161,
        "unique-1-nopunct": 1812,
        "entropy-1-nopunct": 8.212065711807458,
        "distinct-2-nopunct": 0.1449037706205813,
        "vocab_size-2-nopunct": 14757,
        "unique-2-nopunct": 8196,
        "entropy-2-nopunct": 11.259087597054382,
        "cond_entropy-2-nopunct": 3.19752489712509,
        "distinct-3-nopunct": 0.28345110678004853,
        "vocab_size-3-nopunct": 26033,
        "unique-3-nopunct": 17011,
        "entropy-3-nopunct": 12.72876317180949,
        "cond_entropy-3-nopunct": 1.5304220983170753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/schema_guided_dialog_test.json",
        "nist": 7.00524568675835,
        "rouge1": {
            "precision": 0.58711,
            "recall": 0.56711,
            "fmeasure": 0.5654
        },
        "rouge2": {
            "precision": 0.36711,
            "recall": 0.35645,
            "fmeasure": 0.35426
        },
        "rougeL": {
            "precision": 0.5295,
            "recall": 0.51155,
            "fmeasure": 0.51012
        },
        "rougeLsum": {
            "precision": 0.5295,
            "recall": 0.51155,
            "fmeasure": 0.51012
        },
        "bleu": 32.37656,
        "local_recall": {
            "1": 0.5737645187377252
        },
        "bertscore": {
            "precision": 0.8772,
            "recall": 0.87019,
            "f1": 0.87319
        },
        "nubia": {
            "semantic_relation": 3.73105,
            "contradiction": 4.65087,
            "irrelevancy": 21.8545,
            "logical_agreement": 73.49463,
            "grammar_ref": 4.76329,
            "grammar_hyp": 4.51351,
            "nubia_score": 0.6799
        },
        "meteor": 0.31899028971139853,
        "bleurt": -0.02396
    },
    "xsum_validation": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_validation",
        "N": 1117,
        "msttr-100": 0.73111,
        "msttr-100_nopunct": 0.74239,
        "total_length": 22655,
        "mean_pred_length": 20.282005371530886,
        "std_pred_length": 3.713336836823898,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.202162877951887,
        "vocab_size-1": 4580,
        "unique-1": 2754,
        "entropy-1": 9.166772944199561,
        "distinct-2": 0.6296313492431981,
        "vocab_size-2": 13561,
        "unique-2": 11310,
        "entropy-2": 12.908193602888733,
        "cond_entropy-2": 3.5939841994465307,
        "distinct-3": 0.8573527251358896,
        "vocab_size-3": 17508,
        "unique-3": 16280,
        "entropy-3": 13.86800999254865,
        "cond_entropy-3": 0.980604781506295,
        "total_length-nopunct": 21378,
        "mean_pred_length-nopunct": 19.13876454789615,
        "std_pred_length-nopunct": 3.748767806521532,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.21363083543830105,
        "vocab_size-1-nopunct": 4567,
        "unique-1-nopunct": 2751,
        "entropy-1-nopunct": 9.295009744806185,
        "distinct-2-nopunct": 0.636148265139924,
        "vocab_size-2-nopunct": 12889,
        "unique-2-nopunct": 10798,
        "entropy-2-nopunct": 12.846082640619056,
        "cond_entropy-2-nopunct": 3.6892694089500426,
        "distinct-3-nopunct": 0.8656498119515252,
        "vocab_size-3-nopunct": 16572,
        "unique-3-nopunct": 15446,
        "entropy-3-nopunct": 13.814605159158617,
        "cond_entropy-3-nopunct": 0.9969024988446167,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_validation.json",
        "nist": 4.114439142264775,
        "rouge1": {
            "precision": 0.43806,
            "recall": 0.39819,
            "fmeasure": 0.41004
        },
        "rouge2": {
            "precision": 0.18235,
            "recall": 0.16615,
            "fmeasure": 0.17086
        },
        "rougeL": {
            "precision": 0.34727,
            "recall": 0.31638,
            "fmeasure": 0.32539
        },
        "rougeLsum": {
            "precision": 0.34727,
            "recall": 0.31638,
            "fmeasure": 0.32539
        },
        "bleu": 11.53249,
        "local_recall": {
            "1": 0.3730122876761836
        },
        "bertscore": {
            "precision": 0.84044,
            "recall": 0.82791,
            "f1": 0.83381
        },
        "nubia": {
            "semantic_relation": 3.04936,
            "contradiction": 17.04059,
            "irrelevancy": 64.87029,
            "logical_agreement": 18.08912,
            "grammar_ref": 3.8151,
            "grammar_hyp": 3.67487,
            "nubia_score": 0.46547
        },
        "meteor": 0.18015915248572806,
        "bleurt": -0.30102
    },
    "xsum_test": {
        "predictions_file": "ByT5-xl (Baseline)/xsum_test",
        "N": 1166,
        "msttr-100": 0.73326,
        "msttr-100_nopunct": 0.74561,
        "total_length": 23611,
        "mean_pred_length": 20.249571183533448,
        "std_pred_length": 3.626467265079442,
        "median_pred_length": 21.0,
        "min_pred_length": 8,
        "max_pred_length": 29,
        "distinct-1": 0.200923298462581,
        "vocab_size-1": 4744,
        "unique-1": 2843,
        "entropy-1": 9.199168163764687,
        "distinct-2": 0.6235241701938071,
        "vocab_size-2": 13995,
        "unique-2": 11648,
        "entropy-2": 12.931205507885903,
        "cond_entropy-2": 3.576888928366422,
        "distinct-3": 0.8513088021053621,
        "vocab_size-3": 18115,
        "unique-3": 16770,
        "entropy-3": 13.91467504516915,
        "cond_entropy-3": 1.0016507742301095,
        "total_length-nopunct": 22310,
        "mean_pred_length-nopunct": 19.133790737564322,
        "std_pred_length-nopunct": 3.6522425082014363,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 7,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.21214701927386823,
        "vocab_size-1-nopunct": 4733,
        "unique-1-nopunct": 2841,
        "entropy-1-nopunct": 9.331218595832242,
        "distinct-2-nopunct": 0.6296348846008324,
        "vocab_size-2-nopunct": 13313,
        "unique-2-nopunct": 11133,
        "entropy-2-nopunct": 12.869708227149957,
        "cond_entropy-2-nopunct": 3.6752519335582456,
        "distinct-3-nopunct": 0.859545500050055,
        "vocab_size-3-nopunct": 17172,
        "unique-3-nopunct": 15949,
        "entropy-3-nopunct": 13.861094675089108,
        "cond_entropy-3-nopunct": 1.0173812062041931,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/xsum_test.json",
        "nist": 4.0874768743851515,
        "rouge1": {
            "precision": 0.4428,
            "recall": 0.40081,
            "fmeasure": 0.4132
        },
        "rouge2": {
            "precision": 0.18319,
            "recall": 0.16442,
            "fmeasure": 0.17013
        },
        "rougeL": {
            "precision": 0.34865,
            "recall": 0.31577,
            "fmeasure": 0.32535
        },
        "rougeLsum": {
            "precision": 0.34865,
            "recall": 0.31577,
            "fmeasure": 0.32535
        },
        "bleu": 10.97988,
        "local_recall": {
            "1": 0.37008579843770006
        },
        "bertscore": {
            "precision": 0.83901,
            "recall": 0.82581,
            "f1": 0.83201
        },
        "nubia": {
            "semantic_relation": 3.01653,
            "contradiction": 19.48731,
            "irrelevancy": 64.39147,
            "logical_agreement": 16.12122,
            "grammar_ref": 3.76542,
            "grammar_hyp": 3.64077,
            "nubia_score": 0.45378
        },
        "meteor": 0.17872873656811084,
        "bleurt": -0.31316
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_4": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.35303,
        "msttr-100_nopunct": 0.59562,
        "total_length": 3328,
        "mean_pred_length": 15.551401869158878,
        "std_pred_length": 5.702489446305899,
        "median_pred_length": 14.0,
        "min_pred_length": 6,
        "max_pred_length": 35,
        "distinct-1": 0.19681490384615385,
        "vocab_size-1": 655,
        "unique-1": 338,
        "entropy-1": 6.0896244965723385,
        "distinct-2": 0.4210019267822736,
        "vocab_size-2": 1311,
        "unique-2": 700,
        "entropy-2": 9.6710865711655,
        "cond_entropy-2": 3.708266496168319,
        "distinct-3": 0.5696551724137932,
        "vocab_size-3": 1652,
        "unique-3": 1089,
        "entropy-3": 10.228686900555788,
        "cond_entropy-3": 0.599865015596687,
        "total_length-nopunct": 1685,
        "mean_pred_length-nopunct": 7.873831775700935,
        "std_pred_length-nopunct": 3.182599785122429,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.3833827893175074,
        "vocab_size-1-nopunct": 646,
        "unique-1-nopunct": 337,
        "entropy-1-nopunct": 8.587899034447814,
        "distinct-2-nopunct": 0.7015635622025833,
        "vocab_size-2-nopunct": 1032,
        "unique-2-nopunct": 758,
        "entropy-2-nopunct": 9.803049153695198,
        "cond_entropy-2-nopunct": 1.2900338033629637,
        "distinct-3-nopunct": 0.807478122513922,
        "vocab_size-3-nopunct": 1015,
        "unique-3-nopunct": 836,
        "entropy-3-nopunct": 9.86817966425202,
        "cond_entropy-3-nopunct": 0.11177873855476204,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.3565830617842031,
        "rouge1": {
            "precision": 0.04956,
            "recall": 0.17783,
            "fmeasure": 0.07057
        },
        "rouge2": {
            "precision": 0.01519,
            "recall": 0.04224,
            "fmeasure": 0.01983
        },
        "rougeL": {
            "precision": 0.04651,
            "recall": 0.16753,
            "fmeasure": 0.06612
        },
        "rougeLsum": {
            "precision": 0.04651,
            "recall": 0.16753,
            "fmeasure": 0.06612
        },
        "bleu": 0.26321,
        "local_recall": {
            "1": 0.00281214848143982,
            "2": 0.008296460176991151,
            "3": 0.014652014652014652
        },
        "bertscore": {
            "precision": 0.59922,
            "recall": 0.53047,
            "f1": 0.56181
        },
        "nubia": {
            "semantic_relation": 2.63165,
            "contradiction": 31.79997,
            "irrelevancy": 33.29163,
            "logical_agreement": 34.9084,
            "grammar_ref": 2.5317,
            "grammar_hyp": 4.15346,
            "nubia_score": 0.2915
        },
        "meteor": 0.018755929752375274,
        "bleurt": -1.26724
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_3": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 214,
        "msttr-100": 0.35607,
        "msttr-100_nopunct": 0.605,
        "total_length": 2897,
        "mean_pred_length": 13.537383177570094,
        "std_pred_length": 7.000400834511489,
        "median_pred_length": 13.0,
        "min_pred_length": 1,
        "max_pred_length": 60,
        "distinct-1": 0.19502934069727304,
        "vocab_size-1": 565,
        "unique-1": 270,
        "entropy-1": 6.002045792618039,
        "distinct-2": 0.4140887066716362,
        "vocab_size-2": 1111,
        "unique-2": 584,
        "entropy-2": 9.481322167343047,
        "cond_entropy-2": 3.690502154494621,
        "distinct-3": 0.5376518218623482,
        "vocab_size-3": 1328,
        "unique-3": 831,
        "entropy-3": 9.906020879156404,
        "cond_entropy-3": 0.49501775107890866,
        "total_length-nopunct": 1450,
        "mean_pred_length-nopunct": 6.775700934579439,
        "std_pred_length-nopunct": 3.5475630999240946,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 19,
        "distinct-1-nopunct": 0.38413793103448274,
        "vocab_size-1-nopunct": 557,
        "unique-1-nopunct": 269,
        "entropy-1-nopunct": 8.50351549649891,
        "distinct-2-nopunct": 0.6601941747572816,
        "vocab_size-2-nopunct": 816,
        "unique-2-nopunct": 574,
        "entropy-2-nopunct": 9.436107646646231,
        "cond_entropy-2-nopunct": 1.05805672940005,
        "distinct-3-nopunct": 0.7390029325513197,
        "vocab_size-3-nopunct": 756,
        "unique-3-nopunct": 575,
        "entropy-3-nopunct": 9.389514000651841,
        "cond_entropy-3-nopunct": 0.03339889819423759,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.30964092850438146,
        "rouge1": {
            "precision": 0.04666,
            "recall": 0.17081,
            "fmeasure": 0.06686
        },
        "rouge2": {
            "precision": 0.00996,
            "recall": 0.03375,
            "fmeasure": 0.01381
        },
        "rougeL": {
            "precision": 0.0444,
            "recall": 0.16464,
            "fmeasure": 0.06364
        },
        "rougeLsum": {
            "precision": 0.0444,
            "recall": 0.16464,
            "fmeasure": 0.06364
        },
        "bleu": 0.21401,
        "local_recall": {
            "1": 0.002216475803472479,
            "2": 0.0037907505686125853,
            "3": 0.01678445229681979,
            "4": 0.045454545454545456
        },
        "bertscore": {
            "precision": 0.59783,
            "recall": 0.53605,
            "f1": 0.5641
        },
        "nubia": {
            "semantic_relation": 2.37161,
            "contradiction": 31.18644,
            "irrelevancy": 34.31606,
            "logical_agreement": 34.49751,
            "grammar_ref": 2.61878,
            "grammar_hyp": 4.68565,
            "nubia_score": 0.27653
        },
        "meteor": 0.01754396555159955,
        "bleurt": -1.29242
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_2": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 200,
        "msttr-100": 0.36905,
        "msttr-100_nopunct": 0.59636,
        "total_length": 2132,
        "mean_pred_length": 10.66,
        "std_pred_length": 7.370508801975614,
        "median_pred_length": 8.0,
        "min_pred_length": 2,
        "max_pred_length": 36,
        "distinct-1": 0.22420262664165103,
        "vocab_size-1": 478,
        "unique-1": 252,
        "entropy-1": 5.950376211466254,
        "distinct-2": 0.45445134575569357,
        "vocab_size-2": 878,
        "unique-2": 494,
        "entropy-2": 9.18587642781386,
        "cond_entropy-2": 3.4347733657044515,
        "distinct-3": 0.5762124711316398,
        "vocab_size-3": 998,
        "unique-3": 639,
        "entropy-3": 9.590045245743656,
        "cond_entropy-3": 0.4896162448002576,
        "total_length-nopunct": 1101,
        "mean_pred_length-nopunct": 5.505,
        "std_pred_length-nopunct": 4.106089989272032,
        "median_pred_length-nopunct": 4.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.4268846503178928,
        "vocab_size-1-nopunct": 470,
        "unique-1-nopunct": 250,
        "entropy-1-nopunct": 8.1893428934659,
        "distinct-2-nopunct": 0.681465038845727,
        "vocab_size-2-nopunct": 614,
        "unique-2-nopunct": 437,
        "entropy-2-nopunct": 9.027290190625456,
        "cond_entropy-2-nopunct": 0.9674947754422561,
        "distinct-3-nopunct": 0.7443820224719101,
        "vocab_size-3-nopunct": 530,
        "unique-3-nopunct": 405,
        "entropy-3-nopunct": 8.874899302746908,
        "cond_entropy-3-nopunct": -0.03422970072892689,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.46459573256048947,
        "rouge1": {
            "precision": 0.05854,
            "recall": 0.2146,
            "fmeasure": 0.08488
        },
        "rouge2": {
            "precision": 0.01747,
            "recall": 0.0673,
            "fmeasure": 0.02513
        },
        "rougeL": {
            "precision": 0.05621,
            "recall": 0.20871,
            "fmeasure": 0.08173
        },
        "rougeLsum": {
            "precision": 0.05621,
            "recall": 0.20871,
            "fmeasure": 0.08173
        },
        "bleu": 0.55721,
        "local_recall": {
            "1": 0.004887585532746823,
            "2": 0.014112903225806451,
            "3": 0.018205461638491547,
            "4": 0.2,
            "5": 0.0,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.60601,
            "recall": 0.53565,
            "f1": 0.56749
        },
        "nubia": {
            "semantic_relation": 2.12581,
            "contradiction": 35.20808,
            "irrelevancy": 37.5384,
            "logical_agreement": 27.25352,
            "grammar_ref": 2.7039,
            "grammar_hyp": 5.46483,
            "nubia_score": 0.20889
        },
        "meteor": 0.027553213711377793,
        "bleurt": -1.32455
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_6": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 32,
        "msttr-100": 0.33167,
        "msttr-100_nopunct": 0.49333,
        "total_length": 615,
        "mean_pred_length": 19.21875,
        "std_pred_length": 6.112151702755749,
        "median_pred_length": 20.5,
        "min_pred_length": 8,
        "max_pred_length": 28,
        "distinct-1": 0.21300813008130082,
        "vocab_size-1": 131,
        "unique-1": 67,
        "entropy-1": 4.948555442592293,
        "distinct-2": 0.39622641509433965,
        "vocab_size-2": 231,
        "unique-2": 121,
        "entropy-2": 7.147198485327191,
        "cond_entropy-2": 2.2993793562788007,
        "distinct-3": 0.5245009074410163,
        "vocab_size-3": 289,
        "unique-3": 177,
        "entropy-3": 7.719170343643224,
        "cond_entropy-3": 0.636833865929588,
        "total_length-nopunct": 344,
        "mean_pred_length-nopunct": 10.75,
        "std_pred_length-nopunct": 4.085033659592048,
        "median_pred_length-nopunct": 11.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 18,
        "distinct-1-nopunct": 0.36627906976744184,
        "vocab_size-1-nopunct": 126,
        "unique-1-nopunct": 65,
        "entropy-1-nopunct": 6.171468428760614,
        "distinct-2-nopunct": 0.6089743589743589,
        "vocab_size-2-nopunct": 190,
        "unique-2-nopunct": 127,
        "entropy-2-nopunct": 7.252769158429186,
        "cond_entropy-2-nopunct": 1.1972602571508697,
        "distinct-3-nopunct": 0.7285714285714285,
        "vocab_size-3-nopunct": 204,
        "unique-3-nopunct": 150,
        "entropy-3-nopunct": 7.518808184777518,
        "cond_entropy-3-nopunct": 0.3141661307785803,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.2665267773030779,
        "rouge1": {
            "precision": 0.03312,
            "recall": 0.16465,
            "fmeasure": 0.05419
        },
        "rouge2": {
            "precision": 0.00195,
            "recall": 0.00781,
            "fmeasure": 0.00312
        },
        "rougeL": {
            "precision": 0.03312,
            "recall": 0.16465,
            "fmeasure": 0.05419
        },
        "rougeLsum": {
            "precision": 0.03312,
            "recall": 0.16465,
            "fmeasure": 0.05419
        },
        "bleu": 0.13196,
        "local_recall": {
            "1": 0.015517241379310345,
            "2": 0.015659955257270694,
            "3": 0.02875399361022364
        },
        "bertscore": {
            "precision": 0.58264,
            "recall": 0.50765,
            "f1": 0.54179
        },
        "nubia": {
            "semantic_relation": 2.59136,
            "contradiction": 28.41112,
            "irrelevancy": 35.78374,
            "logical_agreement": 35.80514,
            "grammar_ref": 2.45871,
            "grammar_hyp": 3.63846,
            "nubia_score": 0.31877
        },
        "meteor": 0.012444082960553072,
        "bleurt": -1.27128
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_1": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 254,
        "msttr-100": 0.33941,
        "msttr-100_nopunct": 0.53889,
        "total_length": 1720,
        "mean_pred_length": 6.771653543307087,
        "std_pred_length": 8.38229196136934,
        "median_pred_length": 3.0,
        "min_pred_length": 0,
        "max_pred_length": 54,
        "distinct-1": 0.2424418604651163,
        "vocab_size-1": 417,
        "unique-1": 272,
        "entropy-1": 5.457242952578023,
        "distinct-2": 0.42603953646898435,
        "vocab_size-2": 625,
        "unique-2": 402,
        "entropy-2": 8.281454317397069,
        "cond_entropy-2": 3.1798312512023807,
        "distinct-3": 0.4555102040816327,
        "vocab_size-3": 558,
        "unique-3": 363,
        "entropy-3": 8.298511306405175,
        "cond_entropy-3": 0.25904182907679896,
        "total_length-nopunct": 949,
        "mean_pred_length-nopunct": 3.736220472440945,
        "std_pred_length-nopunct": 4.746870818293367,
        "median_pred_length-nopunct": 2.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.42781875658587987,
        "vocab_size-1-nopunct": 406,
        "unique-1-nopunct": 267,
        "entropy-1-nopunct": 7.4953605093022935,
        "distinct-2-nopunct": 0.49928469241773965,
        "vocab_size-2-nopunct": 349,
        "unique-2-nopunct": 237,
        "entropy-2-nopunct": 7.674323973798547,
        "cond_entropy-2-nopunct": 0.51009614984587,
        "distinct-3-nopunct": 0.5180505415162455,
        "vocab_size-3-nopunct": 287,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 7.590805701876698,
        "cond_entropy-3-nopunct": 0.21560607840908305,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.5947348256524323,
        "rouge1": {
            "precision": 0.11597,
            "recall": 0.23171,
            "fmeasure": 0.13257
        },
        "rouge2": {
            "precision": 0.05078,
            "recall": 0.10154,
            "fmeasure": 0.055
        },
        "rougeL": {
            "precision": 0.11558,
            "recall": 0.23122,
            "fmeasure": 0.13213
        },
        "rougeLsum": {
            "precision": 0.11558,
            "recall": 0.23122,
            "fmeasure": 0.13213
        },
        "bleu": 0.63305,
        "local_recall": {
            "1": 0.01970108695652174,
            "2": 0.02912621359223301,
            "3": 0.030716723549488054,
            "4": 0.08571428571428572,
            "5": 0.09090909090909091,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.60809,
            "recall": 0.51953,
            "f1": 0.55789
        },
        "nubia": {
            "semantic_relation": 1.86186,
            "contradiction": 41.09443,
            "irrelevancy": 32.49871,
            "logical_agreement": 26.40686,
            "grammar_ref": 2.90382,
            "grammar_hyp": 6.60452,
            "nubia_score": 0.13394
        },
        "meteor": 0.03315023989333695,
        "bleurt": -1.34868
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_5": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 159,
        "msttr-100": 0.33115,
        "msttr-100_nopunct": 0.55462,
        "total_length": 2633,
        "mean_pred_length": 16.559748427672957,
        "std_pred_length": 5.109605204467014,
        "median_pred_length": 15.0,
        "min_pred_length": 6,
        "max_pred_length": 34,
        "distinct-1": 0.1887580706418534,
        "vocab_size-1": 497,
        "unique-1": 260,
        "entropy-1": 5.793795281069326,
        "distinct-2": 0.3973322554567502,
        "vocab_size-2": 983,
        "unique-2": 526,
        "entropy-2": 9.238035198473316,
        "cond_entropy-2": 3.554953088102859,
        "distinct-3": 0.5438444924406047,
        "vocab_size-3": 1259,
        "unique-3": 808,
        "entropy-3": 9.81566908169712,
        "cond_entropy-3": 0.6266491897159774,
        "total_length-nopunct": 1331,
        "mean_pred_length-nopunct": 8.371069182389936,
        "std_pred_length-nopunct": 2.989611907922778,
        "median_pred_length-nopunct": 7.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 21,
        "distinct-1-nopunct": 0.36589030803906836,
        "vocab_size-1-nopunct": 487,
        "unique-1-nopunct": 259,
        "entropy-1-nopunct": 8.133762567022162,
        "distinct-2-nopunct": 0.6783276450511946,
        "vocab_size-2-nopunct": 795,
        "unique-2-nopunct": 565,
        "entropy-2-nopunct": 9.394414586397895,
        "cond_entropy-2-nopunct": 1.3497824902104065,
        "distinct-3-nopunct": 0.7897334649555775,
        "vocab_size-3-nopunct": 800,
        "unique-3-nopunct": 641,
        "entropy-3-nopunct": 9.50616105221339,
        "cond_entropy-3-nopunct": 0.14404465765778232,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.2962842668274996,
        "rouge1": {
            "precision": 0.04524,
            "recall": 0.15854,
            "fmeasure": 0.06413
        },
        "rouge2": {
            "precision": 0.0121,
            "recall": 0.05363,
            "fmeasure": 0.01821
        },
        "rougeL": {
            "precision": 0.04015,
            "recall": 0.14596,
            "fmeasure": 0.05743
        },
        "rougeLsum": {
            "precision": 0.04015,
            "recall": 0.14596,
            "fmeasure": 0.05743
        },
        "bleu": 0.43035,
        "local_recall": {
            "1": 0.001299545159194282,
            "2": 0.010932475884244373,
            "3": 0.016579406631762654
        },
        "bertscore": {
            "precision": 0.59239,
            "recall": 0.51924,
            "f1": 0.55216
        },
        "nubia": {
            "semantic_relation": 2.61782,
            "contradiction": 32.23181,
            "irrelevancy": 31.559,
            "logical_agreement": 36.2092,
            "grammar_ref": 2.45758,
            "grammar_hyp": 3.99977,
            "nubia_score": 0.28177
        },
        "meteor": 0.017934355641039876,
        "bleurt": -1.25996
    },
    "web_nlg_ru_test_contrast_challenge_input_size-input_length_7": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 29,
        "msttr-100": 0.31833,
        "msttr-100_nopunct": 0.46,
        "total_length": 614,
        "mean_pred_length": 21.17241379310345,
        "std_pred_length": 5.458741584911694,
        "median_pred_length": 23.0,
        "min_pred_length": 10,
        "max_pred_length": 32,
        "distinct-1": 0.1970684039087948,
        "vocab_size-1": 121,
        "unique-1": 56,
        "entropy-1": 4.8769292506382484,
        "distinct-2": 0.37606837606837606,
        "vocab_size-2": 220,
        "unique-2": 111,
        "entropy-2": 7.082070396001085,
        "cond_entropy-2": 2.2363230283208453,
        "distinct-3": 0.5143884892086331,
        "vocab_size-3": 286,
        "unique-3": 178,
        "entropy-3": 7.649587622134965,
        "cond_entropy-3": 0.6121260473788647,
        "total_length-nopunct": 334,
        "mean_pred_length-nopunct": 11.517241379310345,
        "std_pred_length-nopunct": 3.6541963563417803,
        "median_pred_length-nopunct": 12.0,
        "min_pred_length-nopunct": 5,
        "max_pred_length-nopunct": 20,
        "distinct-1-nopunct": 0.3413173652694611,
        "vocab_size-1-nopunct": 114,
        "unique-1-nopunct": 56,
        "entropy-1-nopunct": 6.034602300130225,
        "distinct-2-nopunct": 0.6,
        "vocab_size-2-nopunct": 183,
        "unique-2-nopunct": 122,
        "entropy-2-nopunct": 7.136956581816851,
        "cond_entropy-2-nopunct": 1.1855996339984067,
        "distinct-3-nopunct": 0.7246376811594203,
        "vocab_size-3-nopunct": 200,
        "unique-3-nopunct": 158,
        "entropy-3-nopunct": 7.384058866142117,
        "cond_entropy-3-nopunct": 0.29610175377872827,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.28381926852159384,
        "rouge1": {
            "precision": 0.03966,
            "recall": 0.15322,
            "fmeasure": 0.06008
        },
        "rouge2": {
            "precision": 0.00949,
            "recall": 0.02203,
            "fmeasure": 0.01326
        },
        "rougeL": {
            "precision": 0.03548,
            "recall": 0.1409,
            "fmeasure": 0.05383
        },
        "rougeLsum": {
            "precision": 0.03548,
            "recall": 0.1409,
            "fmeasure": 0.05383
        },
        "bleu": 0.72526,
        "local_recall": {
            "1": 0.0034965034965034965,
            "2": 0.018823529411764704,
            "3": 0.03225806451612903
        },
        "bertscore": {
            "precision": 0.59492,
            "recall": 0.51082,
            "f1": 0.54907
        },
        "nubia": {
            "semantic_relation": 2.60081,
            "contradiction": 30.60544,
            "irrelevancy": 33.33681,
            "logical_agreement": 36.05776,
            "grammar_ref": 2.50557,
            "grammar_hyp": 3.62732,
            "nubia_score": 0.35261
        },
        "meteor": 0.019902666833512436,
        "bleurt": -1.25952
    },
    "web_nlg_ru_test_contrast_challenge_single_predicates-seen": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 253,
        "msttr-100": 0.33824,
        "msttr-100_nopunct": 0.53889,
        "total_length": 1716,
        "mean_pred_length": 6.782608695652174,
        "std_pred_length": 8.397026454272869,
        "median_pred_length": 3.0,
        "min_pred_length": 0,
        "max_pred_length": 54,
        "distinct-1": 0.24242424242424243,
        "vocab_size-1": 416,
        "unique-1": 271,
        "entropy-1": 5.45582147519354,
        "distinct-2": 0.4255464480874317,
        "vocab_size-2": 623,
        "unique-2": 400,
        "entropy-2": 8.275798329917079,
        "cond_entropy-2": 3.1736068592298436,
        "distinct-3": 0.45461978740801307,
        "vocab_size-3": 556,
        "unique-3": 361,
        "entropy-3": 8.292948638511877,
        "cond_entropy-3": 0.2595301419869002,
        "total_length-nopunct": 947,
        "mean_pred_length-nopunct": 3.7430830039525693,
        "std_pred_length-nopunct": 4.754985066769947,
        "median_pred_length-nopunct": 2.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.4276663146779303,
        "vocab_size-1-nopunct": 405,
        "unique-1-nopunct": 266,
        "entropy-1-nopunct": 7.490168040956257,
        "distinct-2-nopunct": 0.498567335243553,
        "vocab_size-2-nopunct": 348,
        "unique-2-nopunct": 236,
        "entropy-2-nopunct": 7.66971582587688,
        "cond_entropy-2-nopunct": 0.5107610495108182,
        "distinct-3-nopunct": 0.5180505415162455,
        "vocab_size-3-nopunct": 287,
        "unique-3-nopunct": 194,
        "entropy-3-nopunct": 7.590805701876698,
        "cond_entropy-3-nopunct": 0.21767149757486745,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.5964330567535207,
        "rouge1": {
            "precision": 0.11643,
            "recall": 0.23263,
            "fmeasure": 0.13309
        },
        "rouge2": {
            "precision": 0.05098,
            "recall": 0.10194,
            "fmeasure": 0.05522
        },
        "rougeL": {
            "precision": 0.11604,
            "recall": 0.23214,
            "fmeasure": 0.13265
        },
        "rougeLsum": {
            "precision": 0.11604,
            "recall": 0.23214,
            "fmeasure": 0.13265
        },
        "bleu": 0.63538,
        "local_recall": {
            "1": 0.019795221843003412,
            "2": 0.029288702928870293,
            "3": 0.030716723549488054,
            "4": 0.08571428571428572,
            "5": 0.09090909090909091,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.60825,
            "recall": 0.51952,
            "f1": 0.55795
        },
        "nubia": {
            "semantic_relation": 1.8635,
            "contradiction": 41.08459,
            "irrelevancy": 32.42859,
            "logical_agreement": 26.48681,
            "grammar_ref": 2.90527,
            "grammar_hyp": 6.60095,
            "nubia_score": 0.13428
        },
        "meteor": 0.033263739040091486,
        "bleurt": -1.34812
    },
    "wiki_lingua_spanish_es_validation": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_lingua_spanish_es_validation",
        "N": 11316,
        "msttr-100": 0.56604,
        "msttr-100_nopunct": 0.59507,
        "total_length": 223752,
        "mean_pred_length": 19.77306468716861,
        "std_pred_length": 8.753746004768438,
        "median_pred_length": 23.0,
        "min_pred_length": 0,
        "max_pred_length": 67,
        "distinct-1": 0.06732453788122564,
        "vocab_size-1": 15064,
        "unique-1": 6579,
        "entropy-1": 9.093254163595537,
        "distinct-2": 0.29249563863953765,
        "vocab_size-2": 62203,
        "unique-2": 38318,
        "entropy-2": 13.832967810722302,
        "cond_entropy-2": 4.731598816297259,
        "distinct-3": 0.5529253023523459,
        "vocab_size-3": 111462,
        "unique-3": 83622,
        "entropy-3": 15.79235377822248,
        "cond_entropy-3": 2.0461762744275,
        "total_length-nopunct": 200029,
        "mean_pred_length-nopunct": 17.67665252739484,
        "std_pred_length-nopunct": 7.964494999285862,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 44,
        "distinct-1-nopunct": 0.07516910048043034,
        "vocab_size-1-nopunct": 15036,
        "unique-1-nopunct": 6577,
        "entropy-1-nopunct": 9.455239770430977,
        "distinct-2-nopunct": 0.3388816851464712,
        "vocab_size-2-nopunct": 64030,
        "unique-2-nopunct": 41812,
        "entropy-2-nopunct": 14.08936724591085,
        "cond_entropy-2-nopunct": 4.828591415993448,
        "distinct-3-nopunct": 0.60506320583594,
        "vocab_size-3-nopunct": 107743,
        "unique-3-nopunct": 83493,
        "entropy-3-nopunct": 15.925102920397153,
        "cond_entropy-3-nopunct": 1.9349992581510813,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_validation.json",
        "nist": 0.0649363836243753,
        "rouge1": {
            "precision": 0.02542,
            "recall": 0.01514,
            "fmeasure": 0.01657
        },
        "rouge2": {
            "precision": 0.00076,
            "recall": 0.00043,
            "fmeasure": 0.00049
        },
        "rougeL": {
            "precision": 0.02433,
            "recall": 0.01452,
            "fmeasure": 0.01585
        },
        "rougeLsum": {
            "precision": 0.02433,
            "recall": 0.01452,
            "fmeasure": 0.01585
        },
        "bleu": 0.03952,
        "local_recall": {
            "1": 0.01208541192677785
        },
        "sari": 40.97424,
        "bertscore": {
            "precision": 0.6004,
            "recall": 0.62427,
            "f1": 0.6072
        },
        "nubia": {
            "semantic_relation": 2.12136,
            "contradiction": 28.74767,
            "irrelevancy": 44.63769,
            "logical_agreement": 26.58813,
            "grammar_ref": 3.95572,
            "grammar_hyp": 4.87314,
            "nubia_score": 0.19295
        },
        "meteor": 0.012826960748353747,
        "bleurt": -1.37694
    },
    "wiki_lingua_spanish_es_test": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_lingua_spanish_es_test",
        "N": 22632,
        "msttr-100": 0.56607,
        "msttr-100_nopunct": 0.59493,
        "total_length": 443692,
        "mean_pred_length": 19.604630611523508,
        "std_pred_length": 8.74711040180716,
        "median_pred_length": 23.0,
        "min_pred_length": 0,
        "max_pred_length": 62,
        "distinct-1": 0.04965156009123446,
        "vocab_size-1": 22030,
        "unique-1": 9221,
        "entropy-1": 9.155538456589875,
        "distinct-2": 0.24264925674104793,
        "vocab_size-2": 102282,
        "unique-2": 61317,
        "entropy-2": 14.126725571560392,
        "cond_entropy-2": 4.962747326658334,
        "distinct-3": 0.49973834246839455,
        "vocab_size-3": 199584,
        "unique-3": 146498,
        "entropy-3": 16.378546532088944,
        "cond_entropy-3": 2.344034459645796,
        "total_length-nopunct": 396576,
        "mean_pred_length-nopunct": 17.522799575821846,
        "std_pred_length-nopunct": 7.992900248043338,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 52,
        "distinct-1-nopunct": 0.05547990801258775,
        "vocab_size-1-nopunct": 22002,
        "unique-1-nopunct": 9221,
        "entropy-1-nopunct": 9.52770410221201,
        "distinct-2-nopunct": 0.28713746584653843,
        "vocab_size-2-nopunct": 107508,
        "unique-2-nopunct": 68728,
        "entropy-2-nopunct": 14.427410196765837,
        "cond_entropy-2-nopunct": 5.100993247627495,
        "distinct-3-nopunct": 0.5558611538003505,
        "vocab_size-3-nopunct": 196040,
        "unique-3-nopunct": 149028,
        "entropy-3-nopunct": 16.570316356061625,
        "cond_entropy-3-nopunct": 2.2514041428389753,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_spanish_es_test.json",
        "nist": 0.06132459237003833,
        "rouge1": {
            "precision": 0.02575,
            "recall": 0.01534,
            "fmeasure": 0.01687
        },
        "rouge2": {
            "precision": 0.00104,
            "recall": 0.00055,
            "fmeasure": 0.00061
        },
        "rougeL": {
            "precision": 0.02466,
            "recall": 0.01468,
            "fmeasure": 0.01612
        },
        "rougeLsum": {
            "precision": 0.02466,
            "recall": 0.01468,
            "fmeasure": 0.01612
        },
        "bleu": 0.06551,
        "local_recall": {
            "1": 0.012051669264182958
        },
        "sari": 40.98232,
        "bertscore": {
            "precision": 0.60078,
            "recall": 0.62399,
            "f1": 0.60719
        },
        "nubia": {
            "semantic_relation": 2.12532,
            "contradiction": 28.83222,
            "irrelevancy": 44.60235,
            "logical_agreement": 26.53892,
            "grammar_ref": 3.94857,
            "grammar_hyp": 4.86541,
            "nubia_score": 0.19252
        },
        "meteor": 0.012831965602837713,
        "bleurt": -1.37984
    },
    "wiki_lingua_turkish_tr_validation": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_lingua_turkish_tr_validation",
        "N": 449,
        "msttr-100": 0.56769,
        "msttr-100_nopunct": 0.62687,
        "total_length": 7863,
        "mean_pred_length": 17.51224944320713,
        "std_pred_length": 7.820392312407398,
        "median_pred_length": 19.0,
        "min_pred_length": 0,
        "max_pred_length": 70,
        "distinct-1": 0.2659290347195727,
        "vocab_size-1": 2091,
        "unique-1": 1171,
        "entropy-1": 8.779945329106825,
        "distinct-2": 0.5388336468691212,
        "vocab_size-2": 4010,
        "unique-2": 2906,
        "entropy-2": 10.99256117456276,
        "cond_entropy-2": 2.2053705317292778,
        "distinct-3": 0.6978068926231843,
        "vocab_size-3": 4900,
        "unique-3": 3890,
        "entropy-3": 11.895531069164937,
        "cond_entropy-3": 0.9454669643519203,
        "total_length-nopunct": 6714,
        "mean_pred_length-nopunct": 14.953229398663698,
        "std_pred_length-nopunct": 6.260851215701351,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 32,
        "distinct-1-nopunct": 0.30905570449806374,
        "vocab_size-1-nopunct": 2075,
        "unique-1-nopunct": 1170,
        "entropy-1-nopunct": 9.333803094528657,
        "distinct-2-nopunct": 0.6205307484506595,
        "vocab_size-2-nopunct": 3905,
        "unique-2-nopunct": 2931,
        "entropy-2-nopunct": 11.359347937752489,
        "cond_entropy-2-nopunct": 2.11473709259799,
        "distinct-3-nopunct": 0.7665985699693565,
        "vocab_size-3-nopunct": 4503,
        "unique-3-nopunct": 3728,
        "entropy-3-nopunct": 11.902243988156131,
        "cond_entropy-3-nopunct": 0.589397183521356,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_validation.json",
        "nist": 0.028346826681226452,
        "rouge1": {
            "precision": 0.02517,
            "recall": 0.01597,
            "fmeasure": 0.01832
        },
        "rouge2": {
            "precision": 0.00075,
            "recall": 0.00042,
            "fmeasure": 0.00054
        },
        "rougeL": {
            "precision": 0.02377,
            "recall": 0.01512,
            "fmeasure": 0.0173
        },
        "rougeLsum": {
            "precision": 0.02377,
            "recall": 0.01512,
            "fmeasure": 0.0173
        },
        "bleu": 0.04172,
        "local_recall": {
            "1": 0.011183261183261184
        },
        "sari": 44.63709,
        "bertscore": {
            "precision": 0.56297,
            "recall": 0.62006,
            "f1": 0.57664
        },
        "nubia": {
            "semantic_relation": 2.27533,
            "contradiction": 28.41586,
            "irrelevancy": 38.50483,
            "logical_agreement": 33.07931,
            "grammar_ref": 3.85457,
            "grammar_hyp": 4.81021,
            "nubia_score": 0.20374
        },
        "meteor": 0.01308903174579874,
        "bleurt": -1.38189
    },
    "wiki_lingua_turkish_tr_test": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_lingua_turkish_tr_test",
        "N": 900,
        "msttr-100": 0.57409,
        "msttr-100_nopunct": 0.63299,
        "total_length": 14972,
        "mean_pred_length": 16.635555555555555,
        "std_pred_length": 7.82051875390929,
        "median_pred_length": 19.0,
        "min_pred_length": 0,
        "max_pred_length": 62,
        "distinct-1": 0.2230162970878974,
        "vocab_size-1": 3339,
        "unique-1": 1796,
        "entropy-1": 9.018394334651543,
        "distinct-2": 0.4980536485243117,
        "vocab_size-2": 7037,
        "unique-2": 5029,
        "entropy-2": 11.571614278462318,
        "cond_entropy-2": 2.527796351829772,
        "distinct-3": 0.6648355782978403,
        "vocab_size-3": 8835,
        "unique-3": 6926,
        "entropy-3": 12.635862224731683,
        "cond_entropy-3": 1.1060035015609675,
        "total_length-nopunct": 12740,
        "mean_pred_length-nopunct": 14.155555555555555,
        "std_pred_length-nopunct": 6.486415053549501,
        "median_pred_length-nopunct": 16.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 31,
        "distinct-1-nopunct": 0.26043956043956046,
        "vocab_size-1-nopunct": 3318,
        "unique-1-nopunct": 1792,
        "entropy-1-nopunct": 9.656636579071538,
        "distinct-2-nopunct": 0.5813093537272039,
        "vocab_size-2-nopunct": 6917,
        "unique-2-nopunct": 5124,
        "entropy-2-nopunct": 12.044804964363717,
        "cond_entropy-2-nopunct": 2.48766080768961,
        "distinct-3-nopunct": 0.7457075727453462,
        "vocab_size-3-nopunct": 8252,
        "unique-3-nopunct": 6751,
        "entropy-3-nopunct": 12.722255392289403,
        "cond_entropy-3-nopunct": 0.7313064199827607,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_turkish_tr_test.json",
        "nist": 0.022657874582155478,
        "rouge1": {
            "precision": 0.03379,
            "recall": 0.01873,
            "fmeasure": 0.02147
        },
        "rouge2": {
            "precision": 0.00206,
            "recall": 0.00105,
            "fmeasure": 0.00133
        },
        "rougeL": {
            "precision": 0.03188,
            "recall": 0.01759,
            "fmeasure": 0.02012
        },
        "rougeLsum": {
            "precision": 0.03188,
            "recall": 0.01759,
            "fmeasure": 0.02012
        },
        "bleu": 0.0409,
        "local_recall": {
            "1": 0.012902061623133487
        },
        "sari": 44.23546,
        "bertscore": {
            "precision": 0.56562,
            "recall": 0.62158,
            "f1": 0.57846
        },
        "nubia": {
            "semantic_relation": 2.28469,
            "contradiction": 28.22819,
            "irrelevancy": 38.72107,
            "logical_agreement": 32.93963,
            "grammar_ref": 3.8726,
            "grammar_hyp": 4.94971,
            "nubia_score": 0.2037
        },
        "meteor": 0.01380522094007948,
        "bleurt": -1.39731
    },
    "wiki_lingua_vietnamese_vi_validation": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_lingua_vietnamese_vi_validation",
        "N": 1957,
        "msttr-100": 0.59417,
        "msttr-100_nopunct": 0.68,
        "total_length": 45644,
        "mean_pred_length": 23.3234542667348,
        "std_pred_length": 5.5764420468126294,
        "median_pred_length": 25.0,
        "min_pred_length": 3,
        "max_pred_length": 38,
        "distinct-1": 0.10316799579353256,
        "vocab_size-1": 4709,
        "unique-1": 2198,
        "entropy-1": 8.544986207576876,
        "distinct-2": 0.389543800215167,
        "vocab_size-2": 17018,
        "unique-2": 11624,
        "entropy-2": 12.754239642942476,
        "cond_entropy-2": 4.168196686459615,
        "distinct-3": 0.6925952552120777,
        "vocab_size-3": 28902,
        "unique-3": 24237,
        "entropy-3": 14.324016335364208,
        "cond_entropy-3": 1.6150807762374768,
        "total_length-nopunct": 38185,
        "mean_pred_length-nopunct": 19.512008175779254,
        "std_pred_length-nopunct": 5.137106775553582,
        "median_pred_length-nopunct": 20.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 34,
        "distinct-1-nopunct": 0.12303260442582166,
        "vocab_size-1-nopunct": 4698,
        "unique-1-nopunct": 2197,
        "entropy-1-nopunct": 9.402507146045822,
        "distinct-2-nopunct": 0.5282378270950646,
        "vocab_size-2-nopunct": 19137,
        "unique-2-nopunct": 14664,
        "entropy-2-nopunct": 13.30173238641541,
        "cond_entropy-2-nopunct": 4.034352464118421,
        "distinct-3-nopunct": 0.8181844708354002,
        "vocab_size-3-nopunct": 28040,
        "unique-3-nopunct": 25068,
        "entropy-3-nopunct": 14.532042150803935,
        "cond_entropy-3-nopunct": 1.28083104383683,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_validation.json",
        "nist": 1.6389215046985086,
        "rouge1": {
            "precision": 0.41985,
            "recall": 0.28173,
            "fmeasure": 0.31776
        },
        "rouge2": {
            "precision": 0.1516,
            "recall": 0.10151,
            "fmeasure": 0.11429
        },
        "rougeL": {
            "precision": 0.34618,
            "recall": 0.23531,
            "fmeasure": 0.26381
        },
        "rougeLsum": {
            "precision": 0.34618,
            "recall": 0.23531,
            "fmeasure": 0.26381
        },
        "bleu": 7.4945,
        "local_recall": {
            "1": 0.23973249087104584
        },
        "sari": 67.13019,
        "bertscore": {
            "precision": 0.85447,
            "recall": 0.82255,
            "f1": 0.83769
        },
        "nubia": {
            "semantic_relation": 2.63773,
            "contradiction": 17.307,
            "irrelevancy": 43.59674,
            "logical_agreement": 39.09626,
            "grammar_ref": 3.90718,
            "grammar_hyp": 3.9088,
            "nubia_score": 0.32196
        },
        "meteor": 0.135813984362462,
        "bleurt": -0.47572
    },
    "wiki_lingua_vietnamese_vi_test": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_lingua_vietnamese_vi_test",
        "N": 3917,
        "msttr-100": 0.59222,
        "msttr-100_nopunct": 0.67665,
        "total_length": 91376,
        "mean_pred_length": 23.328057186622416,
        "std_pred_length": 5.613303577452393,
        "median_pred_length": 25.0,
        "min_pred_length": 2,
        "max_pred_length": 36,
        "distinct-1": 0.07256828926632813,
        "vocab_size-1": 6631,
        "unique-1": 2862,
        "entropy-1": 8.626499477879916,
        "distinct-2": 0.31789752912793423,
        "vocab_size-2": 27803,
        "unique-2": 18208,
        "entropy-2": 13.095829751543175,
        "cond_entropy-2": 4.433799219075048,
        "distinct-3": 0.6221660960953772,
        "vocab_size-3": 51977,
        "unique-3": 42001,
        "entropy-3": 14.970055327119468,
        "cond_entropy-3": 1.924414393676904,
        "total_length-nopunct": 76424,
        "mean_pred_length-nopunct": 19.51085014041358,
        "std_pred_length-nopunct": 5.1314801026774655,
        "median_pred_length-nopunct": 21.0,
        "min_pred_length-nopunct": 1,
        "max_pred_length-nopunct": 33,
        "distinct-1-nopunct": 0.08654349419030671,
        "vocab_size-1-nopunct": 6614,
        "unique-1-nopunct": 2857,
        "entropy-1-nopunct": 9.501354391133079,
        "distinct-2-nopunct": 0.4545354241659426,
        "vocab_size-2-nopunct": 32957,
        "unique-2-nopunct": 24379,
        "entropy-2-nopunct": 13.787190908164423,
        "cond_entropy-2-nopunct": 4.430968965658137,
        "distinct-3-nopunct": 0.7620533306118878,
        "vocab_size-3-nopunct": 52270,
        "unique-3-nopunct": 45337,
        "entropy-3-nopunct": 15.316788041903784,
        "cond_entropy-3-nopunct": 1.5888443855480652,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_vietnamese_vi_test.json",
        "nist": 1.7744302073965994,
        "rouge1": {
            "precision": 0.42648,
            "recall": 0.29086,
            "fmeasure": 0.3267
        },
        "rouge2": {
            "precision": 0.16044,
            "recall": 0.10871,
            "fmeasure": 0.12205
        },
        "rougeL": {
            "precision": 0.35328,
            "recall": 0.2439,
            "fmeasure": 0.27233
        },
        "rougeLsum": {
            "precision": 0.35328,
            "recall": 0.2439,
            "fmeasure": 0.27233
        },
        "bleu": 7.95628,
        "local_recall": {
            "1": 0.25006008296674015
        },
        "sari": 67.11478,
        "bertscore": {
            "precision": 0.85632,
            "recall": 0.82492,
            "f1": 0.83981
        },
        "nubia": {
            "semantic_relation": 2.6672,
            "contradiction": 16.95714,
            "irrelevancy": 42.14041,
            "logical_agreement": 40.90245,
            "grammar_ref": 3.92068,
            "grammar_hyp": 3.89844,
            "nubia_score": 0.33152
        },
        "meteor": 0.1388362654165148,
        "bleurt": -0.46834
    },
    "wiki_lingua_russian_ru_validation": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_lingua_russian_ru_validation",
        "N": 5288,
        "msttr-100": 0.57107,
        "msttr-100_nopunct": 0.6397,
        "total_length": 130039,
        "mean_pred_length": 24.591338880484116,
        "std_pred_length": 5.43093556786914,
        "median_pred_length": 26.0,
        "min_pred_length": 3,
        "max_pred_length": 51,
        "distinct-1": 0.06441144579703012,
        "vocab_size-1": 8376,
        "unique-1": 3487,
        "entropy-1": 8.752597477424692,
        "distinct-2": 0.30146451731849844,
        "vocab_size-2": 37608,
        "unique-2": 24563,
        "entropy-2": 13.366350364909097,
        "cond_entropy-2": 4.631190854235365,
        "distinct-3": 0.6069745444196111,
        "vocab_size-3": 72511,
        "unique-3": 58453,
        "entropy-3": 15.349309578314829,
        "cond_entropy-3": 2.039928003371512,
        "total_length-nopunct": 111196,
        "mean_pred_length-nopunct": 21.027987897125566,
        "std_pred_length-nopunct": 4.969914360452475,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 42,
        "distinct-1-nopunct": 0.07516457426526134,
        "vocab_size-1-nopunct": 8358,
        "unique-1-nopunct": 3481,
        "entropy-1-nopunct": 9.49913504389725,
        "distinct-2-nopunct": 0.4207047626241644,
        "vocab_size-2-nopunct": 44556,
        "unique-2-nopunct": 32453,
        "entropy-2-nopunct": 13.992177449448137,
        "cond_entropy-2-nopunct": 4.627061378372702,
        "distinct-3-nopunct": 0.7314649175114292,
        "vocab_size-3-nopunct": 73600,
        "unique-3-nopunct": 62921,
        "entropy-3-nopunct": 15.72969968075004,
        "cond_entropy-3-nopunct": 1.8038874572545733,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_validation.json",
        "nist": 1.6542714216148442,
        "rouge1": {
            "precision": 0.39975,
            "recall": 0.28272,
            "fmeasure": 0.30906
        },
        "rouge2": {
            "precision": 0.14282,
            "recall": 0.10172,
            "fmeasure": 0.11053
        },
        "rougeL": {
            "precision": 0.32974,
            "recall": 0.23777,
            "fmeasure": 0.25748
        },
        "rougeLsum": {
            "precision": 0.32974,
            "recall": 0.23777,
            "fmeasure": 0.25748
        },
        "bleu": 6.75938,
        "local_recall": {
            "1": 0.23234166277267232
        },
        "sari": 68.02055,
        "bertscore": {
            "precision": 0.84544,
            "recall": 0.81753,
            "f1": 0.83068
        },
        "nubia": {
            "semantic_relation": 2.65889,
            "contradiction": 17.24007,
            "irrelevancy": 46.48676,
            "logical_agreement": 36.27317,
            "grammar_ref": 3.95099,
            "grammar_hyp": 3.73913,
            "nubia_score": 0.3495
        },
        "meteor": 0.12611623085635074,
        "bleurt": -0.52458
    },
    "wiki_lingua_russian_ru_test": {
        "predictions_file": "ByT5-xl (Baseline)/wiki_lingua_russian_ru_test",
        "N": 10580,
        "msttr-100": 0.57137,
        "msttr-100_nopunct": 0.6403,
        "total_length": 259885,
        "mean_pred_length": 24.563799621928165,
        "std_pred_length": 5.4215136738381675,
        "median_pred_length": 26.0,
        "min_pred_length": 3,
        "max_pred_length": 46,
        "distinct-1": 0.0442041672278123,
        "vocab_size-1": 11488,
        "unique-1": 4520,
        "entropy-1": 8.813902682039327,
        "distinct-2": 0.24295541605663745,
        "vocab_size-2": 60570,
        "unique-2": 38551,
        "entropy-2": 13.63338804968874,
        "cond_entropy-2": 4.840274737913571,
        "distinct-3": 0.537551576081265,
        "vocab_size-3": 128327,
        "unique-3": 100254,
        "entropy-3": 15.910415798995764,
        "cond_entropy-3": 2.3402962077805936,
        "total_length-nopunct": 222217,
        "mean_pred_length-nopunct": 21.003497164461248,
        "std_pred_length-nopunct": 4.981979535785199,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 2,
        "max_pred_length-nopunct": 38,
        "distinct-1-nopunct": 0.05158471224073766,
        "vocab_size-1-nopunct": 11463,
        "unique-1-nopunct": 4518,
        "entropy-1-nopunct": 9.568847643848192,
        "distinct-2-nopunct": 0.35498991197191415,
        "vocab_size-2-nopunct": 75129,
        "unique-2-nopunct": 53095,
        "entropy-2-nopunct": 14.369083925418824,
        "cond_entropy-2-nopunct": 4.941312009854899,
        "distinct-3-nopunct": 0.6683627031140423,
        "vocab_size-3-nopunct": 134379,
        "unique-3-nopunct": 111836,
        "entropy-3-nopunct": 16.42158737089069,
        "cond_entropy-3-nopunct": 2.1290387753876283,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/wiki_lingua_russian_ru_test.json",
        "nist": 1.787506713765861,
        "rouge1": {
            "precision": 0.39966,
            "recall": 0.28426,
            "fmeasure": 0.31054
        },
        "rouge2": {
            "precision": 0.14397,
            "recall": 0.10057,
            "fmeasure": 0.11018
        },
        "rougeL": {
            "precision": 0.32983,
            "recall": 0.2385,
            "fmeasure": 0.25843
        },
        "rougeLsum": {
            "precision": 0.32983,
            "recall": 0.2385,
            "fmeasure": 0.25843
        },
        "bleu": 6.95953,
        "local_recall": {
            "1": 0.23469295842309512
        },
        "sari": 67.98275,
        "bertscore": {
            "precision": 0.84603,
            "recall": 0.81821,
            "f1": 0.83131
        },
        "nubia": {
            "semantic_relation": 2.664,
            "contradiction": 17.44145,
            "irrelevancy": 45.83315,
            "logical_agreement": 36.7254,
            "grammar_ref": 3.95647,
            "grammar_hyp": 3.71831,
            "nubia_score": 0.35053
        },
        "meteor": 0.12730467093077513,
        "bleurt": -0.52589
    },
    "dart_validation": {
        "predictions_file": "ByT5-xl (Baseline)/dart_validation",
        "N": 2768,
        "msttr-100": 0.47615,
        "msttr-100_nopunct": 0.48137,
        "total_length": 54605,
        "mean_pred_length": 19.727239884393065,
        "std_pred_length": 6.088077817727842,
        "median_pred_length": 21.0,
        "min_pred_length": 4,
        "max_pred_length": 33,
        "distinct-1": 0.06885816317187071,
        "vocab_size-1": 3760,
        "unique-1": 1772,
        "entropy-1": 7.864383976043451,
        "distinct-2": 0.23126338329764454,
        "vocab_size-2": 11988,
        "unique-2": 7702,
        "entropy-2": 10.9562915438872,
        "cond_entropy-2": 3.041708370482181,
        "distinct-3": 0.37428926613544194,
        "vocab_size-3": 18366,
        "unique-3": 13396,
        "entropy-3": 12.380477191088136,
        "cond_entropy-3": 1.5201783866590763,
        "total_length-nopunct": 49897,
        "mean_pred_length-nopunct": 18.026372832369944,
        "std_pred_length-nopunct": 5.855222052404276,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.07505461250175362,
        "vocab_size-1-nopunct": 3745,
        "unique-1-nopunct": 1769,
        "entropy-1-nopunct": 8.012664325886025,
        "distinct-2-nopunct": 0.23777292113136286,
        "vocab_size-2-nopunct": 11206,
        "unique-2-nopunct": 7325,
        "entropy-2-nopunct": 10.855137031530655,
        "cond_entropy-2-nopunct": 3.011901538390236,
        "distinct-3-nopunct": 0.37938729965510243,
        "vocab_size-3-nopunct": 16830,
        "unique-3-nopunct": 12388,
        "entropy-3-nopunct": 12.283100852688928,
        "cond_entropy-3-nopunct": 1.5261579588289544,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/dart_validation.json",
        "nist": 0.6091261436545529,
        "rouge1": {
            "precision": 0.04006,
            "recall": 0.72247,
            "fmeasure": 0.07534
        },
        "rouge2": {
            "precision": 0.0,
            "recall": 0.0,
            "fmeasure": 0.0
        },
        "rougeL": {
            "precision": 0.04006,
            "recall": 0.72247,
            "fmeasure": 0.07534
        },
        "rougeLsum": {
            "precision": 0.04006,
            "recall": 0.72247,
            "fmeasure": 0.07534
        },
        "bleu": 0.00601,
        "local_recall": {
            "1": 0.02084482864324689,
            "2": 0.014324351397375538,
            "3": 0.014285714285714285,
            "4": 0.02932497233493176,
            "5": 0.04745243822436038,
            "6": 0.06479956068094453,
            "7": 0.08557046979865772,
            "8": 0.09556451612903226,
            "9": 0.10033821871476889,
            "10": 0.11380323054331865,
            "11": 0.11855104281009879,
            "12": 0.10920436817472699,
            "13": 0.08971553610503283,
            "14": 0.06086956521739131,
            "15": 0.0660377358490566,
            "16": 0.0763888888888889,
            "17": 0.01282051282051282,
            "18": 0.06666666666666667,
            "19": 0.020833333333333332,
            "20": 0.08823529411764706,
            "21": 0.08695652173913043,
            "22": 0.0,
            "23": 0.06666666666666667,
            "24": 0.0,
            "25": 0.3333333333333333,
            "26": 0.0,
            "27": 0,
            "28": 0.0,
            "29": 0.0,
            "30": 0.0,
            "31": 0.0,
            "32": 0,
            "33": 0,
            "34": 0,
            "35": 0,
            "36": 0,
            "37": 0.0,
            "38": 0,
            "39": 0,
            "40": 0,
            "41": 0,
            "42": 0,
            "43": 0,
            "44": 0,
            "45": 0,
            "46": 0,
            "47": 0,
            "48": 0,
            "49": 0,
            "50": 0,
            "51": 0,
            "52": 0,
            "53": 0,
            "54": 0,
            "55": 0,
            "56": 0,
            "57": 0,
            "58": 0,
            "59": 0,
            "60": 0,
            "61": 0,
            "62": 0,
            "63": 0,
            "64": 0,
            "65": 0,
            "66": 0,
            "67": 0,
            "68": 0,
            "69": 0,
            "70": 0,
            "71": 0,
            "72": 0
        },
        "bertscore": {
            "precision": 0.90195,
            "recall": 0.8879,
            "f1": 0.89449
        },
        "nubia": {
            "semantic_relation": 4.06957,
            "contradiction": 6.61322,
            "irrelevancy": 19.99846,
            "logical_agreement": 73.38831,
            "grammar_ref": 4.89251,
            "grammar_hyp": 4.87159,
            "nubia_score": 0.6763
        },
        "meteor": 0.08283730141243345,
        "bleurt": 0.04202
    },
    "web_nlg_ru_validation": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_validation",
        "N": 790,
        "msttr-100": 0.24649,
        "msttr-100_nopunct": 0.38327,
        "total_length": 9722,
        "mean_pred_length": 12.30632911392405,
        "std_pred_length": 8.230067470879465,
        "median_pred_length": 10.0,
        "min_pred_length": 1,
        "max_pred_length": 39,
        "distinct-1": 0.09658506480148117,
        "vocab_size-1": 939,
        "unique-1": 459,
        "entropy-1": 5.91160341228398,
        "distinct-2": 0.1996193461710703,
        "vocab_size-2": 1783,
        "unique-2": 851,
        "entropy-2": 9.350728330464351,
        "cond_entropy-2": 3.6826100973976277,
        "distinct-3": 0.29986498097459185,
        "vocab_size-3": 2443,
        "unique-3": 1350,
        "entropy-3": 10.101363788057396,
        "cond_entropy-3": 0.8805106073096034,
        "total_length-nopunct": 4995,
        "mean_pred_length-nopunct": 6.322784810126582,
        "std_pred_length-nopunct": 4.486927548680839,
        "median_pred_length-nopunct": 5.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 24,
        "distinct-1-nopunct": 0.18618618618618618,
        "vocab_size-1-nopunct": 930,
        "unique-1-nopunct": 458,
        "entropy-1-nopunct": 8.27938299246293,
        "distinct-2-nopunct": 0.39205896338563956,
        "vocab_size-2-nopunct": 1649,
        "unique-2-nopunct": 986,
        "entropy-2-nopunct": 9.88628477113811,
        "cond_entropy-2-nopunct": 1.84138248432644,
        "distinct-3-nopunct": 0.5106746370623398,
        "vocab_size-3-nopunct": 1794,
        "unique-3-nopunct": 1202,
        "entropy-3-nopunct": 10.208296914178424,
        "cond_entropy-3-nopunct": 0.485125656410155,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_validation.json",
        "nist": 0.2531325977123483,
        "rouge1": {
            "precision": 0.03989,
            "recall": 0.11018,
            "fmeasure": 0.05187
        },
        "rouge2": {
            "precision": 0.0132,
            "recall": 0.02598,
            "fmeasure": 0.01529
        },
        "rougeL": {
            "precision": 0.03628,
            "recall": 0.10334,
            "fmeasure": 0.0473
        },
        "rougeLsum": {
            "precision": 0.03628,
            "recall": 0.10334,
            "fmeasure": 0.0473
        },
        "bleu": 0.24571,
        "local_recall": {
            "1": 0.0017955217574989438,
            "2": 0.007814065317571629,
            "3": 0.013841734134238705,
            "4": 0.0,
            "5": 0.0,
            "6": 0.0,
            "7": 0.0,
            "8": 0,
            "9": 0.0
        },
        "bertscore": {
            "precision": 0.58795,
            "recall": 0.52015,
            "f1": 0.5509
        },
        "nubia": {
            "semantic_relation": 2.21883,
            "contradiction": 34.48082,
            "irrelevancy": 34.63583,
            "logical_agreement": 30.88335,
            "grammar_ref": 2.60252,
            "grammar_hyp": 5.44239,
            "nubia_score": 0.22193
        },
        "meteor": 0.015543334290015552,
        "bleurt": -1.31188
    },
    "web_nlg_ru_test": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_ru_test",
        "N": 1102,
        "msttr-100": 0.35647,
        "msttr-100_nopunct": 0.57817,
        "total_length": 13939,
        "mean_pred_length": 12.648820326678766,
        "std_pred_length": 7.96003478514916,
        "median_pred_length": 12.0,
        "min_pred_length": 0,
        "max_pred_length": 60,
        "distinct-1": 0.12425568548676376,
        "vocab_size-1": 1732,
        "unique-1": 847,
        "entropy-1": 6.52472228374124,
        "distinct-2": 0.26834397881289923,
        "vocab_size-2": 3445,
        "unique-2": 1690,
        "entropy-2": 10.517767807167425,
        "cond_entropy-2": 4.209353435618675,
        "distinct-3": 0.41416290748148776,
        "vocab_size-3": 4866,
        "unique-3": 2904,
        "entropy-3": 11.398124579567655,
        "cond_entropy-3": 0.9854913404677742,
        "total_length-nopunct": 7194,
        "mean_pred_length-nopunct": 6.528130671506352,
        "std_pred_length-nopunct": 4.3362135193373845,
        "median_pred_length-nopunct": 6.0,
        "min_pred_length-nopunct": 0,
        "max_pred_length-nopunct": 26,
        "distinct-1-nopunct": 0.23839310536558242,
        "vocab_size-1-nopunct": 1715,
        "unique-1-nopunct": 842,
        "entropy-1-nopunct": 9.340425590511256,
        "distinct-2-nopunct": 0.54248687664042,
        "vocab_size-2-nopunct": 3307,
        "unique-2-nopunct": 2181,
        "entropy-2-nopunct": 11.203868656887257,
        "cond_entropy-2-nopunct": 2.039611926815033,
        "distinct-3-nopunct": 0.6713587487781036,
        "vocab_size-3-nopunct": 3434,
        "unique-3-nopunct": 2564,
        "entropy-3-nopunct": 11.437575085337922,
        "cond_entropy-3-nopunct": 0.3493273870614462,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_ru_test.json",
        "nist": 0.4136358936713223,
        "rouge1": {
            "precision": 0.06457,
            "recall": 0.19175,
            "fmeasure": 0.08506
        },
        "rouge2": {
            "precision": 0.02181,
            "recall": 0.05892,
            "fmeasure": 0.02684
        },
        "rougeL": {
            "precision": 0.06218,
            "recall": 0.18523,
            "fmeasure": 0.08176
        },
        "rougeLsum": {
            "precision": 0.06218,
            "recall": 0.18523,
            "fmeasure": 0.08176
        },
        "bleu": 0.40734,
        "local_recall": {
            "1": 0.004996074512882735,
            "2": 0.011971927893215908,
            "3": 0.018846799776077627,
            "4": 0.1038961038961039,
            "5": 0.02702702702702703,
            "6": 0.0,
            "7": 0.0
        },
        "bertscore": {
            "precision": 0.60064,
            "recall": 0.52717,
            "f1": 0.56007
        },
        "nubia": {
            "semantic_relation": 2.30794,
            "contradiction": 34.3741,
            "irrelevancy": 33.90211,
            "logical_agreement": 31.72379,
            "grammar_ref": 2.65213,
            "grammar_hyp": 5.00878,
            "nubia_score": 0.23828
        },
        "meteor": 0.020741409083589818,
        "bleurt": -1.30017
    },
    "web_nlg_en_validation": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_validation",
        "N": 1667,
        "msttr-100": 0.57058,
        "msttr-100_nopunct": 0.59525,
        "total_length": 31135,
        "mean_pred_length": 18.677264547090584,
        "std_pred_length": 6.552742426582859,
        "median_pred_length": 20.0,
        "min_pred_length": 4,
        "max_pred_length": 32,
        "distinct-1": 0.11617151116107274,
        "vocab_size-1": 3617,
        "unique-1": 1459,
        "entropy-1": 8.776946746407447,
        "distinct-2": 0.3794624677616397,
        "vocab_size-2": 11182,
        "unique-2": 6859,
        "entropy-2": 12.27214031982081,
        "cond_entropy-2": 3.3970157229151905,
        "distinct-3": 0.6082515017445416,
        "vocab_size-3": 16910,
        "unique-3": 12678,
        "entropy-3": 13.49492497142668,
        "cond_entropy-3": 1.2958006117911238,
        "total_length-nopunct": 27814,
        "mean_pred_length-nopunct": 16.68506298740252,
        "std_pred_length-nopunct": 6.086245670670799,
        "median_pred_length-nopunct": 18.0,
        "min_pred_length-nopunct": 3,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.12968289350686704,
        "vocab_size-1-nopunct": 3607,
        "unique-1-nopunct": 1459,
        "entropy-1-nopunct": 9.094887970851055,
        "distinct-2-nopunct": 0.39553294833059244,
        "vocab_size-2-nopunct": 10342,
        "unique-2-nopunct": 6541,
        "entropy-2-nopunct": 12.181440115942209,
        "cond_entropy-2-nopunct": 3.2573044265228424,
        "distinct-3-nopunct": 0.6174428104575164,
        "vocab_size-3-nopunct": 15115,
        "unique-3-nopunct": 11488,
        "entropy-3-nopunct": 13.336307826965811,
        "cond_entropy-3-nopunct": 1.2311927882214906,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_validation.json",
        "nist": 9.809068166949935,
        "rouge1": {
            "precision": 0.81665,
            "recall": 0.74957,
            "fmeasure": 0.7723
        },
        "rouge2": {
            "precision": 0.59827,
            "recall": 0.5513,
            "fmeasure": 0.56638
        },
        "rougeL": {
            "precision": 0.69169,
            "recall": 0.63965,
            "fmeasure": 0.65628
        },
        "rougeLsum": {
            "precision": 0.69169,
            "recall": 0.63965,
            "fmeasure": 0.65628
        },
        "bleu": 52.04718,
        "local_recall": {
            "1": 0.2853289375093661,
            "2": 0.6360153256704981,
            "3": 0.8122137404580153,
            "4": 0.8226950354609929,
            "5": 0.9714285714285714,
            "6": 1.0,
            "7": 1.0,
            "8": 1.0
        },
        "bertscore": {
            "precision": 0.94346,
            "recall": 0.93081,
            "f1": 0.93602
        },
        "nubia": {
            "semantic_relation": 4.3983,
            "contradiction": 3.97862,
            "irrelevancy": 6.81788,
            "logical_agreement": 89.2035,
            "grammar_ref": 4.59465,
            "grammar_hyp": 4.70361,
            "nubia_score": 0.7708
        },
        "meteor": 0.39128505192340024,
        "bleurt": 0.25132
    },
    "web_nlg_en_test": {
        "predictions_file": "ByT5-xl (Baseline)/web_nlg_en_test",
        "N": 1779,
        "msttr-100": 0.66798,
        "msttr-100_nopunct": 0.69427,
        "total_length": 33724,
        "mean_pred_length": 18.95671725688589,
        "std_pred_length": 6.405260065648328,
        "median_pred_length": 21.0,
        "min_pred_length": 5,
        "max_pred_length": 32,
        "distinct-1": 0.05770371248962163,
        "vocab_size-1": 1946,
        "unique-1": 606,
        "entropy-1": 8.163478939732991,
        "distinct-2": 0.2116137110658945,
        "vocab_size-2": 6760,
        "unique-2": 3293,
        "entropy-2": 11.293896448411706,
        "cond_entropy-2": 3.071605903318078,
        "distinct-3": 0.37814095339123516,
        "vocab_size-3": 11407,
        "unique-3": 7009,
        "entropy-3": 12.524908201703795,
        "cond_entropy-3": 1.3369091210020863,
        "total_length-nopunct": 30741,
        "mean_pred_length-nopunct": 17.27993254637437,
        "std_pred_length-nopunct": 6.146816886562832,
        "median_pred_length-nopunct": 19.0,
        "min_pred_length-nopunct": 4,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.06301031196122442,
        "vocab_size-1-nopunct": 1937,
        "unique-1-nopunct": 605,
        "entropy-1-nopunct": 8.34349692970074,
        "distinct-2-nopunct": 0.218769422001243,
        "vocab_size-2-nopunct": 6336,
        "unique-2-nopunct": 3217,
        "entropy-2-nopunct": 11.186786028046491,
        "cond_entropy-2-nopunct": 3.026396413603752,
        "distinct-3-nopunct": 0.3848728985027407,
        "vocab_size-3-nopunct": 10462,
        "unique-3-nopunct": 6551,
        "entropy-3-nopunct": 12.387125776397784,
        "cond_entropy-3-nopunct": 1.3016615512412497,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/web_nlg_en_test.json",
        "nist": 6.946097362399909,
        "rouge1": {
            "precision": 0.78267,
            "recall": 0.6862,
            "fmeasure": 0.71821
        },
        "rouge2": {
            "precision": 0.52767,
            "recall": 0.45944,
            "fmeasure": 0.48139
        },
        "rougeL": {
            "precision": 0.64407,
            "recall": 0.56494,
            "fmeasure": 0.59076
        },
        "rougeLsum": {
            "precision": 0.64407,
            "recall": 0.56494,
            "fmeasure": 0.59076
        },
        "bleu": 40.09335,
        "local_recall": {
            "1": 0.19238051523323196,
            "2": 0.5008254831504322,
            "3": 0.7509230769230769,
            "4": 0.8909090909090909,
            "5": 0.7241379310344828
        },
        "bertscore": {
            "precision": 0.92318,
            "recall": 0.90241,
            "f1": 0.91114
        },
        "nubia": {
            "semantic_relation": 4.15816,
            "contradiction": 6.72877,
            "irrelevancy": 9.94675,
            "logical_agreement": 83.32449,
            "grammar_ref": 4.5596,
            "grammar_hyp": 4.78661,
            "nubia_score": 0.68452
        },
        "meteor": 0.3309239148350566,
        "bleurt": 0.07367
    },
    "e2e_nlg_validation": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_validation",
        "N": 4299,
        "msttr-100": 0.31254,
        "msttr-100_nopunct": 0.3032,
        "total_length": 95343,
        "mean_pred_length": 22.17794836008374,
        "std_pred_length": 4.446128118538761,
        "median_pred_length": 24.0,
        "min_pred_length": 7,
        "max_pred_length": 31,
        "distinct-1": 0.006314045079345102,
        "vocab_size-1": 602,
        "unique-1": 90,
        "entropy-1": 6.284943884435206,
        "distinct-2": 0.028854180396291902,
        "vocab_size-2": 2627,
        "unique-2": 586,
        "entropy-2": 8.564459044684929,
        "cond_entropy-2": 2.305409392287312,
        "distinct-3": 0.06098334197936481,
        "vocab_size-3": 5290,
        "unique-3": 1449,
        "entropy-3": 10.077605549082108,
        "cond_entropy-3": 1.5905905011265455,
        "total_length-nopunct": 88822,
        "mean_pred_length-nopunct": 20.661083973016982,
        "std_pred_length-nopunct": 4.312874189562091,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 6,
        "max_pred_length-nopunct": 29,
        "distinct-1-nopunct": 0.006721307784107541,
        "vocab_size-1-nopunct": 597,
        "unique-1-nopunct": 90,
        "entropy-1-nopunct": 6.306280191748888,
        "distinct-2-nopunct": 0.031210439761958284,
        "vocab_size-2-nopunct": 2638,
        "unique-2-nopunct": 612,
        "entropy-2-nopunct": 8.528363538123038,
        "cond_entropy-2-nopunct": 2.3294112585699716,
        "distinct-3-nopunct": 0.0641578579976067,
        "vocab_size-3-nopunct": 5147,
        "unique-3-nopunct": 1419,
        "entropy-3-nopunct": 10.062872199595306,
        "cond_entropy-3-nopunct": 1.6090832556170207,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_validation.json",
        "nist": 4.562695987225723,
        "rouge1": {
            "precision": 0.67724,
            "recall": 0.63567,
            "fmeasure": 0.64548
        },
        "rouge2": {
            "precision": 0.38665,
            "recall": 0.36089,
            "fmeasure": 0.36743
        },
        "rougeL": {
            "precision": 0.49243,
            "recall": 0.46429,
            "fmeasure": 0.47046
        },
        "rougeLsum": {
            "precision": 0.49243,
            "recall": 0.46429,
            "fmeasure": 0.47046
        },
        "bleu": 24.75173,
        "local_recall": {
            "1": 0.6180936920756629
        },
        "bertscore": {
            "precision": 0.89546,
            "recall": 0.88444,
            "f1": 0.88959
        },
        "nubia": {
            "semantic_relation": 3.95322,
            "contradiction": 3.99735,
            "irrelevancy": 28.09263,
            "logical_agreement": 67.91002,
            "grammar_ref": 4.85661,
            "grammar_hyp": 4.74659,
            "nubia_score": 0.65282
        },
        "meteor": 0.31806382782151726,
        "bleurt": -0.01763
    },
    "e2e_nlg_test": {
        "predictions_file": "ByT5-xl (Baseline)/e2e_nlg_test",
        "N": 4693,
        "msttr-100": 0.31053,
        "msttr-100_nopunct": 0.30307,
        "total_length": 104626,
        "mean_pred_length": 22.29405497549542,
        "std_pred_length": 3.974514060165158,
        "median_pred_length": 23.0,
        "min_pred_length": 9,
        "max_pred_length": 32,
        "distinct-1": 0.005237703821229904,
        "vocab_size-1": 548,
        "unique-1": 74,
        "entropy-1": 6.178274134264917,
        "distinct-2": 0.024236238279647365,
        "vocab_size-2": 2422,
        "unique-2": 537,
        "entropy-2": 8.391821222520159,
        "cond_entropy-2": 2.252790684849803,
        "distinct-3": 0.05356992860142797,
        "vocab_size-3": 5102,
        "unique-3": 1298,
        "entropy-3": 9.865032406956688,
        "cond_entropy-3": 1.5605917031640733,
        "total_length-nopunct": 98006,
        "mean_pred_length-nopunct": 20.883443426379714,
        "std_pred_length-nopunct": 3.895427325658159,
        "median_pred_length-nopunct": 22.0,
        "min_pred_length-nopunct": 8,
        "max_pred_length-nopunct": 30,
        "distinct-1-nopunct": 0.005550680570577312,
        "vocab_size-1-nopunct": 544,
        "unique-1-nopunct": 74,
        "entropy-1-nopunct": 6.187445441637362,
        "distinct-2-nopunct": 0.026116403930856364,
        "vocab_size-2-nopunct": 2437,
        "unique-2-nopunct": 555,
        "entropy-2-nopunct": 8.369372787100732,
        "cond_entropy-2-nopunct": 2.296946248117463,
        "distinct-3-nopunct": 0.056556082148499214,
        "vocab_size-3-nopunct": 5012,
        "unique-3-nopunct": 1302,
        "entropy-3-nopunct": 9.885862105833047,
        "cond_entropy-3-nopunct": 1.5899493668720288,
        "references_file": "/usr/local/google/home/gehrmann/Documents/GEM-metrics/data/references/e2e_nlg_test.json",
        "nist": 4.67672323981074,
        "rouge1": {
            "precision": 0.73749,
            "recall": 0.65185,
            "fmeasure": 0.68162
        },
        "rouge2": {
            "precision": 0.42499,
            "recall": 0.37479,
            "fmeasure": 0.39191
        },
        "rougeL": {
            "precision": 0.52336,
            "recall": 0.46558,
            "fmeasure": 0.4852
        },
        "rougeLsum": {
            "precision": 0.52336,
            "recall": 0.46558,
            "fmeasure": 0.4852
        },
        "bleu": 25.35335,
        "local_recall": {
            "1": 0.6358806419059303
        },
        "bertscore": {
            "precision": 0.90943,
            "recall": 0.88975,
            "f1": 0.89914
        },
        "nubia": {
            "semantic_relation": 4.09159,
            "contradiction": 3.57192,
            "irrelevancy": 21.54966,
            "logical_agreement": 74.87843,
            "grammar_ref": 4.83021,
            "grammar_hyp": 4.8004,
            "nubia_score": 0.68399
        },
        "meteor": 0.3235242127663325,
        "bleurt": 0.02197
    }
}
